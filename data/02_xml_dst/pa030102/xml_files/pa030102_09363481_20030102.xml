<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001827A1-20030102-D00000.TIF SYSTEM "US20030001827A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00001.TIF SYSTEM "US20030001827A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00002.TIF SYSTEM "US20030001827A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00003.TIF SYSTEM "US20030001827A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00004.TIF SYSTEM "US20030001827A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00005.TIF SYSTEM "US20030001827A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00006.TIF SYSTEM "US20030001827A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00007.TIF SYSTEM "US20030001827A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00008.TIF SYSTEM "US20030001827A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00009.TIF SYSTEM "US20030001827A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001827A1-20030102-D00010.TIF SYSTEM "US20030001827A1-20030102-D00010.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001827</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09363481</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>19990729</filing-date>
<continued-prosecution-application>This is a publication of a continued prosecution application (CPA) filed under 37 CFR 1.53(d).</continued-prosecution-application>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>9816759.6</doc-number>
</priority-application-number>
<filing-date>19980731</filing-date>
<country-code>GB</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G09G005/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>345</class>
<subclass>204000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>CACHING IN DIGITAL VIDEO PROCESSING APPARATUS</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>ANTONY JAMES</given-name>
<family-name>GOULD</family-name>
</name>
<residence>
<residence-non-us>
<city>BASINGSTOKE</city>
<country-code>GB</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>FROMMER LAWRENCE &amp; HAUG</name-1>
<name-2></name-2>
<address>
<address-1>745 FIFTH AVENUE- 10TH FL.</address-1>
<city>NEW YORK</city>
<state>NY</state>
<postalcode>10151</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Video processing apparatus in which successive video processing operations are applied to images of a video signal to generate corresponding processing results in the form of images or data comprises a cache store for storing, as cached items and processing results associated with the video processing operations; and means for deleting currently cached items to provide cache space for items to be newly cached, the deleting means operating so that non-image processing results are retained in the cache for longer than processing results in the form of images. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> This invention relates to caching in digital video processing apparatus. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Prior Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> In video processing apparatus, such as a video special effects apparatus, digital processing is applied to images of a video sequence. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In one example of such a system, the user can set up a composite special effect to be applied to a video sequence by selecting a succession of effects modules from a large number of available modules. For example, a sequence (or &ldquo;directed acyclic graph&rdquo;) of effects set up by a user might comprise: </paragraph>
<paragraph id="P-0006" lvl="2"><number>&lsqb;0006&rsqb;</number> (i) image loader </paragraph>
<paragraph id="P-0007" lvl="2"><number>&lsqb;0007&rsqb;</number> (ii) motion tracker </paragraph>
<paragraph id="P-0008" lvl="2"><number>&lsqb;0008&rsqb;</number> (iii) lighting effect linked to motion tracking and image loader </paragraph>
<paragraph id="P-0009" lvl="2"><number>&lsqb;0009&rsqb;</number> (iv) image realignment linked to motion tracking and image loader </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Once a particular effect has been selected and all the parameters defined, a &ldquo;rendering&rdquo; operation has to take place. Rendering is the process of generating an output image, a series of images forming an output video sequence or an intermediate data type such as a motion vector or a position within an image, according to the processing operation which has been set up. For example, a lighting effect might involve the user selecting a source and a destination position for a computer-generated spotlight to be applied to a video sequence. Once these positions have been defined, the next task is to render each image in the output sequence by applying the defined lighting effect to determine the colour and luminance of each pixel of each output image. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> With current processing systems, rendering can be very time consuming, typically taking between a few seconds and many hours (depending on the sequence length) to render each image of a video sequence. To alleviate the delays experienced by a user, the processing parameters and the results (rendered images or other result data such as a motion vector in the case of a motion tracking effect) for some or all of the processing operations in the composite effects are cached. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> A main reason for caching the results is that if an effect at a particular position in the directed acyclic graph is altered&mdash;for example, a parameter change&mdash;the results of preceding effects in the directed acyclic graph can then be re-used directly from the cache when the changed effect has to be re-rendered. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> This also enables an operation to be &ldquo;undone&rdquo; very quickly&mdash;for example if a user tries a new set of parameters, does not like the result, and so desires to return to the previous working state of the apparatus before the latest change was made. Instead of re-entering the processing parameters and the apparatus re-rendering the resulting images, they can instead be retrieved quickly from the cache. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Because the cache has a finite capacity, from time to time the cache has to be cleared to make room available for new items to be cached. Generally, the least recently used items in the cache are discarded. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> This invention provides video processing apparatus in which successive video processing operations are applied to images of a video signal to generate corresponding processing results in the form of images or data, the apparatus comprising: </paragraph>
<paragraph id="P-0016" lvl="2"><number>&lsqb;0016&rsqb;</number> a cache store for storing, as cached items and processing results associated with the video processing operations; and </paragraph>
<paragraph id="P-0017" lvl="2"><number>&lsqb;0017&rsqb;</number> means for deleting currently cached items to provide cache space for items to be newly cached, the deleting means operating so that non-image processing results are retained in the cache for longer than processing results in the form of images. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The invention recognises that of the three classes of data referred to above, namely parameter data, image data and non-image result data (e.g. a motion vector), the image data generally occupies vastly more cache space than data in the other two classes. However, non-image result data can still take a long time to render, and so is worth retaining in the cache. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Accordingly, in the invention, non-image result data is retained preferentially over image result data. This non-image result data is therefore available from the cache for a longer period, at the expense of just a small amount of cache storage in comparison with the space required to cache an image. Indeed, it is preferred that non-image result data is never flushed from the cache&mdash;at least, during a particular operating session of the apparatus. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> The above, and other objects, features and advantages of this invention will be apparent from the following detailed description of illustrative embodiments which is to be read in connection with the accompanying drawings.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> schematically illustrates a digital video special effects apparatus; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> schematically illustrates the organisation of operating software of the apparatus of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a more detailed schematic illustration of the organisation of operating software for the apparatus of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> schematically illustrates the propagation of an updated effects parameter in the apparatus of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> schematically illustrates the propagation of a re-render command in the apparatus of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> schematically illustrates a graph editor window and a palette window; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> schematically illustrates a graph editing operation; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> schematically illustrates the creation of a composite effect icon; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> schematically illustrates the file structure of a composite effect; </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> schematically illustrates a viewer window; </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> schematically illustrates an initial arrangement of the operating software; </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> schematically illustrates a previously proposed effects plug-in; </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> schematically illustrates a new form of effects plug-in; </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> schematically illustrates the relationship between the effects servers and proxy effects for the effects plug-in of <cross-reference target="DRAWINGS">FIG. 13</cross-reference>; </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> schematically illustrates a system cache; and </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> schematically illustrates a plug-in interface.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> schematically illustrates a digital video special effects apparatus. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> A digital video signal, comprising successive video images, is received via an input interface <highlight><bold>100</bold></highlight> and stored in a disk array device <highlight><bold>110</bold></highlight>. The disk array device <highlight><bold>110</bold></highlight> also stores any manipulated images generated by the apparatus, and these can be supplied for output via an output interface <highlight><bold>120</bold></highlight>. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> A central processing unit <highlight><bold>130</bold></highlight> accesses data stored in the disk array to carry out various video special effects in accordance with user commands. The CPU <highlight><bold>130</bold></highlight> receives input from user input devices <highlight><bold>140</bold></highlight> such as a mouse and a keyboard, stores working data and programme code in a memory <highlight><bold>150</bold></highlight>, and generates data for output on a display screen <highlight><bold>160</bold></highlight> via a display driver <highlight><bold>170</bold></highlight>. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The apparatus can be implemented as a general purpose computer (e.g. a PC) running appropriate software, for example under the Microsoft Windows NT&reg; operating system. In the present embodiment, the disk array is connected to the CPU <highlight><bold>130</bold></highlight> via an UltraSCSI data link. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> schematically illustrates (at a very general level) the organisation of operating software for the apparatus of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The software is arranged as two categories of programme code: a core framework, shown to the left-hand side of <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, and various &ldquo;plug-ins&rdquo;, shown to the right-hand side of <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Once the software has been initially loaded, the core framework is always present and controls parts of the operation of the apparatus which are shared between different special effects processes. In contrast, the plug-ins relate to individual special effects (such as a lighting effect, a motion-tracking effect, and so on) and are loaded only when needed. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> This is a very efficient arrangement because only those plug-ins relating to effects modules current required by the user need be loaded into memory. This saves memory in comparison with a system in which a programme code for every possible special effect has to be loaded. It also allows for a more rapid initialisation of the apparatus, avoiding the need to load all of the program code into memory when the system is first started up, and can reduce any delays through code loading when an icon is first selected in the graph editor (see below). Furthermore, the arrangement allows a reduced subset of the apparatus (in particular, the operating software) to be supplied or installed, containing just a graph editor and the core processing but without the plug-ins. The system also allows third parties or users to produce their own plug-ins, so long as they stick to a defined interface protocol between the plug-ins and the core framework. So, a user could produce a bespoke effect very simply by writing a relatively small plug-in programme. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> The core framework and the plug-ins communicate with one another using a so-called &ldquo;object linking and embedding&rdquo; (OLE) protocol, described in the book &ldquo;Understanding ActiveX and OLE&rdquo;, David Chappell, Microsoft Press, 1996. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> In the OLE system, a software designer can implement different sections of a computer programme as so-called &ldquo;COM<highlight><superscript>1 </superscript></highlight>objects&rdquo;. Each COM object supports one or more COM &ldquo;interfaces&rdquo;, each including a number of &ldquo;methods&rdquo;. A method is a function or procedure to carry out a specific action. COM methods can be called by software using that COM object. The system is restricted so that other parts of the software using a COM object can do so only via the defined interfaces&mdash;so they cannot directly access programme code or data within the object other than via the defined COM interfaces. <footnote id="FOO-00001"><highlight><superscript>1</superscript></highlight>Component Object Model </footnote></paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> So, in the present system, the core framework communicates with the plug-ins via these COM interfaces. (In fact, the core framework comprises a number of intercommunicating objects capable of providing a COM interface, but the basic principle in the same). </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates the organisation of the operating software in much greater detail than that shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. In <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the diagram is divided into four quadrants. An upper left quadrant shows so-called viewer windows <highlight><bold>310</bold></highlight>; an upper right quadrant shows effect user interfaces (UI) <highlight><bold>320</bold></highlight>; a lower right quadrant shows effect &ldquo;servers&rdquo; <highlight><bold>330</bold></highlight> having associated parameter data (PD); and a lower left quadrant shows a core processor <highlight><bold>340</bold></highlight> including a graph, along with an object manager <highlight><bold>350</bold></highlight>, a render manager <highlight><bold>352</bold></highlight> and a change manager <highlight><bold>358</bold></highlight>. At the interface between the lower left and lower right quadrants is a meta database <highlight><bold>354</bold></highlight> which forms part of the Windows NT Registry, and a palette <highlight><bold>356</bold></highlight> containing effects icons, and default parameter values. The meta database <highlight><bold>354</bold></highlight> will be described further with reference to <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, and the palette with reference to FIGS. <highlight><bold>6</bold></highlight> to <highlight><bold>9</bold></highlight> below. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> Within the core processor <highlight><bold>340</bold></highlight> is a &ldquo;graph&rdquo;&mdash;in fact a &ldquo;directed acyclic graph&rdquo; having a linked series of individual special effects. Each effect is represented in the graph as a proxy effect (PE) having an associated cache (C) for storing the effect&apos;s output as soon as it becomes available, thereby allowing re-use of data from effects in a chain of effects if, for example, a parameter associated with an effect higher in the chain is changed. Each proxy effect is associated with a respective effects server <highlight><bold>330</bold></highlight>. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> The object manager <highlight><bold>350</bold></highlight> is responsible for controlling the lifetime and memory management of active objects in the system. The render manager <highlight><bold>352</bold></highlight> controls the starting, progress, prioritisation and stopping of render tasks. The change manager <highlight><bold>358</bold></highlight> controls undo/redo information and the notification of changes to various parts of the system. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> The basic division of <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is that the two left-hand quadrants (upper left and lower left) relate to features of the core framework, which are not specific to any particular effect. These objects are loaded into memory regardless of which particular special effects the user wishes to implement. The two right-hand quadrants (upper right and lower right) relate to the plug-ins. Each plug-in has a server <highlight><bold>330</bold></highlight>, which carries out the processing associated with the effect performed by the that plug-in, and a user interface <highlight><bold>320</bold></highlight> which provides user interface controls (in fact, for display in a viewer window <highlight><bold>310</bold></highlight>) relating to that effect. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> There is a similar top-bottom split in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, whereby the two upper quadrants (upper left and upper right) relate to user interface controls associated with the special effects, and the two lower quadrants (lower left and lower right) relate to the processing and organisation carried out to implement those effects. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Viewer windows give the user the opportunity to view the output of and control parameters for a particular effect in a chain of effects built up for execution by the apparatus. So, when a viewer window is opened by the user, the output of an effect must either be generated or, if available, retrieved from a cache store. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> In a system of this type employing multiple COM objects, it is generally considered undesirable that each object should save its working or results data in a separate data file. Indeed, such an arrangement would go against much of the reasoning which led to the establishment of the OLE system. Instead, data in this type of system is stored by all of the objects in a single file or &ldquo;compound document&rdquo;, but with an ordered structure within that compound document. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Basically, inside the, compound document, a structure analogous to a file and directory structure is provided. The equivalent of a directory is a so-called &ldquo;storage&rdquo;, and the analogy of a file is a so-called &ldquo;stream&rdquo;. Each compound document contains a root storage, below which is a familiar tree structure of storages and streams. The COM stream interface is simpler than the COM storage interface, but of course the storage interface offers more flexibility. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> In general, each COM object can be assigned either its own storage or its own stream in which to store its working data. However, in a hierarchical system such as the present video special effects processor, where the core <highlight><bold>340</bold></highlight> co-ordinates operation of a number of plug-ins, the arrangement used in previous systems is to allocate a stream to each effects plug-in. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> In contrast, in the present embodiment it is recognised that simply allocating either a storage or a stream to a plug-in places too many constraints on the design and operation of a plug-in object. Instead, in the interface definition between the core and the plug-ins, each plug-in can select between a stream, so that it can&mdash;if desired by the plug-in designer&mdash;store its working data in a straightforward manner, and a storage, so that it can&mdash;if desired&mdash;store its working data under its own &ldquo;directory&rdquo; arrangement of streams and storages. This selection is made in advance by the plug-in designer creating the plug-in program code. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> In the description which follows, communication protocols between the various objects will be described with relation to <cross-reference target="DRAWINGS">FIGS. 4 and 5</cross-reference>. The way in which the graph editor part of the core programme <highlight><bold>340</bold></highlight> is used to set up a chain of individual effects to form a composite effect will be described with relation to FIGS. <highlight><bold>6</bold></highlight> to <highlight><bold>9</bold></highlight>. The viewer windows and their interaction with the effect UIs <highlight><bold>320</bold></highlight> will then be described with reference to <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> So, <cross-reference target="DRAWINGS">FIG. 4</cross-reference> schematically illustrates the propagation of an updated effects parameter in the arrangement of <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> An example of this situation is that the user is setting up a &ldquo;lighting&rdquo; special effect, in which the effect of a light source is added to an image. The light source has user-definable source and destination position with respect to the image. If the user wishes to change one of these positions, this will invalidate any currently rendered output from that effect and also the change will need to be propagated between the various objects shown in the different quadrants of <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. This process is shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the user actually enters a changed parameter via a viewer window <highlight><bold>310</bold></highlight> (see <cross-reference target="DRAWINGS">FIG. 10</cross-reference> below). The viewer window is associated with a particular effect UI <highlight><bold>320</bold></highlight>, which in turn is part of a plug-in relating to an individual effect. (In fact, a single viewer window can be associated with more than one effect, and not all effects need have viewer windows open at any particular time, but the simplified arrangement of <cross-reference target="DRAWINGS">FIG. 3</cross-reference> will be maintained for this discussion). The plug-in issues an &ldquo;about to edit&rdquo; notification to the core. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> After the change has been made, the plug-in issues a &ldquo;change occurred&rdquo; message. This involves and/or initiates a series of actions. As a first step <highlight><bold>401</bold></highlight>, the viewer window communicates the updated parameter to the effect UI <highlight><bold>320</bold></highlight>. The effect UI <highlight><bold>320</bold></highlight> issues a &ldquo;set&rdquo; command to the corresponding effect server <highlight><bold>330</bold></highlight>, setting the revised value in a parameter store within the effect server <highlight><bold>330</bold></highlight>. This is a step <highlight><bold>402</bold></highlight> on <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> In a step <highlight><bold>403</bold></highlight>, the effect server <highlight><bold>330</bold></highlight> writes a &ldquo;undo/redo&rdquo; object into the core <highlight><bold>340</bold></highlight>, providing details of a handle or pointer which points to a record (in the effects server) of the parameter before and after the change. In response to receipt of this undo/redo object, in a step <highlight><bold>404</bold></highlight> the core broadcasts a notification to all viewer windows that a parameter has changed and that some cached data outputs may be invalidated. This notification is not specific to the viewer window in which the parameter change took place. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> At a step <highlight><bold>405</bold></highlight>, each viewer window issues a message to the corresponding effect UI <highlight><bold>320</bold></highlight> requesting an update of its processing parameters. At a step <highlight><bold>406</bold></highlight>, the effect UI <highlight><bold>320</bold></highlight> issues a &ldquo;get&rdquo; command to the corresponding effect server to get the new parameter, and the new parameter is returned to the effect UI <highlight><bold>320</bold></highlight> at a step <highlight><bold>407</bold></highlight>. The effect UI then propagates the change for display in the viewer window at a step <highlight><bold>408</bold></highlight>. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Generally, when a processing parameter is changed, this results in the need to re-render the output of one or more effects. <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates the way in which a re-render A command is propagated through the apparatus, and follows on from the processing of <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> At a step <highlight><bold>502</bold></highlight>, the viewer window issues a re-render command to the render manager. The render manager then issues a re-render command to the corresponding effects server <highlight><bold>330</bold></highlight>. When the effects server has finished re-rendering the image, it issues a &ldquo;finished&rdquo; message to the core <highlight><bold>340</bold></highlight>. The core communicates this to the viewer window at a step <highlight><bold>505</bold></highlight>, and at a step <highlight><bold>506</bold></highlight> and <highlight><bold>507</bold></highlight> the viewer window interacts with the effect UI <highlight><bold>320</bold></highlight> to display the re-rendered effect output. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> Where there are several viewer windows open, and several frames in a range of interest (which can be defined by the user as a subset&mdash;for test purposes&mdash;of the overall video clip), images are rendered as multiple concurrent tasks, according to the following priority order for allocating processing resources: </paragraph>
<paragraph id="P-0067" lvl="2"><number>&lsqb;0067&rsqb;</number> (i) an image or images currently displayed for view by a user; </paragraph>
<paragraph id="P-0068" lvl="2"><number>&lsqb;0068&rsqb;</number> (ii) first and last images of the output sequence of interest; and </paragraph>
<paragraph id="P-0069" lvl="2"><number>&lsqb;0069&rsqb;</number> (iii) remaining images of the output video sequence of interest. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> As a further level of detail, before the render manager issues a re-render command to the effects server, the render manager issues a &ldquo;prepare to render&rdquo; message specifying which image in the sequence is to be rendered. The effects server responds with a notification of its &ldquo;dependencies&rdquo;, i.e. those rendered images which are essential before the request by the render manager can be executed. These might be images rendered by another effect (e.g. the or an immediately preceding effect in the directed acyclic graph) or images rendered by that effect itself. This latter case can occur in the example of a motion tracker, where in order to render, say, image <highlight><bold>5</bold></highlight>, the motion tracker needs its own rendered output for image <highlight><bold>4</bold></highlight>. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> In response to the messages received back from the effects server, the render manager sends a &ldquo;prepare to render&rdquo; message requesting those images, and so on until the dependency tree has ended. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> At each stage, the effect proxy checks whether the required image or rendered output is cached, and informs the render manager. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> So, for example, if a prepare to render message is sent to a motion tracker specifying image <highlight><bold>5</bold></highlight>, it might respond to say it requires a rendered output (by itself) for image <highlight><bold>4</bold></highlight>. The render manager then sends a prepare to render message to the motion tracker for image <highlight><bold>4</bold></highlight>, and the motion tracker responds to indicate that it requires image <highlight><bold>3</bold></highlight> and so on. In this way a list of render jobs which are needed before the required image (image <highlight><bold>5</bold></highlight>) can be rendered is built up. Rendered outputs which are held in the cache are not included on the render manager&apos;s job list. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> The same thing happens where an effect requires the rendered output of a preceding effect, and so on down a chain of effects. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> At the end of this process, the render manager sets all of the required jobs going, in a reverse order so that the currently required image is not rendered until all of its dependent images are rendered. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> As an optimisation, the render manager can detect from the graph what the inputs to each effect are. So, the effects server can send a predetermined code (e.g. a null reply) to say simply &ldquo;all of the inputs to this effect are required&rdquo;. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> As a further extension, the same protocol can be used so that each effects server can notify the render manager if its output is the same between adjacent images. A simple example of this is a (fixed) parameter plug-in, where the output is invariant. A further example is any other effect where the outputs have already been prepared and cached, so that a straightforward detection can be made as to whether successive outputs are identical. In response to such a notification, the render manager pass the information on to an effects server which is later in the directed acyclic graph. That effects server can then (if appropriate) render only one of a range of images and repeat that output for other images where its input remains the same. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> schematically illustrates a graph editor window <highlight><bold>600</bold></highlight> and a palette window <highlight><bold>610</bold></highlight>. These are displayed on the display screen <highlight><bold>160</bold></highlight> under the control of the core <highlight><bold>340</bold></highlight>. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> The palette window <highlight><bold>600</bold></highlight> contains a number of icons <highlight><bold>620</bold></highlight>, each mapped to and representing a different possible effect for which plug-ins exist on the system. Using a mouse control, the user can &ldquo;drag&rdquo; these icons into a scrollable graph window <highlight><bold>610</bold></highlight>. The icons are arranged by the user in the graph window with respect to one another and can then be linked up with logical links <highlight><bold>630</bold></highlight>, shown in the window as graphical lines. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> The links <highlight><bold>630</bold></highlight> represent a passing of the output of an effect to the input of a subsequent effect, and (in this embodiment) always have a direction from the bottom of the graph towards the top of the graph window. So, the example shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> has an image loader icon <highlight><bold>640</bold></highlight> passing its output to a lighting effect <highlight><bold>650</bold></highlight>. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> As the user sets up graphical links in the graph window, the core <highlight><bold>340</bold></highlight> sets up logical links to determine the way in which rendered output is passed from one effect plug-in to another. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> The way in which the graphical links are created will now be described with reference to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. The logical links will then be described with reference to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, the user has selected (e.g. with a mouse click) the lighting effect and now has a moveable graphical line <highlight><bold>720</bold></highlight> directed from the icon <highlight><bold>650</bold></highlight> towards a mouse pointer <highlight><bold>730</bold></highlight>. As the mouse pointer approaches a mixing effect icon <highlight><bold>700</bold></highlight>, the mixing effect icon is magnified, or surrounded by an enlarged <highlight><bold>710</bold></highlight>, showing two input ports at the bottom of the border <highlight><bold>740</bold></highlight>. As the mouse pointer approaches one of the input ports, the graphical line <highlight><bold>720</bold></highlight> snaps onto that input point and can be fixed in place with a mouse click. This establishes a logical and graphical connection between the effect <highlight><bold>650</bold></highlight> and the effect <highlight><bold>700</bold></highlight>. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Once these logical and graphical connections are established, the user can &ldquo;box&rdquo; a linked group <highlight><bold>800</bold></highlight> of the effects icon in the graph window. Here, to &ldquo;box&rdquo; means to draw a box around the group in a standard way using a computer mouse. (One way that this is implemented is to click and hold at the top left hand comer of the box, drag the mouse to the bottom right hand comer and then release the mouse button. It is a standard way of selecting or choosing plural screen objects). </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> The user is then able to drag the linked group of effects into the palette area. This creates a new, composite, effect icon <highlight><bold>810</bold></highlight> having a set of inputs formed from the inputs to the group and a set of outputs formed from the outputs of the group. In logical terms, instead of the effect icon <highlight><bold>810</bold></highlight> being mapped to a particular plug-in, it is mapped to a linked group of plug-ins interconnected in a particular way. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> The composite effect icon <highlight><bold>810</bold></highlight> then forms part of the palette for use by the user in designing a graph. Later, if the user wishes to make use of the composite icon <highlight><bold>810</bold></highlight>, he simply drags it into place on the graph window. Preferably, the effect icon <highlight><bold>810</bold></highlight> remains as a single icon on the graph window, but in other implementations it can expand out into the original group <highlight><bold>800</bold></highlight>. As a further alternative, it can be displayed in its compressed form as a single icon, but with an &ldquo;expand&rdquo; button displayed so that the user can click on the expand button to display the original group of icons <highlight><bold>800</bold></highlight>. In any event, the composite effect provided by the icon <highlight><bold>810</bold></highlight> is a copy of the original group <highlight><bold>800</bold></highlight>. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates the data storage underlying this process. In <cross-reference target="DRAWINGS">FIG. 9</cross-reference> an icon <highlight><bold>850</bold></highlight> has been dragged from the palette icons <highlight><bold>620</bold></highlight> in the palette area <highlight><bold>600</bold></highlight> into the graph editor area <highlight><bold>610</bold></highlight>. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> Associated with the palette area <highlight><bold>600</bold></highlight>, and stored in the palette <highlight><bold>356</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, is a data structure arranged as a tree having a root <highlight><bold>860</bold></highlight> and individual data items <highlight><bold>870</bold></highlight> depending from that root. Each data item <highlight><bold>870</bold></highlight> represents one effects icon <highlight><bold>620</bold></highlight>, except in the case of a composite effect such as an effect <highlight><bold>875</bold></highlight>. Here, the effects icons (<highlight><bold>3</bold></highlight><highlight><italic>a, </italic></highlight><highlight><bold>3</bold></highlight><highlight><italic>b</italic></highlight>) forming that effect are arranged in a sub-structure depending from that data item <highlight><bold>875</bold></highlight>. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> A similar data structure exists to store effects in the graph editor area. Here, a root <highlight><bold>880</bold></highlight> is shown having just one effect <highlight><bold>885</bold></highlight> depending from it. If a number of effects are grouped together in the graph editor area and dragged to the palette, they form a further composite effect structure similar to the structure <highlight><bold>875</bold></highlight>. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> schematically illustrates a viewer window. The viewer window comprises an image display area <highlight><bold>900</bold></highlight>, various &ldquo;property pages&rdquo; <highlight><bold>910</bold></highlight>, and effects control <highlight><bold>920</bold></highlight> (here shown as a positioning cross-wire in the example of a lighting effect), and a &ldquo;button bar&rdquo; <highlight><bold>930</bold></highlight>. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> The basic layout of the viewer window is set by the core framework, and is standard from effect to effect. However, the particular items which can be adjusted using the property pages <highlight><bold>910</bold></highlight> are set by the effect UI <highlight><bold>320</bold></highlight> corresponding to a particular effect. The effect UI also provides display details for the control <highlight><bold>920</bold></highlight>. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> So, in the example shown, the cross-wire <highlight><bold>920</bold></highlight> determines the source or target position of the light in the lighting effect. The user can drag the cross-wire using a computer mouse. Dragging the cross-wire changes the parameter (x,y) values associated with that control, and so the procedure of <cross-reference target="DRAWINGS">FIG. 4</cross-reference> (update parameter values) is initiated. As the last part of that procedure, in the step <highlight><bold>408</bold></highlight>, the effect UI issues the corrected parameter value to the viewer window. At that stage, the cross-wire is re-drawn in its new position. So, although it appears to the user that the dragging action has moved the cross-wire to its ultimate position, in fact the dragging action created a parameter update which, by the route shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, resulted in the movement of the cross-wire. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> schematically illustrates an initial arrangement of the operating software. This represents the situation before any rendering has to be carried out in a particular operating session of the apparatus. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> The plug-ins are implemented under the Windows operating system as &ldquo;dynamic load libraries&rdquo; (DLLs). DLLs are generally large files which can contain program code, data and subroutine libraries. Conventionally, to conserve memory and improve system performance, a DLL loaded into memory when first needed for execution or initiation of a particular process handled by that DLL. In the present embodiment, this idea of conserving memory and improving system performance is taken one step further. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> So, when an effect icon is first taken from the palette area, conventionally the DLL corresponding to that effect would be loaded into memory to provide the core <highlight><bold>340</bold></highlight> with sufficient information (e.g. interconnectivity with other effects icons) for the graph to be built. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> In the present embodiment, the DLL for that effect is not loaded at that stage. Instead, so called &ldquo;metadata&rdquo; <highlight><bold>1000</bold></highlight> representing that effect is loaded. The metadata provides the core with information defining the interconnectivity of the effect with other effects (e.g. number of inputs and outputs). This enables the core to build up a graph without the need to load any DLLs, so saving memory by not loading large files until they are absolutely needed. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> If a viewer window is opened relating to an effect, or if the composite effect is executed by any other means, then the DLLs are loaded and the metadata discarded or ignored. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> FIGS. <highlight><bold>12</bold></highlight> to <highlight><bold>14</bold></highlight> schematically illustrate features of the effects plug-ins which (amongst other things) facilitate automation of the system. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> schematically illustrates a previously proposed effects plug-in. This effect takes image information (shown as a &ldquo;clip&rdquo; <highlight><bold>1300</bold></highlight>) and acts on the basis of three processing parameters P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight> and P<highlight><bold>3</bold></highlight> (such as lighting positions etc.). In the plug-in of <cross-reference target="DRAWINGS">FIG. 12</cross-reference>, the parameter values are set within the plug-in, i.e. by bespoke program code written as part of the plug-in. This makes overall control of the parameters&mdash;e.g. for an animation system where the parameters vary with time, or in an arrangement where a parameter such as a lighting position is varied by another effect such as a motion tracker&mdash;very difficult, requiring additional code within the effects plug-in and often multiple versions of the effects plug-in. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> schematically illustrates another approach according to an embodiment of the invention. Here, each parameter is defined by a separate plug-in <highlight><bold>1320</bold></highlight>, linked to the &ldquo;main&rdquo; effects plug-in <highlight><bold>1330</bold></highlight> in the same way as the links between effects are defined in the graph editor described above. In fact, the description given above was a simplification of the whole process, the simplification being made at that stage to assist in the explanation. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> The parameter plug-ins are normally hidden from the user, for example by displaying them at screen positions in the graph editor and palette which are &ldquo;off the page&rdquo;. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> So, if an effect is to be operated in a self-contained, non-animated manner (i.e. is without importing parameter values from other effects), then parameters are set for each parameter plug-in <highlight><bold>1320</bold></highlight> using the main effect&apos;s viewer window. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> If a parameter is to be defined by another effect&apos;s output, e.g. a position value being provided by a motion tracking effect, then all that is required if for the logical link between the main effect plug-in <highlight><bold>1330</bold></highlight> and the appropriate parameter plug-in <highlight><bold>1320</bold></highlight> to be severed and a link to the motion tracking effect initiated. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> In order to understand how this system can assist in animation, reference is made to <cross-reference target="DRAWINGS">FIG. 14</cross-reference>. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> shows the left-right split between core and plug-in shown first in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. On the left hand side of <cross-reference target="DRAWINGS">FIG. 14, a</cross-reference> proxy effect (PE) <highlight><bold>1340</bold></highlight> is provided for the &ldquo;main&rdquo; effect server <highlight><bold>1350</bold></highlight>. Proxy effects <highlight><bold>1360</bold></highlight> are also provided for each of the parameter plug-ins <highlight><bold>1320</bold></highlight>. These proxy effects <highlight><bold>1360</bold></highlight> are of a much simpler nature than the proxy effect <highlight><bold>1340</bold></highlight>, and communication between the proxy effects <highlight><bold>1360</bold></highlight> and the parameter plug-ins <highlight><bold>1320</bold></highlight> uses a simplified subset of the communication protocol between the proxy effect <highlight><bold>1340</bold></highlight> and the effects server <highlight><bold>1350</bold></highlight>. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> In actual fact, the proxy effects <highlight><bold>1360</bold></highlight> can be a single data value (in a non-animated system) or a list of values in an animated system. In an animated system, the list of values can be expressed as &ldquo;key frame&rdquo; values, i.e. data values set for particular images in a sequence, with intervening values being interpolated by the core according to a linear or user-defined non-linear interpolation. So, animation can be set up in a particularly simple and convenient way without having to write bespoke animation software within each plug-in. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> Relating this description to that given earlier about dependencies between effects, when a &ldquo;prepare to render&rdquo; message from the render manager is received by an effects server <highlight><bold>1350</bold></highlight>, it can respond to say that it requires all of its inputs before that output can be provided. Included in the effect&apos;s inputs are of course the parameter plug-ins, so the next stage would be for the render manager to send a prepare to render message to each parameter plug-in. If the parameter plug-in contains a single value, or if the current image is a key frame, then the parameter plug-in is ready to provide the appropriate parameter at render time. If, however, the parameter plug-in contains animation data and the current image is not a key-frame, the parameter must first be interpolated before it can be used in the effect. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> schematically illustrates a system cache <highlight><bold>1100</bold></highlight>. This is a schematic view of the whole cache area&mdash;in fact, as described earlier, the cache can also be viewed as plural individual caches associated with respective proxy effects, but since memory resources are dynamically allocated between such individual caches the representation of <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is also a valid one. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> The cache is provided in the system memory <highlight><bold>150</bold></highlight> and is able to store images <highlight><bold>1110</bold></highlight> and non-image rendered outputs <highlight><bold>1130</bold></highlight> from effects (e.g. a motion vector in the case of a motion tracking effect). </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> The idea of the cache is to store the rendered output (whether or not this is an image) of each effect in the directed acyclic graph. In this way, if an effect is altered at a particular position in the directed acyclic graph, effects below that position do not need to be re-rendered to provide the new output. Instead, the cached outputs can be re-used. A further benefit is to assist in and speed up undo/redo operations, by storing the output of particular effects (those with open viewer windows) before and after a parameter change is made. The corresponding parameter change is also stored, so that the parameter change can be undone or redone simply by loading the appropriate material from the cache memory <highlight><bold>1100</bold></highlight>. This is under the control of the undo/redo objects written by the effects servers when a change is made. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> Images take up very much more memory space than a simple data value like a motion vector&mdash;perhaps a million times as much memory space. So, in this embodiment, when the cache memory approaches its capacity and another image is to be stored, , the least recently accessed image in the cache is deleted to make room for the newly stored image. However, other data in the cache&mdash;parameter values, non-image rendered outputs and so on&mdash;is not deleted during an operating session of the apparatus because it consumes such a tiny amount of memory space in comparison with an image. This information is then available for re-use, or for an undo/redo operation, as long as the information remains valid throughout an operating session. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> In practice, it can be left that the plug-in specifies whether a data item is flushable or not, with image data items being set by convention as flushable, and non-image items being set as non-flushable. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> schematically illustrates an asynchronous-synchronous converted <highlight><bold>1200</bold></highlight> between the core <highlight><bold>340</bold></highlight> and an effect server. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> The converter <highlight><bold>1200</bold></highlight> receives asynchronous re-rendering commands from the render manager in the form of a &ldquo;To do&rdquo; queue, i.e. a list of rendering jobs to be done. When a job is finished, a &ldquo;finished&rdquo; message is returned from the converter <highlight><bold>1200</bold></highlight> to the render manager. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> The converter <highlight><bold>1200</bold></highlight> receives the asynchronous job requests and issues synchronous requests to the appropriate software plug-in. This means that the interface <highlight><bold>1200</bold></highlight> passes a control &ldquo;thread&rdquo; (a Windows term) to the software plug-in, which retains control of the thread until the job is complete. Only then, the software plug-in returns the thread to the interface, which responds by issuing the &ldquo;finished&rdquo; message to the core. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> At initialisation, the core interrogates each plug-in (or rather the metadata associated with that plug-in) to determine whether the plug-in can handle synchronous or asynchronous communication. If a hardware plug-in (e.g. a peripheral card for rendering in a particular way) or an asynchronous software plug-in, possibly running on a different machine, is installed in place of a software plug-in, that plug-in interacts with the core (in fact the render manager which initiates rendering tasks asynchronously) via the asynchronous interface, as hardware accelerators are much better suited to operation in this way. So, in this case, the converter <highlight><bold>1200</bold></highlight> is bypassed. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> The converter may be implemented as part of the core or part of each relevant plug-in. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> Accordingly, by the counter-intuitive step of providing a converter <highlight><bold>1200</bold></highlight> between two pieces of software, an efficient hardware interface is provided for a later upgrade to dedicated hardware. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> Although illustrative embodiments of the invention have been described in detail herein with reference to the accompanying drawings, it is to be understood that the invention is not limited to those precise embodiments, and that various changes and modifications can be effected therein by one skilled in the art without departing from the scope and spirit of the invention as defined by the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">I claim </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. Video processing apparatus in which successive video processing operations are applied to images of a video signal to generate corresponding processing results in the form of images or data, said apparatus comprising: 
<claim-text>a cache store for storing, as cached items and processing results associated with said video processing operations; and </claim-text>
<claim-text>means for deleting currently cached items to provide cache space for items to be newly cached, said deleting means operating so that non-image processing results are retained in said cache for longer than processing results in said form of images. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. Apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, in which said deleting means is operable not to delete non-image processing results from said cache. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. Apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, in which said deleting means is operable not to delete processing parameters from said cache. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A method of video processing in which successive video processing operations are applied to images of a video signal to generate corresponding processing results in said form of images or data, said method comprising said steps of: 
<claim-text>storing, as cached items and processing results associated with said video processing operations; and </claim-text>
<claim-text>deleting currently cached items to provide cache space for items to be newly cached, so that non-image processing results are retained in said cache for longer than processing results in said form of images.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001827A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001827A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001827A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001827A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001827A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001827A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001827A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001827A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001827A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001827A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001827A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
