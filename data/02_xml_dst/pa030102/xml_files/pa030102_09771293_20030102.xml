<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004710A1-20030102-D00000.TIF SYSTEM "US20030004710A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004710A1-20030102-D00001.TIF SYSTEM "US20030004710A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004710A1-20030102-D00002.TIF SYSTEM "US20030004710A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004710A1-20030102-D00003.TIF SYSTEM "US20030004710A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004710A1-20030102-D00004.TIF SYSTEM "US20030004710A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004710A1-20030102-D00005.TIF SYSTEM "US20030004710A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004710A1-20030102-D00006.TIF SYSTEM "US20030004710A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004710A1-20030102-D00007.TIF SYSTEM "US20030004710A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004710A1-20030102-D00008.TIF SYSTEM "US20030004710A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004710A1-20030102-D00009.TIF SYSTEM "US20030004710A1-20030102-D00009.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004710</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09771293</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010125</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G10L019/04</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>704</class>
<subclass>219000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Short-term enhancement in celp speech coding</title-of-invention>
</technical-information>
<continuity-data>
<non-provisional-of-provisional>
<document-id>
<doc-number>60232929</doc-number>
<document-date>20000915</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Yang</given-name>
<family-name>Gao</family-name>
</name>
<residence>
<residence-us>
<city>Mission Viejo</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<assignee>
<organization-name>Conexant Systems, Inc.</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>FARSHAD FARJAMI Esq</name-1>
<name-2>FARJAMI &amp; FARJAMI LLP</name-2>
<address>
<address-1>16148 Sand Canyon</address-1>
<city>Irvine</city>
<state>CA</state>
<postalcode>92618</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A speech-coding device includes a fixed codebook, an adaptive codebook, a short-term enhancement circuit, and a summing circuit. The short-term enhancement circuit connects an output of the fixed codebook to a summing circuit. The summing circuit adds an adaptive codebook contribution to a fixed codebook contribution. The short-term enhancement circuit can also be connected to a synthesis filter to emphasize the spectral formants in an encoder and a decoder. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">1. CROSS REFERENCE TO RELATED APPLICATIONS </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application claims the benefit of provisional application serial No. 60/232,939 filed on Sep. 15, 2000. The following co-pending and commonly assigned U.S. patent applications have been filed on the same day as the provisional application. All of these applications relate to and further describe other aspects of the embodiments disclosed in this application and are incorporated by reference in their entirety. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;SELECTABLE MODE VOCODER SYSTEM,&rdquo; Attorney Reference Number: 98RSS365CIP (10508/4), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;INJECTING HIGH FREQUENCY NOISE INTO PULSE EXCITATION FOR LOW BIT RATE CELP,&rdquo; Attorney Reference Number: 00CXT0065D (10508/5), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;SYSTEM OF DYNAMIC PULSE POSITION TRACKS FOR PULSE-LIKE EXCITATION IN SPEECH CODING,&rdquo; Attorney Reference Number: 00CXT0573N (10508/7), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;SPEECH CODING SYSTEM WITH TIME-DOMAIN NOISE ATTENUATION,&rdquo; Attorney Reference Number: 00CXT0554N (10508/8), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;SYSTEM FOR AN ADAPTIVE EXCITATION PATTERN FOR SPEECH CODING,&rdquo; Attorney Reference Number: 98RSS366 (10508/9), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;SYSTEM FOR ENCODING SPEECH INFORMATION USING AN ADAPTIVE CODEBOOK WITH DIFFERENT RESOLUTION LEVELS,&rdquo; Attorney Reference Number: 00CXT0670N (10508/13), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;CODEBOOK TABLES FOR ENCODING AND DECODING,&rdquo; Attorney Reference Number: 00CXT0669N (10508/14), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;BIT STREAM PROTOCOL OF TRANSMISSION OF ENCODED VOICE SIGNALS,&rdquo; Attorney Reference Number: 00CXT0668N (10508/15), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;SYSTEM FOR FILTERING SPECTRAL CONTENT OF A SIGNAL FOR SPEECH ENCODING,&rdquo; Attorney Reference Number: 00CXT0667N (10508/16), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;SYSTEM OF ENCODING AND DECODING SPEECH SIGNALS,&rdquo; Attorney Reference Number: 00CXT0665N (10508/17), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;SYSTEM FOR SPEECH ENCODING HAVING AN ADAPTIVE FRAME ARRANGEMENT,&rdquo; Attorney Reference Number: 98RSS384CIP (10508/18), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> U.S. patent application Ser. No. ______, &ldquo;SYSTEM FOR IMPROVED USE OF SUBCODEBOOKS,&rdquo; Attorney Reference Number: 00CXT0569N (10508/19), filed on Sep. 15, 2000, and is now U.S. Pat. No. ______.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> 2. Technical Field </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> This invention relates to speech coding, and more particularly, to a system that enhances the perceptual quality of digital processed speech. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> 3. Related Art </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> Speech synthesis is a complex process that often requires the transformation of voiced and unvoiced sounds into digital signals. To model sounds, sounds are sampled and encoded into a discrete sequence. The number of bits used to represent the sound can determine the perceptual quality of synthesized sound or speech. A poor quality replica can drown out voices with noise, lose clarity, or fail to capture the inflections, tone, pitch, or co-articulations that can create adjacent sounds. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> In one technique of speech synthesis known as Code Excited Linear Predictive Coding (CELP), a sound track is sampled into a discrete waveform before being digitally processed. The discrete waveform is then analyzed according to certain select criteria. Criteria such as the degree of noise content and the degree of voice content can be used to model speech through linear functions in real and in delayed time. These linear functions can capture information and predict future waveforms. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> The CELP coder structure can produce high quality reconstructed speech. However, coder quality can drop quickly when the coder&apos;s bit rate is reduced. To maintain a high coder quality at a low bit rate, such as 4 Kbps, additional approaches must be explored. This invention is directed to providing an efficient coding system of voiced speech that accurately encodes and decodes the perceptually important features of voiced speech. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY </heading>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> This invention is a system that enhances the perceptual quality of reconstructed speech. The system adds short-term enhancements to the spectral envelope of coded voice segments. The system includes a fixed codebook, an adaptive codebook, an enhancement circuit, and a summing circuit. The enhancement circuit interconnects an output of the fixed codebook to a summing circuit. The summing circuit adds an adaptive codebook contribution to a fixed codebook contribution. In another aspect, the enhancement circuit may be connected directly to a synthesis filter. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Other systems, methods, features, and advantages of the invention will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems, methods, features and advantages be included within this description, be within the scope of the invention, and be protected by the accompanying claims.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE FIGURES </heading>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The components in the figures are not necessarily to scale, emphasis instead being placed upon illustrating the principles of the invention. Moreover, in the figures, like reference numerals designate corresponding parts throughout the different views. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a partial block diagram of a speech communication system incorporated in a variant of a Code Excited Linear Prediction System (CELPS) known as the eXtended Code Excited Linear Prediction System (eX-CELPS). </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates a fixed codebook of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates a spectral envelope and a fine spectral structure of a speech segment. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flow diagram of an enhancement of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates a discrete implementation of the enhancement of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a block diagram of an alternative embodiment of the invention. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> illustrates an exemplary z-plane. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a block diagram of an alternative speech coding system implemented in an encoder. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a block diagram of an alternative speech coding system implemented in a decoder.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The dashed lines drawn in <cross-reference target="DRAWINGS">FIGS. 1, 6</cross-reference>, <highlight><bold>8</bold></highlight>, and <highlight><bold>9</bold></highlight> represent direct and indirect connections. For example, the fixed codebook <highlight><bold>102</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> may be directly or indirectly connected to other circuit components including circuits, devices, etc. The fixed codebook <highlight><bold>102</bold></highlight> can also include one or more subcodebooks as illustrated in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Similarly, the dashed lines of <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrate that other functions can occur before or after each illustrated step. </paragraph>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Long-term enhancements to codebook excitations can improve the perceptual quality of reconstructed speech. Perceptual coders may add selective enhancements to the fine spectral structure that represents the long-term correlation of coded voiced segments. These enhancements, however, are not used to enhance the spectral envelope that represents the short-term correlation of coded voice segments. The addition of a short-term enhancement brings back some quality loses that can be caused by bandwidth expansion used in a Linear Prediction Coding (LPC) parameter quantization. A bandwidth expansion moves synthesis filter poles away from the unit circle. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a partial block diagram of a speech coding or speech communication system <highlight><bold>100</bold></highlight> incorporated in a variant of a Code Excited Linear Prediction System (CELPS) known as the eXtended Code Excited Linear Prediction System (eX-CELPS). Conceptually, eX-CELPS achieves toll quality at a low bit rate by emphasizing the perceptually important features of a sampled input signal (i.e., a voiced speech signal) while de-emphasizing the auditory features that are not perceived by a listener. Using a process of linear predictions, this embodiment can represent any speech sample. The short-term prediction of speech s at an instant n can be approximated by Equation 1: </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>s</italic></highlight>(<highlight><italic>n</italic></highlight>)&ap;<highlight><italic>a</italic></highlight><highlight><subscript>1</subscript></highlight><highlight><italic>s</italic></highlight>(<highlight><italic>n&minus;</italic></highlight>1)&plus;<highlight><italic>a</italic></highlight><highlight><subscript>2</subscript></highlight><highlight><italic>s</italic></highlight>(<highlight><italic>n&minus;</italic></highlight>2)&plus; . . . &plus;<highlight><italic>a</italic></highlight><highlight><subscript>p</subscript></highlight><highlight><italic>s</italic></highlight>(<highlight><italic>n&minus;p</italic></highlight>)&emsp;&emsp;(Equation 1) </in-line-formula></paragraph>
<paragraph id="P-0035" lvl="7"><number>&lsqb;0035&rsqb;</number> where a<highlight><subscript>1</subscript></highlight>, a<highlight><subscript>2</subscript></highlight>, . . . a<highlight><subscript>p </subscript></highlight>are Linear Prediction Coding coefficients (LPC coefficients) and p is the Linear Prediction Coding order. The difference between the speech sample and the predicted speech sample is called the prediction residual r(n) that has a similar level of periodicity as the speech signal s(n). The LPC residual r(n) can be expressed as: </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>r</italic></highlight>(<highlight><italic>n</italic></highlight>)&equals;<highlight><italic>s</italic></highlight>(<highlight><italic>n</italic></highlight>)&minus;<highlight><italic>a</italic></highlight><highlight><subscript>1</subscript></highlight><highlight><italic>s</italic></highlight>(<highlight><italic>n&minus;</italic></highlight>1)&minus;<highlight><italic>a</italic></highlight><highlight><subscript>2</subscript></highlight><highlight><italic>s</italic></highlight>(<highlight><italic>n&minus;</italic></highlight>2)&minus; . . . &minus;<highlight><italic>a</italic></highlight><highlight><subscript>p</subscript></highlight><highlight><italic>s</italic></highlight>(<highlight><italic>n&minus;p</italic></highlight>)&emsp;&emsp;(Equation 2) </in-line-formula></paragraph>
<paragraph id="P-0036" lvl="7"><number>&lsqb;0036&rsqb;</number> and can be re-written as: </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>s</italic></highlight>(<highlight><italic>n</italic></highlight>)&equals;<highlight><italic>r</italic></highlight>(<highlight><italic>n</italic></highlight>)&plus;<highlight><italic>a</italic></highlight><highlight><subscript>1</subscript></highlight><highlight><italic>s</italic></highlight>(<highlight><italic>n&minus;</italic></highlight>1)&plus;<highlight><italic>a</italic></highlight><highlight><subscript>2</subscript></highlight><highlight><italic>s</italic></highlight>(<highlight><italic>n&minus;</italic></highlight>2)&plus; . . . &plus;<highlight><italic>a</italic></highlight><highlight><subscript>p</subscript></highlight><highlight><italic>s</italic></highlight>(<highlight><italic>n&minus;p</italic></highlight>)&emsp;&emsp;(Equation 3) </in-line-formula></paragraph>
<paragraph id="P-0037" lvl="7"><number>&lsqb;0037&rsqb;</number> A closer examination of Equation 3 reveals that a current speech sample can be broken down into a predictive portion a<highlight><subscript>1</subscript></highlight>s(n&minus;1)&plus;a<highlight><subscript>2</subscript></highlight>s(n&minus;2)&plus; . . . &plus;a<highlight><subscript>p</subscript></highlight>s(n&minus;p) and the LPC residual r(n). The Long Term Prediction residual (LTP residual) r<highlight><subscript>2</subscript></highlight>(n) is defined through the LPC residual r(n) and an adaptive codebook pitch prediction signal g<highlight><subscript>p</subscript></highlight>e(n&minus;Lag) <highlight><bold>128</bold></highlight>. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>r</italic></highlight><highlight><subscript>2</subscript></highlight>(<highlight><italic>n</italic></highlight>)&equals;<highlight><italic>r</italic></highlight>(<highlight><italic>n</italic></highlight>)&minus;<highlight><italic>g</italic></highlight><highlight><subscript>p</subscript></highlight><highlight><italic>e</italic></highlight>(<highlight><italic>n&minus;Lag</italic></highlight>)&emsp;&emsp;(Equation 4) </in-line-formula></paragraph>
<paragraph id="P-0038" lvl="7"><number>&lsqb;0038&rsqb;</number> It is the filtering of the excitation signal e(n) <highlight><bold>106</bold></highlight> by a synthesizer or a synthesis filter <highlight><bold>108</bold></highlight> that produces the reconstructed speech signal s&prime;(n) <highlight><bold>110</bold></highlight>. The Lag is a measure of the pitch delay that is preferably the true pitch period. Thus, the excitation signal e at an instant n <highlight><bold>106</bold></highlight> can be expressed as: </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>e</italic></highlight>(<highlight><italic>n</italic></highlight>)&equals;<highlight><italic>g</italic></highlight><highlight><subscript>c</subscript></highlight><highlight><italic>v</italic></highlight>(<highlight><italic>n</italic></highlight>)&plus;<highlight><italic>g</italic></highlight><highlight><subscript>p</subscript></highlight><highlight><italic>e</italic></highlight>(<highlight><italic>n&minus;Lag</italic></highlight>)&emsp;&emsp;(Equation 5) </in-line-formula></paragraph>
<paragraph id="P-0039" lvl="7"><number>&lsqb;0039&rsqb;</number> where v(n) <highlight><bold>120</bold></highlight> is the quantized output of the fixed codebook <highlight><bold>102</bold></highlight> and the adaptive codebook pitch prediction e(n&minus;Lag) <highlight><bold>114</bold></highlight> is the output of the adaptive codebook <highlight><bold>112</bold></highlight>. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> Thus, to accurately reproduce voiced and unvoiced speech segments, the excitation signal e(n) <highlight><bold>106</bold></highlight> is created through a linear combination of the outputs from an adaptive codebook <highlight><bold>112</bold></highlight> and a fixed codebook <highlight><bold>102</bold></highlight>. It must be emphasized that codebooks <highlight><bold>102</bold></highlight> and <highlight><bold>112</bold></highlight> should be interpreted in a very broad sense to include single and multiple sub codebooks. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The adaptive codebook <highlight><bold>112</bold></highlight> generates signals that represent the periodicity of the speech signal s(n). In this embodiment, the content of the adaptive codebook <highlight><bold>112</bold></highlight> is formed from previously reconstructed excitations signals e(n) <highlight><bold>106</bold></highlight>. These signals repeat the content of a selectable range of previously sampled signals that lie within adjacent subframes. The content is stored in memory. Due to the high-degree of correlation that exists between the current and previous adjacent subframes, the adaptive codebook <highlight><bold>112</bold></highlight> tracks signals through selected adjacent subframes and then uses these previously sampled signals to generate the entire or a portion of the current excitation signal e(n) <highlight><bold>106</bold></highlight>. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The second codebook used to generate the entire or a portion of the excitation signal e(n) <highlight><bold>106</bold></highlight> is the fixed codebook <highlight><bold>102</bold></highlight>. The fixed codebook <highlight><bold>102</bold></highlight> primarily contributes the non-predictable or non-periodic portion of the excitation signal e(n) <highlight><bold>106</bold></highlight>. This contribution improves the approximation of the speech signal s(n) when the adaptive codebook <highlight><bold>112</bold></highlight> cannot effectively model non-periodic signals. When noise-like structures or non-periodic signals exist in a sound track because of rapid frequency variations in voiced speech or because transitory noise-like signals mask voiced speech, for example, the fixed codebook <highlight><bold>102</bold></highlight> produces an approximation of these non-periodic signals that cannot be captured by the adaptive codebook <highlight><bold>112</bold></highlight>. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The overall objective of the selection of codebook entries in this embodiment is to create the best excitations that approximate the perceptually important features of a speech segment. To improve performance, a modular codebook structure is used in this embodiment that structures the codebooks into multiple sub codebooks. Preferably, the fixed codebook <highlight><bold>102</bold></highlight> is comprised of at least three sub codebooks <highlight><bold>202</bold></highlight>-<highlight><bold>206</bold></highlight> as illustrated in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Two of the fixed sub codebooks are pulse codebooks <highlight><bold>202</bold></highlight> and <highlight><bold>204</bold></highlight> such as a 2-pulse sub codebook and a 3-pulse sub codebook. The third codebook <highlight><bold>206</bold></highlight> is a Gaussian codebook or a higher-pulse sub codebook. Preferably, the level of coding further refines the codebooks, particularly defining the number of entries for a given sub codebook. Further details of the codebooks are described in the co-pending patent application entitled: &ldquo;System of Encoding and Decoding Speech Signals&rdquo; by Yang Gao, Adil Beyassine, Jes Thyssen, Eyal Shlomot, and Huan-yu Su that is incorporated by reference. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> Following a search of the fixed sub codebooks that yields the best output signals, some enhancements h<highlight><subscript>1</subscript></highlight>, h<highlight><subscript>2</subscript></highlight>, h<highlight><subscript>3</subscript></highlight>, . . . h<highlight><subscript>n </subscript></highlight>are filtered or convoluted with the outputs of the codebooks to enhance the perceptual quality of the modeled signal. These enhancements preferably track select aspects of the speech segment and are calculated from subframe to subframe. An enhancement h<highlight><subscript>2 </subscript></highlight>is introduced by filtering or convolving the output of the fixed codebook. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 3, a</cross-reference> sound track can be characterized by its properties in the power spectrum <highlight><bold>300</bold></highlight>. In the power spectral domain, the power spectral envelope or pure LPC spectrum <highlight><bold>302</bold></highlight> corresponds to the &ldquo;short-term&rdquo; time domain correlations and the underlying fine structure <highlight><bold>304</bold></highlight> corresponds to the &ldquo;long-term&rdquo; time domain correlations. Samples of both the spectral envelope <highlight><bold>302</bold></highlight> and fine structure <highlight><bold>304</bold></highlight>, in part, define the LPC coefficients a<highlight><subscript>1</subscript></highlight>, a<highlight><subscript>2</subscript></highlight>, . . . a<highlight><subscript>p</subscript></highlight>. Preferably, an autocorrelation method estimates the LPC coefficients although other methods that minimize prediction error for data sequences may also be used. When an autocorrelation method is used, the synthesis filter <highlight><bold>108</bold></highlight> is stable. In practical terms this means that the poles of the synthesis filter represented by the LPC coefficients lie within the unit circle <highlight><bold>702</bold></highlight> of the z-plane <highlight><bold>700</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Before transmitting LPC coefficients, the LPC coefficients are subject to a quantization. Quantization can create an unstable synthesis filter <highlight><bold>108</bold></highlight> because small changes in the LPC coefficients can lead to a large change in the power spectrum <highlight><bold>300</bold></highlight>. Accordingly, a bandwidth expansion may be used before the LPC quantization to make the formant structure less sharp by moving the poles of the bandwidth filter away from the circumference or toward the origin of the unit circle <highlight><bold>702</bold></highlight> in the z-plane <highlight><bold>700</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIGS. 1 and 6</cross-reference>, a short-term enhancement h<highlight><subscript>2 </subscript></highlight>may be connected to an output of a fixed codebook <highlight><bold>102</bold></highlight> or to an output of a summing circuit <highlight><bold>118</bold></highlight>. Preferably, the short-term enhancement h<highlight><subscript>2 </subscript></highlight>occurs after the LPC quantization so that the short-term enhancement h<highlight><subscript>2 </subscript></highlight>recovers some of the quality losses that can be caused by the bandwidth expansion. In practice, the short-term enhancement h<highlight><subscript>2 </subscript></highlight>makes the combined spectral envelope sharper without affecting the stability of the synthesis filter <highlight><bold>108</bold></highlight> by moving the poles of the h<highlight><subscript>2 </subscript></highlight>enhancement toward the circumference or away from the origin of the unit circle <highlight><bold>702</bold></highlight> in the z-plane <highlight><bold>702</bold></highlight>. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the vector v(n) <highlight><bold>120</bold></highlight> is selected by a fixed codebook index <highlight><bold>130</bold></highlight>. The vector v(n) <highlight><bold>120</bold></highlight> is filtered or convolved by enhancement h<highlight><subscript>2 </subscript></highlight>and then scaled by a scalar or a scaling circuit g<highlight><subscript>c </subscript></highlight><highlight><bold>122</bold></highlight>. Preferably, the enhancement h<highlight><subscript>2 </subscript></highlight>is a spectral filter that emphasizes the formant structure <highlight><bold>306</bold></highlight> of the spectral envelope <highlight><bold>302</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. In this embodiment, the spectral filter is defined by the transfer function H<highlight><subscript>2</subscript></highlight>(z)&equals;1/A(z/&agr;) where &agr; is preferably a small value. &agr;, for example, can be less than 0.1. The output of the spectral filter H<highlight><subscript>2</subscript></highlight>(z)V(z) <highlight><bold>126</bold></highlight> is then combined with the scaled pitch prediction g<highlight><subscript>p</subscript></highlight>e(n&minus;Lag) <highlight><bold>128</bold></highlight> at a summing point by a summing circuit <highlight><bold>118</bold></highlight> to create the excitation signal e(n) <highlight><bold>106</bold></highlight>. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>e</italic></highlight>(<highlight><italic>n</italic></highlight>)&equals;<highlight><italic>g</italic></highlight><highlight><subscript>c</subscript></highlight><highlight><italic>&middot;h</italic></highlight><highlight><subscript>2</subscript></highlight>(<highlight><italic>n</italic></highlight>)*<highlight><italic>v</italic></highlight>(<highlight><italic>n</italic></highlight>)&plus;<highlight><italic>g</italic></highlight><highlight><subscript>p</subscript></highlight><highlight><italic>e</italic></highlight>(<highlight><italic>n&minus;Lag</italic></highlight>)&emsp;&emsp;(Equation 6) </in-line-formula></paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> To reconstruct the peaks <highlight><bold>306</bold></highlight> of the LPC spectrum <highlight><bold>302</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the filter coefficients are preferably calculated through an expansion device. Preferably, the expansion device replaces the LPC coefficients a<highlight><subscript>1</subscript></highlight>, a<highlight><subscript>2</subscript></highlight>, . . . a<highlight><subscript>p </subscript></highlight>with scaled coefficients &ggr;<highlight><superscript>1</superscript></highlight>a<highlight><subscript>1</subscript></highlight>, &ggr;<highlight><superscript>2</superscript></highlight>a<highlight><subscript>2</subscript></highlight>, . . . &ggr;<highlight><superscript>p</superscript></highlight>a<highlight><subscript>p</subscript></highlight>. The replacement of a<highlight><subscript>p </subscript></highlight>with &ggr;<highlight><superscript>p</superscript></highlight>a<highlight><subscript>p </subscript></highlight>is equivalent to scaling up the radii of all poles of the synthesis filter <highlight><bold>108</bold></highlight> by a factor of &ggr;. This results in the creation of sharp pitch harmonic peaks that approximate the pitch harmonic peaks <highlight><bold>306</bold></highlight> of the pure LPC spectrum <highlight><bold>302</bold></highlight>. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flow diagram of the h<highlight><subscript>2 </subscript></highlight>enhancement that can filter the excitation output of any codebook to enhance the perceptual quality of a reconstructed speech signal s&prime;(n). At step <highlight><bold>402</bold></highlight>, the fixed codebook index <highlight><bold>130</bold></highlight> is calculated and an output of the fixed codebook <highlight><bold>102</bold></highlight> is generated. The calculated index <highlight><bold>130</bold></highlight> of the fixed codebook <highlight><bold>102</bold></highlight> preferably results in the smallest difference between the original speech signal s(n) and the reconstructed s&prime;(n) speech signal <highlight><bold>110</bold></highlight>. At step <highlight><bold>404</bold></highlight>, the vector v(n) <highlight><bold>120</bold></highlight> is filtered by the h<highlight><subscript>2 </subscript></highlight>enhancement which emphasizes the sharp peaks <highlight><bold>306</bold></highlight> of the LPC spectrum <highlight><bold>302</bold></highlight>. At step <highlight><bold>406</bold></highlight>, an adaptive scaling factor g<highlight><subscript>c </subscript></highlight>is used to amplify or attenuate the fixed codebook contribution vector v(n) <highlight><bold>120</bold></highlight> to the excitation signal e(n) <highlight><bold>106</bold></highlight>. At step <highlight><bold>408</bold></highlight>, the excitation signal e(n) <highlight><bold>106</bold></highlight> is constructed from the adaptive <highlight><bold>112</bold></highlight> and the fixed codebook <highlight><bold>102</bold></highlight> contributions. The adaptive contribution, which is the scaled pitch prediction g<highlight><subscript>p</subscript></highlight>e(n&minus;Lag) <highlight><bold>128</bold></highlight>, is added to the fixed codebook contribution which is the enhanced scaled vector H<highlight><subscript>2</subscript></highlight>(z)V(z) <highlight><bold>126</bold></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> Of course, the enhancement h<highlight><subscript>2 </subscript></highlight>also can be implemented in the discrete-domain through a convolver having at least two ports or means <highlight><bold>502</bold></highlight> comprising a digital controller (i.e., a digital signal processor), one or more enhancement circuits, one or more digital filters, or other discrete circuitry. These implementations illustrated in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> can be described as follows: </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>V</italic></highlight>&prime;(<highlight><italic>z</italic></highlight>)&equals;<highlight><italic>H</italic></highlight><highlight><subscript>2</subscript></highlight>(<highlight><italic>z</italic></highlight>)<highlight><italic>V</italic></highlight>(<highlight><italic>z</italic></highlight>)&emsp;&emsp;(Equation 7) </in-line-formula></paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> From the foregoing description it should be apparent that the enhancement h<highlight><subscript>2 </subscript></highlight>to the spectral envelope <highlight><bold>302</bold></highlight> also can be added after the fixed codebook contribution is added to the adaptive codebook contribution. As <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates, the power spectrum envelope <highlight><bold>302</bold></highlight> can be enhanced by h<highlight><subscript>2 </subscript></highlight>after the coefficients that characterize the excitation signal e(n) <highlight><bold>106</bold></highlight> are summed. It should also be apparent that the invention is not limited to a particular coding technology. Any perceptual coding technology can be used including a Code Excited Linear Prediction System (CELP) and an Algebraic Code Excited Linear Prediction System (ACELP). </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The invention seamlessly provides an efficient coding system that improves the encoding and the decoding of perceptually important features of speech signals. The short-term enhancement need not be limited to a post processing application. Preferably, the short-term enhancement is integrated within or is a unitary part of an encoder related to a closed-loop search and a decoder as illustrated in <cross-reference target="DRAWINGS">FIGS. 8 and 9</cross-reference>. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, the fixed codebook contribution v(n) <highlight><bold>120</bold></highlight> in an encoder <highlight><bold>802</bold></highlight> can be obtained in a closed loop. Optimization of a closed-loop prediction is accomplished by minimizing the power of a closed loop residual signal &eacute;(n) <highlight><bold>804</bold></highlight> defined by s&prime;(n)&minus;s(n). Preferably, the closed loop residual signal &eacute;(n) <highlight><bold>804</bold></highlight> is filtered by a weighting function such as a tunable perceptual weighting filter W(z) <highlight><bold>806</bold></highlight> or a pole-zero filter. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> To illustrate the operation of a closed-loop embodiment of the encoder <highlight><bold>802</bold></highlight>, <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows the reconstructed speech signal s&prime;(n) <highlight><bold>110</bold></highlight> subtracted from the speech signal s(n) by a subtracting circuit <highlight><bold>808</bold></highlight>. The difference, which is preferably the closed loop residual signal &eacute;(n) <highlight><bold>804</bold></highlight>, is filtered by the weighting filter W(z) <highlight><bold>806</bold></highlight>. The filtered closed loop residual signal &eacute;(n) <highlight><bold>804</bold></highlight> is conditioned by a minimizing circuit <highlight><bold>810</bold></highlight>, which derives the fixed codebook index <highlight><bold>130</bold></highlight>. Preferably, the minimizing circuit <highlight><bold>810</bold></highlight> comprises software and/or hardware that minimize the closed loop residual signal &eacute;(n) <highlight><bold>804</bold></highlight> through a closed loop search of the fixed codebook index <highlight><bold>130</bold></highlight>. In alternative embodiments, the closed-loop selection of the fixed codebook index <highlight><bold>130</bold></highlight> is repeated until a desired reconstructed speech signal s&prime;(n) <highlight><bold>110</bold></highlight> resolution is attained. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> In the decoder <highlight><bold>902</bold></highlight> illustrated in <cross-reference target="DRAWINGS">FIG. 9, a</cross-reference> post enhancement function may be implemented to filter and condition the reconstructed speech signal s&prime;(n) <highlight><bold>110</bold></highlight>. In this embodiment, a post processing <highlight><bold>904</bold></highlight> conditions the reconstructed speech signal s&prime;(n) <highlight><bold>110</bold></highlight> by sharpening the formants&apos; <highlight><bold>306</bold></highlight> bandwidths. Preferably, the post processing <highlight><bold>904</bold></highlight> minimizes the noise that may lie within the spectral valleys between the formants <highlight><bold>306</bold></highlight> by emphasizing the formants&apos; bandwidths. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> While various embodiments of the invention have been described, it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible that are within the scope of this invention. Accordingly, the invention is not to be restricted except in light of the attached claims and their equivalents. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A speech communication system comprising: 
<claim-text>a first codebook that characterizes a speech segment; </claim-text>
<claim-text>a second codebook that characterizes the speech segment; </claim-text>
<claim-text>a convolver electrically connected to an output of the second codebook; and </claim-text>
<claim-text>a synthesizer electrically connected to an output of the convolver and an output of the first codebook, the convolver being configured to emphasize a formant structure of a spectral envelope of the speech segment. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A speech coding system comprising: 
<claim-text>an excitation that characterizes a speech segment; </claim-text>
<claim-text>a convolver having an input configured to receive the excitation; and </claim-text>
<claim-text>a synthesizer coupled to an output of the convolver, the convolver being configured to emphasize a formant structure of a spectral envelope of the speech segment in a closed-loop of an encoder. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the excitation is derived from an output of a first codebook and a second codebook. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein the first codebook comprises an adaptive codebook. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference> wherein the second codebook comprises a fixed codebook. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> further comprising a minimizing circuit coupled to the fixed codebook. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> further comprising a weighting filter coupled to the minimizing circuit. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> further comprising a subtracting circuit coupled to the synthesizer and the weighting filter. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein the convolver generates a convoluted result of an enhancement signal and at least an output signal of the second codebook. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the convolver is electrically coupled to an output of a summing circuit. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the system comprises a Code Excited Linear Prediction System. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the system comprises an eXtended Code Excited Linear Prediction System. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the convolver comprises a short-term enhancement circuit configured to enhance at least one of the formants of the spectral envelope. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the convolver comprises a short-term enhancement circuit configured to enhance the formant structure of the spectral envelope. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the convolver comprises a spectral filter configured to modify an input signal by a transfer function of the form 1/A(z/&agr;). </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference> wherein &agr; is less than about 0.1. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the convolver is configured to emphasize the formant structure of the spectral envelope of the speech segment in a decoder. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A speech coding system comprising: 
<claim-text>a fixed codebook that characterizes a speech segment; </claim-text>
<claim-text>an adaptive codebook that characterizes the speech segment; </claim-text>
<claim-text>means configured to emphasize a formant structure of an envelope of the speech segment connected to an output of the fixed codebook; and </claim-text>
<claim-text>a synthesizer connected to an output of the means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> wherein the means emphasizes the formant structure by convolving two time domain signals. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> wherein the means comprises a filter. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> wherein the means comprises a convolver. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> wherein the means is connected to an output of a summing circuit. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A speech coding system comprising: 
<claim-text>a synthesis filter; and </claim-text>
<claim-text>a short-term enhancement filter directly connected to an input of said synthesis filter, the short-term enhancement being configured to emphasize a formant structure of a spectral envelope of a speech segment in an encoder and a decoder. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A method that improves speech coding comprising: 
<claim-text>generating a fixed codebook index to select an excitation; </claim-text>
<claim-text>scaling the excitation by an adaptive factor; and </claim-text>
<claim-text>filtering the scaled excitation by an enhancement that emphasizes the formants of a Linear Prediction Coding spectrum in a closed loop of an encoder. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference> further comprising summing the filtered and scaled excitation with an output of an adaptive codebook. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> further comprising filtering the summed signal by a synthesis filter. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> further convolving the summed signal and filtering the convoluted signal by a synthesis filter. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein the act of filtering comprises a device having a transfer function of the form 1/A(z/&agr;). </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> wherein &agr; is less than about 0.1. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference> wherein the filtering of the scaled excitation by the enhancement that emphasizes the formants of the Linear Prediction Coding spectrum occurs in a decoder. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference> wherein the fixed codebook index is derived by subtracting a reconstructed speech signal from a speech signal; filtering the difference between the reconstructed speech signal and the speech signal through a weighting function; and minimizing the filtered difference.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>9</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004710A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004710A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004710A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004710A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004710A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004710A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004710A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004710A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004710A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004710A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
