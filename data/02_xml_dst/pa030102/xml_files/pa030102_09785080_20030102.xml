<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004990A1-20030102-D00000.TIF SYSTEM "US20030004990A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00001.TIF SYSTEM "US20030004990A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00002.TIF SYSTEM "US20030004990A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00003.TIF SYSTEM "US20030004990A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00004.TIF SYSTEM "US20030004990A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00005.TIF SYSTEM "US20030004990A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00006.TIF SYSTEM "US20030004990A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00007.TIF SYSTEM "US20030004990A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00008.TIF SYSTEM "US20030004990A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00009.TIF SYSTEM "US20030004990A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00010.TIF SYSTEM "US20030004990A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00011.TIF SYSTEM "US20030004990A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00012.TIF SYSTEM "US20030004990A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030004990A1-20030102-D00013.TIF SYSTEM "US20030004990A1-20030102-D00013.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004990</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09785080</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010215</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F015/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>707</class>
<subclass>511000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>System and method for reducing the size of data difference representations</title-of-invention>
</technical-information>
<continuity-data>
<non-provisional-of-provisional>
<document-id>
<doc-number>60198259</doc-number>
<document-date>20000302</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Stephen</given-name>
<middle-name>P.W.</middle-name>
<family-name>Draper</family-name>
</name>
<residence>
<residence-non-us>
<city>England</city>
<country-code>GB</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>ERIC B. MEYERTONS</name-1>
<name-2>CONLEY, ROSE &amp; TAYON, P.C.</name-2>
<address>
<address-1>P.O. BOX 398</address-1>
<city>AUSTIN</city>
<state>TX</state>
<postalcode>78767-0398</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">An improved system and method for reducing the size of data difference representations. The input data stream may be split into one or more output data streams such that the output data streams may be recombined and used to regenerate the original input data stream. Each of the output data streams may be independently differenced against the equivalent data stream from the previous version of the data. Non-localized changes in the input data stream may be converted into localized changes in a subset of the output data streams. The subset of output data streams no longer containing non-localized changes produce efficient (i.e., small) difference representations. The difference representations of each of these streams may be packaged into a single stream for transmission over a computer network. The receiving computer may reconstruct the multiplicity of difference representations, and recreate the multiplicity of translated data streams representing the updated data. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention generally relates to systems and methods for representing the differences between collections of data stored on computer media. More particularly, the present invention relates to systems and methods for transmitting updates to such data using a representation of the differences between the updated version and a previous version or versions. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> The need to distribute large quantities of electronic information, typically via computer networks, arises in many applications involving geographically distributed computer users. In many such cases the information distributed must be maintained in an up-to-date state at the destination(s). An important goal in the distribution of these updates is to reduce the amount of data which must be sent in order to make the update. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In many cases reduction in the data size of the updates is achieved by means of some form of &lsquo;differencing&rsquo;. In such methods the sending computer system calculates the differences between the version of the data which the receiving computer system already has and the updated version it is desired to distribute. A representation of these differences is then transmitted to the receiving computer system which uses it together with the previous version which it already has to construct the updated version of the data. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Many existing methods for producing a difference representation are known. Examples are the UNIX &lsquo;diff&rsquo; utility, and iOra Limited&apos;s Epsilon Technology (U.S. patent application Ser. No. 09/476,723 filed on Dec. 30, 1999). However, the known methods have a tendency to produce large representations of the differences between one version and an updated version with many common forms of non-textual data. Specifically, data types in which differences tend not to be localized within the data generally produce large difference representations. Important cases of such data types include the following categories: </paragraph>
<paragraph id="P-0007" lvl="2"><number>&lsqb;0007&rsqb;</number> 1) Executable files. Typically small changes made to computer source code (e.g., in small problem fixes) result in non-localized changes to the executable file(s) produced by building the source code. A major cause of this effect is that the insertion or modification of small regions of code or data variables will often cause unchanged data and sub-routines to be moved to different addresses throughout the executable. All references to such moved data or sub-routines then change throughout the executable file image. The effect of this can be considerable. </paragraph>
<paragraph id="P-0008" lvl="2"><number>&lsqb;0008&rsqb;</number> 2) Compressed files. Many data types are typically represented in compressed form so that they take up less space on hard drives and require less time for transmission over computer networks. Small changes to the uncompressed content of such files may then cause large and non-localized changes to the compressed form. Important examples of these data types are the ZIP and CAB compression formats (often used in software distribution) and multimedia files such as images (e.g., GIFs and JPEGs, which are formats frequently used on web pages), sound files, or movies (e.g., MPEGs). </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Accordingly, what is needed is a way to allow the efficient (in the sense that small difference representations are produced) differencing of data types in which non-localized changes are a feature. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The above limitations of previously known differencing methods are overcome by a system and method made in accordance with the principles of the present invention. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The method of the present invention includes the step of adding pre-processor elements which are applied to the data stream to be differenced prior to the use of one of the known differencing methods. These pre-processor elements may perform arbitrary translations upon the input data stream and split it into one or more separate output data streams subject to the constraint that said translated and split data streams can subsequently be recombined and (by addition of reverse translation) used to regenerate the original input data stream. This recombination and reverse translation is accomplished by post-processor elements matched to the pre-processor elements used (as depicted in <cross-reference target="DRAWINGS">FIGS. 7 and 10</cross-reference>). In this manner the original input data stream comprising the updated version of the data to be differenced is split into a multiplicity of data streams. Each of this multiplicity of data streams may then be independently differenced (using any of the known differencing methods) against the equivalent data stream from the previous version of the data. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> By judicious choice of translation and parsing based on the data type of the data being differenced the non-localized changes in the input data stream may be converted into localized changes in a subset of the output data streams. The net result of this is that the subset of output data streams no longer containing non-localized changes produce efficient (i.e., small) difference representations using the known differencing methods. In one embodiment, the difference representations of each of these streams are then packaged into a single stream or file for transmission over a computer network. The receiving computer then employs an unpackaging process to reconstruct the multiplicity of difference representations which (using the known method) are used to recreate the multiplicity of translated data streams representing the updated data (as depicted in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>). Using the post-processor elements described previously the receiving computer is then able to reconstruct the original updated data (as in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>). </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The choice of appropriate pre (and therefore matching post) processor elements is dependent on the type of data being differenced. Specific examples of pre and post processing elements for use with executable files and with compressed files are described. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> These and other benefits and advantages of the present invention shall become apparent from the detailed description of the invention presented below in conjunction with the figures accompanying the description. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> A better understanding of the present invention may be obtained when the following detailed description of the preferred embodiment is considered in conjunction with the following drawings, in which: </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a network diagram of a wide area network which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is an illustration of a typical computer system which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3A</cross-reference> is a block diagram illustrating a generic present information differencing engine which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3B</cross-reference> is a block diagram illustrating a generic present information reconstructor which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> is a block diagram illustrating a generic stored information differencing engine which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> is a block diagram illustrating a generic stored information reconstructor which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4C</cross-reference> is a block diagram illustrating a generic summarizer which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a block diagram illustrating an individual pre-processing step used to enhance the efficiency of existing differencing methods which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a block diagram illustrating multiple pre-processing steps which may be combined to form a single composite pre-processing step of the same general form which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a block diagram illustrating a combined pre-processing step used in conjunction with known differencing methods to produce an enhanced differencer which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a block diagram illustrating an individual post-processing step used to enhance the efficiency of existing differencing methods which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a block diagram illustrating multiple post-processing steps which may be combined to form a single composite post-processing step of the same general form which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a block diagram illustrating a combined post-processing step used in conjunction with the reconstruction steps of known differencing methods to produce an enhanced reconstructor which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a block diagram illustrating packaging and unpackaging processes used to facilitate transmission or storage of the difference representations which is suitable for implementing various embodiments; </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a block diagram illustrating a pre-processor specifically intended to handle executable format data according to one embodiment; and </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a flowchart illustrating a post-processor specifically intended to handle executable format data according to one embodiment.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> While the invention is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims. </paragraph>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF SEVERAL EMBODIMENTS </heading>
<paragraph id="P-0033" lvl="7"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference>: Wide Area Network </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates a wide area network (WAN) according to one embodiment. A WAN <highlight><bold>102</bold></highlight> is a network that spans a relatively large geographical area. The Internet is an example of a WAN <highlight><bold>102</bold></highlight>. A WAN <highlight><bold>102</bold></highlight> typically includes a plurality of computer systems which are interconnected through one or more networks. Although one particular configuration is shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the WAN <highlight><bold>102</bold></highlight> may include a variety of heterogeneous computer systems and networks which are interconnected in a variety of ways and which run a variety of software applications. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> One or more local area networks (LANs) <highlight><bold>104</bold></highlight> may be coupled to the WAN <highlight><bold>102</bold></highlight>. A LAN <highlight><bold>104</bold></highlight> is a network that spans a relatively small area. Typically, a LAN <highlight><bold>104</bold></highlight> is confined to a single building or group of buildings. Each node (i.e., individual computer system or device) on a LAN <highlight><bold>104</bold></highlight> preferably has its own CPU with which it executes programs, and each node is also able to access data and devices anywhere on the LAN <highlight><bold>104</bold></highlight>. The LAN <highlight><bold>104</bold></highlight> thus allows many users to share devices (e.g., printers) as well as data stored on file servers. The LAN <highlight><bold>104</bold></highlight> may be characterized by any of a variety of types of topology (i.e., the geometric arrangement of devices on the network), of protocols (i.e., the rules and encoding specifications for sending data, and whether the network uses a peer-to-peer or client/server architecture), and of media (e.g., twisted-pair wire, coaxial cables, fiber optic cables, radio waves). </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Each LAN <highlight><bold>104</bold></highlight> includes a plurality of interconnected computer systems and optionally one or more other devices: for example, one or more workstations <highlight><bold>110</bold></highlight><highlight><italic>a, </italic></highlight>one or more personal computers <highlight><bold>112</bold></highlight><highlight><italic>a, </italic></highlight>one or more laptop or notebook computer systems <highlight><bold>114</bold></highlight>, one or more server computer systems <highlight><bold>116</bold></highlight>, and one or more network printers <highlight><bold>118</bold></highlight>. As illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, an example LAN <highlight><bold>104</bold></highlight> may include one of each of computer systems <highlight><bold>110</bold></highlight><highlight><italic>a, </italic></highlight><highlight><bold>112</bold></highlight><highlight><italic>a, </italic></highlight><highlight><bold>114</bold></highlight>, and <highlight><bold>116</bold></highlight>, and one printer <highlight><bold>118</bold></highlight>. The LAN <highlight><bold>104</bold></highlight> may be coupled to other computer systems and/or other devices and/or other LANs <highlight><bold>104</bold></highlight> through the WAN <highlight><bold>102</bold></highlight>. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> One or more mainframe computer systems <highlight><bold>120</bold></highlight> may be coupled to the WAN <highlight><bold>102</bold></highlight>. As shown, the mainframe <highlight><bold>120</bold></highlight> may be coupled to a storage device or file server <highlight><bold>124</bold></highlight> and mainframe terminals <highlight><bold>122</bold></highlight><highlight><italic>a, </italic></highlight><highlight><bold>122</bold></highlight><highlight><italic>b, </italic></highlight>and <highlight><bold>122</bold></highlight><highlight><italic>c. </italic></highlight>The mainframe terminals <highlight><bold>122</bold></highlight><highlight><italic>a, </italic></highlight><highlight><bold>122</bold></highlight><highlight><italic>b, </italic></highlight>and <highlight><bold>122</bold></highlight><highlight><italic>c </italic></highlight>may access data stored in the storage device or file server <highlight><bold>124</bold></highlight> coupled to or included in the mainframe computer system <highlight><bold>120</bold></highlight>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The WAN <highlight><bold>102</bold></highlight> may also include computer systems which are connected to the WAN <highlight><bold>102</bold></highlight> individually and not through a LAN <highlight><bold>104</bold></highlight>: as illustrated, for purposes of example, a workstation <highlight><bold>110</bold></highlight><highlight><italic>b </italic></highlight>and a personal computer <highlight><bold>112</bold></highlight> <highlight><italic>b. </italic></highlight>For example, the WAN <highlight><bold>102</bold></highlight> may include computer systems which are geographically remote and connected to each other through the Internet. </paragraph>
<paragraph id="P-0039" lvl="7"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference>: Typical Computer System </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates a typical computer system <highlight><bold>150</bold></highlight> which is suitable for implementing various embodiments of a system and method for reducing the size of data difference representations. Each computer system <highlight><bold>150</bold></highlight> typically includes components such as a CPU <highlight><bold>152</bold></highlight> with an associated memory medium such as floppy disks <highlight><bold>160</bold></highlight>. The memory medium may store program instructions for computer programs, wherein the program instructions are executable by the CPU <highlight><bold>152</bold></highlight>. The computer system <highlight><bold>150</bold></highlight> may further include a display device such as a monitor <highlight><bold>154</bold></highlight>, an alphanumeric input device such as a keyboard <highlight><bold>156</bold></highlight>, and a directional input device such as a mouse <highlight><bold>158</bold></highlight>. The computer system <highlight><bold>150</bold></highlight> may be operable to execute the computer programs to implement reduction of the size of data difference representations as described herein. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The computer system <highlight><bold>150</bold></highlight> preferably includes a memory medium on which computer programs according to various embodiments may be stored. The term &ldquo;memory medium&rdquo; is intended to include an installation medium, e.g., a CD-ROM, or floppy disks <highlight><bold>160</bold></highlight>, a computer system memory such as DRAM, SRAM, EDO RAM, Rambus RAM, etc., or a non-volatile memory such as a magnetic media, e.g., a hard drive, or optical storage. The memory medium may include other types of memory as well, or combinations thereof. In addition, the memory medium may be located in a first computer in which the programs are executed, or may be located in a second different computer which connects to the first computer over a network. In the latter instance, the second computer provides the program instructions to the first computer for execution. Also, the computer system <highlight><bold>150</bold></highlight> may take various forms, including a personal computer system, mainframe computer system, workstation, network appliance, Internet appliance, personal digital assistant (PDA), television system or other device. In general, the term &ldquo;computer system&rdquo; may be broadly defined to encompass any device having a processor which executes instructions from a memory medium. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The memory medium preferably stores a software program or programs for reducing the size of data difference representations as described herein. The software program(s) may be implemented in any of various ways, including procedure-based techniques, component-based techniques, and/or object-oriented techniques, among others. For example, the software program may be implemented using ActiveX controls, C&plus;&plus;objects, JavaBeans, Microsoft Foundation Classes (MFC), browser-based applications (e.g., Java applets), traditional programs, or other technologies or methodologies, as desired. A CPU, such as the host CPU <highlight><bold>152</bold></highlight>, executing code and data from the memory medium includes a means for creating and executing the software program or programs according to the methods and/or block diagrams described below. </paragraph>
<paragraph id="P-0043" lvl="7"><number>&lsqb;0043&rsqb;</number> FIGS. <highlight><bold>3</bold></highlight>A through <highlight><bold>4</bold></highlight>C: Known Differencing Methods </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> In order to provide suitable terminology, known differencing methods are described in FIGS. <highlight><bold>3</bold></highlight>A-<highlight><bold>3</bold></highlight>B and FIGS. <highlight><bold>4</bold></highlight>A-<highlight><bold>4</bold></highlight>C. In general, known differencing methods fall into two broad categories: &ldquo;present information differencing&rdquo; and &ldquo;stored information differencing&rdquo;. In present information differencing an updated version of the data (U) and a previous version of the data (P) are both present and accessible to the differencing process. In stored information differencing an updated version of the data (U) is available, together with stored summary information derived from a previous version of the data at some earlier time (P&prime;). </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> The UNIX utility &ldquo;diff&rdquo; is an example of a present information differencer. The Epsilon method (U.S. patent application Ser. No. 09/476,723 filed on Dec. 30, 1999) is an example of a stored information differencer. Typically, present information differencers are somewhat simpler but require both current versions and previous versions of the data to be held (precluding in-place updating and requiring up to twice the storage space as compared to stored information differencers). Stored information differencers, however, require a current version of the data and summary information derived from the previous version of the data to be kept. This summary information is typically much smaller than the previous version of the data itself. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> As used herein a &ldquo;generic differencer&rdquo; refers to either a present information differencer or a stored information differencer, as appropriate. It is to be understood that what is meant by &ldquo;previous version of the data&rdquo; (i.e., P or P&prime;) is implied by the choice of known differencing method. That is, if the known differencing method used is the present information differencing method, then &ldquo;previous version of the data&rdquo; refers to the previous version of the data (P). Conversely, if the known differencing method used is the stored information differencing method, then &ldquo;previous version of the data&rdquo; refers to summary information derived from the previous version of the data (P&prime;). </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Similarly, as used herein a &ldquo;generic reconstructor&rdquo; refers to either a present information reconstructor or a stored information reconstructor, as appropriate. It is to be understood that what is meant by &ldquo;previous version of the data&rdquo; (i.e., P or P&prime;) is implied by the choice of known reconstructing method. That is, if the known reconstructing method used is the present information reconstructing method, then &ldquo;previous version of the data&rdquo; refers to the previous version of the data (P). Conversely, if the known reconstructing method used is the stored information reconstructing method, then &ldquo;previous version of the data&rdquo; refers to summary information derived from the previous version of the data (P&prime;). </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> Note that a special case of a differencer is one that differences against NULL (i.e., the differences between an input data stream and nothing at all). Such a differencer may be referred to as a &ldquo;NULL differencer&rdquo;. When a NULL differencer produces a difference representation smaller than the original input stream then it acts as a compressor. NULL differencers are considered to be included in the generic differencers enhanced by an embodiment of the present invention. Consequently the present invention may also be seen as a means for improving the efficiency of known compression methods. </paragraph>
<paragraph id="P-0049" lvl="7"><number>&lsqb;0049&rsqb;</number> FIGS. <highlight><bold>3</bold></highlight>A and <highlight><bold>3</bold></highlight>B: Generic Present Information Differencing Engine and Reconstructor </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 3A and 3B</cross-reference> are block diagrams of embodiments of a generic present information differencing engine, and a generic present information reconstructor, respectively. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 3A, a</cross-reference> present information differencing engine <highlight><bold>302</bold></highlight> compares an updated version of the data (U) and a previous version of the data (P) to construct a representation of the differences (R) between the previous version of the data (P) and the updated version of the data (U). In <cross-reference target="DRAWINGS">FIG. 3B, a</cross-reference> present information reconstructor <highlight><bold>304</bold></highlight> may then reconstruct the updated version of the data (U) from the difference representation (R) and the previous version of the data (P). The present information differencing engine <highlight><bold>302</bold></highlight> and the present information reconstructor <highlight><bold>304</bold></highlight> are not illustrated as being connected as they typically are employed at different times, or deployed on different computer systems. The difference representation (R) is typically stored on computer storage media and/or transmitted over a computer network. </paragraph>
<paragraph id="P-0052" lvl="7"><number>&lsqb;0052&rsqb;</number> FIGS. <highlight><bold>4</bold></highlight>A through <highlight><bold>4</bold></highlight>C: Generic Stored Information Differencing Engine, Reconstructor, and Summarizer </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 4A through 4C</cross-reference> are block diagrams of embodiments of a generic stored information differencing engine, a generic stored information reconstructor, and a generic summarizer, respectively. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 4A, a</cross-reference> stored information differencing engine <highlight><bold>402</bold></highlight> may use the summary information derived from the previous version of the data (P&prime;) in conjunction with an updated version of the data (U) to construct a difference representation (R). In <cross-reference target="DRAWINGS">FIG. 4B, a</cross-reference> stored information reconstructor <highlight><bold>404</bold></highlight> may then reconstruct the updated version of the data (U) from the difference representation (R) and the previous version of the data (P). In <cross-reference target="DRAWINGS">FIG. 4C, a</cross-reference> summarizer <highlight><bold>406</bold></highlight> may use a previous version of the data (P) to construct summary information derived from the previous version of the data (P&prime;). </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> In most cases, the summarization performed in <cross-reference target="DRAWINGS">FIG. 4C</cross-reference> will take place when the previous version of the data (P) is distributed. That is, typically, an updated version of the data (U) is used to construct summary information derived from the updated version of the data (U&prime;), in the same way that the derivation of (P&prime;) is shown in <cross-reference target="DRAWINGS">FIG. 4C</cross-reference> as derived from (P). Upon subsequent updates, the old (P&prime;) is discarded, the old (U&prime;) becomes the new (P&prime;), and a new (U&prime;) is derived from the new (U). </paragraph>
<paragraph id="P-0056" lvl="7"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference>: Individual Pre-processing Step </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a block diagram of an embodiment of an individual pre-processing step used to enhance the efficiency of existing differencing methods. This individual pre-processing step may include the process of converting data into a form in which changes are statistically more likely to be localized than is the case in the original form. As used herein, &ldquo;form&rdquo; refers to a structure or a format of data. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> The original form of the updated version of the data (U) may be examined by a segmentor module <highlight><bold>502</bold></highlight>. The updated version of the data (U) may also be referred to as an incoming data stream (U). The segmentor module <highlight><bold>502</bold></highlight> may then break the incoming data stream (U) into a sequence of substream segments (S) by communicating demarcation points (i.e., segmentation boundaries) to a pre-processor type determination module <highlight><bold>504</bold></highlight>. Typically these segmentation boundaries will be chosen to represent logical demarcation points in the semantics of the incoming data stream (U). For example, if (U) represents the data from the files in a filesystem directory then a logical choice of demarcation point would be file boundaries. Each segment (S) may then be examined by the pre-processor type determination module <highlight><bold>504</bold></highlight>. The pre-processor type determination module <highlight><bold>504</bold></highlight> may then use known methods to determine the type of data involved (e.g., a system in which the data is a Microsoft Windows file might determine type by examining the extension of the associated filename; alternatively, examination of a sample of the data may determine the type). Typically the actual instantiations of the segmentor module <highlight><bold>502</bold></highlight> and the preprocessor type determination module <highlight><bold>504</bold></highlight> for any particular embodiment will be mutually dependent and the segmentor module <highlight><bold>502</bold></highlight> will also communicate logical information about the segments (S) it identifies to the pre-processor type determination module <highlight><bold>504</bold></highlight> (e.g., names of the individual files represented by each segment). The pre-processor type determination module <highlight><bold>504</bold></highlight> may then assign a pre-processor module <highlight><bold>510</bold></highlight> to perform processing by instructing the pre-processor multiplexor <highlight><bold>508</bold></highlight> to route each segment (S) to a selected pre-processor module <highlight><bold>510</bold></highlight>. In one embodiment, this selection of pre-processor module <highlight><bold>510</bold></highlight> may be based upon a simple table relating segment types to pre-processor modules in a deterministic fashion, the table may be constructed dynamically by a registration process in which additional pre-processor modules may be registered against segment types when the system is initialized. However, other selection mechanisms not featuring dynamic registration may also be used. The pre-processor type determination module <highlight><bold>504</bold></highlight> may also inform the segment type recorder <highlight><bold>506</bold></highlight> of the selections it has made. The segment type recorder <highlight><bold>506</bold></highlight> may then construct data stream (P<highlight><subscript>0</subscript></highlight>) encoding the selection in a manner which allows the selection to be later determined by examination of data stream (P<highlight><subscript>0</subscript></highlight>). </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Based on the selection provided by the pre-processor type determination module <highlight><bold>504</bold></highlight>, the pre-processor multiplexor <highlight><bold>508</bold></highlight> may route each segment of the incoming data (S) to a selected pre-processor module (i.e., one pre-processor module out of the many preprocessor modules diagrammed as <highlight><bold>510</bold></highlight>). This data flow is labeled as S* (the * notation as used throughout these diagrams indicates that the data is an unchanged copy of the same flow without the *). Thus S* is simply a copy of S. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> The selected pre-processor module <highlight><bold>510</bold></highlight> may then perform arbitrary reversible transformations and splittings on the data to construct one or more transformed data streams P<highlight><subscript>1 </subscript></highlight>. . . P<highlight><subscript>n </subscript></highlight>(n&gt;&equals;1). A constraint on this process may be that there exists a deterministic reverse process capable of taking P<highlight><subscript>1 </subscript></highlight>. . . P<highlight><subscript>n </subscript></highlight>and reconstructing (U) (see <cross-reference target="DRAWINGS">FIG. 8</cross-reference>). In any given instantiation of this diagram, n may be a fixed integer, greater than or equal to 1 for all pre-processor modules that may be selected. This may ensure that, regardless of the selected module, n output streams may result, thus providing a fixed data interface for subsequent processing. Of course any individual pre-processor module may choose to utilize only a subset of these output streams (simply not producing any output on the other output streams). </paragraph>
<paragraph id="P-0061" lvl="7"><number>&lsqb;0061&rsqb;</number> Pre-processor Example &num;<highlight><bold>1</bold></highlight>: Database Record Parsing: </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Suppose that the original form of the input data (U) is a database table representing goods and prices, and that the database table is represented in the data stream in row-major order. That is, the database table consists of a sequence of the form: </paragraph>
<paragraph id="P-0063" lvl="2"><number>&lsqb;0063&rsqb;</number> GOODS DETAILS &num;<highlight><bold>1</bold></highlight>, PRICE &num;<highlight><bold>1</bold></highlight>, RECORD SEPARATOR </paragraph>
<paragraph id="P-0064" lvl="2"><number>&lsqb;0064&rsqb;</number> GOODS DETAILS &num;<highlight><bold>2</bold></highlight>, PRICE &num;<highlight><bold>2</bold></highlight>, RECORD SEPARATOR </paragraph>
<paragraph id="P-0065" lvl="2"><number>&lsqb;0065&rsqb;</number> . . . </paragraph>
<paragraph id="P-0066" lvl="2"><number>&lsqb;0066&rsqb;</number> GOODS DETAILS &num;n, PRICE &num;n, RECORD SEPARATOR </paragraph>
<paragraph id="P-0067" lvl="7"><number>&lsqb;0067&rsqb;</number> An appropriate choice of parser for this data type may be one which parses the data into two streams representing the two fields of the records. Thus P<highlight><subscript>1 </subscript></highlight>would be the sequence: </paragraph>
<paragraph id="P-0068" lvl="2"><number>&lsqb;0068&rsqb;</number> GOODS DETAILS &num;<highlight><bold>1</bold></highlight>, RECORD SEPARATOR </paragraph>
<paragraph id="P-0069" lvl="2"><number>&lsqb;0069&rsqb;</number> GOODS DETAILS &num;<highlight><bold>2</bold></highlight>, RECORD SEPARATOR </paragraph>
<paragraph id="P-0070" lvl="2"><number>&lsqb;0070&rsqb;</number> . . . </paragraph>
<paragraph id="P-0071" lvl="2"><number>&lsqb;0071&rsqb;</number> GOODS DETAILS &num;n, RECORD SEPARATOR </paragraph>
<paragraph id="P-0072" lvl="7"><number>&lsqb;0072&rsqb;</number> and P<highlight><subscript>2 </subscript></highlight>the sequence: </paragraph>
<paragraph id="P-0073" lvl="2"><number>&lsqb;0073&rsqb;</number> PRICE &num;<highlight><bold>1</bold></highlight>, RECORD SEPARATOR </paragraph>
<paragraph id="P-0074" lvl="2"><number>&lsqb;0074&rsqb;</number> PRICE &num;<highlight><bold>2</bold></highlight>, RECORD SEPARATOR </paragraph>
<paragraph id="P-0075" lvl="2"><number>&lsqb;0075&rsqb;</number> . . . </paragraph>
<paragraph id="P-0076" lvl="2"><number>&lsqb;0076&rsqb;</number> PRICE &num;n, RECORD SEPARATOR </paragraph>
<paragraph id="P-0077" lvl="7"><number>&lsqb;0077&rsqb;</number> As a common update to this database may be price changes, (i.e., price is statistically likely to be more volatile than description for this example) it follows that such changes are localized to the data in stream P<highlight><subscript>2</subscript></highlight>, with P<highlight><subscript>1 </subscript></highlight>being unchanged. With known differencing methods being applied to each of P<highlight><subscript>1 </subscript></highlight>and P<highlight><subscript>2 </subscript></highlight>separately, the size of the sum of the resulting difference representations may be significantly less than the size of the difference representation obtained by applying the same known differencing method to the original form of the input data (U). </paragraph>
<paragraph id="P-0078" lvl="7"><number>&lsqb;0078&rsqb;</number> Pre-processor Example &num;<highlight><bold>2</bold></highlight>: Decompression of Compressed Data: </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> Suppose the input data flow (U) is the content of a compressed file using the well known ZIP data compression format frequently encountered on personal computer systems. An appropriate choice of pre-processor for ZIP format data is a ZIP decompressor which takes the compressed file and transforms it into the uncompressed data it represents. To see why this achieves the goal of transforming non-localized changes into localized changes consider the case of a ZIP file containing a collection of text files. Suppose now that the updated version of the ZIP file contains the same text files, one of which has been modified. Because of the effects of compression this modification causes rippling changes to the entire compressed ZIP file, resulting in most of the compressed data changing relative to the original version. However, when an appropriate pre-processor is applied, the changes within the data may be localized to the single changed file, and furthermore only to a region of the single changed file. Such a data stream (with its localized changes) may then provide greatly enhanced differencing performance. One embodiment of a pre-processing method for use with executable content is described in <cross-reference target="DRAWINGS">FIG. 12</cross-reference>. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> In one embodiment, an identity-pre-processor (i.e., a pre-processor which simply constructs one output stream identical to its input: P<highlight><subscript>1 </subscript></highlight>being the only output and being a copy of S*) may be included in the set of selectable pre-processor modules <highlight><bold>510</bold></highlight>. The identity-pre-processor would typically be used when no specific pre-processor mapping is registered for the determined data type. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> Multiple pre-processor modules <highlight><bold>510</bold></highlight> may be combined to construct a single logical composite pre-processor module. Modules may also be referred to as steps or stages. Typically a single logical composite pre-processor module is useful where multiple encoding techniques are involved with the data to be differenced. Such cases occur frequently and a simple example would be a compressed executable file. Such a file would benefit from the use of pre-processor steps both to decompress the file and to identify logically unchanged patterns in the instruction stream. This process is abstractly illustrated in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. </paragraph>
<paragraph id="P-0082" lvl="7"><number>&lsqb;0082&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference>: Composite Pre-processing Step </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a block diagram of an embodiment of a composite pre-processing step. The composite pre-processing step in this example is made up of three stages: a pre-processor stage <highlight><bold>1</bold></highlight> (<highlight><bold>601</bold></highlight>), a pre-processor stage <highlight><bold>2</bold></highlight> (<highlight><bold>602</bold></highlight>), and a pre-processor rename streams stage (<highlight><bold>603</bold></highlight>). </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> The original form of the updated version of the data (U) may be processed by the pre-processor stage <highlight><bold>1</bold></highlight> (<highlight><bold>601</bold></highlight>), resulting in transformed data streams P<highlight><subscript>0 </subscript></highlight>. . . P<highlight><subscript>n</subscript></highlight>. The pre-processor stage <highlight><bold>2</bold></highlight> (<highlight><bold>602</bold></highlight>) is shown as acting upon transformed data stream P<highlight><subscript>1 </subscript></highlight>only. It is noted that the pre-processor stage <highlight><bold>2</bold></highlight> (<highlight><bold>602</bold></highlight>) may just as easily act upon any or all of the transformed data streams P<highlight><subscript>0 </subscript></highlight>. . . P<highlight><subscript>n </subscript></highlight>output from the pre-processor stage <highlight><bold>1</bold></highlight> (<highlight><bold>601</bold></highlight>). Additional pre-processor stages (i.e., a pre-processor stage <highlight><bold>3</bold></highlight>, a pre-processor stage <highlight><bold>4</bold></highlight>, etc.) may also be added in any instantiation or embodiment. Each additional pre-processor stage may act upon any or all of the transformed data streams of previous pre-processor stages. Similarly, further stages may be composited onto the resulting combined stage to an arbitrary degree. For any given instantiation the composition architecture (i.e., the number of stages on any given path) will normally be fixed. Consequently the number and semantics of the output streams may be fixed and deterministic for any given implementation. The processing performed by the pre-processor stage <highlight><bold>2</bold></highlight> (<highlight><bold>602</bold></highlight>) upon transformed data stream P<highlight><subscript>1 </subscript></highlight>may result in transformed data streams P<highlight><subscript>1,0 </subscript></highlight>. . . P<highlight><subscript>1,m</subscript></highlight>. The input to the pre-processor rename streams stage (<highlight><bold>603</bold></highlight>) may be transformed data streams P<highlight><subscript>0</subscript></highlight>, P<highlight><subscript>2 </subscript></highlight>. . . P<highlight><subscript>n</subscript></highlight>, directly from the pre-processor stage <highlight><bold>1</bold></highlight> (<highlight><bold>601</bold></highlight>), along with transformed data streams P<highlight><subscript>1,0 </subscript></highlight>. . . P<highlight><subscript>1,m</subscript></highlight>, directly from the pre-processor stage <highlight><bold>2</bold></highlight> (<highlight><bold>602</bold></highlight>). It is noted that transformed data stream P<highlight><subscript>1 </subscript></highlight>is not an input to the pre-processor rename streams stage (<highlight><bold>603</bold></highlight>). The output of the pre-processor rename streams stage (<highlight><bold>603</bold></highlight>) may be transformed data streams Q<highlight><subscript>0 </subscript></highlight>. . . Q<highlight><subscript>n&plus;m&plus;1</subscript></highlight>. </paragraph>
<paragraph id="P-0085" lvl="7"><number>&lsqb;0085&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference>: Enhanced Differencer </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a block diagram of an embodiment of a composite pre-processing step (i.e., as described in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>) combined with generic differencers for the purpose of constructing an enhanced differencer. The composite pre-processing steps of <cross-reference target="DRAWINGS">FIG. 6</cross-reference> are noted as one step in this example: a composite pre-processor <highlight><bold>701</bold></highlight>. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The original form of the updated version of the data (U) may be processed by the composite pre-processor <highlight><bold>701</bold></highlight>, resulting in transformed data streams Q<highlight><subscript>0 </subscript></highlight>. . . Q<highlight><subscript>n&plus;m&plus;1</subscript></highlight>. Each output stream Q<highlight><subscript>0 </subscript></highlight>. . . Q<highlight><subscript>n&plus;m&plus;1</subscript></highlight>may then be subject to differencing using any known generic differencing method <highlight><bold>702</bold></highlight>, resulting in transformed data streams Q<highlight><subscript>0</subscript></highlight>&prime; . . . Q<highlight><subscript>n&plus;m&plus;1</subscript></highlight>&prime;. As discussed earlier, the known generic differencing method <highlight><bold>702</bold></highlight> may compare the previous version of each data stream with the current output streams Q<highlight><subscript>0 </subscript></highlight>. . . Q<highlight><subscript>n&plus;m&plus;1</subscript></highlight>. It is noted that it is not necessary to use the same known generic differencing method <highlight><bold>702</bold></highlight> on each output data stream Q<highlight><subscript>i </subscript></highlight>provided that there is a deterministic mapping of differencing method to output data stream (to allow reassembling as described in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>). Typical embodiments may use an identity differencer in box <highlight><bold>702</bold></highlight> upon output data stream Q<highlight><subscript>0 </subscript></highlight>along with other differencers upon the other output data streams. The identity differencer ignores the previous version of the data entirely and simply outputs the updated data in full, such that Q<highlight><subscript>i</subscript></highlight>&prime;&equals;Q<highlight><subscript>i</subscript></highlight>. </paragraph>
<paragraph id="P-0088" lvl="7"><number>&lsqb;0088&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference>: Individual Post-processing Step </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a block diagram of an embodiment of an individual post-processing step. This individual post-processing step may invert the transformations made by the matching pre-processor step described in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> Post-processor type determination module <highlight><bold>804</bold></highlight> may interpret the type information recorded in data stream P<highlight><subscript>0 </subscript></highlight>and may use this type information to instruct the post-processor multiplexor <highlight><bold>808</bold></highlight> to select the post-processor module <highlight><bold>810</bold></highlight> which corresponds to the pre-processor module <highlight><bold>510</bold></highlight> selected during difference representation construction (see <cross-reference target="DRAWINGS">FIG. 5</cross-reference>). The post-processor modules <highlight><bold>810</bold></highlight> may implement methods which invert the transformations of the corresponding pre-processor modules <highlight><bold>510</bold></highlight> used during construction of data streams P<highlight><subscript>1 </subscript></highlight>. . . P<highlight><subscript>n</subscript></highlight>, resulting in the sequence of substream segments (S). The desegmentor module <highlight><bold>812</bold></highlight> may then use the sequence of substream segments (S) to reassemble the original incoming data stream (U). </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> Post-processor example &num;<highlight><bold>1</bold></highlight> (database record parsing) may reassemble data stream (U) by reading one record from P<highlight><subscript>1 </subscript></highlight>and one from P<highlight><subscript>2 </subscript></highlight>and then inserting the price information from the P<highlight><subscript>2 </subscript></highlight>record into the P<highlight><subscript>1 </subscript></highlight>record following the goods details information. Similarly, post-processor example &num;<highlight><bold>2</bold></highlight> (decompression of compressed data) may compress the uncompressed stream, P<highlight><subscript>1</subscript></highlight>, back into ZIP format (U). A particular post-processing method for use with executable content is described in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>. </paragraph>
<paragraph id="P-0092" lvl="7"><number>&lsqb;0092&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference>: Composite Post-processing Step </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a block diagram of an embodiment of a composite post-processing step. The composite post-processing step in this example is made up of three stages: a post-processor rename streams stage (<highlight><bold>903</bold></highlight>), a post-processor stage <highlight><bold>1</bold></highlight> (<highlight><bold>901</bold></highlight>), and a post-processor stage <highlight><bold>2</bold></highlight> (<highlight><bold>902</bold></highlight>). This composite post-processing step may invert the transformations made by the matching pre-processor step described in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> The transformed data streams Q<highlight><subscript>0 </subscript></highlight>. . . Q<highlight><subscript>n&plus;m&plus;1 </subscript></highlight>may be processed by the post-processor rename streams stage (<highlight><bold>903</bold></highlight>), resulting in transformed data streams P<highlight><subscript>0</subscript></highlight>,P<highlight><subscript>1,0 </subscript></highlight>. . . P<highlight><subscript>1,m</subscript></highlight>,P<highlight><subscript>2 </subscript></highlight>. . . P<highlight><subscript>n</subscript></highlight>. The post-processor stage <highlight><bold>1</bold></highlight> (<highlight><bold>901</bold></highlight>) is shown as acting upon transformed data streams P<highlight><subscript>1,0 </subscript></highlight>. . . P<highlight><subscript>1,m</subscript></highlight>only. It is noted that the post-processor stage <highlight><bold>1</bold></highlight> (<highlight><bold>901</bold></highlight>) may just as easily act upon any or all of the transformed data streams P<highlight><subscript>0</subscript></highlight>,P<highlight><subscript>2 </subscript></highlight>. . . P<highlight><subscript>n </subscript></highlight>output from the post-processor rename streams stage (<highlight><bold>903</bold></highlight>). Additional post-processor stages (i.e., a post-processor stage <highlight><bold>3</bold></highlight>, a post-processor stage <highlight><bold>4</bold></highlight>, etc.) may also be added in any instantiation or embodiment. Each additional post-processor stage may act upon any or all of the transformed data streams of previous post-processor stages. Similarly, further stages may be composited onto the resulting combined stage to an arbitrary degree. For any given instantiation the composition architecture (i.e., the number of stages on any given path) will normally be fixed. Consequently the number and semantics of the output streams may be fixed and deterministic for any given implementation. The input to the post-processor stage <highlight><bold>2</bold></highlight> (<highlight><bold>902</bold></highlight>) may be transformed data streams P<highlight><subscript>0</subscript></highlight>, P<highlight><subscript>2 </subscript></highlight>. . . P<highlight><subscript>n</subscript></highlight>, directly from the post-processor rename streams stage (<highlight><bold>903</bold></highlight>), along with transformed data stream P<highlight><subscript>1</subscript></highlight>, directly from the postprocessor stage <highlight><bold>1</bold></highlight> (<highlight><bold>901</bold></highlight>). It is noted that transformed data streams P<highlight><subscript>1,0 </subscript></highlight>. . . P<highlight><subscript>1,m </subscript></highlight>are not inputs to the post-processor stage <highlight><bold>2</bold></highlight> (<highlight><bold>902</bold></highlight>). The processing performed by the post-processor stage <highlight><bold>2</bold></highlight> (<highlight><bold>902</bold></highlight>) upon transformed data streams P<highlight><subscript>0 </subscript></highlight>. . . P<highlight><subscript>n </subscript></highlight>may result in the original form of the updated version of the data (U). </paragraph>
<paragraph id="P-0095" lvl="7"><number>&lsqb;0095&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference>: Enhanced Reconstructor </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a block diagram of an embodiment of a composite post-processing step (i.e., as described in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>) combined with generic reconstructors associated with the known differencing methods of <cross-reference target="DRAWINGS">FIG. 7</cross-reference> to produce an enhanced reconstructor. The composite post-processing steps of <cross-reference target="DRAWINGS">FIG. 9</cross-reference> are noted as one step in this example: a composite post-processor <highlight><bold>1001</bold></highlight>. This process, described in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, may invert the process described in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, thus converting the Q<highlight><subscript>i</subscript></highlight>&prime; data streams back to the original form of the updated version of the data (U). </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> The transformed data streams Q<highlight><subscript>0</subscript></highlight>&prime; . . . Q<highlight><subscript>n&plus;m&plus;1</subscript></highlight>&prime; may be subject to reconstructing using any known generic reconstructing method <highlight><bold>1002</bold></highlight>, resulting in transformed data streams Q<highlight><subscript>0 </subscript></highlight>. . . Q<highlight><subscript>n&plus;m&plus;1</subscript></highlight>. As discussed earlier, the known generic reconstructing method <highlight><bold>1002</bold></highlight> may compare the previous version of the data streams with the current transformed data streams Q<highlight><subscript>0</subscript></highlight>&prime; . . . Q<highlight><subscript>n&plus;m&plus;1</subscript></highlight>&prime;. Each output stream Q<highlight><subscript>0 </subscript></highlight>. . . Q<highlight><subscript>n&plus;m&plus;1 </subscript></highlight>may then be passed to the composite post-processor <highlight><bold>1001</bold></highlight>, resulting in the original form of the updated version of the data (U). It is noted that it is not necessary to use the same known generic reconstructing method in box <highlight><bold>1002</bold></highlight> on each output data stream Q<highlight><subscript>i</subscript></highlight>&prime; provided that there is a deterministic mapping of differencing method to output data stream to allow reassembling. Typical embodiments may use an identity reconstructor in box <highlight><bold>1002</bold></highlight> upon data stream Q<highlight><subscript>0</subscript></highlight>&prime; along with other reconstructors upon the other data streams. The identity reconstructor ignores the previous version of the data entirely and simply outputs the updated data in full, such that Q<highlight><subscript>i</subscript></highlight>&prime;&equals;Q<highlight><subscript>i</subscript></highlight>. </paragraph>
<paragraph id="P-0098" lvl="7"><number>&lsqb;0098&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference>: Packaging and Unpackaging Processes </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a block diagram illustrating an embodiment of a packaging process and an unpackaging process which may be used to facilitate transmission or storage of the difference representations, Q<highlight><subscript>0</subscript></highlight>&prime; . . . Q<highlight><subscript>n</subscript></highlight>&prime;. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> The individual data streams Q<highlight><subscript>0</subscript></highlight>&prime; . . . Q<highlight><subscript>n</subscript></highlight>&prime; may be packaged into a single data stream (R) by a known method (e.g., length-encoded concatenation) by a packaging module <highlight><bold>1102</bold></highlight>. In one embodiment, the single data stream (R) may then be compressed by a known compression method (e.g., ZIP) by a compressor module <highlight><bold>1104</bold></highlight>. The resulting data stream (R&prime;) may then be stored or transmitted by means of a computer network <highlight><bold>1110</bold></highlight>. This process facilitates efficient transmission and storage of difference representations. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> When (or where) the original form of the updated version of the data (U) is to be reconstructed an inverse process may proceed as follows: an uncompressor module <highlight><bold>1106</bold></highlight> may use a known decompression method associated with the known compression method used by the compressor module <highlight><bold>1104</bold></highlight> to decompress the data stream (R&prime;) to reconstruct the single data stream (R). An unpackaging module <highlight><bold>1108</bold></highlight> may then split the single data stream (R) into individual data streams Q<highlight><subscript>0</subscript></highlight>&prime; . . . Q<highlight><subscript>n</subscript></highlight>&prime; by inverting the known method employed by the packaging module <highlight><bold>1102</bold></highlight>. The individual data streams Q<highlight><subscript>0</subscript></highlight>&prime; may then be used as input to the reconstruction process described in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. </paragraph>
<paragraph id="P-0102" lvl="7"><number>&lsqb;0102&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference>: Executable Format Example: Pre-processor </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a block diagram illustrating an embodiment of a pre-processor specifically intended to enhance the differencing process for executable format data (e.g., Wintel program files). </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> The function of the pre-processor is to separate the volatile elements of the incoming data stream (e.g., linkage offsets and variable addresses that are likely to change when otherwise localized changes are made to the source file; when the source file is &ldquo;built&rdquo; (i.e., compiled), the output of the build process is the executable in question) from the non-volatile elements (e.g., the pattern of instructions that make up the code in the source file, stripped of the target address components). </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> Instruction scanner <highlight><bold>1202</bold></highlight> may buffer the input data stream (S*) and may scan the input data stream (S*) for data representing sequences of instructions in the associated format. Examples of formats include: Intel machine instruction sequences in the case of a Wintel executable file, Java bytecode, as well as other physical machine architectures, and other virtual machine architectures. Sequences that the instruction scanner <highlight><bold>1202</bold></highlight> determines do not represent instruction sequences may be output to the pattern mismatch buffer <highlight><bold>1206</bold></highlight>. The instruction scanner <highlight><bold>1202</bold></highlight> may output identified instruction sequences to the instruction parser <highlight><bold>1204</bold></highlight>, together with control information relating the provided instruction sequence to its start position within the input data stream (S*). The symbol for the &ldquo;end of input&rdquo; may be treated as a zero-length instruction sequence and processed by the instruction parser <highlight><bold>1204</bold></highlight> accordingly. This process may ensure correct flushing of the output stream via the processes that the instruction parser <highlight><bold>1204</bold></highlight> goes through when processing an instruction sequence. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> Instruction parser <highlight><bold>1204</bold></highlight> may parse each instruction in the sequence in turn. For each possible instruction within the instruction code of the targeted machine architecture (e.g., Intel x86 or its descendants) a pattern template may determine which bytes comprising the instruction are to be considered &ldquo;volatile&rdquo; and which are to be considered &ldquo;non-volatile&rdquo;. In one embodiment, op-codes, op-code modifiers, and immediate operands may be considered &ldquo;non-volatile&rdquo; while address operands or offset operands (e.g., absolute addresses, relative offsets, jump targets, branch relative offsets) may be considered &ldquo;volatile&rdquo;. For example, the instruction: </paragraph>
<paragraph id="P-0107" lvl="2"><number>&lsqb;0107&rsqb;</number> MOV EAX, &lsqb;DWORD &lt;address&gt;&rsqb; is represented by the byte sequence: </paragraph>
<paragraph id="P-0108" lvl="2"><number>&lsqb;0108&rsqb;</number> <highlight><bold>8</bold></highlight>B <highlight><bold>05</bold></highlight> XX XX XX XX where XX XX XX XX is the hex encoding of &lt;address&gt;. </paragraph>
<paragraph id="P-0109" lvl="2"><number>&lsqb;0109&rsqb;</number> The pattern template for this instruction may be: </paragraph>
<paragraph id="P-0110" lvl="2"><number>&lsqb;0110&rsqb;</number> N N V V V V where N indicates a non-volatile byte and V a volatile byte. The instruction parser <highlight><bold>1204</bold></highlight> may then output the non-volatile bytes on the pattern data stream P<highlight><subscript>1 </subscript></highlight>and the volatile bytes on the mismatch data stream M. It is noted that the mismatch data stream M passes through the mismatch buffer <highlight><bold>1206</bold></highlight> to the mismatch data stream P<highlight><subscript>2</subscript></highlight>, as described below. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> The instruction parser <highlight><bold>1204</bold></highlight> may also emit a pseudo op-code demarking the boundary between non-contiguous (in the input stream) instruction sequences. This pseudo op-code may be emitted prior to the start of the second instruction sequence (of the two under consideration). It is noted that the pseudo op-code may be drawn from the set of illegal op-codes for the target machine architecture, so as to make it distinguishable from other legal op-code sequences that may occur in the pattern stream. When generating this pseudo op-code the instruction parser <highlight><bold>1204</bold></highlight> may also instruct the mismatch buffer <highlight><bold>1206</bold></highlight> to flush its buffered non-instruction sequence (if any) preceded by the length of that non-instruction sequence (i.e., a length encoded sequence) on the mismatch data stream P<highlight><subscript>2</subscript></highlight>. If there is no such buffered non-instruction data, then no output may be appended to the mismatch data stream P<highlight><subscript>2</subscript></highlight>. That is, a length-encoding of <highlight><bold>0</bold></highlight> may not be emitted if there is no buffered non-instruction data present. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> One function of the mismatch buffer <highlight><bold>1206</bold></highlight> may be to ensure the correct interleaving of non-instruction data and instruction data. This function may be accomplished by the mismatch buffer <highlight><bold>1206</bold></highlight> responding to flush requests from the instruction parser <highlight><bold>1204</bold></highlight>, as described above. In particular, the mismatch buffer <highlight><bold>1206</bold></highlight> may buffer all non-instruction data up until the start of the following instruction sequence is identified (or end of input occurs). At this point, the mismatch buffer <highlight><bold>1206</bold></highlight> may interleave data as follows: (1) any buffered non-instruction data in length-encoded form (i.e., the mismatch data stream M) and (2) instruction data passed to the mismatch buffer <highlight><bold>1204</bold></highlight> for the identified sequence by the instruction parser <highlight><bold>1204</bold></highlight>. This interleaving may guarantee that the length of any non-instruction sequence precedes that non-instruction sequence section and may allow the start of the following instruction information to be identified. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> One constraint that may be placed on the instruction parser <highlight><bold>1204</bold></highlight> is that all bytes necessary to determine the form of the instruction (e.g., op-code and some op-code modifiers for the Intel x86 instruction set) are considered non-volatile. This constraint may ensure that the non-volatile bytes for a particular instruction, which are known as the instruction pattern, may uniquely identify a particular instruction pattern template. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> Together the pseudo op-code interleaving and the constraint described above may ensure that the pattern data stream P<highlight><subscript>1 </subscript></highlight>is able to be parsed by an inverting post-processor (shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>) in a deterministic fashion, drawing on the mismatch buffer <highlight><bold>1206</bold></highlight> only in response to the parsing of the pattern data stream P<highlight><subscript>1</subscript></highlight>. </paragraph>
<paragraph id="P-0115" lvl="7"><number>&lsqb;0115&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference>: Executable Format Example: Post-processor </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a flowchart illustrating an embodiment of a post-processor corresponding to the pre-processor of <cross-reference target="DRAWINGS">FIG. 12</cross-reference>. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> In step <highlight><bold>1302</bold></highlight>, bytes may be consumed from the pattern data stream P<highlight><subscript>1</subscript></highlight>* until a complete instruction pattern has been read. In step <highlight><bold>1304</bold></highlight>, this instruction pattern may be compared against the pattern for the start-of-sequence pseudo-instruction. If the instruction pattern is the start-of-sequence pseudo-instruction, then step <highlight><bold>1306</bold></highlight> may be processed; otherwise, step <highlight><bold>1310</bold></highlight> may be processed. In step <highlight><bold>1306</bold></highlight>, the length of the preceding non-instruction sequence may be read from the mismatch data stream P<highlight><subscript>2</subscript></highlight>*. In step <highlight><bold>1308</bold></highlight>, the number of bytes indicated by the length (read in step <highlight><bold>1306</bold></highlight>) may then be consumed from the mismatch data stream P<highlight><subscript>2</subscript></highlight>* and these bytes may then be output to the output data stream (S*). Following step <highlight><bold>1308</bold></highlight>, processing may loop back to step <highlight><bold>1302</bold></highlight>, where another instruction pattern may be read. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> In step <highlight><bold>1310</bold></highlight>, the instruction pattern template corresponding to the instruction pattern may be determined. In step <highlight><bold>1312</bold></highlight>, the volatile bytes in the instruction pattern template may then be filled in by reading bytes from the mismatch data stream P<highlight><subscript>2</subscript></highlight>*. In step <highlight><bold>1314</bold></highlight>, the non-volatile bytes from the instruction pattern template may then be read from the instruction pattern template. In step <highlight><bold>1316</bold></highlight>, the resulting complete instruction may then be emitted on the output data stream (S*). Following step <highlight><bold>1316</bold></highlight>, processing may loop back to step <highlight><bold>1302</bold></highlight>, where another instruction pattern may be read. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> One benefit of this process is that, as mentioned earlier, non-localized changes in the input data stream may be localized in the output data streams. In the example described in <cross-reference target="DRAWINGS">FIGS. 12 and 13</cross-reference>, almost all change is confined to the mismatch data stream. This localization of changes may result in very efficient differencing of the pattern stream and therefore improved overall differencing efficiency. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> Another benefit of this process is that by removing the vagaries of the particular operands being used in higher level programming structures (e.g., subroutine entry, looping control structures, etc.) in the pattern stream, recurring sequences that correspond to compiler idioms for these higher-level structures may emerge. Because these sequences recur frequently, additional compression may be achieved when the resulting stream is later compressed with known compression algorithms (e.g., in the packaging process described in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>). Combining efficient data difference representation with compression (i.e., differencing against NULL, as previously mentioned), may significantly increase the effectiveness of the known compression mechanism on executable data types. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> Although the system and method of the present invention have been described in connection with several embodiments, the invention is not intended to be limited to the specific forms set forth herein, but on the contrary, it is intended to cover such alternatives, modifications, and equivalents as may be reasonably included within the spirit and scope of the invention as defined by the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of reducing a size of data difference representations, the method comprising: 
<claim-text>identifying an original version of an input data stream in an original form; </claim-text>
<claim-text>dividing the original form of the original version of the input data stream into one or more separate original version output data streams through the use of a pre-processor; </claim-text>
<claim-text>identifying an updated version of the input data stream in the original form; </claim-text>
<claim-text>dividing the original form of the updated version of the input data stream into one or more separate updated version output data streams through the use of the pre-processor; and </claim-text>
<claim-text>differencing each of the one or more separate updated version output data streams with a corresponding original version output data stream to produce data difference representations. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the data difference representations are smaller than a data difference representation created by differencing the original form of the updated version of the input data stream with the original form of the original input data stream. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>reconstructing the one or more separate updated version output data streams from the data difference representations and the original version output data streams; and </claim-text>
<claim-text>combining the one or more separate updated version output data streams into the original form of the updated version of the input data stream through the use of a post-processor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the original form of the original version of the input data stream is empty. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the pre-processor comprises decompression algorithms. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the dividing steps separate volatile components of the input data stream from less volatile components of the input data stream. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> wherein the input data stream is executable code. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein the volatile components comprise branch targets. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein the volatile components comprise data addresses. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein the less volatile components comprise instruction code. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein the less volatile components comprise immediate data. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>packaging the data difference representations into a single data stream; </claim-text>
<claim-text>compressing the single data stream; and </claim-text>
<claim-text>storing the single data stream. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, further comprising: 
<claim-text>transmitting the single data stream; </claim-text>
<claim-text>uncompressing the single data stream; and </claim-text>
<claim-text>unpackaging the single data stream into the data difference representations. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A system of reducing a size of data difference representations, the system comprising: 
<claim-text>a network; </claim-text>
<claim-text>a first computer system coupled to the network; </claim-text>
<claim-text>a system memory coupled to the first computer system, wherein the system memory stores one or more computer programs executable by the first computer system; </claim-text>
<claim-text>wherein the computer programs are executable to: </claim-text>
<claim-text>identify an original version of an input data stream in an original form; </claim-text>
<claim-text>divide the original form of the original version of the input data stream into one or more separate original version output data streams through the use of a pre-processor; </claim-text>
<claim-text>identify an updated version of the input data stream in the original form; </claim-text>
<claim-text>divide the original form of the updated version of the input data stream into one or more separate updated version output data streams through the use of the pre-processor; and </claim-text>
<claim-text>difference each of the one or more separate updated version output data streams with a corresponding original version output data stream to produce data difference representations. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein the data difference representations are smaller than a data difference representation created by differencing the original form of the updated version of the input data stream with the original form of the original input data stream. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, further comprising: 
<claim-text>a second computer system coupled to the network; </claim-text>
<claim-text>a system memory coupled to the second computer system, wherein the system memory stores one or more computer programs executable by the second computer system; </claim-text>
<claim-text>wherein the pre-processor is located in the first computer system; and </claim-text>
<claim-text>wherein the post-processor is located in the second computer system. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein the computer programs are further executable to: 
<claim-text>reconstruct the one or more separate updated version output data streams from the data difference representations and the original version output data streams; and </claim-text>
<claim-text>combine the one or more separate updated version output data streams into the original form of the updated version of the input data stream through the use of a post-processor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> wherein the original form of the original version of the input data stream is empty. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> wherein the pre-processor comprises decompression algorithms. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> wherein the dividing steps separate volatile components of the input data stream from less volatile components of the input data stream. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> wherein the input data stream is executable code. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference> wherein the volatile components comprise branch targets. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference> wherein the volatile components comprise data addresses. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference> wherein the less volatile components comprise instruction code. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference> wherein the less volatile components comprise immediate data. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein the computer programs are further executable to: 
<claim-text>package the data difference representations into a single data stream; </claim-text>
<claim-text>compress the single data stream; and </claim-text>
<claim-text>store the single data stream on a memory medium coupled to the first computer system. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference>, wherein the computer programs are further executable to: 
<claim-text>transmit the single data stream from the memory medium coupled to the first computer system to the second computer system over the network; </claim-text>
<claim-text>uncompress the single data stream; and </claim-text>
<claim-text>unpackage the single data stream into the data difference representations. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. A carrier medium which stores program instructions, wherein the program instructions are executable to implement reducing a size of data difference representations comprising: 
<claim-text>identifying an original version of an input data stream in an original form; </claim-text>
<claim-text>dividing the original form of the original version of the input data stream into one or more separate original version output data streams through the use of a pre-processor; </claim-text>
<claim-text>identifying an updated version of the input data stream in the original form; </claim-text>
<claim-text>dividing the original form of the updated version of the input data stream into one or more separate updated version output data streams through the use of the pre-processor; and </claim-text>
<claim-text>differencing each of the one or more separate updated version output data streams with a corresponding original version output data stream to produce data difference representations. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, wherein the data difference representations are smaller than a data difference representation created by differencing the original form of the updated version of the input data stream with the original form of the original input data stream. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, wherein the program instructions are further executable to implement: 
<claim-text>reconstructing the one or more separate updated version output data streams from the data difference representations and the original version output data streams; and </claim-text>
<claim-text>combining the one or more separate updated version output data streams into the original form of the updated version of the input data stream through the use of a post-processor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> wherein the original form of the original version of the input data stream is empty. </claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> wherein the pre-processor comprises decompression algorithms. </claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> wherein the dividing steps separate volatile components of the input data stream from less volatile components of the input data stream. </claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00033">claim 33</dependent-claim-reference> wherein the input data stream is executable code. </claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00033">claim 34</dependent-claim-reference> wherein the volatile components comprise branch targets. </claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00033">claim 34</dependent-claim-reference> wherein the volatile components comprise data addresses. </claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00033">claim 34</dependent-claim-reference> wherein the less volatile components comprise instruction code. </claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00033">claim 34</dependent-claim-reference> wherein the less volatile components comprise immediate data. </claim-text>
</claim>
<claim id="CLM-00039">
<claim-text><highlight><bold>39</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, wherein the program instructions are further executable to implement: 
<claim-text>packaging the data difference representations into a single data stream; </claim-text>
<claim-text>compressing the single data stream; and </claim-text>
<claim-text>storing the single data stream on a memory medium coupled to a first computer system. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00040">
<claim-text><highlight><bold>40</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00033">claim 39</dependent-claim-reference>, wherein the program instructions are further executable to implement: 
<claim-text>transmitting the single data stream from the memory medium coupled to the first computer system to a second computer system over a computer system network; </claim-text>
<claim-text>uncompressing the single data stream; and </claim-text>
<claim-text>unpackaging the single data stream into the data difference representations. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00041">
<claim-text><highlight><bold>41</bold></highlight>. The carrier medium of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, wherein the carrier medium is a memory medium.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>4A</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004990A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004990A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004990A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004990A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004990A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004990A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004990A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004990A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004990A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004990A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030004990A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030004990A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030004990A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030004990A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
