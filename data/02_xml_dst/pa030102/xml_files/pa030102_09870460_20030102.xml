<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005245A1-20030102-D00000.TIF SYSTEM "US20030005245A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005245A1-20030102-D00001.TIF SYSTEM "US20030005245A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005245A1-20030102-D00002.TIF SYSTEM "US20030005245A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005245A1-20030102-D00003.TIF SYSTEM "US20030005245A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005245A1-20030102-D00004.TIF SYSTEM "US20030005245A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005245A1-20030102-D00005.TIF SYSTEM "US20030005245A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030005245A1-20030102-D00006.TIF SYSTEM "US20030005245A1-20030102-D00006.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005245</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09870460</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010601</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F012/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>711</class>
<subclass>163000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Modified harvard architecture processor having data memory space mapped to program memory space with erroneous execution protection</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Michael</given-name>
<family-name>Catherwood</family-name>
</name>
<residence>
<residence-us>
<city>Pepperell</city>
<state>MA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>SWIDLER BERLIN SHEREFF FRIEDMAN, LLP</name-1>
<name-2></name-2>
<address>
<address-1>3000 K STREET, NW</address-1>
<address-2>BOX IP</address-2>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20007</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A processor has an architecture that provides the processing speed advantages of the Harvard architecture, but does not require two separate external memories in order to expand both data memory and program instruction memory. The processor has separate program memory space and data memory space, but provides the capability to map at least a portion of the program memory space to the data memory space. This allows most program instructions that are processed to obtain the speed advantages of simultaneous program instruction and data access. It also allows program memory space and data memory space to be expanded externally to the processor using only one external memory device that includes both program instructions and data. The processor includes a program memory space operable to store program instructions and data, a data memory space operable to store data, and mapping circuitry operable to map at least a portion of the program memory space to the data memory space. The program memory space may be internal to the processor. The processor may further comprise a page register operable to specify a location of the program memory space that is mapped to the data memory space. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present invention relates to a modified Harvard architecture processor having data memory space mapped to program memory space and having protection for erroneous execution of data entries in the program memory space. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Processors, including microprocessors, digital signal processors and microcontrollers, operate by running software programs that are embodied in one or more series of program instructions stored in a memory. The processors run the software by fetching the program instructions from the series of program instructions, decoding the program instructions and executing them. In addition to program instructions, data is also stored in memory that is accessible by the processor. Generally, the program instructions process data by accessing data in memory, modifying the data and storing the modified data into memory. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> One well-known architecture for processors is known as the Harvard architecture. In this architecture, data and program instructions are stored in separate memories that can be accessed simultaneously. Because of this simultaneous access, the Harvard architecture provides significant processing speed advantages over other architectures. A typical Harvard architecture processor that includes internal memory includes two separate memories, one for data, and one for program instructions. In order to expand the memory capacity of such a processor, memory external to the processor must be added. However, since a Harvard architecture processor has two separate memories, in order to expand both data memory and program instruction memory, two separate external memories must be added. This is a significant disadvantage when low-cost systems are being built. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> A need arises for a processor having an architecture that provides the processing speed advantages of the Harvard architecture, but does not require two separate external memories in order to expand both data memory and program instruction memory. One solution to this problem is described in co-pending U.S. patent application Ser. No. XX/XXX,XXX. The described processor has separate program memory space and data memory space, but provides the capability to map at least a portion of the program memory space to the data memory space. This allows most program instructions that are processed to obtain the speed advantages of simultaneous program instruction and data access. It also allows program memory space and data memory space to be expanded externally to the processor using only one external memory device that includes both program instructions and data. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> However, a problem arises with this solution. Under some circumstances, the processor may fetch and attempt to execute an entry in the program memory space that has been mapped to the data memory space and which contains data, not a program instruction. Such a situation may occur, for example, as a result of a bug in the software that is being executed. Attempted execution of data that is not a program instruction may cause unpredictable results. A need arises for a technique by which attempted execution of data that is not a program instruction may be detected and recovered from. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The present invention is a method, and a processor implementing the method, that provides the capability to detect and recover from attempted execution of data that is not a program instruction in a processor in which at least a portion of a program memory space to a data memory space. This allows the processor to provide the speed advantages and expansion advantages without the risk of unpredictable program execution behavior. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> According to the present invention, a method of operating a processor comprises the steps of: mapping at least a portion of a program memory space to a data memory space, storing an entry into the program memory space that is mapped to the data memory space, the entry comprising data and a protection opcode, fetching an entry from the program memory space, attempting to execute the fetched entry, trapping the protection opcode, vectoring to a trap handler, and executing the trap handler. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> In one aspect of the present invention, the trap handler is an illegal instruction trap handler and the step of executing the trap handler comprises the steps of determining that the opcode is a protection opcode, and executing a software routine to handle the trap. The program memory space may be internal to the processor. The processor may be operably connected to an external memory device operable to store program instructions and data, the external memory device comprising program memory space. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> In one aspect of the present invention, the trap handler is a protection trap handler. The program memory space may be internal to the processor. The processor may be operably connected to an external memory device operable to store program instructions and data, the external memory device comprising program memory space.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE FIGURES </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The above described features and advantages of the present invention will be more fully appreciated with reference to the detailed description and appended figures in which: </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> depicts a functional block diagram of an embodiment of a processor chip within which the present invention may find application. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> depicts a functional block diagram of a data busing scheme for use in a processor <highlight><bold>100</bold></highlight>, such as that shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> depicts an exemplary memory map of a data space memory, which may be implemented in the processor shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> depicts an exemplary block diagram of program memory space to data memory space mapping which may be implemented in the processor shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, according to the present invention. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> depicts a block diagram of a data execution protection scheme, which may be implemented in the processor shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, according to the present invention. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> depicts a processing flow diagram of a process for detection and handling of erroneous execution of a data entry, which may be implemented in the processor shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, according to the present invention. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0017" lvl="7"><number>&lsqb;0017&rsqb;</number> Overview of Processor Elements </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> depicts a functional block diagram of an embodiment of a processor chip within which the present invention may find application. Referring to <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> processor <highlight><bold>100</bold></highlight> is coupled to external devices/systems <highlight><bold>140</bold></highlight>. The processor <highlight><bold>100</bold></highlight> may be any type of processor including, for example, a digital signal processor (DSP), a microprocessor, a microcontroller, or combinations thereof. The external devices <highlight><bold>140</bold></highlight> may be any type of systems or devices including input/output devices such as keyboards, displays, speakers, microphones, memory, or other systems which may or may not include processors. Moreover, the processor <highlight><bold>100</bold></highlight> and the external devices <highlight><bold>140</bold></highlight> may together comprise a stand alone system. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> The processor <highlight><bold>100</bold></highlight> includes a program memory <highlight><bold>105</bold></highlight>, an instruction fetch/decode unit <highlight><bold>110</bold></highlight>, instruction execution units <highlight><bold>115</bold></highlight> data memory and registers <highlight><bold>120</bold></highlight>, peripherals <highlight><bold>125</bold></highlight>, data I/O <highlight><bold>130</bold></highlight>, and a program counter and loop control unit <highlight><bold>135</bold></highlight>. The bus <highlight><bold>150</bold></highlight>, which may include one or more common buses, communicates data between the units as shown. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> The program memory <highlight><bold>105</bold></highlight> stores software embodied in program instructions for execution by the processor <highlight><bold>100</bold></highlight>. The program memory <highlight><bold>105</bold></highlight> may comprise any type of nonvolatile memory such as a read only memory (ROM), a programmable read only memory (PROM), an electrically programmable or an electrically programmable and erasable read only memory (EPROM or EEPROM) or flash memory. In addition, the program memory <highlight><bold>105</bold></highlight> may be supplemented with external nonvolatile memory <highlight><bold>145</bold></highlight> as shown to increase the complexity of software available to the processor <highlight><bold>100</bold></highlight>. Alternatively, the program memory may be volatile memory, which receives program instructions from, for example, an external non-volatile memory <highlight><bold>145</bold></highlight>. When the program memory <highlight><bold>105</bold></highlight> is nonvolatile memory, the program memory may be programmed at the time of manufacturing the processor <highlight><bold>100</bold></highlight> or prior to or during implementation of the processor <highlight><bold>100</bold></highlight> within a system. In the latter scenario, the processor <highlight><bold>100</bold></highlight> may be programmed through a process called in-line serial programming. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The instruction fetch/decode unit <highlight><bold>110</bold></highlight> is coupled to the program memory <highlight><bold>105</bold></highlight>, the instruction execution units <highlight><bold>115</bold></highlight>, and the data memory <highlight><bold>120</bold></highlight>. Coupled to the program memory <highlight><bold>105</bold></highlight> and the bus <highlight><bold>150</bold></highlight> is the program counter and loop control unit <highlight><bold>135</bold></highlight>. The instruction fetch/decode unit <highlight><bold>110</bold></highlight> fetches the instructions from the program memory <highlight><bold>105</bold></highlight> specified by the address value contained in the program counter <highlight><bold>135</bold></highlight>. The instruction fetch/decode unit <highlight><bold>110</bold></highlight> then decodes the fetched instructions and sends the decoded instructions to the appropriate execution unit <highlight><bold>115</bold></highlight>. The instruction fetch/decode unit <highlight><bold>110</bold></highlight> may also send operand information including addresses of data to the data memory <highlight><bold>120</bold></highlight> and to functional elements that access the registers. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The program counter and loop control unit <highlight><bold>135</bold></highlight> includes a program counter register (not shown) which stores an address of the next instruction to be fetched. During normal instruction processing, the program counter register may be incremented to cause sequential instructions to be fetched. Alternatively, the program counter value may be altered by loading a new value into it via the bus <highlight><bold>150</bold></highlight>. The new value may be derived based on decoding and executing a flow control instruction such as, for example, a branch instruction. In addition, the loop control portion of the program counter and loop control unit <highlight><bold>135</bold></highlight> may be used to provide repeat instruction processing and repeat loop control as further described below. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> The instruction execution units <highlight><bold>115</bold></highlight> receive the decoded instructions from the instruction fetch/decode unit <highlight><bold>110</bold></highlight> and thereafter execute the decoded instructions. As part of this process, the execution units may retrieve one or two operands via the bus <highlight><bold>150</bold></highlight> and store the result into a register or memory location within the data memory <highlight><bold>120</bold></highlight>. The execution units may include an arithmetic logic unit (ALU) such as those typically found in a microcontroller. The execution units may also include a digital signal processing engine, a floating point processor, an integer processor, or any other convenient execution unit. A preferred embodiment of the execution units and their interaction with the bus <highlight><bold>150</bold></highlight>, which may include one or more buses, is presented in more detail below with reference to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The data memory and registers <highlight><bold>120</bold></highlight> are volatile memory and are used to store data used and generated by the execution units. The data memory <highlight><bold>120</bold></highlight> and program memory <highlight><bold>105</bold></highlight> are preferably separate memories for storing data and program instructions respectively. This format is a known generally as a Harvard architecture. It is noted, however, that according to the present invention, the architecture may be a Von-Neuman architecture or a modified Harvard architecture, which permits the use of some program space for data space. A dotted line is shown, for example, connecting the program memory <highlight><bold>105</bold></highlight> to the bus <highlight><bold>150</bold></highlight>. This path may include logic for aligning data reads from program space such as, for example, during table reads from program space to data memory <highlight><bold>120</bold></highlight>. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Referring again to <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> plurality of peripherals <highlight><bold>125</bold></highlight> on the processor may be coupled to the bus <highlight><bold>125</bold></highlight>. The peripherals may include, for example, analog to digital converters, timers, bus interfaces and protocols such as, for example, the controller area network (CAN) protocol or the Universal Serial Bus (USB) protocol and other peripherals. The peripherals exchange data over the bus <highlight><bold>150</bold></highlight> with the other units. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> The data I/O unit <highlight><bold>130</bold></highlight> may include transceivers and other logic for interfacing with the external devices/systems <highlight><bold>140</bold></highlight>. The data I/O unit <highlight><bold>130</bold></highlight> may further include functionality to permit in circuit serial programming of the Program memory through the data I/O unit <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> depicts a functional block diagram of a data busing scheme for use in a processor <highlight><bold>100</bold></highlight>, such as that shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, which has an integrated microcontroller arithmetic logic unit (ALU) <highlight><bold>270</bold></highlight> and a digital signal processing (DSP) engine <highlight><bold>230</bold></highlight>. This configuration may be used to integrate DSP functionality to an existing microcontroller core. Referring to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the data memory <highlight><bold>120</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is implemented as two separate memories: an X-memory <highlight><bold>210</bold></highlight> and a Y-memory <highlight><bold>220</bold></highlight>, each being respectively addressable by an X-address generator <highlight><bold>250</bold></highlight> and a Y-address generator <highlight><bold>260</bold></highlight>. The X-address generator may also permit addressing the Y-memory space thus making the data space appear like a single contiguous memory space when addressed from the X address generator. The bus <highlight><bold>150</bold></highlight> may be implemented as two buses, one for each of the X and Y memory, to permit simultaneous fetching of data from the X and Y memories. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The W registers <highlight><bold>240</bold></highlight> are general purpose address and/or data registers. The DSP engine <highlight><bold>230</bold></highlight> is coupled to both the X and Y memory buses and to the W registers <highlight><bold>240</bold></highlight>. The DSP engine <highlight><bold>230</bold></highlight> may simultaneously fetch data from each the X and Y memory, execute instructions which operate on the simultaneously fetched data and write the result to an accumulator (not shown) and write a prior result to X or Y memory or to the W registers <highlight><bold>240</bold></highlight> within a single processor cycle. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> In one embodiment, the ALU <highlight><bold>270</bold></highlight> may be coupled only to the X memory bus and may only fetch data from the X bus. However, the X and Y memories <highlight><bold>210</bold></highlight> and <highlight><bold>220</bold></highlight> may be addressed as a single memory space by the X address generator in order to make the data memory segregation transparent to the ALU <highlight><bold>270</bold></highlight>. The memory locations within the X and Y memories may be addressed by values stored in the W registers <highlight><bold>240</bold></highlight>. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Any processor clocking scheme may be implemented for fetching and executing instructions. A specific example follows, however, to illustrate an embodiment of the present invention. Each instruction cycle is comprised of four Q clock cycles Q1-Q4. The four phase Q cycles provide timing signals to coordinate the decode, read, process data and write data portions of each instruction cycle. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> According to one embodiment of the processor <highlight><bold>100</bold></highlight>, the processor <highlight><bold>100</bold></highlight> concurrently performs two operations&mdash;it fetches the next instruction and executes the present instruction. Accordingly, the two processes occur simultaneously. The following sequence of events may comprise, for example, the fetch instruction cycle:  
<table-cwu id="TABLE-US-00001">
<number>1</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="42PT" align="right"/>
<colspec colname="2" colwidth="175PT" align="left"/>
<thead>
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry>Q1:</entry>
<entry>Fetch Instruction</entry>
</row>
<row>
<entry>Q2:</entry>
<entry>Fetch Instruction</entry>
</row>
<row>
<entry>Q3:</entry>
<entry>Fetch Instruction</entry>
</row>
<row>
<entry>Q4:</entry>
<entry>Latch Instruction into prefetch register, Increment PC</entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The following sequence of events may comprise, for example, the execute instruction cycle for a single operand instruction:  
<table-cwu id="TABLE-US-00002">
<number>2</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="21PT" align="right"/>
<colspec colname="2" colwidth="196PT" align="left"/>
<thead>
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry>Q1:</entry>
<entry>latch instruction into IR, decode, and determine addresses of</entry>
</row>
<row>
<entry></entry>
<entry>operand data</entry>
</row>
<row>
<entry>Q2:</entry>
<entry>fetch operand</entry>
</row>
<row>
<entry>Q3:</entry>
<entry>execute function specified by instruction and calculate destination</entry>
</row>
<row>
<entry></entry>
<entry>address for data</entry>
</row>
<row>
<entry>Q4:</entry>
<entry>write result to destination</entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The following sequence of events may comprise, for example, the execute instruction cycle for a dual operand instruction using a data pre-fetch mechanism. These instructions pre-fetch the dual operands simultaneously from the X and Y data memories and store them into registers specified in the instruction. They simultaneously allow instruction execution on the operands fetched during the previous cycle.  
<table-cwu id="TABLE-US-00003">
<number>3</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="21PT" align="right"/>
<colspec colname="2" colwidth="196PT" align="left"/>
<thead>
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry>Q1:</entry>
<entry>latch instruction into IR, decode, and determine addresses of</entry>
</row>
<row>
<entry></entry>
<entry>operand data</entry>
</row>
<row>
<entry>Q2:</entry>
<entry>pre-fetch operands into specified registers, execute operation in</entry>
</row>
<row>
<entry></entry>
<entry>instruction</entry>
</row>
<row>
<entry>Q3:</entry>
<entry>execute operation in instruction, calculate destination address for</entry>
</row>
<row>
<entry></entry>
<entry>data</entry>
</row>
<row>
<entry>Q4:</entry>
<entry>complete execution, write result to destination</entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> An exemplary memory map of data space memory <highlight><bold>300</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. Data space memory <highlight><bold>300</bold></highlight> includes a plurality of blocks of memory, divided into X address memory and Y address memory. Typically, data space memory <highlight><bold>300</bold></highlight> is implemented as random access read-write memory (RAM), so as to allow data to be read and written as necessary. However, read-only memory (ROM) may also be advantageously used for at least a portion of data space memory <highlight><bold>300</bold></highlight>. For example, constant data values, look up tables, etc., may be usefully stored in ROM. In the example shown in <cross-reference target="DRAWINGS">FIG. 3, X</cross-reference> address memory includes memory blocks <highlight><bold>302</bold></highlight>, <highlight><bold>304</bold></highlight>, <highlight><bold>306</bold></highlight>, and <highlight><bold>308</bold></highlight>, while Y address memory includes memory block <highlight><bold>310</bold></highlight>. Data space memory <highlight><bold>300</bold></highlight> is split into two blocks, X address memory and Y address memory. A key element of this architecture is that the Y address memory space is a subset of the X address memory space, and is fully contained within the X address memory space. In order to provide an apparent linear addressing space, the X and Y address memory spaces would typically have contiguous addresses, although this is not an architectural necessity. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> In the example shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, memory block <highlight><bold>302</bold></highlight> includes a block of contiguous memory, starting at data memory location 0&times;0000. Memory block <highlight><bold>302</bold></highlight> is reserved in X address memory space and is directly addressable using memory direct instructions. The remaining X address memory and Y address memory spaces are indirectly addressable using other instructions. In the example shown in <cross-reference target="DRAWINGS">FIG. 3, Y</cross-reference> address memory space <highlight><bold>310</bold></highlight> is located between two blocks of X address memory space, block <highlight><bold>304</bold></highlight> and <highlight><bold>306</bold></highlight>. However, this is only an example, as the Y address memory space <highlight><bold>310</bold></highlight> may be located anywhere within the non-reserved X address memory space. The partition between the X and Y address spaces is arbitrary and is determined by the memory decode shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Both the X and Y address generator can generate any effective address (EA) within the range of data memory space <highlight><bold>300</bold></highlight>. However, accesses to memory addresses that are in the other address space, or to memory addresses that are not implemented with physical memory will return data of 0&times;0000 (all zeros). </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Memory block <highlight><bold>308</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> as being an X address memory block. Memory block <highlight><bold>308</bold></highlight>, which includes at least a portion of data memory space <highlight><bold>300</bold></highlight>, may be used as X address memory, Y address memory, or a mixture of X address memory and Y address memory. When used as X address memory, memory block <highlight><bold>308</bold></highlight> may be mapped into program memory space. This provides transparent access to constant data, such as stored constants, look up tables, etc., from the X address data memory space without the need to use special instructions. This feature allows the mapping of a portion of data memory space into an unused area of program memory, and since all unused internal addresses are mapped externally, to the external memory bus. This is shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, which is an exemplary block diagram of the program memory space to data memory space mapping. Data memory space block <highlight><bold>308</bold></highlight>, which is a portion of data memory space <highlight><bold>300</bold></highlight> is mapped to a data memory space page <highlight><bold>402</bold></highlight> in internal program memory space <highlight><bold>404</bold></highlight>. The location of data memory space page <highlight><bold>402</bold></highlight> in internal program memory space <highlight><bold>404</bold></highlight> is specified by page register <highlight><bold>406</bold></highlight>. Internal program memory space <highlight><bold>404</bold></highlight> is still used for program instruction access, as specified by program counter (PC) <highlight><bold>408</bold></highlight>. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> External memory device <highlight><bold>410</bold></highlight> is connected to the external memory bus <highlight><bold>412</bold></highlight> of the processor. External memory device <highlight><bold>410</bold></highlight> includes external program/data memory space <highlight><bold>414</bold></highlight>. Since all unused internal addresses are mapped externally to the external memory bus, data memory space mapped page <highlight><bold>402</bold></highlight> is also mapped to external data memory space mapped page <highlight><bold>416</bold></highlight>, which is located in external program/data memory space <highlight><bold>412</bold></highlight>. If external memory device <highlight><bold>410</bold></highlight> is a RAM, then data may be read from and written to external data memory space mapped page <highlight><bold>416</bold></highlight>. External program/data space <highlight><bold>414</bold></highlight> may also include external program memory space <highlight><bold>418</bold></highlight>, which may be separate from external data memory space mapped page <highlight><bold>416</bold></highlight>, or which may overlap with external data memory space mapped page <highlight><bold>416</bold></highlight>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Since the program memory space may include data that is used when a portion of the program memory space is mapped to the data memory space, there is some danger that the processor will erroneously fetch and attempt to execute that data. This may happen, for example, when there is a bug in a software program that is executing on the processor that sets the program counter (PC) to a memory location in the program memory space that happens to be storing data. This problem can arise when data is stored in internal program memory space and is even more likely to arise when data is stored in an external memory device. The present invention includes a mechanism for detecting such erroneous accesses and provides the capability to handle such errors. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> A block diagram of the data execution protection scheme of the present invention is shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. Data memory space <highlight><bold>502</bold></highlight>, including a plurality of data entries <highlight><bold>504</bold></highlight>, is mapped from a data memory block portion <highlight><bold>506</bold></highlight> of program memory space <highlight><bold>508</bold></highlight>. Program memory space <highlight><bold>508</bold></highlight> also includes one or more blocks of program instructions, such as program instruction blocks <highlight><bold>510</bold></highlight> and <highlight><bold>512</bold></highlight>. As shown, each data entry, such as data entry <highlight><bold>514</bold></highlight>, in data memory space <highlight><bold>502</bold></highlight> includes 16 bits of data. Each program instruction entry, such as program instruction entry <highlight><bold>516</bold></highlight>, in program memory space <highlight><bold>508</bold></highlight> includes 24 bits of program instruction. The entries in data memory block <highlight><bold>506</bold></highlight> of program memory space <highlight><bold>508</bold></highlight>, such as entry <highlight><bold>518</bold></highlight>, are likewise 24 bits. Since a data entry only requires 16 bits, such as data portion <highlight><bold>520</bold></highlight> of entry <highlight><bold>518</bold></highlight>, 8 bits of each entry in data memory block <highlight><bold>506</bold></highlight> are not used by data and may be used for other functions. In the present invention, this other portion is used to contain a protection opcode <highlight><bold>522</bold></highlight>, which allows erroneous execution of a data entry to be detected. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> A process <highlight><bold>600</bold></highlight> for detection and handling of erroneous execution of a data entry is shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. The process begins with step <highlight><bold>602</bold></highlight>, in which data is stored to the data memory space that was mapped from program memory space. This data is stored to the lower 16 bits of each entry that is used. In addition to the data that is stored, a protection opcode is stored to the upper 8 bits (byte) of each data entry that is used. Typically, the protection opcode will be stored when the data entry is stored. For example, since program memory is typically implemented using non-volatile memory, the program instructions stored in the program memory are stored to the program memory during the production process. The protection opcodes may easily be stored to the program memory by this step in the production process. This is true both for internal program memory and for non-volatile external memory. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In step <highlight><bold>604</bold></highlight>, program memory space is mapped to data memory space by issuance of the proper program instructions. In step <highlight><bold>606</bold></highlight>, the processor erroneously fetches and attempts to execute data that was stored in an entry in data memory space that was mapped from program memory space. Since the processor is fetching a program instruction, the processor treats the entry as a program instruction entry and fetches the entire 24 bits of the entry. The upper 8 bits of the entry are the protection opcode, while the lower 16 bits are the data in the entry. The processor attempts to execute the fetched entry, and in particular attempts to decode the protection opcode. In step <highlight><bold>608</bold></highlight>, this attempted decode of the protection opcode causes a processor trap to occur. A trap can be considered to be a non-maskable, nestable interrupt. They provide a means by which erroneous operation can be corrected during software debug and during operation of the software. Upon occurrence of a trap, the execution flow of the processor is vectored to a trap handler in step <highlight><bold>610</bold></highlight>. That is, the program counter of the processor is loaded with a value that points to the trap handler. The trap handler is a software routine that takes the appropriate corrective action upon occurrence of the trapped condition. The value is stored in an exception vector table that includes vectors for a variety of exception conditions, such as reset, stack overflow, address error, illegal instruction trap, arithmetic error, etc. Each entry in the exception vector table points to an exception handler that takes the appropriate action upon occurrence of the corresponding exception. In step <highlight><bold>612</bold></highlight>, the trap handler deals with the error. Typically, the trap handler simply forces a reset of the processor. This would be done, for example, in an implementation in which a stand-alone application is executing in the processor. Since an attempt to execute a data entry is likely a result of a serious program error, performing a reset of the processor is often the best way of recovering from such an error. In an implementation in which there is an operating system controlling the processor, it may be possible to simply terminate the application program that caused the error and allow the operating system to recover from the error. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> In a preferred embodiment, the illegal instruction trap vector is used to vector the processor to a routine that handles the attempted execution of a protection opcode. The protection opcode must be one of the possible 8 bit opcodes that is not used by any instruction of the processor. Attempted execution of this opcode will result in an illegal instruction trap. The illegal instruction trap handler must then examine the opcode that caused the illegal instruction trap, determine that the opcode is the protection opcode, and execute the appropriate software routines to handle the trap, which typically includes recovering from the error condition. Alternatively, there may be a defined protection trap that is separate from the illegal instruction trap. Attempted execution of the protection opcode will cause a protection trap to occur, rather than a general illegal instruction trap. Since the processor will have already determined the opcode that was attempted to be executed was the protection opcode, the protection trap then need only execute the appropriate software routines to handle the error condition. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> In the embodiment described above, internal program memory is organized as a plurality of 24 bit entries, each of which may contain a 16 bit data entry and an 8 bit protection opcode. The present invention also contemplates a number of additional and alternative embodiments. For example, an external memory may be used in which 24 bit entries are stored. In this embodiment, a 24 bit entry may contain a 16 bit data entry and an 8 bit protection opcode. If the external memory is a non-volatile memory, then the data entries and protection opcodes, along with any program instructions, may be stored in the external memory during the production process. If the external memory is a volatile memory, then the data entries and the protection opcodes must be stored to the external memory by the processor. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> Alternatively, data entries may be stored in the external memory as 16 bit data entries, without protection opcodes. In this embodiment, the external memory may be connected to the processor using a memory bus configuration that is aware that the data entries are 16 bits. For example, the memory bus connected to the external memory may be 16 bits wide, rather than the 24 bits wide that would be needed for program instructions. As another example, the address range of the external memory that is mapped to data memory may be used by the processor to identify a portion of the external memory that is storing data entries rather than program entries. In either example, the processor can detect an attempted program instruction access of the external memory or the portion of external memory that is storing data entries. Upon detection of such an attempted access, the processor may directly perform a protection trap. Alternatively, the processor may simply force a protection opcode onto the top 8 bits of the program instruction bus, which will also cause a protection trap to be performed. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> While specific embodiments of the present invention have been illustrated and described, it will be understood by those having ordinary skill in the art that changes may be made to those embodiments without departing from the spirit and scope of the invention. For example, the present invention has been described in terms of 16 bit data entries, 24 bit program instruction entries, and 8 bit opcodes. However, one of skill in the art will recognize that such specific values are only examples, and that other arrangements and numbers of bits may be used without departing from the spirit and scope of the invention. The present invention contemplates any and all such alternative arrangements and numbers of bits. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of operating a processor comprising the steps of: 
<claim-text>mapping at least a portion of a program memory space to a data memory space; </claim-text>
<claim-text>storing an entry into the program memory space that is mapped to the data memory space, the entry comprising data and a protection opcode; </claim-text>
<claim-text>fetching an entry from the program memory space; </claim-text>
<claim-text>attempting to execute the fetched entry; </claim-text>
<claim-text>trapping the protection opcode; </claim-text>
<claim-text>vectoring to a trap handler; and </claim-text>
<claim-text>executing the trap handler. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the trap handler is an illegal instruction trap handler and the step of executing the trap handler comprises the steps of: 
<claim-text>determining that the opcode is a protection opcode; and </claim-text>
<claim-text>executing a software routine to handle the trap. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the program memory space is internal to the processor. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein the processor is operably connected to an external memory device operable to store program instructions and data, the external memory device comprising program memory space. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the trap handler is a protection trap handler. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein the program memory space is internal to the processor. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein the processor is operably connected to an external memory device operable to store program instructions and data, the external memory device comprising program memory space. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A processor comprising circuitry operable to: 
<claim-text>map at least a portion of a program memory space to a data memory space; </claim-text>
<claim-text>store an entry into the program memory space that is mapped to the data memory space, the entry comprising data and a protection opcode; </claim-text>
<claim-text>fetch an entry from the program memory space; </claim-text>
<claim-text>attempt to execute the fetched entry; </claim-text>
<claim-text>trap the protection opcode; </claim-text>
<claim-text>vector to a trap handler; and </claim-text>
<claim-text>execute the trap handler. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The processor of <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein the trap handler is an illegal instruction trap handler and the execution of the trap handler comprises: 
<claim-text>determining that the opcode is a protection opcode; and </claim-text>
<claim-text>executing a software routine to handle the trap. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The processor of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein the program memory space is internal to the processor. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The processor of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the processor is operably connected to an external memory device operable to store program instructions and data, the external memory device comprising program memory space. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The processor of <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein the trap handler is a protection trap handler. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The processor of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein the program memory space is internal to the processor. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The processor of <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the processor is operably connected to an external memory device operable to store program instructions and data, the external memory device comprising program memory space.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005245A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005245A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005245A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005245A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005245A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005245A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030005245A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
