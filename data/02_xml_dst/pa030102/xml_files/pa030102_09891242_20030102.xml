<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004727A1-20030102-D00000.TIF SYSTEM "US20030004727A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00001.TIF SYSTEM "US20030004727A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00002.TIF SYSTEM "US20030004727A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00003.TIF SYSTEM "US20030004727A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00004.TIF SYSTEM "US20030004727A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00005.TIF SYSTEM "US20030004727A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00006.TIF SYSTEM "US20030004727A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00007.TIF SYSTEM "US20030004727A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00008.TIF SYSTEM "US20030004727A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00009.TIF SYSTEM "US20030004727A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00010.TIF SYSTEM "US20030004727A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030004727A1-20030102-D00011.TIF SYSTEM "US20030004727A1-20030102-D00011.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004727</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09891242</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010627</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G10L021/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>704</class>
<subclass>275000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Control apparatus</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Robert</given-name>
<middle-name>Alexander</middle-name>
<family-name>Keiller</family-name>
</name>
<residence>
<residence-non-us>
<city>Guildford</city>
<country-code>GB</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>FITZPATRICK CELLA HARPER &amp; SCINTO</name-1>
<name-2></name-2>
<address>
<address-1>30 ROCKEFELLER PLAZA</address-1>
<city>NEW YORK</city>
<state>NY</state>
<postalcode>10112</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A control apparatus (<highlight><bold>34</bold></highlight>) is provided for enabling a user to control by spoken commands a function of a processor-controlled machine (<highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>) couplable to speech processing apparatus. The control apparatus is configured to provide: </paragraph>
<paragraph id="A-0002" lvl="2">a client module (<highlight><bold>343</bold></highlight>) for receiving dialog interpretable instructions derived from speech data processed by the speech processing apparatus; </paragraph>
<paragraph id="A-0003" lvl="2">a dialog communication arrangement (<highlight><bold>340,342</bold></highlight><highlight><italic>a</italic></highlight><highlight><bold>, 340</bold></highlight>) for interpreting received dialog interpretable instructions using a dialog compatible with the processor-controlled machine (<highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>) and for communicating with the processor-controlled machine (<highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>) using the dialog to enable information to be provided to the user in response to received dialog interpretable instructions, thereby enabling a dialog to be conducted with the user; </paragraph>
<paragraph id="A-0004" lvl="2">a dialog determiner (<highlight><bold>342</bold></highlight>) for determining from information provided by the processor-controlled machine (<highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>) the dialog to be used with that processor-controlled machine; and </paragraph>
<paragraph id="A-0005" lvl="2">a machine communicator (<highlight><bold>341</bold></highlight>) communicating with the processor-controlled machine to cause the processor-controlled machine to carry out a function in accordance with the dialog with the user. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This invention relates to a control apparatus, in particular to a control apparatus that enables voice control of machines or devices using an automatic speech recognition engine accessible by the devices for example accessible over a network. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> In conventional network systems, such as office equipment network systems, instructions for controlling the operation of a machine or device connected to the network are generally input manually, for example using a control panel of the device. Voice control of machines or devices may, at least in some circumstances, be more acceptable or convenient for a user. It is, however, not cost-effective to provide each different machine or device with its own automatic speech recognition engine. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> It is an aim of the present invention to provide a control apparatus that enables voice control of devices or machines using a speech processing apparatus not forming part of the device or machine and that does not require the supplier of a device or machine to be networked to be familiar with any aspects of the voice control arrangement. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> In one aspect, the present invention provides a control apparatus for enabling voice control of a function of a processor-controlled machine using speech recognition means provided independently of the processor-controlled machine wherein the control apparatus is arranged to retrieve information and/or data identifying the functionality of the machine (or information and/or data identifying a location from which that information and/or data can be retrieved) from the machine so that the control apparatus can be developed independently of the machine and does not need to know the functionality of the machine before being coupled to the machine. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In another aspect, the present invention provides a control apparatus for coupling to a processor-controlled machine so as to enable the machine to be voice-controlled using independent speech recognition means, wherein the control apparatus is arranged to retrieve from the machine information identifying a dialog file or information identifying the location of a dialog file to be used by the control apparatus in controlling a dialog with a user. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> A control apparatus in accordance with either of the above aspects should enable any processor-controlled machine that may be coupled to a network to be provided with voice control capability and, because the control apparatus does not need to know about the functionality of the machine, the control apparatus can be produced completely independently of the processor-controlled machines. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Preferably, the control apparatus comprises a JAVA virtual machine which is arranged to determine the processor-controlled device functionality using the JAVA introspection/reflection API. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The control apparatus may be provided by a separate networkable device that is coupled, in use, to a different location on a network from either the speech recognition means or the processor-controlled machine. This has the advantage that only a single control apparatus need be provided. As another possibility, the control apparatus may be provided as part of speech processing apparatus incorporating the speech recognition means which again has the advantage that only a single control apparatus is required and has the additional advantage that communication between the speech recognition means and the control apparatus does not have to occur over the network. As another possibility, each processor-controlled machine may be provided with its own control apparatus. This has the advantage that communication between the processor-controlled machine and the control apparatus does not have to occur over the network and enables voice control of more than one machine at a time provided that this can be handled by the network and the speech processing apparatus, but at the increased cost of providing more than one control apparatus. Of course, even where the control apparatus is provided separately from the processor-controlled machine, the control apparatus may be configured so as to enable voice control of more than one machine. Thus, for example, where the control apparatus comprises a JAVA virtual machine, then the control apparatus may be configured to provide two or more JAVA virtual machines each accessible by a processor-controlled machine coupled to the network. As another possibility, a network may be conceived where some of the processor-controlled machines coupled to the network have their own control apparatus while other processor-controlled machines coupled to the network use a separate control apparatus located on the network. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> As another possibility, the control apparatus may be arranged so as that it can be moved from place to place. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The processor-controlled machine may be, for example, an item of office equipment such as a photocopier, printer, facsimile machine or multi-function machine capable of facsimile, photocopy and printing functions and/or may be an item of home equipment such as a domestic appliance such as a television, a video cassette recorder, a microwave oven and so on.</paragraph>
</summary-of-invention>
<brief-description-of-drawings>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> Embodiments of the present invention will now be described, by way of example, with reference to the accompanying drawings, in which: </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a schematic block diagram of a system embodying the present invention; </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a schematic block diagram of speech processing apparatus for a network system: </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a schematic block diagram to illustrate a typical processor-controlled machine and its connection to a control apparatus and an audio device; </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a flow chart for illustrating steps carried out by the control apparatus shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows a flow chart for illustrating steps carried out by the control apparatus when a user uses voice-control to instruct a processor-controlled machine to carry out a job or function; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows a flow chart illustrating in greater detail a step shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> shows a flow chart illustrating steps carried out by speech processing apparatus shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> to enable a voice-controlled job to be carried out by a processor-controlled machine; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 8 and 9</cross-reference> show block diagrams similar to <cross-reference target="DRAWINGS">FIG. 1</cross-reference> of other examples of network systems embodying the present invention; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> shows diagrammatically a user issuing instructions to a machine coupled in the system shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> or <highlight><bold>9</bold></highlight>; and </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> shows a block diagram similar to <cross-reference target="DRAWINGS">FIG. 1</cross-reference> of another example of a system embodying the present invention. </paragraph>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows by way of a block diagram a system <highlight><bold>1</bold></highlight> comprising a speech processing apparatus or server <highlight><bold>2</bold></highlight> coupled to a number of clients <highlight><bold>3</bold></highlight> and to a look-up service <highlight><bold>4</bold></highlight> via a network N. As shown for one client in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, each client <highlight><bold>3</bold></highlight> comprises a processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>, an audio device <highlight><bold>5</bold></highlight> and a control apparatus <highlight><bold>34</bold></highlight>. The control apparatus <highlight><bold>34</bold></highlight> couples the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to the network N. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> The machines are in the form of items of electrical equipment found in the office and/or home environment and capable of being adapted for communication and/or control over a network N. Examples of items of office equipment are, for example, photocopiers, printers, facsimile machines, digital cameras and multi-functional machines capable of copying, printing and facsimile functions while examples of items of home equipment are video cassette recorders, televisions, microwave ovens, digital cameras, lighting and heating systems and so on. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The clients <highlight><bold>3</bold></highlight> may all be located in the same building or may be located in different buildings. The network N may be a local area Network (LAN), wide area network (WAN), an Intranet or the Internet. It will, of course, be understood that, as used herein the word &ldquo;network&rdquo; does not necessarily imply the use of any known or standard networking system or protocol and that the network N may be any arrangement that enables communication with items of equipment or machines located in different parts of the same building or in different buildings. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> The speech processing apparatus <highlight><bold>2</bold></highlight> comprises a computer system such as a workstation or the like. <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a functional block diagram of the speech processing apparatus <highlight><bold>2</bold></highlight>. The speech processing apparatus <highlight><bold>2</bold></highlight> has a main processor unit <highlight><bold>20</bold></highlight> which, as is known in the art, includes a processor arrangement (CPU) and memory such as RAM, ROM and generally also a hard disk drive. The speech processing apparatus <highlight><bold>2</bold></highlight> also has, as shown, a removable disk drive RDD <highlight><bold>21</bold></highlight> for receiving a removable storage medium RD such as, for example, a CDROM or floppy disk, a display <highlight><bold>22</bold></highlight> and an input device <highlight><bold>23</bold></highlight> such as, for example, a keyboard and/or a pointing device such as a mouse. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Program instructions for controlling operation of the CPU and data are supplied to the main processor unit <highlight><bold>20</bold></highlight> in at least one of two ways: </paragraph>
<paragraph id="P-0027" lvl="2"><number>&lsqb;0027&rsqb;</number> 1) as a signal over the network N; and </paragraph>
<paragraph id="P-0028" lvl="2"><number>&lsqb;0028&rsqb;</number> 2) carried by a removable data storage medium RD. Program instructions and data will be stored on the hard disk drive of the main processor unit <highlight><bold>20</bold></highlight> in known manner. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates block schematically the main functional components of the main processor unit <highlight><bold>20</bold></highlight> of the speech processing apparatus <highlight><bold>2</bold></highlight> when programmed by the aforementioned program instructions. Thus, the main processor unit <highlight><bold>20</bold></highlight> is programmed so as to provide: an automatic speech recognition (ASR) engine <highlight><bold>201</bold></highlight> for recognising speech data input to the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N from the control apparatus <highlight><bold>34</bold></highlight> of any of the clients <highlight><bold>3</bold></highlight>; a grammar module <highlight><bold>202</bold></highlight> for storing grammars defining the rules that spoken commands must comply with and words that may be used in spoken commands; and a speech interpreter module <highlight><bold>203</bold></highlight> for interpreting speech data recognised using the ASR engine <highlight><bold>201</bold></highlight> to provide instructions that can be interpreted by the control apparatus <highlight><bold>34</bold></highlight> to cause the associated processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to carry out the function required by the user. The main processor unit <highlight><bold>20</bold></highlight> also includes a connection manager <highlight><bold>204</bold></highlight> for controlling overall operation of the main processor unit <highlight><bold>20</bold></highlight> and communicating via the network N with the control apparatus <highlight><bold>34</bold></highlight> so as to receive audio data and to supply instructions that can be interpreted by the control apparatus <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> As will be appreciated by those skilled in the art, any known form of automatic speech recognition engine <highlight><bold>201</bold></highlight> may be used. Examples are the speech recognition engines produced by Nuance, Lernout and Hauspie, by IBM under the Trade Name &ldquo;ViaVoice&rdquo; and by Dragon Systems Inc. under the Trade Name &ldquo;Dragon Naturally Speaking&rdquo;. As will be understood by those skilled in the art, communication with the automatic speech recognition engine is via a standard software interface known as &ldquo;SAPI&rdquo; (speech application programmers interface) to ensure compatibility with the remainder of the system. In this case, the Microsoft SAPI is used. The grammars stored in the grammar module may initially be in the SAPI grammar format. Alternatively, the server <highlight><bold>2</bold></highlight> may include a grammar pre-processor for converting grammars in a non-standard form to the SAPI grammar format. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a block schematic diagram of a client <highlight><bold>3</bold></highlight>. The processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>comprises a device operating system module <highlight><bold>30</bold></highlight> that generally includes CPU and memory (such as ROM and/or RAM). The operating system module <highlight><bold>30</bold></highlight> communicates with machine control circuitry <highlight><bold>31</bold></highlight> that, under the control of the operating system module <highlight><bold>30</bold></highlight>, causes the functions required by the user to be carried out. The device operating system module <highlight><bold>30</bold></highlight> also communicates, via an appropriate interface <highlight><bold>35</bold></highlight>, with the control apparatus <highlight><bold>34</bold></highlight>. The machine control circuitry <highlight><bold>31</bold></highlight> will correspond to that of a conventional machine of the same type capable of carrying out the same function or functions (for example photocopying functions in the case of a photocopier) and so will not be described in any greater detail herein. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The device operating system module <highlight><bold>30</bold></highlight> also communicates with a user interface <highlight><bold>32</bold></highlight> that, in this example, includes a display for displaying messages and/or information to a user and a control panel for enabling manual input of instructions by the user. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The device operating system module <highlight><bold>30</bold></highlight> may also communicate with an instruction interface <highlight><bold>33</bold></highlight> that, for example, may include a removable disk drive and/or a network connection for enabling program instructions and/or data to be supplied to the device operating system module <highlight><bold>30</bold></highlight> either initially or as an update of the original program instructions and/or data. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> In this embodiment, the control apparatus <highlight><bold>34</bold></highlight> of a client <highlight><bold>3</bold></highlight> is a JAVA virtual machine <highlight><bold>34</bold></highlight>. The JAVA virtual machine <highlight><bold>34</bold></highlight> comprises processor capability and memory (RAM and/or ROM and possibly also hard disk capacity) storing program instructions and data for configuring the virtual machine <highlight><bold>34</bold></highlight> to have the functional elements shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. The program instructions and data may be prestored in the memory or may be supplied as a signal over the network N or may be provided on a removable storage medium receivable in a removable disc disc drive associated with the JAVA virtual machine or, indeed, supplied via the network N from a removable storage medium in the removable disc disc drive <highlight><bold>21</bold></highlight> of the speech processing apparatus. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> The functional elements of the JAVA virtual machine include a dialog manager <highlight><bold>340</bold></highlight> which co-ordinates the operation of the other functional elements of the JAVA virtual machine <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The dialog manager <highlight><bold>340</bold></highlight> communicates with the device operating system module <highlight><bold>30</bold></highlight> via the interface <highlight><bold>35</bold></highlight> and a device interface <highlight><bold>341</bold></highlight> of the control apparatus which has a JAVA device class obtained by the JAVA virtual machine from information provided by the device operating system module <highlight><bold>30</bold></highlight>. Thus the device operating system module <highlight><bold>30</bold></highlight> may store the actual JAVA device class for that processor-controlled machine or may store information that enables the JAVA virtual machine <highlight><bold>34</bold></highlight> to access the device class via the network N. The device interface <highlight><bold>341</bold></highlight> enables instructions to be sent to the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and details of device and job events to be received. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> In order to enable an operation or job to be carried out under voice control by a user, as will be described in greater detail below, the dialog manager <highlight><bold>340</bold></highlight> communicates with a script interpreter <highlight><bold>347</bold></highlight> and with a dialog interpreter <highlight><bold>342</bold></highlight> which uses a dialog file or files from a dialog file store <highlight><bold>342</bold></highlight> to enable a dialog to be conducted with the user via the device interface <highlight><bold>341</bold></highlight> and the user interface <highlight><bold>32</bold></highlight> in response to dialog interpretable instructions received from the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> In this example, dialog files are implemented in VoiceXML which is based on the World Wide Web Consortiums Industry Standard Extensible Markup Language (XML) and which provides a high-level programming interface to speech and telephony resources. VoiceXML is promoted by the VoiceXML Forum founded by AT&amp;T, IBM, Lucent Technologies and Motorola and the specification for version 1.0 of VoiceXML can be found at http://www.voicexml.org. Other voice adapted markup languages may be used such as, for example, VoxML which is Motorola&apos;s XML based language for specifying spoken dialog. There are many text books available concerning XML see for example &ldquo;XML Unleashed&rdquo; published by SAMS Publishing (ISBN 0-672-31514-9) which includes a chapter 20 on XML scripting languages and a chapter 40 on VoxML. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> In this example, the script interpreter <highlight><bold>347</bold></highlight> is an ECMAScript interpreter (where ECMA stands for European Computer Manufacturer&apos;s Association and ECMAScript is a non-proprietary standardised version of Netscape&apos;s JAVAScript and Microsoft&apos;s JScript). A CD-ROM and printed copies of the current ECMA-290 ECMAScript components specification can be obtained from ECMA <highlight><bold>114</bold></highlight> Rue du Rhone CH-1204, Geneva, Switzerland. A free interpreter for ECMAScript is available from http://home.worldcom.ch/jmlugrin/fesi. As another possibility the dialog manager <highlight><bold>340</bold></highlight> may be run as an applet inside a web browser such as Internet Explorer 5 enabling use of the browser&apos;s own ECMAScript Interpreter. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The dialog manager <highlight><bold>340</bold></highlight> also communicates with a client module <highlight><bold>343</bold></highlight> which communicates with the dialog manager <highlight><bold>340</bold></highlight>, with an audio module <highlight><bold>344</bold></highlight> coupled to the audio device <highlight><bold>5</bold></highlight> and with a server module <highlight><bold>345</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The audio device <highlight><bold>5</bold></highlight> may be a microphone provided as an integral component or add on to the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>or may be a separately provided audio input system. For example, the audio device <highlight><bold>5</bold></highlight> may represent a connection to a separate telephone system such as a DECT telephone system or may simply consist of a separate microphone input. The audio module <highlight><bold>344</bold></highlight> for handling the audio input uses, in this example, the JavaSound 0.9 audio control system. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The server module <highlight><bold>345</bold></highlight> handles the protocols for sending messages between the client <highlight><bold>3</bold></highlight> and the speech processing apparatus or server <highlight><bold>2</bold></highlight> over the network N thus separating the communication protocols from the main client code of the virtual machine <highlight><bold>34</bold></highlight> so that the network protocol can be changed by the speech processing apparatus <highlight><bold>2</bold></highlight> without the need to change the remainder of the JAVA virtual machine <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The client module <highlight><bold>343</bold></highlight> provides, via the server module <highlight><bold>345</bold></highlight>, communication with the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N, enabling requests from the client <highlight><bold>3</bold></highlight> and audio data to be transmitted to the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N and enabling communications and dialog interpretable instructions provided by the speech processing apparatus <highlight><bold>2</bold></highlight> to be communicated to the dialog manager <highlight><bold>340</bold></highlight>. The dialog manager <highlight><bold>340</bold></highlight> also communicates over the network N via a look-up service module <highlight><bold>346</bold></highlight> that enables dialogs run by the virtual machine <highlight><bold>34</bold></highlight> to locate services provided on the network N using the look-up service <highlight><bold>4</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. In this example, the look-up service is a JINI service and the look-up service module <highlight><bold>346</bold></highlight> provides a class which stores registrars so that JINI enabled services available on the network N can be discovered quickly. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> As will be seen from the above, the dialog manager <highlight><bold>340</bold></highlight> forms the central part of the virtual machine <highlight><bold>34</bold></highlight>. Thus, the dialog manager <highlight><bold>340</bold></highlight>: receives input and output requests from the dialog interpreter <highlight><bold>342</bold></highlight>; passes output requests to the client module <highlight><bold>343</bold></highlight>; receives recognition results (dialog interpretable instructions) from the client module <highlight><bold>343</bold></highlight>; and interfaces to the machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>, via the device interface <highlight><bold>341</bold></highlight>, both sending instructions to the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and receiving event data from the machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>. As will be seen, audio communication is handled via the client module <highlight><bold>343</bold></highlight> and is thus separated from the dialog manager <highlight><bold>340</bold></highlight>. This has the advantage that dialog communication with the device operating system module <highlight><bold>30</bold></highlight> can be carried out without having to use spoken commands, if the network connection fails or is unavailable. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> The device interface <highlight><bold>341</bold></highlight> consists, in this example, of a JAVA class that implements the methods defined by DeviceInterface for enabling the dialog manager <highlight><bold>340</bold></highlight> to locate and retrieve the dialog file to be used with the device, to register a device listener which receives notifications of events set by the machine control circuitry <highlight><bold>31</bold></highlight> and to enable the virtual machine <highlight><bold>34</bold></highlight> to determine when a particular event has occurred. As mentioned above, this JAVA class is obtained by the JAVA virtual machine from (or from information provided by) the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>when the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>is coupled to the control apparatus. In this example, the program DeviceInterface contains three public methods: </paragraph>
<paragraph id="P-0046" lvl="2"><number>&lsqb;0046&rsqb;</number> 1) public String getDialogFile( ); </paragraph>
<paragraph id="P-0047" lvl="3"><number>&lsqb;0047&rsqb;</number> which returns a string identifying the location of the requisite dialog file. The string may be a uniform resource identifier (URI) identifying a resource on the Internet (see for example www.w3.org/addressing) for example a uniform resource locator (URL) representing the address of a file accessible on the Internet or a uniform resource name (URN) for enabling the speech processing apparatus <highlight><bold>2</bold></highlight> to access and retrieve the dialog file and then supply it to the JAVA virtual machine; </paragraph>
<paragraph id="P-0048" lvl="2"><number>&lsqb;0048&rsqb;</number> 2) public void registerDeviceListener (DeviceListener dl); </paragraph>
<paragraph id="P-0049" lvl="3"><number>&lsqb;0049&rsqb;</number> which allows the dialog to register a listener which receives notifications of events set by the machine control circuitry <highlight><bold>31</bold></highlight> such as, for example, when the device runs out of paper or toner, in the case of a multi-function device or photocopier; </paragraph>
<paragraph id="P-0050" lvl="2"><number>&lsqb;0050&rsqb;</number> 3) public boolean eventSet(String event); </paragraph>
<paragraph id="P-0051" lvl="3"><number>&lsqb;0051&rsqb;</number> which allows the dialog to discover whether an event has occurred on the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>such as the presence of a document in the hopper of a facsimile device, photocopier or multifunction device. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> In addition to these methods, the device class may implement any number of device specific methods including public methods which return Devicejob which is a wrapper around jobs such as printing or sending a fax. This provides the client module <highlight><bold>343</bold></highlight> with the ability to control and monitor the progress of the job. Devicejob contains the following methods: </paragraph>
<paragraph id="P-0053" lvl="2"><number>&lsqb;0053&rsqb;</number> public void addListener (JobListener jl); </paragraph>
<paragraph id="P-0054" lvl="2"><number>&lsqb;0054&rsqb;</number> which allows the client module <highlight><bold>343</bold></highlight> to supply to the job a listener which receives events that indicate the progress of the job. </paragraph>
<paragraph id="P-0055" lvl="2"><number>&lsqb;0055&rsqb;</number> public String run( ); </paragraph>
<paragraph id="P-0056" lvl="2"><number>&lsqb;0056&rsqb;</number> which starts a job with a return string being passed back to the dialog as an event; and </paragraph>
<paragraph id="P-0057" lvl="2"><number>&lsqb;0057&rsqb;</number> public void Stop( ); </paragraph>
<paragraph id="P-0058" lvl="2"><number>&lsqb;0058&rsqb;</number> which allows the client module <highlight><bold>343</bold></highlight> to stop the job. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> The JAVA introspection or reflection API is used by the dialog manager <highlight><bold>340</bold></highlight> to determine what methods the device class implements and to create a JAVA script object with those properties. The fact that device class is obtained from (or from information provided by) the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to which the JAVA virtual machine <highlight><bold>34</bold></highlight> is coupled and the use of the reflection API enables the JAVA virtual machine to be designed without any knowledge of the functions available on the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>of which the JAVA virtual machine <highlight><bold>34</bold></highlight> forms a part. This means that it should be necessary to design only a single JAVA machine for most, if not all, types of processor-controlled machine. This is achieved in the dialog manager <highlight><bold>340</bold></highlight> by representing the device class as an ECMAScript object in the scripting environment of the ECMAScript interpreter <highlight><bold>347</bold></highlight>. The processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>can then be controlled by the use of Voice XML script elements. The representation of the device class as an ECMAScript object is such that invoking functions of the ECMAScript object cause methods of the same name to be executed on the device class using the JAVA reflection API. As will be understood by the person skilled in the art, invoking JAVA code from ECMAScript is done by using the ECMAScript interpreter&apos;s JAVA API or, in the case of a web browser, by using applet methods. When a method of the device class returns DeviceInterface the returned object is also represented as an ECMAScript object in the scripting environment of the ECMAScript interpreter <highlight><bold>347</bold></highlight> and the registerDeviceListener method is invoked on the object. When a method of the device class returns DeviceJob the addListener and run methods of the returned DeviceJob object are invoked. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a flow chart illustrating the steps carried out by the dialog manager <highlight><bold>340</bold></highlight> when a machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>is first coupled to the network N via the JAVA machine <highlight><bold>34</bold></highlight>. Thus, at step S<highlight><bold>1</bold></highlight> the dialog manager <highlight><bold>340</bold></highlight> determines from the device class provided by the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to the device interface <highlight><bold>341</bold></highlight> information identifying the location of the relevant dialog file and then retrieves that dialog file and stores it in the dialog file store <highlight><bold>342</bold></highlight>. At step S<highlight><bold>2</bold></highlight>, the dialog manager <highlight><bold>340</bold></highlight> registers a device listener for receiving notifications of events set by the machine control circuitry <highlight><bold>31</bold></highlight>, for example when the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>runs out of paper or toner in the case of a multi-functional facsimile/copy machine or for example, insertion of a document into the hopper of a multi-function machine. At step S<highlight><bold>3</bold></highlight>, the dialog manager <highlight><bold>340</bold></highlight> inspects the device class using the JAVA reflection API to derive from the device class the functional properties of the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and then at step S<highlight><bold>4</bold></highlight> the dialog manager <highlight><bold>340</bold></highlight> generates a ECMAScript object with these functional properties so as to enable the processor-controlled machine device to be controlled by script elements in the dialog. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> In operation of the JAVA virtual machine <highlight><bold>34</bold></highlight>, the dialog interpreter <highlight><bold>342</bold></highlight> sends requests and pieces of script to the dialog manager <highlight><bold>340</bold></highlight>. Each request may represent or cause a dialog state change and consists of: a prompt; a recognition grammar; details of the device events to wait for; and details of the job events to monitor. Of course, dependent upon the particular request, the events and jobs to monitor may have a null value, indicating that no device events are to be waited for or no jobs events are to be monitored. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> The operation of the system <highlight><bold>1</bold></highlight> will now be described with reference to the use of a single client <highlight><bold>3</bold></highlight> comprising a multi-functional device capable of facsimile, copying and printing operations. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows a flow chart illustrating the main steps carried out by the multi-function machine to carry out a job in accordance with a user&apos;s verbal instructions. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Initially, a voice-control session must be established at step S<highlight><bold>5</bold></highlight>. In this embodiment, this is initiated by the user activating a &ldquo;voice-control&rdquo; button or switch of the user interface <highlight><bold>32</bold></highlight> of the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>. In response to activation of the voice control switch, the device operating system module <highlight><bold>30</bold></highlight> communicates with the JAVA virtual machine <highlight><bold>34</bold></highlight> via the device interface <highlight><bold>341</bold></highlight> to cause the dialog manager <highlight><bold>340</bold></highlight> to instruct the client module <highlight><bold>343</bold></highlight> to seek, via the server module <highlight><bold>345</bold></highlight>, a slot on the speech processing apparatus or server <highlight><bold>2</bold></highlight>. When the server <highlight><bold>2</bold></highlight> responds to the request and allocates a slot, then the session connection is established. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Once the session connection has been established, then the dialog interpreter <highlight><bold>342</bold></highlight> sends an appropriate request and any relevant pieces of script to the dialog manager <highlight><bold>340</bold></highlight>. In this case, the request will include a prompt for causing the device operating system module <highlight><bold>30</bold></highlight> of the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to display on the user interface <highlight><bold>32</bold></highlight> a welcome message such as: &ldquo;Welcome to this multifunction machine. What would you like to do&quest;&rdquo; The dialog manager <highlight><bold>340</bold></highlight> also causes the client and server modules <highlight><bold>343</bold></highlight> and <highlight><bold>345</bold></highlight> to send to the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N the recognition grammar information in the request from the dialog interpreter so as to enable the appropriate grammar or grammars to be loaded by the ASR engine <highlight><bold>201</bold></highlight> (Step S<highlight><bold>6</bold></highlight>). </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> Step S<highlight><bold>6</bold></highlight> is shown in more detail in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. Thus, at step S<highlight><bold>60</bold></highlight>, when the user activates the voice control switch on the user interface <highlight><bold>32</bold></highlight>, the client module <highlight><bold>343</bold></highlight> requests, via the server module <highlight><bold>345</bold></highlight> and the network N, a slot on the server <highlight><bold>2</bold></highlight>. The client module <highlight><bold>343</bold></highlight> then waits at step S<highlight><bold>61</bold></highlight> for a response from the server indicating whether or not there is a free slot. If the answer at step S<highlight><bold>61</bold></highlight> is no, then the client module <highlight><bold>343</bold></highlight> may simply wait and repeat the request. If the client module <highlight><bold>343</bold></highlight> determines after a predetermined period of time that the server is still busy, then the client module <highlight><bold>343</bold></highlight> may cause the dialog manager <highlight><bold>340</bold></highlight> to instruct the device operating system module <highlight><bold>30</bold></highlight> (via the device interface), to display to the user on the user interface <highlight><bold>32</bold></highlight> a message along the lines of: &ldquo;please wait while communication with the server is established&rdquo;. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> When the server <highlight><bold>2</bold></highlight> has allocated a slot to the device <highlight><bold>3</bold></highlight>, then the dialog manager <highlight><bold>340</bold></highlight> and client module <highlight><bold>343</bold></highlight> cause, via the server module <highlight><bold>345</bold></highlight>, instructions to be transmitted to the server <highlight><bold>2</bold></highlight> identifying the initial grammar file or files required for the ASR engine <highlight><bold>201</bold></highlight> to perform speech recognition on the subsequent audio data (step S<highlight><bold>62</bold></highlight>) and then (step S<highlight><bold>63</bold></highlight>) to cause the user interface <highlight><bold>32</bold></highlight> to display the welcome message. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> Returning to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, at step S<highlight><bold>7</bold></highlight> spoken instructions received as audio data by the audio device <highlight><bold>5</bold></highlight> are processed by the audio module <highlight><bold>344</bold></highlight> and supplied to the client module <highlight><bold>343</bold></highlight> which transmits the audio data, via the server module <highlight><bold>345</bold></highlight>, to the speech processing apparatus or server <highlight><bold>2</bold></highlight> over the network N in blocks or bursts at a rate of, typically, 16 or 32 bursts per second. In this embodiment, the audio data is supplied as raw 16 bit 8 kHz format audio data. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> The JAVA virtual machine <highlight><bold>34</bold></highlight> receives data/instructions from the server <highlight><bold>2</bold></highlight> via the network N at step S<highlight><bold>8</bold></highlight>. These instructions are transmitted via the client module <highlight><bold>343</bold></highlight> to the dialog manager <highlight><bold>340</bold></highlight>. The dialog manager <highlight><bold>340</bold></highlight> accesses the dialog interpreter <highlight><bold>342</bold></highlight> which uses the dialog file stored in the dialog store <highlight><bold>343</bold></highlight> to interpret the instructions received from the speech processing apparatus <highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The dialog manager <highlight><bold>340</bold></highlight> determines from the result of the interpretation whether the data/instructions received are sufficient to enable a job to be carried out by the device (step S<highlight><bold>9</bold></highlight>). Whether or not the dialog manager <highlight><bold>340</bold></highlight> determines that the instructions are complete will depend upon the functions available on the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and the default settings, if any, determined by the dialog file. For example, the arrangement may be such that the dialog manager <highlight><bold>340</bold></highlight> understands the instruction &ldquo;copy&rdquo; to mean only a single copy is required and will not request further information from the user. Alternatively, the dialog file may require further information from the user when he simply instructs the machine to &ldquo;copy&rdquo;. In this case, the dialog interpreter <highlight><bold>342</bold></highlight> will send a new request including an appropriate prompt and identification of the required recognition grammar to the dialog manager <highlight><bold>30</bold></highlight> causing a new dialog state to be entered. The dialog manager will then send the speech processing apparatus <highlight><bold>2</bold></highlight> the recognition grammar information to enable the appropriate grammar or grammars to be loaded by the ASR engine and will instruct the device operating system module <highlight><bold>30</bold></highlight> via the device interface <highlight><bold>341</bold></highlight> to display to the user on the user interface <highlight><bold>32</bold></highlight> the prompt (step S<highlight><bold>10</bold></highlight>) determined by the dialog file and saying, for example, &ldquo;how many copies do you require&quest;&rdquo;. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> The instruction input by the user may specify characteristics required from the copy. For example, the instruction may specify the paper size and darkness of the copy. Where this is specified, then the dialog manager <highlight><bold>340</bold></highlight> will check at step S<highlight><bold>9</bold></highlight> whether the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>is capable of setting those functions by using the JAVA script object obtained for the device using the JAVA reflection API. If the dialog manager <highlight><bold>340</bold></highlight> determines that these features cannot be set on this particular machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>then a prompt will be displayed to the user at step S<highlight><bold>10</bold></highlight> saying, for example: &ldquo;This machine can only produce A4 copies&rdquo;. The dialog manager may then return to step S<highlight><bold>7</bold></highlight> and wait for further instructions from the user. As an alternative to simply advising the user that the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>is incapable of providing the function required, the dialog manager <highlight><bold>340</bold></highlight> may, when it determines that the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>cannot carry out a requested function, access the JINI look-up service <highlight><bold>4</bold></highlight> over the network N via the look-up service module <highlight><bold>346</bold></highlight> to determine whether there are any machines coupled to the network N that are capable of providing the required function and, if so, will cause the device operating system module <highlight><bold>30</bold></highlight> to display a message to the user on the display of the user interface <highlight><bold>32</bold></highlight> at step S<highlight><bold>10</bold></highlight> saying, for example: &ldquo;This machine cannot produce double-sided copies. However, the photocopier on the first floor can&rdquo;. The JAVA virtual machine <highlight><bold>34</bold></highlight> would then return to step S<highlight><bold>7</bold></highlight> awaiting further instructions from the user. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> When the data/instructions received at step S<highlight><bold>9</bold></highlight> are sufficient to enable the job to be carried out, then at step S<highlight><bold>11</bold></highlight> the dialog manager <highlight><bold>340</bold></highlight> registers a job listener to detect communications from the device operating system module <highlight><bold>30</bold></highlight> related to the job to be carried out, and communicates with the device operating system module <highlight><bold>30</bold></highlight> to instruct the processor-controlled machine to carry out the job. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> If at step S<highlight><bold>12</bold></highlight> the job listener detects an event, then the dialog manager <highlight><bold>340</bold></highlight> converts this to, in this example, a VoiceXML event and passes it to the dialog interpreter <highlight><bold>342</bold></highlight> which, in response, instructs the dialog manager <highlight><bold>340</bold></highlight> causes a message to be displayed to the user at step S<highlight><bold>13</bold></highlight> related to that event. For example, if the job listener determines that the multi-function device has run out of paper or toner or a fault has occurred in the copying process (for example, a paper jam or like fault) then the dialog manager <highlight><bold>340</bold></highlight> will cause a message to be displayed to the user at step S<highlight><bold>13</bold></highlight> advising them of the problem. At this stage a dialog state may be entered that enables a user to request context-sensitive help with respect to the problem. When the dialog manager <highlight><bold>340</bold></highlight> determines from the job listener that the problem has been resolved at step S<highlight><bold>14</bold></highlight>, then the job may be continued. of course, if the dialog manager <highlight><bold>340</bold></highlight> determines that the problem has not been resolved at step S<highlight><bold>14</bold></highlight>, then the dialog manager <highlight><bold>340</bold></highlight> may cause the message to continue to be displayed to the user or may cause other messages to be displayed prompting the user to call the engineer (step S<highlight><bold>15</bold></highlight>). </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> Assuming that any problem is resolved, then the dialog manager <highlight><bold>340</bold></highlight> then waits at step S<highlight><bold>16</bold></highlight> for an indication from the job listener that the job has been completed. When the job has been completed, then the dialog manager <highlight><bold>340</bold></highlight> may cause the user interface <highlight><bold>32</bold></highlight> to display to the user a &ldquo;job complete&rdquo; message at step <highlight><bold>16</bold></highlight><highlight><italic>a</italic></highlight>. The dialog manager <highlight><bold>340</bold></highlight> then communicates with the speech processing apparatus <highlight><bold>2</bold></highlight> to cause the session to be terminated at steps S<highlight><bold>16</bold></highlight><highlight><italic>b</italic></highlight>, thereby freeing the slot on the speech processing apparatus for another processor-controlled machine. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> It will, of course, be appreciated that, dependent upon the particular instructions received and the dialog file, the dialog state may or may not change each time step S<highlight><bold>7</bold></highlight> to S<highlight><bold>10</bold></highlight> are repeated for a particular job and that, moreover, different grammar files may be associated with different dialog states. Where a different dialog state requires a different grammar file then, of course, the dialog manager <highlight><bold>340</bold></highlight> will cause the client module <highlight><bold>343</bold></highlight> to send data identifying the new grammar file to the speech processing apparatus <highlight><bold>2</bold></highlight> in accordance with the request from the dialog interpreter so that the ASR engine <highlight><bold>201</bold></highlight> uses the correct grammar files for subsequent audio data. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> shows a flow chart for illustrating the main steps carried out by the server <highlight><bold>2</bold></highlight> assuming that the connection manager <highlight><bold>204</bold></highlight> has already received a request for a slot from the control apparatus <highlight><bold>34</bold></highlight> and has granted the control apparatus a slot. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> At step S<highlight><bold>17</bold></highlight> the connection manager <highlight><bold>204</bold></highlight> receives from the control apparatus <highlight><bold>34</bold></highlight> instructions identifying the required grammar file or files. At step S<highlight><bold>18</bold></highlight>, the connection manager <highlight><bold>204</bold></highlight> causes the identified grammar or grammars to be loaded into the ASR engine <highlight><bold>201</bold></highlight> from the grammar module <highlight><bold>202</bold></highlight>. As audio data is received from the control apparatus <highlight><bold>34</bold></highlight> at step S<highlight><bold>19</bold></highlight>, the connection manager <highlight><bold>204</bold></highlight> causes the required grammar rules to be activated and passes the received audio data to the ASR engine <highlight><bold>201</bold></highlight> at step S<highlight><bold>20</bold></highlight>. At step S<highlight><bold>21</bold></highlight>, the connection manager <highlight><bold>204</bold></highlight> receives the result of the recognition process (the &ldquo;recognition result&rdquo;) from the ASR engine <highlight><bold>201</bold></highlight> and passes it to the speech interpreter module <highlight><bold>203</bold></highlight> which interprets the recognition result to provide an utterance meaning that can be interpreted by the dialog interpreter <highlight><bold>342</bold></highlight> of the device <highlight><bold>3</bold></highlight>. When the connection manager <highlight><bold>204</bold></highlight> receives the utterance meaning from the speech interpreter module <highlight><bold>203</bold></highlight>, it communicates with the server module <highlight><bold>345</bold></highlight> over the network N and transmits the utterance meaning to the control apparatus <highlight><bold>34</bold></highlight>. The connection manager <highlight><bold>204</bold></highlight> then waits at step S<highlight><bold>24</bold></highlight> for further communications from the server module <highlight><bold>345</bold></highlight> of the control apparatus <highlight><bold>34</bold></highlight>. If a communication is received indicating that the job has been completed, then the session is terminated and the connection manager <highlight><bold>204</bold></highlight> releases the slot for use by another device or job. Otherwise steps S<highlight><bold>17</bold></highlight> to S<highlight><bold>24</bold></highlight> are repeated. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> It will be appreciated that during a session the ASR engine <highlight><bold>201</bold></highlight> and speech interpreter module <highlight><bold>203</bold></highlight> function continuously with the ASR engine <highlight><bold>201</bold></highlight> recognising received audio data as and when it is received. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> The connection manager <highlight><bold>204</bold></highlight> may be arranged to retrieve the grammars that may be required by a control apparatus connected to a particular processor-controlled machine and store them in the grammar module <highlight><bold>202</bold></highlight> upon first connection to the network. Information identifying the location of the grammar(s) may be provided in the device class and supplied to the connection manager <highlight><bold>204</bold></highlight> by the dialog manager <highlight><bold>340</bold></highlight> when the processor-controlled machine is initially connected to the network by the control apparatus <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> In the above described embodiment, each processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>is directly coupled to its own control apparatus <highlight><bold>34</bold></highlight> which communicates with the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows a block schematic diagram similar to <cross-reference target="DRAWINGS">FIG. 1</cross-reference> of another network system <highlight><bold>1</bold></highlight><highlight><italic>a </italic></highlight>embodying the present invention. In the system shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, each of the processor-controlled machines <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>is arranged to communicate with a single control apparatus <highlight><bold>34</bold></highlight> over the network N. In this case, a separate audio communication system <highlight><bold>40</bold></highlight> is provided which connects to one or more audio devices <highlight><bold>5</bold></highlight> (only one is shown). The audio communication system <highlight><bold>40</bold></highlight> may comprise a DECT telephone exchange and the audio device <highlight><bold>5</bold></highlight> may be a DECT mobile telephone which would normally be allocated to a specific individual. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> The &ldquo;flashes&rdquo; or jagged lines on the connecting lines between the control apparatus <highlight><bold>34</bold></highlight> and network N and before the audio device <highlight><bold>5</bold></highlight> and audio communication system <highlight><bold>40</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> and between the JAVA virtual machine <highlight><bold>34</bold></highlight> and processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and audio device <highlight><bold>5</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> indicate that the connection need not be a physical connection but could be, for example, a remote link such as an infrared or radio link or a link via another network. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> In this embodiment, the speech processing apparatus <highlight><bold>2</bold></highlight> will again have the configuration shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> and the connection manager <highlight><bold>204</bold></highlight> will communicate with the control apparatus <highlight><bold>34</bold></highlight> over the network N. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> In this embodiment, the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and the single JAVA virtual machine <highlight><bold>34</bold></highlight> will have the same general configuration as shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. However, in this case, the interfaces <highlight><bold>35</bold></highlight> of the processor-controlled machines <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>will provide network interfaces and the JAVA virtual machine <highlight><bold>34</bold></highlight> will be configured to use the JAVA remote method invocation (RMI) protocols to provide at the device interface <highlight><bold>341</bold></highlight> a proxy in the form of a local object that handles all communications over the network N with the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>. As set out above, the connection between the audio module <highlight><bold>343</bold></highlight> of the JAVA virtual machine <highlight><bold>34</bold></highlight> and the audio device or devices <highlight><bold>5</bold></highlight> will be via the audio communication system <highlight><bold>40</bold></highlight> in this example, a DECT telephone exchange. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> The system <highlight><bold>1</bold></highlight><highlight><italic>a </italic></highlight>shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> functions in essentially the same manner as the system <highlight><bold>1</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. In this case, however, instead of activating a voice control button on a processor-controlled machine, a user initiates voice control by using the DECT telephone system. Thus, as illustrated schematically in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, when a user U wishes to control a photocopier <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>using his or her DECT telephone <highlight><bold>5</bold></highlight>, the user U inputs to the DECT telephone <highlight><bold>5</bold></highlight> the telephone number associated with the control apparatus <highlight><bold>34</bold></highlight> enabling the audio communication system <highlight><bold>40</bold></highlight> to connect the audio device <highlight><bold>5</bold></highlight> to the control apparatus <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> In this embodiment, the JAVA virtual machine <highlight><bold>34</bold></highlight> is configured so as to recognise dial tones as an instruction to initiate voice control and to provide instructions to the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N to load a DECT initial grammar upon receipt of such dial tones. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The DECT telephone will not, of course, be associated with a particular machine. It is therefore necessary for the control apparatus <highlight><bold>34</bold></highlight> to identify in some way the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to which the user U is directing his or her voice control instructions. This may be achieved by, for example, determining the location of the mobile telephone <highlight><bold>5</bold></highlight> from communication between the mobile telephone <highlight><bold>5</bold></highlight> and the DECT exchange <highlight><bold>40</bold></highlight>. As another possibility, each of the processor-controlled machines <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>coupled to the network may be given an identification (the photocopier shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> carries a label identifying it as &ldquo;copier 9&rdquo;) and users instructed to initiate voice control by uttering a phrase such as &ldquo;I am at copier number 9&rdquo; or &ldquo;this is copier number 9&rdquo;. When this initial phrase is recognised by the ASR engine <highlight><bold>201</bold></highlight>, the speech interpreter module <highlight><bold>203</bold></highlight> will provide to the control apparatus <highlight><bold>34</bold></highlight> via the connection manager <highlight><bold>204</bold></highlight> dialog interpretable instructions which identify to the control apparatus <highlight><bold>34</bold></highlight> the network address of, in this case, &ldquo;copier 9&rdquo;. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> The control apparatus <highlight><bold>34</bold></highlight> can then communicate with the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>known as &ldquo;copier 9&rdquo; over the network N to retrieve its device class and can then communicate with the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>using the JAVA remote method invocation (RMI) protocol to handle all communications over the network. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> In other respects, the JAVA virtual machine <highlight><bold>34</bold></highlight>, speech processing apparatus <highlight><bold>2</bold></highlight> and processor-controlled machines <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>operate in a manner similar to that described above with reference to FIGS. <highlight><bold>1</bold></highlight> to <highlight><bold>7</bold></highlight> with the main differences being, as set out above, that communication between the control apparatus <highlight><bold>34</bold></highlight> and a processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>is over the network N and audio data is supplied to the control apparatus <highlight><bold>34</bold></highlight> over the audio communication system <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows another system <highlight><bold>1</bold></highlight><highlight><italic>b </italic></highlight>embodying the invention. This system differs from that shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> in that the control apparatus <highlight><bold>34</bold></highlight> forms part of the speech processing apparatus so that the control apparatus <highlight><bold>34</bold></highlight> and speech processing apparatus <highlight><bold>2</bold></highlight> communicate directly rather than over the network N. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> shows a block diagram similar to <cross-reference target="DRAWINGS">FIGS. 1, 8</cross-reference> and <highlight><bold>9</bold></highlight> wherein the control apparatus <highlight><bold>34</bold></highlight> and audio device <highlight><bold>5</bold></highlight> form part of a control device <highlight><bold>300</bold></highlight>. This system differs from that shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> in that there is a direct coupling between the control apparatus <highlight><bold>34</bold></highlight> and the audio device <highlight><bold>5</bold></highlight>. In this embodiment, the connection of the control apparatus <highlight><bold>34</bold></highlight> to the network may be a wireless connection such as, for example, an infrared or radio link enabling the control device <highlight><bold>300</bold></highlight> to be moved between locations connected to the network N. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> The operation of this system will be similar to that described with reference to <cross-reference target="DRAWINGS">FIG. 8</cross-reference> with the exception that the audio device <highlight><bold>5</bold></highlight> is not a telephone but rather a microphone or like device that provides direct audio connection to the audio module <highlight><bold>244</bold></highlight>. Again in this example, the initial step of the dialog may require the user to utter phrases such as &ldquo;I am at machine X&rdquo; or &ldquo;connect me to machine X&rdquo;. In other respects, the system shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference> will function in a similar manner to that shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. This arrangement may be particular advantageous in a home environment. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> In this system <highlight><bold>1</bold></highlight><highlight><italic>c </italic></highlight>and the systems <highlight><bold>1</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>1</bold></highlight><highlight><italic>b </italic></highlight>shown in <cross-reference target="DRAWINGS">FIGS. 8 and 9</cross-reference>, the control apparatus <highlight><bold>34</bold></highlight> may, as shown schematically in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, be provided with its own user interface <highlight><bold>301</bold></highlight> so that a dialog with a user can be conducted via the user interface <highlight><bold>301</bold></highlight> of the control apparatus <highlight><bold>34</bold></highlight> or device <highlight><bold>300</bold></highlight> rather than using a user interface of the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>. This has the advantage that the user need not necessarily be located in the vicinity of the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>that he wishes to control but may, in the case of the system shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> be located at the control apparatus <highlight><bold>34</bold></highlight> or, in the case of the system shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, be located at the speech processing apparatus <highlight><bold>2</bold></highlight>. In the case of FIG. <highlight><bold>11</bold></highlight>, enabling a dialog with the user to be conducted by a user interface <highlight><bold>301</bold></highlight> of a portable control device <highlight><bold>300</bold></highlight> means that the user can carry the control device with him and issue instructions to control a machine anywhere within the range of the remote link to the network N. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> It will, of course, be appreciated that in the system shown in <cross-reference target="DRAWINGS">FIGS. 8 and 9</cross-reference> two or more control apparatus <highlight><bold>34</bold></highlight> may be provided and that in the system shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, individual users of the network may be provided with their own control devices <highlight><bold>300</bold></highlight>. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> As will be appreciated from the above, updates for the grammars and dialog files may easily be supplied over the network, especially where the network provides or includes a connection to the Internet. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> In an office environment, the processor-controlled machines <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>may be items of equipment such as photocopiers, facsimile machines, printers, digital cameras while in the home environment they may be, for example, TV&apos;s, video recorders, microwave ovens, processor-controlled heating or lighting systems etc and, of course, especially where the network N includes or is provided by the Internet, combinations of both office and home equipment. In each case, the JAVA virtual machine <highlight><bold>34</bold></highlight> can be developed completely independently of the processor-controlled machine <highlight><bold>30</bold></highlight> with the manufacturer of the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>merely needing to provide the device class information as set out above which enables the JAVA virtual machine to locate the appropriate dialog file and, by using the JAVA reflection API, to determine the functions provided by the machine. This means that, for example, the JAVA virtual machine <highlight><bold>34</bold></highlight> can be provided as an add-on component that may even be supplied by a separate manufacturer. It is therefore not necessary for the developer of the JAVA virtual machine to have information about the particular type of processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>with which the JAVA virtual machine <highlight><bold>34</bold></highlight> is to be used. This may enable, for example, a single JAVA virtual machine architecture to be developed regardless of the processor-controlled machines with which it is to be used. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> In the above described embodiments, the virtual machines <highlight><bold>34</bold></highlight> are JAVA virtual machines. There are several advantages to using JAVA. Thus, as discussed above, the JAVA introspection/reflection API enables the JAVA virtual machine to determine the functionality of the processor-controlled machine to which it is connected from the device class while the platform independence of JAVA means that the client code is reusable on all JAVA virtual machines. Furthermore, as mentioned above, use of JAVA enables use of the JINI framework and a JINI look-up service on the network. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> Instead of providing the device class, the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>may simply provide the JAVA virtual machine <highlight><bold>34</bold></highlight> with data sufficient to locate the relevant dialog file which may include an applet file for the device class JAVA object. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> In the above described embodiment, a dialog is conducted with a user by displaying messages to the user. It may however be possible to provide a speech synthesis unit controllable by the JAVA virtual machine to enable a fully spoken or oral dialog. This may be particularly advantageous where the processor-controlled machine has only a small display. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> Where such a fully spoken or oral dialog is to be conducted, then requests from the dialog interpreter <highlight><bold>342</bold></highlight> will include a &ldquo;barge-in flag&rdquo; to enable a user to interrupt spoken dialog from the control apparatus when the user is sufficiently familiar with the functionality of the machine to be controlled that he knows exactly the voice commands to issue to enable correct functioning of that machine. Where a speech synthesis unit is provided, then in the system shown in <cross-reference target="DRAWINGS">FIGS. 8 and 9</cross-reference> the dialog with the user may be conducted via the user&apos;s telephone <highlight><bold>5</bold></highlight> rather than via a user interface of either the control apparatus <highlight><bold>34</bold></highlight> or the user interface of the processor-controlled machine and, in the system shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference> by providing the audio device <highlight><bold>5</bold></highlight> with an audio output as well as audio input facility. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> It will be appreciated that the system shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> may be modified to enable a user to use his or her DECT telephone to issue instructions with the communication between the audio device <highlight><bold>5</bold></highlight> and the audio module <highlight><bold>343</bold></highlight> being via the DECT telephone exchange. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> Although the present invention has particular advantage where a number of processor-controlled machines are coupled to a network, it may also be used to enable voice control of one or more stand alone processor-controlled machine using speech processing apparatus accessible over a network or incorporated with a device including the control apparatus. In the later case the control apparatus may be arranged to download the received dialog file from the processor-controlled machine itself or to use information provided by the processor-controlled machine to access the dialog file from another location, for example over the Internet. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> It will be appreciated by those skilled in the art that it is not necessary to use the JAVA platform and that other platforms that provide similar functionality may be used. For example, the Universal Plug and Play device architecture (see web site www.upnp.org) may be used with, in this case, the processor-controlled machine providing an XML file that enables location of a dialog file containing an applet file for the device class JAVA object. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> As used herein the term &ldquo;processor-controlled machine&rdquo; includes any processor-controlled device, system, or service that can be coupled to the control apparatus to enable voice control of a function of that device, system or service. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> Other modifications will be apparent to those skilled in the art. </paragraph>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A control apparatus for enabling a user to control by spoken commands a function of a processor-controlled machine couplable to speech processing apparatus, the control apparatus comprising: 
<claim-text>receiving means for receiving dialog interpretable instructions derived from speech data processed by the speech processing apparatus; </claim-text>
<claim-text>dialog communication means for interpreting received dialog interpretable instructions using a dialog compatible with the processor-controlled machine and for communicating with the processor-controlled machine using the dialog to enable information to be provided to the user in response to received dialog interpretable instructions, thereby enabling a dialog to be conducted with the user; </claim-text>
<claim-text>dialog determining means for determining from information provided by the processor-controlled machine the dialog to be used with that processor-controlled machine; and </claim-text>
<claim-text>machine communication means for communicating with the processor-controlled machine to cause the processor-controlled machine to carry out a function in accordance with the dialog with the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the control apparatus is couplable to a network and the dialog determining means is arranged to determine the location on the network of a file for that dialog. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising storing means for causing the dialog to be stored in a dialog store of the control apparatus. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, comprising means for determining, using information provided by the processor-controlled machine, functions available on that machine. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A control apparatus comprising a JAVA virtual machine for enabling a user to control by spoken commands a function of a processor-controlled machine couplable to to speech processing apparatus, the JAVA virtual machine comprising: 
<claim-text>receiving means receiving dialog interpretable instructions derived from speech processed by the speech processing apparatus; </claim-text>
<claim-text>dialog communication means for interpreting, using a dialog compatible with the processor-controlled machine, received dialog interpretable instructions, </claim-text>
<claim-text>a dialog communicating means for communicating with the processor-controlled machine using the dialog to enable information to be provided to the user in response to received dialog interpretable instructions, thereby enabling the processor-controlled machine to conduct a dialog with the user; </claim-text>
<claim-text>dialog determining means for determining from a device class determined from information provided by the processor-controlled machine the dialog to be used with that processor-controlled machine; and </claim-text>
<claim-text>machine communication means for communicating with the processor-controlled machine to cause the processor-controlled machine to carry out a function in accordance with the dialog with the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein the control apparatus is couplable to a network and the dialog determining means is arranged to determine from the device class the location on the network of a file for the dialog for that processor-controlled machine. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further comprising storing means for causing the dialog to be stored in a dialog store of the control apparatus. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, comprising function determining means for using the JAVA reflection API to determine from the device class information regarding the processor-controlled machine functions available on that processor-controlled machine. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A control apparatus for enabling a user to control by spoken commands a function of a processor-controlled machine couplable to speech processing apparatus, the control apparatus comprising a JAVA virtual machine having: 
<claim-text>receiving means for receiving dialog interpretable instructions derived from speech data processed by the speech processing apparatus; </claim-text>
<claim-text>dialog interpreting means for interpreting, using a dialog compatible with the processor-controlled machine, received dialog interpretable instructions; </claim-text>
<claim-text>dialog communication means for communicating with the processor-controlled machine using the dialog to enable information to be provided to the user in response to received dialog interpretable instructions, thereby enabling the processor-controlled machine to conduct a dialog with the user; </claim-text>
<claim-text>device interface means for receiving from the processor-controlled machine information identifying or representing the device class for that processor-controlled machine; </claim-text>
<claim-text>function determining means for using the JAVA reflection API to determine from the device class information regarding the processor-controlled machine functions available on that processor-controlled machine; and </claim-text>
<claim-text>machine communication means for communicating with the processor-controlled machine to cause the processor-controlled machine to carry out a function in accordance with the dialog with the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, having a job listener registering means for registering a job listener to receive from the processor-controlled machine information relating to events occurring at the machine. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein a dialog has a number of dialog states and the dialog communication means is arranged to control the dialog state in accordance with received dialog interpretable instructions. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the dialog communication means is arranged to supply to the speech processing apparatus information relating to the speech recognition grammar or grammars to be used for processing speech data in accordance with a dialog state. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, comprising audio data receiving means for receiving speech data and audio data transmitting means for transmitting received speech data to the speech processing apparatus. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, comprising network interface means for communicating with the speech processing apparatus over a network. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, comprising network interface means for communicating with a processor-controlled machine over a network. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, comprising remote communication means for communicating with a least one of the speech processing apparatus and a processor-controlled machine. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A control device comprising a control apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> and an audio input device. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A voice-control controller comprising a control apparatus in accordance with <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> and speech processing apparatus comprising: 
<claim-text>speech recognising means for recognising speech in received audio data using at least one speech recognition grammar; </claim-text>
<claim-text>speech interpreting means for interpreting recognised speech to provide dialog interpretable instructions; and </claim-text>
<claim-text>transmitting means for transmitting the dialog interpretable instructions to the dialog communication means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A processor-controlled machine arranged to be connected to a control apparatus in accordance with <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the processor-controlled machine comprises: 
<claim-text>machine control circuitry for carrying out at least one function; </claim-text>
<claim-text>storing means for storing information for at least one of a dialog file and a device class; </claim-text>
<claim-text>a processor for controlling the machine control circuitry; and </claim-text>
<claim-text>means for providing said information to the control apparatus for enabling the dialog determining means to determine the dialog to be used with the processor-controlled machine. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A processor-controlled machine arranged to be connected to a control apparatus in accordance with <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the processor-controlled machine comprises; 
<claim-text>machine control circuitry for carrying out at least one function; </claim-text>
<claim-text>storing means for storing a device class for the processor-controlled machine; </claim-text>
<claim-text>a processor for controlling the machine control circuitry; and </claim-text>
<claim-text>means for supplying the device class to the control apparatus. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. A processor-controlled machine according to <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, capable of providing at least one of photocopying, facsimile and printing functions. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. A processor-controlled machine according to <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, comprising at least one of: 
<claim-text>a television receiver, a video cassette recorder, a microwave oven, a digital camera, a printer, a photocopier, a facsimile machine, a lighting system, a heating system. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A device couplable to a network comprising a processor-controlled machine in accordance with <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> and a control apparatus in accordance with <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A device according to <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference>, wherein the control apparatus, control device or controller is integrated with the processor-controlled machine. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A device according to <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference>, comprising a separate audio input device. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. A system comprising a plurality of devices in accordance with <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference>, and a speech processing apparatus connectable to the devices via a network and comprising: 
<claim-text>means for receiving audio data representing speech by a user; </claim-text>
<claim-text>speech recognition means for recognising speech in the received audio data; </claim-text>
<claim-text>speech interpreting means for interpreting the recognised speech to provide dialog interpretable instructions; and </claim-text>
<claim-text>transmitting means for transmitting the dialog interpretable instructions over the network to at least one of said devices. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference>, further comprising a look-up service connectable to the network. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. In a control apparatus enabling a user to control by spoken commands a function of a processor-controlled machine couplable to speech processing apparatus, a method comprising; 
<claim-text>determining from information provided by the processor-controlled machine a dialog to be used with that processor-controlled machine; </claim-text>
<claim-text>receiving dialog interpretable instructions derived from speech processed by the speech processing apparatus; </claim-text>
<claim-text>interpreting received dialog interpretable instructions using the determined dialog; and </claim-text>
<claim-text>communicating with the processor-controlled machine using the dialog to enable the processor-controlled machine to provide information to the user in response to received dialog interpretable instructions, thereby enabling the processor-controlled machine to conduct a dialog with the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, which comprises determining the location on a network of a file for the dialog. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, further comprising storing the dialog in a dialog store of the control apparatus. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, comprising determining from information provided by the processor-controlled machine functions available on that machine. </claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. In a control apparatus comprising a JAVA virtual machine for enabling a user to control by spoken commands a function of a processor-controlled machine couplable to speech processing apparatus, a method comprising: 
<claim-text>determining from information provided by the processor-controlled machine relating to or identifying a device class for that machine a dialog to be used with that processor-controlled machine; </claim-text>
<claim-text>receiving dialog interpretable instructions derived from speech processed by the speech processing apparatus; </claim-text>
<claim-text>interpreting received dialog interpretable instructions using the dialog; and </claim-text>
<claim-text>communicating with the processor-controlled machine using the dialog to enable the processor-controlled machine to provide information to the user in response to received dialog interpretable instructions, thereby enabling the processor-controlled machine to conduct a dialog with the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, which comprises determining from the device class the location on a network of a file for the dialog for that processor-controlled machine. </claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, further comprising storing the dialog in a dialog store of the control apparatus. </claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, comprising using the JAVA reflection API to determine from the device class information regarding the processor-controlled machine functions available on that processor-controlled machine. </claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, wherein a dialog has a number of dialog states and the dialog state is controlled in accordance with received dialog interpretable instructions. </claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, wherein information relating to the speech recognition grammar or grammars to be used for processing speech data is supplied to the speech processing apparatus in accordance with a dialog state. </claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, further comprising receiving speech data and transmitting received speech data to the speech processing apparatus. </claim-text>
</claim>
<claim id="CLM-00039">
<claim-text><highlight><bold>39</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, comprising communicating with the speech processing apparatus over a network. </claim-text>
</claim>
<claim id="CLM-00040">
<claim-text><highlight><bold>40</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, comprising communicating with a processor-controlled machine over a network. </claim-text>
</claim>
<claim id="CLM-00041">
<claim-text><highlight><bold>41</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, comprising communicating via a remote communication link with at least one of the speech processing apparatus and a processor-controlled machine. </claim-text>
</claim>
<claim id="CLM-00042">
<claim-text><highlight><bold>42</bold></highlight>. In a control apparatus comprising a JAVA virtual machine for enabling a user to control by spoken commands a processor-controlled machine couplable to speech processing apparatus, a method comprising: 
<claim-text>receiving from the processor-controlled machine information regarding the device class for that processor-controlled machine; </claim-text>
<claim-text>receiving dialog interpretable instructions derived from speech processed by the speech processing apparatus; </claim-text>
<claim-text>interpreting, using a dialog compatible with the processor-controlled machine, received dialog interpretable instructions; and </claim-text>
<claim-text>communicating with the processor-controlled machine using the dialog to enable the processor-controlled machine to provide information to the user in response to received dialog interpretable instructions, thereby enabling the processor-controlled machine to conduct a dialog with the user; and using the JAVA reflection API to determine from the device class information regarding the processor-controlled machine functions available on that processor-controlled machine. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00043">
<claim-text><highlight><bold>43</bold></highlight>. A computer program product comprising processor implementable instructions for configuring a processor to provide a control apparatus in accordance with any one of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00044">
<claim-text><highlight><bold>44</bold></highlight>. A computer program product comprising processor implementable instructions for configuring a processor to carry out a method in accordance with <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00045">
<claim-text><highlight><bold>45</bold></highlight>. A signal comprising a computer program product in accordance with <dependent-claim-reference depends_on="CLM-00044">claim 43</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00046">
<claim-text><highlight><bold>46</bold></highlight>. A storage medium carrying a computer program product in accordance with <dependent-claim-reference depends_on="CLM-00044">claim 44</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00047">
<claim-text><highlight><bold>47</bold></highlight>. A computer program product comprising processor implementable instructions for configuring a processor to carry out a method in accordance with <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00048">
<claim-text><highlight><bold>48</bold></highlight>. A computer program product comprising processor implementable instructions for configuring a processor to carry out a method in accordance with claim <highlight><bold>42</bold></highlight>.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>5</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004727A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004727A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004727A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004727A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004727A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004727A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004727A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004727A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004727A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004727A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030004727A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030004727A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
