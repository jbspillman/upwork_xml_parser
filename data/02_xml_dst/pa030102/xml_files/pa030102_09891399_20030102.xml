<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004728A1-20030102-D00000.TIF SYSTEM "US20030004728A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00001.TIF SYSTEM "US20030004728A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00002.TIF SYSTEM "US20030004728A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00003.TIF SYSTEM "US20030004728A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00004.TIF SYSTEM "US20030004728A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00005.TIF SYSTEM "US20030004728A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00006.TIF SYSTEM "US20030004728A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00007.TIF SYSTEM "US20030004728A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00008.TIF SYSTEM "US20030004728A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00009.TIF SYSTEM "US20030004728A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00010.TIF SYSTEM "US20030004728A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00011.TIF SYSTEM "US20030004728A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030004728A1-20030102-D00012.TIF SYSTEM "US20030004728A1-20030102-D00012.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004728</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09891399</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010627</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G10L021/00</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G10L011/00</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>704</class>
<subclass>275000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>System</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Robert</given-name>
<middle-name>Alexander</middle-name>
<family-name>Keiller</family-name>
</name>
<residence>
<residence-non-us>
<city>Guildford</city>
<country-code>GB</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>FITZPATRICK CELLA HARPER &amp; SCINTO</name-1>
<name-2></name-2>
<address>
<address-1>30 ROCKEFELLER PLAZA</address-1>
<city>NEW YORK</city>
<state>NY</state>
<postalcode>10112</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A processor-controlled machine (<highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>) is coupled via a control apparatus (<highlight><bold>34</bold></highlight>) to speech processing apparatus (<highlight><bold>2</bold></highlight>) for enabling a user to control at least one function of the machine by spoken commands. The speech processing apparatus (<highlight><bold>2</bold></highlight>) has a speech recognition engine (<highlight><bold>201</bold></highlight>) associated with a grammar module (<highlight><bold>202</bold></highlight>) for providing the speech recognition grammar or grammars required by the engine (<highlight><bold>201</bold></highlight>). The control apparatus (<highlight><bold>34</bold></highlight>) provides the speech processing apparatus (<highlight><bold>2</bold></highlight>) with instructions regarding the speech recognition grammars to be used for recognising speech data. The grammar store stores at least first and second grammars having grammar rules and at least one interface grammar defining grammar rules with the first grammar being arranged to use grammar rules defined by the interface grammar, and the second, being arranged to implement rules defined by the interface grammar so as to enable an extended grammar to be formed when the control apparatus provides instructions for causing the second grammar to be linked to the first grammar using the interface grammar. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This invention relates to a system, in particular to a system that enables voice control of devices or machines using an automatic speech recognition engine accessible by the devices, for example accessible over a network. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> In conventional network systems, such as office equipment network systems, instructions for controlling the operation of a machine or device connected to the network are generally input manually, for example using a control panel of the device. Voice control of machines or devices may, at least in some circumstances, be more acceptable or convenient for a user. It is, however, not cost effective to provide each different machine or device with its own automatic speech recognition engine. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> One solution to this problem is to provide a speech processing apparatus coupled to the network and to transmit the speech data over the network to the speech processing apparatus which, in response, provides instructions for enabling a machine coupled to the network to carry out a function specified by the spoken commands represented by the speech data. It is, of course, not practical for such speech processing apparatus to incorporate an automatic speech recognition engine trained for every possible user&apos;s voice. Rather, it is desirable to provide a single untrained automatic speech recognition engine. Although such a speech recognition engine could use a single grammar that contains the terms and phrases that may be used for voice control of any machines that may be coupled to the network, the use of such a single general grammar with an untrained automatic speech recognition engine may result in a high proportion of mis-recognitions and, moreover, may result in the speech processing operation being unacceptably slow. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> It is an aim of the present invention to provide a system, a speech processing apparatus, a control apparatus and a grammar for use in such a system that enables voice control of machines using a remote speech processing apparatus using a speech recognition grammar that is adapted to the machine or machines to be controlled while providing a relatively simple and natural voice control interface for the user. For example, it is an aim of the present invention to enable a user to issue voice commands to enable, for example, a picture stored by a digital camera to be printed by a printer coupled to a network without the user having to separate camera-related speech commands from printer related speech commands and without the camera having to know about the printer commands available on the printer and without the printer having to know about the possible camera formatting commands. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In one aspect, the present invention provides a system comprising a processor-controlled machine for carrying out at least one function specified by a user and being couplable to a remote speech processing apparatus arranged to receive and interpret spoken commands issued by the user and to supply to control apparatus instructions or commands for enabling the or a different machine to carry out the function required by the user, wherein the speech processing apparatus has access to at least first and second grammars having grammar rules and at least one interface grammar defining grammar rules such that the first grammar is arranged to use grammar rules defined by the interface grammar and the second grammar is arranged to implement rules defined by the interface grammar and wherein the control apparatus is arranged to provide instructions for causing the second grammar to be linked to the first grammar using the interface grammar to produce an extended grammar when the control apparatus determines that the use of an extended grammar is necessary. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> In an embodiment the processor-controlled machine to which the user directs the spoken commands is a digital camera while the processor-controlled machine carrying out the at least one function is a printer and the digital camera includes a control apparatus arranged to provide instructions for causing the first and second grammars to be linked using the interface grammar when a user&apos;s spoken instructions indicate that an image stored by the digital camera is to be printed. This arrangement means that the digital camera does not need to have any information about the functionality of any of the printers that may be used to print its images. Similarly, the available printers do not need to have any information about the digital camera. This enables the printer and digital camera to be manufactured and supplied completely independently from one another and should mean that, for example, a network operator does not need to ensure compatibility, at least from the point of view of speech control, between machines coupled to a network. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> The present invention may also enable, for example, a generic grammar for a particular type of machine, (printer, photocopier, facsimile machine etc) to be provided which can be linked via an interface grammar to a second grammar specific to the particular machine. This would mean that, for example, a generic printer grammar could be provided and that individual printer manufacturers would only need to provide grammars specific to the particular non-generic features and functions provided by their printers and would also facilitate upgrading or changing of the specific printing grammars because it would not be necessary to change the entire printer grammar, only the grammar specific to that specific printer. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The present invention also provides a speech processing apparatus having, or having means for accessing, a speech recognition grammar store comprising at least first and second grammars having grammar rules and at least one interface grammar defining grammar rules, with the first grammar being arranged to use grammar rules defined by the interface grammar and the second grammar being arranged to implement rules defined by the interface grammar such that the first and second grammars can be linked using the interface grammar to form an extended grammar. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> The present invention also provides a control apparatus for coupling a processor-controlled machine to speech processing apparatus for enabling a user to control a function of a machine by spoken command, wherein the control apparatus is arranged to provide to the speech processing apparatus speech data and speech recognition grammar instructions including, where appropriate, instructions for causing first and second grammars to be linked by an interface grammar having grammar rules usable by the first grammar and implementable by the second grammar to form an extended grammar. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The present invention also provides a grammar store for use in or by a system or speech processing apparatus as set out above wherein the grammar store has at least first and second grammars and at least one interface grammar defining grammar rules usable by the first grammar and implementable by the second grammar to enable first and second grammars to be linked by an interface grammar to form an extended grammar. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> More than one interface grammar may be provided and, for example, it may be possible to link the second grammar to a further grammar by a further interface grammar defining grammar rules usable by the second grammar and implementable by the further grammar so as to link the three grammars together. This interface linking may be further expanded so as to enable a cascade of grammars to be connected together via interface grammars in accordance with instructions received from the processor-controlled machine or control apparatus to which the user&apos;s voice commands are directed. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> Preferably, the control apparatus comprises a JAVA virtual machine. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The processor-controlled machine may be, for example, an item of office equipment such as a photocopier, printer, facsimile machine or multi-function machine capable of facsimile, photocopy and printing functions and/or may be an item of home equipment such as a domestic appliance such as a television, a video cassette recorder, a microwave oven and so on. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Embodiments of the present invention will now be described, by way of example, with reference to the accompanying drawings, in which: </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a schematic block diagram of a system embodying the present invention; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a schematic block diagram of a speech processing apparatus of the system shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a schematic block diagram to illustrate a processor-controlled machine and its connection to a control apparatus and audio device; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a flow chart for illustrating steps carried out by a virtual machine of a client when a user instructs the client to carry out a job or function; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows a flow chart illustrating in greater detail a step shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows a flow chart illustrating in greater detail a step shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> shows a flow chart illustrating steps carried out by speech processing apparatus shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> to enable a voice-controlled job to be carried out by a client of the system shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows a functional block diagram of a grammar store to illustrate the linking of grammars; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows a schematic block diagram of a client which comprises as the processor-controlled machine a digital camera; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> shows a schematic block diagram similar to <cross-reference target="DRAWINGS">FIG. 1</cross-reference> of another system embodying the invention; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> shows a schematic block diagram similar to <cross-reference target="DRAWINGS">FIG. 2</cross-reference> of a modified form of speech processing apparatus for use in the system shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>; and </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> shows a block schematic diagram similar to <cross-reference target="DRAWINGS">FIG. 3</cross-reference> of a client suitable for use in the system shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>.</paragraph>
</summary-of-invention>
<detailed-description>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows by way of a block diagram a system <highlight><bold>1</bold></highlight> comprising a speech processing apparatus or server <highlight><bold>2</bold></highlight> coupled to a number of clients <highlight><bold>3</bold></highlight> and to a look-up service <highlight><bold>4</bold></highlight> via a network N. As shown for one client in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, each client <highlight><bold>3</bold></highlight> comprises a processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>, an audio device <highlight><bold>5</bold></highlight> and a control apparatus <highlight><bold>34</bold></highlight>. The control apparatus <highlight><bold>34</bold></highlight> couples the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to the network N. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The machines are in the form of items of electrical equipment found in the office and/or home environment and capable of being adapted for communication and/or control over a network N. Examples of items of office equipment are, for example, photocopiers, printers, facsimile machines, digital cameras and multi-functional machines capable of copying, printing and facsimile functions while examples of items of home equipment are video cassette recorders, televisions, microwave ovens, digital cameras, lighting and heating systems and so on. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> The clients <highlight><bold>3</bold></highlight> may all be located in the same building or may be located in different buildings. The network N may be a local area Network (LAN), wide area network (WAN), an Intranet or the Internet. It will, of course, be understood that, as used herein the word &ldquo;network&rdquo; does not necessarily imply the use of any known or standard networking system or protocol and that the network N may be any arrangement that enables communication with items of equipment or machines located in different parts of the same building or in different buildings. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> The speech processing apparatus <highlight><bold>2</bold></highlight> comprises a computer system such as a workstation or the like. <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a functional block diagram of the speech processing apparatus <highlight><bold>2</bold></highlight>. The speech processing apparatus <highlight><bold>2</bold></highlight> has a main processor unit <highlight><bold>20</bold></highlight> which, as is known in the art, includes a processor arrangement (CPU) and memory such as RAM, ROM and generally also a hard disk drive. The speech processing apparatus <highlight><bold>2</bold></highlight> also has, as shown, a removable disk drive RDD <highlight><bold>21</bold></highlight> for receiving a removable storage medium RD such as, for example, a CDROM or floppy disk, a display <highlight><bold>22</bold></highlight> and an input device <highlight><bold>23</bold></highlight> such as, for example, a keyboard and/or a pointing device such as a mouse. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Program instructions for controlling operation of the CPU and data are supplied to the main processor unit <highlight><bold>20</bold></highlight> in at least one of two ways: </paragraph>
<paragraph id="P-0032" lvl="1"><number>&lsqb;0032&rsqb;</number> 1) as a signal over the network N; and </paragraph>
<paragraph id="P-0033" lvl="1"><number>&lsqb;0033&rsqb;</number> 2) carried by a removable data storage medium RD. Program instructions and data will be stored on the hard disk drive of the main processor unit <highlight><bold>20</bold></highlight> in known manner. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates block schematically the main functional components of the main processor unit <highlight><bold>20</bold></highlight> of the speech processing apparatus <highlight><bold>2</bold></highlight> when programmed by the aforementioned program instructions. Thus, the main processor unit <highlight><bold>20</bold></highlight> is programmed so as to provide: an automatic speech recognition (ASR) engine <highlight><bold>201</bold></highlight> for recognising speech data input to the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N from the control apparatus <highlight><bold>34</bold></highlight> of any of the clients <highlight><bold>3</bold></highlight>; a grammar module <highlight><bold>202</bold></highlight> for storing grammars defining the rules that spoken commands must comply with and words that may be used in spoken commands; and a speech interpreter module <highlight><bold>203</bold></highlight> for interpreting speech data recognised using the ASR engine <highlight><bold>201</bold></highlight> to provide instructions that can be interpreted by the control apparatus <highlight><bold>34</bold></highlight> to cause the associated processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to carry out the function required by the user. The main processor unit <highlight><bold>20</bold></highlight> also includes a connection manager <highlight><bold>204</bold></highlight> for controlling overall operation of the main processor unit <highlight><bold>20</bold></highlight> and communicating via the network N with the control apparatus <highlight><bold>34</bold></highlight> so as to receive audio data and to supply instructions that can be interpreted by the control apparatus <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> As will be appreciated by those skilled in the art, any known form of automatic speech recognition engine <highlight><bold>201</bold></highlight> may be used. Examples are the speech recognition engines produced by Nuance, Lernout and Hauspie, by IBM under the Trade Name &ldquo;ViaVoice&rdquo; and by Dragon Systems Inc. under the Trade Name &ldquo;Dragon Naturally Speaking&rdquo;. As will be understood by those skilled in the art, communication with the automatic speech recognition engine is via a standard software interface known as &ldquo;SAPI&rdquo; (speech application programmers interface) to ensure compatibility with the remainder of the system. In this case, the Microsoft SAPI is used. The grammars stored in the grammar module may initially be in the SAPI grammar format. Alternatively, the server <highlight><bold>2</bold></highlight> may include a grammar pre-processor for converting grammars in a non-standard form to the SAPI grammar format. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a block schematic diagram of a client <highlight><bold>3</bold></highlight>. The processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>comprises a device operating system module <highlight><bold>30</bold></highlight> that generally includes CPU and memory (such as ROM and/or RAM). The operating system module <highlight><bold>30</bold></highlight> communicates with machine control circuitry <highlight><bold>31</bold></highlight> that, under the control of the operating system module <highlight><bold>30</bold></highlight>, causes the functions required by the user to be carried out. The device operating system module <highlight><bold>30</bold></highlight> also communicates, via an appropriate interface <highlight><bold>35</bold></highlight>, with the control apparatus <highlight><bold>34</bold></highlight>. The machine control circuitry <highlight><bold>31</bold></highlight> will correspond to that of a conventional machine of the same type capable of carrying out the same function or functions (for example photocopying functions in the case of a photocopier) and so will not be described in any greater detail herein. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> The device operating system module <highlight><bold>30</bold></highlight> also communicates with a user interface <highlight><bold>32</bold></highlight> that, in this example, includes a display for displaying messages and/or information to a user and a control panel for enabling manual input of instructions by the user. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The device operating system module <highlight><bold>30</bold></highlight> may also communicate with an instruction interface <highlight><bold>33</bold></highlight> that, for example, may include a removable disk drive and/or a network connection for enabling program instructions and/or data to be supplied to the device operating system module <highlight><bold>30</bold></highlight> either initially or as an update of the original program instructions and/or data. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> In this embodiment, the control apparatus <highlight><bold>34</bold></highlight> of a client <highlight><bold>3</bold></highlight> is a JAVA virtual machine <highlight><bold>34</bold></highlight>. The JAVA virtual machine <highlight><bold>34</bold></highlight> comprises processor capability and memory (RAM and/or ROM and possibly also hard disk capacity) storing program instructions and data for configuring the virtual machine <highlight><bold>34</bold></highlight> to have the functional elements shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. The program instructions and data may be pre-stored in the memory or may be supplied as a signal over the network N or may be provided on a removable storage medium receivable in a removable disc drive associated with the JAVA virtual machine or, indeed, supplied via the network N from a removable storage medium in the removable disc disc drive <highlight><bold>21</bold></highlight> of the speech processing apparatus. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The functional elements of the JAVA virtual machine include a dialog manager <highlight><bold>340</bold></highlight> which co-ordinates the operation of the other functional elements of the JAVA virtual machine <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The dialog manager <highlight><bold>340</bold></highlight> communicates with the device operating system module <highlight><bold>30</bold></highlight> via the interface <highlight><bold>35</bold></highlight> and a device interface <highlight><bold>341</bold></highlight> of the control apparatus that enables instructions to be sent to the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and details of device and job events to be received. In order to enable an operation or job to be carried out under voice control by a user, as will be described in greater detail below, the dialog manager <highlight><bold>340</bold></highlight> communicates with a script interpreter <highlight><bold>347</bold></highlight> and with a dialog interpreter <highlight><bold>342</bold></highlight> which uses a dialog file or files from a dialog file store <highlight><bold>342</bold></highlight> to enable a dialog to be conducted with the user via the device interface <highlight><bold>341</bold></highlight> and the user interface <highlight><bold>32</bold></highlight> in response to dialog interpretable instructions received from the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> In this example, dialog files are implemented in VoiceXML which is based on the World Wide Web Consortiums Industry Standard Extensible Markup Language (XML) and which provides a high-level programming interface to speech and telephony resources. VoiceXML is promoted by the VoiceXML Forum found by AT&amp;T, IBM Lucent Technologies and Motorola and the specification for version 1.0 of VoiceXML can be found at http://www.voicexml.org. Other voice-adapted mark-up languages may be used such as, for example, VoxML which is Motorola&apos;s XML based language for specifying spoken dialog. There are many text books available concerning XML, see for example &ldquo;XML Unleashed&rdquo; published by SAMS Publishing (ISBN 0-672-31514-9) which includes a chapter 20 on XML scripting languages and a chapter 40 on VoxML. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> In this example, the script interpreter <highlight><bold>347</bold></highlight> is an ECMAScript interpreter (where ECMA stands for European Computer Manufacturer&apos;s Association and ECMAScript is a non-proprietary standardised version of Netscape&apos;s JAVAScript and Microsoft&apos;s JScript). A CD-ROM and printed copies of the current ECMA-290 ECMAScript Components Specification can be obtained from ECMA <highlight><bold>114</bold></highlight> Rue du Rhone CH-1204 Geneva Switzerland. A free interpreter for ECMAScript is available from http://home.worldcom.ch/jmlugrin/fesi. As another possibility the dialog manager <highlight><bold>340</bold></highlight> may be run as an applet inside a web browser such as Internet Explorer 5 enabling use of the browser&apos;s own ECMAScript Interpreter. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> The dialog manager <highlight><bold>340</bold></highlight> also communicates with a client module <highlight><bold>343</bold></highlight> which communicates with the dialog manager <highlight><bold>340</bold></highlight>, with an audio module <highlight><bold>344</bold></highlight> coupled to the audio device <highlight><bold>5</bold></highlight> and with a server module <highlight><bold>345</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> The audio device <highlight><bold>5</bold></highlight> may be a microphone provided as an integral component or add on to the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>or may be a separately provided audio input system. For example, the audio device <highlight><bold>5</bold></highlight> may represent a connection to a separate telephone system such as a DECT telephone system or may simply consist of a separate microphone input. The audio module <highlight><bold>344</bold></highlight> for handling the audio input uses, in this example, the JavaSound 0.9 audio control system. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> The server module <highlight><bold>345</bold></highlight> handles the protocols for sending messages between the client <highlight><bold>3</bold></highlight> and the speech processing apparatus or server <highlight><bold>2</bold></highlight> over the network N thus separating the communication protocols from the main client code of the virtual machine <highlight><bold>34</bold></highlight> so that the network protocol can be changed by the speech processing apparatus <highlight><bold>2</bold></highlight> without the need to change the remainder of the JAVA virtual machine <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> The client module <highlight><bold>343</bold></highlight> provides, via the server module <highlight><bold>345</bold></highlight>, communication with the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N, enabling requests from the client <highlight><bold>3</bold></highlight> and audio data to be transmitted to the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N and enabling communications and dialog interpretable instructions provided by the speech processing apparatus <highlight><bold>2</bold></highlight> to be communicated to the dialog manager <highlight><bold>340</bold></highlight>. The dialog manager <highlight><bold>340</bold></highlight> also communicates over the network N via a look-up service module <highlight><bold>346</bold></highlight> that enables dialogs run by the virtual machine <highlight><bold>34</bold></highlight> to locate services provided on the network N using the look-up service <highlight><bold>4</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. In this example, the look-up service is a JINI service and the look-up service module <highlight><bold>346</bold></highlight> provides a class which stores registrars so that JINI enabled services available on the network N can be discovered quickly. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> As will be seen from the above, the dialog manager <highlight><bold>340</bold></highlight> forms the central part of the virtual machine <highlight><bold>34</bold></highlight>. Thus, the dialog manager <highlight><bold>340</bold></highlight>: receives input and output requests from the dialog interpreter <highlight><bold>342</bold></highlight>; passes output requests to the client module <highlight><bold>343</bold></highlight>; receives recognition results (dialog interpretable instructions) from the client module <highlight><bold>343</bold></highlight>; and interfaces to the machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>, via the device interface <highlight><bold>341</bold></highlight>, both sending instructions to the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and receiving event data from the machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>. As will be seen, audio communication is handled via the client module <highlight><bold>343</bold></highlight> and is thus separated from the dialog manager <highlight><bold>340</bold></highlight>. This has the advantage that dialog communication with the device operating system module <highlight><bold>30</bold></highlight> can be carried out without having to use spoken commands, if the network connection fails or is unavailable. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> The device interface <highlight><bold>341</bold></highlight> stores as a device object the information necessary for the JAVA virtual machine to determine the functions that can be carried out by the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and also enables registration in the dialog manager <highlight><bold>340</bold></highlight> of a device listener which receives notifications of events set by the machine control circuitry <highlight><bold>31</bold></highlight> such as, for example, when the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>runs out of paper or toner in the case of a multi-function device or photocopier or when an event has occurred at the machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>which would affect the performance of a job, for example whether or not a document is present in a hopper in the case of a multifunctional device or photocopier. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> In addition the device interface enables implementation by the JAVA virtual machine of any number of device specific methods including public methods which return Devicejob which is a wrapper around job such as printing or sending a fax which provides the client module <highlight><bold>343</bold></highlight> with the ability to control and monitor the progress of the job. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> In operation of the JAVA virtual machine <highlight><bold>34</bold></highlight>, the dialog interpreter <highlight><bold>342</bold></highlight> sends requests and pieces of script to the dialog manager <highlight><bold>340</bold></highlight>. Each request may represent or cause a dialog state change and consists of: a prompt; a recognition grammar; details of the device events to wait for; and details of the job events to monitor. Of course, dependent upon the particular request, the events and jobs to monitor may have a null value, indicating that no device events are to be waited for or no jobs events are be monitored. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The operation of the system <highlight><bold>1</bold></highlight> will now be described with reference to the use of a single client <highlight><bold>3</bold></highlight> comprising a multi-functional device capable of facsimile, copying and printing operations. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a flow chart illustrating the main steps carried out by the multi-function machine to carry out a job in accordance with a user&apos;s verbal instructions. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Initially, a voice-control session must be established at step S<highlight><bold>5</bold></highlight>. In this embodiment, this is initiated by the user activating a &ldquo;voice-control&rdquo; button or switch of the user interface <highlight><bold>32</bold></highlight> of the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a</italic></highlight>. In response to activation of the voice control switch, the device operating system module <highlight><bold>30</bold></highlight> communicates with the JAVA virtual machine <highlight><bold>34</bold></highlight> via the device interface <highlight><bold>341</bold></highlight> to cause the dialog manager <highlight><bold>340</bold></highlight> to instruct the client module <highlight><bold>343</bold></highlight> to seek, via the server module <highlight><bold>345</bold></highlight>, a slot on the speech processing apparatus or server <highlight><bold>2</bold></highlight>. When the server <highlight><bold>2</bold></highlight> responds to the request and allocates a slot, then the session connection is established. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Once the session connection has been established, then the dialog interpreter <highlight><bold>342</bold></highlight> sends an appropriate request and any relevant pieces of script to the dialog manager <highlight><bold>340</bold></highlight>. In this case, the request will include a prompt for causing the device operating system module <highlight><bold>30</bold></highlight> of the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to display on the user interface <highlight><bold>32</bold></highlight> a welcome message such as: &ldquo;Welcome to this multifunction machine. What would you like to do&quest;&rdquo; The dialog manager <highlight><bold>340</bold></highlight> also causes the client and server modules <highlight><bold>343</bold></highlight> and <highlight><bold>345</bold></highlight> to send to the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N the recognition grammar information in the request from the dialog interpreter so as to enable the appropriate grammar or grammars to be loaded by the ASR engine <highlight><bold>201</bold></highlight> (Step S<highlight><bold>6</bold></highlight>). </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> Step S<highlight><bold>6</bold></highlight> is shown in more detail in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. Thus, at step S<highlight><bold>60</bold></highlight>, when the user activates the voice control switch on the user interface <highlight><bold>32</bold></highlight>, the client module <highlight><bold>343</bold></highlight> requests, via the server module <highlight><bold>345</bold></highlight> and the network N, a slot on the server <highlight><bold>2</bold></highlight>. The client module <highlight><bold>343</bold></highlight> then waits at step S<highlight><bold>61</bold></highlight> for a response from the server indicating whether or not there is a free slot. If the answer at step S<highlight><bold>61</bold></highlight> is no, then the client module <highlight><bold>343</bold></highlight> may simply wait and repeat the request. If the client module <highlight><bold>343</bold></highlight> determines after a predetermined period of time that the server is still busy, then the client module <highlight><bold>343</bold></highlight> may cause the dialog manager <highlight><bold>340</bold></highlight> to instruct the device operating system module <highlight><bold>30</bold></highlight> (via the device interface), to display to the user on the user interface <highlight><bold>32</bold></highlight> a message along the lines of: &ldquo;please wait while communication with the server is established&rdquo;. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> When the server <highlight><bold>2</bold></highlight> has allocated a slot to the device <highlight><bold>3</bold></highlight>, then the dialog manager <highlight><bold>340</bold></highlight> and client module <highlight><bold>343</bold></highlight> cause, via the server module <highlight><bold>345</bold></highlight>, instructions to be transmitted to the server <highlight><bold>2</bold></highlight> identifying the initial grammar file or files required for the ASR engine <highlight><bold>201</bold></highlight> to perform speech recognition on the subsequent audio data (step S<highlight><bold>62</bold></highlight>) and then (step S<highlight><bold>63</bold></highlight>) to cause the user interface <highlight><bold>32</bold></highlight> to display the welcome message. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Returning to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, at step S<highlight><bold>7</bold></highlight> spoken instructions received as audio data by the audio device <highlight><bold>5</bold></highlight> are processed by the audio module <highlight><bold>344</bold></highlight> and supplied to the client module <highlight><bold>343</bold></highlight> which transmits the audio data, via the server module <highlight><bold>345</bold></highlight>, to the speech processing apparatus or server <highlight><bold>2</bold></highlight> over the network N in blocks or bursts at a rate of, typically, 16 or second bursts per second. In this embodiment, the audio data is supplied as raw 16 bit 8 kHz format audio data. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> The JAVA virtual machine <highlight><bold>34</bold></highlight> receives data/instructions from the server <highlight><bold>2</bold></highlight> via the network N at step S<highlight><bold>8</bold></highlight>. These instructions are transmitted via the client module <highlight><bold>343</bold></highlight> to the dialog manager <highlight><bold>340</bold></highlight>. The dialog manager <highlight><bold>340</bold></highlight> accesses the dialog interpreter <highlight><bold>342</bold></highlight> which uses the dialog file stored in the dialog store <highlight><bold>343</bold></highlight> to interpret the instructions received from the speech processing apparatus <highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> The dialog manager <highlight><bold>340</bold></highlight> determines from the result of the interpretation whether the data/instructions received are sufficient to enable a job to be carried out by the device (step S<highlight><bold>9</bold></highlight>). Whether or not the dialog manager <highlight><bold>340</bold></highlight> determines that the instructions are complete will depend upon the functions available on the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>and the default settings, if any, determined by the dialog file. For example, the arrangement may be such that the dialog manager <highlight><bold>340</bold></highlight> understands the instruction &ldquo;copy&rdquo; to mean only a single copy is required and will not request further information from the user. Alternatively, the dialog file may require further information from the user when he simply instructs the machine to &ldquo;copy&rdquo;. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> When the dialog manager <highlight><bold>340</bold></highlight> determines that further information is required from the user then further processing is performed at step S<highlight><bold>10</bold></highlight> and steps S<highlight><bold>9</bold></highlight> and S<highlight><bold>10</bold></highlight> are repeated until the answer at step S<highlight><bold>9</bold></highlight> is YES. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows in greater detail the step S<highlight><bold>10</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. Thus, at step S<highlight><bold>101</bold></highlight>, a new dialog state is entered in response to the interpretation by the dialog interpreter of the machine interpretable instructions. Thus, for example, where the original spoken instruction was the instruction &ldquo;copy&rdquo; and the multifunction machines requires further information (such as the number of copies, size and darkness of copies), then the JAVA virtual machine will enter a dialog state awaiting commands relating to those features. Thus for example, the JAVA virtual machine <highlight><bold>34</bold></highlight> may cause a prompt along the lines of &ldquo;how many copies do you require&quest;&rdquo; to be displayed in the user interface <highlight><bold>32</bold></highlight>. When, at step S<highlight><bold>102</bold></highlight>, further speech data is received from the user via the audio device <highlight><bold>5</bold></highlight>, the client module <highlight><bold>343</bold></highlight> will transmit that speech data to the server <highlight><bold>2</bold></highlight> together with instructions identifying the speech recognition grammar to be used for that particular dialog state. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> It is, of course, possible, particularly where a user is unfamiliar with a particular multifunction machine, that the user will ask the machine to perform functions that are not available on that machine, for example the user may ask for an A3 copy where the particular machine is only capable of producing A4 copies. Where the grammar or grammars associated with the particular multifunctional machine do not include words or rules for enabling identification of functions not available on that machine, then the speech processing apparatus will simply return machine interpretable instructions that enable the dialog manager <highlight><bold>340</bold></highlight> to cause the user interface <highlight><bold>32</bold></highlight> to display a method such as, for example: &ldquo;command not recognised&rdquo;. This, however, is not particularly helpful to a user. Accordingly, in a preferred arrangement, the grammar or grammars associated with the multi-function machine may include the rules or words necessary for identifying functions that may be carried out by machines of the same type but are not available on this particular machine. In this case, if the dialog manager <highlight><bold>340</bold></highlight> determines from the information in the device interface <highlight><bold>341</bold></highlight> that these features cannot be set on this particular machine then a prompt will be displayed to the user at step S<highlight><bold>10</bold></highlight> saying, for example: &ldquo;This machine cannot produce A<highlight><bold>3</bold></highlight> copies&rdquo;. The dialog manager may then wait for further instructions from the user. As an alternative to simply advising the user that the machine is incapable of providing the function required, the dialog manager <highlight><bold>340</bold></highlight> may, when it determines that the machine cannot carry out a requested function, access the JINI look-up service <highlight><bold>4</bold></highlight> over the network N via the look-up service module <highlight><bold>346</bold></highlight> to determine whether there are any machines coupled to the network N that are capable of providing the required function and, if so, will cause the device operating system module <highlight><bold>30</bold></highlight> to display a message to the user on the display of the user interface <highlight><bold>32</bold></highlight> at step S<highlight><bold>10</bold></highlight> saying, for example: &ldquo;This machine cannot produce double-sided copies. However, the photocopier on the first floor can&rdquo;. The machine would then return to step S<highlight><bold>7</bold></highlight> awaiting further instructions from the user. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> When the data/instructions received at step S<highlight><bold>9</bold></highlight> are sufficient to enable the job to be carried out, then at step S<highlight><bold>11</bold></highlight> the dialog manager <highlight><bold>340</bold></highlight> registers a job listener to detect communications from the device operating system module <highlight><bold>30</bold></highlight> related to the job to be carried out, and communicates with the device operating system module <highlight><bold>30</bold></highlight> to instruct the processor-controlled machine to carry out the job. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> If at step S<highlight><bold>12</bold></highlight> the job listener detects an event, then the dialog manager <highlight><bold>340</bold></highlight> converts this to, in this example, a Voice XML event and passes it to the dialog interpreter <highlight><bold>342</bold></highlight> which, in response, instructs the dialog manager <highlight><bold>340</bold></highlight> causes a message to be displayed to the user at step S<highlight><bold>13</bold></highlight> related to that event. For example, if the job listener determines that the multi-function device has run out of paper or toner or a fault has occurred in the copying process (for example, a paper jam or like fault) then the dialog manager <highlight><bold>340</bold></highlight> will cause a message to be displayed to the user at step S<highlight><bold>13</bold></highlight> advising them of the problem. At this stage a dialog state may be entered that enables a user to request context-sensitive help with respect to the problem. When the dialog manager <highlight><bold>340</bold></highlight> determines from the job listener that the problem has been resolved at step S<highlight><bold>14</bold></highlight>, then the job may be continued. Of course, if the dialog manager <highlight><bold>340</bold></highlight> determines that the problem has not been resolved at step S<highlight><bold>14</bold></highlight>, then the dialog manager <highlight><bold>340</bold></highlight> may cause the message to continue to be displayed to the user or may cause other messages to be displayed prompting the user to call the engineer (step S<highlight><bold>15</bold></highlight>). </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> Assuming that any problem is resolved, then the dialog manager <highlight><bold>340</bold></highlight> then waits at step S<highlight><bold>16</bold></highlight> for an indication from the job listener that the job has been completed. When the job has been completed, then the dialog manager <highlight><bold>340</bold></highlight> may cause the user interface <highlight><bold>32</bold></highlight> to display to the user a &ldquo;job complete&rdquo; message at step <highlight><bold>16</bold></highlight><highlight><italic>a</italic></highlight>. The dialog manager <highlight><bold>340</bold></highlight> then communicates with the speech processing apparatus <highlight><bold>2</bold></highlight> to cause the session to be terminated at steps S<highlight><bold>16</bold></highlight><highlight><italic>b</italic></highlight>, thereby freeing the slot on the speech processing apparatus for another processor-controlled machine. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> It will, of course, be appreciated that, dependent upon the particular instructions received and the dialog file, the dialog state may or may not change each time the further processing step S<highlight><bold>10</bold></highlight> is repeated for a particular job and that, moreover, different grammar files may be associated with different dialog states. Where a different dialog state requires a different grammar file then, of course, the dialog manager <highlight><bold>340</bold></highlight> will cause the client module <highlight><bold>343</bold></highlight> to send data identifying the new grammar file to the speech processing apparatus <highlight><bold>2</bold></highlight> in accordance with the request from the dialog interpreter <highlight><bold>342</bold></highlight> so that the ASR engine <highlight><bold>201</bold></highlight> uses the correct grammar files for subsequent audio data. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> shows a flow chart for illustrating the main steps carried out by the server <highlight><bold>2</bold></highlight> assuming that the connection manager <highlight><bold>204</bold></highlight> has already received a request for a slot from the control apparatus <highlight><bold>34</bold></highlight> and has granted the control apparatus a slot. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> At step S<highlight><bold>17</bold></highlight> the connection manager <highlight><bold>204</bold></highlight> receives from the control apparatus <highlight><bold>34</bold></highlight> instructions identifying the required grammar file or files. At step S<highlight><bold>18</bold></highlight>, the connection manager <highlight><bold>204</bold></highlight> causes the identified grammar or grammars to be loaded into the ASR engine <highlight><bold>201</bold></highlight> from the grammar module <highlight><bold>202</bold></highlight>. As audio data is received from the control apparatus <highlight><bold>34</bold></highlight> at step S<highlight><bold>19</bold></highlight>, the connection manager <highlight><bold>204</bold></highlight> causes the required grammar rules to be activated and passes the received audio data to the ASR engine <highlight><bold>201</bold></highlight> at step S<highlight><bold>20</bold></highlight>. At step S<highlight><bold>21</bold></highlight>, the connection manager <highlight><bold>204</bold></highlight> receives the result of the recognition process (the &ldquo;recognition result&rdquo;) from the ASR engine <highlight><bold>201</bold></highlight> and passes it to the speech interpreter module <highlight><bold>203</bold></highlight> which interprets the recognition result to provide an utterance meaning that can be interpreted by the dialog interpreter <highlight><bold>342</bold></highlight> of the device <highlight><bold>3</bold></highlight>. When the connection manager <highlight><bold>204</bold></highlight> receives the utterance meaning from the speech interpreter module <highlight><bold>203</bold></highlight>, it communicates with the server module <highlight><bold>345</bold></highlight> over the network N and transmits the utterance meaning to the control apparatus <highlight><bold>34</bold></highlight>. The connection manager <highlight><bold>204</bold></highlight> then waits at step S<highlight><bold>24</bold></highlight> for further communications from the server module <highlight><bold>345</bold></highlight> of the control apparatus <highlight><bold>34</bold></highlight>. If a communication is received indicating that the job has been completed, then the session is terminated and the connection manager <highlight><bold>204</bold></highlight> releases the slot for use by another device or job. Otherwise steps S<highlight><bold>17</bold></highlight> to S<highlight><bold>24</bold></highlight> are repeated. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> It will be appreciated that during a session the ASR engine <highlight><bold>201</bold></highlight> and speech interpreter module <highlight><bold>203</bold></highlight> function continuously with the ASR engine <highlight><bold>201</bold></highlight> recognising received audio data as and when it is received. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> The connection manager <highlight><bold>204</bold></highlight> may be arranged to retrieve the grammars that may be required by a control apparatus connected to a particular processor-controlled machine and store them in the grammar module <highlight><bold>202</bold></highlight> upon first connection to the network. Information identifying the location of the grammar(s) may be provided in the device interface <highlight><bold>341</bold></highlight> and supplied to the connection manager <highlight><bold>204</bold></highlight> by the dialog manager <highlight><bold>340</bold></highlight> when the processor-controlled machine is initially connected to the network by the control apparatus <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> It would be possible to provide each individual processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>with its own unique grammar or set of grammars that includes the rules for every possible function that a user may request via that particular machine. However, providing independent different grammars for each processor-controlled machine may result in duplication of rules between grammars. Thus, for example, providing one multi-function machine capable of photocopying and facsimile functions with its own unique grammar will inevitably result in duplication of rules between that grammar and the grammar for another different multi-function machine capable of the same or similar functions or, indeed, a photocopier capable of carrying out the same photocopy functions, for example. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> In order to address this problem, the grammars stored in the grammar module <highlight><bold>202</bold></highlight> are configured so as to enable linking of two or more grammars by an interface grammar in accordance with linking instructions received from the dialog manager <highlight><bold>340</bold></highlight> in accordance with the dialog state. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows a very simplified functional block diagram of a grammar store <highlight><bold>202</bold></highlight><highlight><italic>a </italic></highlight>within the grammar module <highlight><bold>202</bold></highlight> to illustrate the linking of grammars. Thus, <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows grammars A and B that can be linked by an interface grammar I. The grammar A is configured to use grammar rules defined by the interface grammar I while the grammar B is configured to implement rules defined by the interface grammar I. Normally, the grammars A and B are independent. However, these grammars will be linked together by the interface grammar I by instructions provided by the JAVA virtual machine <highlight><bold>34</bold></highlight> when the dialog state indicates that linking of the grammars is required. This enables, in the case of a multifunction machine, for example, the grammar A to define grammar rules generic to a multiplicity of multi-function machines and grammar B to implement rules related to functions specific to that particular multi-function machine so that, for example, the grammar A can include grammar rules relating to commands such as &ldquo;copy&rdquo;, &ldquo;fax&rdquo;, &ldquo;print&rdquo; while grammar B can implement rules relating to, for example, copying options such as single-sided, double-sided etc., paper size such as A4, A3 etc and copy darkness, for example. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> In the grammar store <highlight><bold>202</bold></highlight><highlight><italic>a </italic></highlight>shown functionally in <cross-reference target="DRAWINGS">FIG. 8, a</cross-reference> single grammar A is linked via an interface grammar I to a grammar B. The grammar store <highlight><bold>202</bold></highlight><highlight><italic>a </italic></highlight>may, however, include a plurality of grammars A each linkable to a corresponding grammar B via an interface grammar I. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> More than one grammar A may import interface I while more than one grammar B may implement rules defined by the interface I. The particular grammars A and B to be linked will be defined by the instructions related to the particular dialog state. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> In addition, a plurality of different interfaces I may be provided so as to enable connection of grammars in a cascade. Thus, grammar B may, in addition to implementing rules B defined by the interface I, use rules implemented by a grammar C and defined by an interface J (not shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>). Also a first a grammar may be configured to import different interface grammars each of which defines rules implementable by a different second grammar or different set of second grammars. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> The linking of grammars by an interface grammar also has the advantage that the developer or designer of a grammar need know nothing about any other grammars. All that the developer or designer of a grammar needs to know about is the characteristics and requirements of the interface grammar. Moreover, as set out above, a particular grammar A may be linked by the same interface grammar A to different grammars B dependant upon the circumstances. Thus, for example, a generic facsimile grammar A may be linked by the interface grammar I to a first specific facsimile grammar B by the dialog file for one specific type of facsimile machine and to a different specific facsimile grammar B by the dialog file for another specific facsimile machine. Also, a multifunction grammar A may be linked by the interface I to a copy grammar B when the function required of the multifunction machine is copying process and to a facsimile grammar B when the function required is a facsimile function. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> This enables flexibility in the generation of the grammars and should allow, for example, standardisation of generic grammars which can be linked via an appropriate interface grammar or grammars to grammars specific to specific processor-controlled machines. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> Another example which illustrates this is the case where the processor-controlled machine is facsimile machine. In this case, grammar A may be a grammar generic to all facsimile machines while grammar B may include functionalities specific to that type of facsimile machine, for example, the ability to delay transmission to a predetermined time. In this case the interface grammar I would define rules relating to spoken commands concerning time and date and these would be implemented by time and date grammar B. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> As will be appreciated from the above, linking between grammars is a dynamic process and whether or not linking occurs depends upon the particular dialog state. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> In contrast, although conventional systems may allow a first grammar to import a second grammar, the first grammar needs to identify the specific second grammar to be imported and accordingly in a conventional system a specific grammar A can only ever be linked with a specific grammar B. Thus, for example, in a conventional system a specific digital camera grammar may be designed to import a specific printer grammar which would enable printing of images from that camera only by the printer associated with the specific printer grammar and not by printers associated with different printer grammars. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows a functional block diagram similar to <cross-reference target="DRAWINGS">FIG. 3</cross-reference> for the case where the processor-controlled machine <highlight><bold>3</bold></highlight> is a digital camera. As can be seen from a comparison of <cross-reference target="DRAWINGS">FIGS. 3 and 9</cross-reference>, the digital camera <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference> has the same general functional components as the generic processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> except that, of course, the device operating system module is of course a specifically adapted camera operating system module <highlight><bold>30</bold></highlight> and the machine control circuitry is digital camera control circuitry <highlight><bold>31</bold></highlight>. The JAVA virtual machine <highlight><bold>34</bold></highlight> has the same general functional components as set out in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. In this case the device interface <highlight><bold>341</bold></highlight> comprises a camera object. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> In addition to the components shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the JAVA virtual machine for the digital camera includes a printer service <highlight><bold>347</bold></highlight> and a printer chooser service <highlight><bold>348</bold></highlight>. The printer service <highlight><bold>347</bold></highlight> and printer chooser service <highlight><bold>348</bold></highlight> may be downloaded by the JAVA virtual machine <highlight><bold>34</bold></highlight> from the network using the JINI look-up service <highlight><bold>4</bold></highlight> when the JAVA virtual machine <highlight><bold>34</bold></highlight> first couples the camera <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to the network. The printer chooser service <highlight><bold>348</bold></highlight> uses the local JINI registrars in the look-up service module <highlight><bold>346</bold></highlight> to determine from the JINI look-up service <highlight><bold>4</bold></highlight> coupled to the network the available printers and information relating to the name by which these printers are identified. Once the printer chooser service <highlight><bold>347</bold></highlight> has identified the available printers, then the dialog manager <highlight><bold>340</bold></highlight> can conduct a dialog with the user via the user interface <highlight><bold>32</bold></highlight>. Thus, the dialog manager <highlight><bold>340</bold></highlight> will cause instructions to be sent to the speech processing apparatus to access a printer chooser grammar that includes rules relating to printer choice and will then cause the user interface <highlight><bold>32</bold></highlight> to display to the user a message identifying the available printers and prompting a selection by the user. When a response is received from the user, the dialog manager <highlight><bold>340</bold></highlight> will cause the client module <highlight><bold>343</bold></highlight> and server module <highlight><bold>345</bold></highlight> to send the received speech data to the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N for processing using the printer chooser grammar. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> When the speech processing apparatus <highlight><bold>2</bold></highlight> returns the dialog interpretable instructions identifying the user&apos;s printer choice, the dialog manage <highlight><bold>340</bold></highlight> causes a JINI service object associated with the selected printer to be downloaded to form a printer service object <highlight><bold>347</bold></highlight> in the JAVA virtual machine <highlight><bold>34</bold></highlight> of the digital camera. This printer service object acts to emulate the functionality of the printer so that the digital camera JAVA virtual machine <highlight><bold>34</bold></highlight> can conduct a dialog with the user to obtain all information necessary to enable printing as required by the user without having to communicate with the printer until the printer service object <highlight><bold>347</bold></highlight> determines that all the information necessary for carrying out the job has been obtained. The printer service object <highlight><bold>347</bold></highlight> also enables communication with the selected printer during the carrying out of a printing operation so that the dialog manager <highlight><bold>340</bold></highlight> can advise the user of any events specific to the printer such as, for example, the lack of printing paper or a paper jam as described above with reference to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> The digital camera and selected printer are associated with their own respective grammar or grammars. However, as explained above with reference to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, the grammars in the grammar store <highlight><bold>202</bold></highlight><highlight><italic>a </italic></highlight>are configured so that a camera grammar can be linked with a printer grammar via an interface grammar I in accordance with linking instructions provided by the dialog manager <highlight><bold>340</bold></highlight> when the dialog is in an appropriate dialog state. This means that the camera grammar and dialog need know nothing about the available printers and their grammars and dialogs and also that the printer grammars need have no information about the digital cameras that may be coupled to the network. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The information necessary for the dialog manager <highlight><bold>340</bold></highlight> to instruct linking of the camera grammar with the printer grammar specific to the selected printer will be determined from the information provided by the printer service object <highlight><bold>348</bold></highlight>. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> The following illustrates in broad outline how grammar A, in this case a printer grammar called &ldquo;printergrammar&rdquo;, may be linked to grammar B, in this case a camera grammar called &ldquo;photograph_grammar&rdquo;, via an interface grammar I called &ldquo;document_grammar&rdquo;. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> In this case, the printer grammar &ldquo;printergrammar&rdquo; has the following general format: </paragraph>
<paragraph id="P-0090" lvl="2"><number>&lsqb;0090&rsqb;</number> grammar printergrammar: </paragraph>
<paragraph id="P-0091" lvl="2"><number>&lsqb;0091&rsqb;</number> import&lt;document_grammar.*&gt;; </paragraph>
<paragraph id="P-0092" lvl="1"><number>&lsqb;0092&rsqb;</number> public &lt;Printoption&gt;&equals;(&lt;printoption&gt;&verbar;&lt;documentoption&gt;)&plus;; </paragraph>
<paragraph id="P-0093" lvl="1"><number>&lsqb;0093&rsqb;</number> private &lt;printoption&gt;&equals;A3&verbar;A4&verbar;high resolution &verbar; . . . ; </paragraph>
<paragraph id="P-0094" lvl="1"><number>&lsqb;0094&rsqb;</number> while the interface grammar &ldquo;document_grammar&rdquo; has the general format: </paragraph>
<paragraph id="P-0095" lvl="2"><number>&lsqb;0095&rsqb;</number> grammarinterface document_grammar; </paragraph>
<paragraph id="P-0096" lvl="2"><number>&lsqb;0096&rsqb;</number> public &lt;documentoption&gt;; </paragraph>
<paragraph id="P-0097" lvl="1"><number>&lsqb;0097&rsqb;</number> and the camera grammar called &ldquo;photograph_grammar&rdquo; has, in broad outline, the following format: </paragraph>
<paragraph id="P-0098" lvl="2"><number>&lsqb;0098&rsqb;</number> photograph_grammar implements document_grammar; </paragraph>
<paragraph id="P-0099" lvl="2"><number>&lsqb;0099&rsqb;</number> &lt;documentoption&gt;&equals;panorama format&verbar; . . . ; </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> It will be seen from the above that the printer grammar &ldquo;printer_grammar&rdquo; imports the interface grammar named &ldquo;document_grammar&rdquo; while the interface grammar &ldquo;document_grammar&rdquo; defines a public grammar rule &ldquo;documentoption&rdquo; and the photograph grammar &ldquo;photograph_grammar&rdquo; implements that grammar rule. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> In this case, in order to link the grammars &ldquo;printergrammar&rdquo; and &ldquo;photograph_grammar&rdquo; via the &ldquo;document_grammar&rdquo; interface grammar, the dialog file will contain, for the appropriate dialog states, a command along the following lines: </paragraph>
<paragraph id="P-0102" lvl="2"><number>&lsqb;0102&rsqb;</number> dialog file </paragraph>
<paragraph id="P-0103" lvl="1"><number>&lsqb;0103&rsqb;</number> &lt;inputgrammar&equals;&ldquo;printergrammar printoptionlink: </paragraph>
<paragraph id="P-0104" lvl="2"><number>&lsqb;0104&rsqb;</number> document_grammar&equals;photograph_grammar&rdquo;&gt;</paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> It will, of course, be appreciated that the above-mentioned dialog file command will occupy a single line in the relevant dialog file and is only split into two lines for convenience. It will also be appreciated that there is no significance in the different format of the grammar names and that, for example, &ldquo;printer grammar&rdquo; could be &ldquo;printer_grammar&rdquo; for example. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> In the example grammars and dialog file given above the ellipsis indicate the possibility of further rules in the grammar. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> It will, of course, be appreciated that the specific rules and methods given above are only examples and that there may be many more or different rules and methods with the only requirements being that the interface grammar defines rules implementable by one grammar, the other grammar uses the grammar rules defined in the interface grammar and the dialog files provide, in the appropriate dialog states, instructions for the speech processing apparatus to link the two grammars using the interface grammar to form an extended, in the above example, &ldquo;camera plus printer&rdquo; grammar. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> It will be appreciated by the person skilled in the art that the general grammar and dialog format described above may be applied to any grammars A and B to be linked together by an interface grammar I. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> The embodiment described above with reference to <cross-reference target="DRAWINGS">FIG. 9</cross-reference> can, of course, be applied to any circumstance where one processor-controlled machine makes use of an independently supplied service, e.g. a printing service in the case of the digital camera. Thus, for example, the service may be an address book accessible by a facsimile machine or multi-function machine capable of facsimile operation for providing facsimile addresses or accessible by a computer or telephone having e-mail capability for providing e-mail addresses. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> In the above described embodiment, each processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>is directly coupled to its own control apparatus <highlight><bold>34</bold></highlight> which communicates with the speech processing apparatus <highlight><bold>2</bold></highlight> over the network N. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> In the above described embodiment, a dialog is conducted with a user by displaying messages to the user. It may however be possible to include on a client a speech synthesis unit controllable by the JAVA virtual machine to enable a fully spoken or oral dialog. This may be particularly advantageous where the processor-controlled machine has only a small display. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> Where such a fully spoken or oral dialog is to be conducted, then requests from the dialog interpreter <highlight><bold>342</bold></highlight> will include a &ldquo;barge-in flag&rdquo; to enable a user to interrupt spoken dialog from the control apparatus when the user is sufficiently familiar with the functionality of the machine to be controlled that he knows exactly the voice commands to issue to enable correct functioning of that machine. Where a speech synthesis unit is provided, then in the system shown in <cross-reference target="DRAWINGS">FIGS. 10 and 11</cross-reference> the dialog with the user may be conducted via the user&apos;s telephone <highlight><bold>5</bold></highlight> rather than via a user interface of either the control apparatus <highlight><bold>34</bold></highlight> or the user interface of the processor-controlled machine and, in the system shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference> by providing the audio device <highlight><bold>5</bold></highlight> with an audio output as well as audio input facility. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> It will be appreciated that the system shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> may be modified to enable a user to use his or her DECT telephone to issue instructions with the communication between the audio device <highlight><bold>5</bold></highlight> and the audio module <highlight><bold>343</bold></highlight> being via the DECT telephone exchange. The DECT telephone will not, of course, be associated with a particular machine. It is therefore necessary for the control apparatus <highlight><bold>34</bold></highlight> to identify in some way the processor-controlled machine <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to which the user is directing his or her voice control instructions. This may be achieved by, for example, determining the location of the mobile telephone from communication between the mobile telephone and the DECT exchange. As another possibility, each of the processor-controlled machines <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>coupled to the network may be given an identification and users instructed to initiate voice control by uttering a phrase such as &ldquo;I am at copier number 9&rdquo; or &ldquo;this is copier number 9&rdquo;. When this initial phrase is recognised by the ASR engine <highlight><bold>201</bold></highlight>, the speech interpreter module <highlight><bold>203</bold></highlight> will provide to the control apparatus <highlight><bold>34</bold></highlight> via the connection manager <highlight><bold>204</bold></highlight> dialog interpretable instructions which identify to the control apparatus <highlight><bold>34</bold></highlight> the network address of, in this case, &ldquo;copier <highlight><bold>9</bold></highlight>&rdquo;. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> Where a speech synthesis unit is provided then the dialog with the user may be completely oral. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> shows another example of a system <highlight><bold>1</bold></highlight><highlight><italic>a </italic></highlight>embodying the invention. This system is specifically adapted to enable a fully oral communication or dialog with a user. In the system <highlight><bold>1</bold></highlight><highlight><italic>a</italic></highlight>, the clients <highlight><bold>3</bold></highlight>&prime; are not provided with audio devices <highlight><bold>5</bold></highlight>. Rather, the speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>is coupled to a communications device <highlight><bold>2</bold></highlight><highlight><italic>b </italic></highlight>which, in the simplest case, may consist of a microphone and loudspeaker combination or may consist of a telecommunications interface providing for connection to a telephone via, for example, a DECT telephone communication system installed in the building containing the speech processing apparatus or via a conventional land line or mobile telecommunication system. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, the speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>of the system <highlight><bold>1</bold></highlight><highlight><italic>a </italic></highlight>differs from that shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> in that the speech processing apparatus incorporates an audio module <highlight><bold>205</bold></highlight> for receiving and processing audio data received from the communications device <highlight><bold>2</bold></highlight><highlight><italic>b </italic></highlight>in a similar manner to the audio module <highlight><bold>344</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> and also a speech synthesizer <highlight><bold>206</bold></highlight>, which under the control of the connection manager <highlight><bold>204</bold></highlight><highlight><italic>a</italic></highlight>, synthesizes spoken dialog to enable oral communication with the user via the communications device <highlight><bold>2</bold></highlight><highlight><italic>b. </italic></highlight></paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> The client <highlight><bold>3</bold></highlight>&prime; shown in <cross-reference target="DRAWINGS">FIG. 12</cross-reference> differs from that shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> in that the audio device <highlight><bold>5</bold></highlight> and audio module <highlight><bold>344</bold></highlight> are omitted. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> The speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is programmed so that, upon initial receipt of spoken commands via the communications device <highlight><bold>2</bold></highlight><highlight><italic>b</italic></highlight>, the ASR engine <highlight><bold>201</bold></highlight> uses a connection grammar from the grammar module <highlight><bold>2</bold></highlight> to recognise speech in the received audio data. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> As an example, the clients <highlight><bold>3</bold></highlight>&prime; may constitute processor-controlled machines comprising items of home equipment such as video recorders, televisions, microwaves and processor-controlled heating and lighting systems that may be coupled to the speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>via a network N. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> In operation of such a system, a user may issue instructions via the communications device <highlight><bold>2</bold></highlight><highlight><italic>b </italic></highlight>to the speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>to, for example: </paragraph>
<paragraph id="P-0121" lvl="2"><number>&lsqb;0121&rsqb;</number> &ldquo;connect me to the VCR&rdquo;. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> Once this command has been recognised by the ASR engine <highlight><bold>201</bold></highlight>, the meaning is extracted by the speech interpreter module <highlight><bold>203</bold></highlight> and the connection manager <highlight><bold>204</bold></highlight> sends over the network N a dialog interpretable instruction or command to the VCR that the dialog manager <highlight><bold>340</bold></highlight> of the VCR JAVA virtual machine <highlight><bold>34</bold></highlight> interprets as a command activating voice control. The dialog interpreter <highlight><bold>342</bold></highlight> then causes the dialog manager <highlight><bold>340</bold></highlight> to send to the speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>via the client and server modules <highlight><bold>343</bold></highlight> and <highlight><bold>345</bold></highlight> instructions for the connection manager <highlight><bold>204</bold></highlight> to cause the connection grammar to be linked with a VCR grammar in the manner described above. The VCR grammar may be pre-stored in the grammar module <highlight><bold>202</bold></highlight> or may be stored by the dialog manager <highlight><bold>340</bold></highlight> of the virtual machine <highlight><bold>34</bold></highlight> and downloaded to the speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>when requested. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> When the JAVA virtual machine <highlight><bold>34</bold></highlight> receives acknowledgement from the connection manager <highlight><bold>204</bold></highlight><highlight><italic>a </italic></highlight>that the grammar linking has been effected, then the dialog interpreter <highlight><bold>342</bold></highlight> enters a dialog state awaiting VCR command instructions and sends to the speech processing apparatus commands for causing the connection manager <highlight><bold>204</bold></highlight><highlight><italic>a </italic></highlight>to cause the speech synthesizer <highlight><bold>206</bold></highlight> to synthesize a prompt to the user saying something along the lines of: &ldquo;Connection to VCR established&rdquo;. Please input your instruction&rdquo;. The user may then use voice control commands to control operation of the VCR in a manner similar to that described above with reference to FIGS. <highlight><bold>1</bold></highlight> to <highlight><bold>9</bold></highlight> with the exception that the dialog between the user and the JAVA virtual machine <highlight><bold>34</bold></highlight> is conducted by the JAVA virtual machine <highlight><bold>34</bold></highlight> causing the speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>to supply audio prompts to the user rather than by displaying such prompts on a user interface of the VCR. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> Because the JAVA virtual machine <highlight><bold>34</bold></highlight> causes the VCR grammar to be linked with the connection grammar, when the user wishes to control another processor-controlled machine, for example a processor controlling a heating or lighting system, then the user need simply issue the command &ldquo;connect me to the lighting system&rdquo; and the ASR engine <highlight><bold>201</bold></highlight> will be able to recognise this message because the connection grammar is still loaded. Thus, it is not necessary for the user to terminate the voice control of the VCR and then request re-connection to the connection grammar to enable another client to be subject to voice control. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> It will be appreciated that the system shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> may be adapted so that the communications device <highlight><bold>2</bold></highlight><highlight><italic>b </italic></highlight>displays visual (or visual and audio) prompts to the user, for example in the case where the user is issuing voice control commands directly at the communications device <highlight><bold>2</bold></highlight><highlight><italic>b </italic></highlight>or the user has a video phone. Where visual prompts are possible then, of course, the speech synthesizer <highlight><bold>206</bold></highlight> may be omitted and the communications device need only be capable of receiving audio data. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> The communications device <highlight><bold>2</bold></highlight><highlight><italic>b </italic></highlight>may be incorporated in the speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>and the speech processing apparatus <highlight><bold>2</bold></highlight><highlight><italic>a </italic></highlight>may be portable. In this case, the link between the speech processing apparatus and a client need not necessarily be over a fixed network but may be a one-to-one remote link, for example an infra red or wireless remote link. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> In the above described example, the grammar specific to an individual client may be downloaded from the client as and when required by the speech processing apparatus so that the grammar module <highlight><bold>202</bold></highlight> does not need to store all possible grammars. This would have advantage even where the JAVA virtual machines are not capable of linking grammars although in those cases it would be necessary for the user always to return to the connection grammars between voice control of different clients. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> In the above described embodiments, grammars can be linked in accordance with the dialog state of the JAVA virtual machine so that the extent of grammar available to the automatic speech recognition engine is controlled in accordance with the dialog state of the JAVA virtual machine. This dynamic linking of grammars enables, for example, standard generic grammars to be provided, for example, generic print, copy and fax grammars containing the rules common to all types of printer, copier and facsimile machines), and for these to be linked dynamically, as and when necessary, to further grammars specific to the particular printer, copier or facsimile machine. Also, the ability to link grammars enables a function of one machine coupled to the network to be controlled by spoken demands directed to another machine coupled to the network (for example, a printer and digital camera) without either of the two machines having to have any information about the functionality of the other machine. </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> Although the present invention has particular applications and advantages to network systems, it will be appreciated that the present invention may be used in circumstances where a speech processing apparatus communicates remotely with one or more stand alone devices incorporating control apparatus as described above via, for example, a remote link such as an infra red or radio link. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> In the above described embodiments, the virtual machines <highlight><bold>34</bold></highlight> are JAVA virtual machines. There are several advantages to using JAVA. Thus, the platform independence of JAVA means that the client code is reusable on all JAVA virtual machines and, as mentioned above, use of JAVA enables use of the JINI framework and a JINI look-up service on the network. </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> It will be appreciated by those skilled in the art that it is not necessary to use the JAVA platform and that other platforms that provide similar functionality may be used. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> As used herein the term &ldquo;processor-controlled machine&rdquo; includes any processor-controlled device, system or service that can be coupled to the control apparatus to enable voice control of a function of that device, system or service. </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> Other modifications will be apparent to those skilled in the art. </paragraph>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A system comprising: 
<claim-text>at least one device having a processor-controlled machine for causing at least one function specified by a user to be carried out and a control apparatus for enabling voice-control of the processor-controlled machine and a speech processing apparatus having means for receiving speech data representing speech by a user, a grammar store storing speech recognition grammars, speech recognition means for recognising speech in the received speech data using at least one of the speech recognition grammars, speech interpreting means for interpreting the recognised speech to provide instructions for controlling at least one function of a processor-controlled machine and transmitting means for transmitting the instructions to the control apparatus, </claim-text>
<claim-text>the control apparatus being arranged to couple the processor-controlled machine to the speech processing apparatus and having means for providing speech recognition grammar instructions regarding the speech recognition grammar to be used by the speech recognition means for recognising speech data and means for transmitting speech recognition grammar instructions to the speech processing apparatus, wherein the grammar store comprises at least first and second grammars having grammar rules and at least one interface grammar defining grammar rules, the first grammar being arranged to use grammar rules defined by the interface grammar and the second grammar being arranged to implement rules defined by the interface grammar, and wherein the speech recognition grammar instructions providing means is arranged to provide instructions for causing the second grammar to be linked to the first grammar using the interface grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the control apparatus comprises a JAVA virtual machine. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the processor-controlled machine of said at least one device is arranged to carried out said at least one function. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein the processor-controlled machine is selected from the group consisting of: 
<claim-text>a photocopier, a facsimile machine, a multi-function machine, a television, a video cassette recorder, a microwave oven, a heating system, a lighting system. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the processor-controlled machine of said at least one device is arranged to cause another device coupled to the network to carry out the at least one function. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, comprising as said other device a device comprising a processor-controlled machine and a control apparatus. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein the at least one device comprises a digital camera and said other device comprises a printer. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>&excl; wherein the first grammar comprises a camera grammar and the second grammar comprises a printer grammar. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the control apparatus comprises receiving means for receiving instructions derived from speech recognised by the speech recognition means; 
<claim-text>dialog communication means for communicating with the user to provide information to the user in response to instructions received by said receiving means thereby enabling a dialog with the user, wherein the dialog communication means has a number of different dialog states and is arranged to change dialog states in response to instructions receiving by the receiving means, the control apparatus being arranged to supply to the speech processing apparatus instructions regarding the speech recognition grammar or grammars to be used in dependence upon the dialog state of the dialog communication means such that, in at least one dialog state, the control apparatus is arranged to provide instructions to cause said first and second grammars to be linked by said interface grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the control apparatus is arranged to couple the processor-controlled machine to the speech processing apparatus via a network. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A speech processing apparatus for receiving speech data representing commands spoken by a user for controlling a function of a device, the speech processing apparatus having: 
<claim-text>receiving means for receiving speech data representing speech by a user; </claim-text>
<claim-text>a grammar store storing speech recognition grammars; </claim-text>
<claim-text>speech recognition means for recognising speech in the received speech data using at least one of the speech recognition grammars; </claim-text>
<claim-text>speech interpreting means for interpreting recognised speech to provide instructions for enabling a function of a device to be controlled; and </claim-text>
<claim-text>transmitting means for transmitting the instructions to a device for enabling control of a function of that device, wherein the grammar store comprises at least first and second grammars having grammar rules and at least one interface grammar defining grammar rules, the first grammar being arranged to use grammar rules defined by the interface grammar and the second grammar being arranged to implement rules defined by the interface grammar such that the second grammar can be linked to the first grammar using the interface grammar to form an extended grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A speech processing apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the first and second grammars comprises camera and printer grammars, respectively. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A control apparatus for coupling a processor-controlled machine to speech processing apparatus for enabling a user to control a function of a machine by spoken commands, the control apparatus having: means for providing speech recognition grammar instructions defining a speech recognition grammar or grammars to be used by the speech processing apparatus means for recognising speech data; and means for transmitting to the speech processing apparatus the speech recognition grammar instructions for speech data representing words spoken by a user, the speech recognition grammar instructions providing means being arranged to provide instructions for causing first and second grammars to be linked by an interface grammar having grammar rules usable by the first grammar and implementable by the second grammar so as to form an extended grammar. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A control apparatus for enabling coupling of a processor-controlled machine to speech processing apparatus for enabling a user to control a function of the processor-controlled machine by spoken commands, the control apparatus comprising: 
<claim-text>receiving means for receiving from the speech processing apparatus instructions derived from speech recognised by the speech processing apparatus; </claim-text>
<claim-text>dialog communication means for communicating with the user to provide information to the user in response to instructions received from the speech processing apparatus thereby enabling a dialog with the user, wherein the dialog communication means has a number of different dialog states and is arranged to change dialog state in response to received instructions, the control apparatus being arranged to supply to the speech processing apparatus instructions regarding the speech recognition grammar or grammars to be used in dependence upon the dialog state of the dialog communication means such that, in at least one dialog state, the control apparatus is arranged to provide instructions to cause first and second grammars to be linked by an interface grammar having grammar rules usable by the first grammar and implementable by the second grammar so as to form an extended grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the control apparatus comprises a JAVA virtual machine. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A device couplable to a network, the device comprising a control apparatus in accordance with the <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference> and a processor-controlled machine. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A device according to <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein the processor-controlled machine is arranged to carry out at least one function. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A device according to <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, wherein the processor-controlled machine is selected from the group consisting of: 
<claim-text>a photocopier, a facsimile machine, a multi-function machine, a television, a video cassette recorder, a microwave oven, a heating system, a lighting system. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A device according to <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein the processor-controlled machine is arranged to cause another device coupled to the network to carry out the at least one function. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. An assembly comprising a device in accordance with <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> and, as said other device, a device comprising a processor controlled machine and a control device. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. An assembly according to <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the device comprises a digital camera and said other device comprises a printer. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. A grammar store for use in a system in accordance with <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, the grammar store having at least one of the following: 
<claim-text>a first grammar; an interface grammar defining grammar rules usable by the first grammar; and a second grammar configured to implement grammar rules defined by the interface grammar to enable the first and second grammars to be linked by the interface grammar to form an extended grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A grammar store for use in a system in accordance with <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, the grammar store having at least one of the following: 
<claim-text>a first grammar comprising one of a camera and a printer grammar; </claim-text>
<claim-text>a second grammar comprising the other of the camera and printer grammars; and </claim-text>
<claim-text>an interface grammar defining grammar rules usable by the first grammar, the second grammar being configured to implement grammar rules defined by the interface grammar to enable the first and second grammars to be linked by the interface grammar to form an extended grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A computer program product comprising processor implementable instructions for configuring a processor to provide control apparatus of a system in accordance with <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A signal comprising a computer program product in accordance with <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. A storage medium carrying a computer program product in accordance with <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. In a system comprising: 
<claim-text>at least one device having a processor-controlled machine for causing at least one function specified by a user to be carried out and a control apparatus for enabling voice-control of the processor-controlled machine and a speech processing apparatus having means for receiving speech data representing speech by a user, a grammar store storing speech recognition grammars, speech recognition means for recognising speech in the received speech data using at least one of the speech recognition grammars, speech interpreting means for interpreting the recognised speech to provide instructions for controlling at least one function of a processor-controlled machine and transmitting means for transmitting the instructions to the control apparatus, a method of operating the control apparatus which comprises: </claim-text>
<claim-text>providing speech recognition grammar instructions regarding the speech recognition grammar to be used by the speech recognition means for recognising speech data to the speech processing apparatus to cause a first grammar using grammar rules defined by an interface grammar to be linked by the interface grammar to a second grammar which implements rules defined by the interface grammar to form an extended grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 27</dependent-claim-reference>, which comprises: 
<claim-text>receiving instructions derived from speech recognised by the speech recognition means; </claim-text>
<claim-text>communicating with the user to provide information to the user in response to received instructions enabling a dialog with the user with the dialog having a dialog state dependent on the received instructions; and supplying to the speech processing apparatus instructions regarding the speech recognition grammar or grammars to be used in dependence upon the dialog state such that, in at least one dialog state, the instructions cause said first and second grammars to be linked by said interface grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. A method of operating a speech processing apparatus for receiving speech data representing commands spoken by a user for controlling a function of a device, the method comprising: 
<claim-text>receiving speech data representing speech by a user; </claim-text>
<claim-text>accessing a grammar store comprising at least first and second grammars having grammar rules and at least one interface grammar defining grammar rules; </claim-text>
<claim-text>causing a first grammar which uses grammar rules defined by an interface grammar to be linked by the interface grammar to a second grammar which implements rules defined by the interface grammar; </claim-text>
<claim-text>recognising speech in the received speech data; </claim-text>
<claim-text>interpreting recognised speech to provide instructions for enabling a function of a device to be controlled; and </claim-text>
<claim-text>transmitting the instructions to a device for enabling control of a function of that device to form an extended grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. A method of operating a control apparatus for coupling a processor-controlled machine to speech processing apparatus for enabling a user to control a function of a machine by spoken commands, which method comprises transmitting speech recognition grammar instructions defining a speech recognition grammar or grammars to be used by the speech processing apparatus means for recognising speech data including instructions for causing first and second grammars to be linked by an interface grammar having grammar rules usable by the first grammar and implementable by the second grammar so as to form an extended grammar. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. A method of operating a control apparatus for enabling coupling of a processor-controlled machine to speech processing apparatus remote from the processor-controlled machine for enabling a user to control a function of the processor-controlled machine by spoken commands, the method comprising: 
<claim-text>receiving from the speech processing apparatus instructions derived from speech recognised by the speech processing apparatus; </claim-text>
<claim-text>communicating with the user to provide information to the user in response to instructions received from the speech processing apparatus using a dialog which has a number of different dialog states dependent upon the received instructions; and supplying to the speech processing apparatus instructions regarding the speech recognition grammar or grammars to be used in dependence upon the dialog state of the dialog communication means such that, in at least one dialog state, the instructions cause first and second grammars to be linked by an interface grammar having grammar rules usable by the first grammar and implementable by the second grammar so as to form an extended grammar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. A computer program product comprising processor implementable instructions for causing a processor to carry out a method in accordance with <dependent-claim-reference depends_on="CLM-00022">claim 27</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. A signal or storage medium carrying a computer program product in accordance with <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. A control apparatus for enabling a user to control a function of each of a plurality of processed-controlled machines by spoken commands interpreted by speech processing apparatus using speech recognition grammars, the control apparatus having a connection manager for determining from a command spoken by a user the machine that the user wishes to control and speech recognition grammar accessing means for accessing a grammar or grammars for the machine identified by the connecting manager to enable subsequent commands to be interpreted by the speech processing apparatus using the access grammar or grammars. </claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 34</dependent-claim-reference>, wherein the control apparatus is arranged to access the speech recognition grammar or grammars by downloading from the identified machine. </claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 34</dependent-claim-reference>, incorporating speech processing apparatus for processing commands received by the control apparatus. </claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. A control apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 34</dependent-claim-reference>, wherein the connection manager is arranged to determine from commands spoken by a user when the user wishes to control another machine and to access the speech recognition grammar or grammars for that machine to enable subsequent commands to interpreted using the accessed grammar or grammars. </claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. A system comprising: 
<claim-text>a processor-controlled machine for causing at least one function specified by a user to be carried out; a control apparatus for enabling voice-control of the processor-controlled machine; </claim-text>
<claim-text>an audio input device for receiving speech from a user and for supplying speech data representing the received speech; and </claim-text>
<claim-text>a speech processing apparatus having means for receiving speech data from the audio input device, a grammar store storing speech recognition grammars, speech recognition means for recognising speech in the received speech data using at least one of the speech recognition grammars, speech interpreting means for interpreting the recognised speech to provide instructions for controlling at least one function of a processor-controlled machine and transmitting means for transmitting the instructions to the control apparatus, </claim-text>
<claim-text>the control apparatus being arranged to couple the processor-controlled machine to the speech processing apparatus and having means for providing speech recognition grammar instructions regarding the speech recognition grammar to be used by the speech recognition means for recognising speech data and means for transmitting speech recognition grammar instructions to the speech processing apparatus, wherein the grammar store comprises at least first and second grammars having grammar rules and at least one interface grammar defining grammar rules, the first grammar being arranged to use grammar rules defined by the interface grammar and the second grammar being arranged to implement rules defined by the interface grammar, and wherein the speech recognition grammar instructions providing means is arranged to provide instructions for causing the second grammar to be linked to the first grammar using the interface grammar.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004728A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004728A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004728A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004728A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004728A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004728A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004728A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004728A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004728A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004728A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030004728A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030004728A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030004728A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
