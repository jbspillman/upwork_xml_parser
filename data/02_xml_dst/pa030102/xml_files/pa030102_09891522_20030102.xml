<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005167A1-20030102-D00000.TIF SYSTEM "US20030005167A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005167A1-20030102-D00001.TIF SYSTEM "US20030005167A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005167A1-20030102-D00002.TIF SYSTEM "US20030005167A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005167A1-20030102-D00003.TIF SYSTEM "US20030005167A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005167A1-20030102-D00004.TIF SYSTEM "US20030005167A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005167A1-20030102-D00005.TIF SYSTEM "US20030005167A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030005167A1-20030102-D00006.TIF SYSTEM "US20030005167A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030005167A1-20030102-D00007.TIF SYSTEM "US20030005167A1-20030102-D00007.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005167</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09891522</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010627</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F015/163</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G06F009/54</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>709</class>
<subclass>310000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method and apparatus for managing transaction requests in a multi-node architecture</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Manoj</given-name>
<family-name>Khare</family-name>
</name>
<residence>
<residence-us>
<city>Saratoga</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Akhilesh</given-name>
<family-name>Kumar</family-name>
</name>
<residence>
<residence-us>
<city>Sunnyvale</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Loannis</given-name>
<family-name>Schoinas</family-name>
</name>
<residence>
<residence-us>
<city>Portland</city>
<state>OR</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Lily</given-name>
<middle-name>Pao</middle-name>
<family-name>Looi</family-name>
</name>
<residence>
<residence-us>
<city>Portland</city>
<state>OR</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>KENYON &amp; KENYON</name-1>
<name-2></name-2>
<address>
<address-1>1500 K STREET, N.W., SUITE 700</address-1>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20005</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Embodiments of the present invention relate to methods and apparatus for managing transaction requests in a multi-node architecture. In one embodiment, a previously received ordered group request may be forwarded to a destination agent. Whether a next received ordered group request belongs to a same ordered group as the previously received ordered group request may be determined. Additionally, it may be determined whether an ordering fork is encountered if the next received ordered group request belongs to the same ordered group as the previously received ordered group request. If an ordering fork is encountered, it may be determined whether a request complete message for the previously received ordered group request has been received. If the request complete message for the previously received ordered group request has not been received and the next received ordered group request in the same ordered group is at least one of a unordered request and a forward-ordered request, then the next received ordered group request may be forwarded to the destination agent after the request complete message for the previously received at least one of a forward-ordered request and a sequential-ordered request issued on a different path at the ordering fork has been received. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> Embodiments of the present invention relate to a computer system having a multi-node computer architecture. In particular, the present invention relates to a method and apparatus for managing transaction requests in a multi-node architecture. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Computer systems may contain multiple processors that may work together to perform a task. For example, a computer system may contain four processors that may share system resources (e.g., input devices or memory devices) and may perform parallel processing. The processors may send messages to each other, may send messages to system resources, and may receive messages from the system resources. For example, such messages may include requests for information that is stored at a location in a memory device (i.e., read requests) or a request to store information in a location of a memory device (i.e., write requests). </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The processors may share multiple system resources (e.g., memory) and multiple independent paths to these system resources for exchanging messages and requests. In some cases, the existence of these distributed resources and paths may result in reordering of messages or requests in a multi-node architecture. For example, a first processor may issue write requests for updating data to a memory address location in another node. However, before the request is completed, if a second processor issues another request to read data from the memory address location, the second processor may read data that is &ldquo;stale&rdquo; or has become outdated. This situation becomes complicated in a multiple node architecture having distributed memory resources. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> For example, consider a case where memory locations &ldquo;A&rdquo; and &ldquo;B&rdquo; in a memory resource have initial conditions or values of &ldquo;10&rdquo; and &ldquo;False,&rdquo; respectively (i.e., A&equals;10 and B&equals;&ldquo;False&rdquo;). Agent A such as a node controller of one of the processor nodes in the multi-node architecture may issue requests to write to memory locations A and B in the memory resource located, for example, in another node. Such requests may be, for example, &ldquo;WR A&equals;20&rdquo; (i.e., write to location A the value 20) followed by &ldquo;WR B&equals;True&rdquo; (i.e., write to location B the value True). Before the write requests issued by Agent A are executed, Agent B such as a node controller of another processor node may issue a request to the same memory location such as &ldquo;if (B&equals;True) RD A&rdquo; (i.e., if the value of location B is True, then read the value of location A). If the receiving agent containing the memory resource receives and executes &ldquo;WR B&equals;True&rdquo; from Agent A before &ldquo;WR A&equals;20&rdquo; from Agent A and the requests issued by Agent B (&ldquo;if (B&equals;True) RD A&rdquo;) are executed before &ldquo;WR A&equals;20&rdquo; request from Agent A, then Agent B may not receive the correct value of location A since the value of location B has been updated but the value of location A is not updated.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a partial block diagram of a system having an agent that manages memory requests in accordance with an exemplary embodiment of the present invention. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a partial block diagram showing a memory address space for a multi-node system in accordance with embodiments of the present invention. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a flow diagram of a method of managing requests in a multi-node system. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a table showing ordering semantics and corresponding ordering bits in accordance with embodiments of the present invention. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a diagrammatic representation of a data packet of a semantically ordered request in accordance with embodiments of the present invention. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates processing orders for semantically ordered requests in accordance with embodiments of the present invention. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a semantic ordering relationship matrix in accordance with embodiments of the present invention. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flow diagram of a method of managing requests in a multi-node system in accordance with embodiments of the present invention. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a simplified block diagram of the system shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> in accordance with an exemplary embodiment of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Embodiments of the present invention relate to methods and apparatus for managing transaction requests in a multi-node architecture. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In an embodiment of the present invention, a receiving agent may establish ordering semantics for transaction requests issued by a requesting agent. The ordering semantics may specify an order for processing the transaction requests. The requesting agent may forward requests having the ordering semantics to a receiving agent. The receiving agent receives a first request and may forward the request to a destination agent. The receiving agent may receive a subsequent request and examines the subsequent request. The receiving agent may determine whether the next request belongs to the same ordered group as the previous request. If the next request does not belong to the same ordered group as the previous request, the next request is forwarded to the destination agent for processing. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> If, on the other hand, the next request does belong to the same ordered group as the previous request, then if an ordering fork has been encountered and no request complete message has been received for the previous request, the receiving agent forwards the next request to the destination agent based on semantic ordering. The receiving agent may examine the request to determine if the next request is either un-ordered, forward-ordered, backward-ordered, or sequentially ordered with respect to the previous request. Based on results of this ordering examination, the receiving agent may wait for a request complete message from the destination agent before sending the next request to the destination node for processing. After the awaited request complete message for the previous request has been received, the receiving agent forwards the next request to the destination agent for processing. After the request has been forwarded to the destination agent, the receiving agent examines the subsequent request in the ordered group to process the subsequent request based on the semantic ordering of the request. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> If the next request does belong to the same ordered group as the previous request, then if an ordering fork has not been encountered or if the ordering fork has been encountered but a request complete message has been received for the previous request, no ordering is required with respect to the previous request. The receiving agent forwards the next request to the destination agent for processing. After the request has been forwarded to the destination agent, the receiving agent examines the subsequent request in the ordered group to process the subsequent request based on the semantic ordering of the request. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a partial block diagram of a system having an agent that manages memory requests according to embodiments of the present invention. <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a system <highlight><bold>100</bold></highlight> that is a computer system that includes processors, memory devices, and input/output devices. Components in system <highlight><bold>100</bold></highlight> are arranged into architectural units that are referred to herein as &ldquo;nodes&rdquo; and/or &ldquo;agents.&rdquo; It is recognized that any of the components shown in system <highlight><bold>100</bold></highlight> could be referred to as nodes and/or agents, and that any of these components could perform the functions of a &ldquo;node&rdquo; or an &ldquo;agent&rdquo; as described herein. A system that has multiple nodes may be referred to as a &ldquo;multinode&rdquo; system. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In one embodiment of the present invention, each node may contain one or more processors, memories, or input/output devices. The components within a node may be connected to other components in that node though one or more busses or lines. In addition, each node in system <highlight><bold>100</bold></highlight> has an external connector that may be used by the components within that node to communicate with components in other nodes. In one embodiment, any communication from a component within a first node to another node must be routed though the external connection for the first node. In system <highlight><bold>100</bold></highlight>, the external connection for each node is connected to a switching agent <highlight><bold>140</bold></highlight>. In an alternative embodiment of the present invention, each of the nodes may communicate with other nodes through direct connections (not shown) that do not pass through switching agent <highlight><bold>140</bold></highlight>. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> In embodiments of the present invention, the switching agent <highlight><bold>140</bold></highlight> could be implemented in a central switch for all nodes (as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>) or, alternatively, the switching agent could be implemented in a distributed manner integrated in one or more node controllers of the node(s). Optionally and/or additionally, the switching agent could be implemented in a distributed manner and integrated within the intelligence of one or more processors and/or within an input/output hub located in system <highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The nodes in system <highlight><bold>100</bold></highlight> may send messages that are directed to a processor or resource in another node. For example, one node may send a request to read from a memory location in another node or write to particular location in memory in another node. Similarly, a node and/or switching agent <highlight><bold>140</bold></highlight> may send a request to snoop the caches in the other nodes. In one embodiment, all requests in system <highlight><bold>100</bold></highlight> from one node to another node may be sent to switching agent <highlight><bold>140</bold></highlight>, and switching agent <highlight><bold>140</bold></highlight> may send requests to other nodes based on the first request. For example, switching agent <highlight><bold>140</bold></highlight> may receive a request from a first node to read or write data to a particular memory location, and switching agent <highlight><bold>140</bold></highlight> may send snoop requests to the other nodes in system <highlight><bold>100</bold></highlight> as needed to carry out the received request from the first node. The snoop requests may be sent by the switching agent to determine the status of data in other nodes prior to completing the request from the first node. Alternatively, a node may send requests to another node without sending the same request to the switching agent <highlight><bold>140</bold></highlight>. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The details shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> will now be discussed. As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, system <highlight><bold>100</bold></highlight> includes, for example, a first node <highlight><bold>110</bold></highlight>, a second node <highlight><bold>120</bold></highlight>, a third node <highlight><bold>130</bold></highlight>, a fourth node <highlight><bold>160</bold></highlight> and an input/output node <highlight><bold>150</bold></highlight>. Each of these nodes is coupled to switching agent <highlight><bold>140</bold></highlight>. The term &ldquo;coupled&rdquo; encompasses a direct connection, an indirect connection, an indirect communication, etc. First node <highlight><bold>110</bold></highlight> is coupled to switching agent <highlight><bold>140</bold></highlight> through external connection <highlight><bold>118</bold></highlight>, second node <highlight><bold>120</bold></highlight> is coupled to switching agent <highlight><bold>140</bold></highlight> through external connection <highlight><bold>128</bold></highlight>, third node <highlight><bold>130</bold></highlight> is coupled to switching agent <highlight><bold>140</bold></highlight> through external connection <highlight><bold>138</bold></highlight>, and fourth node <highlight><bold>160</bold></highlight> is coupled to switching agent <highlight><bold>140</bold></highlight> through external connection <highlight><bold>168</bold></highlight>. External connections <highlight><bold>118</bold></highlight>, <highlight><bold>128</bold></highlight>, <highlight><bold>138</bold></highlight> and <highlight><bold>168</bold></highlight> may be one or more lines capable of communicating information to and from the node. In embodiments of the invention, the nodes may be coupled to each other through direct connections (not shown). First node <highlight><bold>110</bold></highlight> includes processors <highlight><bold>111</bold></highlight>,<highlight><bold>112</bold></highlight>, and node controller <highlight><bold>115</bold></highlight>, which are coupled to each other by bus <highlight><bold>114</bold></highlight>. Processor <highlight><bold>111</bold></highlight> and processor <highlight><bold>112</bold></highlight> may be any micro-processors that are capable of processing instructions, such as for example a processor in the INTEL PENTIUM&trade; family of processors manufactured by Intel Corporation, of Santa Clara, Calif. Bus <highlight><bold>114</bold></highlight> may be a shared bus. First node <highlight><bold>110</bold></highlight> also contains a memory <highlight><bold>119</bold></highlight> that is coupled to node controller <highlight><bold>115</bold></highlight>. Memory <highlight><bold>119</bold></highlight> may be, for example, a Random Access Memory (RAM). Processor <highlight><bold>111</bold></highlight> may contain a cache <highlight><bold>113</bold></highlight>, and processor <highlight><bold>112</bold></highlight> may contain a cache <highlight><bold>117</bold></highlight>. Cache <highlight><bold>113</bold></highlight> and cache <highlight><bold>117</bold></highlight> may be Level 2 (L2) cache memories that are comprised of static random access memory (SRAM). Of course, first node <highlight><bold>110</bold></highlight> may include processors additional to the processors shown (e.g., <highlight><bold>111</bold></highlight>, <highlight><bold>112</bold></highlight>). </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Similarly, second node <highlight><bold>120</bold></highlight> contains processors <highlight><bold>121</bold></highlight>, <highlight><bold>122</bold></highlight> and node controller <highlight><bold>125</bold></highlight> that are coupled to each other by bus <highlight><bold>124</bold></highlight>. Second node <highlight><bold>120</bold></highlight> also contains a memory <highlight><bold>129</bold></highlight> that is coupled to node controller <highlight><bold>125</bold></highlight>. Third node <highlight><bold>130</bold></highlight> contains processors <highlight><bold>131</bold></highlight>, <highlight><bold>132</bold></highlight> and node controller <highlight><bold>135</bold></highlight> that are coupled to each other by bus <highlight><bold>134</bold></highlight>. Third node <highlight><bold>130</bold></highlight> also contains a memory <highlight><bold>139</bold></highlight> that is coupled to node controller <highlight><bold>135</bold></highlight>. Fourth node <highlight><bold>160</bold></highlight> contains processors <highlight><bold>161</bold></highlight>, <highlight><bold>162</bold></highlight>, and node controller <highlight><bold>165</bold></highlight> that are coupled to each other by bus <highlight><bold>164</bold></highlight>. Fourth node <highlight><bold>160</bold></highlight> also contains a memory <highlight><bold>169</bold></highlight> that is coupled to node controller <highlight><bold>165</bold></highlight>. Processors <highlight><bold>121</bold></highlight>, <highlight><bold>122</bold></highlight> may contain cache <highlight><bold>123</bold></highlight>, <highlight><bold>127</bold></highlight>, respectively. Processors <highlight><bold>131</bold></highlight>, <highlight><bold>132</bold></highlight> may contain cache <highlight><bold>133</bold></highlight>, <highlight><bold>137</bold></highlight>, respectively. Processors <highlight><bold>161</bold></highlight>, <highlight><bold>162</bold></highlight> may contain cache <highlight><bold>163</bold></highlight>, <highlight><bold>167</bold></highlight>, respectively. Processors <highlight><bold>121</bold></highlight>, <highlight><bold>122</bold></highlight>, <highlight><bold>131</bold></highlight>, <highlight><bold>132</bold></highlight>, <highlight><bold>161</bold></highlight>, and <highlight><bold>162</bold></highlight> may be similar to processors <highlight><bold>111</bold></highlight> and <highlight><bold>112</bold></highlight>. In an embodiment, two or more of processors <highlight><bold>111</bold></highlight>, <highlight><bold>112</bold></highlight>, <highlight><bold>121</bold></highlight>, <highlight><bold>122</bold></highlight>, <highlight><bold>131</bold></highlight>, <highlight><bold>132</bold></highlight>, <highlight><bold>161</bold></highlight> and <highlight><bold>162</bold></highlight> are capable of processing a program in parallel. System <highlight><bold>100</bold></highlight> may include additional nodes, and each of the nodes (e.g., <highlight><bold>110</bold></highlight>, <highlight><bold>120</bold></highlight>, <highlight><bold>130</bold></highlight>, <highlight><bold>160</bold></highlight>, etc.) may include processors additional to the ones shown (e.g., <highlight><bold>111</bold></highlight>, <highlight><bold>112</bold></highlight>, <highlight><bold>121</bold></highlight>, <highlight><bold>122</bold></highlight>, <highlight><bold>131</bold></highlight>, <highlight><bold>132</bold></highlight>, <highlight><bold>161</bold></highlight>, <highlight><bold>162</bold></highlight>). Node controllers <highlight><bold>125</bold></highlight>, <highlight><bold>135</bold></highlight>, <highlight><bold>165</bold></highlight> may be similar to node controller <highlight><bold>115</bold></highlight>, and memory <highlight><bold>129</bold></highlight>, <highlight><bold>139</bold></highlight>, <highlight><bold>169</bold></highlight> may be similar to memory <highlight><bold>119</bold></highlight>. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> In an embodiment, switching agent <highlight><bold>140</bold></highlight> may be a routing switch for managing read and/or write requests, and for routing other messages within system <highlight><bold>100</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, switching agent <highlight><bold>140</bold></highlight> contains request manager <highlight><bold>148</bold></highlight> and memory <highlight><bold>144</bold></highlight> and may contain other components (not shown). Request manager <highlight><bold>148</bold></highlight> may manage and regulate requests passed among nodes <highlight><bold>110</bold></highlight>, <highlight><bold>120</bold></highlight>, <highlight><bold>130</bold></highlight>, and <highlight><bold>160</bold></highlight>. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> In an embodiment of the present invention, request manager <highlight><bold>148</bold></highlight> may monitor read and writes to memory locations (e.g., in cache and main memory) that may occur in system <highlight><bold>100</bold></highlight>. Request manager <highlight><bold>148</bold></highlight> may maintain ordering between requests exchanged in the multi-node system <highlight><bold>100</bold></highlight>. For example, to prevent &ldquo;stale&rdquo; information from being read in system <highlight><bold>100</bold></highlight>, request manager <highlight><bold>148</bold></highlight> may permit a request issued earlier to be executed before a later issued request. In addition, request manager <highlight><bold>148</bold></highlight> may permit ordered requests to be executed based on semantic ordering established by a node controller. It is recognized that switching agent <highlight><bold>140</bold></highlight> that includes the request manager <highlight><bold>148</bold></highlight> may be distributed in any of the components shown in system <highlight><bold>100</bold></highlight>. Accordingly, any of the node controllers, for example, controller <highlight><bold>115</bold></highlight>, <highlight><bold>125</bold></highlight>, <highlight><bold>135</bold></highlight> and/or <highlight><bold>165</bold></highlight>, and/or any of the processors, for example, processors <highlight><bold>111</bold></highlight>, <highlight><bold>112</bold></highlight>, <highlight><bold>121</bold></highlight>, <highlight><bold>122</bold></highlight>, <highlight><bold>131</bold></highlight>, <highlight><bold>132</bold></highlight>, <highlight><bold>161</bold></highlight>, and/or <highlight><bold>162</bold></highlight>, and/or input output hub <highlight><bold>151</bold></highlight> may also manage or maintain ordering between read and/or write requests in accordance with embodiment of the present invention. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, input/output node <highlight><bold>150</bold></highlight> contains an input/output hub <highlight><bold>151</bold></highlight> that is coupled to one or more input/output devices <highlight><bold>152</bold></highlight>. Input/output devices <highlight><bold>152</bold></highlight> may be, for example, any combination of one or more of a printer, keyboard, mouse, or any other input/output device. Input/output hub <highlight><bold>151</bold></highlight> may by an integrated circuit that contains bus interface logic for interfacing with a bus that complies to, for example, the Peripheral Component Interconnect (PCI) standard. PCI Special Interest Group (SIG) PCI Local Bus Specification, Revision 2.2, published Dec. 18, 1998. Input/output hub <highlight><bold>150</bold></highlight> may be similar to, for example, the INTEL 82801AA I/O Controller Hub. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> In an embodiment, node controller <highlight><bold>115</bold></highlight>, switching agent <highlight><bold>140</bold></highlight>, and input/output hub <highlight><bold>151</bold></highlight> may be a chipset that provides the core functionality of a motherboard, such as a modified version of a chipset in the INTEL 815 family of chipsets. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> In a further embodiment, inter-node communication in system <highlight><bold>100</bold></highlight> may be asynchronous (i.e., there is no fixed timing between events). In a still further embodiment, inter-node communication may be sent in the form of packets that may contain a header or a header and data sections. An example of a message size may be 144 bits. In an embodiment, the messages sent may include requests and responses. In a further embodiment, the types of requests that the nodes may send and receive may include a memory read request, memory write request, cache snoop request, cache flush request, memory update request, cache line replacement request, input/output port read request, and input/output port write request. Requests may contain fields such as a packet type, destination ID, request type, node ID, transaction address, request length, stream ID, and ordering semantics. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> In an embodiment of the present invention, the processors in nodes <highlight><bold>110</bold></highlight>, <highlight><bold>120</bold></highlight>, <highlight><bold>130</bold></highlight> and <highlight><bold>160</bold></highlight> may be shared memory multi-processors, and each of the memories <highlight><bold>119</bold></highlight>, <highlight><bold>129</bold></highlight>, <highlight><bold>139</bold></highlight> and <highlight><bold>169</bold></highlight> may be part of the same shared physical address space. In a further embodiment, the processors in nodes <highlight><bold>110</bold></highlight>, <highlight><bold>120</bold></highlight>, <highlight><bold>130</bold></highlight> and <highlight><bold>160</bold></highlight> communicate with each other through shared memory reads and writes (i.e., by writing to and reading from memory <highlight><bold>119</bold></highlight>, <highlight><bold>129</bold></highlight>, <highlight><bold>139</bold></highlight>, and <highlight><bold>169</bold></highlight>). In a further embodiment, the processors in nodes <highlight><bold>110</bold></highlight>, <highlight><bold>120</bold></highlight>, <highlight><bold>130</bold></highlight> and <highlight><bold>160</bold></highlight> each have one or more caches (e.g., Level 1 and Level 2 caches), and these caches may be kept coherent using the switching agent <highlight><bold>140</bold></highlight>. For example, when processor <highlight><bold>111</bold></highlight> accesses a location in memory <highlight><bold>119</bold></highlight>, it may send a snoop request for that memory location to switching agent <highlight><bold>140</bold></highlight>, which may determine if any of the processors in second node <highlight><bold>120</bold></highlight>, third node <highlight><bold>130</bold></highlight> or fourth node <highlight><bold>140</bold></highlight> have cached that memory location. A snoop request may be generated when a processor needs other processors in the system to look in their own caches to see if a particular line is present in their cache. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a partial block diagram showing distributed memory address space <highlight><bold>201</bold></highlight> and caches for a multi-node system according to an embodiment of the present invention. Memory address space <highlight><bold>201</bold></highlight> includes first memory <highlight><bold>119</bold></highlight>, second memory <highlight><bold>129</bold></highlight>, third memory <highlight><bold>139</bold></highlight>, and fourth memory <highlight><bold>169</bold></highlight> which are shown respectively in first node <highlight><bold>110</bold></highlight>, second node <highlight><bold>120</bold></highlight>, third node <highlight><bold>130</bold></highlight> and fourth node <highlight><bold>160</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. For the purpose of illustration, first memory <highlight><bold>119</bold></highlight> is shown as containing the addresses 0 to 49, second memory <highlight><bold>129</bold></highlight> is shown as containing the addresses 50 to 99, third memory <highlight><bold>139</bold></highlight> is shown as containing the addresses 100 to 149, and fourth memory <highlight><bold>169</bold></highlight> is shown as containing the addresses 150 to 199. Thus, in this embodiment, address space <highlight><bold>201</bold></highlight> contains the locations in addresses 0 to 199. Of course, in other embodiments address space <highlight><bold>201</bold></highlight> may contain other addresses, and address space <highlight><bold>201</bold></highlight> may be spread across more or less memories than as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Address space <highlight><bold>201</bold></highlight> may be referred to as a &ldquo;shared&rdquo; address space because any node in the multi-node system may address any location in address space <highlight><bold>201</bold></highlight>. Thus, second node <highlight><bold>120</bold></highlight> may send a request to read from location 0 in the address space, location 0 being contained in memory <highlight><bold>119</bold></highlight> in first node <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> also shows caches <highlight><bold>113</bold></highlight>, <highlight><bold>123</bold></highlight>, <highlight><bold>133</bold></highlight>, and <highlight><bold>163</bold></highlight> which are contained in first node <highlight><bold>110</bold></highlight>, second node <highlight><bold>120</bold></highlight>, third node <highlight><bold>130</bold></highlight> and fourth node <highlight><bold>160</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, respectively. The multi-node system may contain additional caches than shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> (such as caches <highlight><bold>117</bold></highlight>, <highlight><bold>127</bold></highlight>, <highlight><bold>137</bold></highlight> and <highlight><bold>167</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>). In an embodiment, each addressable location of memory in address space <highlight><bold>201</bold></highlight> may be the size of a cache line in caches <highlight><bold>113</bold></highlight>, <highlight><bold>123</bold></highlight>, <highlight><bold>133</bold></highlight>, and <highlight><bold>163</bold></highlight>. In <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, certain locations in the memory address space <highlight><bold>201</bold></highlight> are designated as A, B, C, D, E and F for the purposes of reference. Each of these locations stores some information (data or instructions). </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The information in any particular location in the memory address space <highlight><bold>201</bold></highlight> may be cached in one or more of the caches in the system. Thus, a copy of the information in the location designated A in first memory <highlight><bold>119</bold></highlight> is cached in caches <highlight><bold>113</bold></highlight>, <highlight><bold>123</bold></highlight>, <highlight><bold>133</bold></highlight>, and <highlight><bold>163</bold></highlight>; a copy of the information in the location designated B in first memory <highlight><bold>119</bold></highlight> is cached in cache <highlight><bold>123</bold></highlight>; a copy of the information in the location designated C in first memory <highlight><bold>119</bold></highlight> is cached in caches <highlight><bold>113</bold></highlight>, and <highlight><bold>133</bold></highlight>; a copy of the information in the location designated D in second memory <highlight><bold>129</bold></highlight> is cached in cache <highlight><bold>123</bold></highlight>, <highlight><bold>133</bold></highlight> and cache <highlight><bold>163</bold></highlight>; a copy of the information in the location designated E in second memory <highlight><bold>129</bold></highlight> is cached in cache <highlight><bold>113</bold></highlight> and <highlight><bold>163</bold></highlight>; and a copy of the information in the location designated F in third memory <highlight><bold>139</bold></highlight> is cached in cache <highlight><bold>133</bold></highlight> and <highlight><bold>163</bold></highlight>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Switching agent <highlight><bold>140</bold></highlight> may process requests as follows. If switching agent <highlight><bold>140</bold></highlight> receives from first node <highlight><bold>110</bold></highlight> a request to access the memory location designated as D (in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>), request manager <highlight><bold>148</bold></highlight> may determine that memory location D is cached in cache <highlight><bold>123</bold></highlight> (in second node <highlight><bold>120</bold></highlight>), cache <highlight><bold>133</bold></highlight> (in third node <highlight><bold>120</bold></highlight>), and cache <highlight><bold>163</bold></highlight> (in fourth node <highlight><bold>169</bold></highlight>). Request manager <highlight><bold>148</bold></highlight> may then cause snoop requests that are associated with location D to be sent to second node <highlight><bold>120</bold></highlight>, third node <highlight><bold>130</bold></highlight>, and fourth node <highlight><bold>160</bold></highlight>. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a flow diagram of a method of managing transaction ordering in a multi-node system. The method shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> may be controlled by a requesting node or agent, such as a node controller <highlight><bold>115</bold></highlight>, <highlight><bold>125</bold></highlight>, <highlight><bold>135</bold></highlight>, and/or <highlight><bold>165</bold></highlight> or processors <highlight><bold>111</bold></highlight>, <highlight><bold>112</bold></highlight>, <highlight><bold>123</bold></highlight>, <highlight><bold>127</bold></highlight>, <highlight><bold>131</bold></highlight>, <highlight><bold>137</bold></highlight>, <highlight><bold>163</bold></highlight>, and/or <highlight><bold>167</bold></highlight> as shown <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Transaction ordering may be desirable in a multi-node system to ensure that most current data is being written or read by the request manager <highlight><bold>148</bold></highlight> in response to requests from nodes in system <highlight><bold>100</bold></highlight>. In this example, node <highlight><bold>110</bold></highlight> may issue a group of ordered requests to switching agent <highlight><bold>140</bold></highlight> to write data A, B, C, to memory locations of nodes <highlight><bold>120</bold></highlight>, <highlight><bold>130</bold></highlight> and <highlight><bold>160</bold></highlight>, respectively. For this group of requests, it may be desirable that each request be completed in the specified order. For example, first request &ldquo;WR A&equals;10&rdquo; (i.e., write to location A the value 10) may need to be completed before second request &ldquo;WR B&equals;20&rdquo; (i.e., write to location B the value 20) that may need to be completed before the third request &ldquo;WR C&equals;30&rdquo; (write to location C the value 30). </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> To maintain ordering, node controller <highlight><bold>115</bold></highlight> of first node <highlight><bold>110</bold></highlight> may issue a first write request, for example, &ldquo;WR A&equals;10&rdquo; to manager <highlight><bold>148</bold></highlight> of switching agent <highlight><bold>140</bold></highlight> (<highlight><bold>301</bold></highlight>). The request may include, for example, appropriate source and destination identifiers (IDs) to identify the requesting node and the destination node for the request. Manager <highlight><bold>148</bold></highlight> may receive the request from node <highlight><bold>110</bold></highlight> and, after determining the identity of the destination node, may forward the request to, for example, destination node <highlight><bold>120</bold></highlight> (<highlight><bold>302</bold></highlight>). Destination node <highlight><bold>120</bold></highlight> may receive, for example, the write request and may write the value &ldquo;10&rdquo; to an appropriate memory location in memory location &ldquo;A.&rdquo;</paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> After the request has been processed by destination node <highlight><bold>120</bold></highlight>, a request complete message may be sent to the manager <highlight><bold>148</bold></highlight> (<highlight><bold>303</bold></highlight>). Manager <highlight><bold>148</bold></highlight> may forward the request complete message to the issuing node <highlight><bold>120</bold></highlight> (i.e., source node) (<highlight><bold>304</bold></highlight>). In alternative embodiments, the destination node may send the request complete message to the issuing node directly. The node controller <highlight><bold>115</bold></highlight> for the issuing node <highlight><bold>120</bold></highlight> may determine whether the request complete message has been received for the first issued request (<highlight><bold>305</bold></highlight>). If the request complete message has not been received, the node controller <highlight><bold>115</bold></highlight> may continue to check its receipt (<highlight><bold>305</bold></highlight>). </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> If the request complete message associated with the first issued request has been received, node controller <highlight><bold>115</bold></highlight> may determine whether another request associated with the ordered group is pending (<highlight><bold>305</bold></highlight> and <highlight><bold>306</bold></highlight>). If another request is not pending, the node controller terminates processing requests associate with the current group and may continue to process other requests or perform other tasks (<highlight><bold>307</bold></highlight>). </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> If another request is pending, for example second request, &ldquo;WR B&equals;20,&rdquo; node controller <highlight><bold>115</bold></highlight> may send the second request to switching agent <highlight><bold>140</bold></highlight> (<highlight><bold>306</bold></highlight> and <highlight><bold>301</bold></highlight>). The process as shown by steps <highlight><bold>301</bold></highlight>-<highlight><bold>307</bold></highlight> may continue until all of the requests related to the current group are completed. Accordingly, transactions can be processed in a multi-node system in an embodiment of the present invention. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a table <highlight><bold>400</bold></highlight> listing the types of ordering semantics and corresponding bits that may represent these ordering semantics in embodiments of the present invention. In embodiments of the present invention, ordering semantics may be exported with each transaction request. Ordering semantics may define, for example, rules by which a transaction or request is allowed to be processed or completed before another transaction. As listed in columns <highlight><bold>401</bold></highlight>, types of ordering semantics may include, for example, un-ordered, forward-ordered, backward-ordered, and sequentially-ordered semantics. As indicated above, the semantic orders may specify a permissible order sequence for processing the transaction requests. Columns <highlight><bold>402</bold></highlight>-<highlight><bold>404</bold></highlight> list corresponding command representations as well as bit representations (e.g., Ord&lsqb;<highlight><bold>0</bold></highlight>&rsqb;, Ord&lsqb;<highlight><bold>1</bold></highlight>&rsqb;) for each type of ordering semantic. For example, a request having a forward-ordered designation may be coded as &ldquo;req&lt;fworder&gt;&rdquo; and may be pre-pended with first two bits of the request being represented as <highlight><bold>1</bold></highlight> and <highlight><bold>0</bold></highlight>, where the first bit <highlight><bold>404</bold></highlight> Ord&lsqb;<highlight><bold>0</bold></highlight>&rsqb;&equals;1, and the second bit <highlight><bold>403</bold></highlight> Ord&lsqb;<highlight><bold>1</bold></highlight>&rsqb;&equals;0. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows an example of a request data packet <highlight><bold>500</bold></highlight> that may be created by, for example, a node controller or switching agent <highlight><bold>140</bold></highlight> in response to transaction request from a node. As shown, request data packet <highlight><bold>500</bold></highlight> may have bits in locations as shown, as well as additional bits in locations not shown. The bits in locations E and F, may be the ordering bits Ord&lsqb;<highlight><bold>0</bold></highlight>&rsqb; and Ord&lsqb;<highlight><bold>1</bold></highlight>&rsqb; <highlight><bold>502</bold></highlight> indicating the semantic ordering established by the node controller. As indicated in columns <highlight><bold>403</bold></highlight> and <highlight><bold>404</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the appropriate combination of the bits <highlight><bold>0</bold></highlight> and <highlight><bold>1</bold></highlight> can be inserted in locations E and F of data packet <highlight><bold>500</bold></highlight> to indicate the particular semantic ordering type of the request. In embodiments of the invention, the data packet <highlight><bold>500</bold></highlight> may be, for example, 32 bits, 64 bits, 144 bits, etc. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> Request data packet <highlight><bold>500</bold></highlight> may include bits <highlight><bold>503</bold></highlight> in locations G through L that may include a stream identifier (StrmID) created by a node controller to indicate that the data packet <highlight><bold>500</bold></highlight> belongs to a particular ordered stream. Data packet <highlight><bold>500</bold></highlight> may include bits <highlight><bold>504</bold></highlight> in locations N through S that may include node identifier (NodeID) which designates the identity of the requesting or sending node that originated the request. Requests that have the same StreamID and/or the same NodeID belong to the same orderd group. Collectively, the StrmID and the NodeID may be referred to herein as an ordered group identifier. Data packet <highlight><bold>500</bold></highlight> may include additional bits <highlight><bold>501</bold></highlight> in locations U through Y that may carry other header and/or payload information related to the request. For example, header information may include a destination node ID indicating the identity of the node where the request is to be delivered (i.e., destination node). Data packet <highlight><bold>500</bold></highlight> may contain additional fields such as a packet type, request type, transaction address, request length, etc. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Now, each of the semantic ordering types will be described in more detail. An un-ordered request transaction (req&lt;unorder&gt;) may have no specific ordering designation. An un-ordered transaction may be allowed to pass other un-ordered transaction and can be executed as it is received by a request manager, node controller or other processing device. A forward-ordered request transaction (req&lt;fworder&gt;) may be ordered with respect to all future request transactions, thus, request transactions issued in the future (i.e., issued after the forward-ordered request) may not be allowed to be executed ahead of the forward-ordered request transactions. A backward-ordered request transaction (req&lt;bworder&gt;) may be ordered with respect to all the previously issued or previously received request transactions, thus, later issued request transactions having backward-ordered semantics may not be allowed to be executed ahead of the earlier issued request transactions (i.e., issued before the backward ordered request transaction). A sequentially or strictly-ordered request transaction (req&lt;sorder&gt;) is both forward and backward-ordered with respect to other request transactions. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows a listing <highlight><bold>600</bold></highlight> illustrating the ordering relationship among semantically ordered transaction requests in accordance with embodiments of the present invention. For example, node <highlight><bold>110</bold></highlight> may issue Request A through Request W. Requests A through W may be read requests, write requests, other suitable requests, or any combination thereof. The requests may be issued, for example, by processors <highlight><bold>111</bold></highlight> through <highlight><bold>112</bold></highlight> to node controller <highlight><bold>115</bold></highlight>. Node controller may establish semantic ordering for each request and send the request or a group of requests to a request manager <highlight><bold>148</bold></highlight> or to another node such as destination agent. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> In this example, Request A may be issued before Request B which is issued before Request C, and so on. As further shown, issue order starts from top to bottom, thus Request A is ahead of Request B in issue order, Request B is ahead of Request C, and so on. Of course, based on established semantic ordering for each request, actual processing order may be different. Requests that are listed without semantic ordering would typically considered as un-ordered (i.e., Req&lt;unorder&gt;). </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Node controller <highlight><bold>115</bold></highlight> in conjunction with one or more of the processors <highlight><bold>111</bold></highlight> through <highlight><bold>112</bold></highlight> may establish semantic ordering for the issued requests. In embodiments of the invention, manager <highlight><bold>148</bold></highlight> based on the established ordering semantics may forward the requests to the appropriate node for processing. In alternative embodiments of the invention, one of the node controllers such as controller <highlight><bold>115</bold></highlight> may forward the ordered requests to the appropriate node or destination agent for processing. For example, Request B may be established with a forward-ordering (fworder), thus future request transactions may not be allowed to be processed ahead of the forward-ordered request transaction. As indicated, since Request C was issued after (i.e., in the future) Request B&lt;fworder&gt;, thus, Request C cannot pass or be processed before Request B&lt;fworder&gt;(as indicated by the X). Since Request A is not ordered with respect the other requests, Request B&lt;fworder&gt;can pass or be processed before Request A. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> In another example, Request M may be established with backward-ordering (bworder), thus, this backward-ordered request can not be processed ahead of any earlier issued request. As indicated, since Request L was issued before (i.e., earlier than) Request M&lt;bworder&gt;, thus, Request M&lt;bworder&gt; may not pass or be processed before Request L (as indicated by the X). Since Request N is issued after (i.e., not earlier than) Request M&lt;bworder&gt;, thus, Request N can pass or processed before Request M&lt;bworder&gt;. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> Referring again to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, Request V may be established with sequential-ordering (sorder) indicating that no other request can pass the sequential-ordered request. Sequential-ordering may indicate that the corresponding request should be executed in the specified order in which the sequential-ordered request was issued. Thus, a sequential-ordered request may be considered to have a strict ordering relationship with respect to other issued requests. For example, since Request W was issued after Request V&lt;sorder&gt;, thus, Request W may not be executed before Request V&lt;sorder&gt; (as indicated by the X). Since Request U has been issued before Request V&lt;sorder&gt;, thus, Request V&lt;sorder&gt; may not be executed before Request U (as indicated by the X). </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> shows a table <highlight><bold>700</bold></highlight> indicating the ordering relationships between transactions that belong to the same ordered group. Table <highlight><bold>700</bold></highlight> shows relationships between previous requests <highlight><bold>701</bold></highlight> having ordering semantics <highlight><bold>702</bold></highlight> and subsequent requests <highlight><bold>704</bold></highlight> having ordering semantics <highlight><bold>703</bold></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> An &ldquo;O&rdquo; entry in the table <highlight><bold>700</bold></highlight> may indicate that the subsequent request <highlight><bold>704</bold></highlight> with the corresponding ordering semantics <highlight><bold>703</bold></highlight> is ordered with respect to the previous request <highlight><bold>701</bold></highlight> with corresponding ordering semantics <highlight><bold>702</bold></highlight>. Accordingly, these ordered requests must be processed in accordance with the ordering semantics. For example, a backward-ordered subsequent request <highlight><bold>704</bold></highlight> is ordered (i.e., designated with an O) with respect to all previously issued and/or previously received request transactions <highlight><bold>701</bold></highlight>, so backward ordered subsequent requests should be processed after the earlier requests have been processed. In another example, a forward-ordered subsequent request <highlight><bold>704</bold></highlight> is ordered (i.e., designated with an O) with respect to a sequentially-ordered previous request <highlight><bold>702</bold></highlight>, so the sequentially-ordered previous request should be processed before the forward-ordered subsequent request. Also, the forward-ordered subsequent request <highlight><bold>704</bold></highlight> is ordered (i.e., designated with an O) with respect to a forward-ordered previous request <highlight><bold>701</bold></highlight>, so the forward-ordered previous request should be processed before the forward-ordered subsequent request. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> Referring again to table <highlight><bold>700</bold></highlight>, a &ldquo;--&rdquo; indicates that the requests having the indicated semantic ordering are not ordered with respect to each other and they can be processed in any order at the destination node. For example, a forward-ordered subsequent request <highlight><bold>704</bold></highlight> can be processed in any order with respect to an un-ordered and/or a backward-ordered previous request <highlight><bold>701</bold></highlight>. Now the operation of an embodiment of the present invention relating to semantically ordered requests will be described referring to the flow chart shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> and block diagram shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The flow chart of <cross-reference target="DRAWINGS">FIG. 8</cross-reference> describes a method for managing transaction requests in a multi-node architecture in accordance with embodiments of the present invention. In embodiments of the present invention, ordering semantics may be exported with each transaction request. Ordering semantics may define, for example, rules by which a transaction or request is allowed to be processed or completed before another transaction at the receiving agent. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> For ease of illustration, <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a simplified version of system <highlight><bold>100</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows a requesting agent <highlight><bold>901</bold></highlight> that is coupled with receiving agent <highlight><bold>902</bold></highlight>. The receiving agent <highlight><bold>902</bold></highlight> may be further coupled to destination agent <highlight><bold>903</bold></highlight> and destination agent <highlight><bold>904</bold></highlight>. It is recognized that requesting agent is indirectly coupled to both destination agents <highlight><bold>903</bold></highlight>, <highlight><bold>904</bold></highlight> through receiving agent <highlight><bold>902</bold></highlight>. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Requesting agent <highlight><bold>901</bold></highlight> may be any node or component in system <highlight><bold>100</bold></highlight> that sends requests (e.g., read and/or write requests) to another node or component in the system. For example, any of the nodes such as first node <highlight><bold>110</bold></highlight> or the input/output node <highlight><bold>150</bold></highlight> may be the requesting agent <highlight><bold>901</bold></highlight>. It is recognized that any one of the processors, for example, processor <highlight><bold>122</bold></highlight> and/or one of the controllers such as node controller <highlight><bold>135</bold></highlight> can be the requesting agent. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Receiving agent <highlight><bold>902</bold></highlight> may be any node or component in system <highlight><bold>100</bold></highlight> that receives requests from the requesting agent <highlight><bold>901</bold></highlight>. For example, any of the node controllers such as controller <highlight><bold>125</bold></highlight>, or any of the processors such as processor <highlight><bold>163</bold></highlight>, and the switching agent <highlight><bold>140</bold></highlight> can be a receiving agent <highlight><bold>902</bold></highlight>. In alternative embodiments of the present invention, the input/output node <highlight><bold>150</bold></highlight> may be the receiving agent. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> Destination agents <highlight><bold>903</bold></highlight>, <highlight><bold>904</bold></highlight> may be one or more nodes or components in system <highlight><bold>100</bold></highlight> that are the designated destination for the particular request. For example, any of the processors such as processors <highlight><bold>131</bold></highlight> and/or processors <highlight><bold>161</bold></highlight> can be the destination agents. In embodiments of the invention, switching agent <highlight><bold>140</bold></highlight> and/or input/output node <highlight><bold>150</bold></highlight> may be destination agents. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIGS. 8 and 9</cross-reference>, requesting agent <highlight><bold>901</bold></highlight> sends one or more requests (e.g., Request A, Request B, etc.) to receiving agent <highlight><bold>902</bold></highlight>. The request may be a single request or a group of ordered requests. A group of ordered requests are requests that have the same StreamID and/or the same requesting NodeID. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> In an exemplary embodiment of the present invention, the request(s) may be issued by one or more processors <highlight><bold>111</bold></highlight> to <highlight><bold>112</bold></highlight> to, for example, the node controller <highlight><bold>115</bold></highlight>. Node controller <highlight><bold>115</bold></highlight> may generate for each request, a request data packet <highlight><bold>500</bold></highlight> including data representing, for example, a request type, Node ID, a destination ID, a stream ID and established semantic ordering information (e.g., ordering bits Ord&lsqb;<highlight><bold>0</bold></highlight>&rsqb; and Ord&lsqb;<highlight><bold>1</bold></highlight>&rsqb;). Requests that belong to the same ordered group may share the same StreamID and/or same NodeID. Node controller <highlight><bold>115</bold></highlight> may send the generated request data packet <highlight><bold>500</bold></highlight> for each request to receiving agent <highlight><bold>902</bold></highlight> or alternatively, node controller, acting as the receiving agent <highlight><bold>902</bold></highlight>, may examine the request and send the request to the appropriate destination agent <highlight><bold>903</bold></highlight>, <highlight><bold>904</bold></highlight>. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Receiving agent <highlight><bold>902</bold></highlight> receives the request(s), for example, Request A from requesting agent. In one example, a switch manager such as manager <highlight><bold>148</bold></highlight> will manage the received request(s) for the receiving agent (e.g., switching agent <highlight><bold>140</bold></highlight>). In alternative embodiments of the invention, the node controller <highlight><bold>115</bold></highlight>, for example, or input/output node <highlight><bold>150</bold></highlight> may manage the received requests. As referred to herein, Request A, Request B, etc. each include the request data packet <highlight><bold>500</bold></highlight> with information corresponding to its respective request. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Receiving agent <highlight><bold>902</bold></highlight> forwards a previous received request, for example, Request A to its destination agent for processing (<highlight><bold>805</bold></highlight>). For example, the destination agent for Request A may be agent <highlight><bold>903</bold></highlight>. Receiving agent <highlight><bold>902</bold></highlight> receives and examines the next or subsequent request, for example, Request B whose destination node may be agent <highlight><bold>904</bold></highlight> (<highlight><bold>807</bold></highlight>). </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Receiving agent <highlight><bold>902</bold></highlight> determines whether the subsequent request (e.g., Request B) and the previously received request (Request A) belong to the same ordered group (<highlight><bold>809</bold></highlight>). As indicated above, requests belong to the same ordered group if they have the same StreamID and/or the same requesting NodeID. If the subsequent request does not belong to same ordered group as the previous request, then there is no ordering requirement between the requests and the receiving agent <highlight><bold>902</bold></highlight> forwards the next request towards the destination agent, for example, agent <highlight><bold>904</bold></highlight> (<highlight><bold>833</bold></highlight>). </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> If the next request belongs to the same ordered group as the previous request, then the requests must be processed in the proper order and the receiving agent <highlight><bold>902</bold></highlight> determines whether an &ldquo;ordering fork&rdquo; exists between the subsequent request and the previously received request (<highlight><bold>811</bold></highlight>). The term &ldquo;ordering fork&rdquo; as used herein, may refer to a point at the receiving agent <highlight><bold>902</bold></highlight> where a request stream is split into multiple separate streams and ordering between these streams can not be guaranteed. In other words, an ordering fork exists at a receiving agent when requests that belong to the same ordered group are being sent to different destinations. Accordingly, a &ldquo;fork&rdquo; is encountered where a first request is sent to one destination while a subsequent request, in the same ordered group, is being sent to another destination. Thus, in this example, Request A and Request B belong to the same ordered group, but have different destinations. For example, Request A is destined for agent <highlight><bold>903</bold></highlight> and Request B is destined for agent <highlight><bold>904</bold></highlight>. Therefore, in this example, with respect to Request A and Request B, an &ldquo;ordering fork&rdquo; is encountered at the receiving node. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> In embodiments of the present invention, if an ordering fork does not exist (i.e., requests that belong to the same ordered group are being sent to the same destination agent), then the receiving agent <highlight><bold>902</bold></highlight> forwards the subsequent request towards the designated destination agent (<highlight><bold>833</bold></highlight>). The destination agent receives requests that belong to the same ordered group and processes them in the order in which they were received. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> If in step <highlight><bold>811</bold></highlight>, an ordering fork exists, receiving agent <highlight><bold>902</bold></highlight> determines whether a &ldquo;request complete&rdquo; message has been received for the previously sent request that belongs to the same ordered group, for example, Request A (<highlight><bold>813</bold></highlight>). A request complete may be sent by a destination agent to indicate that the previously sent request has been completed. If the request complete message has been received by the receiving agent <highlight><bold>902</bold></highlight>, then the receiving agent <highlight><bold>902</bold></highlight> may forward the next request that belong to the same ordered group towards the designated destination agent for processing (<highlight><bold>833</bold></highlight>). </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> If the request complete message has not been received by the receiving agent <highlight><bold>902</bold></highlight>, the receiving agent <highlight><bold>902</bold></highlight> determines whether the subsequent or next request, in the same ordered group as the earlier request, is an un-ordered request (i.e., req&lt;unorder&gt;) (<highlight><bold>815</bold></highlight>). If the next request is an unordered request, then the receiving agent <highlight><bold>902</bold></highlight> waits for one or more request complete messages from the destination agent for previously issued and/or previously received forward-ordered (i.e., req&lt;fworder&gt;) and/or sequential-ordered (i.e., req&lt;sorder&gt;) requests issued on a different path at the ordering fork (<highlight><bold>835</bold></highlight>). After the awaited request complete message(s) have been received, the receiving agent <highlight><bold>902</bold></highlight> forwards the next request to the destination agent for processing (<highlight><bold>833</bold></highlight>). After the request has been forwarded to the destination agent, the receiving agent examines the next request in the ordered group (<highlight><bold>807</bold></highlight>). </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> If the next request is not an un-ordered request, then the receiving agent <highlight><bold>902</bold></highlight> determines whether the next request, in the same ordered group as the earlier request, is a forward-ordered request (<highlight><bold>817</bold></highlight>). If the next request is a forward-ordered request, then the receiving agent <highlight><bold>902</bold></highlight> waits for one or more request complete messages from the destination agent for previously received forward-ordered and/or sequential-ordered requests issued on a different path at the ordering fork (<highlight><bold>835</bold></highlight>). After the awaited request complete message(s) have been received, the receiving agent forwards the next request to the destination agent for processing (<highlight><bold>833</bold></highlight>). After the request has been forwarded to the destination agent, the receiving agent examines the next request in the ordered group (<highlight><bold>807</bold></highlight>). </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> If the next request is not an un-ordered and forward-ordered request, then the receiving agent <highlight><bold>902</bold></highlight> determines whether the next request is an backward-ordered request (<highlight><bold>819</bold></highlight>). If the next request is a backward-ordered request, then the receiving agent <highlight><bold>902</bold></highlight> waits for one or more request complete messages from the destination agent for previously received un-ordered, forward-ordered, backward-ordered and/or sequential-ordered requests issued on a different path at the ordering fork (<highlight><bold>837</bold></highlight>). After the awaited request complete message(s) have been received, the receiving agent forwards the next request to the destination agent for processing (<highlight><bold>833</bold></highlight>). After the request has been forwarded to the destination agent, the receiving agent examines the next request in the ordered group (<highlight><bold>807</bold></highlight>). </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> If the next request is not an un-ordered, forward-ordered request or a backward-ordered request, then the receiving agent <highlight><bold>902</bold></highlight> determines whether the next request, in the same ordered group as the earlier request, is a sequentially-ordered request (<highlight><bold>821</bold></highlight>). If the next request is a sequentially-ordered request, then the receiving agent <highlight><bold>902</bold></highlight> waits for one or more request complete messages from the destination node for previously received un-ordered, forward-ordered, backward-ordered and/or sequential-ordered requests issued on a different path at the ordering fork (<highlight><bold>837</bold></highlight>). After the awaited request complete message(s) have been received, the receiving agent forwards the next request to the destination agent for processing (<highlight><bold>833</bold></highlight>). After the request has been forwarded to the destination agent, the receiving agent examines the next request in the ordered group (<highlight><bold>807</bold></highlight>). </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Ordering semantics may apply to transactions that belong to the same ordered group. In embodiments of the present invention, requests may belong to the same ordering group if, for example, the requests have the same streaming ID (i.e., StrmID), same issuing NodeID and/or belong to the same peripheral domain (e.g., system specific collection of addresses such as the addresses located at an I/O bus). It is recognized that additional criteria may be used to established that requests belong to the same ordering group. Since, coherent and non-coherent transactions represent transactions of different type, no ordering relationship may be defined between these types of transactions. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The present invention may be used to for efficient pipelining of ordered requests in a multi-node architecture. Several embodiments of the present invention are specifically illustrated and/or described herein. However, it will be appreciated that modifications and variations of the present invention are covered by the above teachings and within the purview of the appended claims without departing from the spirit and intended scope of the invention. For example, while the nodes in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> are shown containing one or two processors, a node may contain any number of processors. In one embodiment, a node contains only one processor, and in another embodiment a node contains sixteen processors. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> As another example, while the nodes in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> are connected through receiving agent <highlight><bold>140</bold></highlight>, in another embodiment two or more nodes may be directly connected to each other and the switching agent could be implemented in a distributed manner integrated in the node controllers of the node(s). For example, in a system with that has two nodes, the node controller of a first node may be connected to the node controller of a second node. In another embodiment, the node controller for a node may be part of a processor in that node. For example, a first node in a system may only contain one processor, and the node controller for that node may be part of that processor. In addition, a node (e.g., node <highlight><bold>110</bold></highlight>) may contain one or more processors and an input/output hub. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of managing transaction requests in a multi-node architecture, the method comprising: 
<claim-text>forwarding a previously received ordered group request to a destination agent; </claim-text>
<claim-text>determining whether a next received ordered group request belongs to a same ordered group as the previously received ordered group request; </claim-text>
<claim-text>determining whether an ordering fork is encountered if the next received ordered group request belongs to the same ordered group as the previously received ordered group request; </claim-text>
<claim-text>if an ordering fork is encountered, determining whether a request complete message for the previously received ordered group request has been received; and </claim-text>
<claim-text>if the request complete message for the previously received ordered group request has not been received and the next received ordered group request in the same ordered group is at least one of a un-ordered request and a forward-ordered request, then forwarding the next received ordered group request to the destination agent after the request complete message for the previously received at least one of a forward-ordered request and a sequential-ordered request issued on a different path at the ordering fork has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>forwarding the next received ordered group request to the destination agent if the next received ordered group request belongs to a different ordered group than the ordered group of the previously received ordered group request. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>forwarding the next received ordered group request to the destination agent if no ordering fork is encountered. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>forwarding the next received ordered group request in the same ordered group to the destination agent if the request complete message for the previously received ordered group request has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>if the request complete message for the previously received ordered group request has not been received and the next received ordered group request in the same ordered group is at least one of a backward-ordered request and a sequentially-ordered request, then forwarding the next received ordered group request to the destination agent after the request complete message for the previously received at least one of a un-ordered, forward-ordered, backward-ordered and sequential-ordered requests issued on the different path at the ordering fork has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A system of managing transaction requests in a multi-node architecture, the system comprising: 
<claim-text>a requesting agent to issue one or more ordered group requests; </claim-text>
<claim-text>a receiving agent to receive the one or more issued ordered group requests and to examine the one or more issued ordered group requests; and </claim-text>
<claim-text>a destination agent to process the one or more issued ordered group requests, wherein the receiving agent to examine the one or more issued ordered group requests to determine whether a request complete message for a previously received ordered group request has been received, and if the request complete message for the previously received ordered group request has not been received and a next received ordered group request is at least one of a un-ordered request and a forward-ordered request, then the receiving agent to forward the next received ordered group request to the destination agent after the request complete message for the previously received at least one of a forward-ordered request and a sequential-ordered request issued on a different path at an ordering fork has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein receiving agent further determines whether the next received ordered group request belongs to a same ordered group as the previously received ordered group request. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the receiving agent forwards the next received ordered group request to the destination agent if the next received ordered group request belongs to a different ordered group than the ordered group of the previously received ordered group request. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the receiving agent forwards the next received ordered group request in the same ordered group as the previously received ordered group request to the destination agent if the request complete message for the previously received ordered group request has been received. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein the receiving agent forwards the next received ordered group request to the destination agent if no ordering fork is encountered. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein if the request complete message for the previously received ordered group request has not been received and the next received ordered group request is at least one of a backward-ordered request and a sequentially-ordered request, then the receiving agent forwards the next received ordered group request to the destination agent after the request complete message for the previously received at least one of a un-ordered, forward-ordered, backward-ordered and sequential-ordered requests issued on the different path at the ordering fork has been received. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A receiving agent for managing transaction requests in a multi-node architecture, wherein the receiving agent comprising: 
<claim-text>a processor to examine the one or more received ordered group requests and to determine whether a request complete message for a previously received ordered group request has been received, and if the request complete message for the previously received ordered group request has not been received and a next received ordered group request is at least one of a un-ordered request and a forward-ordered request, then the processor to forward the next received ordered group request to a destination agent after the request complete message for the previously received at least one of a forward-ordered request and a sequential-ordered request issued on a different path at an ordering fork has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The receiving agent of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein the processor further determines whether the next received ordered group request belongs to a same ordered group as the previously received ordered group request. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The receiving agent of <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the processor forwards the next received ordered group request to the destination agent if the next received ordered group request belongs to a different ordered group than the ordered group of the previously received ordered group request. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The receiving agent of <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the processor forwards the next received ordered group request in the same ordered group as the previously received ordered group request to the destination agent if the request complete message for the previously received ordered group request has been received. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The receiving agent of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein the processor forwards the next received ordered group request to the destination agent if no ordering fork is encountered. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The receiving agent of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein if the request complete message for the previously received ordered group request has not been received and the next received ordered group request is at least one of a backward-ordered request and a sequentially-ordered request, then the processor forwards the next received ordered group request to the destination agent after the request complete message for the previously received at least one of a un-ordered, forward-ordered, backward-ordered and sequential-ordered requests issued on the different path at the ordering fork has been received. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A method for managing transaction requests in a multi-node architecture, the method comprising: 
<claim-text>examining one or more received ordered group requests; and </claim-text>
<claim-text>determining whether a request complete message for a previously received ordered group request has been received, and if the request complete message for the previously received ordered group request has not been received and a next received ordered group request is at least one of a un-ordered request and a forward-ordered request, then forwarding the next received ordered group request to a destination agent after the request complete message for the previously received at least one of a forward-ordered request and a sequential-ordered request issued on a different path at an ordering fork has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, further comprising: 
<claim-text>forwarding a previously received ordered group request to the destination agent. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, further comprising: 
<claim-text>determining whether the next received ordered group request belongs to a same ordered group as the previously received ordered group request. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, further comprising: 
<claim-text>forwarding the next received ordered group request to the destination agent if the next received ordered group request belongs to a different ordered group than the ordered group of the previously received ordered group request. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, further comprising: 
<claim-text>forwarding the next received ordered group request in the same ordered group as the previously received ordered group request to the destination agent if the request complete message for the previously received ordered group request has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, further comprising: 
<claim-text>forwarding the next received ordered group request to the destination agent if no ordering fork is encountered. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, further comprising, 
<claim-text>if the request complete message for the previously received ordered group request has not been received and the next received ordered group request is at least one of a backward-ordered request and a sequentially-ordered request, then forwarding the next received ordered group request to the destination agent after the request complete message for the previously received at least one of a un-ordered, forward-ordered, backward-ordered and sequential-ordered requests issued on the different path at the ordering fork has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A data signal embodied in a propagation medium, the data signal comprising: 
<claim-text>an ordered group identifier segment to indicate that the data signal belongs to a particular ordered group; and </claim-text>
<claim-text>an ordering bit segment to specify ordering semantics for processing transaction requests, wherein the ordering bit segment to indicate whether a previously received transaction request included in the data signal is at least one of a un-ordered, forward-ordered, backward-ordered and sequentially-ordered with respect to a next received transaction request that belongs to the same particular ordered group. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The data signal of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein the ordered group identifier segment further comprising: 
<claim-text>a stream identifier segment to indicate that the data signal belongs to a particular ordered stream, wherein the data signal having the same stream identifier segment are semantically ordered with respect to each other. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The data signal of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein the ordered group identifier segment further comprising: 
<claim-text>a node identifier segment to indicate that the data signal was issued by a particular node, wherein the data signal having the same node identifier segment are semantically ordered with respect to each other. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The data signal of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein the next received transaction request cannot be processed before the previously received forward-ordered transaction request that belongs to the same particular ordered group. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The data signal of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein the previously received backward-ordered transaction request can be processed after the next-received transaction request that belongs to the same particular ordered group. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The data signal of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein the next received transaction request cannot be processed before the previously received sequentially-ordered transaction request and the previously received sequentially-ordered transaction request cannot be processed before a next received transaction request that belongs to the same particular ordered group. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. The data signal of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein the previously received un-ordered transaction request can be processed after a next received un-ordered transaction request that belongs to the same particular ordered group. </claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. A machine-readable medium having stored thereon a plurality of executable instructions, the plurality of instructions comprising instructions to: 
<claim-text>forward a previously received ordered group request to a destination agent; </claim-text>
<claim-text>determine whether a next received ordered group request belongs to a same ordered group as the previously received ordered group request; </claim-text>
<claim-text>determine whether an ordering fork is encountered if the next received ordered group request belongs to the same ordered group as the previously received ordered group request; </claim-text>
<claim-text>if an ordering fork is encountered, determine whether a request complete message for the previously received ordered group request has been received; and </claim-text>
<claim-text>if the request complete message for the previously received ordered group request has not been received and the next received ordered group request in the same ordered group is at least one of a un-ordered request and a forward-ordered request, then forward the next received ordered group request to the destination agent after the request complete message for the previously received at least one of a forward-ordered request and a sequential-ordered request issued on a different path at the ordering fork has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. The machine-readable medium of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference> having stored thereon additional executable instructions, the additional instructions comprising instructions to: 
<claim-text>forward the next received ordered group request to the destination agent if the next received ordered group request belongs to a different ordered group than the ordered group of the previously received ordered group request. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. The machine-readable medium of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference> having stored thereon additional executable instructions, the additional instructions comprising instructions to: 
<claim-text>forward the next received ordered group request to the destination agent if no ordering fork is encountered. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. The machine-readable medium of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference> having stored thereon additional executable instructions, the additional instructions comprising instructions to: 
<claim-text>forward the next received ordered group request in the same ordered group to the destination agent if the request complete message for the previously received ordered group request has been received. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, further comprising: 
<claim-text>if the request complete message for the previously received ordered group request has not been received and the next received ordered group request in the same ordered group is at least one of a backward-ordered request and a sequentially-ordered request, then forward the next received ordered group request to the destination agent after the request complete message for the previously received at least one of a un-ordered, forward-ordered, backward-ordered and sequential-ordered requests issued on the different path at the ordering fork has been received.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>3</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005167A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005167A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005167A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005167A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005167A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005167A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030005167A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030005167A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
