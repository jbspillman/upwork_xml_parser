<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004721A1-20030102-D00000.TIF SYSTEM "US20030004721A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004721A1-20030102-D00001.TIF SYSTEM "US20030004721A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004721A1-20030102-D00002.TIF SYSTEM "US20030004721A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004721A1-20030102-D00003.TIF SYSTEM "US20030004721A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004721A1-20030102-D00004.TIF SYSTEM "US20030004721A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004721A1-20030102-D00005.TIF SYSTEM "US20030004721A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004721A1-20030102-D00006.TIF SYSTEM "US20030004721A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004721A1-20030102-D00007.TIF SYSTEM "US20030004721A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004721A1-20030102-D00008.TIF SYSTEM "US20030004721A1-20030102-D00008.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004721</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09891610</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010627</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G10L015/04</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>704</class>
<subclass>251000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Integrating keyword spotting with graph decoder to improve the robustness of speech recognition</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Guojun</given-name>
<family-name>Zhou</family-name>
</name>
<residence>
<residence-us>
<city>Portland</city>
<state>OR</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>PILLSBURY WINTHROP, LLP</name-1>
<name-2></name-2>
<address>
<address-1>P.O. BOX 10500</address-1>
<city>MCLEAN</city>
<state>VA</state>
<postalcode>22102</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">An arrangement is provided for integrating graph decoder with keyword spotting to improve the robustness of speech recognition. When a graph decoder based speech recognition mechanism fails to recognize a word sequence from input speech data, a keyword based speech recognition mechanism is activated to recognize the word sequence based on a set of keywords that are detected from the input data. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">RESERVATION OF COPYRIGHT </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This patent document contains information subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent, as it appears in the U.S. Patent and Trademark Office files or records but otherwise reserves all copyright rights whatsoever. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Aspects of the present invention relate to speech processing. Other aspects of the present invention relate to speech understanding. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> Most automated speech recognition systems employ a graph decoder to decode an acoustic feature sequence, measured from input speech data, into a word sequence that is allowed by an underlying language. A graph decoder may use acoustic models of words or phonemes (e.g., Hidden Markov Model or HMM) to translate an acoustic feature sequence into the most likely word sequence based on a language model that describes the allowed word sequences. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Such an automated speech recognition system with a graph decoder can recognize only word sequences that are explicitly allowed in the corresponding language model. This introduces limitations to the speech recognition system. For example, the sentence &ldquo;change to channel two, please&rdquo; may correspond to a valid word sequence according to a language model but the sentence &ldquo;change to, umm, channel two, please&rdquo; may not, even though the two sentences actually mean the same thing, both linguistically and semantically. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Different solutions have been used to improve the flexibility of a graph decoder based speech recognition system. In some recognition systems, different patterns of a same sentence may be explicitly modeled. In other recognition systems, the recognition of a word sequence may merely use the vocabulary without imposing any pre-defined sentence structure. In the former case, the modeling task may become overwhelming. In the latter case, the recognition result may become less meaningful because any word is now allowed to follow the previously recognized word even though most of the possible combinations may not correspond to meaningful sentences at all.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The present invention is further described in terms of exemplary embodiments, which will be described in detail with reference to the drawings. These embodiments are non-limiting exemplary embodiments, in which like reference numerals represent similar parts throughout the several views of the drawings, and wherein: </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a high level system architecture of embodiments of the present invention; </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates an exemplary internal structure of an integrated speech recognition mechanism and the environment in which it operates, according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows an exemplary language model represented using a finite state machine; </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows an exemplary language, represented as a plurality of word sequences, derived from a language model; </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates a different exemplary embodiment of the internal structure of an integrated speech recognition mechanism and the environment in which it operates, according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates an example of matching a list of keywords with a word sequence in a language; </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is an exemplary flowchart of a process, in which an integrated speech recognition mechanism improves the robustness of speech recognition by combining a graph decoder based recognition mechanism with a keyword based recognition mechanism, according to an embodiment of the present invention; and </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is an exemplary flowchart of a process, in which a keyword based speech recognition mechanism recognizes a word sequence based on spotted keywords according to an embodiment of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The invention is described below, with reference to detailed illustrative embodiments. It will be apparent that the invention can be embodied in a wide variety of forms, some of which may be quite different from those of the disclosed embodiments. Consequently, the specific structural and functional details disclosed herein are merely representative and do not limit the scope of the invention. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> The processing described below may be performed by a general-purpose computer alone or in connection with a special purpose computer. Such processing may be performed by a single platform or by a distributed processing platform. In addition, such processing and functionality can be implemented in the form of special purpose hardware or in the form of software being run by a general-purpose computer. Any data handled in such processing or created as a result of such processing can be stored in any memory as is conventional in the art. By way of example, such data may be stored in a temporary memory, such as in the RAM of a given computer system or subsystem. In addition, or in the alternative, such data may be stored in longer-term storage devices, for example, magnetic disks, rewritable optical disks, and so on. For purposes of the disclosure herein, a computer-readable media may comprise any form of data storage mechanism, including such existing memory technologies as well as hardware or circuit representations of such structures and of such data. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a high level system architecture of embodiments of the present invention. An integrated speech recognition mechanism <highlight><bold>100</bold></highlight> comprises a graph decoder based speech recognition mechanism <highlight><bold>110</bold></highlight> and a keyword based speech recognition mechanism <highlight><bold>120</bold></highlight>. The graph decoder based speech recognition mechanism <highlight><bold>110</bold></highlight> receives input speech data <highlight><bold>105</bold></highlight> and recognizes a word sequence <highlight><bold>125</bold></highlight>. If the graph decoder based speech recognition mechanism <highlight><bold>110</bold></highlight> fails to generate the word sequence <highlight><bold>125</bold></highlight>, the keyword based speech recognition mechanism <highlight><bold>120</bold></highlight> is activated to recognize the word sequence <highlight><bold>125</bold></highlight> based on at least some of the keywords detected from the input speech data <highlight><bold>105</bold></highlight>. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> In some speech recognition tasks, the number of word sequences that are recognizable by a speech recognizer is limited. One example application of such constrained speech recognition may be a home entertaining center where voice commands may used to control home appliances. In this scenario, there may be a small set of commands such as &ldquo;dim the light&rdquo; or &ldquo;lower the volume of the television&rdquo;. Each of such commands corresponds to a sequence of words. To understand these voice commands, a constrained speech recognizer may be deployed that recognizes spoken words according to a constrained language model that defines specific sequences of words, each of those sequences of words corresponds to a command. For example, the command &ldquo;dim the light&rdquo; is a sequence of three words &ldquo;dim&rdquo;, &ldquo;the&rdquo;, &ldquo;light&rdquo; that are arranged in a specified order or pattern. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In a generic speech recognition environment, when a transcription of speech data (corresponding to a sequence of words) is generated, the meaning or the semantics of a transcribed sequence of words may be unknown to the speech recognizer. Often, a language understanding module further analyzes the recognized sequence of words to interpret the semantics of the sequence of words. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> In constrained speech recognition, recognition of a sequence of words may directly lead to understanding because association of sequences of words to the semantics of the sequences may be made prior to the recognition of spoken words. For example, in an automated voice controlled home entertainment center, there may be a total of 10 commands corresponding to 10 different sequences of words. In this case, each sequence of words (e.g., &ldquo;lower the volume of the television&rdquo;) may have clearly defined semantics. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates an exemplary internal structure of the integrated speech recognition mechanism <highlight><bold>100</bold></highlight> and the environment in which it operates, according to an embodiment of the present invention. The graph decoder based speech recognition mechanism <highlight><bold>110</bold></highlight> comprises an acoustic feature extractor <highlight><bold>210</bold></highlight>, a graph decoder <highlight><bold>230</bold></highlight>, and a recognition acceptance mechanism <highlight><bold>220</bold></highlight>. The acoustic feature extractor <highlight><bold>210</bold></highlight> measures certain pre-defined acoustic features from the input speech <highlight><bold>105</bold></highlight>. Such extracted acoustic features are fed to the graph decoder <highlight><bold>230</bold></highlight> that recognizes sequences of words from the input speech <highlight><bold>105</bold></highlight> based on both acoustic models <highlight><bold>250</bold></highlight> and a language model <highlight><bold>240</bold></highlight>. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The acoustic models <highlight><bold>250</bold></highlight> may be phoneme based, in which each word is modeled according to one or more phonemes. The acoustic models <highlight><bold>250</bold></highlight> are used to identify words from acoustic signals. A language model specifies allowed sequences of words that are consistent with the underlying language. A language model may be constructed based on finite state machines and specification of each allowed sequence of words in a language model may be statistical. The language model <highlight><bold>240</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> may correspond to a generic language model or it may correspond to a constrained language model. The latter is similar to the former except that it may describe a much smaller set of allowed sequences of words. For instance, a language model used in an automated home entertainment environment may specify only 10 allowed sequences of words (corresponding to 10 commands). The language model <highlight><bold>240</bold></highlight> is used to recognize valid sequences of words. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows an exemplary language model expressed in a finite state machine <highlight><bold>300</bold></highlight>. A finite state machine comprises a plurality of states and the transitions among different states. For example, node <highlight><bold>305</bold></highlight> is a state representing word &ldquo;tell&rdquo; which may transit to state <highlight><bold>310</bold></highlight> representing word &ldquo;me&rdquo;. The finite state machine <highlight><bold>300</bold></highlight> includes multiple paths, each of which corresponds to an allowed sequence of words. For example, the path comprising states <highlight><bold>305</bold></highlight>, <highlight><bold>310</bold></highlight>, <highlight><bold>315</bold></highlight>, <highlight><bold>320</bold></highlight>, <highlight><bold>325</bold></highlight>, <highlight><bold>330</bold></highlight>, <highlight><bold>335</bold></highlight>, and <highlight><bold>345</bold></highlight> corresponds to allowed sequence of words &ldquo;tell me about the weather in New York&rdquo;; while the path comprising states <highlight><bold>307</bold></highlight>, <highlight><bold>312</bold></highlight>, <highlight><bold>320</bold></highlight>, <highlight><bold>325</bold></highlight>, <highlight><bold>330</bold></highlight>, <highlight><bold>335</bold></highlight>, and <highlight><bold>340</bold></highlight> corresponds to allowed sequence of words &ldquo;how is the weather in New Orleans&rdquo;. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Each state in a finite state machine may branch into different paths and each branching path may be specified (modeled) according to a probability. For example, in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, state <highlight><bold>325</bold></highlight> corresponding to word &ldquo;weather&rdquo; may transit to two different states (depending on the input speech <highlight><bold>105</bold></highlight>). One is state <highlight><bold>330</bold></highlight> corresponding to work &ldquo;in&rdquo; and state <highlight><bold>365</bold></highlight> corresponding to word &ldquo;back&rdquo;, where the former transit is specified with a high probability 0.93 and the latter is specified with a low probability 0.07. Such probability may indicate that 93% of the time, people say &ldquo;. . . weather in . . . &rdquo; while only 7% of the time, people say &ldquo;. . . weather back . . . &rdquo;. Such statistics may be obtained and incorporate into a language model based on statistical training. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> A plurality of allowed sequences of words may be derived from the finite state machine <highlight><bold>300</bold></highlight>. In <cross-reference target="DRAWINGS">FIG. 4, a</cross-reference> total of 19 sequences of words are illustrated and they are the valid sequences of words allowed according to the exemplary language model described by the finite state machine <highlight><bold>300</bold></highlight>. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> The graph decoder <highlight><bold>230</bold></highlight> first recognizes individual spoken words based on the acoustic models <highlight><bold>250</bold></highlight> and then determines whether the sequence of the recognized words corresponds to an allowed sequence of words according to the language model <highlight><bold>240</bold></highlight>. In constrained speech recognition, once a sequence of recognized words is identified as valid, the semantic meaning of the recognized word sequence <highlight><bold>125</bold></highlight> may be understood. In language model <highlight><bold>240</bold></highlight>, there may be tags which mark the semantic meaning of recognized words. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> With the graph decoder based speech recognition mechanism <highlight><bold>110</bold></highlight>, a word sequence that is not explicitly modeled by the language model <highlight><bold>240</bold></highlight> may not be recognized. For instance, word sequence &ldquo;how is the weather in New Jersey&rdquo; will not be recognized using the language model illustrated in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. In addition, if an individual word is recognized wrong, the overall sequence of words may be considered as invalid. For example, if word &ldquo;weather&rdquo; is misrecognized as &ldquo;feather&rdquo;, the graph decoder may reject the entire word sequence &ldquo;tell me about the feather in Washington state&rdquo; as invalid. In this case, the graph decoder <highlight><bold>230</bold></highlight> may simply generate an error code to indicate a failure. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> A word sequence may also be considered as invalid due to other reasons. For example, the graph decoder <highlight><bold>230</bold></highlight> may yield a confidence measure with respect to each recognized word sequence. Such a confidence measure may be designed to reflect how sure the recognition mechanism is regarding its recognition result. A low confidence measure may indicate that the recognition result may be questionable. In <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the recognition acceptance mechanism <highlight><bold>220</bold></highlight> determines whether the graph decoder <highlight><bold>230</bold></highlight> is able to recognize a word sequence with reasonable confidence. The decision may be made based on the recognition result from the graph decoder <highlight><bold>230</bold></highlight>, which may be an error code or a recognized word sequence associated with a confidence measure. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> The recognition acceptance mechanism <highlight><bold>220</bold></highlight> may internally employ a threshold that specifies a minimum acceptable confidence level with respect to a recognition result. In this case, any recognized word sequence from the graph decoder <highlight><bold>230</bold></highlight> that has a confidence measure lower than the threshold may be considered as invalid. In this case, the recognized word sequence is not accepted and the recognition acceptance mechanism <highlight><bold>220</bold></highlight> may consider that the graph decoder <highlight><bold>230</bold></highlight> has failed. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> In some applications, a word sequence may correspond to a question or a command, which requires an answer or reaction. For example, word sequence &ldquo;lower the volume of the television&rdquo; may trigger an automatic control mechanism to tune down the volume of the television. In those applications, failing to recognize a word sequence may significantly degrade the performance of the underlying system in which the automated speech recognition mechanism serves as a front-end interface. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Referring again to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, in the integrated speech recognition mechanism <highlight><bold>100</bold></highlight>, an alternative recognition mechanism, the keyword based speech recognition mechanism <highlight><bold>120</bold></highlight>, is provided. Such an alternative recognition mechanism is activated by the recognition acceptance mechanism <highlight><bold>220</bold></highlight> whenever the graph decoder based speech recognition mechanism <highlight><bold>110</bold></highlight> fails (either error or low confidence) to recognize the word sequence <highlight><bold>125</bold></highlight> from the input speech <highlight><bold>105</bold></highlight>. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the keyword based speech recognition mechanism <highlight><bold>120</bold></highlight> comprises a keyword spotting mechanism <highlight><bold>260</bold></highlight>, a keyword list <highlight><bold>270</bold></highlight>, and a keyword based recognition mechanism <highlight><bold>280</bold></highlight>. In <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the keyword spotting mechanism <highlight><bold>260</bold></highlight> detects one or more keywords that are included in the keyword list <highlight><bold>270</bold></highlight> from the input speech <highlight><bold>105</bold></highlight>. The acoustic models <highlight><bold>250</bold></highlight> are used in detecting the keywords. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The keyword list <highlight><bold>270</bold></highlight> may include words that are substantially significant. The significance of a word may be determined according to application needs. For example, word &ldquo;television&rdquo; may be considered as significant in an application for automated control of home appliances. Word &ldquo;weather&rdquo; may be significant in a voice portal application that provides information services. On the other hand, words &ldquo;the&rdquo;, &ldquo;a&rdquo;, or &ldquo;and&rdquo; may not be significant in most of the applications. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Keyword spotting is a technique that recognizes individual spoken keywords (pre-determined) from a continuous speech. Word spotting yields a list of keywords that are often spotted at discontinuous locations yet arranged in certain order. For example, the list of detected keywords &ldquo;lower . . . volume . . . television&rdquo; may be detected from a continuous speech that corresponds to &ldquo;lower the volume of the television&rdquo;. Similarly, the list of keywords &ldquo;. . . weather . . . New Orleans&rdquo; may be detected from a continuous speech that corresponds to &ldquo;tell me about the weather in New Orleans&rdquo;. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Often, words are specified as keywords because they may be important in determining the meaning of an underlying sentence. This may be particularly so in constrained speech recognition. For example, assume there are a total of 10 commands (a constrained language) used in an automated voice based home appliance control and two of the commands related to television control, corresponding to either lower the volume or raise the volume of the television, if keywords &ldquo;lower&rdquo; and &ldquo;television&rdquo; are spotted from a continuous speech, the underlying command may be fairly confidently recognized as &ldquo;lower the volume of the television&rdquo;. The recognition may be achieved even when some of the keywords are not detected (e.g., keyword &ldquo;volume&rdquo; is not detected in the above example) because there is only one command or one word sequence in the constrained language (10 commands) that contains both word &ldquo;lower&rdquo; and &ldquo;television&rdquo;. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> In the keyword based speech recognition mechanism <highlight><bold>120</bold></highlight>, shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the keyword based recognition mechanism <highlight><bold>280</bold></highlight> recognizes the word sequence <highlight><bold>125</bold></highlight> based on a list of detected keywords. The keyword based recognition mechanism <highlight><bold>280</bold></highlight> may identify an allowed word sequence, according to the language model <highlight><bold>240</bold></highlight>, that best matches the list of the detected keywords. The matching may be performed directly against the language model <highlight><bold>240</bold></highlight>. For example, a search may be performed with respect to the language model <highlight><bold>240</bold></highlight> to identify a path in a finite state machine that comprises the states of words that are most consistent with the list of detected keywords. The consistency may be defined with respect to both the occurrences of the words and the order in which the words are arranged. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> Matching a list of keywords with a valid word sequence may also be performed against a list of all possible word sequences that are allowed by the language model <highlight><bold>240</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates different exemplary embodiments of the present invention, in which the keyword based speech recognition mechanism <highlight><bold>120</bold></highlight> in the integrated speech recognition mechanism <highlight><bold>100</bold></highlight> recognizes the word sequence <highlight><bold>125</bold></highlight> by matching a list of detected keywords with allowed word sequences of a language. In <cross-reference target="DRAWINGS">FIG. 5, a</cross-reference> language <highlight><bold>510</bold></highlight> is derived from the language model <highlight><bold>240</bold></highlight>. The language <highlight><bold>510</bold></highlight> corresponds to all the word sequences that are allowed according to the language model <highlight><bold>240</bold></highlight>. An example of a language is illustrated in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, which is derived from the exemplary language model (or finite state machine) <highlight><bold>300</bold></highlight> illustrated in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The matching may be performed in a simple exhaustive search (if the number of allowed word sequences is reasonably small) or in an index based search (if the number of allowed word sequences is large). In an exhaustive search, the keyword based recognition mechanism <highlight><bold>280</bold></highlight> may simply match the list of detected keywords (from the keyword spotting mechanism <highlight><bold>260</bold></highlight>) with each and every word sequence in the language <highlight><bold>510</bold></highlight>. Each match may yield a matching score, which may be defined based on both the number of words that find a match and the degree of match with respect to the relative position of the matched words. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Matching result may correspond to a single best match or a set of matching word sequences. A best match may be identified as the one with the highest matching score. A set of matched valid word sequences may be identified as the matches whose scores are above a given threshold. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> To facilitate index based search, indices to valid word sequences may be established prior to the search. In <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, an index mechanism <highlight><bold>520</bold></highlight> is established with respect to the keyword list <highlight><bold>270</bold></highlight> and is used to facilitate index based search. For each keyword in the keyword list, indices may be built that point to the word sequences in the language <highlight><bold>510</bold></highlight> that contain the keyword. It is also possible to establish indices based on a combination of keywords. Such indices may significantly reduce search space. For example, referring back to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the indices of single word &ldquo;weather&rdquo; point to almost all the valid word sequences. The indices of the combination of both &ldquo;weather&rdquo; and &ldquo;New Orleans&rdquo; point to only four valid word sequences (<highlight><bold>410</bold></highlight>, <highlight><bold>420</bold></highlight>, <highlight><bold>430</bold></highlight>, and <highlight><bold>440</bold></highlight>). </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> With such established indices, to search for a match, the keyword based recognition mechanism <highlight><bold>280</bold></highlight> may first identify relevant indices from index mechanism <highlight><bold>520</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 5</cross-reference>) and then match a list of detected keywords with the word sequences that are retrieved from the language <highlight><bold>510</bold></highlight> using the indices. This is illustrated in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. In <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, an exemplary list of detected keywords is &ldquo;tell . . . weather . . . New Orleans. . . &rdquo;. The index for word &ldquo;weather&rdquo; points to 12 out of 13 allowed word sequences. The combination of &ldquo;weather&rdquo; and &ldquo;New Orleans&rdquo; points to only 4 allowed word sequences. By matching &ldquo;tell . . . weather . . . New Orleans&rdquo; to the four indexed word sequences, only two matches are found (&ldquo;tell me about the weather in New Orleans&rdquo; and &ldquo;tell me about the weather back in New Orleans&rdquo;). Although different, both word sequences may have the same semantics. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is an exemplary flowchart of a process, in which the integrated speech recognition mechanism <highlight><bold>100</bold></highlight> improves the robustness of speech recognition by combining the graph decoder based recognition mechanism <highlight><bold>110</bold></highlight> with the keyword based recognition mechanism <highlight><bold>120</bold></highlight>. Input speech data <highlight><bold>105</bold></highlight> is first received at act <highlight><bold>710</bold></highlight>. The acoustic feature extractor <highlight><bold>210</bold></highlight> extracts, at act <highlight><bold>720</bold></highlight>, various acoustic features from the input speech data. Based on the acoustic features, the graph decoder <highlight><bold>230</bold></highlight> recognizes, at act <highlight><bold>730</bold></highlight>, a word sequence, using the language model <highlight><bold>240</bold></highlight>, from the input speech data based on the acoustic features. The recognition result is evaluated at act <highlight><bold>740</bold></highlight>. If the result is acceptable, the recognized word sequence from the graph decoder is outputted, at act <highlight><bold>750</bold></highlight>, as recognition result. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> If the recognition result from the graph decoder based speech recognition mechanism <highlight><bold>110</bold></highlight> is not acceptable, determined at act <highlight><bold>740</bold></highlight>, the keyword based speech recognition mechanism <highlight><bold>120</bold></highlight> is activated. The keyword spotting mechanism <highlight><bold>260</bold></highlight> detects, at act <highlight><bold>760</bold></highlight>, keywords, using the acoustic models <highlight><bold>250</bold></highlight>, from the input speech data. The list of detected keywords are then used to recognize, at act <highlight><bold>770</bold></highlight>, whether the underlying sentence corresponds to a valid word sequence. A valid word sequence may be identified by matching the list of detected keywords with the word sequences allowed by the language model <highlight><bold>240</bold></highlight>. The recognition result from the keyword based speech recognition mechanism is outputted, at act <highlight><bold>780</bold></highlight>, as the recognition result. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is an exemplary flowchart of a process, in which the keyword based speech recognition mechanism <highlight><bold>120</bold></highlight> uses a list of detected keywords to recognize valid word sequences based on appropriately established indices. The appropriate indices that link keywords to valid word sequences are established priori to keyword based speech recognition. Valid word sequences are first derived, at act <highlight><bold>810</bold></highlight>, from the language model <highlight><bold>240</bold></highlight>. Indices to the valid word sequences are established, at act <highlight><bold>820</bold></highlight>, with respect to the keyword list <highlight><bold>270</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> When the keyword based speech recognition mechanism <highlight><bold>120</bold></highlight> is activated, a list of keywords is first detected, at act <highlight><bold>830</bold></highlight> using the acoustic models <highlight><bold>250</bold></highlight>, from the input speech data based on the keyword list <highlight><bold>270</bold></highlight>. Using the indices between the keywords and the valid word sequences, candidate word sequences containing detected keywords are identified at act <highlight><bold>840</bold></highlight>. One or more word sequences may be recognized, at act <highlight><bold>850</bold></highlight>, from the candidate word sequences that match with the detected list of keywords. Such matched word sequence is outputted, at act <highlight><bold>860</bold></highlight>, as recognition result. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> While the invention has been described with reference to the certain illustrated embodiments, the words that have been used herein are words of description, rather than words of limitation. Changes may be made, within the purview of the appended claims, without departing from the scope and spirit of the invention in its aspects. Although the invention has been described herein with reference to particular structures, acts, and materials, the invention is not to be limited to the particulars disclosed, but rather extends to all equivalent structures, acts, and, materials, such as are within the scope of the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A system, comprising: 
<claim-text>a graph-decoder based speech recognition mechanism for recognizing a word sequence, from input speech data, based on a language model using a graph decoder; and </claim-text>
<claim-text>a keyword based speech recognition mechanism for recognizing, when the graph-decoder based speech recognition mechanism fails, the word sequence based on at least one keyword detected from the input speech data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the graph decoder based speech recognition mechanism comprises: 
<claim-text>a graph decoder for recognizing the word sequence from the input speech data based on at least one acoustic feature to generate a recognition result, the recognizing being performed according to at least one acoustic model and a language model; and </claim-text>
<claim-text>a recognition acceptance mechanism for determining whether to accept the recognition result generated by the graph decoder based speech recognition mechanism or to activate, when the recognition result from the graph decoder based recognition mechanism is not accepted, the keyword based speech recognition mechanism. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The system according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, further comprising an acoustic feature extractor to extract the at least one acoustic feature from the input speech data. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The system according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the keyword based speech recognition mechanism comprises: 
<claim-text>a keyword spotting mechanism, activated by the recognition acceptance mechanism, for detecting, using the at least one acoustic models, the at least one keyword from the input speech data based on a keyword list; and </claim-text>
<claim-text>a keyword based recognition mechanism for recognizing the word sequence using the at least one keyword, detected by the keyword spotting mechanism, based on the language model. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A keyword based speech recognition mechanism, comprising: 
<claim-text>a keyword spotting mechanism for detecting, using at least one acoustic models, at least one keyword from input speech data based on a keyword list; and </claim-text>
<claim-text>a keyword based recognition mechanism for recognizing a word sequence using the at least one keyword, detected by the keyword spotting mechanism, based on a language model. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The system according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further comprising: 
<claim-text>an index mechanism for establishing indices to word sequences that are allowed by the language model based on the keyword list, the indices being used by the keywork based recognition mechanism to recognize the word sequence. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A method, comprising: 
<claim-text>recognizing, by a graph decoder, a word sequence from input speech data based on at least one acoustic features, the recognizing being performed using at least one acoustic model and a language model; </claim-text>
<claim-text>determining, by a recognition acceptance mechanism, whether to accept the word sequence or to activate a keyword based speech recognition mechanism; and </claim-text>
<claim-text>performing, by a keyword based speech recognition mechanism when it is activated, keyword based speech recognition from the input speech data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the performing comprises: 
<claim-text>detecting, by a keyword spotting mechanism, at least one keyword, according to a keyword list, from the input speech data based on the at least one acoustic model; and </claim-text>
<claim-text>recognizing, by a keyword based recognition mechanism, the word sequence using the at least one keyword, detected by the detecting, based on the language model. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, further comprising: 
<claim-text>receiving the input speech data; and </claim-text>
<claim-text>extracting, by an acoustic feature extractor, the at least one acoustic feature from the input speech data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A method for keyword based speech recognition, comprising: 
<claim-text>detecting, by a keyword spotting mechanism, at least one keyword, according to a keyword list, from input speech data based on at least one acoustic model; and </claim-text>
<claim-text>recognizing, by a keyword based recognition mechanism, a word sequence using the at least one keyword, detected by the detecting, based on a language model. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, further comprising: 
<claim-text>deriving at least one word sequence from the language model to generate a language associated with the language model; and </claim-text>
<claim-text>establishing indices to the at least one word sequence based on each word in the keyword list prior to the detecting. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the recognizing comprises: 
<claim-text>identifying zero or more candidate word sequences, through the indices between each keyword in the keyword list to the at least one word sequence, that contain at least some of the at least one keyword; and </claim-text>
<claim-text>determining the word sequence from the zero or more candidate word sequences that match the at least one keyword. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A computer-readable medium encoded with a program, the program, when executed, causing: 
<claim-text>recognizing, by a graph decoder, a word sequence from input speech data based on at least one acoustic features, the recognizing being performed using at least one acoustic model and a language model; </claim-text>
<claim-text>determining, by a recognition acceptance mechanism, whether to accept the word sequence or to activate a keyword based speech recognition mechanism; and </claim-text>
<claim-text>performing, by a keyword based speech recognition mechanism when it is activated, keyword based speech recognition from the input speech data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The medium according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the performing comprises: 
<claim-text>detecting, by a keyword spotting mechanism, at least one keyword, according to a keyword list, from the input speech data based on the at least one acoustic model; and </claim-text>
<claim-text>recognizing, by a keyword based recognition mechanism, the word sequence using the at least one keyword, detected by the detecting, based on the constrined language model. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The medium according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, the program, when executed, further causing: 
<claim-text>receiving the input speech data; and </claim-text>
<claim-text>extracting, by an acoustic feature extractor, the at least one acoustic feature from the input speech data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A computer-readable medium encoded with a program for keyword based speech recognition, the program, when executed, causing: 
<claim-text>detecting, by a keyword spotting mechanism, at least one keyword, according to a keyword list, from input speech data based on at least one acoustic model; and </claim-text>
<claim-text>recognizing, by a keyword based recognition mechanism, a word sequence using the at least one keyword, detected by the detecting, based on a constrined language model. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The medium according to <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, the program, when executed, further causing: 
<claim-text>deriving at least one word sequence from the language model to generate a language associated with the language model; and </claim-text>
<claim-text>establishing indices to the at least one word sequence based on each word in the keyword list prior to the detecting. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The medium according to <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, wherein the recognizing comprises: 
<claim-text>identifying zero or more candidate word sequences, through the indices between each keyword in the keyword list to the at least one word sequence, that contain at least some of the at least one keyword; and </claim-text>
<claim-text>determining the word sequence from the zero or more candidate word sequences that match the at least one keyword.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>2</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004721A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004721A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004721A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004721A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004721A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004721A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004721A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004721A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004721A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
