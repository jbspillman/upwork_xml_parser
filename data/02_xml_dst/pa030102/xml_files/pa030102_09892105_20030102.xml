<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004711A1-20030102-M00001.NB SYSTEM "US20030004711A1-20030102-M00001.NB" NDATA NB>
<!ENTITY US20030004711A1-20030102-M00001.TIF SYSTEM "US20030004711A1-20030102-M00001.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-M00002.NB SYSTEM "US20030004711A1-20030102-M00002.NB" NDATA NB>
<!ENTITY US20030004711A1-20030102-M00002.TIF SYSTEM "US20030004711A1-20030102-M00002.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-M00003.NB SYSTEM "US20030004711A1-20030102-M00003.NB" NDATA NB>
<!ENTITY US20030004711A1-20030102-M00003.TIF SYSTEM "US20030004711A1-20030102-M00003.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-M00004.NB SYSTEM "US20030004711A1-20030102-M00004.NB" NDATA NB>
<!ENTITY US20030004711A1-20030102-M00004.TIF SYSTEM "US20030004711A1-20030102-M00004.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-M00005.NB SYSTEM "US20030004711A1-20030102-M00005.NB" NDATA NB>
<!ENTITY US20030004711A1-20030102-M00005.TIF SYSTEM "US20030004711A1-20030102-M00005.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-M00006.NB SYSTEM "US20030004711A1-20030102-M00006.NB" NDATA NB>
<!ENTITY US20030004711A1-20030102-M00006.TIF SYSTEM "US20030004711A1-20030102-M00006.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00000.TIF SYSTEM "US20030004711A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00001.TIF SYSTEM "US20030004711A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00002.TIF SYSTEM "US20030004711A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00003.TIF SYSTEM "US20030004711A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00004.TIF SYSTEM "US20030004711A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00005.TIF SYSTEM "US20030004711A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00006.TIF SYSTEM "US20030004711A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00007.TIF SYSTEM "US20030004711A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00008.TIF SYSTEM "US20030004711A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00009.TIF SYSTEM "US20030004711A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00010.TIF SYSTEM "US20030004711A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030004711A1-20030102-D00011.TIF SYSTEM "US20030004711A1-20030102-D00011.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004711</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09892105</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010626</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G10L019/12</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>704</class>
<subclass>223000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method for coding speech and music signals</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Kazuhito</given-name>
<family-name>Koishida</family-name>
</name>
<residence>
<residence-us>
<city>Redmond</city>
<state>WA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Vladimir</given-name>
<family-name>Cuperman</family-name>
</name>
<residence>
<residence-us>
<city>Goleta</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Amir</given-name>
<middle-name>H.</middle-name>
<family-name>Majidimehr</family-name>
</name>
<residence>
<residence-us>
<city>Woodinville</city>
<state>WA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Allen</given-name>
<family-name>Gersho</family-name>
</name>
<residence>
<residence-us>
<city>Santa Barbara</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>Microsoft Corporation</organization-name>
<address>
<city>Redmond</city>
<state>WA</state>
</address>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>LEYDIG VOIT &amp; MAYER, LTD</name-1>
<name-2></name-2>
<address>
<address-1>TWO PRUDENTIAL PLAZA, SUITE 4900</address-1>
<address-2>180 NORTH STETSON AVENUE</address-2>
<city>CHICAGO</city>
<state>IL</state>
<postalcode>60601-6780</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The present invention provides a transform coding method efficient for music signals that is suitable for use in a hybrid codec, whereby a common Linear Predictive (LP) synthesis filter is employed for both speech and music signals. The LP synthesis filter switches between a speech excitation generator and a transform excitation generator, in accordance with the coding of a speech or music signal, respectively. For coding speech signals, the conventional CELP technique may be used, while a novel asymmetrical overlap-add transform technique is applied for coding music signals. In performing the common LP synthesis filtering, interpolation of the LP coefficients is conducted for signals in overlap-add operation regions. The invention enables smooth transitions when the decoder switches between speech and music decoding modes. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This invention is directed in general to a method and an apparatus for coding signals, and more particularly, for coding both speech signals and music signals. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Speech and music are intrinsically represented by very different signals. With respect to the typical spectral features, the spectrum for voiced speech generally has a fine periodic structure associated with pitch harmonics, with the harmonic peaks forming a smooth spectral envelope, while the spectrum for music is typically much more complex, exhibiting multiple pitch fundamentals and harmonics. The spectral envelope may be much more complex as well. Coding technologies for these two signal modes are also very disparate, with speech coding being dominated by model-based approaches such as Code Excited Linear Prediction (CELP) and Sinusoidal Coding, and music coding being dominated by transform coding techniques such as Modified Lapped Transformation (MLT) used together with perceptual noise masking. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> There has recently been an increase in the coding of both speech and music signals for applications such as Internet multimedia, TV/radio broadcasting, teleconferencing or wireless media. However, production of a universal codec to efficiently and effectively reproduce both speech and music signals is not easily accomplished, since coders for the two signal types are optimally based on separate techniques. For example, linear prediction-based techniques such as CELP can deliver high quality reproduction for speech signals, but yield unacceptable quality for the reproduction of music signals. On the other hand, the transform coding-based techniques provide good quality reproduction for music signals, but the output degrades significantly for speech signals, especially in low bit-rate coding. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> An alternative is to design a multi-mode coder that can accommodate both speech and music signals. Early attempts to provide such coders are for example, the Hybrid ACELP/Transform Coding Excitation coder and the Multi-mode Transform Predictive Coder (MTPC). Unfortunately, these coding algorithms are too complex and/or inefficient for practically coding speech and music signals. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> It is desirable to provide a simple and efficient hybrid coding algorithm and architecture for coding both speech and music signals, especially adapted for use in low bit-rate environments. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The invention provides a transform coding method for efficiently coding music signals. The transform coding method is suitable for use in a hybrid codec, whereby a common Linear Predictive (LP) synthesis filter is employed for reproduction of both speech and music signals. The LP synthesis filter input is switched between a speech excitation generator and a transform excitation generator, pursuant to the coding of a speech signal or a music signal, respectively. In a preferred embodiment, the LP synthesis filter comprises an interpolation of the LP coefficients. In the coding of speech signals, a conventional CELP or other LP technique may be used, while in the coding of music signals, an asymmetrical overlap-add transform technique is preferably applied. A potential advantage of the invention is that it enables a smooth output transition at points where the codec has switched between speech coding and music coding. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Additional features and advantages of the invention will be made apparent from the following detailed description of illustrative embodiments that proceeds with reference to the accompanying figures.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> While the appended claims set forth the features of the present invention with particularity, the invention, together with its objects and advantages, may be best understood from the following detailed description taken in conjunction with the accompanying drawings of which: </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates exemplary network-linked hybrid speech/music codecs according to an embodiment of the invention; </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference><highlight><italic>a </italic></highlight>illustrates a simplified architectural diagram of a hybrid speech/music encoder according to an embodiment of the invention; </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference><highlight><italic>b </italic></highlight>illustrates a simplified architectural diagram of a hybrid speech/music decoder according to an embodiment of the invention; </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference><highlight><italic>a </italic></highlight>is a logical diagram of a transform encoding algorithm according to an embodiment of the invention; </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference><highlight><italic>b </italic></highlight>is a timing diagram depicting an asymmetrical overlap-add window operation and its effect according to an embodiment of the invention; </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a block diagram of a transform decoding algorithm according to an embodiment of the invention; </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 5</cross-reference><highlight><italic>a </italic></highlight>and <highlight><bold>5</bold></highlight><highlight><italic>b </italic></highlight>are flow charts illustrating exemplary steps taken for encoding speech and music signals according to an embodiment of the invention; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 6</cross-reference><highlight><italic>a </italic></highlight>and <highlight><bold>6</bold></highlight><highlight><italic>b </italic></highlight>are flow charts illustrating exemplary steps taken for decoding speech and music signals according to an embodiment of the invention; and </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a simplified schematic illustrating a computing device architecture employed by a computing device upon which an embodiment of the invention may be executed.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The present invention provides an efficient transform coding method for coding music signals, the method being suitable for use in a hybrid codec, wherein a common Linear Predictive (LP) synthesis filter is employed for the reproduction of both speech and music signals. In overview, the input of the LP synthesis filter is dynamically switched between a speech excitation generator and a transform excitation generator, corresponding to the receipt of either a coded speech signal or a coded music signal, respectively. A speech/music classifier identifies an input speech/music signal as either speech or music and transfers the identified signal to either a speech encoder or a music encoder as appropriate. During coding of a speech signal, a conventional CELP technique may be used. However, a novel asymmetrical overlap-add transform technique is applied for the coding of music signals. In a preferred embodiment of the invention, the common LP synthesis filter comprises an interpolation of LP coefficients, wherein the interpolation is conducted every several samples over a region where the excitation is obtained via an overlap. Because the output of the synthesis filter is not switched, but only the input of the synthesis filter, a source of audible signal discontinuity is avoided. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> An exemplary speech/music codec configuration in which an embodiment of the invention may be implemented is described with reference to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. The illustrated environment comprises codecs <highlight><bold>110</bold></highlight>, <highlight><bold>120</bold></highlight> communicating with one another over a network <highlight><bold>100</bold></highlight>, represented by a cloud. Network <highlight><bold>100</bold></highlight> may include many well-known components, such as routers, gateways, hubs, etc. and may provide communications via either or both of wired and wireless media. Each codec comprises at least an encoder <highlight><bold>111</bold></highlight>, <highlight><bold>121</bold></highlight>, a decoder <highlight><bold>112</bold></highlight>, <highlight><bold>122</bold></highlight>, and a speech/music classifier <highlight><bold>113</bold></highlight>, <highlight><bold>123</bold></highlight>. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> In an embodiment of the invention, a common linear predictive synthesis filter is used for both music and speech signals. Referring to <cross-reference target="DRAWINGS">FIGS. 2</cross-reference><highlight><italic>a </italic></highlight>and <highlight><bold>2</bold></highlight><highlight><italic>b</italic></highlight>, the structure of an exemplary speech and music codec wherein the invention may be implemented is shown. In particular, <cross-reference target="DRAWINGS">FIG. 2</cross-reference><highlight><italic>a </italic></highlight>shows the high-level structure of a hybrid speech/music encoder, while <cross-reference target="DRAWINGS">FIG. 2</cross-reference><highlight><italic>b </italic></highlight>shows the high-level structure of a hybrid speech/music decoder. Referring to <cross-reference target="DRAWINGS">FIG. 2</cross-reference><highlight><italic>a</italic></highlight>, the speech/music encoder comprises a speech/music classifier <highlight><bold>250</bold></highlight>, which classifies an input signal as either a speech signal or a music signal. The identified signal is then transmitted accordingly to either a speech encoder <highlight><bold>260</bold></highlight> or a music encoder <highlight><bold>270</bold></highlight>, respectively, and a mode bit characterizing the speech/music nature of input signal is generated. For example, a mode bit of zero represents a speech signal and a mode bit of 1 represents a music signal. The speech encoder <highlight><bold>260</bold></highlight> encodes an input speech based on the linear predictive principle well known to those skilled in the art and outputs a coded speech bit-stream. The speech coding used is for example, a codebook excitation linear predictive (CELP) technique, as will be familiar to those of skill in the art. In contrast, the music encoder <highlight><bold>270</bold></highlight> encodes an input music signal according to a transform coding method, to be described below, and outputs a coded music bit-stream. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 2</cross-reference><highlight><italic>b</italic></highlight>, a speech/music decoder according to an embodiment of the invention comprises a linear predictive (LP) synthesis filter <highlight><bold>240</bold></highlight> and a speech/music switch <highlight><bold>230</bold></highlight> connected to the input of the filter <highlight><bold>240</bold></highlight> for switching between a speech excitation generator <highlight><bold>210</bold></highlight> and a transform excitation generator <highlight><bold>220</bold></highlight>. The speech excitation generator <highlight><bold>210</bold></highlight> receives the transmitted coded speech/music bit-stream and generates speech excitation signals. The music excitation generator <highlight><bold>220</bold></highlight> receives the transmitted coded speech/music signal and generates music excitation signals. There are two modes in the coder, namely a speech mode and a music mode. The mode of the decoder for a current frame or superframe is determined by the transmitted mode bit. The speech/music switch <highlight><bold>230</bold></highlight> selects an excitation signal source pursuant to the mode bit, selecting a music excitation signal in music mode and a speech excitation signal in speech mode. The switch <highlight><bold>230</bold></highlight> then transfers the selected excitation signal to the linear predictive synthesis filter <highlight><bold>240</bold></highlight> for producing the appropriate reconstructed signals. The excitation or residual in speech mode is encoded using a speech optimized technique such as Code Excited Linear Prediction (CELP) coding, while the excitation in music mode is quantified by a transform coding technique, for example a Transform Coding Excitation (TCX). The LP synthesis filter <highlight><bold>240</bold></highlight> of the decoder is common for both music and speech signals. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> A conventional coder for encoding either speech or music signals operates on blocks or segments, which are usually called frames, of 10 ms to 40 ms. Since in general, transform coding is more efficient when the frame size is large, these 10 ms to 40 ms frames are generally too short to align a transform coder to obtain acceptable quality, particularly at low bit rates. An embodiment of the invention therefore operates on superframes consisting of an integral number of standard 20 ms frames. A typical superframe sized used in an embodiment is 60 ms. Consequently, the speech/music classifier preferably performs its classification once for each consecutive superframe. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Unlike current transform coders for coding music signals, the coding process according to the invention is performed in the excitation domain. This is a product of the use of a single LP synthesis filter for the reproduction of both types of signals, speech and music. Referring to <cross-reference target="DRAWINGS">FIG. 3</cross-reference><highlight><italic>a</italic></highlight>, a transform encoder according to an embodiment of the invention is illustrated. A Linear Predictive (LP) analysis filter <highlight><bold>310</bold></highlight> analyzes music signals of the classified music superframe output from the speech/music classifier <highlight><bold>250</bold></highlight> to obtain appropriate Linear Predictive Coefficients (LPC). An LP quantization module <highlight><bold>320</bold></highlight> quantifies the calculated LPC coefficients. The LPC coefficients and the music signals of the superframe are then applied to an inverse filter <highlight><bold>330</bold></highlight> that has as input the music signal and generates as output a residual signal. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The use of superframes rather than typical frames aids in obtaining high quality transform coding. However, blocking distortion at superframe boundaries may cause quality problems. A preferred solution to alleviate the blocking distortion effect is found in an overlap-add window technique, for example, the Modified Lapped Transform (MLT) technique having an overlapping of adjacent frames of 50%. However, such a solution would be difficult to integrate into a CELP based hybrid codec because CELP employs zero overlap for speech coding. To overcome this difficulty and ensure the high quality performance of the system in music mode, an embodiment of the invention provides an asymmetrical overlap-add window method as implemented by overlap-add module <highlight><bold>340</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 3</cross-reference><highlight><italic>a</italic></highlight>. <cross-reference target="DRAWINGS">FIG. 3</cross-reference><highlight><italic>b </italic></highlight>depicts the asymmetrical overlap-add window operation and effects. Referring to <cross-reference target="DRAWINGS">FIG. 3</cross-reference><highlight><italic>b</italic></highlight>, the overlap-add window takes into account the possibility that the previous superframe may have different values for superframe length and overlap length denoted, for example, by N<highlight><subscript>p </subscript></highlight>and L<highlight><subscript>p</subscript></highlight>, respectively. The designators N<highlight><subscript>c </subscript></highlight>and L<highlight><subscript>c </subscript></highlight>represent the superframe length and the overlap length for the current superframe, respectively. The encoding block for the current superframe comprises the current superframe samples and overlap samples. The overlap-add windowing occurs at the first N<highlight><subscript>p </subscript></highlight>samples and the last L<highlight><subscript>p </subscript></highlight>samples in the current encoding block. By way of example and not limitation, an input signal x(n) is transformed by an overlap-add window function w(n) and produces a windowed signal y(n) as follows: </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>y</italic></highlight>(<highlight><italic>n</italic></highlight>)&equals;<highlight><italic>x</italic></highlight>(<highlight><italic>n</italic></highlight>)<highlight><italic>w</italic></highlight>(<highlight><italic>n</italic></highlight>), 0&lE;<highlight><italic>n&lE;N</italic></highlight><highlight><subscript>c</subscript></highlight><highlight><italic>N</italic></highlight><highlight><subscript>c</subscript></highlight><highlight><italic>&plus;L</italic></highlight><highlight><subscript>c</subscript></highlight>&minus;1&emsp;&emsp;(equation 1) </in-line-formula></paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> and the window function w(n) is defined as follows:  
<math-cwu id="MATH-US-00001">
<number>1</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>w</mi>
          <mo>&af;</mo>
          <mrow>
            <mo>(</mo>
            <mi>n</mi>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mo>{</mo>
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mstyle>
                    <mtext>&emsp;</mtext>
                  </mstyle>
                  <mo>&it;</mo>
                  <mrow>
                    <mrow>
                      <mi>sin</mi>
                      <mo>&af;</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mfrac>
                            <mi>&pi;</mi>
                            <mrow>
                              <mn>2</mn>
                              <mo>&it;</mo>
                              <msub>
                                <mi>L</mi>
                                <mi>p</mi>
                              </msub>
                            </mrow>
                          </mfrac>
                          <mo>&it;</mo>
                          <mrow>
                            <mo>(</mo>
                            <mrow>
                              <mi>n</mi>
                              <mo>+</mo>
                              <mn>0.5</mn>
                            </mrow>
                            <mo>)</mo>
                          </mrow>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                    <mo>,</mo>
                  </mrow>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mstyle>
                    <mtext>&emsp;</mtext>
                  </mstyle>
                  <mo>&it;</mo>
                  <mrow>
                    <mn>0</mn>
                    <mo>&leq;</mo>
                    <mi>n</mi>
                    <mo>&leq;</mo>
                    <mrow>
                      <msub>
                        <mi>L</mi>
                        <mi>p</mi>
                      </msub>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mn>1</mn>
                  <mo>,</mo>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mstyle>
                    <mtext>&emsp;</mtext>
                  </mstyle>
                  <mo>&it;</mo>
                  <mrow>
                    <msub>
                      <mi>L</mi>
                      <mi>p</mi>
                    </msub>
                    <mo>&leq;</mo>
                    <mi>n</mi>
                    <mo>&leq;</mo>
                    <mrow>
                      <msub>
                        <mi>N</mi>
                        <mi>c</mi>
                      </msub>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mn>1</mn>
                    <mo>-</mo>
                    <mrow>
                      <mi>sin</mi>
                      <mo>&af;</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mfrac>
                            <mi>&pi;</mi>
                            <mrow>
                              <mn>2</mn>
                              <mo>&it;</mo>
                              <msub>
                                <mi>L</mi>
                                <mi>c</mi>
                              </msub>
                            </mrow>
                          </mfrac>
                          <mo>&it;</mo>
                          <mrow>
                            <mo>(</mo>
                            <mrow>
                              <mi>n</mi>
                              <mo>-</mo>
                              <msub>
                                <mi>N</mi>
                                <mi>c</mi>
                              </msub>
                              <mo>+</mo>
                              <mn>0.5</mn>
                            </mrow>
                            <mo>)</mo>
                          </mrow>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </mrow>
                  <mo>,</mo>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <msub>
                    <mi>N</mi>
                    <mi>c</mi>
                  </msub>
                  <mo>&leq;</mo>
                  <mi>n</mi>
                  <mo>&leq;</mo>
                  <mrow>
                    <msub>
                      <mi>N</mi>
                      <mi>c</mi>
                    </msub>
                    <mo>+</mo>
                    <msub>
                      <mi>L</mi>
                      <mi>c</mi>
                    </msub>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>equation</mi>
          <mo>&it;</mo>
          <mstyle>
            <mtext>&emsp;</mtext>
          </mstyle>
          <mo>&it;</mo>
          <mn>2</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00001" file="US20030004711A1-20030102-M00001.NB"/>
<image id="EMI-M00001" wi="216.027" he="51.11505" file="US20030004711A1-20030102-M00001.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0026" lvl="7"><number>&lsqb;0026&rsqb;</number> wherein N<highlight><subscript>c </subscript></highlight>and L<highlight><subscript>c </subscript></highlight>are the superframe length and the overlap length of the current superframe, respectively. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> It can be seen from the overlap-add window form in <cross-reference target="DRAWINGS">FIG. 3</cross-reference><highlight><italic>b </italic></highlight>that the overlap-add areas <highlight><bold>390</bold></highlight>, <highlight><bold>391</bold></highlight> are asymmetrical, for example, the region marked <highlight><bold>390</bold></highlight> is different from the region marked <highlight><bold>391</bold></highlight>, and the overlap-add windows may be different in size from each other. Such size variable windows overcome the blocking effect and pre-echo. Also, since the overlap regions are small compared to the 50% overlap utilized in the MLT technique, this asymmetrical overlap-add window method is efficient for a transform coder integratable into a CELP based speech coder as will be described. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> Referring again to <cross-reference target="DRAWINGS">FIG. 3</cross-reference><highlight><italic>a</italic></highlight>, the residual signal output from the inverse LP filter <highlight><bold>330</bold></highlight> is processed by the asymmetrical overlap-add windowing module <highlight><bold>340</bold></highlight> for producing a windowed signal. The windowed signal is then input to a Discrete Cosine Transformation (DCT) module <highlight><bold>350</bold></highlight>, wherein the windowed signal is transformed into the frequency domain and a set of DCT coefficients obtained. The DCT transformation is defined as:  
<math-cwu id="MATH-US-00002">
<number>2</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mrow>
            <mi>Z</mi>
            <mo>&af;</mo>
            <mrow>
              <mo>(</mo>
              <mi>k</mi>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>=</mo>
          <mrow>
            <msqrt>
              <mfrac>
                <mn>2</mn>
                <mi>K</mi>
              </mfrac>
            </msqrt>
            <mo>&it;</mo>
            <mrow>
              <munderover>
                <mo>&Sum;</mo>
                <mrow>
                  <mi>i</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mrow>
                <mrow>
                  <mi>K</mi>
                  <mo>-</mo>
                  <mn>1</mn>
                </mrow>
              </munderover>
              <mo>&it;</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mrow>
                <mrow>
                  <mi>c</mi>
                  <mo>&af;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>k</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>&it;</mo>
                <mrow>
                  <mi>Z</mi>
                  <mo>&af;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>i</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>&it;</mo>
                <mrow>
                  <mi>cos</mi>
                  <mo>&af;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mfrac>
                      <mrow>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>i</mi>
                            <mo>+</mo>
                            <mn>0.5</mn>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mo>&it;</mo>
                        <mi>k</mi>
                        <mo>&it;</mo>
                        <mstyle>
                          <mtext>&emsp;</mtext>
                        </mstyle>
                        <mo>&it;</mo>
                        <mi>&pi;</mi>
                      </mrow>
                      <mi>K</mi>
                    </mfrac>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
        <mo>,</mo>
        <mrow>
          <mn>0</mn>
          <mo>&leq;</mo>
          <mi>k</mi>
          <mo>&leq;</mo>
          <mrow>
            <mi>K</mi>
            <mo>-</mo>
            <mn>1</mn>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>equation</mi>
          <mo>&it;</mo>
          <mstyle>
            <mtext>&emsp;</mtext>
          </mstyle>
          <mo>&it;</mo>
          <mn>3</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00002" file="US20030004711A1-20030102-M00002.NB"/>
<image id="EMI-M00002" wi="216.027" he="25.9119" file="US20030004711A1-20030102-M00002.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0029" lvl="7"><number>&lsqb;0029&rsqb;</number> where c(k) is defined as:  
<math-cwu id="MATH-US-00003">
<number>3</number>
<math>
<mrow>
  <mrow>
    <mi>c</mi>
    <mo>&af;</mo>
    <mrow>
      <mo>(</mo>
      <mi>k</mi>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mo>{</mo>
    <mrow>
      <mtable>
        <mtr>
          <mtd>
            <mrow>
              <mrow>
                <mn>1</mn>
                <mo>/</mo>
                <msqrt>
                  <mn>2</mn>
                </msqrt>
              </mrow>
              <mo>,</mo>
              <mrow>
                <mi>k</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
            </mrow>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mrow>
              <mn>1</mn>
              <mo>,</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mi>otherwise</mi>
            </mrow>
          </mtd>
        </mtr>
      </mtable>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>and</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>K</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>is</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>the</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>transformation</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>size</mi>
    </mrow>
  </mrow>
</mrow>
</math>
<mathematica-file id="MATHEMATICA-00003" file="US20030004711A1-20030102-M00003.NB"/>
<image id="EMI-M00003" wi="216.027" he="24.01245" file="US20030004711A1-20030102-M00003.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0030" lvl="7"><number>&lsqb;0030&rsqb;</number> Although the DCT transformation is preferred, other transformation techniques may also be applied, such techniques including the Modified Discrete Cosine Transformation (MDCT) and the Fast Fourier Transformation (FFT). In order to efficiently quantify the DCT coefficients, dynamic bit allocation information is employed as part of the DCT coefficients quantization. The dynamic bit allocation information is obtained from a dynamic bit allocation module <highlight><bold>370</bold></highlight> according to masking thresholds computed by a threshold masking module <highlight><bold>360</bold></highlight>, wherein the threshold masking is based on the input signal or on the LPC coefficients output from the LPC analysis module <highlight><bold>310</bold></highlight>. The dynamic bit allocation information may also be obtained from analyzing the input music signals. With the dynamic bit allocation information, the DCT coefficients are quantified by quantization module <highlight><bold>380</bold></highlight> and then transmitted to the decoder. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> In keeping with the encoding algorithm employed in the above-described embodiment of the invention, the transform decoder is illustrated in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. Referring to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the transform decoder comprises an inverse dynamic bit allocation module <highlight><bold>410</bold></highlight>, an inverse quantization module <highlight><bold>420</bold></highlight>, a DCT inverse transformation module <highlight><bold>430</bold></highlight>, an asymmetrical overlap-add window module <highlight><bold>440</bold></highlight>, and an overlap-add module <highlight><bold>450</bold></highlight>. The inverse dynamic bit allocation module <highlight><bold>410</bold></highlight> receives the transmitted bit allocation information output from the dynamic bit allocation module <highlight><bold>370</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 3</cross-reference><highlight><italic>a </italic></highlight>and provides the bit allocation information to the inverse quantization module <highlight><bold>420</bold></highlight>. The inverse quantization module <highlight><bold>420</bold></highlight> receives the transmitted music bit-stream and the bit allocation information and applies an inverse quantization to the bit-stream for obtaining decoded DCT coefficients. The DCT inverse transformation module <highlight><bold>430</bold></highlight> then conducts inverse DCT transformation of the decoded DCT coefficients and generates a time domain signal. The inverse DCT transformation is shown as follows:  
<math-cwu id="MATH-US-00004">
<number>4</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mrow>
            <mi>Z</mi>
            <mo>&af;</mo>
            <mrow>
              <mo>(</mo>
              <mi>i</mi>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>=</mo>
          <mrow>
            <msqrt>
              <mfrac>
                <mn>2</mn>
                <mi>K</mi>
              </mfrac>
            </msqrt>
            <mo>&it;</mo>
            <mrow>
              <munderover>
                <mo>&Sum;</mo>
                <mrow>
                  <mi>i</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mrow>
                <mrow>
                  <mi>K</mi>
                  <mo>-</mo>
                  <mn>1</mn>
                </mrow>
              </munderover>
              <mo>&it;</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mrow>
                <mrow>
                  <mi>c</mi>
                  <mo>&af;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>k</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>&it;</mo>
                <mrow>
                  <mi>Z</mi>
                  <mo>&af;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>k</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>&it;</mo>
                <mrow>
                  <mi>cos</mi>
                  <mo>&af;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mfrac>
                      <mrow>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>i</mi>
                            <mo>+</mo>
                            <mn>0.5</mn>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mo>&it;</mo>
                        <mi>k</mi>
                        <mo>&it;</mo>
                        <mstyle>
                          <mtext>&emsp;</mtext>
                        </mstyle>
                        <mo>&it;</mo>
                        <mi>&pi;</mi>
                      </mrow>
                      <mi>K</mi>
                    </mfrac>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
        <mo>,</mo>
        <mrow>
          <mn>0</mn>
          <mo>&leq;</mo>
          <mi>i</mi>
          <mo>&leq;</mo>
          <mrow>
            <mi>K</mi>
            <mo>-</mo>
            <mn>1</mn>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>equation</mi>
          <mo>&it;</mo>
          <mstyle>
            <mtext>&emsp;</mtext>
          </mstyle>
          <mo>&it;</mo>
          <mn>4</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00004" file="US20030004711A1-20030102-M00004.NB"/>
<image id="EMI-M00004" wi="216.027" he="25.9119" file="US20030004711A1-20030102-M00004.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0032" lvl="7"><number>&lsqb;0032&rsqb;</number> where c(k) is defined as:  
<math-cwu id="MATH-US-00005">
<number>5</number>
<math>
<mrow>
  <mrow>
    <mi>c</mi>
    <mo>&af;</mo>
    <mrow>
      <mo>(</mo>
      <mi>k</mi>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mo>{</mo>
    <mrow>
      <mtable>
        <mtr>
          <mtd>
            <mrow>
              <mrow>
                <mn>1</mn>
                <mo>/</mo>
                <msqrt>
                  <mn>2</mn>
                </msqrt>
              </mrow>
              <mo>,</mo>
              <mrow>
                <mi>k</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
            </mrow>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mrow>
              <mn>1</mn>
              <mo>,</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mi>otherwise</mi>
            </mrow>
          </mtd>
        </mtr>
      </mtable>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>and</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>K</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>is</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>the</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mi>transformation</mi>
      <mo>&it;</mo>
      <mstyle>
        <mtext>&emsp;</mtext>
      </mstyle>
      <mo>&it;</mo>
      <mrow>
        <mi>size</mi>
        <mo>.</mo>
      </mrow>
    </mrow>
  </mrow>
</mrow>
</math>
<mathematica-file id="MATHEMATICA-00005" file="US20030004711A1-20030102-M00005.NB"/>
<image id="EMI-M00005" wi="216.027" he="24.01245" file="US20030004711A1-20030102-M00005.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The overlap-add windowing module <highlight><bold>440</bold></highlight> performs the asymmetrical overlap-add windowing operation on the time domain signal, for example, &ycirc;&prime;(n)&equals;w(n)&ycirc;(n), where &ycirc;(n) represents the time domain signal, w(n) denotes the windowing function and &ycirc;&prime;(n) is the resulting windowed signal. The windowed signal is then fed into the overlap-add module <highlight><bold>450</bold></highlight>, wherein an excitation signal is obtained via performing an overlap-add operation By way of example and not limitation, an exemplary overlap-add operation is as follows:  
<math-cwu id="MATH-US-00006">
<number>6</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mover>
            <mi>e</mi>
            <mo>^</mo>
          </mover>
          <mo>&af;</mo>
          <mrow>
            <mo>(</mo>
            <mi>n</mi>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mo>{</mo>
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mrow>
                      <mrow>
                        <msub>
                          <mi>w</mi>
                          <mi>p</mi>
                        </msub>
                        <mo>&af;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>n</mi>
                            <mo>+</mo>
                            <msub>
                              <mi>N</mi>
                              <mi>p</mi>
                            </msub>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>&it;</mo>
                      <mrow>
                        <msub>
                          <mover>
                            <mi>y</mi>
                            <mo>^</mo>
                          </mover>
                          <mi>p</mi>
                        </msub>
                        <mo>&af;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>n</mi>
                            <mo>+</mo>
                            <msub>
                              <mi>N</mi>
                              <mi>p</mi>
                            </msub>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                    </mrow>
                    <mo>+</mo>
                    <mrow>
                      <mrow>
                        <msub>
                          <mi>w</mi>
                          <mi>c</mi>
                        </msub>
                        <mo>&af;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mi>n</mi>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>&it;</mo>
                      <mrow>
                        <msub>
                          <mover>
                            <mi>y</mi>
                            <mo>^</mo>
                          </mover>
                          <mi>c</mi>
                        </msub>
                        <mo>&af;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mi>n</mi>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                    </mrow>
                  </mrow>
                  <mo>,</mo>
                  <mrow>
                    <mn>0</mn>
                    <mo>&leq;</mo>
                    <mi>n</mi>
                    <mo>&leq;</mo>
                    <mrow>
                      <msub>
                        <mi>L</mi>
                        <mi>p</mi>
                      </msub>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mstyle>
                    <mtext>&emsp;</mtext>
                  </mstyle>
                  <mo>&it;</mo>
                  <mrow>
                    <mrow>
                      <msub>
                        <mover>
                          <mi>y</mi>
                          <mo>^</mo>
                        </mover>
                        <mi>c</mi>
                      </msub>
                      <mo>&af;</mo>
                      <mrow>
                        <mo>(</mo>
                        <mi>n</mi>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                    <mo>,</mo>
                    <mrow>
                      <msub>
                        <mi>L</mi>
                        <mi>p</mi>
                      </msub>
                      <mo>&leq;</mo>
                      <mi>n</mi>
                      <mo>&leq;</mo>
                      <mrow>
                        <msub>
                          <mi>N</mi>
                          <mi>c</mi>
                        </msub>
                        <mo>-</mo>
                        <mn>1</mn>
                      </mrow>
                    </mrow>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>equation</mi>
          <mo>&it;</mo>
          <mstyle>
            <mtext>&emsp;</mtext>
          </mstyle>
          <mo>&it;</mo>
          <mn>5</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00006" file="US20030004711A1-20030102-M00006.NB"/>
<image id="EMI-M00006" wi="216.027" he="24.97635" file="US20030004711A1-20030102-M00006.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0034" lvl="7"><number>&lsqb;0034&rsqb;</number> wherein &ecirc;(n) is the excitation signal, and &ycirc;<highlight><subscript>p</subscript></highlight>(n) and &ycirc;<highlight><subscript>c</subscript></highlight>(n) are the previous and current time domain signals, respectively. Functions w<highlight><subscript>p</subscript></highlight>(n) and w<highlight><subscript>c</subscript></highlight>(n) are respectively the overlap-add window functions for previous and current superframes. Values N<highlight><subscript>p </subscript></highlight>and N<highlight><subscript>c </subscript></highlight>are the sizes of the previous and current superframes respectively. Value L<highlight><subscript>p </subscript></highlight>is the overlap-add size of the previous superframe. The generated excitation signal &ecirc;(n) is then switchably fed into an LP synthesis filter as illustrated in <cross-reference target="DRAWINGS">FIG. 2</cross-reference><highlight><italic>b </italic></highlight>for reconstructing the original music signal. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> An interpolation synthesis technique is preferably applied in processing the excitation signal. The LP coefficients are interpolated every several samples over the region of 0&lE;n&lt;L<highlight><subscript>p</subscript></highlight>&minus;1, wherein the excitation is obtained employing the overlap-add operation. The interpolation of the LP coefficients is performed in the Line Spectral Pairs (LSP) domain, whereby the values of interpolated LSP coefficients are given by: </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>f</italic></highlight>(<highlight><italic>i</italic></highlight>)&equals;(1&minus;<highlight><italic>v</italic></highlight>(<highlight><italic>i</italic></highlight>)){circumflex over (<highlight><italic>f</italic></highlight>)}<highlight><subscript>p</subscript></highlight>(<highlight><italic>i</italic></highlight>)&plus;<highlight><italic>v</italic></highlight>(<highlight><italic>i</italic></highlight>){circumflex over (<highlight><italic>f</italic></highlight>)}<highlight><subscript>c</subscript></highlight>(<highlight><italic>i</italic></highlight>), 0&lE;<highlight><italic>i&lE;M</italic></highlight>&minus;1&emsp;&emsp;(equation 6) </in-line-formula></paragraph>
<paragraph id="P-0036" lvl="7"><number>&lsqb;0036&rsqb;</number> where {circumflex over (f)}<highlight><subscript>p</subscript></highlight>(i) and {circumflex over (f)}<highlight><subscript>c</subscript></highlight>(i are the quantified LSP parameters of the previous and current superframes respectively. Factor v(i) is the interpolation weighting factor, while value M is the order of the LP coefficients. After use of the interpolation technique, conventional LP synthesis techniques may be applied to the excitation signal for obtaining a reconstructed signal. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIGS. 5</cross-reference><highlight><italic>a </italic></highlight>and <highlight><bold>5</bold></highlight><highlight><italic>b</italic></highlight>, exemplary steps taken to encode interleaved input speech and music signals in accordance with an embodiment of the invention will be described. At step <highlight><bold>501</bold></highlight>, an input signal is received and a superframe is formed. At step <highlight><bold>503</bold></highlight>, it is decided whether the current superframe is different in type (i.e., music/speech) from a previous superframe. If the superframes are different, then a &ldquo;superframe transition&rdquo; is defined at the start of the current superframe and the flow of operations branches to step <highlight><bold>505</bold></highlight>. At step <highlight><bold>505</bold></highlight>, the sequence of the previous superframe and the current superframe is determined, for example, by determining whether the current superframe is music. Thus, for example, execution of step <highlight><bold>505</bold></highlight> results in a &ldquo;yes&rdquo; if the previous superframe is a speech superframe followed by a current music superframe. Likewise step <highlight><bold>505</bold></highlight> results in a &ldquo;no&rdquo; if the previous superframe is a music superframe followed by a current speech superframe. In step <highlight><bold>511</bold></highlight>, branching from a &ldquo;yes&rdquo; result at step <highlight><bold>505</bold></highlight>, the overlap length L<highlight><subscript>p </subscript></highlight>for the previous speech superframe is set to zero, meaning that no overlap-add window will be performed at the beginning of the current encoding block. The reason for this is that CELP based speech coders do not provide or utilize overlap signals for adjacent frames or superframes. From step <highlight><bold>511</bold></highlight>, transform encoding procedures are executed for the music superframe at step <highlight><bold>513</bold></highlight>. If the decision at step <highlight><bold>505</bold></highlight> results in a &ldquo;no&rdquo;, the operational flow branches to step <highlight><bold>509</bold></highlight>, where the overlap samples in the previous music superframe are discarded. Subsequently, CELP coding is performed in step <highlight><bold>515</bold></highlight> for the speech superframe. At step <highlight><bold>507</bold></highlight>, which branches from step <highlight><bold>503</bold></highlight> after a &ldquo;no&rdquo; result, it is decided whether the current superframe is a music or a speech superframe. If the current superframe is a music superframe, transform encoding is applied at step <highlight><bold>513</bold></highlight>, while if the current superframe is speech, CELP encoding procedures are applied at step <highlight><bold>515</bold></highlight>. After the transform encoding is completed at step <highlight><bold>513</bold></highlight>, an encoded music bit-stream is produced. Likewise after performing CELP encoding at step <highlight><bold>515</bold></highlight>, an encoded speech bit-stream is generated. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The transform encoding performed in step <highlight><bold>513</bold></highlight> comprises a sequence of sub-steps as shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference><highlight><italic>b</italic></highlight>. At step <highlight><bold>523</bold></highlight>, the LP coefficients of the input signals are calculated. At step <highlight><bold>533</bold></highlight>, the calculated LPC coefficients are quantized. At step <highlight><bold>543</bold></highlight>, an inverse filter operates on the received superframe and the calculated LPC coefficients to produce a residual signal x(n). At step <highlight><bold>553</bold></highlight>, the overlap-add window is applied to the residual signal x(n) by multiplying x(n) by the window function w(n) as follows: </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>y</italic></highlight>(<highlight><italic>n</italic></highlight>)&equals;<highlight><italic>x</italic></highlight>(<highlight><italic>n</italic></highlight>)<highlight><italic>w</italic></highlight>(<highlight><italic>n</italic></highlight>) </in-line-formula></paragraph>
<paragraph id="P-0039" lvl="7"><number>&lsqb;0039&rsqb;</number> wherein the window function w(n) is defined as in equation 2. At step <highlight><bold>563</bold></highlight>, the DCT transformation is performed on the windowed signal y(n) and DCT coefficients are obtained. At step <highlight><bold>583</bold></highlight>, the dynamic bit allocation information is obtained according to a masking threshold obtained in step <highlight><bold>573</bold></highlight>. Using the bit allocation information, the DCT coefficients are then quantified at step <highlight><bold>593</bold></highlight> to produce a music bit-stream. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> In keeping with the encoding steps shown in <cross-reference target="DRAWINGS">FIGS. 5</cross-reference><highlight><italic>a </italic></highlight>and <highlight><bold>5</bold></highlight><highlight><italic>b</italic></highlight>, <cross-reference target="DRAWINGS">FIGS. 6</cross-reference><highlight><italic>a </italic></highlight>and <highlight><bold>6</bold></highlight><highlight><italic>b </italic></highlight>illustrate the steps taken by a decoder to provide a synthesized signal in an embodiment of the invention. Referring to <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>a</italic></highlight>, at step <highlight><bold>601</bold></highlight>, the transmitted bit stream and the mode bit are received. At step <highlight><bold>603</bold></highlight>, it is determined whether the current superframe corresponds to music or speech according to the mode bit. If the signal corresponds to music, a transform excitation is generated at step <highlight><bold>607</bold></highlight>. If the bit stream corresponds to speech, step <highlight><bold>605</bold></highlight> is performed to generate a speech excitation signal as by CELP analysis. Both of steps <highlight><bold>607</bold></highlight> and <highlight><bold>605</bold></highlight> merge at step <highlight><bold>609</bold></highlight>. At step <highlight><bold>609</bold></highlight>, a switch is set so that the LP synthesis filter receives either the music excitation signal or the speech excitation signal as appropriate. When superframes are overlap-added in a region such as for example, 0&lE;n&lE;L<highlight><subscript>p</subscript></highlight>&minus;1, it is preferable to interpolate the LPC coefficients of the signals in this overlap-add region of a superframe. At step <highlight><bold>611</bold></highlight>, interpolation of the LPC coefficients is performed. For example, equation <highlight><bold>6</bold></highlight> may be employed to conduct the LPC coefficient interpolation. Subsequently at step <highlight><bold>613</bold></highlight>, the original signal is reconstructed or synthesized via an LP synthesis filter in a manner well understood by those skilled in the art. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> According to the invention, the speech excitation generator may be any excitation generator suitable for speech synthesis, however the transform excitation generator is preferably a specially adapted method such as that described by <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>b</italic></highlight>. Referring to <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>b</italic></highlight>, after receiving the transmitted bit-stream in step <highlight><bold>617</bold></highlight>, inverse bit-allocation is performed at step <highlight><bold>627</bold></highlight> to obtain bit allocation information. At step <highlight><bold>637</bold></highlight>, the DCT coefficients are obtained by performing an inverse DCT quantization of the DCT coefficients. At step <highlight><bold>647</bold></highlight>, a preliminary time domain excitation signal is reconstructed by performing an inverse DCT transformation, defined by equation 4, on the DCT coefficients. At step <highlight><bold>657</bold></highlight>, the reconstructed excitation signal is further processed by applying an overlap-add window defined by equation 2. At step <highlight><bold>667</bold></highlight>, an overlap-add operation is performed to obtain the music excitation signal as defined by equation 5. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> Although it is not required, the present invention may be implemented using instructions, such as program modules, that are executed by a computer. Generally, program modules include routines, objects, components, data structures and the like that perform particular tasks or implement particular abstract data types. The term &ldquo;program&rdquo; as used herein includes one or more program modules. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The invention may be implemented on a variety of types of machines, including cell phones, personal computers (PCs), hand-held devices, multi-processor systems, microprocessor-based programmable consumer electronics, network PCs, minicomputers, mainframe computers and the like, or on any other machine usable to code or decode audio signals as described herein and to store, retrieve, transmit or receive signals. The invention may be employed in a distributed computing system, where tasks are performed by remote components that are linked through a communications network. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> With reference to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, one exemplary system for implementing embodiments of the invention includes a computing device, such as computing device <highlight><bold>700</bold></highlight>. In its most basic configuration, computing device <highlight><bold>700</bold></highlight> typically includes at least one processing unit <highlight><bold>702</bold></highlight> and memory <highlight><bold>704</bold></highlight>. Depending on the exact configuration and type of computing device, memory <highlight><bold>704</bold></highlight> may be volatile (such as RAM), non-volatile (such as ROM, flash memory, etc.) or some combination of the two. This most basic configuration is illustrated in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> within line <highlight><bold>706</bold></highlight>. Additionally, device <highlight><bold>700</bold></highlight> may also have additional features/functionality. For example, device <highlight><bold>700</bold></highlight> may also include additional storage (removable and/or non-removable) including, but not limited to, magnetic or optical disks or tape. Such additional storage is illustrated in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> by removable storage <highlight><bold>708</bold></highlight> and non-removable storage <highlight><bold>710</bold></highlight>. Computer storage media include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Memory <highlight><bold>704</bold></highlight>, removable storage <highlight><bold>708</bold></highlight> and non-removable storage <highlight><bold>710</bold></highlight> are all examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CDROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by device <highlight><bold>700</bold></highlight>. Any such computer storage media may be part of device <highlight><bold>700</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Device <highlight><bold>700</bold></highlight> may also contain one or more communications connections <highlight><bold>712</bold></highlight> that allow the device to communicate with other devices. Communications connections <highlight><bold>712</bold></highlight> are an example of communication media. Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term &ldquo;modulated data signal&rdquo; means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. As discussed above, the term computer readable media as used herein includes both storage media and communication media. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Device <highlight><bold>700</bold></highlight> may also have one or more input devices <highlight><bold>714</bold></highlight> such as keyboard, mouse, pen, voice input device, touch input device, etc. One or more output devices <highlight><bold>716</bold></highlight> such as a display, speakers, printer, etc. may also be included. All these devices are well known in the art and need not be discussed at greater length here. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> A new and useful transform coding method efficient for coding music signals and suitable for use in a hybrid codec employing a common LP synthesis filter have been provided. In view of the many possible embodiments to which the principles of this invention may be applied, it should be recognized that the embodiments described herein with respect to the drawing figures are meant to be illustrative only and should not be taken as limiting the scope of invention. Those of skill in the art will recognize that the illustrated embodiments can be modified in arrangement and detail without departing from the spirit of the invention. Thus, while the invention has been described as employing a DCT transformation, other transformation techniques such as Fourier transformation modified discrete cosine transformation may also be applied within the scope of the invention. Similarly, other described details may be altered or substituted without departing from the scope of the invention. Therefore, the invention as described herein contemplates all such embodiments as may come within the scope of the following claims and equivalents thereof. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">I claim: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method for decoding a portion of a coded signal, the portion comprising a coded speech signal or a coded music signal, the method comprising the steps of: 
<claim-text>determining whether the portion of the coded signal corresponds to a coded speech signal or to a coded music signal; </claim-text>
<claim-text>providing the portion of the coded signal to a speech excitation generator if it is determined that the portion of the coded signal corresponds to a coded speech signal, wherein an excitation signal is generated in keeping with a linear predictive procedure; </claim-text>
<claim-text>providing the portion of the coded signal to a transform excitation generator if it is determined that the portion of the coded signal corresponds to a coded music signal, wherein an excitation signal is generated in keeping with a transform coding procedure; </claim-text>
<claim-text>switching the input of a common linear predictive synthesis filter between the output of the speech excitation generator and the output of the transform excitation generator, whereby the common linear predictive synthesis filter provides as output a reconstructed signal corresponding to the input excitation. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the coded music signal is formed according to an asymmetrical overlap-add transform method comprising the steps of: 
<claim-text>receiving a music superframe consisting a sequence of input music signals; </claim-text>
<claim-text>generating a residual signal and a plurality of linear predictive coefficients for the music superframe according to a linear predictive principle; </claim-text>
<claim-text>applying an asymmetrical overlap-add window to the residual signal of the superframe to produce a windowed signal; </claim-text>
<claim-text>performing a discrete cosine transformation on the windowed signal to obtain a set of discrete cosine transformation coefficients; </claim-text>
<claim-text>calculating dynamic bit allocation information according to the input music signals or the linear predictive coefficients; and </claim-text>
<claim-text>quantifying the discrete cosine transformation coefficients according to the dynamic bit allocation information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the portion of the coded signal comprises a signal superframe of a size optimized for transform coding. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the superframe is comprised of a series of elements, and wherein the step of applying an asymmetrical overlap-add window further comprises the steps of: 
<claim-text>creating the asymmetrical overlap-add window by: 
<claim-text>modifying a first sub-series of elements of a present superframe in accordance with a last sub-series of elements of a previous superframe; and </claim-text>
<claim-text>modifying a last sub-series of elements of the present superframe in accordance with a first sub-series of elements of a subsequent superframe; and </claim-text>
</claim-text>
<claim-text>multiplying the window by the present superframe in the time domain. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, further comprising the step of: conducting an interpolation of a set of linear predictive coefficients. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A computer readable medium having instructions thereon for performing steps for decoding a portion of a coded signal, the portion comprising a coded speech signal or a coded music signal, the steps comprising: 
<claim-text>determining whether the portion of the coded signal corresponds to a coded speech signal or to a coded music signal; </claim-text>
<claim-text>providing the portion of the coded signal to a speech excitation generator if it is determined that the portion of the coded signal corresponds to a coded speech signal, wherein an excitation signal is generated in keeping with a linear predictive procedure; </claim-text>
<claim-text>providing the portion of the coded signal to a transform excitation generator if it is determined that the portion of the coded signal corresponds to a coded music signal, wherein an excitation signal is generated in keeping with a transform coding procedure; </claim-text>
<claim-text>switching the input of a common linear predictive synthesis filter between the output of the speech excitation generator and the output of the transform excitation generator, whereby the common linear predictive synthesis filter provides as output a reconstructed signal corresponding to the input excitation. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The computer readable medium according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein the coded music signal is formed according to an asymmetrical overlap-add transform method comprising the steps of: 
<claim-text>receiving a music superframe consisting a sequence of input music signals; </claim-text>
<claim-text>generating a residual signal and a plurality of linear predictive coefficients for the music superframe according to a linear predictive principle; </claim-text>
<claim-text>applying an asymmetrical overlap-add window to the residual signal of the superframe to produce a windowed signal; </claim-text>
<claim-text>performing a discrete cosine transformation on the windowed signal to obtain a set of discrete cosine transformation coefficients; </claim-text>
<claim-text>calculating dynamic bit allocation information according to the input music signals or the linear predictive coefficients; and </claim-text>
<claim-text>quantifying the discrete cosine transformation coefficients according to the dynamic bit allocation information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The computer readable medium according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein the portion of the coded signal comprises a signal superframe of a size optimized for transform coding. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The computer readable medium according to <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the superframe is comprised of a series of elements, and wherein the step of applying an asymmetrical overlap-add window further comprises the steps of: 
<claim-text>creating the asymmetrical overlap-add window by: 
<claim-text>modifying a first sub-series of elements of a present superframe in accordance with a last sub-series of elements of a previous superframe; and </claim-text>
<claim-text>modifying a last sub-series of elements of the present superframe in accordance with a first sub-series of elements of a subsequent superframe; and </claim-text>
</claim-text>
<claim-text>multiplying the window by the present superframe in the time domain. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The computer readable medium according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, further comprising instructions for causing the step of conducting an interpolation of a set of linear predictive coefficients. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. An apparatus for coding a superframe signal, wherein the superframe signal comprises a sequence of speech signals or music signals, the apparatus comprising: 
<claim-text>a speech/music classifier for classifying the superframe as being a speech superframe or music superframe; </claim-text>
<claim-text>a speech/music encoder for encoding the speech or music superframe and providing a plurality of encoded signals, wherein the speech/music encoder comprises a music encoder employing a transform coding method to produce an excitation signal for reconstructing the music superframe using a linear predictive synthesis filter; and 
<claim-text>a speech/music decoder for decoding the encoded signals, comprising: 
<claim-text>a transform decoder that performs an inverse of the transform coding method for decoding the encoded music signals; and </claim-text>
<claim-text>a linear predictive synthesis filter for generating a reconstructed signal according to a set of linear predictive coefficients, wherein the filter is usable for the reproduction of both of music and speech signals. </claim-text>
</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein speech/music classifier provides a mode bit indicating whether the superframe is music or speech. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the speech/music encoder further comprises a speech encoder for encoding a speech superframe, wherein the speech encoder operates in accordance with a linear predictive principle. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The apparatus of claim <highlight><bold>111</bold></highlight>, wherein the music encoder further comprises: 
<claim-text>a linear predictive analysis module for analyzing the music superframe and generating a set of linear predictive coefficients; </claim-text>
<claim-text>a linear predictive coefficients quantization module for quantifying the linear predictive coefficients; </claim-text>
<claim-text>an inverse linear predictive filter for receiving the linear predictive coefficients and the music superframe and providing a residual signal; </claim-text>
<claim-text>an asymmetrical overlap-add windowing module for windowing the residual signal and producing a windowed signal; </claim-text>
<claim-text>a discrete cosine transformation module for transforming the windowed signal to a set of discrete cosine transformation coefficients; </claim-text>
<claim-text>a dynamic bit allocation module for providing bit allocation information based on at least one of the input signal or the linear predictive coefficients; and </claim-text>
<claim-text>a discrete cosine transformation coefficients quantization module for quantifying the discrete cosine transformation coefficients according to the bit allocation information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the transform decoder further comprises: 
<claim-text>a dynamic bit allocation module for providing bit allocation information; </claim-text>
<claim-text>an inverse quantization module for transferring quantified discrete cosine transformation coefficients into a set of discrete cosine transformation coefficients; </claim-text>
<claim-text>a discrete cosine inverse transformation for transforming the discrete cosine transformation coefficients into a time-domain signal; </claim-text>
<claim-text>an asymmetrical overlap-add windowing module for windowing the time-domain signal and producing a windowed signal; and </claim-text>
<claim-text>an overlap-add module for modifying the windowed signal based on the asymmetrical windows.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004711A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004711A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004711A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004711A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004711A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004711A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004711A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004711A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004711A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004711A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030004711A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030004711A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
