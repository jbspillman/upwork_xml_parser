<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002725A1-20030102-P00001.TIF SYSTEM "US20030002725A1-20030102-P00001.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-P00002.TIF SYSTEM "US20030002725A1-20030102-P00002.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-P00003.TIF SYSTEM "US20030002725A1-20030102-P00003.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-P00004.TIF SYSTEM "US20030002725A1-20030102-P00004.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-P00005.TIF SYSTEM "US20030002725A1-20030102-P00005.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-P00006.TIF SYSTEM "US20030002725A1-20030102-P00006.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-P00007.TIF SYSTEM "US20030002725A1-20030102-P00007.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-P00008.TIF SYSTEM "US20030002725A1-20030102-P00008.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-P00009.TIF SYSTEM "US20030002725A1-20030102-P00009.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-P00010.TIF SYSTEM "US20030002725A1-20030102-P00010.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00000.TIF SYSTEM "US20030002725A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00001.TIF SYSTEM "US20030002725A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00002.TIF SYSTEM "US20030002725A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00003.TIF SYSTEM "US20030002725A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00004.TIF SYSTEM "US20030002725A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00005.TIF SYSTEM "US20030002725A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00006.TIF SYSTEM "US20030002725A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00007.TIF SYSTEM "US20030002725A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00008.TIF SYSTEM "US20030002725A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00009.TIF SYSTEM "US20030002725A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00010.TIF SYSTEM "US20030002725A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00011.TIF SYSTEM "US20030002725A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00012.TIF SYSTEM "US20030002725A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030002725A1-20030102-D00013.TIF SYSTEM "US20030002725A1-20030102-D00013.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002725</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09893065</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010628</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06K009/00</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G06K009/40</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>382</class>
<subclass>132000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>382</class>
<subclass>274000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Method and system of contrast management of images using SIMD instructions and saturation arithmetic</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Walter</given-name>
<middle-name>Vincent</middle-name>
<family-name>Dixon</family-name>
</name>
<residence>
<residence-us>
<city>Delanson</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>David</given-name>
<middle-name>Allen</middle-name>
<family-name>Langan</family-name>
</name>
<residence>
<residence-us>
<city>Clifton Park</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>General Electric Company</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>GENERAL ELECTRIC COMPANY</name-1>
<name-2>GLOBAL RESEARCH CENTER</name-2>
<address>
<address-1>PATENT DOCKET RM. 4A59</address-1>
<address-2>PO BOX 8, BLDG. K-1 ROSS</address-2>
<city>NISKAYUNA</city>
<state>NY</state>
<postalcode>12309</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A method and system of processing raw images for display. First, a processor corrects the raw images with respect to an offset image to generate an offset corrected image. Next, a level of the offset corrected image is adjusted with respect to a gain adjust by employing saturation arithmetic to clip the level of the offset corrected image to generate a gain corrected image. Next, a window of the gain corrected image is adjusted with respect to a reference window to generate an output image. Next, the output image is packed into a register for display. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This invention generally relating to processing of video images and, in particular, to method of processing raw video images using single instruction, multiple data (SIMD) instructions and saturation arithmetic to achieve contrast management of the images. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> In certain environments, particularly in medical imaging, display technology may have a more limited dynamic range than the video sensors being used to collect the video data images to be displayed. Therefore, it is usually necessary to modify the video signals to correspond the limited dynamic range of the display technology which will be used to display the video signals. In particular, in order to display video data, the dynamic range of the data must be mapped to the dynamic range of the display technology which will be used to display the data. In the past, lookup tables have been used to achieve the mapping, although such tables have processing speed and dynamic range limitations. In addition, the case of high speed video data, specialized hardware may be needed to provide contrast management. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> There is a need for a simpler system and method for transforming the video data images so that their dynamic ranges corresponds to the dynamic range of the video display technology which will be used to display the images. There is also a need for such a system and method which linearly transforms the video data, which transformation is less taxing on the processor performing the transformation thereby reducing the processor requirements. There is also a need for such a system and method which linearly transforms the video data, which transformation reduces memory bandwidth requirements. There is also a need for such a system and method which linearly transforms the video data, which transformation clips output of the video range without requiring branches that degrade processor performance. </paragraph>
</section>
<section>
<heading lvl="1">BRIEF SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> In one form, the invention comprises a method of processing raw images for display. First, the raw images are corrected with respect to an offset image to generate an offset corrected image. Next, a level of the offset corrected image is adjusted with respect to a gain adjust to generate a gain corrected image. Next, a window of the gain corrected image is adjusted with respect to a reference window to generate an output image. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In another form, the invention includes a system for processing raw images for display comprising a processor. The processor corrects the raw images with respect to an offset image to generate an offset corrected image. The processor adjusts a level of the offset corrected image with respect to a gain adjust to generate a gain corrected image. The processor adjusts a window of the gain corrected image with respect to a reference window to generate an output image. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> This method and system of the invention has a number of advantages over the prior art. It avoids the need for lookup tables and specialized hardware for contrast management. It provides a linear transformation which is less taxing on the processor performing the transformation. It requires less bandwidth than systems and methods of the prior art. It clips output to the video range of the display technology by saturation arithmetic while avoiding the need for branches which degrade processor performance. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Other objects and features will be in part apparent and in part pointed out hereinafter.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a flow diagram illustrating one preferred embodiment of the invention. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flow chart of a high level view of the overall processing sequence of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a flow chart of the processing sequence of an individual image used by a processor according to the invention. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flow chart of the processing details for a first set of 16 pixels processed per iteration according to <cross-reference target="DRAWINGS">FIG. 3</cross-reference> of the invention. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a flow chart of the processing details for a second set of 16 pixels processed per iteration according to <cross-reference target="DRAWINGS">FIG. 3</cross-reference> of the invention. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a flow chart of a high level view of the gain calibration procedure used by a processor according to <cross-reference target="DRAWINGS">FIG. 2</cross-reference> the invention. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> illustrates the architecture for optional bad-pixel processing according to the invention. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates the architecture for cardiac and fluoro-rad processing. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates the data flow for the gain correction according to <cross-reference target="DRAWINGS">FIG. 6</cross-reference> the invention. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> illustrates one preferred embodiment for optimized data flow for cardio and fluoro-rad processing according to <cross-reference target="DRAWINGS">FIG. 8</cross-reference> the invention. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a flow chart illustrating window-level processing according to the invention. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> illustrates the format of optimized processing of a constant data structure according to <cross-reference target="DRAWINGS">FIGS. 6 and 9</cross-reference> of the invention. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> illustrates the format of the bad pixel map of <cross-reference target="DRAWINGS">FIG. 7</cross-reference>.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Corresponding reference characters indicate corresponding parts throughout the drawings. </paragraph>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE APPENDICES </heading>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> Appendix A is an example of a listing of a commented source code (assuming a 512 count wide window) file according to the invention. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Appendix B is a modified example of the listing of the commented source code file of Appendix A in floating point instructions and using prefetch instructions to move the data closer to the processor, i.e., from memory to cache. </paragraph>
</section>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The invention uses an implementation of a linear transform which exploits SIMD (single instruction multiple data) instruction architecture and avoids branches required to clip output to the video range with saturation arithmetic. One important aspect of the invention is the parallel nature or computational nuances of the image-processing algorithm. The method and system works simultaneously with three different images. A stream of one or more images is acquired by the processor performing the transformation. These images are referred to as raw images. An offset or dark image is also acquired. This image is generated by reading a reference image. For example, in the case of processing x-ray images, this images is generated by reading out the x-ray panel in the absence of any x-rays. The purpose of acquiring this reference image is to remove certain artifacts from the final image. The actual timing and number of offset images depend on the particular application. For example, in current cardiac applications, an initial offset image for the entire sequence is acquired. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> The method also uses a gain image. The gain image is a composite image that is acquired as part of system calibration. The method may optionally acquire this image daily, weekly, bi-weekly, etc. The algorithm assumes that this gain image has been previously obtained. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the invention includes a method <highlight><bold>100</bold></highlight>A of processing raw images for display comprising the steps of: </paragraph>
<paragraph id="P-0027" lvl="2"><number>&lsqb;0027&rsqb;</number> a first series of steps <highlight><bold>110</bold></highlight> correcting the raw images with respect to an offset (or dark) image to generate an offset corrected image; </paragraph>
<paragraph id="P-0028" lvl="2"><number>&lsqb;0028&rsqb;</number> a second series of steps <highlight><bold>120</bold></highlight> adjusting (by employing saturation arithmetic) a level of the offset corrected image with respect to a gain adjust (such as a gain integer and/or a gain fraction) to generate a gain corrected image; </paragraph>
<paragraph id="P-0029" lvl="2"><number>&lsqb;0029&rsqb;</number> a third series of steps <highlight><bold>130</bold></highlight> adjusting a window and/or level of the gain corrected image with respect to a reference window by right shifting to generate an output image; and </paragraph>
<paragraph id="P-0030" lvl="2"><number>&lsqb;0030&rsqb;</number> a fourth series of steps <highlight><bold>140</bold></highlight> packing the output image into a register for display by the display technology having a dynamic range to which the dynamic range of the raw image has now been mapped. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> For a 16 pixel data file, the method <highlight><bold>100</bold></highlight>A is performed on the first 4 pixels while parallel processing method <highlight><bold>100</bold></highlight>B, which is substantially the same as method <highlight><bold>100</bold></highlight>A, is performed on the next 4 bits of the 32 bit data file. The next 4 pixels are processed by parallel processing method <highlight><bold>100</bold></highlight>C, which is substantially the same as method <highlight><bold>100</bold></highlight>A, and the last 4 pixels are processed by parallel processing method <highlight><bold>100</bold></highlight>D, which is substantially the same as method <highlight><bold>10</bold></highlight>A. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> In particular as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, to begin processing data the gain calibration file of the data to be processed is first acquired at step <highlight><bold>202</bold></highlight> and then converted to a binary-fixed point file. A binary fixed point file is a file of floating-point numbers wherein each number is converted into an integer portion and a fractional portion. Both portions of the gain are represented as 16-bit integers. <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows a high level view of an exemplary gain calibration. Any type of gain calibration may be employed. For example, the floating-point data file produced by the calibration procedure at step <highlight><bold>602</bold></highlight> converts the gain to a binary, fixed point representation at step <highlight><bold>604</bold></highlight>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Next, an offset corrected image is acquired by step <highlight><bold>204</bold></highlight>. The offset corrected image and converted gain image are then rearranged to have 16 offset pixels, followed by 16 integer gain calibration, followed by 16 gain fraction values. The specific order of offset, integer gain, and gain is not important. However, the specific order is important to the performance of the algorithm such that these 48 values should be located in virtually contiguous memory for proper display. In particular, each of the data items must be contiguous and properly aligned. The processor fetches a cache, one line at a time (on Pentium processors versions prior to Pentium IV, a cache line is 32 bytes). If an operation references data that crosses a cache line, there is a significant performance degradation. The spatial proximity of these three quantities is important. If they are located arbitrarily the processor must generate extra instructions to reference the data. If the three data sets are far apart, the processor must use a large offset to reference all three items with a single register. The large offset limits the decode rate of the processor. At step <highlight><bold>206</bold></highlight>, bad pixels are fixed (see <cross-reference target="DRAWINGS">FIGS. 7 and 13</cross-reference>) and the display is updated. At step <highlight><bold>208</bold></highlight>, the method waits for the next blanking interval to proceed to process the next image, if there are any more images to process. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows the overall processing sequence for an individual image. At step <highlight><bold>302</bold></highlight>, the pixels remaining are set equal to the image size which must be a multiple of 16 bits or it must be padded to be a multiple of 16 bits. If zero pixels are remaining as determined by step <highlight><bold>304</bold></highlight>, the method is done at step <highlight><bold>305</bold></highlight>. Otherwise, the first 4 pixels of the offset corrected image are processed as noted above in FIG. I to accomplish window and level adjustment by subtraction and shifting, respectively. This corresponds to method <highlight><bold>100</bold></highlight>A. Similarly, the next 4 pixels are processed at step <highlight><bold>308</bold></highlight> according to method <highlight><bold>100</bold></highlight>B and the results are packed into a 64 bit register at step <highlight><bold>310</bold></highlight>. At this point, the first 8 pixels are provided to the display memory by step <highlight><bold>312</bold></highlight>. This process is then repeated for the last 8 pixels. The next 4 pixels are processed by step <highlight><bold>314</bold></highlight> (method <highlight><bold>100</bold></highlight>C) followed by the last 4 pixels being processed by step <highlight><bold>316</bold></highlight> (method <highlight><bold>100</bold></highlight>D). Step <highlight><bold>318</bold></highlight> packs the results in the 64 bit register and step <highlight><bold>320</bold></highlight> writes the last 8 pixels to the display memory. Step <highlight><bold>322</bold></highlight> determines the number of remaining pixels so that step <highlight><bold>304</bold></highlight> can decide to proceed with step <highlight><bold>306</bold></highlight> or end with step <highlight><bold>305</bold></highlight>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> The loop in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates how a processor processes 16 pixels per iteration. One cache line at a time is processed. A cache line is 32 bytes (on PENTIUM processors prior to PENTIUM IV). The raw and offset images contain 2 byte pixels; therefore one cache line &equals;16 pixels. The four pixels correspond to an MMX register width of 8 bytes. <cross-reference target="DRAWINGS">FIGS. 4 and 5</cross-reference> show the processing details for the first and second sets of four pixels within the image processing loop. Processing for the third set of 4 pixels is identical to the first set as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. Processing of the fourth set of 4 pixels is identical to the second set as shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> In general, the method of the invention processes raw images wherein the raw image comprises an N (e.g., 64) pixel sub-image, wherein the N pixel sub-image is divided into M (e.g., 4) sets of N/M (e.g., 16 pixels each), wherein N is an integer multiple of M, and wherein the first through fourth steps are applied to each of the M sets and the M sets are simultaneously processed in parallel by the first through fourth steps. </paragraph>
</section>
<section>
<heading lvl="1">Image Processing Library </heading>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> The image processing library which is the source of the code used by the processor to process the images according to the invention provides basic image processing and contrast management for the platform method. To support time-critical processing for cardiac, fluoro-rad, and similar medical modalities, one aspect of the invention optimizes the implementation of this library. The routines utilize the Pentium processor&apos;s MMX instruction set. For floating point instructions (see Appendix B), SSE registers of the processor are also used. This hardware feature allows the invention to process as many as four pixels with one arithmetic instruction. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Basic library services include offset correction <highlight><bold>110</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>), gain correction <highlight><bold>120</bold></highlight> (<cross-reference target="DRAWINGS">FIG.1 </cross-reference>), and bad pixel correction <highlight><bold>110</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>). Specific library routines for each of these operations are provided; these routines accept the address of an input and an output buffer. The image processing for cardiac, fluoro-rad, and similar modalities are memory bandwidth limited. Having separate modules for each operation provides the flexibility one would expect from a data acquisition platform, but the necessary extra memory reads and writes can limit performance. The library also includes a generic processing routine optimized to minimize the memory bandwidth. Logically, contrast management is a display function but such a separation would require additional memory copies. The invention also may include a window-level operation in the generic processing and also provides a separate window-level routine for non time-critical applications (see window adjustment <highlight><bold>130</bold></highlight>; <cross-reference target="DRAWINGS">FIG. 1</cross-reference>). </paragraph>
</section>
<section>
<heading lvl="1">Offset Correction </heading>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates the architecture of the offset correction data flow, particularly step <highlight><bold>110</bold></highlight>, as noted above. Offset correction subtracts a previously acquired offset image from the current light image. This operation utilizes the Pentium processor&apos;s MMX instructions. Four pixels from a previously acquired offset image are subtracted from four pixels from the current raw image using an unsigned subtract with saturation instruction. Should an offset pixel be larger than the corresponding pixel from the raw image, the result is forced to zero by the saturation operation. </paragraph>
</section>
<section>
<heading lvl="1">Gain Correction <highlight><bold>120</bold></highlight> </heading>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates the architecture of the gain correction processing, particularly step <highlight><bold>120</bold></highlight>, as noted above. <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates one preferred implementation of the gain calibration according to the invention. Gain calibration multiplies a previously acquired, offset corrected image by an experimentally determined gain correction. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 9 and 12</cross-reference> illustrate in more detail the data flow for the gain correction generally illustrated in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. The gain is divided into an integer and fractional part prior to performing the gain correction. The gain correction as a floating point number is initially computed. The integer part of the gain the then computed by truncating the floating point gain. Next, the gain fraction is computed by subtracting the integer gain from the original floating point value and multiplying the result by 2<highlight><superscript>15</superscript></highlight>. Scaling is important so as not to have overflow errors in implementing the binary fixed point multiply. Next, the product of gain and input image (normally, the offset corrected image) is computed using 16-bit integer operations. The order of computation may vary or the computations may be performed simultaneously. </paragraph>
</section>
<section>
<heading lvl="1">Window &mdash;Level Transformation <highlight><bold>130</bold></highlight> </heading>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates the architecture of the window-level transformation, particularly step <highlight><bold>130</bold></highlight>, as noted above. This transform allows an application to manage image brightness and contrast. Data from the detectors has a larger dynamic range than a monitor can display. The window-level transform provides a mapping from detector resolution to display resolution. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> illustrates window-level processing. The library may provide a stand-alone version of this algorithm as well as a version built in to the cardiac/fluoro-rad processing. The data flow is identical for these two cases. In the optimized version, the image is not explicitly from memory. </paragraph>
</section>
<section>
<heading lvl="1">Bad Pixel Processing </heading>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> illustrates the architecture of the optional bad-pixel processing. All detectors will most likely have bad pixels. Normally, a correction algorithm is applied to panels used in final products. A bad-pixel correction algorithm is included in the tester platform to support image quality measurements. One logical way to implement bad-pixel processing is to correct the raw-image, but because of a requirement to save this data, it is difficult to tolerate the overhead of making a copy. To solve this problem, all the other processing steps on the entire raw image are performed and then these calculations for the bad pixels are repeated. <cross-reference target="DRAWINGS">FIG. 13</cross-reference> shows the format of the bad pixel map. This structure permits implementing a very general bad pixel replacement policy. </paragraph>
</section>
<section>
<heading lvl="1">Cardiac/Fluoro-rad Processing </heading>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates the architecture for cardiac and fluoro-rad processing. Although the same algorithms are used to process this data, all the processing steps are applied at the same time to avoid extra memory accesses. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> illustrates the optimized data flow for cardiac/fluoro-rad processing. All the processing steps are combined to eliminate memory accesses. The window-level transform is processed as a separate step, but for efficiency it may be combined with the gain and offset corrections. </paragraph>
</section>
<section>
<heading lvl="1">Resources </heading>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> The following identifies and describes the resources external to the design entity that may be used by the entity to perform its function. Resources may take on a number of forms. For example, physical devices may include one or more of the following: hardware devices, user interface devices, networks, printers, disk partitions and memory banks. As another example, software services may include operating systems services and/or Commercial Off-The-Shelf Software (COTS). As yet another example, the processing resources may include one or more of the following: CPU cycles, memory allocation and disk and network bandwidth management and/or allocation. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> For each resource identified, there are several interaction rules and methods that must be specified. In particular, the usage characteristics of the resources must be described, such as: performance characteristics such as access time, bandwidth, or process time; and sizing characteristics such as disk space, memory allocation, quantity and physical sizes of buffers. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> There are also some special considerations for real time environments. When working in a real time environment, time is treated as a resource so that the real time constraints should be specified. </paragraph>
</section>
<section>
<heading lvl="1">Image Data Parameters </heading>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> Based on the nature of the design entity, the following image data parameters may be applicable. </paragraph>
</section>
<section>
<heading lvl="1">Input Image </heading>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> The input image consists of an array of unsigned short (16-bit) pixels. The most significant bit(s) will be zero; the dynamic range of the data depends on the panel. The base address can be aligned on at least a 16-byte boundary. Page alignment (4096-byte boundary) is generally required and not preferable because of the way in which memory is managed. For example, 16 byte alignment is required for performance. The DFN driver provides page aligned buffers. </paragraph>
</section>
<section>
<heading lvl="1">Offset Image </heading>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The library works with two different offset image formats. The stand-alone offset processing expects an array of unsigned short (16-bit) pixels with a 16-byte boundary minimum alignment. The optimized processing works with the constant data structure described in a subsequent section. </paragraph>
</section>
<section>
<heading lvl="1">Integer Gain </heading>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> The library works with two different integer gain formats. The standalone gain processing expects an array of unsigned short (16-bit) integer gains with a 16-byte boundary minimum alignment. The optimized processing works with the constant data structure described in a subsequent section. </paragraph>
</section>
<section>
<heading lvl="1">Fraction Gain </heading>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> The library works with two different fraction gain formats. The standalone gain processing expects an array of unsigned short (16-bit) fraction gains with a 16-byte boundary minimum alignment. The optimized processing works with the constant data structure described in a subsequent section. </paragraph>
</section>
<section>
<heading lvl="1">Constant Data </heading>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The optimized processing works with a constant data structure. There is a library routine that builds this structure from an unsigned short (16-bit) offset array and a 32-bit floating point gain array. The library routine will return a page aligned constant data structure. <cross-reference target="DRAWINGS">FIG. 12</cross-reference> describes the format of this. </paragraph>
</section>
<section>
<heading lvl="1">Commented Source Code </heading>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> Appendix A is an example of a listing of a commented source code file according to the invention. There are two include files referenced in this listing. The first is a file required by the compiler. The second file defines function prototypes. There is a library of image processing functions. The listing of Appendix A describes the processing according to the invention. Note that the listing assumes a window width of <highlight><bold>512</bold></highlight>. In contrast, the flow charts in the figure above have been modified to show a general window width. The window width is restricted to be a power of 2 so that the software shifts rather than divides. The details of the image processing has been described above. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Appendix B is a modified example of the listing of the commented source code file of Appendix A in floating point instructions and using prefetch instructions. The code in Appendix B does not do the contrast management (window / level adjust) as does the code of Appendix A, so that it is useful with any software that does not require the window level adjustment. The changes as embodied in the code of Appendix B tend to make the processing according the invention faster than processing by the code of Appendix A, but the code of Appendix A runs fast enough. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> The code of Appendix B differs from the code in Appendix A in two significant ways: (1) the code of Appendix B uses PENTIUM SSE (floating point) instructions, and (2) the code of Appendix B uses prefetch instructions to move the data closer to the processor, i.e., from memory to cache, so that the data is in L1 or L2 cache when it is referenced. These two changes require a PENTIUM III or newer processor; they are not valid for a PENTIUM II. The code of Appendix A runs on a PENTIUM II processor. There are two benefits derived from using the floating point instructions: (1) the code is shorter and simpler and (2) more processor registers are available. The more data that can be kept in processor registers, the faster that the code will run. Prefetching data increases performance by about 25%. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> The code of Appendix A has some other &ldquo;processing optimizations,&rdquo; such as: (1) the number of points is not required to be a multiple of 16, and (2) the output data is allowed to overwrite the input data. In the code of Appendix A, it was assumed that a 1024&times;1024 image would always be processed. Appendix B relaxes that restriction by adding a loop at the end to process any extra pixels using scalar operations. Overwriting the input array minimizes memory bandwidth, but is not desirable in all cases. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> In view of the above, it will be seen that the several objects of the invention are achieved and other advantageous results attained. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> As various changes could be made in the above methods and systems without departing from the scope of the invention, it is intended that all matter contained in the above description and shown in the accompanying drawings shall be interpreted as illustrative and not in a limiting sense. 
<image file="US20030002725A1-20030102-P00001.TIF" id="EMI-00001"></image>
<image file="US20030002725A1-20030102-P00002.TIF" id="EMI-00002"></image>
<image file="US20030002725A1-20030102-P00003.TIF" id="EMI-00003"></image>
<image file="US20030002725A1-20030102-P00004.TIF" id="EMI-00004"></image>
<image file="US20030002725A1-20030102-P00005.TIF" id="EMI-00005"></image>
<image file="US20030002725A1-20030102-P00006.TIF" id="EMI-00006"></image>
<image file="US20030002725A1-20030102-P00007.TIF" id="EMI-00007"></image>
<image file="US20030002725A1-20030102-P00008.TIF" id="EMI-00008"></image>
<image file="US20030002725A1-20030102-P00009.TIF" id="EMI-00009"></image>
<image file="US20030002725A1-20030102-P00010.TIF" id="EMI-00010"></image>
</paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of processing raw images for display comprising the steps of: 
<claim-text>a first step of correcting the raw images with respect to an offset image to generate an offset corrected image; and </claim-text>
<claim-text>a second step of adjusting a level of the offset corrected image with respect to a gain adjust to generate a gain corrected image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the second step of adjusting includes employing saturation arithmetic to clip the level of the offset corrected image. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> further comprising: 
<claim-text>a third step of adjusting a window of the gain corrected image with respect to a reference window to generate an output image; and </claim-text>
<claim-text>a fourth step of packing the output image into a register for display. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein the raw image comprises an N pixel sub-image, wherein the N pixel sub-image is divided into M sets of N/M pixels each, wherein N is an integer multiple of M, and wherein the first through fourth steps are applied to each of the M sets and the M sets are simultaneously processed in parallel by the first through fourth steps. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference> wherein N equals 64 and M equals 4. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> further comprising a fifth step after the fourth step of separately processing any bad pixels of the raw image. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein the raw data comprises cardio images or a fluoro-rad image and wherein the first through fourth steps are applied at the same time to the raw data. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein the second step of adjusting includes a linear transformation and wherein the third step of adjusting includes employing saturation to adjust the window. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the raw image comprises an N pixel sub-image, wherein the N pixel sub-image is divided into M sets of N/M pixels each, wherein N is an integer multiple of M, and wherein the first and second steps are applied to each of the M sets and the M sets are simultaneously processed in parallel by the first and second steps. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein single instruction multiple data (SIMD) instruction architecture is used and wherein the transformation exploits the SIMD architecture whereby branches to clip the offset corrected image are avoided with the saturation arithmetic. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the raw images comprise x-ray images and wherein the offset image is an x-ray image corresponding to the absence of the x-rays. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the gain adjust comprises a composite image acquired by calibration. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. Software for performing the method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A system for processing raw images for display comprising a processor: 
<claim-text>correcting the raw images with respect to an offset image to generate an offset corrected image; </claim-text>
<claim-text>adjusting a level of the offset corrected image with respect to a gain adjust by employing saturation arithmetic to clip the level of the offset corrected image to generate a gain corrected image; </claim-text>
<claim-text>adjusting a window of the gain corrected image with respect to a reference window to generate an output image; and </claim-text>
<claim-text>packing the output image into a register for display. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein the raw image comprises N pixel sub-image, wherein the N pixel sub-image is divided into M sets of N/M pixels each, wherein N is an integer multiple of M, and wherein the correcting, first adjusting, second adjusting and packing are applied to each of the M sets and the M sets are simultaneously processed in parallel by the processor. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference> wherein N equals 64 and M equals 4. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein the raw images comprise x-ray images and wherein the offset image is an x-ray image corresponding to the absence of the x-rays. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein the gain adjust comprises a composite image acquired by calibration. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> further comprising separately processing any bad pixels of the raw image. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein the raw data comprises cardio images or a fluoro-rad image and wherein the correcting, first adjusting, second adjusting and packing are applied at the same time to the raw data. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein single instruction multiple data (SIMD) instruction architecture is used to process the data through the processor and wherein the transformation exploits the SIMD architecture whereby branches to clip the offset corrected image are avoided with the saturation arithmetic. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein the first adjusting includes a linear transformation and wherein the second adjusting includes employing saturation to adjust the window. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> including software for controlling the operation of the processor to perform the correcting, first adjusting, second adjusting and packing.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002725A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002725A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002725A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002725A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002725A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002725A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002725A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002725A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002725A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030002725A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030002725A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030002725A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030002725A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030002725A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
