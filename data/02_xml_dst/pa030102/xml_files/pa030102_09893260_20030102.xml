<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002646A1-20030102-D00000.TIF SYSTEM "US20030002646A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002646A1-20030102-D00001.TIF SYSTEM "US20030002646A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002646A1-20030102-D00002.TIF SYSTEM "US20030002646A1-20030102-D00002.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002646</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09893260</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010627</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04M011/00</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>H04M007/00</ipc>
</classification-ipc-secondary>
<classification-ipc-secondary>
<ipc>G06K009/00</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>379</class>
<subclass>220010</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>379</class>
<subclass>258000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>379</class>
<subclass>093030</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>382</class>
<subclass>115000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Intelligent phone router</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Srinivas</given-name>
<family-name>Gutta</family-name>
</name>
<residence>
<residence-us>
<city>Buchanan</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Larry</given-name>
<family-name>Eshelman</family-name>
</name>
<residence>
<residence-us>
<city>Ossining</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Hugo</given-name>
<middle-name>J.</middle-name>
<family-name>Strubbe</family-name>
</name>
<residence>
<residence-us>
<city>Yorktown Heights</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>John</given-name>
<family-name>Milanski</family-name>
</name>
<residence>
<residence-us>
<city>Boulder</city>
<state>CO</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>Philips Electronics North America Corp.</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>Corporate Patent Counsel</name-1>
<name-2>U.S. Philips Corporation</name-2>
<address>
<address-1>580 White Plains Road</address-1>
<city>Tarrytown</city>
<state>NY</state>
<postalcode>10591</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A system and method for directing an incoming telephone call. The system comprises a control unit that receives images associated with two or more regions of a local environment. The two or more regions are each serviced by a respective telephone extension. The control unit processes the images to identify, from a group of known persons associated with the local environment, any one or more known persons located in the respective regions. For each known person so identified, an indicium is generated that associates the known person with the respective region in which the known person is located. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The invention relates to routing of telephone calls and other telecommunications services, in particular within a local environment, such as a home or office. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Certain techniques for routing calls within a local environment are known. In a simple example, a small office has a number of telephone extensions that connect with a switchboard. An operator receives an incoming call, inquires who the caller wishes to speak with, and manually attaches the call to the extension of the desired recipient. If the recipient is not at his or her desk, the operator may page the recipient and, if the recipient responds from another extension in the office, route the call to the other extension. Alternatively, the operator may route the call into a voice mailbox for the desired recipient. This technique is disadvantageous because, among other reasons, it relies on manual routing of the call by the operator. Also, when the recipient is not at an assigned extension, it requires a manual search by the operator, as well as a response by the recipient. Thus, the recipient may not receive the call even if he or she is available. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> In a similar example, an incoming call may be routed to an extension of a desired recipient in an office or other local environment via a automated routing system, such as a private branch exchange (PBX) system. In such a system, after the call is picked up, the caller is prompted via an automated response to input the name or extension of the desired recipient. The system then routes the call to the selected extension of the recipient. This technique is disadvantageous because, among other things, it requires that the intended recipient be at an assigned extension (or, perhaps, an extension to where the call is forwarded) in order to receive the call. It does not route the call to a different extension even if the recipient is available for the call. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Other more sophisticated call routing techniques and systems exist. For example, PCT Application WO 00/22805 describes a telephone management system that controls routing within an office by a PBX. When a caller places a call to a recipient in the office, the PBX receives caller ID data and signaling relating to the destination number related to the recipient. Before the call is routed, the telephone management system determines the identity of the recipient based upon the destination number. The telephone management system searches a database for routing instructions for the recipient that may be programmed in by the recipient. The particular instruction retrieved for the recipient may be based on the caller (as determined by the caller ID), the time, day and date. The call is routed by the PBX based on the applicable instruction. Among other deficiencies, this system requires that the users (recipients) diligently follow or update their programmed instructions. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> UK Patent Application No. 2222503A describes a PABX (private automatic branch exchange) system that has a number of telephone extensions and telephone sets. A plurality of receivers are also located in proximity to or within the telephone sets. Users of the system each carry a transceiver that provide a signal to the nearest receiver thereby identifying the user&apos;s location. The system uses the caller&apos;s location to route the call to the nearest extension. The signal from the transceiver may also include the user&apos;s status, which may result in the system routing the call elsewhere. For example, if the user status signal indicates he or she is at lunch, the call may be routed to voicemail. Among other deficiencies, this system requires that the users diligently carry the transceivers and update the status signal emitted. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> European Patent Application EP 0905956A2 describes a system that routes calls to a wireless terminal of an agent having particular knowledge or skill at a particular location. An example given is an employee that has advance knowledge of power tools located in the tool department of a store. If such an agent is not available at the particular location (or is busy), the call is routed to a wireless terminal of another agent having the appropriate (or some) pertinent knowledge or skill in another location. The system identifies the location of the agents based on information obtained from the system&apos;s base stations. Among other deficiencies, this system also requires that the agents diligently carry the transceivers and update their knowledge or skill set with the system. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> In short, the known routing techniques require manual routing of calls, user programming of routing instructions and/or a user carrying a transceiver. The known techniques fail to provide automatic routing of calls to a user based on the user&apos;s location. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> It is thus an objective of the invention to provide automatic routing of calls in a local environment. It is also an objective to provide automatic detection of the location of a particular user in a local environment and automatic routing of a call for the particular user to the nearest telephone extension. It is also an objective to provide automatic detection of the location of a particular user in a local environment using image recognition and/or voice recognition. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Accordingly, the invention provides a system comprising a control unit that receives images associated with two or more regions of a local environment. The two or more regions are each serviced by a respective telephone extension. The control unit processes the images to identify, from a group of known persons associated with the local environment, any one or more known persons located in the respective regions. For each known person so identified, an indicium is generated that associates the known person with the respective region in which the known person is located. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> In addition, the invention provides a system comprising a control unit that receives images associated with two or more regions of a local environment. The two or more regions are each serviced by a respective telephone branch. The control unit processes the images to detect any persons located in the respective regions. An incoming call is switched by the control unit to at least one of the respective telephone branches in which at least one detected person is located. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> Also, the invention provides a method for directing an incoming telephone call. The method comprises capturing images associated with each of a number of regions of a local environment. From a group of known persons each associated with the local environment, any known persons in each of the number of regions are identified from the captured images associated with each of the number of regions. A desired recipient of the incoming call is also identified and it is determined whether the desired recipient is one of the known persons identified in one of the regions. Where the desired recipient is one of the known persons identified in one of the regions, the incoming call is connected to an extension servicing the respective region in which the desired recipient is located. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In addition, the invention provides an alternative method for directing an incoming telephone call. Images associated with each of a number of regions of a local environment are captured. Any persons located in each of the number of regions are detected from the captured images associated with each of the number of region. An incoming call is connected to an extension servicing at least one of the regions in which at least one person is located.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a representative view of an embodiment of the invention; </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a </italic></highlight>depicts further details of a component of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a representative view of a second embodiment of the invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> local environment <highlight><bold>10</bold></highlight> is represented that is serviced by a number of telephone sets or phones P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, . . . PN connected to a private branch exchange PBX <highlight><bold>20</bold></highlight>. Although phones P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, . . . , PN are referred to, it is understood that these may be any device that is used to answer a call, including any display surface, such as, for example, a dynamic photograph. The local environment <highlight><bold>10</bold></highlight> may be any setting that is serviced by such a PBX configuration, such as an office, home, store, hospital, etc. For convenience, the ensuing description will focus on an office environment. However, the system may be easily adapted to other settings by one skilled in the art. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> Each phone P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, . . . PN provides a separate extension of the PBX <highlight><bold>20</bold></highlight>. Each phone P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, . . . PN is connected via a separate line L<highlight><bold>1</bold></highlight>, L<highlight><bold>2</bold></highlight>, . . . , LN, respectively, to the PBX <highlight><bold>20</bold></highlight>. As is known in the art, PBX <highlight><bold>20</bold></highlight> switches an incoming call to a desired extension by switching the incoming call to the appropriate line (either L<highlight><bold>1</bold></highlight>, L<highlight><bold>2</bold></highlight>, . . . or LN), thereby routing the call to the phone servicing that extension (either P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, . . . or PN). (Although only one &ldquo;incoming call&rdquo; to the PBX <highlight><bold>20</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, it is generally the case that PBX <highlight><bold>20</bold></highlight> will have a number of connections to the public switching telephone network (PSTN).) The extensions of PBX <highlight><bold>20</bold></highlight> are given reference numbers X<highlight><bold>1</bold></highlight>, X<highlight><bold>2</bold></highlight>, . . . XN in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. Thus, extension X<highlight><bold>1</bold></highlight> is represented as comprised of phone P<highlight><bold>1</bold></highlight>, line L<highlight><bold>1</bold></highlight> and the pertinent switching connections of PBX <highlight><bold>20</bold></highlight>. The other extensions are analogously described. The phones P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, . . . PN for each extension X<highlight><bold>1</bold></highlight>, X<highlight><bold>2</bold></highlight>, . . . , XN are shown as servicing a particular region R<highlight><bold>1</bold></highlight>, R<highlight><bold>2</bold></highlight>, . . . , RN, respectively, of the office <highlight><bold>10</bold></highlight>. The particular regions may be, for example, an individual office, a conference room, a lunch room, etc. Switching of an incoming call to an appropriate extension X<highlight><bold>1</bold></highlight>, X<highlight><bold>2</bold></highlight>, . . . , or XN may be made based on signaling that the PBX <highlight><bold>20</bold></highlight> receives from the caller after the incoming call is picked up. For example, the caller may identify the desired recipient by providing (via touch tone or by speaking, for example) all or portion of the recipient&apos;s name. In a standard mode of operation, the PBX <highlight><bold>20</bold></highlight> then switches the call to a particular extension (X<highlight><bold>1</bold></highlight>, X<highlight><bold>2</bold></highlight>, or XN) that is assigned to the desired recipient. Alternatively, the caller may identify the desired recipient by providing the extension number for the extension (X<highlight><bold>1</bold></highlight>, X<highlight><bold>2</bold></highlight>, . . . , or XN) that is assigned to the desired recipient and the PBX <highlight><bold>20</bold></highlight> then switches the call to the identified extension. Where the extension services a region that is not assigned to a particular recipient, such as a conference room or lunch room, analogous procedures may apply. If the extension is busy or not answered after a number of rings, the call may be switched by PBX <highlight><bold>20</bold></highlight> to the recipient&apos;s mailbox in voicemail <highlight><bold>24</bold></highlight>. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> Each region R<highlight><bold>1</bold></highlight>, R<highlight><bold>2</bold></highlight>, . . . , RN includes an image capturing device, such as a camera C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, . . . , CN. Data lines <highlight><bold>26</bold></highlight>(<highlight><bold>1</bold></highlight>), <highlight><bold>26</bold></highlight>(<highlight><bold>2</bold></highlight>), . . . , <highlight><bold>26</bold></highlight>(N) connect cameras C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, . . . , CN, respectively, to server or control unit <highlight><bold>30</bold></highlight>. (Alternatively, data lines <highlight><bold>26</bold></highlight>(<highlight><bold>1</bold></highlight>), <highlight><bold>26</bold></highlight>(<highlight><bold>2</bold></highlight>), . . . <highlight><bold>26</bold></highlight>(N) may connect to a multiplexer wherein the images from each camera may be transmitted in a multiplexed fashion to a single input of the control unit <highlight><bold>30</bold></highlight>.) Each camera thus provides images of the respective region in which it is located to the control unit <highlight><bold>30</bold></highlight>. Thus, for example, camera C<highlight><bold>1</bold></highlight> provides images of region R<highlight><bold>1</bold></highlight> to control unit <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Control unit <highlight><bold>30</bold></highlight> may comprise, for example, a processor <highlight><bold>32</bold></highlight> and memory <highlight><bold>34</bold></highlight> and run image recognition software, as shown further in <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a</italic></highlight>. The image recognition software processes the incoming images of each region R<highlight><bold>1</bold></highlight>, R<highlight><bold>2</bold></highlight>, . . . , RN, received from cameras C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, . . . , CN, respectively. For convenience, the ensuing description will focus on the images received from a single camera, Cx, of a single region, Rx, shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. The description is representative of images received from any of the other cameras C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, . . . , CN located in regions R<highlight><bold>1</bold></highlight>, R<highlight><bold>2</bold></highlight>, . . . , RN shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. It is further noted that region Rx is also served by extension Xx, comprised of phone Px and line Lx, which are also representative of the extensions of the other regions shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> As noted, camera Cx captures images of region Rx and transmits the image data to control unit <highlight><bold>30</bold></highlight>. The images are typically comprised of pixel data, for example, those from a CCD array in a typical digital camera. The pixel data of the images is assumed to be pre-processed into a known digital format that may be further processed using the image recognition software in control unit <highlight><bold>30</bold></highlight>. Such pre-processing of the images may take place in a processor of the camera Cx. Such processing of images by digital cameras (which provides the pre-processed image data to the control unit <highlight><bold>30</bold></highlight> for further processing by the image recognition software) is well known in the art and, for convenience, it&apos;s description will be omitted except to the extent necessary to describe the invention. While such pre-processing of the images of camera Cx may take place in the camera Cx, it may alternatively take place in the processor <highlight><bold>32</bold></highlight> of control unit <highlight><bold>30</bold></highlight> itself. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Processor <highlight><bold>32</bold></highlight> includes known image recognition software loaded therein that analyzes the image data received from camera Cx via data line <highlight><bold>26</bold></highlight>(<highlight><italic>x</italic></highlight>). If a person is located in region Rx, he or she will thus be depicted in the image data. The image recognition software may be used, for example, to recognize the contours of a human body in the image, thus recognizing the person in the image. Once the person&apos;s body is located, the image recognition software may be used to locate the person&apos;s face in the received image and to identify the person. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> For example, if control unit <highlight><bold>30</bold></highlight> receives a series of images from camera Cx, control unit <highlight><bold>30</bold></highlight> may detect and track a person that moves into the region Rx covered by camera Cx and, in particular, may detect and track the approximate location of the person&apos;s head. Such a detection and tracking technique is described in more detail in &ldquo;Tracking Faces&rdquo; by McKenna and Gong, Proceedings of the Second International Conference on Automatic Face and Gesture Recognition, Killington, Vt., Oct. 14-16, 1996, pp. 271-276, the contents of which are hereby incorporated by reference. (Section 2 of the aforementioned paper describes tracking of multiple motions.) </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> When the person is stationary in region Rx, for example, when he or she sits in a chair, the movement of the body (and the head) will be relatively stationary. Where the software of the control unit <highlight><bold>30</bold></highlight> has previously tracked the person&apos;s movement in the image, it may then initiate a separate or supplementary technique of face detection that focuses on the portion of the subsequent images received from the camera Cx where the person&apos;s head is located. If the software of the control unit <highlight><bold>30</bold></highlight> does not track movements in the images, then the person&apos;s face may be detected using the entire image, for example, by applying face detection processing in sequence to segments of the entire image. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> For face detection, the control unit <highlight><bold>30</bold></highlight> may identify a static face in an image using known techniques that apply simple shape information (for example, an ellipse fitting or eigen-silhouettes) to conform to the contour in the image. Other structure of the face may be used in the identification (such as the nose, eyes, etc.), the symmetry of the face and typical skin tones. A more complex modeling technique uses photometric representations that model faces as points in large multi-dimensional hyperspaces, where the spatial arrangement of facial features are encoded within a holistic representation of the internal structure of the face. Face detection is achieved by classifying patches in the image as either &ldquo;face&rdquo; or &ldquo;non-face&rdquo; vectors, for example, by determining a probability density estimate by comparing the patches with models of faces for a particular sub-space of the image hyperspace. This and other face detection techniques are described in more detail in the aforementioned Tracking Faces paper. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Face detection may alternatively be achieved by training a neural network supported within the control unit <highlight><bold>30</bold></highlight> to detect frontal or near-frontal views. The network may be trained using many face images. The training images are scaled and masked to focus, for example, on a standard oval portion centered on the face images. A number of known techniques for equalizing the light intensity of the training images may be applied. The training may be expanded by adjusting the scale of the training face images and the rotation of the face images (thus training the network to accommodate the pose of the image). The training may also involve back-propagation of false-positive non-face patterns. The control unit <highlight><bold>30</bold></highlight> provides portions of the image to such a trained neural network routine in the control unit <highlight><bold>30</bold></highlight>. The neural network processes the image portion and determines whether it is a face image based on its image training. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> The neural network technique of face detection is also described in more detail in the aforementioned Tracking Faces paper. Additional details of face detection (as well as detection of other facial sub-classifications, such as gender, ethnicity and pose) using a neural network is described in &ldquo;Mixture of Experts for Classification of Gender, Ethnic Origin and Pose of Human Faces&rdquo; by Gutta, Huang, Jonathon and Wechsler, IEEE Transactions on Neural Networks, vol. 11, no. 4, pp. 948-960 (July 2000), the contents of which are hereby incorporated by reference and referred to below as the &ldquo;Mixture of Experts&rdquo; paper. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> Once a face is detected in the image, the control unit <highlight><bold>30</bold></highlight> provides image recognition processing to the face to identify the person. Thus, the image recognition processing may be programmed to recognize particular faces, and each face is correlated to the identity of a person. The neural network technique of face detection described above may be adapted for identification by training the network using the faces of those persons who must be identified. Faces of other persons may be used in the training as negative matches (for example, false-positive indications). Thus, a determination by the neural network that a portion of the image contains a face image will be based on a training image for a known (identified) person, thus simultaneously providing the identification of the person. So programmed, the neural network provides both face detection and identification of the person. Alternatively, where a face is detected in the image using a technique other than a neural network (such as that described above), the neural network procedure may be used to confirm detection of a face and to also provide identification of the face. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> As another alternative technique of face recognition and processing that may be programmed in control unit <highlight><bold>30</bold></highlight>, U.S. Pat. No. 5,835,616, &ldquo;FACE DETECTION USING TEMPLATES&rdquo; of Lobo et al, issued Nov. 10, 1998, hereby incorporated by reference herein, presents a two step process for automatically detecting and/or identifying a human face in a digitized image, and for confirming the existence of the face by examining facial features. Thus, the technique of Lobo may be used in lieu of, or as a supplement to, the face detection and identification provided by the neural network technique and through the initial tracking of a moving body, as described above. The system of Lobo et al is particularly well suited for detecting one or more faces within a camera&apos;s field of view, even though the view may not correspond to a typical position of a face within an image. Thus, control unit <highlight><bold>30</bold></highlight> may analyze portions of the image for an area having the general characteristics of a face, based on the location of flesh tones, the location of non-flesh tones corresponding to eye brows, demarcation lines corresponding to chins, nose, and so on, as in the referenced U.S. Pat. No. 5,835,616. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> If a face is detected, it is characterized for comparison with reference faces for persons in the office (which are stored in database <highlight><bold>32</bold></highlight>), as in the referenced U.S. Pat. No. 5,835,616. This characterization of the face in the image is preferably the same characterization process that is used to characterize the reference faces, and facilitates a comparison of faces based on characteristics, rather than an &lsquo;optical&rsquo; match, thereby obviating the need to have two identical images (current face and reference face) in order to locate a match. In a preferred embodiment, the number of reference faces is relatively small, typically limited to the number of people in an office, household, or other small sized environment, thereby allowing the face recognition process to be effected quickly. The reference faces stored in memory <highlight><bold>34</bold></highlight> of control unit <highlight><bold>30</bold></highlight> have the identity of the person associated therewith; thus, a match between a face detected in the image and a reference face provides an identification of the person in the image. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Thus, the memory <highlight><bold>34</bold></highlight> and/or software of control unit <highlight><bold>30</bold></highlight> effectively includes a pool of reference images and the identities of the persons associated therewith. Using the images received from camera Cx, the control unit <highlight><bold>30</bold></highlight> effectively detects and identifies a known person (or persons) located in region Rx by locating a face (or faces) in the image and matching it with an image in the pool of reference images. The &ldquo;match&rdquo; may be detection of a face in the image provided by a neural network trained using the pool of reference images, or the matching of facial characteristics in the camera image and reference images as in U.S. Pat. No. 5,835,616, as described above. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Data indicating the detection of a known person, for example, employee A, in region Rx is transmitted via line <highlight><bold>40</bold></highlight> from control unit <highlight><bold>30</bold></highlight> to PBX <highlight><bold>20</bold></highlight>. Equivalently, control unit <highlight><bold>30</bold></highlight> may transmit data associating employee A and extension Xx to PBX <highlight><bold>20</bold></highlight>, since extension Xx services region Rx in which employee A is located. Of course, PBX <highlight><bold>20</bold></highlight> may make the association between extension Xx and region Rx itself PBX <highlight><bold>20</bold></highlight> makes an updated record that associates employee A and extension Xx. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> As noted above, after an incoming call is received by PBX, the caller will typically provide signaling that identifies a desired recipient, for example, employee A. As also noted above, in a traditional mode of operation, the PBX <highlight><bold>20</bold></highlight> will route the call to a particular extension that is assigned to employee A. For example, signaling provided by the caller may be an indicium of employee A&apos;s name or the number for the extension otherwise assigned to employee A (for example, extension X<highlight><bold>1</bold></highlight>, which may be employee A&apos;s office). Upon receipt of the signaling from the caller indicating employee A is the desired recipient, the PBX <highlight><bold>20</bold></highlight> in the traditional mode routes the call to extension X<highlight><bold>1</bold></highlight>, even in the case where employee A may be located in region Rx. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> However, in accordance with the processing comprising this embodiment of the invention, when the caller provides signaling to PBX <highlight><bold>20</bold></highlight> that indicates that the desired recipient is employee A, PBX <highlight><bold>20</bold></highlight> accesses the record that associates employee A with extension Xx based on the data received from control unit <highlight><bold>30</bold></highlight>. The call is routed to extension Xx servicing region Rx, where employee A is located. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> In like manner, cameras C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, . . . , CN serve to provide images of other regions R<highlight><bold>1</bold></highlight>, R<highlight><bold>2</bold></highlight>, . . . , RN of the local office environment to control unit <highlight><bold>30</bold></highlight> over lines L<highlight><bold>1</bold></highlight>, L<highlight><bold>2</bold></highlight>, . . . , LN. The control unit <highlight><bold>30</bold></highlight> processes the images associated with each region in the manner described above, thus identifying known persons in the various regions from images for the respective regions. In like manner, for each known person identified in an image, control unit <highlight><bold>30</bold></highlight> sends data associating the identity of the person with the particular region (or the extension serving the region) to PBX <highlight><bold>20</bold></highlight>. PBX <highlight><bold>20</bold></highlight> maintains a record that associates each such identified person with the corresponding extension in the region that he or she is located. When an incoming call is received, PBX <highlight><bold>20</bold></highlight> checks the records for the desired recipient and, if a record exists, routes the call to the associated extension for the desired recipient. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> As a person moves from one region to a new region, the camera for the new region will capture the person in the subsequent images that are transmitted to control unit <highlight><bold>30</bold></highlight>. After identification of the person in the image for the new region, control unit <highlight><bold>30</bold></highlight> will transmit data associating the person with the new region to PBX <highlight><bold>20</bold></highlight>. PBX <highlight><bold>20</bold></highlight> will replace any existing record for the person with a new record associating the person with the extension serving the new region. Thus, incoming calls for the person will be routed to the extension serving the new region. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> For example, if employee A moves from region Rx to region R<highlight><bold>2</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the images transmitted from camera C<highlight><bold>2</bold></highlight> to control unit <highlight><bold>30</bold></highlight> via line <highlight><bold>26</bold></highlight>(<highlight><bold>2</bold></highlight>) will include employee A. After image detection and identification processing of the image, control unit <highlight><bold>30</bold></highlight> identifies employee A in region R<highlight><bold>2</bold></highlight> and transmits data associating employee A with region R<highlight><bold>2</bold></highlight> (or extension X<highlight><bold>2</bold></highlight> serving region R<highlight><bold>2</bold></highlight>) to PBX <highlight><bold>20</bold></highlight>. PBX <highlight><bold>20</bold></highlight> updates its record for employee A by associating employee A with extension R<highlight><bold>2</bold></highlight>. Incoming calls for employee A are thus now routed to R<highlight><bold>2</bold></highlight>. In like manner, records for all known persons in the various regions are updated in PBX <highlight><bold>20</bold></highlight> as they move into new regions. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> In addition, if a record is made in the PBX <highlight><bold>20</bold></highlight> associating a person with an extension, but the person is not detected in another image within a predetermined amount of time, the PBX <highlight><bold>20</bold></highlight> may be programmed to presume that the person has left the office <highlight><bold>10</bold></highlight> and the record may be deleted. If an incoming call is received for a person or employee where there is no record of an associated extension in the PBX <highlight><bold>20</bold></highlight>, then the call may be routed directly to voice mail <highlight><bold>24</bold></highlight>. Alternatively, it may be switched to the particular extension assigned to the person and, if there is no answer after a number of rings, switched to voice mail <highlight><bold>24</bold></highlight>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The image processing may also detect gestures in addition to the identity of an employee. The control unit <highlight><bold>30</bold></highlight> may be programmed to detect certain pre-determined gestures and make appropriate adjustments to the signal sent to PBX <highlight><bold>20</bold></highlight> for the identified employee making the gesture. For example, as an employee enters a conference room, he or she may hold up three fingers toward the camera. This gesture may indicate that the employee does not want to be disturbed. After detecting the identity of the employee and the gesture from the received image, the control unit <highlight><bold>30</bold></highlight> sends a signal to the PBX <highlight><bold>20</bold></highlight> that associates the identified employee with voice mail, instead of the extension for the conference room. The PBX <highlight><bold>20</bold></highlight> makes an appropriate record and, when an incoming call is received for the employee, it is forwarded to voice mail <highlight><bold>24</bold></highlight>. As noted above, the Mixture Of Experts paper provides further details on recognition of gestures from images. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> In the description above, control unit <highlight><bold>30</bold></highlight> and PBX <highlight><bold>20</bold></highlight> were depicted and described as separate components. Some of the processing ascribed to the PBX <highlight><bold>20</bold></highlight> in the description may be performed by the control unit <highlight><bold>30</bold></highlight> and vice versa. For example, the records associating identified employees with particular extensions may be maintained in the control unit <highlight><bold>30</bold></highlight>. When an incoming call is received by the PBX for an employee, the PBX <highlight><bold>20</bold></highlight> may query control unit <highlight><bold>30</bold></highlight> (via line <highlight><bold>40</bold></highlight>) to determine whether a record exists for the employee. The control unit <highlight><bold>30</bold></highlight> may search the records and, if one is found for the employee, may identify the associated extension to the PBX <highlight><bold>20</bold></highlight>, wherein PBX <highlight><bold>20</bold></highlight> then makes the appropriate connection. In addition, the control unit <highlight><bold>30</bold></highlight> and the PBX <highlight><bold>20</bold></highlight> may be combined into one component. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> Cameras C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, . . . , CN are positioned such that they capture images of substantially the entire region R<highlight><bold>1</bold></highlight>, R<highlight><bold>2</bold></highlight>, . . . , RN, respectively, and, in particular, such that they are likely to capture the faces of persons located in each region. A region may be serviced by more than one camera in order to ensure that the face of a person is captured in the image. Determination of an adequate number of cameras for a region and their position may be determined empirically, for example, by changing the positions and/or the number of cameras and then testing how well a known person is properly identified in different positions in the region. Where a plurality of cameras service a region, a number of images from each camera may be transmitted in a multiplexed fashion over a single line to the control unit <highlight><bold>30</bold></highlight>. Alternatively, there may be a line from each camera in the region to the control unit <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> Referring back to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, both the respective phone and the camera are represented as being within each region. For example, both camera C<highlight><bold>1</bold></highlight> and phone P<highlight><bold>1</bold></highlight> are represented as being in region R<highlight><bold>1</bold></highlight>. The figure is only intended to be representative of the relationship between a spatial region, a camera C<highlight><bold>1</bold></highlight> that captures images for that region, and a phone that services the region. The phone does not necessarily have to be within the region it services; for example, it may be a phone that is located outside of a conference room. In such a case, the phone may be answered by a nominee for the desired recipient of a call, such as a receptionist stationed outside the conference room. Before the call is connected, the nominee may be notified of the identity of the desired recipient. The nominee may take the call on behalf of the desired recipient, and/or may alternatively locate the desired recipient (in the example, in the conference room) and alert him or her of the call. Similarly, if an extension serving a region is occupied and the desired recipient of the call is located in the region, then the call may be routed to a phone serving an adjacent region. Before the call is answered by a person in the adjacent region, the system may notify the answering person of the identity of the desired recipient. The person may take the call on behalf of the desired recipient, and/or may alternatively locate the desired recipient and alert him or her of the call. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> In addition, the camera does not have to be within a region. It may, for example, provide images that enable the control unit <highlight><bold>30</bold></highlight> to keep track of persons within a region of the office. Thus, for example, a camera may be located so that it captures images at the entrance of the region it services. For example, a camera may be located at the hallway that leads to a conference room. The images will include facial images of persons entering the conference room, and calls for known persons identified in the images are routed to the phone servicing the conference room. As noted, the local environment may also be, for example, a home serviced by a number of telephones in various rooms. A home may not have a number of separate exchanges serviced by a PBX, as in the above-described embodiment. In general, a home has one or a few telephone lines, each having a separate telephone number, provided directly from the PSTN. Each line is routed to one (or more) telephones, a fax machine, PC, etc. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, another exemplary embodiment of the invention as applied to a home <highlight><bold>100</bold></highlight> is shown. A single phone line <highlight><bold>102</bold></highlight> is shown serving the home. The phone line is connected to the PSTN and, for example, supports a telephone number for the home. As also shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, phone P<highlight><bold>1</bold></highlight> is located on the ground floor G, phone P<highlight><bold>2</bold></highlight> is located on the second floor S and phone P<highlight><bold>3</bold></highlight> is located in the home office O. In a traditional configuration, phone line <highlight><bold>102</bold></highlight> is divided when it enters the home <highlight><bold>100</bold></highlight> and connects directly to each phone P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, P<highlight><bold>3</bold></highlight>. Thus, an incoming call causes each phone P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, P<highlight><bold>3</bold></highlight> to ring and the incoming call may be picked up on any phone P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight> or P<highlight><bold>3</bold></highlight>. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> In the embodiment of <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, an incoming call over line <highlight><bold>102</bold></highlight> is received by home server <highlight><bold>130</bold></highlight>, which also includes a switching network. Each phone P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight> and P<highlight><bold>3</bold></highlight> is attached to separate switching terminals of the switching network of home server <highlight><bold>130</bold></highlight> via branch B<highlight><bold>1</bold></highlight>, B<highlight><bold>2</bold></highlight> and B<highlight><bold>3</bold></highlight>, respectively. Home server <highlight><bold>130</bold></highlight> may connect the incoming call to one or more of phones P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight> and P<highlight><bold>3</bold></highlight> by switching phone line <highlight><bold>102</bold></highlight> to connect to one or more of branches B<highlight><bold>1</bold></highlight>, B<highlight><bold>2</bold></highlight> and B<highlight><bold>3</bold></highlight>, respectively. Thus, for example, home server <highlight><bold>130</bold></highlight> may connect an incoming call to phone Pi alone by switching phone line <highlight><bold>102</bold></highlight> so that it connects with branch B<highlight><bold>1</bold></highlight> alone. As another example, home server <highlight><bold>130</bold></highlight> may connect an incoming call to phones P<highlight><bold>1</bold></highlight> and P<highlight><bold>3</bold></highlight> by switching line <highlight><bold>102</bold></highlight> to connect with branches B<highlight><bold>1</bold></highlight> and B<highlight><bold>3</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Camera C<highlight><bold>1</bold></highlight> is positioned to capture images on the ground floor G and transmits the image data to home server via line <highlight><bold>126</bold></highlight>(<highlight><bold>1</bold></highlight>). Similarly, camera C<highlight><bold>2</bold></highlight> positioned on second floor S captures images on the second floor S and transmits the image data to home server <highlight><bold>130</bold></highlight> via line <highlight><bold>126</bold></highlight>(<highlight><bold>2</bold></highlight>), and camera C<highlight><bold>3</bold></highlight> positioned in office O captures images of the office and transmits the image data to home server <highlight><bold>130</bold></highlight> via line <highlight><bold>126</bold></highlight>(<highlight><bold>3</bold></highlight>). As noted above, the image data may be pre-processed in the cameras before being sent to the home server <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Home server <highlight><bold>130</bold></highlight> includes image recognition software such as that described above for the first embodiment. In a simple implementation, the image recognition may simply detect the presence of a human body in the image. Thus, home server <highlight><bold>130</bold></highlight> applies the image detection processing to the images received from cameras C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight> and C<highlight><bold>3</bold></highlight> and determines where persons are located in the home <highlight><bold>100</bold></highlight>. If, for example, the server detects a person in the office O, then an incoming call is routed to phone P<highlight><bold>3</bold></highlight> in the office O. If a person is also detected on the second floor S, then an incoming call may be routed to phones P<highlight><bold>2</bold></highlight> and P<highlight><bold>3</bold></highlight>. Alternatively, the home server <highlight><bold>130</bold></highlight> may be programmed to switch to a single branch based on a priority scheme. For example, for the case where a person is detected in the office O and the second floor S, priority may be given to switching the call to the office phone P<highlight><bold>3</bold></highlight> alone. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Multiple cameras may be necessary on the ground floor G, second floor S and/or office O in order to completely cover the regions and detect persons located in the regions. Alternatively, if only one or a lesser number of cameras is feasible than can completely cover a region, then they may be strategically positioned within the region. For example, camera C<highlight><bold>2</bold></highlight> may be positioned at the top of the stairs of the second floor S, thus determining whether a person is on the second floor by keeping track of the number of persons entering and exiting the second floor S. As another example, on the ground floor G, where there may be a number of entrances and exits which cannot be covered by a single camera, camera C<highlight><bold>1</bold></highlight> may be a wide angle camera that is positioned to provide images from the busiest sector or corridor of the ground floor G. Detection of a person in the sector by the server <highlight><bold>130</bold></highlight>, of course, indicates that a call should be routed to phone P<highlight><bold>1</bold></highlight> (unless a prioritization routes the call elsewhere, as described above). The router <highlight><bold>130</bold></highlight> may also set a timer that continues to switch calls to the ground floor G for a certain amount of time after a person is detected, for example, 15 minutes. In this case, if a person on the ground floor G moves to another area that is not covered by camera C<highlight><bold>1</bold></highlight>, the call is still routed to the ground floor. If a person is not again detected in the busiest sector during that time interval, the timer times out and home server <highlight><bold>130</bold></highlight> concludes that nobody is present on the ground floor G and does not route the call to P<highlight><bold>1</bold></highlight>. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> Similar to the first embodiment, if the server <highlight><bold>130</bold></highlight> does not detect any persons in any of the regions of the home, then the call may be switched to the home answering machine <highlight><bold>124</bold></highlight> via line B<highlight><bold>4</bold></highlight>. Alternatively, all phones P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, P<highlight><bold>3</bold></highlight> may be connected and allowed to ring a certain number of times, in the event that somebody is present in the house but has not been detected. If there is nobody answers on any of the phones, then the call may be switched to the answering machine. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> In a more advanced version of the embodiment, the software of the home server <highlight><bold>130</bold></highlight> not only detects persons, but also identifies known persons in the images received from the cameras, using, for example, one of the identification processing techniques discussed above for the first embodiment. A call is routed to the ground floor G, second floor S or office O when a known person is identified in the image received from the respective camera covering that region. If two or more known persons are identified from the images as being in different regions, the call may be routed to one or multiple regions where the known persons are located. For example, a first known person may be identified in the images sent from camera C<highlight><bold>2</bold></highlight> as being on the second floor S and a second known person may be identified in the images sent from camera C<highlight><bold>3</bold></highlight> as being in the office O. An incoming call may thus be routed to both phones, namely phone P<highlight><bold>2</bold></highlight> serving the second floor S and phone P<highlight><bold>3</bold></highlight> serving the office O. However, the home server <highlight><bold>130</bold></highlight> may also prioritize among known persons, thus routing the call only to the identified person with the higher priority. For example, if the second known person identified has a higher priority programmed in the home server <highlight><bold>130</bold></highlight> than the first known person, the call is routed to the second known person via line B<highlight><bold>3</bold></highlight> to phone P<highlight><bold>3</bold></highlight> in the office O. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> Where the server <highlight><bold>130</bold></highlight> identifies known persons from the received images, it may use the information to keep track that a person has left one region when he or she is subsequently identified in a different region. Thus, for example, if known person A is identified as being on the ground floor G, the server <highlight><bold>130</bold></highlight> may route incoming calls to phone P<highlight><bold>1</bold></highlight>. At a later time, if person A is identified as being on the second floor S and no other persons have been detected on the ground floor G, then the server <highlight><bold>130</bold></highlight> determines that nobody is on the ground floor G. An incoming call may thus be routed to phone P<highlight><bold>2</bold></highlight> on the second floor S. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> Voice detection in the various regions and voice recognition processing may be used instead of (or as a supplement to) the image detection and processing in the invention. One skilled in the art will readily recognize how to adapt, for example, the above-described embodiments to use voice detection and voice recognition processing. For example, the cameras associated with the regions may be replaced with microphones. The control unit may be programmed with known processing that detects voices and/or identifies known voices in the various regions. Other facets of the above-described embodiments remain the same or are adapted in a straight-forward manner. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The following five documents are hereby incorporated by reference herein: </paragraph>
<paragraph id="P-0053" lvl="1"><number>&lsqb;0053&rsqb;</number> 1) &ldquo;Pfinder: Real-Time Tracking Of the Human Body&rdquo; by Wren et al., M.I.T. Media Laboratory Perceptual Computing Section Technical Report No. 353, published in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 19, no. 7, pp 780-85 (July 1997), which describes a &ldquo;person finder&rdquo; that finds and follows people&apos;s bodies (or head or hands, for example) in a video image </paragraph>
<paragraph id="P-0054" lvl="1"><number>&lsqb;0054&rsqb;</number> 2) &ldquo;Pedestrian Detection From A Moving Vehicle&rdquo; by D. M. Gavrila (Image Understanding Systems, DaimlerChrysler Research), Proceedings of the European Conference on Computer Vision, Dublin, Ireland (2000) (available at www.gavrila.net), which describes detection of a person (a pedestrian) within an image using a template matching approach. </paragraph>
<paragraph id="P-0055" lvl="1"><number>&lsqb;0055&rsqb;</number> 3) &ldquo;Condensation&mdash;Conditional Density Propagation For Visual Tracking&rdquo; by Isard and Blake (Oxford Univ. Dept. of Engineering Science), Int. J. Computer Vision, vol. 29, no. 1, pp. 5-28 (1998) (available at www.dai.ed.ac.uk/CVonline/LOCAL COPIES/ISARD1/condensation.html, along with the &ldquo;Condensation&rdquo; source code), which describes use of a statistical sampling algorithm for detection of a static object in an image and a stochastical model for detection of object motion. </paragraph>
<paragraph id="P-0056" lvl="1"><number>&lsqb;0056&rsqb;</number> 4) U.S. patent application Ser. No. 09/685,683 entitled &ldquo;Device Control Via Image-Based Recognition&rdquo; of Miroslav Trajkovic, Yong Yan, Antonio Colmenarez and Srinivas Gutta, filed Oct. 10, 2000, Attorney docket US000269, which provides further description of image recognition. </paragraph>
<paragraph id="P-0057" lvl="1"><number>&lsqb;0057&rsqb;</number> 5) U.S. patent application Ser. No. 09/800,219 entitled &ldquo;Automatic Positioning Of Display Depending Upon The Viewer&apos;s Location&rdquo; for Srinivas Gutta, et al., filed Mar. 5, 2001, Attorney docket US010050, which provides further description of face detection in a moving and/or static image. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> In addition, it is noted that software that can recognize faces in images (including digital images) is commercially available, such as the &ldquo;Facelt&rdquo; software sold by Visionics and described at www.faceit.com. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Although illustrative embodiments of the present invention have been described herein with reference to the accompanying drawings, it is to be understood that the invention is not limited to those precise embodiments, but rather it is intended that the scope of the invention is as defined by the scope of the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A system comprising a control unit that receives images associated with two or more regions of a local environment, the two or more regions each being serviced by a respective telephone extension, the control unit processing the images to identify, from a group of known persons associated with the local environment, any one or more known persons located in the respective regions and, for each known person so identified, generating an indicium that associates the known person with the respective region in which the known person is located. </claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising two or more cameras that provide the images associated with the two or more regions of the local environment, each region having associated therewith at least one of the two or more cameras, wherein images captured by the at least one camera associated with each region are processed to identify any known persons located in the respective region. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the indicium generated by the control unit, for each known person identified, that associates the known person with the respective region in which the known person is located is incorporated in a signal. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> further comprising a private branch exchange (PBX), wherein the signal is output by the control unit to the PBX. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein, for each known person identified, the PBX uses the signal to create a record that associates the known person with the telephone exchange servicing the respective region in which the known person is located. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein, when the PBX receives an incoming call for one known person of the group of known persons and determines that one of the records relates to the one known person, the PBX connects the call to the telephone extension associated with the one known person in the record. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The system as in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the indicium, for each known person identified, that associates the known person with the respective region is incorporated in a record maintained in the control unit. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The system as in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the control unit switches an incoming call to at least one of the respective telephone extensions servicing at least one of the two or more regions in which at least one identified known person is located. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A system comprising a control unit that receives images associated with two or more regions of a local environment, the two or more regions each being serviced by a respective telephone branch, the control unit processing the images to detect any persons located in the respective regions and switching an incoming call to at least one of the respective telephone branches in which at least one detected person is located. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A method for directing an incoming telephone call, the method comprising the steps of: 
<claim-text>a) capturing images associated with each of a number of regions of a local environment; </claim-text>
<claim-text>b) identifying, from a group of known persons each associated with the local environment, any known persons in each of the number of regions from the captured images associated with each of the number of regions; </claim-text>
<claim-text>c) identifying a desired recipient of the incoming call; </claim-text>
<claim-text>d) determining whether the desired recipient is one of the known persons identified in one of the regions in step b; and </claim-text>
<claim-text>e) where the desired recipient is one of the known persons identified in one of the regions in step b, connecting the incoming call to an extension servicing the respective region in which the desired recipient is located. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the step of capturing images associated with each of a number of regions comprises, for one or more of the regions, directing at least one camera at at least a portion of the region. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the step of capturing images associated with each of a number of regions comprises, for one or more of the regions, positioning a camera to capture images at an entrance of the region. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the step of identifying any known persons from the captured images includes applying image recognition processing to the images. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the application of the image recognition processing to the images includes accessing a database of image data for the group of known persons. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein step b further comprises creating a record associating each known person identified from the captured images with the respective region in which the known person is located. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, wherein the step of determining whether the desired recipient is one of the known persons identified in one of the regions in step b comprises searching the records relating to each known person and the respective region in which the known person is located. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A method for directing an incoming telephone call, the method comprising the steps of: 
<claim-text>a) capturing images associated with each of a number of regions of a local environment; </claim-text>
<claim-text>b) detecting any persons located in each of the number of regions from the captured images associated with each of the number of regions; and </claim-text>
<claim-text>c) connecting an incoming call to an extension servicing at least one of the regions in which at least one person is located.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>2</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002646A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002646A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002646A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
