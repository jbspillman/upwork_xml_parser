<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004584A1-20030102-D00000.TIF SYSTEM "US20030004584A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00001.TIF SYSTEM "US20030004584A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00002.TIF SYSTEM "US20030004584A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00003.TIF SYSTEM "US20030004584A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00004.TIF SYSTEM "US20030004584A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00005.TIF SYSTEM "US20030004584A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00006.TIF SYSTEM "US20030004584A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00007.TIF SYSTEM "US20030004584A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00008.TIF SYSTEM "US20030004584A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00009.TIF SYSTEM "US20030004584A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00010.TIF SYSTEM "US20030004584A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00011.TIF SYSTEM "US20030004584A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00012.TIF SYSTEM "US20030004584A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00013.TIF SYSTEM "US20030004584A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00014.TIF SYSTEM "US20030004584A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00015.TIF SYSTEM "US20030004584A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00016.TIF SYSTEM "US20030004584A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00017.TIF SYSTEM "US20030004584A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00018.TIF SYSTEM "US20030004584A1-20030102-D00018.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00019.TIF SYSTEM "US20030004584A1-20030102-D00019.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00020.TIF SYSTEM "US20030004584A1-20030102-D00020.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00021.TIF SYSTEM "US20030004584A1-20030102-D00021.TIF" NDATA TIF>
<!ENTITY US20030004584A1-20030102-D00022.TIF SYSTEM "US20030004584A1-20030102-D00022.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004584</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09894285</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010627</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G05B011/01</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G05B015/00</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>700</class>
<subclass>017000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>700</class>
<subclass>083000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>User interface for a gamma camera which acquires multiple simultaneous data sets</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Jeffrey</given-name>
<middle-name>A.</middle-name>
<family-name>Hallett</family-name>
</name>
<residence>
<residence-us>
<city>Livermore</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>Corporate Patent Counsel</name-1>
<name-2>Philips Electronics North America Corp.</name-2>
<address>
<address-1>580 White Plains Road</address-1>
<city>Tarrytown</city>
<state>NY</state>
<postalcode>10591</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A gamma camera system is described having a user interface by which protocols can be set up for the simultaneous acquisition of different views. Pull-down menus prevent the selection of incompatible simultaneous views for acquisition. The protocol being assembled, including its sequential steps and multiple simultaneous views, are displayed to the user. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This invention relates to nuclear (gamma camera) imaging systems and, in particular, to gamma cameras which acquire multiple data sets simultaneously during a study. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> When diagnosing a patient in a gamma camera study, the results of one study at times can determine whether another different study is required. For example, a cardiac study may acquire gated event data for imaging a particular phase of the heart cycle such as end-diastole. However, if the heartbeat is irregular, the acquired data set can be non-diagnostic, as it can be contaminated with event data acquired at times other than the desired phase of the heart cycle. In such a case the clinician may then decide to do an ungated study, where the irregular heartbeat is less of an obstacle to the intended data acquisition. This of course mandates a second study and may require a second dosing of the patient with the radionuclide. It would be desirable to be able to obviate the need for such subsequent studies so as to make more efficient use of the patient&apos;s time and the utilization of the gamma camera, and to obviate the need for repeated exposure of the patient to radionuclides. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> Concurrently filed U.S. patent application serial number &lsqb;ADAC19006&rsqb; addresses this problem by providing a gamma camera system which acquires multiple data sets during a single study. The data sets are used to produce different types of images from the same protocol. If one type of image proves to be diagnostically unsuitable or ambiguous at the conclusion of the protocol, one of the alternate types of images may provide information which is better suited for making the diagnosis. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Since the multiple acquisitions are done during performance of the same protocol, the different acquisitions must be compatible with the same camera gantry behavior. The gamma camera system should automatically check for and prevent attempts to perform incompatible acquisitions simultaneously. Furthermore, these checks should occur as the clinician sets up the camera for the study. The user interface (control panel or display) of the camera should enable the clinician to set up a protocol uniquely designed for the patient and should allow the setting and editing of study parameters. Furthermore, the user interface should enable the setup of protocols which acquire multiple sets of image data simultaneously, thereby providing the clinician with a variety of diagnostic results. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In accordance with the principles of the present invention, a user interface is provided for a gamma camera system. The user interface enables a clinician to set up study protocols which have one or more sequential steps for automatic execution by the camera. Concurrently acquired views can be set up for a particular step in the protocol, and the user interface prevents setup of protocols with conflicting acquisition requirements. The user interface enables the clinician to set up different types of acquisitions concurrently without allowing the setup of protocols with conflicting simultaneous requirements.</paragraph>
</summary-of-invention>
<brief-description-of-drawings>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> In the drawings: </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates the major components of a gamma camera system; </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates in block diagram form the post data acquisition processing and display system of the gamma camera of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates some of the parameters which may be used in a gated SPECT study; </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates in block diagram form a network of the gamma camera which simultaneously processes different data sets from the same imaging procedure in accordance with the principles of the present invention; </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates a high speed data path from which the Producer of <cross-reference target="DRAWINGS">FIG. 4</cross-reference> reads input data; </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 6</cross-reference><highlight><italic>a</italic></highlight>-<highlight><bold>6</bold></highlight><highlight><italic>d </italic></highlight>illustrate the format of the data used in a constructed embodiment of the present invention; and </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> FIGS. <highlight><bold>7</bold></highlight>-<highlight><bold>12</bold></highlight> illustrate user interface displays by which a clinician can set up proper protocols which perform different types of acquisitions concurrently.</paragraph>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates the major components of a nuclear camera image acquisition, processing and display system. The present invention includes either a single head (single detector) camera <highlight><bold>10</bold></highlight> as shown in the drawing or a dual head (dual detector) camera as shown in U.S. Pat. No. 5,760,402 (Hug. et al.) or U.S. Pat. No. 6,150,662 (Hug et al.). These camera systems are SPECT cameras ideal for cardiac, abdominal, and whole body studies and are capable of implementing gated SPECT imaging techniques. In the illustration of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, two arms <highlight><bold>11</bold></highlight> and <highlight><bold>9</bold></highlight> mounted on vertical tracks <highlight><bold>16</bold></highlight> and <highlight><bold>15</bold></highlight> form a gantry structure that can move the detector head <highlight><bold>12</bold></highlight> in various projection angles to accomplish the required 180 and 360 degree movements of the detector <highlight><bold>12</bold></highlight> used in gated SPECT studies. Pivot structure <highlight><bold>17</bold></highlight> allows the camera detector <highlight><bold>12</bold></highlight> and gantry structure to pivot clockwise or counterclockwise. The camera system <highlight><bold>10</bold></highlight> includes a detector head <highlight><bold>12</bold></highlight> comprising a number of well known radiation detection components of the Anger camera type including a photomultiplier array, a collimator, a scintillating crystal and a digital pixel output. The camera system <highlight><bold>10</bold></highlight>, in a well known fashion, images the patient to provide digital image data which is binned according to particular discrete angles of rotation in which the detector <highlight><bold>12</bold></highlight> traverses about the patient. Binning can also occur according to particular phases of the cardiac cycle (R-R interval, defined below). For each angle of rotation, several phases of the cardiac cycle may be interrogated. Particular (x,y) coordinate positions within the imaging detector of the camera system are called pixel locations and the number of scintillations detected by each pixel location is represented by a count value for that pixel. Each pixel contains a count value representing the number of radiation emissions detected at that location of the detector <highlight><bold>12</bold></highlight>. The resulting digital image data from the camera system <highlight><bold>10</bold></highlight> is binned according to the particular discrete angle of rotation in which the detector was situated when the image data was acquired. Also binned is the gated segment (phase) within the R-R interval in which the data was acquired in gated SPECT studies. The pixel matrix of (x,y) locations is referred to herein as a histogram of scintillations at these coordinate locations. It is understood that a histogram represents a raw image. For example, a typical detector <highlight><bold>12</bold></highlight> may have a resolution of (64&times;64) pixels or (128&times;128) pixels available for imaging and is capable of imaging at a maximum resolution of approximately (1000&times;1000) pixels. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The camera system <highlight><bold>10</bold></highlight> is coupled to a data acquisition computer system <highlight><bold>20</bold></highlight>, which in a particular constructed embodiment is implemented using a general purpose computer system having high speed communications ports for input and output coupled to a two-way data transmission line <highlight><bold>19</bold></highlight> coupling the camera system <highlight><bold>10</bold></highlight> to the computer system <highlight><bold>20</bold></highlight>. The computer system <highlight><bold>20</bold></highlight> communicates data acquisition parameters (also called data acquisition protocols) selected by a user to the camera system <highlight><bold>10</bold></highlight> to initiate a particular type of study by the camera system <highlight><bold>10</bold></highlight>. The imaging data from the camera system <highlight><bold>10</bold></highlight> is then transferred over line <highlight><bold>19</bold></highlight> to the communications device of the system <highlight><bold>20</bold></highlight> and this raw gated SPECT image data is then forwarded to a post acquisition processing computer system <highlight><bold>120</bold></highlight>. The data acquisition system <highlight><bold>20</bold></highlight> also comprises a keyboard entry device <highlight><bold>21</bold></highlight> for user interface to allow selection and modification of predefined data acquisition parameters which control the imaging processes of the camera system <highlight><bold>10</bold></highlight>. Also coupled to the data acquisition system <highlight><bold>20</bold></highlight> is a standard color display monitor <highlight><bold>28</bold></highlight> for display of parameter information and relevant information regarding the particular gated SPECT study underway such as imaging status communicated from the camera system <highlight><bold>10</bold></highlight> during an imaging session. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> For a gated SPECT study a cardiac electrode and signal amplification unit <highlight><bold>25</bold></highlight> is also coupled to the data acquisition computer system <highlight><bold>20</bold></highlight>. This unit <highlight><bold>25</bold></highlight> is specially adapted to couple with a patient&apos;s chest near the heart to receive the heartbeat electrical signal. The unit <highlight><bold>25</bold></highlight> is composed of well known heartbeat detection and amplification (EKG) components and any of several well known devices can be utilized within the scope of the present invention. In order to perform gated SPECT analysis on the heart, the heartbeat pulse or electrical wave must be studied for each patient, as each heart is different. The heartbeat wave is examined to determine the points within the cycle where the well-known R wave is encountered. The time interval between successive R waves is measured to determine the R-R interval. These points and timing intervals between these points will be used to gate the imaging process of the camera system <highlight><bold>10</bold></highlight> during the cardiac cycle and particularly at the end-diastole and end-systole interval segments. The preferred embodiment of the present invention automatically, under control of the system <highlight><bold>20</bold></highlight>, collects five sample heartbeat waves once the detector <highlight><bold>25</bold></highlight> is located on the subject patient in order to determine the average R-R period. This information is fed to the computer system <highlight><bold>20</bold></highlight> and then sent to the camera system <highlight><bold>10</bold></highlight>. However such information could also be detected and determined directly by the computer system <highlight><bold>10</bold></highlight> once conditioned to do so by the acquisition computer system <highlight><bold>20</bold></highlight> under user control. For a particular projection angle, the system <highlight><bold>10</bold></highlight> directs the acquired imaging counts to the first segment bin, and upon each successive time interval the image data is directed to a new gated bin. When the R wave is detected once more, the first bin receives the image data again and the process continues through each other segment and associated bin until a new projection angle is encountered. The electrode <highlight><bold>25</bold></highlight> also is used by the camera system <highlight><bold>10</bold></highlight> in order to detect the start of a cardiac cycle and gate the camera imaging system appropriately depending on the number of selected segments of the R-R interval used for collection. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> As discussed above, the data acquisition portion of the imaging system is composed of camera system <highlight><bold>10</bold></highlight> and computer system <highlight><bold>20</bold></highlight>. Referring still to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the image data is sent from the camera system <highlight><bold>10</bold></highlight> over line <highlight><bold>19</bold></highlight> to acquisition system <highlight><bold>20</bold></highlight> and then over line <highlight><bold>22</bold></highlight> to the post acquisition processing system <highlight><bold>120</bold></highlight>. This system <highlight><bold>120</bold></highlight> is responsible for processing, displaying and quantifying certain data acquired by system <highlight><bold>10</bold></highlight> and system <highlight><bold>20</bold></highlight>. Specifically, the system <highlight><bold>120</bold></highlight> can process and uniquely display quantitative information regarding blood flow within the myocardium (perfusion) and wall motion of the myocardium (function) as a result of the gated SPECT data acquired. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The post acquisition processing system <highlight><bold>120</bold></highlight> acquires the raw gated SPECT image data generated by the camera system <highlight><bold>10</bold></highlight> and, using user configurable procedures, reconstructs (performs tomography or backprojection) the data to provide a reconstructed volume and from the volume generates specialized planar or volumetric images for diagnosis, including generating and displaying the functional images as described above. In cardiac imaging the generated images or frames represent different slices of the reconstructed heart volume at variable thicknesses in a short axis dimension, a vertical dimension and a horizontal dimension (all three are user configurable) for a number of gated time segments. Therefore, complete three dimensional information can be displayed by display <highlight><bold>105</bold></highlight> in a two dimensional manner in a variety of formats and orientations including a display providing quantitative information regarding both wall thickening (perfusion) and wall motion (function) of the myocardium under study. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> The computer of the post acquisition processing system <highlight><bold>120</bold></highlight> in a constructed embodiment illustrated in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a SPARC system available from Sun Microsystems of California, however any number of similar computer systems having the requisite processing power and display capabilities will suffice within the scope of the present invention. Generally, the system <highlight><bold>120</bold></highlight> comprises a bus <highlight><bold>100</bold></highlight> for communicating information, a central processor <highlight><bold>101</bold></highlight> coupled with the bus for processing information (such as image data and acquired counts) and command instructions, a random access memory <highlight><bold>102</bold></highlight> coupled with the bus <highlight><bold>100</bold></highlight> for storing information and instructions for the central processor <highlight><bold>101</bold></highlight>, a read only memory <highlight><bold>103</bold></highlight> coupled with the bus <highlight><bold>100</bold></highlight> for storing static information and command instructions for the processor <highlight><bold>101</bold></highlight>, a data storage device <highlight><bold>104</bold></highlight> such as a magnetic disk or optical disk drive coupled with the bus <highlight><bold>100</bold></highlight> for storing information (such as both raw gated SPECT and reconstructed data sets) and command instructions, and a display device <highlight><bold>105</bold></highlight> coupled to the bus <highlight><bold>100</bold></highlight> for displaying information to the computer user. There is also an alphanumeric input device <highlight><bold>106</bold></highlight> including alphanumeric and function keys coupled to the bus <highlight><bold>100</bold></highlight> for communicating information and command selections to the central processor <highlight><bold>101</bold></highlight>, a cursor control device <highlight><bold>107</bold></highlight> coupled to the bus for communicating user input information and command selections to the central processor <highlight><bold>101</bold></highlight> based on hand movement, and an input and output device <highlight><bold>108</bold></highlight> coupled to the bus <highlight><bold>100</bold></highlight> for communicating information to and from the computer system <highlight><bold>120</bold></highlight>. The input and output device <highlight><bold>108</bold></highlight> includes, as an input device, a high speed communication port configured to receive image data acquired by the nuclear camera system <highlight><bold>10</bold></highlight> and fed over line <highlight><bold>22</bold></highlight>. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> The display device <highlight><bold>105</bold></highlight> utilized with the system of the present invention may be a liquid crystal device, cathode ray tube, or other display device suitable for creating graphic images and alphanumeric characters recognizable to the user. The display unit <highlight><bold>105</bold></highlight> of the preferred embodiment of the present invention is a high resolution color monitor. The cursor control device <highlight><bold>107</bold></highlight> allows the computer user to dynamically signal the two dimensional movement of a visible symbol or cursor <highlight><bold>5</bold></highlight> (pointer) on a display screen of the display device <highlight><bold>105</bold></highlight>. Many implementations of the cursor control device are known in the art including a trackball, mouse, joystick or special keys on the alphanumeric input device <highlight><bold>105</bold></highlight> capable of signaling movement of a given direction or manner of displacement. It will be appreciated that the cursor control device <highlight><bold>107</bold></highlight> also may be directed and/or activated via input from the keyboard using special keys and key sequence commands, or from a touchscreen display device. In the discussions regarding cursor movement and/or activation within the preferred embodiment, it is to be assumed that the input cursor directing device may consist of any of those described above and is not limited to the mouse cursor device. It will be appreciated that the computer chassis <highlight><bold>110</bold></highlight> may include the following components of the image processor system: the processor <highlight><bold>101</bold></highlight>, ROM <highlight><bold>103</bold></highlight>, RAM <highlight><bold>102</bold></highlight>, the data storage device <highlight><bold>104</bold></highlight>, and the signal input and output communication device <highlight><bold>108</bold></highlight> and optionally a hard copy printing device. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The data acquisition system <highlight><bold>20</bold></highlight> allows a user via keyboard control to select and/or create a predefined set of parameters (or protocols) for direction of a gated SPECT imaging session or other selected study by the camera system <highlight><bold>10</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates a parameter interface screen and configurable parameters of a nuclear camera system for data acquisition that are selected and displayed on a screen by the user via keyboard <highlight><bold>21</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates some of the parameters that are configurable by the data acquisition system <highlight><bold>20</bold></highlight>. It is appreciated that once set, the configurable parameters can be saved and referenced in a computer file for subsequent recall. The stored parameters or protocol file can then be recalled and utilized for a particular study, thus eliminating the need to again enter the parameters for similar or identical studies. The name of the parameter file shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is &ldquo;GATED SPECT&rdquo; and is indicated at <highlight><bold>300</bold></highlight>. It is appreciated that the computer system <highlight><bold>20</bold></highlight>, once instructed by the user, will relay the parameters set by the user to the camera system <highlight><bold>10</bold></highlight> in order to initialize and begin a particular study. The initiation is done by selection of processing command <highlight><bold>357</bold></highlight>. A user interface of this type is thus versatile while at the same time providing a high degree of automation of the execution of selected study protocols. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> In accordance with the principles of the present invention, the gamma camera system of FIGS. <highlight><bold>1</bold></highlight>-<highlight><bold>3</bold></highlight> is capable of performing several studies simultaneously by use of the data network shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. The network includes a ring buffer <highlight><bold>1720</bold></highlight> into which gamma camera data is entered at a high data rate. The data in the illustrated ring buffer <highlight><bold>1720</bold></highlight> may have a specified start point <highlight><bold>1722</bold></highlight> and an end point <highlight><bold>1724</bold></highlight> that may adjust around the ring buffer as data is received and processed. The gamma camera data is entered into the ring buffer by one or more Producers, one of which is shown at <highlight><bold>1700</bold></highlight>. A Producer is a camera subsystem or data path which enters data into the ring buffer <highlight><bold>1720</bold></highlight>. The Producer illustrated in the drawing is a data stream <highlight><bold>1710</bold></highlight> from a detector or camera head, which inputs detector data into the ring buffer. Other Producers may provide data from other sources such as stored data sources, for example. Some of the types of data words which are provided by a detector are described in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> below. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Accessing the data which traverses the ring buffer <highlight><bold>1720</bold></highlight> are one or more Consumers. Three Consumers are shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, and are labeled C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, and C<highlight><bold>3</bold></highlight>. A Consumer is a data processor or path or other entity which makes use of some or all of the data in the ring buffer <highlight><bold>1720</bold></highlight>. In the illustrated embodiment each Consumer is an entity conditioned to look for specific characteristics of event data and to read data from the ring buffer selected for a particular type of study. The studies in the following examples are all associated with types of images and hence the Consumers shown in this example read and process selected data into images, which can then be forwarded to an image display. Each Consumer C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight> and C<highlight><bold>3</bold></highlight> examines the data in the ring buffer as it passes by its input, and independently reads those data words which are needed for the studies being supported by that Consumer. The Consumers operate both independently and simultaneously, and each can support one or more imaging processes. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> In a constructed embodiment the data from a detector, being produced in real time as the detector head detects scintillation events, is provided over a high speed data path <highlight><bold>1730</bold></highlight> as illustrated in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. The stream of data words is provided serially from the detector as indicated by sequential data locations <highlight><bold>1732</bold></highlight>, <highlight><bold>1734</bold></highlight> . . . <highlight><bold>1736</bold></highlight>. The data at the output of the data path <highlight><bold>1730</bold></highlight> is read by the input of a Producer, which enters the data into the ring buffer <highlight><bold>1720</bold></highlight>. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Examples of the types of event data which may be provided by a detector are shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. In this example each event word is 64 bits long. The words in this drawing are shown in four lines of sixteen bits each. <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>a </italic></highlight>illustrates a scintillation event word <highlight><bold>1802</bold></highlight> with four energy window bytes EWIN of four bits each. The setting of one of these bits denotes one of sixteen energy windows in which the particular scintillation event was acquired. Typically a detector will only produce data for energy windows chosen by the camera operator. The TAG ID and TAG VERSION (VER.) bytes identify the data word as a scintillation event word. The TAG bytes provide information such as the detector number which produced the event. Data X and Data Y provide the x and y coordinate locations on the detector at which the event was sensed. The Data Z byte provides the energy number of the detected event. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>b </italic></highlight>shows a format for a gantry event word <highlight><bold>1804</bold></highlight>. Gantry event words provide information as to the current position of the gantry and hence the locations of the detectors. Gantry event data originates with sensors, controllers, and other devices associated with the gantry or from control programs for the gantry. The illustrated gantry event word <highlight><bold>1804</bold></highlight> has TAG ID and VER. bytes which identify the word as a gantry event word. The TAG bytes provide information as to the type of information contained in the gantry event word. The last three lines contain the data pertinent to the gantry event. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>c </italic></highlight>gives an example of a time event word <highlight><bold>1806</bold></highlight>. The acquisition system provides these words as time markers so that the other events of the camera can be oriented in time. Time events occur in regular intervals such as once every millisecond. The TAG bytes of the time event word denote the word as a time event word. The rest of the time event word comprises data giving the time information. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>d </italic></highlight>illustrates an EKG event word <highlight><bold>1808</bold></highlight>, which will be produced when a cardiac electrode unit <highlight><bold>25</bold></highlight> is used for a gated study. The TAG bytes identify the word as an EKG event word. A TRIGGER DATA byte provides information as to the trigger event, and the other data bytes of the EKG event word provide other information pertinent to the EKG event. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Other event words may also be present in the data stream provided by the detectors and entered into the ring buffer <highlight><bold>1720</bold></highlight>. For example Start and Stop event words may be used to indicate the start of an image acquisition session and the conclusion of an image acquisition session. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Some examples will illustrate various studies which can be carried out simultaneously by an embodiment of the present invention. One example is imaging with two energy windows simultaneously. Consumer C<highlight><bold>1</bold></highlight> is conditioned to look for scintillation event words in the ring buffer for which the EWIN&num;1 bit is set. Scintillation event data exhibiting this characteristic is selected and is binned to form pixels for a first image W<highlight><bold>1</bold></highlight>. Consumer C<highlight><bold>2</bold></highlight> is conditioned to look for scintillation events in the ring buffer for which the EWIN&num;2 bit is set, and this scintillation event data is read by the Consumer C<highlight><bold>2</bold></highlight> and binned to form pixels for a second image W<highlight><bold>2</bold></highlight>. A third Consumer C<highlight><bold>3</bold></highlight> is conditioned to look for scintillation event words in which either bit EWIN&num;1 or bit EWIN&num;2 is set, and reads and bins this event data to produce pixels for a third image W<highlight><bold>1</bold></highlight>&plus;W<highlight><bold>2</bold></highlight>. All three Consumers use gantry events and time events. A variation of this operation would be to use only a single Consumer to look for scintillation event words in which either bit EWIN&num;1 or bit EWIN&num;2 is set, and to thereafter sort and bin this event data into distinct images W<highlight><bold>1</bold></highlight>, W<highlight><bold>2</bold></highlight>, or W<highlight><bold>1</bold></highlight>&plus;W<highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> A second example of an application of the present invention is to perform gated and ungated studies simultaneously. Two Consumers C<highlight><bold>1</bold></highlight> and C<highlight><bold>2</bold></highlight> are separately conditioned for the two types of studies. In this example, Consumer C<highlight><bold>1</bold></highlight> monitors the event data for EKG trigger event data, while Consumer C<highlight><bold>2</bold></highlight> does not monitor this data. For example, C<highlight><bold>1</bold></highlight> may be conditioned to acquire an image of data produced during a heart cycle interval occurring 600-700 milliseconds after the start of a heart cycle. The Consumer C<highlight><bold>1</bold></highlight> would monitor the event data in the ring buffer until an EKG trigger event word is identified. Consumer C<highlight><bold>1</bold></highlight> then begins reading scintillation event data and forwarding the event data to an image processor. When the count of time event words by C<highlight><bold>1</bold></highlight> reaches the predefined time (600-700 milliseconds in this example), C<highlight><bold>1</bold></highlight> stops binning the scintillation event words. Consumer C<highlight><bold>1</bold></highlight> then monitors the event data for the next EKG event word, whereupon the process repeats for the next heart cycle. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> While Consumer C<highlight><bold>1</bold></highlight> is acquiring the gated heart data, Consumer C<highlight><bold>2</bold></highlight> is acquiring ungated event data. For example, Consumer C<highlight><bold>2</bold></highlight> may be conditioned to acquire scintillation event data continuously for 20 seconds, which covers many heart cycles. As Consumer C<highlight><bold>1</bold></highlight> begins to monitor and acquire its gated acquisition data, the Consumer C<highlight><bold>2</bold></highlight> acquires a continuous stream of event data for 20 seconds or 20 heart cycles, or some other selected period. Consumer C<highlight><bold>2</bold></highlight> forwards the event data it selects to an image processor for binning of an ungated image. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> This acquisition sequence, in which one Consumer acquires gated event data while another Consumer acquires ungated event data, is performed for each gantry position of the protocol. The simultaneous acquisitions are repeated for each gantry position based upon the detection of new gantry events by the Consumers. In a constructed embodiment the Consumers provide status of their acquisitions to a control program. When each Consumer has satisfied its needs for new event data at a particular gantry location, this status is reported to the control program. When all Consumers report that they are satisfied, the control program commands the movement of the gantry to the next detector position. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> When acquisition data has been acquired from all of the gantry positions of the protocol, the study and its acquisition of the simultaneous images is complete. The clinician may find that the gated image is sufficient for a diagnosis and may make a diagnosis without examining the ungated image at all. Alternatively, the clinician may discover that the patient has experienced an irregular heartbeat during the study, and that this has caused the scintillation events to be inaccurately binned. The gated image may thus be nondiagnostic. The clinician can then examine the ungated image, which is not similarly affected by the irregular heartbeat. The ungated image may be sufficient for the clinician to conclude a diagnosis, which is thus made without conducting another study and without the need to redose the patient. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Other types of simultaneous studies are possible with an embodiment of the present invention. For instance, zoomed and unzoomed images may be produced simultaneously by conditioning the Consumers to select event data from the appropriate detector locations, and binning the event to the appropriate zoomed and unzoomed pixel resolution. As another example, both flow and wall motion images can be acquired simultaneously, as well as both perfusion and wall motion images. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> One skilled in the art will appreciate that, since the simultaneous acquisitions are being made during the same sequence of gantry motion, the two acquisitions must be ones that can be performed during the extant gantry behavior. For example, a planar gated study (in which the detector head is stationary) and an ECT study (in which the detector head moves) cannot be performed simultaneously, since these two procedures call for different detector motion. Accordingly, the control program which sets up the simultaneous protocols at the outset of the exam performs consistency checks of the multiple acquisitions called for by the operator to assure that the two acquisitions utilize the same gantry behavior. In accordance with the principles of the present invention, a user interface which presents these features to the operator is described in FIGS. <highlight><bold>7</bold></highlight>-<highlight><bold>12</bold></highlight>. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> illustrates a user interface screen <highlight><bold>200</bold></highlight> by which the operator of the gamma camera sets up a protocol. At the top of the display is a row <highlight><bold>214</bold></highlight> of control buttons, including one labeled &ldquo;Acquire Patient.&rdquo; This button is clicked by the operator to command the camera to begin executing the protocol which has been set up by the operator. Below the row <highlight><bold>214</bold></highlight> of control button and on the left side of the screen is a display area <highlight><bold>202</bold></highlight> where the operator enters patient identification data. Below this area is a display area <highlight><bold>204</bold></highlight> where the steps of the protocol are displayed. A protocol may have one or more steps which are performed sequentially. In the illustrated example the protocol has a static step followed by an ECT (SPECT) step. During the static step the camera detector heads do not move, and during the SPECT step the detector heads are moved around the patient as radionuclide events are gathered. Below the protocol step area <highlight><bold>204</bold></highlight> is a protocol edit area <highlight><bold>206</bold></highlight> where the operator is given selections to add or remove steps or acquired views from the protocol. At the bottom of the screen is a status bar <highlight><bold>220</bold></highlight>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> In the center of the screen are display areas <highlight><bold>208</bold></highlight>, <highlight><bold>210</bold></highlight>, and <highlight><bold>212</bold></highlight> which provide for the setting of details of the particular protocol being set up. The example shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a protocol called &ldquo;concurrent example&rdquo; because it exemplifies a protocol where several views are acquired concurrently during one step of the protocol. Since the &ldquo;Static&rdquo; step is highlighted in display area <highlight><bold>204</bold></highlight>, the center area of the screen displays and allows entry of information concerning the Static step of the Concurrent Example protocol. The Detector/Imaging area <highlight><bold>208</bold></highlight> is where parameters of the detector are entered. Information about the isotopes being used in the study is entered in area <highlight><bold>210</bold></highlight>. In this example the isotope Tc-99m is being used in the static step of the protocol. Identification of the isotopes used aids in setting up and manipulating the energy windows used in the study. In Stop Criteria area <highlight><bold>212</bold></highlight> the operator enters parameters which will determine when the particular step of the protocol is ended. In this example event data is acquired for an image until 10,000 counts have been accumulated. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows how the operator adds another view to a step of the protocol. This is done by clicking on the pull-down &ldquo;Add View&rdquo; menu. In this example the operator is given the choice of adding a static, dynamic, or gated planar view to the Static step highlighted in the protocol box <highlight><bold>204</bold></highlight>. By using pull-down menus instead of allowing data to be typed in, the user interface restricts additional views to those that are valid for the particular step being modified. The pull-down menu could display all views of the camera with incompatible ones greyed out. However, in the preferred embodiment the pull-down menu shows only those choices which are valid for the protocol step highlighted. This self-check mechanism is necessary for tasks being performed concurrently such as simultaneous image acquisition, but is not generally a concern for serial tasks such as the sequential steps of the protocol. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows the result of adding the acquisition of a concurrent dynamic view to the static step. Concurrent views are now shown beneath the Static step heading in the protocol box <highlight><bold>204</bold></highlight>. Thus, during execution of the static step of the protocol, the camera will perform two different types of image data acquisition. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 10</cross-reference> the operator has highlighted the SPECT step in the protocol box <highlight><bold>204</bold></highlight>, and details of this step of the protocol appear in the central boxes <highlight><bold>208</bold></highlight>-<highlight><bold>212</bold></highlight>. In addition, a SPECT box <highlight><bold>216</bold></highlight> is displayed showing information particular to detector head movement (gantry operation) during the SPECT step of the protocol. When the user pulls down the &ldquo;Add View&rdquo; menu in box <highlight><bold>206</bold></highlight> to add another view to this step, the choices of &ldquo;SPECT&rdquo; (non-gated SPECT) and &ldquo;Gated SPECT&rdquo;, which are compatible with the SPECT step are displayed to the operator for selection. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 11</cross-reference> the operator has added a gated SPECT view to the SPECT step, as shown by the highlighted view line &ldquo;GPROJ-R&rdquo; in the protocol box <highlight><bold>204</bold></highlight>. Parameters of the gating may be set in the &ldquo;Gated&rdquo; box <highlight><bold>218</bold></highlight> which now appears for the operator. The camera is now set up to perform both a gated and a non-gated acquisition simultaneously as described above. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> shows the simultaneous acquisitions of the static step being set up for multi-energy operation. As the Isotope box <highlight><bold>210</bold></highlight> shows, event data of the isotope Co-57 is being acquired in one view while the parent static step is acquiring event data of the isotope Tc-99m (see <cross-reference target="DRAWINGS">FIG. 7</cross-reference>). Thus, views from different isotopes can be set up and acquired simultaneously through the user interface <highlight><bold>200</bold></highlight>. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> It is seen that an embodiment of the present invention can allow a clinician to set up protocols of multiple steps and with the acquisition of multiple simultaneous views. Energy windows can be turned on and off or edited for any step and isotopes can be set up for any step. Concurrent acquisition of different energy windows allows energy windows to be combined and images of specific combinations of energy windows to be produced. As the clinician sets up the desired protocol the user interface disables conflicting parameters so that validly executable protocols result. </paragraph>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A nuclear camera system comprising: 
<claim-text>a detector coupled to a gantry; </claim-text>
<claim-text>a controller, coupled to the gantry and detector, which controls operation of the gantry and detector in accordance with a study protocol; and </claim-text>
<claim-text>a user interface, coupled to the controller, which enables the setup of a study protocol for performing different types of acquisitions concurrently. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The nuclear camera system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the user interface further acts to prevent the setup of concurrent acquisitions which are incompatible with each other. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The nuclear camera system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the concurrent acquisitions are gated SPECT and non-gated SPECT acquisitions. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The nuclear camera system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the concurrent acquisitions are a static acquisition and one of a dynamic, static, and gated planar acquisition. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The nuclear camera system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the user interface further comprises a display which displays the steps selected for a protocol and the views selected for each step. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The nuclear camera system of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein the user interface further comprises a control by which at least one of an additional step or an additional view can be added to the protocol. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The nuclear camera system of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein the user interface control comprises a pull-down menu which prevents the addition of an incompatible step or view to the protocol. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The nuclear camera system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the pull-down menu further comprises selections of only compatible additions to a step or view. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The nuclear camera system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the pull-down menu further comprises grayed-out selections which are incompatible with the step or view being modified. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The nuclear camera system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the user interface comprises means for enabling a user to produce a protocol for acquiring two event data sets during the same acquisition step; and 
<claim-text>wherein the means for enabling further comprises means for checking that acquisition of the two data sets is consistent with the gantry behavior of the acquisition step. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A method for setting up a study protocol for a gamma camera having a camera controller and a user interface coupled to the camera controller comprising: 
<claim-text>displaying a list of steps which may be added to the protocol; </claim-text>
<claim-text>displaying a list of views which may be added to a step of the protocol; </claim-text>
<claim-text>enabling the selection of steps to be added to the protocol; and </claim-text>
<claim-text>enabling the selection of multiple views which may be acquired during a step of the protocol. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, further comprising: 
<claim-text>preventing the selection of multiple incompatible views for simultaneous acquisition. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, further comprising: 
<claim-text>displaying the steps and multiple simultaneous views chosen for a protocol.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004584A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004584A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004584A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004584A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004584A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004584A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004584A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004584A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004584A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004584A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030004584A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030004584A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030004584A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030004584A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030004584A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030004584A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030004584A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030004584A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030004584A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00019">
<image id="EMI-D00019" file="US20030004584A1-20030102-D00019.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00020">
<image id="EMI-D00020" file="US20030004584A1-20030102-D00020.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00021">
<image id="EMI-D00021" file="US20030004584A1-20030102-D00021.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00022">
<image id="EMI-D00022" file="US20030004584A1-20030102-D00022.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
