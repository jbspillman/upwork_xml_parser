<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002870A1-20030102-D00000.TIF SYSTEM "US20030002870A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002870A1-20030102-D00001.TIF SYSTEM "US20030002870A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002870A1-20030102-D00002.TIF SYSTEM "US20030002870A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002870A1-20030102-D00003.TIF SYSTEM "US20030002870A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002870A1-20030102-D00004.TIF SYSTEM "US20030002870A1-20030102-D00004.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002870</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09894380</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010627</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G03B013/30</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>396</class>
<subclass>147000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>System for and method of auto focus indications</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>John</given-name>
<middle-name>M.</middle-name>
<family-name>Baron</family-name>
</name>
<residence>
<residence-us>
<city>Longmont</city>
<state>CO</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>HEWLETT-PACKARD COMPANY</name-1>
<name-2>Intellectual Property Administration</name-2>
<address>
<address-1>P.O. Box 272400</address-1>
<city>Fort Collins</city>
<state>CO</state>
<postalcode>80527-2400</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The present invention includes a system for and method of highlighting portions of the displayed image in a camera which are in focus to the photographer. Included in the highlighted portion are all focused portions of objects within the depth of field. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> Cameras, and other image capturing devices, have been used by individuals to record visual images for many years. Earlier cameras used light sensitized emulsion coated on a plate or film onto which a latent image was captured and, once captured and developed, used to create visual images which portrayed the original photographed scene. More recently, digital cameras have become available with their popularity increasing over the last couple of years. Digital cameras typically record captured images as bitmap images in a storage device such as a 3&frac12; inch magnetic disk or similar storage media. These stored images may be processed or modified by a computer user and may be printed out and used accordingly. While the original digital cameras included basic functionality, today&apos;s digital cameras include numerous features and in some instances include features which cannot be implemented with conventional film-based cameras. For instance, storage techniques have evolved in such a way that digital cameras may store hundreds of low resolution images. Additionally, digital camera users may select the resolution desired for images being captured and stored. The digital camera user may select images to be recorded in low, medium, or high resolution modes. Since, as the resolution of the captured image increases, the amount of memory dedicated to storing the image also increases, appropriate selection of picture resolution allows faster image capture when only low resolution is required and a corresponding reduction in image processing and storage requirements. Digital photography also allows modifications of captured digital images heretofore unavailable in conventional film photography. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Some types of cameras, both digital and conventional film cameras, include built in automatic focusing. Simple cameras sometimes use Infra Red (IR) detectors to determine range to a subject, others use sonic transducers to provide distance information. In contrast, single lenses reflect (SLR) cameras typically include autofocusing systems which may be classified as contrast measurement or phase matching systems. While phase matching systems are typically used in conventional film cameras, contrast measurement is the preferred method for digital cameras. Thus, most digital cameras achieve a focused image by maximizing the contrast between objects within an image. An object in exact focus is one which is at the precise focusing distance and is dependent on image format (e.g., aspect ratio), lense focal length, aperture size, and focus distance and tolerable circle of confusion for the final image. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The depth of field is an indication of the distance of objects from the focal point of the camera which will appear in focus at a given time. Typically, one-third of the depth of field lies in front of the subject at the precise focusing distance and two-thirds of the depth of field lies behind the subject. One of ordinary skill in the art would appreciate that ultimate print size also effects the depth of field. Typically, for conventional photography, an 8&times;10 inch print viewed at a distance of 24 inches is used to determine acceptable depths of field guidemarks on lenses. The depth of field is related to a circle of confusion which indicates how large a circle related to an object which is not at the exact focus may become without appearing distorted (e.g., &ldquo;fuzzy&rdquo;) to the human eye. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Fully autofocus devices incorporated into prior art cameras may be implemented to adjust depth of field and aperture to bring, for example, a large portion of the viewed image into focus. Alternatively, many prior art cameras include spot focusing which allows the user to identify, to the camera, a specific portion of the image the photographer desires to be focused. One of ordinary skill in the art understands and appreciates these focusing techniques. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> All of these prior art devices required the user to determine which portion of the image is being focused by the camera. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The present invention is directed to a system of and method for indicating to the photographer the specific portion or portions of the image which are in focus. The method of the present invention includes the steps of receiving a digital representation of an image, examining the digital representation to determine the portions of the image which are in focus and highlighting those focused portions to the photographer. For larger depths of field, far and near focused objects, and objects positioned between the far and near focus objects, may be highlighted, or all focused objects in the digital image may be highlighted. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a flow diagram of a procedure implemented by a system to determine the focused areas of an image; </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flow diagram of a procedure implemented by a system which displays and highlights the focused areas of an image to a user; </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a hardware block diagram of a camera which incorporates the present invention; and </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> FIGS. <highlight><bold>4</bold></highlight>A-<highlight><bold>4</bold></highlight>C contain sample images, as viewed by the photographer through the viewfinder, which illustrate an embodiment of the present invention. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> Generally, the present invention relates to a system for and method of unambiguously highlighting to a photographer the portions of an image contained in the viewfinder of a camera that are in focus. By highlighting the portions of the image which are in focus, confusion and uncertainty are eliminated and expected photographic images will result. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a flow diagram of a procedure implemented by a system to determine the focused area of an image. In step <highlight><bold>101</bold></highlight>, a first region of the captured image is selected. In step <highlight><bold>102</bold></highlight>, the first region selected is analyzed to determine the contrast between objects or pixels within the region. As one of ordinary skill in the art appreciates, as the contrast increases so does the focus of the region. In step <highlight><bold>103</bold></highlight>, the contrast of the region calculated in step <highlight><bold>102</bold></highlight> is compared to a contrast threshold value. If the calculated contrast is greater than the threshold value, the region is considered to be in focus. For regions in which the calculated contrast is greater than the threshold contrast, step <highlight><bold>104</bold></highlight> marks the region as in focus. For regions in which the calculated contrast is equal to or less than the threshold contrast, step <highlight><bold>105</bold></highlight> marks the region as out-of-focus. In step <highlight><bold>106</bold></highlight>, a determination is made as to whether additional regions remain to be checked. If additional regions remain, the next region is selected in step <highlight><bold>107</bold></highlight> and the process flow is returned to step <highlight><bold>102</bold></highlight>. When each region has been checked and each region has been marked as in-focus or out-of-focus, the process is completed. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flow diagram of a procedure used by a system to highlight the regions or areas of the image which are in focus. In step <highlight><bold>201</bold></highlight>, a first region is selected for analysis. In step <highlight><bold>202</bold></highlight>, the region is checked to determine if it has been marked as in-focus or out-of-focus. If the region is not marked, flow returns to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. If the analyzed region is marked as in-focus, step <highlight><bold>203</bold></highlight> determines the edge of the region. If edges are found in step <highlight><bold>204</bold></highlight>, then these edges are highlighted in step <highlight><bold>205</bold></highlight>. Highlighting may include blinking the identified portion of the object, reversing its color scheme, enclosing the focused section within a box, or similar highlighting techniques. If edges are not detected in step <highlight><bold>204</bold></highlight> or, after the detected edges are highlighted in step <highlight><bold>205</bold></highlight>, the procedure continues by determining if additional regions are present which must be checked for in-focus markings. If additional regions are available step <highlight><bold>207</bold></highlight> selects the next region and the process continues in step <highlight><bold>202</bold></highlight>. If, however, all regions have been checked the procedure is completed. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a hardware block diagram of a camera which incorporates the present invention. Processor <highlight><bold>301</bold></highlight> is electrically connected to User Input <highlight><bold>302</bold></highlight>, Image Sensor <highlight><bold>303</bold></highlight>, Focus Motor <highlight><bold>304</bold></highlight>, memory <highlight><bold>305</bold></highlight> and Viewfinder Display <highlight><bold>306</bold></highlight>. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> User Input <highlight><bold>302</bold></highlight> ensures that the input from the user, such as turning the highlighting feature on or off, is accepted by the system. Image Sensor <highlight><bold>303</bold></highlight> converts the light image into a suitable signal and/or image data for analysis. Once the image data is available to processor <highlight><bold>301</bold></highlight>, processor <highlight><bold>301</bold></highlight> may determine areas of the image which are within the near focus ranges, the far focus range, and everything which is in focus between the near focus and the far focus. Focus motor <highlight><bold>304</bold></highlight> works with process or <highlight><bold>301</bold></highlight> to present a focused input to the user. Once processor <highlight><bold>301</bold></highlight> determines which portions of the image are in focus using <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and highlights the appropriate portions using <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the image, including highlighted portions, is presented on Viewfinder Display <highlight><bold>306</bold></highlight>. When selected by the user, for instance by depressing the shutter, the captured image is recorded, without the associated highlighting, in memory <highlight><bold>305</bold></highlight>. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Note that contrast measurements may be taken during focusing so as to distinguish near focus objects from far focus objects. For example, as focus motor <highlight><bold>304</bold></highlight> adjusts the lens system from an infinity focus towards a near focus configuration, objects in the far field will increase in contrast until precisely focused, and then decrease in contrast as the lens system continues to be adjusted. The system keeps track of when each object reaches maximum contrast to determine a range to the object based on the focus setting of the lens system. Further, the lens system may be caused to pass through the preferred focus so as to allow mapping of all objects and/or portions of the image, i.e., determine the range to each object based on when the object achieves maximum contrast. Assuming distinct objects will tend to be varying distances from the camera, this technique can also be used to identify the bounds, outline, and extent of image areas representing individual objects. This technique may be used in lieu of or in addition to, edge recognition previously described. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> shows a representative image as the image would be displayed on the viewfinder without benefit of the present invention. While a photographer presented with this image can clearly tell the portion of the image which is in focus, one of ordinary skill in the art would understand other images contain objects which the average photographer cannot be assured are in focus. <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> shows the image of <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> after the in-focus section has been highlighted, in this case by outlining, by the present invention. Additional contrast can be obtained by &ldquo;greying out&rdquo; or de-emphasizing portions of the image which are not in-focus as determined by contrast measurement as shown in <cross-reference target="DRAWINGS">FIG. 4C</cross-reference>. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The present invention can also be applied to a manual focusing camera which lacks a focus motor in the lens. For implementation in a manual focusing camera software is included which enables the processor to interface with an encoder included within the lens and determine where in the focus travel the lens currently is positioned. This information is used to determine the portions of the view which are in focus and these portions are highlighted. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of automatically highlighting focused objects within a preview window comprising the steps of: 
<claim-text>receiving a digital representation of an image; </claim-text>
<claim-text>determining a near focus distance; </claim-text>
<claim-text>identifying near portions of objects within said image at said near focus distance; </claim-text>
<claim-text>determining a far focus distance; </claim-text>
<claim-text>identifying far portions of objects within said image at said far focus distance; and </claim-text>
<claim-text>highlighting said near portions and said far portions of said objects within said image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further including the stop of: 
<claim-text>displaying a digital image including said highlighted near and far portions. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight> The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> further comprising the step of: 
<claim-text>performing said steps of receiving, determining a near focus distance, identifying near portions, determining a far focus distance, identifying far portions, highlight and displaying within a digital camera. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight> The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising the step of: 
<claim-text>determining focused portions of objects between said near portions and said far portions; and </claim-text>
<claim-text>highlighting said focused portions. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference> further including the step of: 
<claim-text>displaying said highlighted focused portions on said digital image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A camera comprising: 
<claim-text>an image sensor responsive to a light image projected onto said image sensor for providing image data; </claim-text>
<claim-text>an adjustable focus lens configured to project said light image onto said image sensor; </claim-text>
<claim-text>a controller configured to adjust a focus of said adjustable focus lens and receive said image data from said image sensor, said controller further configured to distinguish portions of said image data that represent focused portions of said light image from portions that are not in focus; and </claim-text>
<claim-text>a display configured to display said image data together with highlighting distinguishing said portions of said image data that represent said focused portions of said light image from said portions that are not in focus. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> further comprising a memory storing a contrast evaluation procedure executable by said controller for distinguishing said portions of said image data that represent said focused portions of said light image from said portions that are not in focus. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> wherein said image sensor comprises a two-dimensional array of light detectors. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> wherein said adjustable focus lens includes a focusing motor connected to adjust a configuration of optical elements of said adjustable focus lens in response to a control signal from said controller. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> wherein said controller is configured to determine contrast values of said light image. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> wherein said controller is further configured to process said image data for storage in a memory. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> wherein said controller implements a lossy compression algorithm on said image data to form compressed image data and stores said compressed image data in a memory. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> further comprising the step of: 
<claim-text>disabling said highlighting of said near and said far portions. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> further comprising the steps of: 
<claim-text>compressing said digital image to provide compressed image data; and </claim-text>
<claim-text>storing said compressed image data in a memory. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> wherein said determining said near and said far portions is performed from identified edges of objects contained within the digital representation of an image. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> wherein said highlighting comprises blinking said near and far portions of said image in focus. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A focus highlighting system comprising: 
<claim-text>a processor for highlighting focused portions of an image; </claim-text>
<claim-text>an autofocus mechanism configured to determine portions of an image within focus; </claim-text>
<claim-text>a display configured to display a digital image including highlighting; and </claim-text>
<claim-text>a memory configured to store said digital representation of said image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The focus highlighting system of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> wherein: 
<claim-text>said autofocus calculates a near focus distance and determines near portions of objects using said near focus distance. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The focus highlighting system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> wherein: 
<claim-text>said autofocus calculates a far focus distance and determines far portions of objects using said far focus distance. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The focus highlighting system of <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> wherein: 
<claim-text>said portions of said image include said near focus portions and said far focus portions. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The focus highlighting system of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> wherein said highlighting includes blinking. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The focus highlighting of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> further including: 
<claim-text>a disable feature which disables highlighting when selected by a user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A camera comprising: 
<claim-text>an image sensor; </claim-text>
<claim-text>an image processor configured to determine portions of objects which appear in focus and to highlight said portions; and </claim-text>
<claim-text>a memory configured to store said image captured by said image sensor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference> further comprising: 
<claim-text>a display connected to display an image captured by said image sensor including said highlighting. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference> further comprising: 
<claim-text>an image compressor configured to perform compression of said corrected image data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein said image compressor implements a lossy image compression algorithm. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference> further comprising a housing containing said image sensor, display, image processor and memory. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The camera according to <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference> wherein said objects which appear in focus includes objects at different distances from said camera.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002870A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002870A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002870A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002870A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002870A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
