<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004725A1-20030102-D00000.TIF SYSTEM "US20030004725A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004725A1-20030102-D00001.TIF SYSTEM "US20030004725A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004725A1-20030102-D00002.TIF SYSTEM "US20030004725A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004725A1-20030102-D00003.TIF SYSTEM "US20030004725A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004725A1-20030102-D00004.TIF SYSTEM "US20030004725A1-20030102-D00004.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004725</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09894608</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010628</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G10L021/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>704</class>
<subclass>270000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Compressed list presentation for speech user interfaces</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Ciprian</given-name>
<family-name>Agapi</family-name>
</name>
<residence>
<residence-us>
<city>Hollywood</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>James</given-name>
<middle-name>R.</middle-name>
<family-name>Lewis</family-name>
</name>
<residence>
<residence-us>
<city>Delray Beach</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>International Business Machines Corporation</organization-name>
<address>
<city>Armonk</city>
<state>NY</state>
</address>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>Gregory A. Nelson</name-1>
<name-2>Akerman Sentarfitt</name-2>
<address>
<address-1>222 Lakeview Avenue, Fourth Floor</address-1>
<address-2>P.O. Box 3188</address-2>
<city>West Palm Beach</city>
<state>FL</state>
<postalcode>33402-3188</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A list presentation method. The list presentation method can include the steps of: dynamically grouping selected items in a list based on sequentially positioned symbols in the items which are common to one another; labeling each group of selected items; audibly presenting each group label through a speech user interface; and, responsive to a selection of one of the presented group labels, presenting through the speech user interface items in a group corresponding to the selected group label. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">CROSS REFERENCE TO RELATED APPLICATIONS </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> (Not Applicable) </paragraph>
</section>
<section>
<heading lvl="1">STATEMENT REGARDING FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> (Not Applicable) </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 1. Technical Field </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> The present invention relates to the field of online voice response systems and more particular to speech user interfaces for use with online voice response systems. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Speech systems are systems which can process speech both as input and output. Speech input can be processed into computer recognizable text through well-known speech recognition technology. Similarly, speech output can be generated through well-known speech synthesis technology. One type of speech system, the online voice processing system, has become widespread in recent years. Online voice processing systems are data processing systems which can process speech input and provide audio output, both through an audio user interface. Typical online voice processing systems are deployed in a telephony setting where users interact with the online voice processing system through the use of a telephone. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Generally, online voice processing systems can provide speech prompts to a user as required by the data processing system by speech synthesizing text and transmitting the speech synthesized text over a public switched telephone network (PSTN) to the user. Notwithstanding, online voice processing systems are not limited to use over a PSTN and other online voice processing systems have been integrated with packet switched network voice transport technology, such as Voice over IP (VolP) technology. In any case, users can respond to online voice processing system speech prompts by &ldquo;speaking&rdquo; to the online voice processing system over the PSTN. Online voice processing systems can speech recognize user speech thereby producing speech recognized text which can be processed by the data processing system. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Oftentimes, online voice processing systems prompt users with a list of menu choices. For example, in an online voice processing system for use with a library catalog data processing system, users can be prompted with lists of books which satisfy a searching criteria such as &ldquo;Fiction&rdquo; or &ldquo;Sports&rdquo;. Human memory limitations can limit the effectiveness of such an online voice processing system, however, where lists include many entries. For example, where the resulting list of books exceeds a dozen entries, in most cases users will not recall each item included in the list. Accordingly, what is needed is a method for compressing the presentation of lengthy lists in an online voice processing system to facilitate selection of list items by users. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> The present invention solves the problem of presenting items in a list through a speech user interface by providing a compressed list presentation system, apparatus and method which overcomes the deficiencies of the prior art. In particular, the present invention can include a method for automatically compressing the presentation of lengthy lists in an interactive voice response system in order to facilitate the selection of list items by users. Specifically, a list presentation method in accordance with the inventive arrangements can include the steps of: grouping selected items in a list based on sequentially positioned symbols in the items which are common to one another; labeling each group of selected items; audibly presenting each group label through a speech user interface; and, responsive to a selection of one of the presented group labels, presenting through the speech user interface items in a group corresponding to the selected group label. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> In one aspect of the present invention, the grouping step can include the steps of: parsing a list of items into component symbols; identifying among the items in the list, sequentially positioned component symbols which are common as between at least two of the items; and, associating in a group the at least two items. Additionally, the labeling step can include the steps of: forming a label based on the sequentially positioned component symbols which are common as between the at least two of the items; and, assigning the formed label to the association. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> In another aspect of the present invention, the grouping step can include the steps of: sorting the list alphabetically based on initial symbols in the items in the list; further sorting the list alphabetically based on subsequent sequentially encountered symbols in the items in the list; and, forming groups based the initial and subsequent sequentially encountered symbols in the items in the list which are common as between at least two of the items. Additionally, the method can include the step of ignoring article symbols when performing the sorting steps. Finally, the labeling step can include the step of forming a label comprising the initial and subsequent sequentially encountered symbols in the items in the list which are common as between at least two of the items. Importantly, the method can be applied recursively to groups of items. In particular, if any group produced by the method contains too many items, the method can be re-applied to the group to reduce the size of the group. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> A list presentation system in accordance with the inventive arrangements can include: grouping component for grouping selected items in a list based on sequentially positioned symbols in the items which are common to one another; a group labler for labeling each group of selected items; and, a presentation component for audibly presenting through a speech user interface each group label and items in a group corresponding to a selected group label. The grouping component can include: a parser for parsing a list of items into component symbols; a comparator for identifying among items in a parsed list, sequentially positioned component symbols which are common as between at least two of the items; and, an associator for associating in a group the at least two items. Alternatively, the grouping component can include: a sorter for sorting a list of items alphabetically both based on initial symbols in the items in the list and based on subsequent sequentially encountered symbols in the items in the list; and, an associator for associating in a group items in the sorted list having common initial and subsequent sequentially encountered symbols. Finally, the list presentation system can include a symbol exclusion component for preventing the sorter from considering symbols such as articles when sorting a list of items. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> There are presently shown in the drawings embodiments which are presently preferred, it being understood, however, that the invention is not limited to the precise arrangements and instrumentalities shown. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> FIGS. <highlight><bold>1</bold></highlight>A-<highlight><bold>1</bold></highlight>F, taken together, are a pictorial drawing illustrating a compressed list presentation method and system in accordance with the inventive arrangements. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flow chart illustrating a list presentation method configured in accordance with one aspect of the present invention. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a grouping method for use with the list presentation method of <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> The present invention is a compressed list presentation system, method and apparatus for use with a speech user interface. The present invention can efficiently process a list of items to be presented to a user through a speech user interface. Unlike prior art speech user interface list presentation methods which non-dynamically present each item in a list to a user, the present invention intelligently and dynamically groups selected list items, formulates a group label for each group and presents the group labels to the user through the speech user interface. Subsequently, the list items in the group are presented to the user through the speech user interface only when the user selects a particular group by specifying a corresponding group label. In this way, users are presented with shorter, compressed lists through the speech user interface which enhances the usability of a speech system which incorporates the present invention. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> FIGS. <highlight><bold>1</bold></highlight>A-<highlight><bold>1</bold></highlight>F, taken together, collectively illustrate a list presentation system and method in accordance with the inventive arrangements. In <cross-reference target="DRAWINGS">FIG. 1A, a</cross-reference> user <highlight><bold>102</bold></highlight> interacts with a speech system which includes a speech server <highlight><bold>112</bold></highlight> and a back-end data processing system <highlight><bold>114</bold></highlight> communicatively linked to one another through packet-switched network <highlight><bold>110</bold></highlight>. Notably, though shown in FIGS. <highlight><bold>1</bold></highlight>A-<highlight><bold>1</bold></highlight>F as the &ldquo;Internet&rdquo;, the invention is not limited in this regard and any network topology can suffice, for example a private local area network. Moreover, the invention can be performed in a stand-alone or in an embedded system. In any case, the back-end data processing system <highlight><bold>114</bold></highlight> can include one or more databases in which data can be stored for use by the data processing system <highlight><bold>114</bold></highlight>. User <highlight><bold>102</bold></highlight> can interact with the speech system using a conventional telephone handset <highlight><bold>104</bold></highlight> over a public switched telephone network (PSTN) <highlight><bold>106</bold></highlight>. Notably, telephony gateway <highlight><bold>108</bold></highlight> can bridge communications between the packet-switched network <highlight><bold>110</bold></highlight> and the PSTN <highlight><bold>106</bold></highlight>. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In operation, user <highlight><bold>102</bold></highlight> can establish a connection with the speech server <highlight><bold>112</bold></highlight> over the PSTN <highlight><bold>106</bold></highlight>. Specifically, the telephony gateway <highlight><bold>108</bold></highlight> can configure a telephone call originating from the user <highlight><bold>102</bold></highlight> and maintain the call as necessary. Moreover, the telephony gateway <highlight><bold>108</bold></highlight> both can forward data received over the PSTN <highlight><bold>106</bold></highlight> to devices in the packet-switched network <highlight><bold>110</bold></highlight>, and can forward data received over the packet-switched network <highlight><bold>110</bold></highlight> to nodes in the PSTN <highlight><bold>106</bold></highlight>. As will be apparent to one skilled in the art, telephony gateways are conventional devices well-known in the art and typically are used for establishing and maintaining telephone calls between a PSTN-based node and a packet-switched network-based device. Moreover, alternative gateway configurations are possible for instance a gatekeeper can be provided to perform call maintenance where the gateway digitizes and packetizes audio streams. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>A, the speech system can prompt the user <highlight><bold>102</bold></highlight> for information. For example, the speech system can be library catalog system and the speech server <highlight><bold>112</bold></highlight> can prompt the user <highlight><bold>102</bold></highlight> to request a topic for which the data processing system <highlight><bold>114</bold></highlight> can search the database <highlight><bold>116</bold></highlight>. Specifically, the speech server <highlight><bold>112</bold></highlight> can generate a speech synthesized prompt and transmit the prompt over the network <highlight><bold>110</bold></highlight> to the telephony gateway <highlight><bold>108</bold></highlight>. The telephony gateway <highlight><bold>108</bold></highlight>, in turn, can transmit the prompt over the PSTN <highlight><bold>106</bold></highlight> to the user <highlight><bold>102</bold></highlight> via handset <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The user can respond to the prompt by requesting that the speech server query the data processing system for all items relating to &ldquo;Usability&rdquo; as shown in <cross-reference target="DRAWINGS">FIG. 1B</cross-reference>. The speech request can be transmitted over the PSTN <highlight><bold>106</bold></highlight> to the telephony gateway <highlight><bold>108</bold></highlight> which can digitize and packetize the speech audio request. The telephony gateway <highlight><bold>108</bold></highlight> can forward the packetized speech audio request over the packet-switched network <highlight><bold>110</bold></highlight> to speech server <highlight><bold>112</bold></highlight> which can perform speech recognition operations on the received speech audio data. Once converted to computer recognizable text, the user&apos;s request can be forwarded to the back-end data processing system <highlight><bold>114</bold></highlight> which can process the user&apos;s request by querying the database <highlight><bold>116</bold></highlight>. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>C, the database <highlight><bold>116</bold></highlight> can respond by providing a result set in the form of a full list <highlight><bold>120</bold></highlight> which includes all items which match the query terms provided by the user <highlight><bold>102</bold></highlight>. In the exemplary case, the full list <highlight><bold>120</bold></highlight> can include all topics relating to &ldquo;Usability&rdquo;. An exemplary full list <highlight><bold>120</bold></highlight> is shown in Appendix A. The full list <highlight><bold>120</bold></highlight> can be extensive and can include numerous entries which, in the absence of the present invention, would be difficult to present through a speech user interface. Thus, in accordance with the inventive arrangements, the full list <highlight><bold>120</bold></highlight> can be processed by a list presentation system <highlight><bold>118</bold></highlight> referred to hereinafter as a compressed list processor (CLP). </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> The CLP <highlight><bold>118</bold></highlight> can group selected items in the full list <highlight><bold>120</bold></highlight> based on symbols found to be common among the selected items. Symbols can include graphic elements, words, numbers and other characters or combination of characters. In one aspect of the invention, the CLP <highlight><bold>118</bold></highlight> can identify words which are common between items in the full list <highlight><bold>120</bold></highlight>. Based on these common words, a sub-set of groups can be generated for which group labels <highlight><bold>122</bold></highlight> can be created. In particular, the group labels can include the common words which are identified for each group. An exemplary set of group labels is shown in Appendix B. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Notwithstanding, the invention is not limited in this regard and other methods of generating a group label can suffice, for instance, meta-data associated with the items in the group can be used to determine an appropriate group label. In any case, once the group labels <highlight><bold>122</bold></highlight> have been created, the group labels can be speech synthesized by the speech server <highlight><bold>112</bold></highlight> and provided over the network <highlight><bold>110</bold></highlight> to the telephony gateway <highlight><bold>108</bold></highlight>. From the telephony gateway <highlight><bold>108</bold></highlight>, the group labels can be presented to the user <highlight><bold>102</bold></highlight> over the PSTN <highlight><bold>106</bold></highlight> via the handset <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>D, from the presented group labels <highlight><bold>122</bold></highlight>, the user <highlight><bold>102</bold></highlight> can select a particular group label by speaking the group label itself, though the invention is not limited in regard to the particular method of selecting a group label. Turning to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>E, once selected, the CLP <highlight><bold>118</bold></highlight> can generate a list of items <highlight><bold>124</bold></highlight> in the selected group. As in the case of the group labels <highlight><bold>122</bold></highlight>, can be speech synthesized in the speech server <highlight><bold>112</bold></highlight> and provided to the telephony gateway <highlight><bold>108</bold></highlight> over the network <highlight><bold>110</bold></highlight>. Hence, in the example shown, if the user had selected from among the group labels, &ldquo;Human Factors&rdquo;, a list of items in the Human Factors group (shown in Appendix C) can be provided to the user <highlight><bold>102</bold></highlight> via the PSTN <highlight><bold>106</bold></highlight> and telephone handset <highlight><bold>104</bold></highlight>. Finally, as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>F, the user <highlight><bold>102</bold></highlight> can select an item from among the list of items <highlight><bold>124</bold></highlight>, for example &ldquo;Human Factors in Product Design&rdquo;. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flow chart illustrating a list presentation method <highlight><bold>200</bold></highlight> which can be performed by the CLP <highlight><bold>118</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. Beginning in step <highlight><bold>202</bold></highlight>, a query can be performed which can return a full list of query result items in step <highlight><bold>204</bold></highlight>. In step <highlight><bold>206</bold></highlight>, the items can be grouped and in step <highlight><bold>208</bold></highlight>, group labels can be created for each group. In step <highlight><bold>210</bold></highlight>, the group labels can be presented to a user through a speech user interface. In step <highlight><bold>212</bold></highlight>, the user can select a particular group label. In response, in step <highlight><bold>214</bold></highlight>, items included in a group associated with the selected group label can be presented to the user through the speech user interface. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> Importantly, the grouping aspect of the list presentation method <highlight><bold>200</bold></highlight> can facilitate the presentation of list items to a user through a speech user interface in a manner not previously possible in conventional speech systems. <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a flow chart which illustrates one possible method of grouping items in a list. In reference to FIGS. <highlight><bold>1</bold></highlight>A-<highlight><bold>1</bold></highlight>F, a grouping method <highlight><bold>300</bold></highlight> can be performed in the CLP <highlight><bold>118</bold></highlight> and can begin in step <highlight><bold>302</bold></highlight> when a full list <highlight><bold>120</bold></highlight> is received. Specifically, in step <highlight><bold>302</bold></highlight>, the full list <highlight><bold>120</bold></highlight> can be sorted, for instance alphabetically by first symbol. As before, symbol can refer not only to word, but also character, group of characters or graphical indicia. In step <highlight><bold>304</bold></highlight>, the first two items in the full list <highlight><bold>120</bold></highlight> can be loaded. Subsequently, in step <highlight><bold>306</bold></highlight>, the first two symbols can be loaded. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> In step <highlight><bold>308</bold></highlight>, grammatical articles can be detected among the two symbols and, if detected, in step <highlight><bold>310</bold></highlight>, the articles can be skipped. In this way, symbols which have little contextual meaning such as &ldquo;the&rdquo;, &ldquo;a&rdquo; and the like can be excluded from the grouping process. In step <highlight><bold>312</bold></highlight>, the symbols can be compared to one another. In step <highlight><bold>314</bold></highlight>, if a match is detected, in step <highlight><bold>316</bold></highlight> the items can be grouped together. If not match is detected, in step <highlight><bold>318</bold></highlight>, a new group can be created. In any case, in step <highlight><bold>320</bold></highlight> if more items remain in the full list <highlight><bold>120</bold></highlight>, the next item in the list can be loaded to be compared to the previous item in the list. Subsequently, the process can repeat until no items remain in which the case grouping method can terminate in step <highlight><bold>324</bold></highlight>. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Notably, the method is neither limited to initially loading the first two words nor the first two items in the list. Also, the invention is not limited to sorting alphabetically. Rather, sorting alphabetically can facilitate the grouping process, but failure to sort will not prevent an effective grouping. In fact other grouping methods, such as dynamically identifying common symbols in each list item by parsing individual items and storing the parsed symbols for subsequent comparison can suffice. Still, sorting alphabetically by first word and sequentially comparing words in two items can facilitate the identification of common words from a processing efficiency standpoint. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> The present invention can be realized in hardware, software, or a combination of hardware and software. Moreover, the present invention can be realized in a centralized fashion in one computer system, or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system&mdash;or other apparatus adapted for carrying out the methods described herein&mdash;is suited. A typical combination of hardware and software could be a general purpose computer system with a computer program that, when being loaded and executed, controls the computer system such that it carries out the methods described herein. The present invention can also be embedded in a computer program product, which comprises all the features enabling the implementation of the methods described herein, and which when loaded in a computer system is able to carry out these methods. Computer program means or computer program in the present context means any expression, in any language, code or notation, of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a) conversion to another language, code or notation; b) reproduction in a different material form. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Significantly, this invention can be embodied in other specific forms without departing from the spirit or essential attributes thereof, and accordingly, reference should be had to the following claims, rather than to the foregoing specification, as indicating the scope of the invention. </paragraph>
</section>
<section>
<heading lvl="1">APPENDIX A </heading>
<paragraph id="P-0032" lvl="1"><number>&lsqb;0032&rsqb;</number> Ergonomics for Beginners </paragraph>
<paragraph id="P-0033" lvl="1"><number>&lsqb;0033&rsqb;</number> Ergonomics in Computerized Offices </paragraph>
<paragraph id="P-0034" lvl="1"><number>&lsqb;0034&rsqb;</number> Ergonomics: Advanced Methods </paragraph>
<paragraph id="P-0035" lvl="1"><number>&lsqb;0035&rsqb;</number> The Ergonomics of Working Postures </paragraph>
<paragraph id="P-0036" lvl="1"><number>&lsqb;0036&rsqb;</number> The Ergonomics of Workspaces and Machines </paragraph>
<paragraph id="P-0037" lvl="1"><number>&lsqb;0037&rsqb;</number> Fitting the Task to the Human </paragraph>
<paragraph id="P-0038" lvl="1"><number>&lsqb;0038&rsqb;</number> A Handbook of Work and Organizational Psychology </paragraph>
<paragraph id="P-0039" lvl="1"><number>&lsqb;0039&rsqb;</number> Handbook of Control Design and Ergonomics </paragraph>
<paragraph id="P-0040" lvl="1"><number>&lsqb;0040&rsqb;</number> Handbook of Human Factors and Ergonomic </paragraph>
<paragraph id="P-0041" lvl="1"><number>&lsqb;0041&rsqb;</number> Handbook of Human-Computer Interaction </paragraph>
<paragraph id="P-0042" lvl="1"><number>&lsqb;0042&rsqb;</number> Handbook of Manual Materials Handling </paragraph>
<paragraph id="P-0043" lvl="1"><number>&lsqb;0043&rsqb;</number> Human Factors and Speech Technology </paragraph>
<paragraph id="P-0044" lvl="1"><number>&lsqb;0044&rsqb;</number> Human Factors in Air Traffic Control </paragraph>
<paragraph id="P-0045" lvl="1"><number>&lsqb;0045&rsqb;</number> Human Factors in Consumer Products </paragraph>
<paragraph id="P-0046" lvl="1"><number>&lsqb;0046&rsqb;</number> Human Factors in Nuclear Safety </paragraph>
<paragraph id="P-0047" lvl="1"><number>&lsqb;0047&rsqb;</number> Human Factors in Product Design </paragraph>
<paragraph id="P-0048" lvl="1"><number>&lsqb;0048&rsqb;</number> The Human Factors of Alarm Design </paragraph>
<paragraph id="P-0049" lvl="1"><number>&lsqb;0049&rsqb;</number> Risk </paragraph>
<paragraph id="P-0050" lvl="1"><number>&lsqb;0050&rsqb;</number> Risk Analysis for Process Plant, Pipelines and Transport </paragraph>
<paragraph id="P-0051" lvl="1"><number>&lsqb;0051&rsqb;</number> Risk Analysis in Project Management </paragraph>
<paragraph id="P-0052" lvl="1"><number>&lsqb;0052&rsqb;</number> Risk and Misfortune </paragraph>
<paragraph id="P-0053" lvl="1"><number>&lsqb;0053&rsqb;</number> Risk Management </paragraph>
<paragraph id="P-0054" lvl="1"><number>&lsqb;0054&rsqb;</number> Usability Evaluation by Questionnaire </paragraph>
<paragraph id="P-0055" lvl="1"><number>&lsqb;0055&rsqb;</number> Usability Evaluation in Industry </paragraph>
<paragraph id="P-0056" lvl="1"><number>&lsqb;0056&rsqb;</number> Work and Aging </paragraph>
<paragraph id="P-0057" lvl="1"><number>&lsqb;0057&rsqb;</number> Work and Health </paragraph>
<paragraph id="P-0058" lvl="1"><number>&lsqb;0058&rsqb;</number> Work and Technology </paragraph>
<paragraph id="P-0059" lvl="1"><number>&lsqb;0059&rsqb;</number> Work Designs in Practice </paragraph>
<paragraph id="P-0060" lvl="1"><number>&lsqb;0060&rsqb;</number> Work Fitness </paragraph>
<paragraph id="P-0061" lvl="1"><number>&lsqb;0061&rsqb;</number> Work Rules </paragraph>
<paragraph id="P-0062" lvl="1"><number>&lsqb;0062&rsqb;</number> Work-Related Musculoskeletal Disorders </paragraph>
</section>
<section>
<heading lvl="1">APPENDIX B </heading>
<paragraph id="P-0063" lvl="1"><number>&lsqb;0063&rsqb;</number> Ergonomics </paragraph>
<paragraph id="P-0064" lvl="1"><number>&lsqb;0064&rsqb;</number> Fitting the Task to the Human </paragraph>
<paragraph id="P-0065" lvl="1"><number>&lsqb;0065&rsqb;</number> Handbook </paragraph>
<paragraph id="P-0066" lvl="1"><number>&lsqb;0066&rsqb;</number> Human Factors </paragraph>
<paragraph id="P-0067" lvl="1"><number>&lsqb;0067&rsqb;</number> Risk </paragraph>
<paragraph id="P-0068" lvl="1"><number>&lsqb;0068&rsqb;</number> Usability Evaluatoin </paragraph>
<paragraph id="P-0069" lvl="1"><number>&lsqb;0069&rsqb;</number> Work </paragraph>
</section>
<section>
<heading lvl="1">APPENDIX C </heading>
<paragraph id="P-0070" lvl="1"><number>&lsqb;0070&rsqb;</number> Human Factors and Speech Technology </paragraph>
<paragraph id="P-0071" lvl="1"><number>&lsqb;0071&rsqb;</number> Human Factors in Air Traffic Control </paragraph>
<paragraph id="P-0072" lvl="1"><number>&lsqb;0072&rsqb;</number> Human Factors in Consumer Products </paragraph>
<paragraph id="P-0073" lvl="1"><number>&lsqb;0073&rsqb;</number> Human Factors in Nuclear Safety </paragraph>
<paragraph id="P-0074" lvl="1"><number>&lsqb;0074&rsqb;</number> Human Factors in Product Design </paragraph>
<paragraph id="P-0075" lvl="1"><number>&lsqb;0075&rsqb;</number> The Human Factors of Alarm Design </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A list presentation method comprising the steps of: 
<claim-text>dynamically grouping selected items in a list based on sequentially positioned symbols in said items which are common to one another; labeling each group of selected items; </claim-text>
<claim-text>audibly presenting each group label through a speech user interface; and, responsive to a selection of one of said audibly presented group labels, presenting through said speech user interface items in a group corresponding to said selected group label. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The list presentation method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the grouping step comprises the steps of: 
<claim-text>parsing a list of items into component symbols; </claim-text>
<claim-text>identifying among said parsed items sequentially positioned component symbols which are common as between at least two of said items; and, </claim-text>
<claim-text>associating in a group said at least two items having said identified component symbols in common. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The list presentation method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the labeling step comprises the steps of: 
<claim-text>forming a label based on said sequentially positioned component symbols which are common as between said at least two of said items; and, </claim-text>
<claim-text>assigning said formed label to said association. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The list presentation method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the grouping step comprises the step of: 
<claim-text>sorting said list alphabetically based on initial symbols in said items in said list; </claim-text>
<claim-text>further sorting said list alphabetically based on subsequent sequentially encountered symbols in said items in said list; and, </claim-text>
<claim-text>forming groups based said initial and subsequent sequentially encountered symbols in said items in said list which are common as between at least two of said items. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The list presentation method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, further comprising the step of ignoring article symbols when performing said sorting steps. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The list presentation method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein the labeling step comprises the step of forming a label comprising said initial and subsequent sequentially encountered symbols in said items in said list which are common as between at least two of said items. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A list presentation system comprising: 
<claim-text>a grouping component for grouping selected items in a list based on sequentially positioned symbols in said items which are common to one another; </claim-text>
<claim-text>a group labler for labeling each group of selected items; and, </claim-text>
<claim-text>a presentation component for audibly presenting through a speech user interface each group label and items in a group corresponding to a selected group label. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The list presentation system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein said grouping component comprises: 
<claim-text>a parser for parsing a list of items into component symbols; </claim-text>
<claim-text>a comparator for identifying among items in a parsed list, sequentially postioned component symbols which are common as between at least two of said items; and, </claim-text>
<claim-text>an associator for associating in a group said at least two items. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The list presentation system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein said grouping component comprises: 
<claim-text>a sorter for sorting a list of items alphabetically both based on initial symbols in said items in said list and based on subsequent sequentially encountered symbols in said items in said list; and, </claim-text>
<claim-text>an associator for associating in a group items in said sorted list having common initial and subsequent sequentially encountered symbols. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The list presentation system of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, further comprising a symbol exclusion component for preventing said sorter from considering selected symbols when sorting a list of items. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. An machine readable storage having stored thereon a computer program having a plurality of code sections executable by a machine for causing the machine to perform the steps of: 
<claim-text>grouping selected items in a list based on sequentially positioned symbols in said items which are common to one another; </claim-text>
<claim-text>labeling each group of selected items; </claim-text>
<claim-text>audibly presenting each group label through a speech user interface; and, responsive to a selection of one of said audibly presented group labels, presenting through said speech user interface items in a group corresponding to said selected group label. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The machine readable storage of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the grouping step comprises the steps of: 
<claim-text>parsing a list of items into component symbols; </claim-text>
<claim-text>identifying among said parsed items sequentially positioned component symbols which are common as between at least two of said items; and, </claim-text>
<claim-text>associating in a group said at least two items having said identified component symbols in common. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The machine readable storage of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein the labeling step comprises the steps of: 
<claim-text>forming a label based on said sequentially positioned component symbols which are common as between said at least two of said items; and, </claim-text>
<claim-text>assigning said formed label to said association. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The machine readable storage of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the grouping step comprises the step of: 
<claim-text>sorting said list alphabetically based on initial symbols in said items in said list; </claim-text>
<claim-text>further sorting said list alphabetically based on subsequent sequentially encountered symbols in said items in said list; and, </claim-text>
<claim-text>forming groups based said initial and subsequent sequentially encountered symbols in said items in said list which are common as between at least two of said items. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The machine readable storage of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, further comprising the step of ignoring article symbols when performing said sorting steps. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The machine readable storage of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein the labeling step comprises the step of forming a label comprising said initial and subsequent sequentially encountered symbols in said items in said list which are common as between at least two of said items.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>2</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004725A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004725A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004725A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004725A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004725A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
