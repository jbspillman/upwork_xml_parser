<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005225A1-20030102-D00000.TIF SYSTEM "US20030005225A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005225A1-20030102-D00001.TIF SYSTEM "US20030005225A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005225A1-20030102-D00002.TIF SYSTEM "US20030005225A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005225A1-20030102-D00003.TIF SYSTEM "US20030005225A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005225A1-20030102-D00004.TIF SYSTEM "US20030005225A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005225A1-20030102-D00005.TIF SYSTEM "US20030005225A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030005225A1-20030102-D00006.TIF SYSTEM "US20030005225A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030005225A1-20030102-D00007.TIF SYSTEM "US20030005225A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030005225A1-20030102-D00008.TIF SYSTEM "US20030005225A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030005225A1-20030102-D00009.TIF SYSTEM "US20030005225A1-20030102-D00009.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005225</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09894638</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010627</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F013/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>711</class>
<subclass>119000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Cache architecture with redundant sub array</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Kenneth</given-name>
<middle-name>R.</middle-name>
<family-name>Smits</family-name>
</name>
<residence>
<residence-us>
<city>San Ramon</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<assignee>
<organization-name>Intel Corporation</organization-name>
<address>
<address-1>2200 Mission College Boulevard</address-1>
<city>Santa Clara</city>
<state>CA</state>
<postalcode>95052</postalcode>
</address>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>Bradley J. Bereznak</name-1>
<name-2>Blakely, Sokoloff, Taylor &amp; Zafman LLP</name-2>
<address>
<address-1>Seventh Floor</address-1>
<address-2>12400 Wilshire Boulevard</address-2>
<city>Los Angeles</city>
<state>CA</state>
<postalcode>90025-1030</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Architecture for a cache fabricated on a die with a processor including a plurality of cache banks, each containing a plurality of memory cell sub arrays. The sub arrays including a plurality of arrays of memory cells, the arrays including regular arrays and at least one redundant sub array. Logic circuitry is associated with each cache bank. A change in a single bit of the logic circuitry from a first to a second logic state causes one of the regular arrays to become disconnected from the global data bus, and the redundant array to become connected to the global data bus. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">RELATED APPLICATIONS </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application is related to Ser. No. ______ filed ______, entitled &ldquo;ON-DIE CACHE MEMORY WITH REPEATERS&rdquo; and Ser. No. ______ filed ______, entitled &ldquo;CACHE ARCHITECTURE FOR PIPELINED OPERATION WITH ON-DIE PROCESSOR&rdquo;, both of which are assigned to the assignee of the present application.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates generally to the field of very large-scale integrated circuits fabricated on a single semiconductor die or chip. More particularly, the invention relates to the field of high-performance cache memories. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> Cache memories have been used to maximize processor performance, while maintaining reasonable system costs, for many years. A cache memory is a very fast buffer comprising an array of local storage cells that is used by a processor to hold frequently requested copies of data. A typical cache memory system comprises a hierarchy of memory structures, which usually includes a local (L1), on-chip cache that represents the first level in the hierarchy. A secondary (L2) cache is often associated with the processor for providing an intermediate level of cache memory between the processor and main memory. Main memory, also commonly referred to as system or bulk memory, lies at the bottom (i.e., slowest, largest) level of the memory hierarchy. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> In a conventional computer system, a processor is coupled to a system bus that provides access to main memory. An additional backside bus may be utilized to couple the processor to a L2 cache memory. Other system architectures may couple the L2 cache memory to the system bus via its own dedicated bus. Most often, L2 cache memory comprises a static random access memory (SRAM) that includes a data array, a cache directory, and cache management logic. The cache directory usually includes a tag array, tag status bits, and least recently used (LRU) bits. (Each directory entry is called a &ldquo;tag&rdquo;.) The tag RAM contains the main memory addresses of code and data stored in the data cache RAM plus additional status bits used by the cache management logic. By way of background, U.S. Pat. No. 6,115,795 discloses a computer system comprising a processor that includes second level cache controller logic for use in conjunction with an external second level cache memory. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Recent advances in semiconductor processing technology have made possible the fabrication of large L2 cache memories on the same die as the processor core. As device and circuit features continue to shrink as the technology improves, researchers have begun proposing designs that integrate a very large (e.g., multiple megabytes) third level (L3) cache memory on the same die as the processor core for improved data processing performance. While such a high level of integration is desirable from the standpoint of achieving high-speed performance, there are still difficulties that must be overcome. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Large on-die cache memories are typically subdivided into multiple cache memory banks, which are then coupled to a wide (e.g., 32 bytes, 256 bits wide) data bus. For instance, U.S. Pat. Nos. 5,752,260 and 5,818,785 teach interleaved cache memory devices having a plurality of banks consisting of memory cell arrays. In a very large cache memory comprising multiple banks, one problem that arises is the large RC signal delay associated with the long bus lines when driven at a high clock rate (e.g., 1 GHz). Thus, there is a need for some sort of repeater device to connect each bank of cache memory to the data bus without loss of signal integrity. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> One traditional method for sharing a bus is to have each circuit utilize a tri-state driver in order to connect to the bus. Tri-state driver devices are well known in the prior art. A conventional tri-state driver comprises two transistor devices coupled in series to pull the output to either a high or low logic level. The third output state is a high impedance (i.e., inactive) state. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> When a tri-state driver is utilized to connect to a bus, the two series-connected output devices of the driver need to be large so as to provide adequate drive strength to the long bus wire. This requirement, however, makes it difficult to use tri-state drivers as repeaters in a multi-megabyte on-die cache memory because the large source/drain diode of the output devices adds considerable load to the bus. The additional load attributable to the tri-state drivers increases bus power and causes significant resistive/capacitive (RC) signal delay. Another drawback of using tri-state drivers as repeaters is the need for decoding circuitry for the drivers. This decoding circuitry is in addition to the decoding circuitry already required for the cache memory banks. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> The requirement of sharing the data bus between banks in a large cache memory also creates timing difficulties. The sub arrays within a bank may be placed close enough such that the individual bits of the bus will have about the same timing. However, the cache banks themselves are often located at various physical distances from the receiver or central location on the die that provides a point for information transfer to the processor core. This means that the relative signal timing of data to/from each bank may be very different. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> For example, one bank may be located far from the core (or some central location on the die that provides a point for information transfer between the processor and the cache) whereas another bank may be located adjacent to the core. The farther bank would incur a significant signal delay due to the RC nature of the metal lines whereas the nearer bank would not. In other words, some data bits travel a long distance and have a long delay, while other data bits travel a short distance and have a short delay to reach the receiver. At high processor speeds and with very large cache sizes, it can take one or more clock cycles for the bits that are farthest away to arrive at the receiver relative to the bits that are closest. That is, even though data is sent/received synchronously with the clock, the RC delay of the long metal lines prevents the data signals from traversing the distance between a bank and the core in a single clock cycle. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> Very large on-die caches also present further difficulties in the implementation of redundant storage elements. In traditional cache designs with redundancy, the redundant array element is read at the same time all the other array elements are read. The selection of which bits are output from the cache is typically controlled through multiplexing. When an array element fails, fuses on the chip are usually blown in order to decode the defective bits out and replace them with the redundant element. The drawback of this approach is that if the cache is very large, the multiplexing problem is huge. For example, if the cache outputs 256 bits, then the redundant element has to have multiplexing connections to be able to feed the data to any one of those 256 bits. Naturally, a huge overhead problem is created by such connections. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> Therefore, what is needed is a cache architecture that overcomes the shortcomings of the prior art in the design of a very large, on-die cache memory operating with a high-speed processor core. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The present invention will be understood more fully from the detailed description that follows and from the accompanying drawings, which however, should not be taken to limit the invention to the specific embodiments shown, but are for explanation and understanding only. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a logic diagram of a repeater circuit utilized in one embodiment of the present invention. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a circuit schematic diagram of a cache memory according to one embodiment of the present invention. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a logic diagram of another repeater circuit utilized in a particular embodiment of the present invention. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a block diagram illustrating one embodiment of the cache architecture of the present invention. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is an example of a chip floorplan for a processor that includes an on-die L3 cache. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is an example of sub array busing according to one embodiment of the present invention. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a logic diagram of one implementation of a decoding scheme for use with the sub array busing shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 8A &amp; 8B</cross-reference> illustrate an example of the use of a redundant sub array according to one embodiment of the present invention. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 9A &amp; 9B</cross-reference> illustrate another example of the use of a redundant sub array according to one embodiment of the present invention. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a circuit schematic diagram of a fuse circuit for use with the decoding logic shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Architecture for a cache fabricated on a die with a processor is described. In the following description, numerous details are set forth, such as specific circuit configurations, logic device types, numerical values, etc., in order to provide a thorough understanding of the invention. It will be clear, however, to one skilled in the art, that these specific details may not be needed to practice the present invention. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> In typical cache memory storage arrays that are organized into banks, when one bank is active, it drives a global data bus. All of the bit signal lines of the data bus are usually received at some central location on the die. From there the information is transmitted to the processor core. (In the context of the present application, the term &ldquo;central location&rdquo; is intended to have a broad meaning. The term may be construed to include the processor core itself, a receiver device, a set of buffers or latches, or simply a point on the die where the signal lines are coupled to the core. Additionally, the term &ldquo;central location&rdquo; is not limited to any particular area, such as the center, of the die; for example, it may refer to a set of connections or points distributed along the periphery of a circuit or region of the core.) </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Because of the high frequencies that signals are driven at, and the thinner metal traces that are printed on the die using modern processing techniques, there is a need to repeat or rejuvenate the signal every so often. For example, in state-of-the-art semiconductor processing technology a transmitted signal usually needs to be repeated every 1500 microns or so of metal trace. Without some means of rejuvenating or repeating the signal, the RC delay associated with a long bus line operating at high frequency would result in loss of data. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> According to one embodiment of the present invention, each bit of the cache memory bank is connected to a repeater that comprises logic that overcomes the drawbacks associated with the conventional use of tri-state buffers. In one particular implementation, the repeater comprises a single logic gate that drives an inverter. If a bank in the memory is unselected, its output is precharged so that it does not drive the bus. In this manner, when the bank connected to the logic gate is selected, the data stored in the cache array is transmitted through the combinatorial logic structure. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> With reference to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, there is shown a circuit diagram in which repeater <highlight><bold>10</bold></highlight> is connected in series with data bus <highlight><bold>13</bold></highlight>. Repeater <highlight><bold>10</bold></highlight> comprises a 2-input NAND gate <highlight><bold>11</bold></highlight> having an output connected to the input of an inverter <highlight><bold>12</bold></highlight>. One of the inputs of gate <highlight><bold>11</bold></highlight> is coupled to data bus <highlight><bold>13</bold></highlight>, and the other input is coupled to receive data output from the sub array of an associated cache bank (in this example bank B<highlight><subscript>0</subscript></highlight>). The output of inverter <highlight><bold>12</bold></highlight> drives data bus <highlight><bold>13</bold></highlight>, which, in this example, is shown connected to another repeater comprising NAND gate <highlight><bold>14</bold></highlight> and inverter <highlight><bold>15</bold></highlight>, both associated with a corresponding sub array of bank B<highlight><subscript>1</subscript></highlight>. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> The use of the repeater structure shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> implies certain conventions be adopted in the cache memory architecture. One convention is that if the cache bank is unselected (i.e., inactive), the data output from the cache bank is held precharged (high). In the example of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the precharged state is a logical high potential (&equals;1). A logical high potential at one input of NAND gate <highlight><bold>11</bold></highlight> means that repeater <highlight><bold>10</bold></highlight> will allow whatever signal is present on data bus <highlight><bold>13</bold></highlight> to pass through the repeater structure unaltered. That is, data driven from any other cache bank in the memory is unaffected by an inactive cache bank. In this way, repeaters may be concatenated together along a data bus line, with individual repeaters being associated with corresponding sub arrays of each bank of cache memory storage. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Practitioners familiar with the data storage arts will also appreciate that the repeater structure of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> obviates the need for additional enable logic or enable pulses. This is made possible, in part, by the convention of precharging the output of the cache bank when the bank is inactive, and also by assigning a default logic value to the data bus itself. Note that in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, data bus line <highlight><bold>13</bold></highlight> is initially coupled to a logical high potential (e.g., V<highlight><subscript>CC</subscript></highlight>). In other words, the first segment of data bus <highlight><bold>13</bold></highlight> that is provided as one of the inputs to NAND gate <highlight><bold>11</bold></highlight> of the first cache bank (B<highlight><subscript>0</subscript></highlight>) is driven by the positive supply potential of the integrated circuit. Thus, a logical high potential is the default value assigned to the data bus in the cache memory architecture of the embodiment of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> All together, the combinatorial logic gate structure of repeater <highlight><bold>10</bold></highlight> and the convention of precharging the cache data output and assigning a default logic potential to the bus lines allows data to simply flow from cache bank to processor core, without concern about set-up and hold times. For instance, in the case where the data output from an active cache bank is a logical 1, it is already valid by the existing bus line state. The state of data bus line <highlight><bold>13</bold></highlight> only changes if the data value output from a given cache bank is a logical 0, in which case there is a propagation delay through all of the repeaters associated with each of the banks before the data on the bus becomes valid. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> It should be understood that there is no precharging of the data bus line itself; that is, there is no switching or clocking applied to the data bus. A scheme in which the data bus is switched or clocked periodically would require some sort of dynamic driver design, adding complexity, power, and cost. Instead, the repeater structure of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> may be advantageously implemented with simple combinatorial logic. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Another important advantage of the repeater structure shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is that the NAND logic gate <highlight><bold>11</bold></highlight> may be made relatively small, with the inverter <highlight><bold>12</bold></highlight> made relatively large to drive the next segment of the bus. This circuit construction has the benefit of providing increased speed and reduced power so that no additional repeaters are needed before the bus line reaches the next data bank in the cache memory. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Practitioners in the art will further appreciate that the approach of the present invention also provides another advantage when redundant sub arrays are employed. Each sub array in a block can have its own enable signal that is used to switch the sub array on or off the bus. In this manner, a sub array can be substituted for any other sub array with just the switching of an enable signal, leaving the bus itself unchanged. Hence, the repeater circuit of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> permits implementing a redundant sub array scheme without adversely impacting power or speed. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> With reference now to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, there is shown an alternative embodiment of a repeater circuit. The embodiment of <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is essentially the same as that shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> except that repeater <highlight><bold>20</bold></highlight> includes a NOR gate <highlight><bold>21</bold></highlight> instead of a NAND gate as the input logic device. The output of NOR gate <highlight><bold>21</bold></highlight> is coupled to inverter <highlight><bold>22</bold></highlight>, which, in turn, drives data bus <highlight><bold>23</bold></highlight>. As can be seen, repeater <highlight><bold>20</bold></highlight> is associated with cache bank B<highlight><subscript>0</subscript></highlight>, and is concatenated in series on the bus with a second repeater (associated with bank B<highlight><subscript>1</subscript></highlight>) comprising NOR gate <highlight><bold>24</bold></highlight> and inverter <highlight><bold>25</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Instead of being precharged to a logical high potential, the data output from all inactive cache banks are precharged to a logical low potential (&equals;0). Also, the default data bus logic level is a logical 0, e.g., V<highlight><subscript>SS</subscript></highlight>. Thus, when the data output from an active bank is logically low, the data on the bus is already valid. The only case in which there is a propagation delay through the repeaters before the data on the bus becomes valid is when a cache bank outputs a logical <highlight><bold>1</bold></highlight>. As discussed in connection with <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> cache organization implemented using the repeaters shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> has the advantage of permitting activation of redundant sub array elements with minimal overhead. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates a cache memory <highlight><bold>17</bold></highlight> organized into banks (B<highlight><subscript>0</subscript></highlight>-B<highlight><subscript>M</subscript></highlight>) with repeaters associated with corresponding sub arrays (A<highlight><subscript>0</subscript></highlight>-A<highlight><subscript>N</subscript></highlight>) of each bank in accordance to one embodiment of the present invention. By way of example, data from sub array A<highlight><subscript>0 </subscript></highlight>of each bank is selectively connected to one of the lines of bus <highlight><bold>18</bold></highlight> through repeaters <highlight><bold>10</bold></highlight>. In typical operation, only one of the banks of memory <highlight><bold>17</bold></highlight> is activated at a time, with the data from the sub arrays of that bank being transmitted onto bus <highlight><bold>18</bold></highlight> exclusively. For instance, bank B<highlight><subscript>2 </subscript></highlight>may be activated (with remaining banks B<highlight><subscript>0</subscript></highlight>-B<highlight><subscript>1 </subscript></highlight>and B<highlight><subscript>3</subscript></highlight>-B<highlight><subscript>M </subscript></highlight>inactive) in order to read data stored sub arrays A<highlight><subscript>0</subscript></highlight>-A<highlight><subscript>N </subscript></highlight>on bus <highlight><bold>18</bold></highlight>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> It should be appreciated that the repeater structure described above allows cache memory <highlight><bold>17</bold></highlight> to be easily configurable to any size as spaced allows on the die. Moreover, the solution offered by the present invention may be used on any cache memory. For example, current cache memory designs often use the way hit information to decode individual wordlines internal to the sub array. According to the prior art, if the size of the cache memory is changed and the number of ways changes, then the sub array must be redesigned to accommodate the new number of ways. In contrast, according to the present invention, the way hit may be used to select a bank. If the number of ways is changed, the bank is simply added or removed from the die. This approach is much easier and less disruptive to the die floorplan as compared to prior art schemes, and no edits to the sub arrays are required. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> With reference now to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, there is shown an example floorplan of a chip <highlight><bold>100</bold></highlight> having a processor core <highlight><bold>101</bold></highlight> that includes L1 and L2 caches. Also included on chip <highlight><bold>100</bold></highlight> is an on-die L3 cache <highlight><bold>105</bold></highlight>. The bus lines <highlight><bold>102</bold></highlight> coupled to the multiple banks of the L3 cache are received at a central location <highlight><bold>104</bold></highlight> on the die for communication with the processor core <highlight><bold>101</bold></highlight>. (Although the direction of the arrow shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> denotes information transfer from the banks to the core, it is appreciated that information is likewise transferred in the opposite direction, i.e., from the core to the cache banks.) </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> In the example of <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, some banks of L3 cache memory <highlight><bold>105</bold></highlight> are located relatively close to central location <highlight><bold>104</bold></highlight>, and other banks are located relatively far from central location <highlight><bold>104</bold></highlight>. As previously discussed data timing and synchronization problems arise in the prior art due to the various distances between the banks and central location <highlight><bold>104</bold></highlight>. To overcome these problems, the cache memory architecture of the present invention sends data synchronously along the bus lines such that it arrives at the receiver (e.g., central location <highlight><bold>104</bold></highlight>) at a predetermined time regardless of which bank the data originated from. This is achieved by inserting flip-flops (i.e., &ldquo;flops&rdquo;), buffers or latches along the bus in the data path such that data read from the closest banks passes through the same number of flops, and therefore takes the same number of clocks, as data read from the farthest bank. The same scheme is utilized along the input data path for writing data to the cache banks. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates an exemplary cache memory <highlight><bold>20</bold></highlight> organized in accordance with one embodiment of the present invention. Cache memory <highlight><bold>20</bold></highlight> includes seven cache banks (Bank<highlight><subscript>0</subscript></highlight>-Bank<highlight><subscript>6</subscript></highlight>) each of which is coupled to an input data/address bus and to a data output bus. The input and output buses are both coupled to a block <highlight><bold>28</bold></highlight>, which represents the central location on the chip where information is transferred to/from the processor core. By way of example, block <highlight><bold>28</bold></highlight> may comprise the tag arrays associated with the cache, the processor core itself, or other logic. Data either originates from or is received by block <highlight><bold>28</bold></highlight> depending upon the data flow direction. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The spaced-relationship shown between each of the cache banks and block <highlight><bold>28</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is intended to represent the various physical distances that each of the banks are located on the die relative to the central location associated with data transmission from/to the processor core. For example, Bank<highlight><subscript>6 </subscript></highlight>is shown being located closest to block <highlight><bold>28</bold></highlight>, and Banks is shown being located farthest from block <highlight><bold>28</bold></highlight>. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The cache memory of <cross-reference target="DRAWINGS">FIG. 4</cross-reference> also includes bus repeaters <highlight><bold>21</bold></highlight>-<highlight><bold>24</bold></highlight> inserted in the output data path and bus repeaters <highlight><bold>31</bold></highlight>-<highlight><bold>34</bold></highlight> included in the input data/address path. Each of the bus repeaters is a synchronous device such a clocked flop, buffer, or latch. Bus repeaters are inserted in the data transmission path because a data or address signal can only travel a certain physical or geographic distance along the bus within a given clock cycle. This distance determines the spacing of the bus repeaters along the bus. In other words, bus repeaters are spaced along the bus lines such that a synchronously transmitted signal is received by a next bus repeater (down the line) prior to the next clock cycle. The physical spacing between bus repeaters, therefore, represents the distance a signal can be transmitted on the bus lines in a single clock cycle. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> For example, data output from Bank<highlight><subscript>0 </subscript></highlight>must travel the longest distance across the chip and therefore requires the use of bus repeaters <highlight><bold>21</bold></highlight>-<highlight><bold>24</bold></highlight> in order to reach block <highlight><bold>28</bold></highlight>. Stated differently, it takes five clock cycles for signal transmission to/from Bank<highlight><subscript>0</subscript></highlight>. In contrast, Bank<highlight><subscript>6</subscript></highlight>, being the closest bank, only requires the use of bus repeater <highlight><bold>24</bold></highlight> for output data to reach block <highlight><bold>28</bold></highlight>. To insure that all data arrives and is latched at the central location at a predetermined time regardless of which bank the data is actually stored in, the present invention includes staging devices in the input and output data paths. The blocks labeled &ldquo;S&rdquo; (e.g., blocks <highlight><bold>40</bold></highlight> and <highlight><bold>41</bold></highlight>) in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> denote the staging devices. The staging devices may comprise any ordinary synchronous device such a clocked flop, buffer, or latch. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Note that three staging devices are shown inserted in the data path (input and output) coupled to Bank<highlight><subscript>6</subscript></highlight>. In this example, these staging devices are included in order to make the latency associated with Bank<highlight><subscript>6 </subscript></highlight>the same as that associated with the farthest bank, Bank<highlight><subscript>6</subscript></highlight>. By staging data transmission in this manner, synchronization problems inherent in the prior art&mdash;such as data accessed from a closer bank colliding on the bus with data from an earlier access to a farther bank&mdash;are overcome. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Practitioners in the art will appreciate that the concept of staging provides the further advantage of pipelined data accesses. Because the latency to/from all cache banks is made to be identical in the architecture of the present invention, data accesses can be pipelined, i.e., continuous read and write operations can be performed regardless of which bank the data is actually located. Output data flows back the processor core in the same order it was requested irrespective of the location of the cache bank on the chip where the data is physically stored. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> It should be understood that the insertion of the staging devices in the data path for a given bank in the cache is a function of the physical distance of the bank from the central location, and also the operating frequency. For example, more staging devices (and also more bus repeaters) will be needed the faster the operating frequency. Similarly, more staging devices and bus repeaters will be needed the larger the distance between the closest and farthest cache bank. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> Whatever the number of staging devices and bus repeaters utilized, the latency or synchronous delay (&num; of clocks) when accessing any bank in the cache remains constant. In other words, in the cache memory of the present invention a data request to the farthest bank can be immediately followed by a data request to the nearest bank, and the outputs from the respective banks will not collide. The solution of the present invention therefore allows 100% of the bandwidth of the data bus to be utilized. Moreover, it is appreciated that the architecture of the present invention may be used advantageously on non-banked cache memory designs. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> With reference now to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, there is shown an example sub array busing for one embodiment of the cache architecture of the present invention. This basic sub array busing is repeated throughout the cache. In the example of <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, two sub arrays (A<highlight><subscript>1 </subscript></highlight>and A<highlight><subscript>2</subscript></highlight>) of a common bank in the cache are depicted. For purposes of clarity, the word line decoder circuitry is omitted, and only one half of the data storage elements of each sub array are shown in the figure. For example, data arrays <highlight><bold>43</bold></highlight> and <highlight><bold>48</bold></highlight> comprise half the storage capacity of sub arrays A<highlight><subscript>1 </subscript></highlight>and A<highlight><subscript>2</subscript></highlight>, respectively. In the particular architecture shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, four 256-bit chunks of data are read out sequentially. In this example, 32 bits are taken down to <highlight><bold>8</bold></highlight> bits in each half portion of the sub array by multiplexers <highlight><bold>44</bold></highlight> and <highlight><bold>49</bold></highlight>, respectively associated with sub arrays A<highlight><subscript>1 </subscript></highlight>and A<highlight><subscript>2</subscript></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> The data output from each sub array is feed out in either a left or right direction, depending on the state of a pair of enable control lines. For example, in sub array A<highlight><subscript>1 </subscript></highlight>the <highlight><bold>8</bold></highlight>-bit data from array <highlight><bold>43</bold></highlight> is input to NAND gates <highlight><bold>45</bold></highlight> and <highlight><bold>46</bold></highlight>. The other input to NAND gate <highlight><bold>45</bold></highlight> is provided by a left enable control signal line, L<highlight><subscript>1</subscript></highlight>, whereas the second input to NAND gate <highlight><bold>46</bold></highlight> is coupled to a right enable control signal line, R<highlight><subscript>1</subscript></highlight>. The output of NAND gate <highlight><bold>45</bold></highlight> is coupled to one input of AND gate <highlight><bold>42</bold></highlight>, and the output of NAND gate <highlight><bold>46</bold></highlight> is coupled to one input of AND gate <highlight><bold>47</bold></highlight>. AND gates <highlight><bold>42</bold></highlight> and <highlight><bold>47</bold></highlight> (and <highlight><bold>52</bold></highlight>) comprise the repeater structure discussed previously (e.g., <cross-reference target="DRAWINGS">FIG. 1</cross-reference>). </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> Similarly, in sub array A<highlight><subscript>2</subscript></highlight>, 8-bit data from data storage array <highlight><bold>48</bold></highlight> is coupled to NAND gates <highlight><bold>50</bold></highlight> and <highlight><bold>51</bold></highlight>, which also receive L<highlight><subscript>2 </subscript></highlight>and R<highlight><subscript>2 </subscript></highlight>control signals, respectively. Data output from NAND gate <highlight><bold>50</bold></highlight> is coupled to one input of AND gate <highlight><bold>47</bold></highlight>, with the output of NAND gate <highlight><bold>51</bold></highlight> being coupled to an input of AND gate <highlight><bold>52</bold></highlight>. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Each of the repeaters <highlight><bold>42</bold></highlight>, <highlight><bold>47</bold></highlight>, and <highlight><bold>52</bold></highlight> has an input connected to a global data bus line driven from a previous bank, and, in turn, each of repeaters <highlight><bold>42</bold></highlight>, <highlight><bold>47</bold></highlight>, and <highlight><bold>52</bold></highlight> drives the data output on the line to the next cache bank. The third input to each of the AND gates shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is connected to receive data from an adjacent sub array. For instance, AND gate <highlight><bold>42</bold></highlight> has inputs coupled to receive data from either sub array A<highlight><subscript>0 </subscript></highlight>or A<highlight><subscript>1</subscript></highlight>; AND gate <highlight><bold>47</bold></highlight> has inputs coupled to receive data from either sub array A<highlight><subscript>1 </subscript></highlight>or A<highlight><subscript>2</subscript></highlight>. Finally, AND gate <highlight><bold>52</bold></highlight> is connected so as to be able to drive data onto its associated bus line from either sub array A<highlight><subscript>2 </subscript></highlight>or A<highlight><subscript>3</subscript></highlight>. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> The state of the enable control single lines determines the direction (left or right) that data flows from a particular sub array. In other words, which global data bus line carries data from which sub array is determined by the L and R signal lines coupled to each sub array. By way of example, if the cache shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is configured so that data flows to the right from each sub array, then L<highlight><subscript>1 </subscript></highlight>will be set to a logic low potential, R<highlight><subscript>1 </subscript></highlight>will be set to a logic high potential, L<highlight><subscript>2</subscript></highlight>&equals;low, R<highlight><subscript>2</subscript></highlight>&equals;high, and so on throughout the cache. In this case, data output from A<highlight><subscript>0 </subscript></highlight>is driven on the data bus line associated with repeater <highlight><bold>42</bold></highlight>, data from A<highlight><subscript>1 </subscript></highlight>is driven on the data bus line associated with repeater <highlight><bold>47</bold></highlight>, data originating from A<highlight><subscript>2 </subscript></highlight>is driven on the data bus by repeater <highlight><bold>52</bold></highlight>, and so on. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> As will be seen shortly, data flow direction from one or more sub arrays changes when a redundant sub array element is activated to replace a defective sub array within a bank. To disconnect a particular sub array A<highlight><subscript>k </subscript></highlight>from the bus, both the L<highlight><subscript>k </subscript></highlight>and R<highlight><subscript>k </subscript></highlight>signal lines associated with the sub array are driven to a low (i.e., logic &ldquo;0&rdquo;) potential. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> According to the cache architecture of the present invention, at least one redundant sub array element is included in each bank. By including dual NAND gates in data output path of each sub array, data can feed in two alternative directions toward two different bus lines. Each sub array also has its own left and right enable control bits that determine which direction data gets output. The left and right enable bits can be used to switch individual sub arrays on or off the bus. In this way, a sub array can be substituted for any other sub array with just a change in the enable signaling&mdash;the global data bus, itself, is unchanged. All of this is achieved with no impact to power or speed. The large number of additional bus lines that characterized prior art cache designs with redundancy is thus obviated by the architecture of the present invention. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a schematic diagram illustrating the enable control circuitry utilized in one embodiment of the present invention. As can be seen, the L and R control signal lines of each sub array (e.g., A<highlight><subscript>0</subscript></highlight>, A<highlight><subscript>1</subscript></highlight>, A<highlight><subscript>2</subscript></highlight>, etc.) are driven by the same basic circuit shown enclosed in dashes, which is simply repeated across the cache. In the embodiment shown, a fuse circuit is utilized to selectively disconnect one of the sub arrays from the bank. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> One possible implementation of the fuse circuit used in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is illustrated in the circuit schematic diagram of <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. In the circuit of <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, inverter <highlight><bold>73</bold></highlight> normally outputs a logic one (&ldquo;Fuseout&rdquo;) so that each of the L<highlight><subscript>i </subscript></highlight>and R<highlight><subscript>i </subscript></highlight>enable control signals comprise a logic one and logic zero, respectively. This condition dictates a state in which all of the sub arrays connect to the left-side data output bus lines. The logic one state at the output of inverter <highlight><bold>73</bold></highlight> is maintained so long as one or both of the &ldquo;Program Fuse&rdquo; and &ldquo;Select&rdquo; inputs to NAND gate <highlight><bold>70</bold></highlight> remain low. The &ldquo;Program Fuse&rdquo; line is connected to each of the fuse circuits shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, with each fuse circuit having its own &ldquo;Select&rdquo; signal line. This allows a single fuse circuit associated with a particular sub array to be blown without affecting the other fuse circuits. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> To blow a selected one of the fuse circuits, the &ldquo;Program Fuse&rdquo; line is raised to a high potential along with the &ldquo;Select&rdquo; line associated with the particular sub array to be disconnected. When both inputs to NAND gate <highlight><bold>70</bold></highlight> are raised to a high potential, the gate of PFET <highlight><bold>71</bold></highlight> transitions low, which turns on device <highlight><bold>71</bold></highlight>. The current flowing through device <highlight><bold>71</bold></highlight> is used to blow the fuse <highlight><bold>72</bold></highlight>, causing the output of inverter <highlight><bold>73</bold></highlight> to flip to a logical zero state. Thus, when the fuse circuit associated with a particular sub array is blown, the L and R enable signals are both set low, which disconnects that sub array from the cache bank. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> By way of example, assume that sub array A<highlight><subscript>1 </subscript></highlight>in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is disconnected by selectively blowing its fuse circuit in the manner described above. In this case, sub array A<highlight><subscript>0 </subscript></highlight>is unaffected and still outputs data to the left (i.e., L<highlight><subscript>0</subscript></highlight>&equals;1, R<highlight><subscript>0</subscript></highlight>&equals;0), sub array A<highlight><subscript>1 </subscript></highlight>is disconnected (i.e., L<highlight><subscript>0</subscript></highlight>&equals;0, R<highlight><subscript>0</subscript></highlight>&equals;0). But each of sub arrays A<highlight><subscript>2-N </subscript></highlight>have their enable control states reversed (i.e., L<highlight><subscript>0</subscript></highlight>&equals;0, R<highlight><subscript>0</subscript></highlight>&equals;1), so that all of the sub arrays with a higher index (&gt;1) now output data to the right side bus lines. In other words, in this example every sub array below the defective, disconnected sub array stays on the same bus lines that they were originally connected to. Every sub array above the defective, disconnected sub array is shifted up one bus line to the opposite side (e.g., to the right side). </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> It is appreciated that the opposite affect can also be achieved. That is, by reversing the L and R outputs in the enable control logic circuitry shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, disconnecting a particular sub array from the cache will change the bus line connections in a contrary manner; i.e., every sub array above the disconnected array stays on the same bus lines that they were originally connected to, and every sub array below the disconnected array is shifted to the left. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> As the following examples demonstrate, the control logic scheme employed in the illustrated embodiment permits substitution of a redundant sub array for any other sub array in the cache bank. This is accomplished simply by blowing a fuse, without the need for extensive bus line multiplexing, and with no adverse impact to power or speed. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIGS. 8A &amp; 8B</cross-reference>, there is shown an example of the use of a redundant sub array in accordance with one embodiment of the present invention. <cross-reference target="DRAWINGS">FIG. 8A</cross-reference> shows normal sub array decoding in which the redundant sub array (labeled &ldquo;R&rdquo;) is not used. Each of the sub arrays A<highlight><subscript>0-N </subscript></highlight>is show in an initial state, wherein each is connected to the data bus lines via a right-side connection. <cross-reference target="DRAWINGS">FIG. 8B</cross-reference> shows the same cache bank after removal of defective sub array A<highlight><subscript>1 </subscript></highlight>and connection to the redundant sub array. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> As described above, sub array A<highlight><subscript>1 </subscript></highlight>is removed from the bank by blowing its associated fuse circuit, disconnecting it from the bus. The sub array below sub array A<highlight><subscript>1 </subscript></highlight>(i.e., A<highlight><subscript>0</subscript></highlight>) is unaffected and still has a right-side connection to the data bus. The sub arrays with a higher index, above sub array A<highlight><subscript>1 </subscript></highlight>(i.e., A<highlight><subscript>2-N</subscript></highlight>), have their connections reversed; each of the sub arrays A<highlight><subscript>2-N </subscript></highlight>and the redundant sub array &ldquo;R&rdquo; is now shown being connected to the data bus through a left-side connection. Importantly, the global bus remains unchanged. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 9A &amp; 9B</cross-reference> show a further example of an embodiment of the present invention that uses a redundant sub array in a non-linear array pattern. The 2&times;4 array pattern consists of two rows of four regular sub arrays. The top row comprises sub arrays A<highlight><subscript>4-7 </subscript></highlight>and the bottom row comprises sub arrays A<highlight><subscript>0-3</subscript></highlight>, arranged as shown. An additional, redundant sub array element is included in the cache bank. In this example, the redundant element is arranged on the bottom row. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9A</cross-reference> represents a normal sub array decoding situation in which the redundant sub array is not employed. In this case, the rows of regular sub arrays connect to the data bus lines in an alternate fashion; the top row sub arrays A<highlight><subscript>4</subscript></highlight>-<highlight><subscript>7 </subscript></highlight>being connected to the right-side bus lines, and the bottom row sub arrays A<highlight><subscript>0-3 </subscript></highlight>being connected to the left-side bus lines. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9B</cross-reference> shows the same cache bank after disconnection of defective sub array A<highlight><subscript>1</subscript></highlight>, and use of the redundant element &ldquo;R&rdquo;. As was the case in the previous example, disconnection sub array A<highlight><subscript>1 </subscript></highlight>does not affect the bus connection of the lower index sub array; that is, sub array A<highlight><subscript>0 </subscript></highlight>remains connected to the left-side data bus lines. The higher index sub arrays, however, have their connections reversed as a consequence of removal of the defective sub array A<highlight><subscript>1</subscript></highlight>. As can be seen, each of the sub arrays A<highlight><subscript>2-7 </subscript></highlight>is now shown being connected to the opposite side bus lines. For instance, sub arrays A<highlight><subscript>2-3</subscript></highlight>, which previously were connected to the left-side bus lines, are now shown being connected to the right-side data bus lines. Likewise, each of the sub arrays A<highlight><subscript>4-7</subscript></highlight>, which previously were connected to the right-side bus lines, are now shown connected to the bus via the left side. In this example, the redundant sub array &ldquo;R&rdquo; is connected to its adjacent bus lines, i.e., the left side. Once again, the global bus remains unchanged after replacement of the defective sub array. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Practitioners in the art will appreciate that the concepts presented in the foregoing examples can be extended to accommodate any grouping or organization of cache arrays. Moreover, the bus lines themselves need not extend along left and right sides adjacent to the sub arrays in the manner shown in the drawings. In addition, ordinary logic circuits other than the specific type shown in the examples of the illustrated embodiments may be used. Alternatively, the changing of the bit setting may be implemented in software or firmware under the control of the computer&apos;s operating system. Accordingly, the specification and drawings are to be regarded in an illustrative rather than a restrictive sense. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">We claim: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A cache, comprising: 
<claim-text>a plurality of arrays of memory cells, the arrays being arranged in banks, each bank including regular arrays and a redundant array; </claim-text>
<claim-text>a bus having sets of data lines for connection to the arrays; </claim-text>
<claim-text>circuitry to connect a regular array to either a first set or a second set of the data lines, or to disconnect the regular array from the bus. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the circuitry comprises a bit that, when set to a first logic state, causes the circuitry to disconnect the regular array from the bus. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the circuitry is further operative to connect the redundant array to the bus responsive to the bit being set. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein each bank comprises N regular arrays and the bus comprises N sets of data lines. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference> wherein the circuitry has a normal state in which each of the N regular arrays connect in a first direction to a corresponding one of the N sets of data lines of the bus. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> wherein the circuitry also has a changed state in which an ith regular array is disconnected from the bus, each of the regular arrays 0 to (i&minus;1) connect to the bus in the first direction, and further wherein each of the regular arrays (i&plus;1) to N, and also the redundant array, connect to the bus in a second direction. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> wherein the circuitry also has a changed state in which an ith regular array is disconnected from the bus, each of the regular arrays 0 to (i&minus;1) connect to the bus in a second direction, and further wherein each of the regular arrays (i&plus;1) to N, and also the redundant array, connect to the bus in the first direction. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the arrays in a bank are arranged linearly. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the arrays in a bank are arranged in multiple rows. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>a plurality of repeaters each of which provides for series connection of an array with a data line of the bus. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A cache, comprising: 
<claim-text>a plurality of arrays of memory cells, the arrays being arranged in banks, each bank including regular arrays, A<highlight><subscript>0-N</subscript></highlight>, and a redundant array; </claim-text>
<claim-text>a data bus having sets of N sets of bus lines, B<highlight><subscript>0-N</subscript></highlight>, for connection to the arrays; </claim-text>
<claim-text>logic associated with each array, the logic being configured with a bit that is set to a first state to connect an ith regular array to an ith set of the bus lines, with the redundant array being disconnected from the data bus; </claim-text>
<claim-text>a change in the bit setting from the first state to a second state causing the regular array, A<highlight><subscript>i</subscript></highlight>, to be disconnected from the data bus and the redundant array to be connected to the data bus. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> wherein the redundant array is connected to the Nth set of bus lines, B<highlight><subscript>N</subscript></highlight>, responsive to the change in the bit setting to the second state. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> wherein regular arrays, A<highlight><subscript>0 </subscript></highlight>to A<highlight><subscript>(i&minus;) </subscript></highlight>connect to bus lines B<highlight><subscript>0 </subscript></highlight>to B<highlight><subscript>(i&minus;1)</subscript></highlight>, respectively, and regular arrays, A<highlight><subscript>(i&plus;1) </subscript></highlight>to A<highlight><subscript>N </subscript></highlight>connect to bus lines B<highlight><subscript>i </subscript></highlight>to B<highlight><subscript>(N&minus;1)</subscript></highlight>, respectively, responsive to the change. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> wherein the arrays in a bank are arranged linearly. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> wherein the arrays in a bank are arranged in multiple rows. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The cache of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> further comprising: 
<claim-text>a plurality of repeaters each of which provides for series connection of an array with a data line of the bus. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A cache of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> wherein the logic includes a fuse circuit having a fuse, when the fuse is in a first conductivity state, the bit setting corresponding to the first state, and when the fuse is in a second conductivity state, the bit setting corresponding to the changed state. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A method of operation for a cache, comprising: 
<claim-text>changing a single bit associated with a cache bank from a first to a second logic state, the cache bank comprising a plurality of arrays of memory cells, the arrays including regular arrays, A<highlight><subscript>0-N</subscript></highlight>, and a redundant array, the regular arrays being connected to corresponding bus lines, B<highlight><subscript>0-N</subscript></highlight>, of a data bus when the single bit is in the first logic state; </claim-text>
<claim-text>disconnecting a regular array, A<highlight><subscript>i</subscript></highlight>, from the data bus data bus responsive to the single bit state being changed to the second logic state; </claim-text>
<claim-text>connecting the redundant array to the data bus responsive to the single bit state being changed to the second logic state. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> wherein regular arrays, A<highlight><subscript>0 </subscript></highlight>to A<highlight><subscript>(i&minus;1) </subscript></highlight>connect to bus lines B<highlight><subscript>0 </subscript></highlight>to B<highlight><subscript>(i&minus;1)</subscript></highlight>, respectively, and regular arrays, A<highlight><subscript>(i&plus;1) </subscript></highlight>to A<highlight><subscript>N </subscript></highlight>connect to bus lines B<highlight><subscript>i </subscript></highlight>to B<highlight><subscript>(N&minus;1)</subscript></highlight>, respectively, responsive to the single bit state being changed to the second logic state. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> wherein the redundant array connects to bus line BN of the data bus responsive to the single bit state being changed to the second logic state. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> regular arrays, A<highlight><subscript>0 </subscript></highlight>to A<highlight><subscript>(i&minus;1) </subscript></highlight>connect to bus lines B<highlight><subscript>1 </subscript></highlight>to B<highlight><subscript>(i)</subscript></highlight>, respectively, and regular arrays, A<highlight><subscript>(i&plus;1) </subscript></highlight>to A<highlight><subscript>N </subscript></highlight>connect to bus lines B(<highlight><subscript>i&plus;1) </subscript></highlight>to B<highlight><subscript>N</subscript></highlight>, respectively, responsive to the single bit state being changed to the second logic state. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference> wherein the redundant array connects to bus line B<highlight><subscript>0 </subscript></highlight>of the data bus responsive to the single bit state being changed to the second logic state. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> wherein the data bus is unaffected by the single bit state being changed to the second logic state. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> wherein changing the single bit state comprises blowing a fuse.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>4</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005225A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005225A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005225A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005225A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005225A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005225A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030005225A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030005225A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030005225A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030005225A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
