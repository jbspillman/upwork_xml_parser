<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002854A1-20030102-D00000.TIF SYSTEM "US20030002854A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002854A1-20030102-D00001.TIF SYSTEM "US20030002854A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002854A1-20030102-D00002.TIF SYSTEM "US20030002854A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002854A1-20030102-D00003.TIF SYSTEM "US20030002854A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002854A1-20030102-D00004.TIF SYSTEM "US20030002854A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002854A1-20030102-D00005.TIF SYSTEM "US20030002854A1-20030102-D00005.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002854</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09895055</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010629</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04N005/91</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>386</class>
<subclass>068000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Systems, methods, and computer program products to facilitate efficient transmission and playback of digital information</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>William</given-name>
<middle-name>R.</middle-name>
<family-name>Belknap</family-name>
</name>
<residence>
<residence-us>
<city>San Jose</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Jane</given-name>
<middle-name>K.</middle-name>
<family-name>Doong</family-name>
</name>
<residence>
<residence-us>
<city>San Jose</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>International Business Machines Corporation</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>INTERNATIONAL BUSINESS MACHINES CORP</name-1>
<name-2>IP LAW</name-2>
<address>
<address-1>555 BAILEY AVENUE , J46/G4</address-1>
<city>SAN JOSE</city>
<state>CA</state>
<postalcode>95141</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Systems, methods, and computer products that facilitate transmission of information used for fast and responsive video and audio playback at non-standard, trick mode speeds. An embodiment of the present invention uses low resolution, compressed, and independent frames derived from the encoded digital video or audio information to facilitate the operation of user-requested VTR-like speed change functions associated with digital video and digital audio frames. The present invention greatly simplifies locating specific frames in a video or audio presentation for purposes such as fast forward and fast reverse scanning that is typically used in digital editing. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention is directed to the field of video and audio scanning, storage, and playback. It is more particularly directed to digital video and audio operations to facilitate trick mode playback on a computer system. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Background Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Digital video and audio information is typically transmitted between computer systems in a highly compressed and encoded frame format. Further, the video information may be translated into differentially encoded frames for storage and transmission. The compressed and encoded frames are formatted so that the digital video and audio information may be referenced and played back in an order dependent fashion that is also time sensitive. Typically the information is ordered with respect to a forward directed presentation of the frames. These encoding techniques enable trick mode operations that emulate Video Tape Recorder (VTR) functions, such as fast forward scan and fast reverse scan. However, digital encoding operations have suffered from problems of efficiency and slow responsiveness during playback primarily due to the large amount of variable sized, order dependent, and time sensitive information that is generated during the creation of the encoded frames. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Typically, trick mode files are processed on an initiating computer system or a managing computer system that is often called a &ldquo;data server&rdquo; computer system. These trick mode files are created by extracting video frames, re-timing the video frames, and eliminating some of the encoded video frames. The audio information associated with the extracted video frames is typically compressed and identified so that the association between the video and audio information is preserved. These trick mode frames tend to be difficult to properly produce due to their complexity. Further, these complex frames may increase the data storage requirements over the encoded digital video and audio files by as much as seventy-five percent. Also, since the trick mode files are typically located on the data server computer system they suffer from transmission latency problems with respect to the viewing computer system, often called a &ldquo;client&rdquo; computer system. The transmission rate associated with trick mode files may be as much as twenty times greater than the transmission rate associated with the digital video and audio information. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Alternately, the trick mode video frames and the associated compressed audio frames may be stored locally, such as on the client computer system. That is, the trick mode video frames and the associated compressed audio frames may be decoded and reencoded on the client computer system when the video and audio is played back. However, this solution requires extensive computer processing resources and a large data storage capacity on the client computer system. Also this solution suffers from transmission latency since the large files are downloaded on the client computer system. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Yet another solution to the problem of processing complex trick mode frames is to tightly couple the client computer system and the data server computer system. That is, the playback requests from the client computer system may be associated with indexing commands that are managed on the data server computer system. The playback operations on the client computer system rely on proper location of the requested video and audio frames that are stored on the data server computer system. This solution also suffers from transmission latency problems between the data server computer system and the client computer system. Further this solution suffers from problems when scaling to accommodate increased numbers of users due to the extensive requirements for both computer resources and network utilization that are associated with maintaining the tight coupling between the data server computer system and the client computer system. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Differential encoding typically tracks differences between key frames that may be referred to as &ldquo;anchor&rdquo; frames. However, random access of frames that may be used for trick mode operations is difficult since multiple anchor frames may be required to provide sufficient information to reference a randomly selected location, and since headers that contain information associated with the encoded frames may vary in size. More particularly, referential information associated with locating a particular frame may be stored in more than one associated frame. Also, the decoding rules that are associated with each frame and that enable accurate decoding of encoded digital video frames vary in size, and the headers that store the information associated with the rules also vary in size. Performing trick mode operations adds further complexity to the process of playing video frames that have been differentially encoded. Therefore differential encoding operations have suffered from efficiency problems and slow responsiveness during playback due to the number of associated frames and the variable sized differentially encoded frames. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Transmission errors that are associated with the anchor frame may affect many digital video frames. Therefore, encoding operations that have suffered from problems associated with management of transmission errors that are related to transmitting a large amount of digital information, are addition-ally hampered when the information is differentially encoded. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Fast reverse video playback operations are especially difficult. The difficulty is primarily associated with playing information in the reverse direction that was created in a forward order fashion that is also time sensitive. Reverse playback is also difficult due to the variable size of the encoded frames. More particularly, it is difficult to locate a particular frame for the purpose of scanning in a fast reverse direction while maintaining a constant delivery rate of the information. Those skilled in the art will appreciate that video and audio delivery technologies often rely on a constant delivery rate of the information. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> From the foregoing it will be apparent that there is still a need to improve transmission of information used to facilitate fast and responsive playback of video and audio digital data. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> An embodiment of the present invention relates to systems, methods, and computer products that facilitate transmission of information used for fast and responsive video and audio playback at non-standard, trick mode speeds. An embodiment of the present invention uses low resolution, compressed, and independent frames derived from the encoded digital video or audio information. The independent frames facilitate the operation of user-requested VTR-like speed change functions associated with digital video and digital audio frames. That is, the low resolution, compressed frames facilitate indexing into the full resolution encoded digital video and audio information. Typically, the encoded digital video and audio information is stored on one computer system and is played on another computer system. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The present invention greatly simplifies locating specific frames in a video or audio presentation for fast forward and fast reverse scanning that is typically used in digital editing. The present invention delivers and manipulates smaller amounts of digital data thereby locating positions in a stream of digital data more quickly than in the past. Also, since the compressed frames are a subset of the entire set of frames, the scanning operation will appear to the user as a fast operation when viewed in either the forward or the backward direction. That is, the use of low resolution, compressed, and independent frames to locate positions in associated digitally encoded video or audio data improves the responsiveness and transmission efficiency of locating digitally encoded data. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> The compressed streams are much smaller than the original digital video and therefore may be processed, transmitted, and displayed more efficiently than past solutions. The high level of data reduction is achieved by reducing the image size, the resolution, and the color depth, and may take advantage of data compression operations such as JPEG. The present invention enables fast mode presentation of audio information associated with the compressed video data. A high level of data reduction is also applied to the audio data. This enables fast mode scanning for audio cues. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The present invention is especially useful since the compressed, independent frame data stream is small enough to be downloaded and managed on a user-accessible client computer system that is sometimes referred to as a &ldquo;thin client.&rdquo; This enables very fast response times to user input and reduces the latency that is associated with transmission between computer systems of the information used in fast speed playback. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> The Joint Photographic Experts Group (JPEG) is a group of experts that produce standards for continuous-tone image coding. The JPEG committee created the first of a multi-part set of standards for still image compression. JPEG is defined in International Standard 10918. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> More particularly the present invention may be a computer implemented method for digital video and audio scanning that facilitates trick mode playback. The preferred embodiment of the present invention accesses encoded digital video and digital audio frames. The encoded frames may be stored on a data storage media associated with a computer system or may be created by a computer system when they are needed. The digital video frames are typically differentially encoded, by compressing the information and including differential positional information. The associated digital audio frames are typically compressed. A subset of the encoded digital video frames are identified for fast playback, and will be referred to herein as &ldquo;playback video frames.&rdquo; Similarly, a subset of the encoded digital audio frames are processed and identified for fast playback, and will be referred to herein as &ldquo;playback audio frames.&rdquo; For each of the identified encoded digital video frames the associated playback video frame is encoded, typically by translating information in an MPEG format into information in an JPEG format. Likewise, for each of the identified encoded digital audio frames the associated playback audio frame is encoded. This encoding may include additional compression or may merely include a location identifier that associates the proper playback video frame with the playback audio frame to ensure synchronized fast speed playback. Visual representations of the audio frames may be presented in addition to the audio information. For example, audio attributes, such as the audio frequency or amplitude change, could be represented on a graph. Those skilled in the art will appreciate representation of audio frequency or amplitude information. By means of example, every third digital frame and audio frame may be included in the subset encoded for fast mode operations. Then the number of compressed frames is one-third of the associated digital frames. Therefore, playing of the playback frames will result in a fast speed presentation of the data that is suitable for trick mode operations. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The Moving Picture Experts Group (MPEG) is a working group of the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC) in charge of the development of standards for encoded representation of digital data representing audio and video information. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> According to the preferred embodiment of the present invention, the encoded digital video and audio frames are multiplexed by methods known to those skilled in the art. Also, the playback frames may be multiplexed. Then the multiplexed and encoded digital video and audio frames are transmitted, typically by streaming, from the initiating computer system to the receiving computer system where they are de-multiplexed and decoded. The receiving computer system could be a data server computer system or a client computer system. The encoded playback frames that may also be multiplexed are transmitted, typically by downloading to the receiving computer system where they are de-multiplexed if necessary and decoded. Now the receiving computer system may play the digital video frames, the digital audio frames, the playback video frames, and the playback audio frames so that the user can see and hear the digital frames and the playback frames. Synchronization of the digital frames and the playback frames is important. Typically synchronization during playing of the digital frames and the playback frames is enabled by using a time stamp location identifier that is associated with each frame. Synchronization is enabled by identifying the frames with the same time stamp identifier and ensuring that the identified frames are played concurrently. If directed by a user, the present embodiment will change the played frames to preserve synchronization. Therefore, the playback frames that are playing in a fast viewing mode, either forward or backward, enable quick location of digital video frames for customized viewing and editing. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> The digital video frame and the digital audio frame may be played on the receiving computer system or on another playback computer system, typically by the use of a digital window. Another viewing window, such as a trick mode, preview window, may be used to play the associated playback video frame and playback audio frame. Alternately, the associated playback frames may be played by overlaying the information on the digital window. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> It will be appreciated that the benefits of the present invention may be realized in an alternative embodiment of the present invention without inclusion of either the digital audio information or the digital video information. For example, synchronization and indexing between the digital video data and the playback video data enables more efficient editing of digital video information even without including audio data. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> Other aspects and advantages of the present invention will become apparent from the following detailed description, taken in conjunction with the accompanying drawings, illustrating by way of example the principles of the invention. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram that illustrates the present invention; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram that illustrates the association between the digital frames and the playback frames; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram that illustrates a computer system that plays the digital frames, and the playback frames; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flow diagram that illustrates the present invention; and </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a block diagram of a computer system suitably configured for employment of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> In the following detailed description and in the several figures of the drawings, like elements are identified with like reference numerals. </paragraph>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> As shown in the drawings and for purposes of illustration, the embodiment of the invention novelly facilitates transmission of information used for fast and responsive video and audio playback at non-standard trick mode speeds. Existing playback systems have not been able to efficiently produce and transmit non-standard trick mode video and audio information. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> The present invention decreases digital resolution by converting a subset of the digital frames into a sequence of compressed frames, such as JPEG frames that can be scanned forward or backward. Since the compressed frames are a subset of the entire set of frames, the scanning operation will appear to the user as a fast operation in the forward or the backward direction. The low resolution requires a lower bit rate and therefore a smaller digital file. The low resolution does not limit the user&apos;s ability to scan since user scanning does not require high resolution. Therefore by treating each frame as a new compressed frame, each frame can be scanned in either the forward or the backward direction more efficiently than in the past. The phrase, &ldquo;bit rate&rdquo; as used herein refers to the rate of transmission of small amounts of computer information. A &ldquo;bit&rdquo; is typically the smallest unit of information in a computer system. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Alternative embodiments of the present invention may create varying sized subsets of the digital frames. For example every other frame could be included in a sequence of compressed frames and the resulting subset of compressed frames yields a two-times faster data presentation than the original digital frames. In another alternative, a repeating sequence could be created in which one digital frame is skipped, the next digital frame is translated into a compressed frame, then two digital frames are skipped before the next compressed frame is created. This asymmetric repeating sequence is possible since there are no dependencies between the compressed images with respect to the scanning function. Therefore, almost any scanning rate may be achieved by the present invention. A &ldquo;frame&rdquo; is typically digital data that represents an independent, single sample of digital information. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> In the preferred embodiment of the present invention as illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and element <highlight><bold>100</bold></highlight>, the extraction of compressed image information occurs on an initiating computer system <highlight><bold>105</bold></highlight> and is stored on a data server computer system <highlight><bold>110</bold></highlight>. Then the compressed frame information may be efficiently transmitted when requested to a client computer system <highlight><bold>115</bold></highlight>. In an alternative embodiment the operations may be performed on one computer system or on two computer systems, instead of by use of the initiating computer system <highlight><bold>105</bold></highlight>, the data server computer system <highlight><bold>110</bold></highlight>, and the client computer system <highlight><bold>115</bold></highlight>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> More particularly the present invention may be a computer implemented system, method, or computer program product for digital video and audio scanning that facilitates trick mode playback. The preferred embodiment of the present invention accesses encoded digital video frames <highlight><bold>120</bold></highlight> and digital audio frames <highlight><bold>125</bold></highlight>, jointly referred to herein as encoded digital frames <highlight><bold>126</bold></highlight>. The encoded digital frames <highlight><bold>126</bold></highlight> may be stored on a data storage device <highlight><bold>130</bold></highlight> associated with a computer system or may be created by a computer system when they are needed from the video information <highlight><bold>135</bold></highlight> and the audio information <highlight><bold>140</bold></highlight>. The encoder <highlight><bold>155</bold></highlight> typically encodes the digital video frames <highlight><bold>120</bold></highlight> and the digital audio frames <highlight><bold>125</bold></highlight>, by compressing the information and differential positional information is included with the compressed digital video frames <highlight><bold>120</bold></highlight>. For example the encoder <highlight><bold>155</bold></highlight> may be an MPEG encoder. A subset of the encoded digital video frames <highlight><bold>120</bold></highlight> are identified and translated into playback video frames <highlight><bold>145</bold></highlight>. Similarly, a subset of the encoded digital audio frames <highlight><bold>125</bold></highlight> are identified and translated into playback audio frames <highlight><bold>150</bold></highlight>. The playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight> may be generated from the encoded digital frames <highlight><bold>126</bold></highlight> or may be created as needed from the digital video information <highlight><bold>135</bold></highlight> and the digital audio information <highlight><bold>140</bold></highlight>. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Each of the playback video frames <highlight><bold>145</bold></highlight> is processed by the encoder <highlight><bold>155</bold></highlight> that produces encoded playback video frames. Also, each of the playback audio frames <highlight><bold>150</bold></highlight> is processed by the encoder <highlight><bold>155</bold></highlight> that produces encoded playback audio frames. The encoded playback video frames and encoded playback audio frames are jointly represented herein by the encoded playback frames <highlight><bold>161</bold></highlight>. Those skilled in the art will recognize that any combination of the components, or any number of different components, and other devices, may be used to create the encoder <highlight><bold>155</bold></highlight>. The encoder <highlight><bold>155</bold></highlight> may be a software module, a hardware component, or a combination of the two. Further, the encoder <highlight><bold>155</bold></highlight> that generates encoded playback frames <highlight><bold>161</bold></highlight> may be different from the encoder <highlight><bold>155</bold></highlight> that generates encoded digital frames <highlight><bold>126</bold></highlight>. In an alternative embodiment of the present invention only digital audio frames <highlight><bold>125</bold></highlight> or only digital video frames <highlight><bold>120</bold></highlight> are processed. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Typically the present invention will translate video information in an MPEG format into compressed information in an JPEG format during the encoding stage. There are many compression applications and standards known in the art that typically use encoding techniques. What is seen as a smooth, full motion video or film is actually a sequence of still images flashing by just faster than what the eye can see. The audio encoding may include additional compression or may merely include information to ensure synchronization of the video and audio information during playback. Analog audio information may be sampled and transformed into digital values representing the sound in terms of functions, such as volume, pitch, or timbre. These samples represent digital audio, such as is found in WAV files or Compact Disks. This digital audio information can be of very high quality and accuracy if sufficiently refined samples are used. The digital audio data is compressed by the encoder <highlight><bold>155</bold></highlight> to enable streaming. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> In the preferred embodiment both video and audio information is processed. The encoded digital frames <highlight><bold>126</bold></highlight> are multiplexed by the multiplexor <highlight><bold>160</bold></highlight> producing multiplexed digital frames <highlight><bold>162</bold></highlight>. The encoded playback frames <highlight><bold>161</bold></highlight> are multiplexed by the multiplexor <highlight><bold>160</bold></highlight> producing multiplexed playback frames <highlight><bold>163</bold></highlight>. The multiplexed digital frames <highlight><bold>162</bold></highlight> are streamed to the data server computer system <highlight><bold>110</bold></highlight> and typically directly on to the client computer system <highlight><bold>115</bold></highlight>. Then the client computer system <highlight><bold>115</bold></highlight> may operate as a software-based player <highlight><bold>175</bold></highlight> and provide bit manipulation that is required for audio and video rendering. The client computer system <highlight><bold>115</bold></highlight> may include a de-multiplexor <highlight><bold>165</bold></highlight> that translates the multiplexed digital frames <highlight><bold>162</bold></highlight> to individual encoded digital video <highlight><bold>120</bold></highlight> and encoded digital audio frames <highlight><bold>125</bold></highlight>, jointly referred to as encoded digital frames <highlight><bold>126</bold></highlight>. The decoder <highlight><bold>170</bold></highlight> then translates the encoded digital frames <highlight><bold>126</bold></highlight> back into digital video <highlight><bold>135</bold></highlight> and digital audio frames <highlight><bold>140</bold></highlight> suitable for playing to the user on the client computer system <highlight><bold>115</bold></highlight>. For example, MPEG decoders receive data, typically from a network interface card or a local disk and then directly write the video and audio bit map to the computer memory for presentation to the user. Those skilled in the art will appreciate that applications may buffer all or a part of the digital video <highlight><bold>135</bold></highlight> and digital audio <highlight><bold>140</bold></highlight> clips before playing. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> By means of explanation, a simple stream encapsulates audio or video data or the output of data encoding and transmits the data in portions, typically referred to as &ldquo;packets,&rdquo; directly to the receiving computer system, such as the client computer system <highlight><bold>115</bold></highlight>. A simple stream typically contains a single type of signal, such as digital audio <highlight><bold>140</bold></highlight> or digital video <highlight><bold>135</bold></highlight>. The process of combining simple streams into a single synchronous transmission bit stream is multiplexing. The multiplexed information may be streamed over data transmission devices <highlight><bold>197</bold></highlight> that are typically referred to as &ldquo;links,&rdquo; such as radio frequency links (UHF and VHF), digital broadcast satellite links, and cable TV networks. A transport stream is a particular type of multiplexed stream that combines one or more simple streams and transports the data, typically between computer systems. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Also, the multiplexed playback frames <highlight><bold>163</bold></highlight>, when available, may be streamed directly to a computer system such as the client computer system <highlight><bold>115</bold></highlight> or may be stored in data storage <highlight><bold>130</bold></highlight>. The multiplexed playback frames <highlight><bold>163</bold></highlight> may be de-multiplexed by the de-multiplexor <highlight><bold>165</bold></highlight>. Then the encoded playback frames <highlight><bold>161</bold></highlight> may be translated by the decoder <highlight><bold>170</bold></highlight> back into the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight> for presentation to the user. The encoded playback frames <highlight><bold>161</bold></highlight> typically require less storage space and may be efficiently transmitted and stored on the client computer system <highlight><bold>115</bold></highlight> or alternately on the data server computer system <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> More particularly, the multiplexed playback frames <highlight><bold>163</bold></highlight> may be streamed directly to the client computer system <highlight><bold>115</bold></highlight> or may be downloaded and stored until needed on a data storage device <highlight><bold>130</bold></highlight> associated with the data server computer system <highlight><bold>110</bold></highlight> or the client computer system <highlight><bold>115</bold></highlight>. With the high level of data reduction achieved by reducing the image size, the resolution, and the color depth, and the high level of compression offered by well known techniques such as JPEG, the frames are much smaller than the encoded digital frames <highlight><bold>126</bold></highlight> and therefore may be processed, transmitted, and displayed more efficiently than past solutions. This small size allows the stream to be downloaded as a file using well-known operations such as HTTP download or File Transfer Protocol (FTP) onto the client computer system <highlight><bold>115</bold></highlight> thereby allowing very fast user response time in viewing and scanning the compressed frames. Those skilled in the art will appreciate the use of HTTP download or FTP for downloading digital data. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> In the preferred embodiment, the encoding process includes time stamp information into the simple stream and the decoder <highlight><bold>170</bold></highlight> may regenerate accurate time stamps from the encoded information. The video and audio information may be synchronized by use of the time stamp information. For example, the player <highlight><bold>175</bold></highlight> may provide audio <highlight><bold>140</bold></highlight> and video <highlight><bold>135</bold></highlight> digital data that is associated with the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight> that is synchronized by a time stamp that is associated with each frame. The time stamp may indicate the exact moment when the digital video frame <highlight><bold>135</bold></highlight> and the digital audio frame <highlight><bold>140</bold></highlight> were created. The time stamp associated with either the playback video frame <highlight><bold>145</bold></highlight> or the playback audio frame <highlight><bold>150</bold></highlight> may reference the time code from which they were derived. Synchronization is achieved by concurrently presenting the frames with the same time stamp to the user, via the player <highlight><bold>175</bold></highlight>. Therefore, when the time stamps of each frame match, the information may be synchronized. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In the preferred embodiment of the present invention the user may direct whether incremental playing of the digital information <highlight><bold>126</bold></highlight> or the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight> occurs. The user input <highlight><bold>199</bold></highlight> may be received from either the initiating computer system <highlight><bold>105</bold></highlight>, the data server computer system <highlight><bold>110</bold></highlight>, or the client computer system <highlight><bold>115</bold></highlight>. The user may pause the playing of the digital frames <highlight><bold>126</bold></highlight> or the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight>. When switching from playing the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight> to playing the digital frames <highlight><bold>126</bold></highlight> the time stamp location identifier is matched with the current playing location of the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight>. For example, as the user changes the position of the currently presented playback video frames <highlight><bold>145</bold></highlight> the subsequent playing of the associated playback audio frames <highlight><bold>150</bold></highlight> and the digital frames <highlight><bold>126</bold></highlight> is matched to ensure synchronization of the playing frames. The time stamp references associated with each frame preserve the time-based ordering associated with the original video and audio information. The reduced size of the stored information may result in an enormous improvement over the computer information storage required to operate fast forward or fast backward operations of the prior art. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> In the present embodiment examples of the computer system <highlight><bold>500</bold></highlight>, as described with reference to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, include the initiating computer system <highlight><bold>105</bold></highlight>, the data server computer system <highlight><bold>110</bold></highlight>, and the client computer system <highlight><bold>115</bold></highlight>. Those skilled in the art will recognize that any combination of the components, or any number of different components, peripherals, and other devices, may be used with the initiating computer system <highlight><bold>105</bold></highlight>, the data server computer system <highlight><bold>110</bold></highlight>, and the client computer system <highlight><bold>115</bold></highlight>. Those skilled in the art will also recognize that the present invention may be implemented on a single computer system or any number of computer systems that are networked together. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram that illustrates, as shown in element <highlight><bold>200</bold></highlight>, the association between the encoded video frames <highlight><bold>120</bold></highlight>, the encoded audio frames <highlight><bold>125</bold></highlight>, the playback video frames <highlight><bold>145</bold></highlight>, and the playback audio frames <highlight><bold>150</bold></highlight>. The encoded video frames <highlight><bold>120</bold></highlight> may be associated with the encoded audio frames <highlight><bold>125</bold></highlight> in order to synchronize the frames. For example, encoded video frame(<highlight><bold>1</bold></highlight>) <highlight><bold>210</bold></highlight> and encoded audio frame(<highlight><bold>1</bold></highlight>) <highlight><bold>212</bold></highlight> may each include a location identifier <highlight><bold>305</bold></highlight> (as shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>), such as a time stamp. Then encoded video frame(<highlight><bold>1</bold></highlight>) <highlight><bold>210</bold></highlight> and encoded frame audio frame(<highlight><bold>1</bold></highlight>) <highlight><bold>212</bold></highlight> may be synchronized, even after multiplexed transmission, by matching the associated location identifiers <highlight><bold>305</bold></highlight>. Those skilled in the art will recognize that the association between the encoded video frames <highlight><bold>120</bold></highlight> and the encoded audio frames <highlight><bold>125</bold></highlight> does not have to be one-to one since the audio information may be represented by audio samples that are a portion of the available audio information. Likewise, the association between the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight> does not have to be one-to-one. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> Low resolution, compressed playback frames are translated from encoded digital frames <highlight><bold>126</bold></highlight> to form a compressed playback frame stream <highlight><bold>225</bold></highlight> that represents a subset of the digital information. For example, JPEG images could be captured for every third, fourth, or sixth video frame <highlight><bold>120</bold></highlight> and stored into the playback frame stream <highlight><bold>225</bold></highlight>. Then as these images are displayed in sequence they appear to be displaying the video information at three-times, four-times, or six-times faster than normal, respectively. Additional speeds could be generated by skipping over frames and only displaying identified frames to achieve a wide range of display speeds, again in either forward or reverse order. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Alternately, low resolution, compressed playback audio frames <highlight><bold>150</bold></highlight> are translated from the encoded digital audio frames <highlight><bold>125</bold></highlight>. Therefore, the present invention also enables quick location of digital audio frames <highlight><bold>125</bold></highlight> by the use of audio cues included in the playback audio frames <highlight><bold>150</bold></highlight> by use of matching location identifiers <highlight><bold>305</bold></highlight>. That is, the digital encoded audio frames <highlight><bold>125</bold></highlight> can be compressed and sub-sampled to enable indexing by the client computer system <highlight><bold>115</bold></highlight> (as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>) of the playback audio frames <highlight><bold>150</bold></highlight>. Therefore, the location identifier <highlight><bold>305</bold></highlight> associated with the sub-sampled digital encoded audio frames <highlight><bold>125</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight> may be compared to synchronize the playing location. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> By means of example, in an embodiment of the present invention playing the compressed information results in a three-times speed increase over the playing rate of the digital video and audio information. Therefore the playback frame stream <highlight><bold>225</bold></highlight> includes every third frame in a compressed frame format. Now, the encoded video frame(<highlight><bold>1</bold></highlight>) <highlight><bold>210</bold></highlight> is associated with the playback video frame(<highlight><bold>1</bold></highlight>) <highlight><bold>230</bold></highlight> and every third encoded video frame is then associated with a playback video frame <highlight><bold>145</bold></highlight>. So, encoded video frame(n&minus;<highlight><bold>3</bold></highlight>) <highlight><bold>235</bold></highlight> is associated with playback video frame(n&minus;<highlight><bold>3</bold></highlight>) <highlight><bold>240</bold></highlight>, and encoded video frame(n) <highlight><bold>245</bold></highlight> is associated with encoded video frame(n) <highlight><bold>250</bold></highlight>, if &ldquo;n&rdquo; is divisible by three. The procedure is similar for the playback audio frames <highlight><bold>150</bold></highlight>. Therefore the encoded audio frame(<highlight><bold>1</bold></highlight>) <highlight><bold>212</bold></highlight> is associated with the playback audio frame(<highlight><bold>1</bold></highlight>) <highlight><bold>255</bold></highlight> and every third encoded audio frame <highlight><bold>125</bold></highlight> is then associated with a playback audio frame <highlight><bold>150</bold></highlight>. So, encoded audio frame(n&minus;<highlight><bold>3</bold></highlight>) <highlight><bold>260</bold></highlight> is associated with playback audio frame(n&minus;<highlight><bold>3</bold></highlight>) <highlight><bold>265</bold></highlight>, and encoded audio frame(n) <highlight><bold>270</bold></highlight> is associated with playback audio frame(n) <highlight><bold>275</bold></highlight>, if &ldquo;n&rdquo; is divisible by three. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram that in element <highlight><bold>300</bold></highlight> illustrates the presentation of information to the user. The preferred embodiment presents the information on the client computer system <highlight><bold>115</bold></highlight>. It will be appreciated that the information could be presented on another computer system, such as the initiating computer system <highlight><bold>105</bold></highlight> or the data server computer system <highlight><bold>110</bold></highlight>. For example, the user could be presented with both the normal digital window <highlight><bold>320</bold></highlight> and a special preview window <highlight><bold>325</bold></highlight> that enables trick mode viewing. The preview window <highlight><bold>325</bold></highlight> enables fast previewing and VTR-like browsing of the playback audio <highlight><bold>150</bold></highlight> and video frames <highlight><bold>145</bold></highlight> that are associated with the digital frames that may be streamed to the client computer system <highlight><bold>115</bold></highlight>. Alternately these windows could be overlaid or combined to achieve the appropriate function. This will allow the user to quickly locate a position in the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight> and then access the associated position in the digital audio frames <highlight><bold>140</bold></highlight> and the digital video frames <highlight><bold>135</bold></highlight> that are presented in full resolution mode. The encoded playback frames <highlight><bold>161</bold></highlight> are typically stored on the data storage device <highlight><bold>130</bold></highlight> and may be decoded for presentation via the preview window <highlight><bold>325</bold></highlight>. Elements <highlight><bold>105</bold></highlight>, <highlight><bold>110</bold></highlight>, and <highlight><bold>161</bold></highlight> are also described with reference to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> The user can indicate that the presentation of either the digital window <highlight><bold>320</bold></highlight> or the preview window <highlight><bold>325</bold></highlight> should be changed. The new location can be identified by the user via movement throughout the frames that are played via the preview window <highlight><bold>325</bold></highlight>. The location identifier <highlight><bold>305</bold></highlight> that facilitates synchronizing the playing location of the digital audio frames <highlight><bold>140</bold></highlight>, the digital video frames <highlight><bold>135</bold></highlight>, the playback video frames <highlight><bold>145</bold></highlight>, and the playback audio frames <highlight><bold>150</bold></highlight> could be a time stamp or other location identification information. In the present embodiment, the user input device <highlight><bold>310</bold></highlight> is used to indicate that the preview window <highlight><bold>325</bold></highlight> or the digital window <highlight><bold>320</bold></highlight> should be changed and to indicate that a new location for the presentation is desired. The user may indicate in the preview frame <highlight><bold>325</bold></highlight> that the location playing should be changed. The user input device functions may be accomplished by any method known in the art such as a slider switch, a knob, a joy-stick, or any other technique whether known now or developed in the future. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flow diagram that illustrates the present invention. The preferred embodiment of the present invention as shown in element <highlight><bold>400</bold></highlight>, accesses encoded digital video frames <highlight><bold>120</bold></highlight>, as shown in element <highlight><bold>405</bold></highlight>, and digital audio frames <highlight><bold>125</bold></highlight> as shown in element <highlight><bold>410</bold></highlight>. The digital video frames <highlight><bold>135</bold></highlight> are typically differentially encoded, by compressing the information and including differential positional information. The digital audio frames <highlight><bold>140</bold></highlight> are typically compressed. A subset of the encoded digital video frames <highlight><bold>120</bold></highlight> are identified for compressed video playback encoding, as shown in element <highlight><bold>415</bold></highlight>. Similarly, a subset of the encoded digital audio frames <highlight><bold>125</bold></highlight> are processed and identified for compressed audio playback encoding, as shown in element <highlight><bold>420</bold></highlight>. For each of the identified encoded digital video frames <highlight><bold>120</bold></highlight> the associated compressed playback video frame <highlight><bold>145</bold></highlight> is encoded, as shown in element <highlight><bold>425</bold></highlight>. Likewise, for each of the identified encoded digital audio frames <highlight><bold>125</bold></highlight> the associated compressed playback audio frame <highlight><bold>150</bold></highlight> is encoded, as shown in element <highlight><bold>430</bold></highlight>. By means of example, an evenly spaced subset of the digital frames may be identified as appropriate for compressed encoding. Then the amount of compressed frame data is smaller than the associated digital frame data. Therefore, playing of the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight> will result in a fast-speed presentation of the data that is suitable for trick mode operations. Elements <highlight><bold>120</bold></highlight>, <highlight><bold>125</bold></highlight>, <highlight><bold>135</bold></highlight>, <highlight><bold>140</bold></highlight>, <highlight><bold>145</bold></highlight>, and <highlight><bold>150</bold></highlight> are described with reference to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> According to an embodiment of the present invention as shown in element <highlight><bold>435</bold></highlight>, when the encoded playback video <highlight><bold>145</bold></highlight> and playback audio frames <highlight><bold>150</bold></highlight> are not multiplexed, they are downloaded from the initiating computer system <highlight><bold>105</bold></highlight> to the data server computer system <highlight><bold>110</bold></highlight>. Then, the encoded digital video frames <highlight><bold>120</bold></highlight>, digital audio frames <highlight><bold>125</bold></highlight>, and encoded playback frames <highlight><bold>161</bold></highlight> are multiplexed by methods known to those skilled in the art, as shown in element <highlight><bold>440</bold></highlight>. It will be appreciated that multiplexing the encoded playback frames <highlight><bold>161</bold></highlight> is optional. Then, the multiplexed digital frames <highlight><bold>162</bold></highlight> are transmitted by streaming from the initiating computer system <highlight><bold>105</bold></highlight> to the client computer system <highlight><bold>115</bold></highlight>, as shown in element <highlight><bold>445</bold></highlight>. Also, if the playback frames <highlight><bold>163</bold></highlight> have been multiplexed they are downloaded to the data server computer system <highlight><bold>110</bold></highlight> or the client computer system <highlight><bold>115</bold></highlight>, as shown in element <highlight><bold>447</bold></highlight>. Then, if there are multiplexed playback frames <highlight><bold>163</bold></highlight> they, along with the multiplexed digital frames <highlight><bold>162</bold></highlight>, are de-multiplexed as shown in element <highlight><bold>450</bold></highlight>. The encoded digital frames <highlight><bold>126</bold></highlight> and the encoded playback frames <highlight><bold>161</bold></highlight> are also decoded, as shown in element <highlight><bold>455</bold></highlight>. Now the client computer system <highlight><bold>115</bold></highlight> may process the digital video frames <highlight><bold>135</bold></highlight>, the digital audio frames <highlight><bold>140</bold></highlight>, the playback video frames <highlight><bold>145</bold></highlight>, and the playback audio frames <highlight><bold>150</bold></highlight>, typically by incrementally playing the information so that the user can see and hear the digital and audio information. Elements <highlight><bold>105</bold></highlight>, <highlight><bold>110</bold></highlight>, <highlight><bold>115</bold></highlight>, <highlight><bold>126</bold></highlight>, <highlight><bold>161</bold></highlight>, <highlight><bold>162</bold></highlight>, and <highlight><bold>163</bold></highlight> are described with reference to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> Synchronization of the digital frames and the compressed frames is important and as shown in element <highlight><bold>460</bold></highlight>, the present embodiment synchronizes the playing of the playback video frames <highlight><bold>145</bold></highlight>, the playback audio frames <highlight><bold>150</bold></highlight>, the digital video frames <highlight><bold>135</bold></highlight>, and the digital audio frames <highlight><bold>140</bold></highlight>. Typically synchronization of the playing of the frames is enabled by using a time stamp identifier. The time stamp identifier is associated with each frame. Synchronization is enabled by identifying the frames with the same time stamp identifier and ensuring that the playing of each frame is timed to occur at the proper time as referenced on the time stamp identifier. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> If directed by a user, the present embodiment will incrementally play the digital video frames <highlight><bold>135</bold></highlight> and the digital audio frames <highlight><bold>140</bold></highlight>. Alternately the user may direct the playing of the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight>. The user may switch between each alternative. This user direction is shown in element <highlight><bold>465</bold></highlight>. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> The user may change the location of playing the playback video frames <highlight><bold>145</bold></highlight> and playback audio frames <highlight><bold>150</bold></highlight>. When a location change has occurred and the playing is switched to playing the digital video frames <highlight><bold>135</bold></highlight> and the digital audio frames <highlight><bold>150</bold></highlight> the present invention ensures that the location now matches the most recent playing location of the playback video frames <highlight><bold>145</bold></highlight> and the playback audio frames <highlight><bold>150</bold></highlight>. This is shown in element <highlight><bold>470</bold></highlight>. This enables quick location of playback video frames <highlight><bold>145</bold></highlight> and playback audio frames <highlight><bold>150</bold></highlight> for customized scanning. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a block diagram of a computer system <highlight><bold>500</bold></highlight>, suitable for employment of the present invention. System <highlight><bold>500</bold></highlight> may be implemented on a general-purpose microcomputer, such as one of the members of the IBM Personal Computer family, or other conventional work-station or graphics computer device. In its preferred embodiment, system <highlight><bold>500</bold></highlight> includes a user interface <highlight><bold>505</bold></highlight>, a user input device <highlight><bold>310</bold></highlight>, a display <highlight><bold>515</bold></highlight>, a printer <highlight><bold>520</bold></highlight>, a processor <highlight><bold>555</bold></highlight>, a read only memory (ROM) <highlight><bold>550</bold></highlight>, a data storage device <highlight><bold>130</bold></highlight>, such as a hard drive, a random access memory (RAM) <highlight><bold>540</bold></highlight>, and a storage media interface <highlight><bold>535</bold></highlight>, all of which are coupled to a bus <highlight><bold>525</bold></highlight> or other communication means for communicating information. Although system <highlight><bold>500</bold></highlight> is represented herein as a standalone system, it is not limited to such, but instead can be part of a networked system. For example, the computer system <highlight><bold>500</bold></highlight> may be connected locally or remotely to fixed or removable data storage devices <highlight><bold>130</bold></highlight> and data transmission devices <highlight><bold>197</bold></highlight>. For example, the initiating computer system <highlight><bold>105</bold></highlight>, the data server computer system <highlight><bold>110</bold></highlight>, and the client computer system <highlight><bold>115</bold></highlight> also could be connected to other computer systems via the data transmission devices <highlight><bold>197</bold></highlight>. Elements <highlight><bold>105</bold></highlight>, <highlight><bold>110</bold></highlight>, <highlight><bold>115</bold></highlight>, <highlight><bold>130</bold></highlight>, and <highlight><bold>197</bold></highlight> are described with reference to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The RAM <highlight><bold>540</bold></highlight>, the data storage device <highlight><bold>130</bold></highlight> and the ROM <highlight><bold>550</bold></highlight>, are memory components <highlight><bold>558</bold></highlight> that store data and instructions for controlling the operation of processor <highlight><bold>555</bold></highlight>, which may be configured as a single processor or as a plurality of processors. The processor <highlight><bold>555</bold></highlight> executes a program <highlight><bold>542</bold></highlight> to perform the methods of the present invention, as described herein. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> While the program <highlight><bold>542</bold></highlight> is indicated as loaded into the RAM <highlight><bold>540</bold></highlight>, it may be configured on a storage media <highlight><bold>530</bold></highlight> for subsequent loading into the data storage device <highlight><bold>130</bold></highlight>, the ROM <highlight><bold>550</bold></highlight>, or the RAM <highlight><bold>540</bold></highlight> via an appropriate storage media interface <highlight><bold>535</bold></highlight>. Storage media <highlight><bold>530</bold></highlight> can be any conventional storage media such as a magnetic tape, an optical storage media, a compact disk, or a floppy disk. Alternatively, storage media <highlight><bold>530</bold></highlight> can be a random access memory <highlight><bold>540</bold></highlight>, or other type of electronic storage, located on a remote storage system. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Generally, the computer programs and operating systems are all tangibly embodied in a computer-readable device or media, such as the memory <highlight><bold>558</bold></highlight>, the data storage device <highlight><bold>130</bold></highlight>, or the data transmission devices <highlight><bold>197</bold></highlight>, thereby making an article of manufacture, such as a computer program product, according to the invention. As such, the terms &ldquo;computer program product&rdquo; as used herein are intended to encompass a computer program accessible from any computer readable device or media. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Moreover, the computer programs <highlight><bold>542</bold></highlight> and operating systems are comprised of instructions which, when read and executed by the initiating computer system <highlight><bold>105</bold></highlight>, the data server computer system <highlight><bold>110</bold></highlight>, and the client computer system <highlight><bold>115</bold></highlight>, cause the initiating computer system <highlight><bold>105</bold></highlight>, the data server computer system <highlight><bold>110</bold></highlight>, and the client computer system <highlight><bold>115</bold></highlight> to perform the steps necessary to implement and use the present invention. Under control of the operating system, the computer programs <highlight><bold>542</bold></highlight> may be loaded from the memory <highlight><bold>558</bold></highlight>, the data storage device <highlight><bold>130</bold></highlight>, or the data transmission devices <highlight><bold>197</bold></highlight> into the memories <highlight><bold>558</bold></highlight> of the initiating computer system <highlight><bold>105</bold></highlight>, the data server computer system <highlight><bold>110</bold></highlight>, and the client computer system <highlight><bold>115</bold></highlight> for use during actual operations. Those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope of the present invention. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> User interface <highlight><bold>505</bold></highlight> is an input device, such as a keyboard or speech recognition subsystem, for enabling a user to communicate information and command selections to the processor <highlight><bold>555</bold></highlight>. The user can observe information generated by the system <highlight><bold>500</bold></highlight> via the display <highlight><bold>515</bold></highlight> or the printer <highlight><bold>520</bold></highlight>. The user input device <highlight><bold>310</bold></highlight> is a device such as a mouse, track-ball, or joy stick, that allows the user to manipulate a cursor on the display <highlight><bold>515</bold></highlight> for communicating additional information and command selections to the processor <highlight><bold>555</bold></highlight>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> When operating in accordance with one embodiment of the present invention, system <highlight><bold>500</bold></highlight> selects a function for use in producing low resolution, compressed frames from encoded digital video <highlight><bold>120</bold></highlight> or audio information <highlight><bold>125</bold></highlight> (as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>). The processor <highlight><bold>555</bold></highlight> and the program <highlight><bold>542</bold></highlight> collectively operate as a module for fast and efficient playback of video and audio information at non-standard, trick mode speeds. It will be appreciated that the present invention offers many advantages over prior art techniques. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> The present invention is typically implemented using one or more computer programs, each of which executes under the control of an operating system and causes the initiating computer system <highlight><bold>105</bold></highlight>, the data server computer system <highlight><bold>110</bold></highlight>, and the client computer system <highlight><bold>115</bold></highlight> to perform the desired functions as described herein. Thus, using the present specification, the invention may be implemented as a machine, process, method, system, or article of manufacture by using standard programming and engineering techniques to produce software, firmware, hardware or any combination thereof. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> It should be understood that various alternatives and modifications can be devised by those skilled in the art. However, these should not be viewed as limitations upon the practice of these teachings, as those skilled in the art, when guided by the foregoing teachings, may derive other suitable characteristics of a similar or different nature. The present invention is intended to embrace all such alternatives, modifications and variances that fall within the scope of the appended claims </paragraph>
</section>
<section>
<heading lvl="1">Trademarks </heading>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> IBM is a trademark or registered trademark of International Business machines, Corporation in the United States and other countries. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> MPEG is a trademark or registered trademark of Philips Electronics N.V. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">We claim: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A computer implemented method for facilitating trick mode playback for a user, comprising: 
<claim-text>accessing a plurality of encoded digital video frames on a first computer system; </claim-text>
<claim-text>identifying a subset of said encoded digital video frames for compressed video encoding; </claim-text>
<claim-text>for all said identified encoded digital video frames, encoding an associated playback video frame; </claim-text>
<claim-text>downloading said encoded playback video frames on a second computer system; </claim-text>
<claim-text>streaming said encoded digital video frames to said second computer system; </claim-text>
<claim-text>decoding said digital video frames and said playback video frames; </claim-text>
<claim-text>if said user directs, incrementally playing said digital video frames or said playback video frames; </claim-text>
<claim-text>enabling said user to switch between playing said digital video frames and said playback video frames; </claim-text>
<claim-text>enabling said user to change location of playing said playback video frames; and </claim-text>
<claim-text>when switching from playing said playback video frames to playing said digital video frames, matching playing of said digital video frames with said location of playing said playback video frames. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising said second computer system including a data server computer system and a client computer system. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising said first computer system including an initiating computer system and a data server computer system. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising, when said user directs incrementally playing said playback video frames, enabling said user to direct playing of said playback video frames in either a forward direction or a reverse direction. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising: 
<claim-text>playing said digital video frames via a digital window on said second computer system; and </claim-text>
<claim-text>playing said playback video frames via a preview window on said second computer system. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising: 
<claim-text>playing said digital video frames via a digital window on said second computer system; and </claim-text>
<claim-text>playing said playback video frames via overlaying a preview window on said digital window. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A computer implemented method for facilitating fast audio playback for a user, comprising: 
<claim-text>accessing a plurality of encoded digital audio frames on a first computer system; </claim-text>
<claim-text>identifying a subset of said encoded digital audio frames for compressed audio encoding; </claim-text>
<claim-text>for all said identified encoded digital audio frames, encoding an associated playback audio frame; </claim-text>
<claim-text>downloading said encoded playback audio frames on a second computer system; </claim-text>
<claim-text>streaming said encoded digital audio frames to said second computer system; </claim-text>
<claim-text>decoding said digital audio frames and said playback audio frames; </claim-text>
<claim-text>if said user directs, incrementally playing said digital audio frames or said playback audio frames; </claim-text>
<claim-text>enabling said user to switch between playing said digital audio frames and said playback audio frames; </claim-text>
<claim-text>enabling said user to change location of playing said playback audio frames; and </claim-text>
<claim-text>when switching from playing said playback audio frames to playing said digital audio frames, matching playing of said digital audio frames with said location of playing of said playback audio frames. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> further comprising said second computer system including a data server computer system and a client computer system. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> further comprising said first computer system including an initiating computer system and a data server computer system. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> further comprising: 
<claim-text>playing said digital audio frames via a digital window on said second computer system; and </claim-text>
<claim-text>playing said playback audio frames via a preview window on said second computer system. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> further comprising: 
<claim-text>associating audio attributes with said playback audio frames; and </claim-text>
<claim-text>representing said associated audio attributes on said preview window. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A computer implemented method for facilitating trick mode playback for a user, comprising: 
<claim-text>accessing a plurality of encoded digital video frames and a plurality of encoded digital audio frames on a first computer system; </claim-text>
<claim-text>identifying a subset of said encoded digital video frames for compressed video encoding; </claim-text>
<claim-text>identifying a subset of said encoded digital audio frames for compressed audio encoding; </claim-text>
<claim-text>for all said identified encoded digital video frames, encoding an associated playback video frame; </claim-text>
<claim-text>for all said identified encoded digital audio frames, encoding an associated playback audio frame; </claim-text>
<claim-text>downloading said encoded playback video frames and said encoded playback audio frames on a second computer system; </claim-text>
<claim-text>multiplexing said encoded digital video frames and said encoded digital audio frames on said first computer system; </claim-text>
<claim-text>streaming said multiplexed digital frames to said second computer system; </claim-text>
<claim-text>de-multiplexing said multiplexed digital frames; </claim-text>
<claim-text>decoding said encoded digital video frames, said encoded digital audio frames, said </claim-text>
<claim-text>encoded playback video frames, and said encoded playback audio frames; and </claim-text>
<claim-text>if said user directs: 
<claim-text>synchronizing said digital video frames and said digital audio frames and playing said synchronized digital video frames and digital audio frames; or </claim-text>
<claim-text>synchronizing said playback video frames and said playback audio frames and playing said synchronized playback video frames and playback audio frames; </claim-text>
</claim-text>
<claim-text>enabling said user to switch between playing said synchronized digital video frames and digital audio frames and said synchronized playback video frames and playback audio frames; </claim-text>
<claim-text>enabling said user to change location of playing said synchronized playback video frames and playback audio frames; and </claim-text>
<claim-text>when switching to playing said synchronized digital video frames and digital audio frames, matching playing of said synchronized digital video frames and digital audio frames with said location of playing of said synchronized playback video frames and playback audio frames. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> further comprising said second computer system including a data server computer system and a client computer system. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> further comprising said first computer system including an initiating computer system and a data server computer system. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> further comprising: 
<claim-text>playing said synchronized digital video frames and digital audio frames via a digital window on said second computer system; and </claim-text>
<claim-text>playing said synchronized playback video frames and playback audio frames via a preview window on said second computer system. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> further comprising: 
<claim-text>playing said synchronized digital video frames and digital audio frames via a digital window on said second computer system; and </claim-text>
<claim-text>playing said synchronized playback video frames and playback audio frames via overlaying a preview window on said digital window. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A computer implemented method for facilitating trick mode playback on a computer system for a user, comprising: 
<claim-text>accessing a plurality of encoded digital video frames; </claim-text>
<claim-text>identifying a subset of said encoded digital video frames for compressed video encoding; </claim-text>
<claim-text>for all said identified encoded digital video frames, encoding an associated playback video frame; </claim-text>
<claim-text>downloading said encoded playback video frames on said computer system; </claim-text>
<claim-text>decoding said digital video frames and said playback video frames on said computer system; </claim-text>
<claim-text>if said user directs, incrementally playing said digital video frames or said playback video frames; </claim-text>
<claim-text>enabling said user to switch between playing said digital video frames and said playback video frames; </claim-text>
<claim-text>enabling said user to change location of playing said playback video frames; and </claim-text>
<claim-text>when switching from playing said playback video frames to playing said digital video frames, matching playing of said digital video frames with said location of playing said playback video frames. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A computer implemented method for facilitating fast audio playback on a computer system for a user, comprising: 
<claim-text>accessing a plurality of encoded digital audio frames; </claim-text>
<claim-text>identifying a subset of said encoded digital audio frames for compressed audio encoding; </claim-text>
<claim-text>for all said identified encoded digital audio frames, encoding an associated playback audio frame; </claim-text>
<claim-text>downloading said encoded playback audio frames on said computer system; </claim-text>
<claim-text>decoding said digital audio frames and said playback audio frames on said computer system; </claim-text>
<claim-text>if said user directs, incrementally playing said digital audio frames or said playback audio frames; </claim-text>
<claim-text>enabling said user to switch between playing said digital audio frames and said playback audio frames; </claim-text>
<claim-text>enabling said user to change location of playing said playback audio frames; and </claim-text>
<claim-text>when switching from playing said playback audio frames to playing said digital audio frames, matching playing of said digital audio frames with said location of playing of said playback audio frames. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. An article of manufacture comprising a program storage medium readable by a computer and embodying one or more instructions executable by said computer for causing a computer system to facilitate trick mode playback for a user, comprising: 
<claim-text>accessing a plurality of encoded digital video frames on a first computer system; </claim-text>
<claim-text>identifying a subset of said encoded digital video frames for compressed video encoding; </claim-text>
<claim-text>for all said identified encoded digital video frames, encoding an associated playback video frame; </claim-text>
<claim-text>downloading said encoded playback video frames on a second computer system; </claim-text>
<claim-text>streaming said encoded digital video frames to said second computer system; </claim-text>
<claim-text>decoding said digital video frames and said playback video frames; </claim-text>
<claim-text>if said user directs, incrementally playing said digital video frames or said playback video frames; </claim-text>
<claim-text>enabling said user to switch between playing said digital video frames and said playback video frames; </claim-text>
<claim-text>enabling said user to change location of playing said playback video frames; and </claim-text>
<claim-text>when switching from playing said playback video frames to playing said digital video frames, matching playing of said digital video frames with said location of playing said playback video frames. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The article of manufacture of <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> further comprising said second computer system including a data server computer system and a client computer system. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The article of manufacture of <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> further comprising said first computer system including an initiating computer system and a data server computer system. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. An article of manufacture comprising a program storage medium readable by a computer and embodying one or more instructions executable by said computer for causing a computer system to facilitate fast audio playback for a user, comprising: 
<claim-text>accessing a plurality of encoded digital audio frames on a first computer system; </claim-text>
<claim-text>identifying a subset of said encoded digital audio frames for compressed audio encoding; </claim-text>
<claim-text>for all said identified encoded digital audio frames, encoding an associated playback audio frame; </claim-text>
<claim-text>downloading said encoded playback audio frames on a second computer system; </claim-text>
<claim-text>streaming said encoded digital audio frames to said second computer system; </claim-text>
<claim-text>decoding said digital audio frames and said playback audio frames; </claim-text>
<claim-text>if said user directs, incrementally playing said digital audio frames or said playback audio frames; </claim-text>
<claim-text>enabling said user to switch between playing said digital audio frames and said playback audio frames; </claim-text>
<claim-text>enabling said user to change location of playing said playback audio frames; and </claim-text>
<claim-text>when switching from playing said playback audio frames to playing said digital audio frames, matching playing of said digital audio frames with said location of playing of said playback audio frames. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference> further comprising said second computer system including a data server computer system and a client computer system. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference> further comprising said first computer system including an initiating computer system and a data server computer system. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A computer system for facilitating trick mode playback for a user, comprising: 
<claim-text>a plurality of encoded digital video frames on a first said computer system; </claim-text>
<claim-text>a subset of said encoded digital video frames that are identified for compressed video encoding; </claim-text>
<claim-text>for all said identified encoded digital video frames, an associated encoded playback video frame; </claim-text>
<claim-text>said encoded playback video frames that are downloaded on a second said computer system; </claim-text>
<claim-text>said encoded digital video frames that are streamed to said second computer system; </claim-text>
<claim-text>said digital video frames that are decoded from said encoded digital video frames; </claim-text>
<claim-text>said playback video frames that are decoded from said encoded playback video frames; </claim-text>
<claim-text>while said user directs: 
<claim-text>said digital video frames being incrementally played on said second computer system; or </claim-text>
<claim-text>said playback video frames being incrementally played on said second computer system; </claim-text>
</claim-text>
<claim-text>a location of playing said playback video frames being changed by said user; and </claim-text>
<claim-text>said location of playing facilitating synchronized playing of said digital video frames when said user directs playing said digital video frames after playing said playback video frames. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The computer system of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> further comprising said second computer system including a data server computer system and a client computer system. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The computer system of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> further comprising said first computer system including an initiating computer system and a data server computer system. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. A computer system for facilitating fast audio playback for a user, comprising: 
<claim-text>a plurality of encoded digital audio frames on a first said computer system; </claim-text>
<claim-text>a subset of said encoded digital audio frames that are identified for compressed audio encoding; </claim-text>
<claim-text>for all said identified encoded digital audio frames, an associated encoded playback audio frame; </claim-text>
<claim-text>said encoded playback audio frames that are downloaded on a second said computer system; </claim-text>
<claim-text>said encoded digital audio frames that are streamed to said second computer system; </claim-text>
<claim-text>said digital audio frames that are decoded from said encoded digital audio frames; </claim-text>
<claim-text>said playback audio frames that are decoded from said encoded playback audio frames; </claim-text>
<claim-text>while said user directs: 
<claim-text>said digital audio frames being incrementally played on said second computer system; or </claim-text>
<claim-text>said playback audio frames being incrementally played on said second computer system; </claim-text>
</claim-text>
<claim-text>a location of playing said playback audio frames being changed by said user; and </claim-text>
<claim-text>said location of playing facilitating synchronized playing of said digital audio frames when said user directs playing said digital audio frames after playing said playback audio frames. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The computer system of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> further comprising said second computer system including a data server computer system and a client computer system. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The computer system of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> further comprising said first computer system including an initiating computer system and a data server computer system.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002854A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002854A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002854A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002854A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002854A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002854A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
