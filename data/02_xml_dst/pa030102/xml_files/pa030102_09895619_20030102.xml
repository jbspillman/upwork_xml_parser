<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004912A1-20030102-D00000.TIF SYSTEM "US20030004912A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004912A1-20030102-D00001.TIF SYSTEM "US20030004912A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004912A1-20030102-D00002.TIF SYSTEM "US20030004912A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004912A1-20030102-D00003.TIF SYSTEM "US20030004912A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004912A1-20030102-D00004.TIF SYSTEM "US20030004912A1-20030102-D00004.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004912</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09895619</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010629</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06N005/02</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>706</class>
<subclass>047000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Architecture for intelligent agents and distributed platform therefor</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Lalit</given-name>
<family-name>Pant</family-name>
</name>
<residence>
<residence-us>
<city>Monroeville</city>
<state>PA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Rahul</given-name>
<family-name>Tripathi</family-name>
</name>
<residence>
<residence-us>
<city>Pittsburgh</city>
<state>PA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Richendra</given-name>
<family-name>Khanna</family-name>
</name>
<residence>
<residence-us>
<city>Pittsburgh</city>
<state>PA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Vineet</given-name>
<family-name>Manohar</family-name>
</name>
<residence>
<residence-us>
<city>Monroeville</city>
<state>PA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>BUCHANAN INGERSOLL, P.C.</name-1>
<name-2></name-2>
<address>
<address-1>ONE OXFORD CENTRE, 301 GRANT STREET</address-1>
<address-2>20TH FLOOR</address-2>
<city>PITTSBURGH</city>
<state>PA</state>
<postalcode>15219</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Disclosed is an architecture for an intelligent agent and for a distributed platform for supporting many of such agents. Also described are scenarios wherein intelligent agents may be used. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This invention relates to the field of artificial intelligence, and, in particular, to software objects commonly known as intelligent agents. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The web is fast evolving from being a repository of information for human consumption&mdash;the syntactic web&mdash;to something that carries much richer forms of information&mdash;the semantic web. To make optimal use of the new kind of information, a new kind of intelligent program, often referred to as an agent, is required. Systems based on agent technology will be the building blocks of the intelligent web of the future. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The World Wide Web is both a massive repository of information, and an enabler of a large number and variety of e-services. Many products and services, for example, books, airline tickets, banking, encyclopedias, auctions and trading hubs, are available on the web. Most of the information available on the web has just a few common essential characteristics: </paragraph>
<paragraph id="P-0004" lvl="2"><number>&lsqb;0004&rsqb;</number> It is unstructured </paragraph>
<paragraph id="P-0005" lvl="2"><number>&lsqb;0005&rsqb;</number> It is transmitted around in chunks called pages using a simple protocol called HTTP </paragraph>
<paragraph id="P-0006" lvl="2"><number>&lsqb;0006&rsqb;</number> These pages are marked-up in a format called Hypertext Mark-Up Language (HTML) that is geared towards presentation to human beings </paragraph>
<paragraph id="P-0007" lvl="2"><number>&lsqb;0007&rsqb;</number> HTML allows easy linking of content in one document to content in another document </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The uncomplicated nature of the web content creation process, combined with the simplicity, expressiveness and power of web transport and presentation technology, has led to an explosion in the size of the web and the information available thereon. It has given an enormous number of people the ability to move around in the web using inexpensive computers and a piece of software called a browser. But now, as the web stretches to accommodate new kinds of business-related applications, some of these characteristics that make the web so attractive are starting to become a bottleneck. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> One fundamental problem is that the web, in its current incarnation, is really geared towards presenting information to human beings. The default language of the web&mdash;HTML&mdash;essentially describes how the information on a web page is to be presented by a browser for consumption by a human being. However, all of the interesting, powerful interactions between computer systems in the world today happen in islands of information. As soon as information passes through a web front-end in the form of HTML, the ability of non-humans to make use of this information is decreased dramatically. The web, in its current incarnation, is not very friendly to the programs trying to access and use the vast amounts of information that it contains. Ironically, given the heterogeneity and volume of this information, it is precisely these programs that can bring out the most value from the information. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> One solution to this problem is provided by XML. XML allows us to mark-up information with syntax that is meaningful in a specific domain. When this domain-specific syntax is combined with associated semantics, all of the prerequisites that are necessary for programs to really go out and make full use of the information on the web are present&mdash;thereby providing tremendous value to consumers, businesses, individuals and organizations. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> A key element for communications between non-humans is something known as an ontology. Basically, an ontology is the specification of a model for the language of a domain. The main purpose of an ontology is to enable communication between programs in a way that is independent of the architecture and the implementation of the programs. The key ingredients that make up an ontology are a vocabulary of basic terms and a precise specification of what those terms means. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> The concept of an ontology is a key enabler for large scale internet commerce. Even though XML goes a long way towards solving the problem with HTML, XML by itself is not enough. XML allows us to mark-up information in a domain specific manner using tags defined for that domain. But, unless programs that use this domain specific language for communication can agree on the &lsquo;meaning&rsquo; of these tags, they can&apos;t really interact effectively. The ontology is able to bridge this gap by providing an exact specification of the meaning of domain-specific XML tags with which content is marked-up. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> CommerceOne, Rosetta-Net, cXML and ebXML are examples of initiatives in this direction. The primary purpose of these initiatives is to provide global online vocabularies and ontologies for different business domains, so that programs can start communicating over the web in a much more meaningful and powerful manner. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Intelligent agents are the software programs that will be able to take advantage of the web using the defined ontologies. However, before such systems can become a reality, a powerful general-purpose technology infrastructure is required for developing and deploying agents. This patent discloses an infrastructural technology, in the form of a generic agent architecture upon which domain-specific intelligent agents can be built and a distributed artificial intelligence platform upon which the intelligent agents can be deployed. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The distributed artificial intelligence platform disclosed herein includes a very scalable distributed architecture capable of simultaneously running millions of context monitoring agents. The architecture has built-in support for fault tolerance in the face of software and hardware failures, and allows for the transparent resurrection of agents on different hosts if the server they are running on goes down, in a manner that is guaranteed to preserve semantic correctness. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Also included a general-purpose layered agent architectural framework, which includes core technology for reasoning, planning, optimization, constraint satisfaction, communication, workflow management, and learning. Using this framework, domain-specific technology can be easily embedded inside different kinds of agents. Equipped with the abilities provided by these core technology building-blocks, agents deployed on the platform will have the ability to define and fully participate in the next generation of intelligent distributed systems running on the semantic web.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows the layered architecture of an intelligent agent according to this invention. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a detailed architectural diagram of an agent, showing the movement of events and messages. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows the components of a distributed platform to support intelligent agents. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows the flow of data within the distributed platform.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The word agent is a heavily over-used one, and over the years many definitions have been given for the term. For purposes of this disclosure, we consider an agent to be a computer program having the characteristics of autonomy, reactivity, proactivity (goal-directed behavior) and social ability (communications with humans and other agents). </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The basic distributed platform is modeled after the traditional notion of an operating system, which, provides, amongst other things, an interface over bare hardware. At the end user level, the operating system provides a friendly set of applications that make it possible for a user to productively use a complex piece of hardware without knowing a whole lot about it. At the programmer level, it provides a system call interface that makes it possible for a programmer to program complex operations without bothering about low level hardware details and without worrying about conflicts with other programs. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> The distributed platform provides a similar interface over the semantic Web. This interface, too, works at two levels. At the end user level, it provides a set of intelligent web applications in different business domains that make it possible for users to tap into the information and services on the web. At the developer level, it provides a set of re-useable, pre-built agents and components that can be used to build intelligent web applications without a lot of effort, and without worrying too much about communications and artificial intelligence issues. </paragraph>
<paragraph id="P-0024" lvl="7"><number>&lsqb;0024&rsqb;</number> Agent Architecture </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> For an agent to exhibit the characteristics that we identified earlier, it needs to have certain essential capabilities. These include the ability to reason, the ability to plan, the ability to learn from its actions and the ability to communicate with other agents and information systems. The architecture disclosed herein enables the agents to have these characteristics. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows the layered architecture of a generic agent in the preferred embodiment. The architecture of an agent is complex, and an agent is capable of doing a variety of different tasks, at several levels of abstraction. For this purpose, an agent is decomposed into layers, so that a higher-level layer can use the behavior of a lower level layer. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The various layers of the agent architecture communicate with each other via events, which are published on event bus <highlight><bold>60</bold></highlight>. Any layer of the architecture can publish events on bus <highlight><bold>60</bold></highlight> or read events from bus <highlight><bold>60</bold></highlight> and act upon them. When a layer receives some input in the form of an event, it processes it, and publishes the result of the processing as a new event on bus <highlight><bold>60</bold></highlight>. Any layer interested in this new event is welcome to pick it up and do its own processing on the event. This interlayer, event-based communication between layers is asynchronous, and is designed to be capable of very high event throughput. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The collaboration layer <highlight><bold>10</bold></highlight> is responsible for handling incoming and outgoing messages. With respect to outgoing messages, collaboration layer <highlight><bold>10</bold></highlight> verifies and directs outgoing messages to other agents. With respect to incoming messages, collaboration layer <highlight><bold>10</bold></highlight> determines whether the agent is interested in the incoming message. Thus, collaboration layer <highlight><bold>10</bold></highlight> contains an interpreter <highlight><bold>15</bold></highlight> that is aware of the domain-specific language and ontology. As a result of the interpretation of the message, collaboration layer <highlight><bold>10</bold></highlight> may publish an event on event bus <highlight><bold>60</bold></highlight>. As an example, with reference to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, agent <highlight><bold>5</bold></highlight> receives message <highlight><bold>12</bold></highlight> containing a new rule that agent <highlight><bold>4</bold></highlight> needs to run. Collaboration layer <highlight><bold>10</bold></highlight> receives message <highlight><bold>12</bold></highlight> and hands it to interpreter <highlight><bold>15</bold></highlight> for decoding. The interpreter has an ontology handler that decodes the message and publishes a &ldquo;New-Rule&rdquo; event <highlight><bold>14</bold></highlight> on event bus <highlight><bold>60</bold></highlight>. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Reasoning layer <highlight><bold>30</bold></highlight> and belief layer <highlight><bold>40</bold></highlight> are part of an expert system that is the core of the agent architecture. Although conceptually, reasoning and belief functions can be though of as separate, in reality, they together form part of a powerful expert system <highlight><bold>35</bold></highlight>. As a result, we will often refer to them herein as &ldquo;reasoning/belief layer <highlight><bold>30</bold></highlight>/<highlight><bold>40</bold></highlight>&rdquo;. Belief layer <highlight><bold>40</bold></highlight> comprises a collection of facts <highlight><bold>42</bold></highlight> in the working memory of expert system <highlight><bold>35</bold></highlight>. Reasoning layer <highlight><bold>30</bold></highlight> comprises a database of rules <highlight><bold>32</bold></highlight> in the knowledge base of expert system <highlight><bold>35</bold></highlight> and the execution of the rules within the inference engine of expert system <highlight><bold>35</bold></highlight>. In our example with the &ldquo;New-Rule&rdquo; event <highlight><bold>14</bold></highlight>, reasoning layer <highlight><bold>30</bold></highlight> would read event <highlight><bold>14</bold></highlight> from event bus <highlight><bold>60</bold></highlight> and place the new rule contained in event <highlight><bold>14</bold></highlight> into the rule database <highlight><bold>32</bold></highlight> of expert system <highlight><bold>35</bold></highlight>. Reasoning layer <highlight><bold>30</bold></highlight> also contains logic engine <highlight><bold>34</bold></highlight> which evaluates rules <highlight><bold>32</bold></highlight> based on facts <highlight><bold>42</bold></highlight>. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Sensory layer <highlight><bold>50</bold></highlight> is responsible for monitoring the world outside of agent <highlight><bold>5</bold></highlight> and reporting changes in the environment to the other layers of the agent <highlight><bold>5</bold></highlight>. To this end, sensory layer <highlight><bold>50</bold></highlight> will monitor sensors <highlight><bold>52</bold></highlight> and gather regular sensor updates. When a change is sensed, sensory layer <highlight><bold>50</bold></highlight> will publish a &ldquo;New-Fact&rdquo; event <highlight><bold>16</bold></highlight> on event bus <highlight><bold>60</bold></highlight>. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Reasoning/belief layer <highlight><bold>30</bold></highlight>/<highlight><bold>40</bold></highlight> reads &ldquo;New-Fact&rdquo; event <highlight><bold>16</bold></highlight> from event bus <highlight><bold>60</bold></highlight> and will update fact database <highlight><bold>42</bold></highlight> with the new fact. This causes an evaluation of the rules with rules database <highlight><bold>32</bold></highlight> of expert system <highlight><bold>35</bold></highlight> that might fire because of the presence of this new fact. As part of this evaluation, calls are potentially made into logic engine <highlight><bold>34</bold></highlight> to check to see whether certain conditions hold. This feature gives each agent <highlight><bold>5</bold></highlight> access to not only the powerful and expressive logic-programming paradigm, but also to additional features such as constraint satisfaction and optimization. This allows reasoning layer <highlight><bold>30</bold></highlight> of agent <highlight><bold>5</bold></highlight> to be as complex and powerful as required for the particular function to be carried out by agent <highlight><bold>5</bold></highlight>. And this can all be configured at run time, without any overhead for a simple agent that doesn&apos;t need all these features. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The action layer <highlight><bold>20</bold></highlight> of agent <highlight><bold>5</bold></highlight> is responsible for taking in pending actions and storing and carrying out actions required by agent <highlight><bold>5</bold></highlight>. For example, the evaluation of the rules in rules database <highlight><bold>32</bold></highlight>, based on facts stored in facts database <highlight><bold>42</bold></highlight> may require that agent <highlight><bold>5</bold></highlight> undertake a certain action. In this case, an &ldquo;Action-Event&rdquo; <highlight><bold>18</bold></highlight> is published on event bus <highlight><bold>60</bold></highlight> by reasoning/belief layer <highlight><bold>30</bold></highlight>/<highlight><bold>40</bold></highlight>. Event <highlight><bold>18</bold></highlight> is picked up by action layer <highlight><bold>20</bold></highlight> from event bus <highlight><bold>60</bold></highlight> and the appropriate action <highlight><bold>19</bold></highlight> is carried out. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Logic engine <highlight><bold>34</bold></highlight> is the technology that provides core reasoning ability to an agent. Essentially, given a domain-specific ontology, the logic engine provides a very quick and easy way for an enterprise to become a participant in the domain/market defined by the ontology. All that needs to be done is to, first, import the ontology into logic engine <highlight><bold>34</bold></highlight>, and, second, to define business rules stored in rules database <highlight><bold>32</bold></highlight> that embody the strategy of the enterprise. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Logic engine <highlight><bold>34</bold></highlight> provides support for a style of programming known as logic programming. Logic programming is based on ideas derived from the discipline of formal knowledge representation and reasoning. Formal logic is used to represent knowledge about specific domains, captured in the ontology for each specific domain, and to reason about things in these domains. It consists of the following: </paragraph>
<paragraph id="P-0035" lvl="2"><number>&lsqb;0035&rsqb;</number> A basic alphabet of symbols, which stand for things of interest in a domain. </paragraph>
<paragraph id="P-0036" lvl="2"><number>&lsqb;0036&rsqb;</number> Valid syntax, defined by a grammar, which describes how to make sentences from these symbols. These sentences state facts about the domain. </paragraph>
<paragraph id="P-0037" lvl="2"><number>&lsqb;0037&rsqb;</number> Semantics, which provides an interpretation for sentences i.e. how sentences relate to state of affairs in the domain. </paragraph>
<paragraph id="P-0038" lvl="2"><number>&lsqb;0038&rsqb;</number> Proof theory&mdash;made up of rules of inference for deducing new sentences from old ones. </paragraph>
<paragraph id="P-0039" lvl="2"><number>&lsqb;0039&rsqb;</number> A set of axioms that describe the known set of facts and rules about a domain. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> A logic programming language is an embodiment of these ideas. It provides syntax and a proof theory for representing knowledge about a domain. The programmer specifies axioms describing the domain, and provides an interpretation for statement. Queries posed to the system are answered on the basis of the axioms by the application of the rules of inference of the system. Contrast this with the imperative programming, where the programmer specifies exactly what to do and when to do it. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> One advantage of taking a logic programming approach to implementing domain-specific ontologies is that globally defined business rules can be imported as-is into the logic engine in an executable form. Another advantage is that rules specific to a business enterprise can be defined in a declarative fashion, which has advantages over any other method of defining business rules because of: </paragraph>
<paragraph id="P-0042" lvl="2"><number>&lsqb;0042&rsqb;</number> 1. The high level of abstraction at which these rules are defined; </paragraph>
<paragraph id="P-0043" lvl="2"><number>&lsqb;0043&rsqb;</number> 2. The ease with which business analysts can work these rules; and </paragraph>
<paragraph id="P-0044" lvl="2"><number>&lsqb;0044&rsqb;</number> 3. The fact that these rules are executable. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Preferably, logic engine <highlight><bold>34</bold></highlight> is implemented as an interpreter for a dialect of Prolog that has been extended to give it the ability to reason about numbers and constraints/optimization-problems based on numbers. Most preferably, the logic engine is a pure Java implementation of a superset of Prolog. It features very good interoperability between the logic programming model and the well-known object oriented programming model, thereby allowing access to a wide range of Java application programming interfaces (APIs) from a logic program. This interoperability, for example, enables the access of multiple databases (through JDBC) in a single logic query. The logic engine has a very extensible architecture that allows the plugging-in of predicates written in Java. In fact, all the Prolog built-in predicates within the Logic Engine have been implemented as independent Java classes. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> The logic engine also features a constraint satisfaction ability. This facilitates the efficient solving of a large class of numeric problems that would otherwise be difficult to solve based on just the Prolog programming model. Some of features of this subsystem may include: </paragraph>
<paragraph id="P-0047" lvl="2"><number>&lsqb;0047&rsqb;</number> Node, arc and bounds consistency based solvers for Finite Domain Constraints </paragraph>
<paragraph id="P-0048" lvl="2"><number>&lsqb;0048&rsqb;</number> A solver based on Integer Programming (branch and sound) for Finite-Domain Optimization problems </paragraph>
<paragraph id="P-0049" lvl="2"><number>&lsqb;0049&rsqb;</number> Support for Real-Domain constraints/optimization based on the Simplex method. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> An important aspect of the distributed platform is the ability of agents to learn the best way to complete a given task. In our view, an agent is said to learn how to do a task based on the experience of doing that task, if some performance measure associated with the agent&apos;s doing the task improves as the agent gains more experience. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> In computational terms, it is very important to decide on the exact nature of the knowledge that is to be learned by the agent. In general, it is useful to define an entity called the target function to represent the knowledge to be learned. The target function should be such that the process of learning the function leads to improved performance by the agent on the task under consideration. Given this conceptual framework, a machine learning algorithm can be said to consist of a target function that is learned and a way of learning this function from training data or experience </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The framework disclosed herein contains implementations of the following: </paragraph>
<paragraph id="P-0053" lvl="2"><number>&lsqb;0053&rsqb;</number> Decision Trees, which can be used to learn discreet valued functions. We disclose a special kind of decision tree called an identification tree; </paragraph>
<paragraph id="P-0054" lvl="2"><number>&lsqb;0054&rsqb;</number> Neural Networks, which can be used to learn discreet valued or real valued functions; and </paragraph>
<paragraph id="P-0055" lvl="2"><number>&lsqb;0055&rsqb;</number> Reinforcement Learning, which is used for learning optimal control policies for an agent in an uncertain and non-deterministic environment. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> What follows is a brief description of each of these algorithms. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Decision trees are used to classify data. The discreet valued function that is learned is a mapping from a set of attributes that characterize an instance of data to a category. A decision tree classifies an instance by sorting it down the tree from the root to a leaf node. Each node in the tree corresponds to a test on an attribute of the instance, and each branch descending from the node corresponds to one of the possible values of the attribute. The leaf nodes correspond to the different categories that define the possible classifications. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Once a decision tree is built, it is straightforward to convert it into a set of equivalent rules. We get a rule by tracing the path starting from a leaf node ending at the root node. By repeating this for all the leaf nodes a set of rules is obtained. After devising a rule set, useless rules must be eliminated. The question to be asked is: can any of the test outcomes be eliminated without changing what the rule does to the sample. If yes, it should be eliminated, thereby simplifying the rule set. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Preferably, the decision tree will have some means of reading training data from a relational database management system and a means of saving a decision tree in to a database. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Neural networks provide a powerful solution to the problems of both function approximation and classification. They have been used in a wide variety of tasks, ranging from character recognition to reinforcement learning action-value function approximation. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> The implementation of the neural network for the distributed platform is preferably of the Multi-Layer-Perception type. This type of neural network has more than one layer of adaptable weights, and can be used to learn any kind of non-linear function. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> The most important part in training a neural net is the weight update method, called back propagation. It helps search the most optimal configuration of the neural net. Preferably, the neural network component of the machine learning subsystem will have support for weight decay, support for use of momentum and support for variable search rates (e.g. RProp where the search rate automatically reduces if we are far from our goal and vice versa). </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> Reinforcement learning is concerned with the issue of how an agent, situated in an environment that it senses, and on which it acts, can learn an optimal control policy to achieve its goals. Or to be more precise, how an agent can learn to map situations to actions&mdash;so as to maximize a numerical reward signal. The agent is not told which actions to take, but instead must discover which actions yield the most reward by trying them. The target function that is learned here is something called the action-value function, and it assigns a numerical value to each action available in a state. Learning an optimal control policy boils down to learning the optimal action-value function. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> In reinforcement learning, actions may affect not only the immediate reward, but also the next situation and, through that, all subsequent rewards. These two characteristics, trial-and-error search and delayed reward, are the two most important distinguishing features of reinforcement learning. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Reinforcement learning is defined not by characterizing learning algorithms, but by characterizing a learning problem. Any algorithm that is well suited to solving that problem can be considered a reinforcement learning algorithm. The basic idea is simply to capture the most important aspects of the real problem facing a learning agent interacting with its environment to achieve a goal. Clearly, such an agent must be able to sense the state of the environment to some extent and must be able to take actions that affect that state. The agent must also have a goal or goals relating to the state of the environment. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> The job of a reinforcement learning agent is to maximize, over a given period of time, the numerical reward signal that it receives from the environment. However, it is impossible to write a single agent that solves all reinforcement learning problems. There are different kinds of environments, for example, finite or infinite, episodic or non-episodic, deterministic or non-deterministic, stationary or non-stationary. Depending on the nature of the environment, the agent must choose an optimal type of value function. So, for example, agents with tabular value-functions can interact only with finite environments. Similarly different kinds of planning agents would be appropriate for deterministic and non-deterministic environments. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> A reinforcement learning agent must learn which action is good and which is bad by trial and error. Thus, an agent needs to completely explore all possibilities before deciding which one is the best. However, for optimal performance, it should always select the best action encountered so far. This inhibits explorations. A soft-max action selection criterion spares the agent this dilemma. However, there are many kinds of action selection methods, each of which may be suitable in a different kind of environment. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> The most important aspect of a reinforcement learning agent is learning from the response of the environment (i.e. the reward signal). The agent compares the actual reward to the expected reward. Using these errors as a starting point, it learns and refines its policy using backup evaluation and credit assignment methods. Different agents may use different types of backup evaluation and credit assignment methods to achieve optimal performance. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Discussed herein are some aspects of the behavior of a reinforcement learning agent. After factoring in all of them, it should be obvious that hundreds of different agents may be needed for different scenarios. To overcome this problem we, have come up with a generic architecture that allows mixing and matching of capabilities. This enables custom-creation of an agent. Each aspect is characterized by a module, which can be implemented in several ways. Each one of the implementations may have their advantages and disadvantages. Moreover, different implementations may cater to different kind of problem. In a nutshell, this architecture supports a library of implementations of the various modules, which must be correctly chosen depending on the nature of the problem. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> Typical modules include: </paragraph>
<paragraph id="P-0071" lvl="2"><number>&lsqb;0071&rsqb;</number> Action selectors: Boltzmann, Epsilon </paragraph>
<paragraph id="P-0072" lvl="2"><number>&lsqb;0072&rsqb;</number> Backup evaluators: TDSarsa, TDQ, TTD </paragraph>
<paragraph id="P-0073" lvl="2"><number>&lsqb;0073&rsqb;</number> Credit assigners: Waltkins, Eligibility Traces </paragraph>
<paragraph id="P-0074" lvl="2"><number>&lsqb;0074&rsqb;</number> Value Functions: Tabular, Linear, Non-Linear </paragraph>
<paragraph id="P-0075" lvl="2"><number>&lsqb;0075&rsqb;</number> Planner: DynaQ, DynaQ&plus;, DynaAC, Prioritized Sweep </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> One obvious advantage of this architecture is that we can create an agent suitable for our needs by assembling the appropriate modules. Practically, this may be as easy as just writing a configuration file or assembling things with a few mouse clicks. Another advantage is that this architecture is extensible. A new planning algorithm, for example, can be added to the library of existing implementations and then can be used while assembling the agent without any modification to the rest of the reinforcement learning framework. </paragraph>
<paragraph id="P-0077" lvl="7"><number>&lsqb;0077&rsqb;</number> Distributed Platform Architecture </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> This invention also defines a distributed architecture for support of intelligent agents. Note that it is not necessary that the intelligent agent conform to the architecture above. An intelligent agent of any design can be supported by the distributed platform. For purposes of this disclosure, the distributed platform will be referred to as a &ldquo;society.&rdquo; The architecture for the society is composed of several logical elements, which will be discussed below. The society is physically supported by many hardware elements, including a plurality of computers and a communications network, such as the internet to interconnect the computers together </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> The society is a scaleable distributed architecture capable of simultaneously running millions of context monitoring agents. The society has build-in support for fault tolerance in the face of software and hardware failure and allows for the transparent resurrection of agents on different hosts if the server that they are running on goes down, in a manner that is guaranteed to preserve semantic correctness and context. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> The society is capable of supporting three basic types of agents. These are entity agents, stateless task agents and stateful task agents. Entity agents generally represent entities that are interacting with the society, such as a physical user. These agents are generally very long lived and do context aware computation within the society. Generally the entity agents always need to be running because they need to continuously monitor the context for specific conditions. Entity agents are capable of surviving server crashes transparently to the client. One example of an entity agent would be a user agent that monitors a users location in the physical world to inform him of things of interest that are nearby. Physical users who register with the society will have an entity agent constantly running on their behalf, awaiting instructions from the user regarding a task to be carried out. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> Stateful task agents carry out a specific, multi-step tasks for a client, which may require the recall of previous states or the results of previous steps as the steps of the task are executed. Thus, as state context is maintained between steps of the multi-step task. Stateful task agents typically expire when the task has been completed. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> Stateless task agents are similar to stateful tasks agents except they do not retain a context and are generally useful for carrying out single step tasks, for example, the sending of an e-mail on behalf of a user. These agents are generally short lived and expire at the completion of the single step that they are instructed to carry out. Thus, no context needs to be retained within the stateless task agent. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> Agent hosts <highlight><bold>110</bold></highlight> and <highlight><bold>120</bold></highlight> in the society are physical computers which house agents and manage their life cycles. Agent hosts also act as a message dispatcher for all agents living within it. Agent host <highlight><bold>110</bold></highlight> represents host capable of hosting entity agents while hosts <highlight><bold>120</bold></highlight> capable of hosting stateful and stateless task agents. It is useful to think of the agent hosts in this context because the entity and task agents are managed in different ways by the agent hosts. Therefore, some agent hosts are better suited to manage entity agents while other agent hosts are more suited to host task type agents. Typically in a society, there maybe dozens or hundreds of agent hosts. Typically, an agent host is a single physical computer able to communicate with other elements of the distributed platform via a communications network such as the internet. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Facilitator <highlight><bold>160</bold></highlight> facilities communication within the society. Facilitator <highlight><bold>160</bold></highlight> first and foremost provides a facade to the society with multiple high level helpful methods for dealing with agents and services running in the society. Any outside entity, such as a user monitoring agent which have been deployed on his behalf, can communicate to the society through the facilitator. The facilitator controls the agent activation protocol in the case of communications failure between a client of an agent and the agent host within which the client is running. Additionally, the facilitator houses servers for white pages <highlight><bold>162</bold></highlight>, yellow pages <highlight><bold>164</bold></highlight> and agent activator <highlight><bold>166</bold></highlight>. White pages server <highlight><bold>162</bold></highlight> provides information on specific agents and users, such as the address of the agent host where the agent is running, the agent&apos;s identifier, etc. Yellow page server <highlight><bold>164</bold></highlight> provides information about agents or sets of agents that provide services to the society. Agent activator <highlight><bold>166</bold></highlight> controls the agent activation protocol. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> Workflow manager <highlight><bold>150</bold></highlight> controls the execution of multi-step tasks on behalf of the agents. The workflow manager itself is implemented as a stateful task agent that manages workflows within the system. The main components of the workflow subsystem are outlined below. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> Within workflow manager <highlight><bold>150</bold></highlight> is process definition repository <highlight><bold>152</bold></highlight>. It is a component of the workflow subsystem in which definitions of business processes are stored. These definitions are preferably in the form of XML documents in a global database, which allows for cross-enterprise operability. The repository is accessible over the network and allows different versions of the same process to be stored. In this way, changes can be made to the process definition without effecting processes that might already be running. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> Workflow agent <highlight><bold>154</bold></highlight> is the heart of the workflow subsystem. It is responsible for running the workflows. It parses the process definitions, decides the tasks or task steps that are to be activated next, and sends out notifications when necessary. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> Because the workflow manager <highlight><bold>150</bold></highlight> is a stateful task agent, it is running under a stateful task agent host <highlight><bold>120</bold></highlight>. This host is responsible for managing the workflow agent&apos;s life cycle and also acts as a dispatcher for incoming messages addressed to the workflow manager. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> There are task agents participating in the workflows being managed by the workflow manager. A workflow may be triggered by an external event (for example, in response to a 10% change in the cost of an airline ticket). A request to trigger the workflow must contain any relevant contextual information and the information regarding specific agents who shall participate in the process. Agents may be contacted by the workflow engine on the basis of their names (a lookup in white pages server <highlight><bold>162</bold></highlight>) or on the basis of services they perform (a lookup in yellow pages server <highlight><bold>164</bold></highlight>). A third way to contact the agents is by means of their agent identifier, which corresponds to a low level address as opposed to a name/service category-based lookup. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> A workflow may involve several tasks being farmed out to a number of agents in parallel. Each agent asynchronously notifies the workflow engine when its assigned task has been completed. The agent then performs a dependency analysis to figure out if the workflow can proceed further and what new tasks need to be assigned. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> Database <highlight><bold>130</bold></highlight> is a central repository of persistent information in the society. This information include such things as context rules for context aware agents and conversation information for stateful task agents. LDAP directory <highlight><bold>140</bold></highlight> is the central naming service in the system that houses administrative information such as user ids and user descriptions, agent ids and agent descriptions and host ids and host network endpoint descriptions. Agents are activated within the society via an agent activation protocol. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> All network messages for an agent are sent to an entity called the message dispatcher, shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> as <highlight><bold>112</bold></highlight> within each agent host <highlight><bold>110</bold></highlight>, or <highlight><bold>120</bold></highlight>. The message dispatcher in each agent host accepts messages for agents running on that host. Address for the agents are looked up from the society LDAP directory <highlight><bold>140</bold></highlight>. Message dispatchers are implemented using a special kind of remote object that supports fault tolerance and load balancing capabilities. For this kind of remote object, stubs that are delivered to a client to enable remote calls are smart. If the stub detects a network failure that makes it impossible for the stub to communicate with its server-side message dispatcher, the stub, instead of returning an error to the client, instead forwards an agent activation request to agent activator <highlight><bold>166</bold></highlight> within facilitator <highlight><bold>160</bold></highlight>. Facilitator <highlight><bold>160</bold></highlight>, on receiving a request for agent activation, puts an activation request into a piece of distributed memory <highlight><bold>170</bold></highlight> called the collaboration space, that is shared amongst all entities in the society. Any one of agent hosts <highlight><bold>110</bold></highlight> or <highlight><bold>120</bold></highlight> running in the society can pick up the activation request from the collaboration space <highlight><bold>170</bold></highlight> and activate the agent <highlight><bold>5</bold></highlight> or <highlight><bold>7</bold></highlight>. Once agent <highlight><bold>5</bold></highlight> or <highlight><bold>7</bold></highlight> is up and running the end point information for the agent&apos;s dispatcher is sent back to the stub running within the client process. The stub gets updated to point to this new location and a call is made to this new message dispatcher to forward the client&apos;s message to its agent. All this happens in a manner that is totally transparent to the client, through the use of the smart stub. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates the flow of messages within a society as a user client <highlight><bold>200</bold></highlight> interacts with the its entity agent <highlight><bold>5</bold></highlight>. Client <highlight><bold>200</bold></highlight> may be any one of a variety of well known means of interacting with the society, such as a dedicated software tool or a browser. In step <highlight><bold>101</bold></highlight>, the client queries facilitator <highlight><bold>160</bold></highlight> for the location of white pages server <highlight><bold>162</bold></highlight>. In step <highlight><bold>102</bold></highlight>, client <highlight><bold>200</bold></highlight> queries white pages server <highlight><bold>162</bold></highlight> through facilitator <highlight><bold>160</bold></highlight> to discover the location of agent <highlight><bold>5</bold></highlight>. (i.e., what agent host the agent is running on). White pages server <highlight><bold>162</bold></highlight> will access LDAP directory <highlight><bold>140</bold></highlight> to get the latest information about agent <highlight><bold>5</bold></highlight>. In step <highlight><bold>103</bold></highlight>, client <highlight><bold>200</bold></highlight> sends a message to agent <highlight><bold>5</bold></highlight>. The message is picked up by agent host <highlight><bold>110</bold></highlight> which is hosting agent <highlight><bold>5</bold></highlight>. Message dispatcher <highlight><bold>112</bold></highlight> running in agent host <highlight><bold>110</bold></highlight> receives the message and routs it to agent <highlight><bold>5</bold></highlight>. In step <highlight><bold>104</bold></highlight>, a sensor within agent <highlight><bold>5</bold></highlight> fires and queries a task agent <highlight><bold>7</bold></highlight> for some sensory information. Message dispatcher <highlight><bold>112</bold></highlight> in task agent host <highlight><bold>120</bold></highlight> receives the message for task agent <highlight><bold>7</bold></highlight> and routes it to task agent <highlight><bold>7</bold></highlight>. In step <highlight><bold>105</bold></highlight>, the information received from task agent <highlight><bold>7</bold></highlight> is placed into the belief layer of agent <highlight><bold>5</bold></highlight>, and, causing a re-evaluation of the rules in the expert system of agent <highlight><bold>5</bold></highlight>. As a result of the re-evaluation of the rules in the expert system of agent <highlight><bold>5</bold></highlight>, a workflow is initiated in step <highlight><bold>106</bold></highlight>. In steps <highlight><bold>107</bold></highlight> and <highlight><bold>108</bold></highlight> , the workflow manager makes use of different stateful or stateless task agents to carry out the tasks in the workflow. This accomplishes whatever client <highlight><bold>200</bold></highlight> wanted to get done on by triggering of the context of interest. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> As a real life example of the process flow shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, consider that client <highlight><bold>200</bold></highlight> needs to go to the post office. He wishes to have a message delivered to his cellular telephone the next time he passes within five hundred yards of a post office as a reminder. To do this client <highlight><bold>200</bold></highlight> must author a rule to be sent to his entity agent. The rule is authored via an authoring tool on the desktop or via a tool or applet accessible through a web browser. Once client <highlight><bold>200</bold></highlight> has authored the rule, through whatever means is available, facilitator <highlight><bold>160</bold></highlight> is contacted to get the address of white pages server <highlight><bold>162</bold></highlight>. White pages server <highlight><bold>162</bold></highlight> is then accessed to find on which agent host <highlight><bold>110</bold></highlight> client&apos;s agent <highlight><bold>5</bold></highlight> (an entity agent) is being hosted. This information is stored in LDAP <highlight><bold>140</bold></highlight>. Client <highlight><bold>200</bold></highlight> sends the rule to agent host <highlight><bold>110</bold></highlight>, which includes message dispatcher <highlight><bold>112</bold></highlight>. Message dispatcher <highlight><bold>112</bold></highlight> will route the message to client&apos;s agent <highlight><bold>5</bold></highlight>. The message is parsed by agent <highlight><bold>5</bold></highlight> as described earlier in the description of the agent architecture. In this case, the placement of the new rule in the expert system would cause an action to be taken by the client&apos;s agent <highlight><bold>5</bold></highlight>, namely, the initiation of a workflow through a message to the workflow manager <highlight><bold>150</bold></highlight>. Workflow manager <highlight><bold>150</bold></highlight> would consult yellow pages server <highlight><bold>164</bold></highlight> within facilitator <highlight><bold>160</bold></highlight> to find if there is a task agent running somewhere in the society which is capable of returning the location of a post office nearest to the location of client <highlight><bold>200</bold></highlight>. It will also be necessary to constantly monitor the location of client <highlight><bold>200</bold></highlight>, preferably through another task agent who is accessing a locator service over the Internet. This can be accomplished through a service which monitors the client&apos;s location through a GPS receiver located in the client&apos;s cellular telephone or by any other means that is well known in the art. Workflow manager <highlight><bold>150</bold></highlight> is constantly checking both the client&apos;s location and the location of the post office nearest to the client and returning this information to the client&apos;s entity agent <highlight><bold>5</bold></highlight>. When it is determined that the locations are within five hundred yards of each other, entity agent <highlight><bold>5</bold></highlight> will initiate a stateless task agent that will send a message to client <highlight><bold>200</bold></highlight> by calling his cellular telephone. The task agent responsible for sending the message to the client&apos;s cell phone may be required to search the yellow pages to find a task agent or service that knows the number of client&apos;s cellular phone. Alternatively, this information may be provided in the rule authored by client <highlight><bold>200</bold></highlight>. Once the client is notified of his proximity to the post office, the workflow is ended and the rule is removed from the expert system of client&apos;s entity agent <highlight><bold>5</bold></highlight>. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> Many such examples of services could be envisioned besides location based services. These could be things such as, requesting that your agent monitor the price of a stock of a certain company and send signals or messages to the client when the stocks price meets certain criteria or reminding the client of important dates, such as, anniversaries or birthdays, etc. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> We have provided a general purpose architecture for both an intelligent agent and a distributed platform for the support of intelligent agents. The invention is not meant to be limited by the scope of the examples used, but is embodied in the claims which follow. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">We claim: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. An architecture for an intelligent agent comprising: 
<claim-text>a messaging facility for handling incoming and outgoing messages; </claim-text>
<claim-text>an expert system for evaluating rules and maintaining known facts; </claim-text>
<claim-text>a sensory facility for sensing conditions external to said intelligent agent; and </claim-text>
<claim-text>a means for communication between said messaging facility, said expert system and said sensory facility. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein said means for communication comprises an event bus upon which events are published and from which said messaging facility, said expert system and said sensory facility can receive events. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein said messaging facility further comprises an interpreter for decoding incoming messages. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein said interpreter is aware of a domain-specific ontology. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference> wherein said interpreter may publish an event on said event bus in response to a decoded message. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein said messaging facility verifies and directs outgoing messages. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein said expert system further comprises: 
<claim-text>a reasoning facility for storing and evaluating rules; and </claim-text>
<claim-text>a beliefs storage facility wherein known facts are stored. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein said known facts stored in said beliefs storage facility originate from a sensory input from said sensory facility. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein said known facts stored in said beliefs storage facility originate from a message received by said messaging facility. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein said known facts stored in said beliefs storage facility originate from an evaluation of a rule by said reasoning facility. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference> wherein said sensory facility publishes an event on said event bus noting a change external to said agent when such a change is detected. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> wherein said event published by said sensory layer is received by said expert system said external change is stored in said beliefs storage facility. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein a change is said beliefs storage facility triggers a re-evaluation of said rules by said reasoning facility. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> further comprising an action facility for carrying out actions required by said agent. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein said actions result from a re-evaluation of said rules by said reasoning facility. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein said actions result from an external condition sensed by said sensory facility. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> further comprising a logic engine component to aid said reasoning facility in the evaluation of rules. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> wherein said logic engine is aware of a domain-specific ontology. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> wherein said logic engine is further aware of a set of axioms describing said domain. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> wherein said logic engine has a constraint satisfaction capability. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference> wherein said logic engine enables said agent to learn optimal ways of solving certain problems or performing certain actions </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference> wherein said logic engine learns via a decision tree. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference> wherein said logic engine learns via a neural network. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The architecture of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference> wherein said logic engine learns via reinforcement learning. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A society of intelligent agents comprising: 
<claim-text>one or more agent hosts for executing agents; </claim-text>
<claim-text>a facilitator for enabling entities external to said society to communicate with and </claim-text>
<claim-text>discover information regarding entities within said society; and </claim-text>
<claim-text>a database containing information regarding all agents running in said society. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein all entities with said society are able to communicate via a communications network. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference> wherein said communications network is the Internet. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein said each of said agent hosts can host a plurality of said agents. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> wherein each of said agent hosts further comprises a message dispatcher for routing messages to all of said agents hosted by that agent host. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein said database further comprises a white pages directory containing information necessary to identify, locate and send messages to a particular agent within the society. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00033">claim 30</dependent-claim-reference> wherein said database further comprises a yellow pages directory containing information regarding services available to agents running within the society. </claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> further comprising a workflow manager for managing the execution of multi-step tasks. </claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference> wherein said workflow manager is capable of parsing multi-step task definitions and organizing the sequence of said steps necessary to complete the task described by said multi-step task definition. </claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00033">claim 33</dependent-claim-reference> wherein said workflow manager may use task agents to complete one or more of said steps of said task. </claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00033">claim 34</dependent-claim-reference> wherein said workflow manager can execute said steps of said task in parallel when appropriate. </claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00033">claim 35</dependent-claim-reference> wherein said workflow manager further comprises a task definition repository for storing said multi-step task definitions. </claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein said facilitator includes an agent activator responsible for instantiating agents. </claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00033">claim 37</dependent-claim-reference> wherein said agent activator is able to recover agents and their context which are no longer running due to software or hardware faults within said society. </claim-text>
</claim>
<claim id="CLM-00039">
<claim-text><highlight><bold>39</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00033">claim 37</dependent-claim-reference> wherein agents are activated by placing them in a distributed memory area accessible to all entities within said society. </claim-text>
</claim>
<claim id="CLM-00040">
<claim-text><highlight><bold>40</bold></highlight>. The society of <dependent-claim-reference depends_on="CLM-00033">claim 39</dependent-claim-reference> wherein any one of said plurality of agent hosts within said society may remove an agent from said distributed memory and run said agent. </claim-text>
</claim>
<claim id="CLM-00041">
<claim-text><highlight><bold>41</bold></highlight>. A society of intelligent agents comprising: 
<claim-text>one or more agent hosts for executing agents; </claim-text>
<claim-text>a facilitator for enabling entities external to said society to communicate with and discover information regarding entities within said society; and </claim-text>
<claim-text>a database containing information regarding all agents running in said society; </claim-text>
<claim-text>wherein said intelligent agents comprise: 
<claim-text>a messaging facility for handling incoming and outgoing messages; </claim-text>
<claim-text>an expert system for evaluating rules and maintaining known facts; </claim-text>
<claim-text>a sensory facility for sensing conditions external to said intelligent agent; and </claim-text>
<claim-text>a means for communication between said messaging facility, said expert system and said sensory facility. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00042">
<claim-text><highlight><bold>42</bold></highlight>. The society of claim <highlight><bold>41</bold></highlight> wherein said society further comprises a workflow manager for managing the execution of multi-step tasks. </claim-text>
</claim>
<claim id="CLM-00043">
<claim-text><highlight><bold>43</bold></highlight>. The society of claim <highlight><bold>41</bold></highlight> wherein said agents further comprise an action facility for carrying out actions required by said agent.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>2</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004912A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004912A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004912A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004912A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004912A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
