<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001078A1-20030102-D00000.TIF SYSTEM "US20030001078A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001078A1-20030102-D00001.TIF SYSTEM "US20030001078A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001078A1-20030102-D00002.TIF SYSTEM "US20030001078A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001078A1-20030102-D00003.TIF SYSTEM "US20030001078A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001078A1-20030102-D00004.TIF SYSTEM "US20030001078A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001078A1-20030102-D00005.TIF SYSTEM "US20030001078A1-20030102-D00005.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001078</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09895627</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010628</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H01L027/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>250</class>
<subclass>208100</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Bad pixel detection and correction in an image sensing device</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Izhak</given-name>
<family-name>Baharav</family-name>
</name>
<residence>
<residence-us>
<city>San Jose</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Ramakrishna</given-name>
<family-name>Kakarala</family-name>
</name>
<residence>
<residence-us>
<city>Sunnyvale</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Xuemei</given-name>
<family-name>Zhang</family-name>
</name>
<residence>
<residence-us>
<city>Mountain View</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Dietrich</given-name>
<middle-name>Werner</middle-name>
<family-name>Vook</family-name>
</name>
<residence>
<residence-us>
<city>Menlo Park</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>AGILENT TECHNOLOGIES, INC.</name-1>
<name-2>Legal Department, DL429</name-2>
<address>
<address-1>Intellectual Property Administration</address-1>
<address-2>P.O. Box 7599</address-2>
<city>Loveland</city>
<state>CO</state>
<postalcode>80537-0599</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A sensor includes an array of photodetectors each generating an output signal of pixel data indicative of incident light intensity. This pixel data is read out from the array one line at a time and stored in a line buffer. A bad pixel processor includes a first buffer that stores pixel data obtained from the line buffer for a certain pixel in a currently read out line and pixel signal light data for pixels adjacent to the certain pixel. An included second buffer stores features that are indicative of whether the pixels in a previously read out line were identified as bad pixels. Using the information in the first and second buffers, the processor identifies whether the certain pixel is a bad pixel. In one operation, the processor precludes any finding of the certain pixel as being a bad pixel if the features in the second buffer indicate that a pixel in the previous line that is adjacent to the certain pixel in the current line was identified as a bad pixel. In another operation, the processor applies a variable detection threshold against the certain pixel, with the value of that threshold being set higher if the features in the second buffer indicate that a pixel in the previous line that is adjacent to the certain pixel in the current line was identified as a bad pixel. When a bad pixel is detected, a correction algorithm is executed to replace the pixel data for the bad pixel with data that more accurately represents, estimates or approximates the intensity of the light that is incident on the photodetector. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Technical Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to an image sensing device comprising an arrayed plurality of photodetectors and, in particular, to the detection of bad pixels in such a device and the correction of pixel data output from those bad pixels. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> It is well known in the art to assemble a plurality of photodetectors (also referred to in the art as &ldquo;photosites&rdquo;) in an array format to create an image sensing device. Each individual photodetector operates to output a signal whose magnitude is proportional to the intensity of light incident on the site of the photodetector. These output signals can then be subsequently processed and manipulated to generate an image comprised of a plurality of individual picture elements (also referred to in the art as &ldquo;pixels&rdquo;), wherein each pixel in the image corresponds with one of the photodetectors. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> The individual photodetectors used in such a sensing device are typically photodiodes that are formed on a semiconductor substrate or chip. The array of these photodetectors may include thousands (if not hundreds of thousands or millions) of individual photodetectors. Even with a semiconductor manufacturing process having a 99% yield, it is recognized that the sensing device array will inevitably include a number of bad photodetectors (also referred to herein as &ldquo;bad pixels&rdquo;). Requiring a semiconductor production line to produce sensors without any bad pixels is a very stringent and perhaps an economically unfeasible and unrealizable demand. It is accordingly accepted for sensors to include some bad pixels as long as a suitable mechanism is available to detect the bad pixels and satisfactorily correct the photodetector output signals. These detection/correction mechanisms generally comprise hardware or software processes that detect bad pixels based on their output signals and alter/replace their output signals to more accurately reflect the intensity of the light incident on the photodetector. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> A bad pixel within a sensor may arise in a number of ways. First, the signal output from the photodetector may always give a high reading (a &ldquo;hot pixel&rdquo;). This defect produces a brighter than expected spot in the generated image. Second, the signal output from the photodetector may always give a low reading (a &ldquo;dead pixel&rdquo;). This defect produces a darker that expected spot in the generated image. Third, a signal proportional to the incident light may be generated, but (due, for example, to incorrect photodiode gain, dark current and/or offset) does not accurately represent of the incident light in the sense that it differs from signals generated by other similarly situated photodetectors (a &ldquo;noisy pixel&rdquo;). This defect produces an erroneous spot (color, intensity, contrast, and the like) in the generated image. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a simplified schematic diagram of a sensor read-out operation in accordance with the prior art. A sensor array <highlight><bold>10</bold></highlight> includes a plurality of photodetectors <highlight><bold>12</bold></highlight>. Each photodetector <highlight><bold>12</bold></highlight> outputs a signal (referred to herein as &ldquo;pixel data&rdquo;) whose magnitude ideally has a predetermined monotonic relationship to the intensity of light incident on the photodetector. Although not explicitly shown, the generated signal for each pixel has a digital format (obtained through appropriate analog-to-digital conversion) normally ten to twelve bits in size. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> A read-out buffer <highlight><bold>14</bold></highlight> is used to read out and capture either a horizontal row or vertical column of individual pixel data that is generated from the photodetectors. In this context, a horizontal row or a vertical column is referred to as a &ldquo;line&rdquo; <highlight><bold>16</bold></highlight>. Following capture of a line <highlight><bold>16</bold></highlight> of pixel data in the buffer <highlight><bold>14</bold></highlight>, each individual piece of pixel data <highlight><bold>18</bold></highlight> is processed by a bad pixel processor <highlight><bold>20</bold></highlight>. The processor <highlight><bold>20</bold></highlight> operates to serially examine each piece of pixel data <highlight><bold>18</bold></highlight> in a line <highlight><bold>16</bold></highlight>, detect instances where that piece of data has been output by a bad pixel, and in such cases effectuate a correction on the pixel data so that it more accurately represents the intensity of the light that is incident on the photodetector. Pixel data is then serially output <highlight><bold>22</bold></highlight> by the processor <highlight><bold>20</bold></highlight> for each pixel in either its original form <highlight><bold>24</bold></highlight> (i.e., as read out by the buffer <highlight><bold>14</bold></highlight>) or a modified form <highlight><bold>24</bold></highlight>&prime; (i.e., as corrected when a bad pixel is detected). </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a block diagram illustrating one known operation for bad pixel processing performed by processor <highlight><bold>20</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. The bad pixel processor <highlight><bold>20</bold></highlight> serially processes the pixel data <highlight><bold>18</bold></highlight> captured by the buffer <highlight><bold>14</bold></highlight> for one line <highlight><bold>16</bold></highlight> (see, <cross-reference target="DRAWINGS">FIG. 1</cross-reference>) one pixel at a time (generically referred to as pixel &ldquo;X&rdquo;) in order to determine if each piece of the pixel data under examination is generated by a bad pixel. To assist in the making of this determination, the mechanism includes a data buffer <highlight><bold>26</bold></highlight> that stores the pixel data <highlight><bold>18</bold></highlight> (as captured in buffer <highlight><bold>14</bold></highlight>) for not only the pixel X under examination, but also for the pixels Y and Z that neighbor (e.g., are immediately adjacent to) the pixel X in the same read-out line <highlight><bold>16</bold></highlight>. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> A detection algorithm <highlight><bold>28</bold></highlight> processes the pixel data <highlight><bold>18</bold></highlight> for pixels X, Y and Z and determines if the pixel data for pixel X differs from the pixel data for pixels Y and Z (either individually, by median or on average) by a deviation that exceeds a certain threshold. If not, the pixel data <highlight><bold>18</bold></highlight> for pixel X is assumed to represent valid pixel data generated from a good pixel, and is serially output <highlight><bold>22</bold></highlight> in its original form <highlight><bold>24</bold></highlight>. If there is an excessive deviation (beyond the threshold), the pixel data <highlight><bold>18</bold></highlight> for pixel X is assumed to be generated from a bad pixel, and a correction algorithm <highlight><bold>30</bold></highlight> is executed to modify the pixel data to produce modified pixel data <highlight><bold>24</bold></highlight>&prime; that attempts to more accurately represent the intensity of the light that is incident on the photodetector. As an example, the correction algorithm may replace the pixel data <highlight><bold>18</bold></highlight> for pixel X with pixel data <highlight><bold>24</bold></highlight>&prime; comprising the median or average value of the pixel data <highlight><bold>18</bold></highlight> for the adjacent pixels Y and Z on the same line <highlight><bold>16</bold></highlight>. As another example, the correction algorithm may replace the pixel data <highlight><bold>18</bold></highlight> for pixel X with pixel data <highlight><bold>24</bold></highlight>&prime; comprising the pixel data <highlight><bold>18</bold></highlight> for either one of the adjacent pixels Y or Z on the same line <highlight><bold>16</bold></highlight>. Numerous other operations for correcting pixel data from bad pixel are known in the art. Following correction, the modified data <highlight><bold>24</bold></highlight>&prime; for pixel X is passed to serial output <highlight><bold>22</bold></highlight>. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a block diagram illustrating another known operation for bad pixel processing performed by the processor <highlight><bold>20</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. The bad pixel processor <highlight><bold>20</bold></highlight> serially processes the pixel data <highlight><bold>18</bold></highlight> captured by the buffer <highlight><bold>14</bold></highlight> for one line <highlight><bold>16</bold></highlight> (see, <cross-reference target="DRAWINGS">FIG. 1</cross-reference>) one pixel at a time (generically referred to as pixel &ldquo;X&rdquo;) in order to determine if any of the pixel data under examination is generated by a bad pixel. To assist in the making of this determination, the processor <highlight><bold>20</bold></highlight> includes a data buffer <highlight><bold>26</bold></highlight> that stores the pixel data <highlight><bold>18</bold></highlight> (as currently captured in buffer <highlight><bold>14</bold></highlight>) for not only the pixel X under examination, but also for the pixels Y and Z that neighbor (e.g., are immediately adjacent to) the pixel X in the currently read-out line <highlight><bold>16</bold></highlight>(n). To farther assist in the making of this determination, the processor <highlight><bold>20</bold></highlight> includes a data buffer <highlight><bold>32</bold></highlight> storing the pixel data <highlight><bold>18</bold></highlight> that was previously captured in buffer <highlight><bold>14</bold></highlight> for an adjacent, previously read-out line <highlight><bold>16</bold></highlight>(n&minus;1). More specifically, the pixel data <highlight><bold>18</bold></highlight> of interest comprises that pixel data for pixels A, B and C that most closely neighbor pixel X in the previously read-out line <highlight><bold>16</bold></highlight>(n&minus;1). </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> A detection algorithm <highlight><bold>28</bold></highlight> processes the pixel data <highlight><bold>18</bold></highlight> for pixels A, B, C, X, Y and Z and determines if the pixel data for pixel X differs from the pixel data for pixels A, B, C, Y and Z (either individually, in pairs or groups, by median or on average) by a deviation that exceeds a certain threshold. If not, the pixel data <highlight><bold>18</bold></highlight> for pixel X is assumed to represent valid pixel data generated from a good pixel, and is serially output <highlight><bold>22</bold></highlight> in its original form <highlight><bold>24</bold></highlight>. If there is an excessive deviation (beyond the threshold), the pixel data <highlight><bold>18</bold></highlight> for pixel X is assumed to be generated by a bad pixel, and a correction algorithm <highlight><bold>30</bold></highlight> is executed to modify the pixel data to generate modified pixel data <highlight><bold>24</bold></highlight>&prime; that more accurately represents the intensity of the light that is incident on the photodetector. Again, as discussed above, any of the known operations for correcting bad pixel signal light data may be used, and beneficially pixel data from additional pixels (e.g., pixels A, B and C) may be evaluated during this correction. Following correction, the modified pixel data <highlight><bold>24</bold></highlight>&prime; for pixel X is passed to serial output <highlight><bold>22</bold></highlight>. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The bad pixel processing operation of <cross-reference target="DRAWINGS">FIG. 3</cross-reference> considers more pixel data <highlight><bold>18</bold></highlight> than the operation of <cross-reference target="DRAWINGS">FIG. 2</cross-reference> for purposes of both detecting bad pixels (see, operation <highlight><bold>28</bold></highlight>) and correcting/modifying the pixel data for the detected bad pixels (see, operation <highlight><bold>30</bold></highlight>). However, the operation illustrated in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> has a significant memory overhead requirement. For example, consider an array <highlight><bold>10</bold></highlight> that generates for each photodetector <highlight><bold>12</bold></highlight> digitized pixel data <highlight><bold>18</bold></highlight> that is ten to twelve bits in magnitude, and wherein each line <highlight><bold>16</bold></highlight> includes one-thousand photodetectors (such as would be the case, for example, with a one mega-pixel sensor array). The bad pixel processor <highlight><bold>20</bold></highlight> would accordingly require, for the implementation shown in <cross-reference target="DRAWINGS">FIG. 3, a</cross-reference> buffer <highlight><bold>32</bold></highlight> memory capable of storing 10-12 kbits of data in addition to the memory required for the buffer <highlight><bold>26</bold></highlight>. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> It is recognized that the array <highlight><bold>10</bold></highlight> along with the line read-out buffer <highlight><bold>14</bold></highlight> and the bad pixel processor <highlight><bold>20</bold></highlight> can be implemented on a single integrated circuit chip (i.e., the same semiconductor substrate). This is possible using, for example, CMOS fabrication techniques that allow for such an integration of components and functionalities. At the same time, however, even given the miniaturization capable through integrated circuit fabrication, the array <highlight><bold>10</bold></highlight> itself along with the associated circuitry (for example, the A/D conversion circuit, the line read-out buffer <highlight><bold>14</bold></highlight>, the detector <highlight><bold>28</bold></highlight> and the corrector <highlight><bold>30</bold></highlight>) take up a significant amount of semiconductor area, and there would be an advantage for many applications of the sensor if the memory requirements of at least the previous line <highlight><bold>16</bold></highlight>(n&minus;1) buffer <highlight><bold>32</bold></highlight> could be minimized. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The invention provides a sensor that comprises a plurality of photodetectors arranged in a sensor array. Each photodetector generates an output signal of pixel data that is indicative of incident light intensity. This pixel data is read out from the array one line at a time and stored in a line buffer. The invention further includes a bad pixel processor that includes a first buffer storing pixel data obtained from the line buffer for a certain pixel in a currently read out line and pixel data for pixels adjacent to the certain pixel. A second buffer included in the processor stores characteristic features for each of the pixels in a line read out from the array previous to the currently read out line. The pixel data stored in the first buffer and the characteristic features stored in the second buffer are then processed to identify whether the certain pixel in the currently read out line is a bad pixel. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> In one embodiment, processing for bad pixel detection includes an operation that precludes any finding of the certain pixel as being a bad pixel if the characteristic features in the second buffer indicate that a pixel in the previous line that is adjacent to the certain pixel in the current line was identified as a bad pixel. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> In another embodiment, processing for bad pixel detection includes an operation that applies a variable detection threshold against the certain pixel, with the value of the threshold being set higher if the characteristic features stored in the second buffer indicate that a pixel in the previous line that is adjacent to the certain pixel in the current line was identified as a bad pixel.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> A more complete understanding of the method and apparatus of the present invention may be acquired by reference to the following Detailed Description when taken in conjunction with the accompanying Drawings wherein: </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, previously described, is a simplified schematic diagram of a sensor read-out operation in accordance with the prior art; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, previously described, is a block diagram illustrating one known operation for bad pixel processing; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, previously described, is a block diagram illustrating one known operation for bad pixel processing; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a simplified schematic diagram of a sensor read-out operation in accordance with an embodiment of the present invention; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a block diagram illustrating an operation for bad pixel processing in accordance with an embodiment of the present invention; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a flow diagram illustrating one embodiment of a process for bad pixel detection using the processing operation of <cross-reference target="DRAWINGS">FIG. 5</cross-reference>; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a receiver operating characteristics (ROC) graph illustrating an improvement in bad pixel detection operation performance using the process of <cross-reference target="DRAWINGS">FIG. 6</cross-reference>; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flow diagram illustrating another embodiment of a process for bad pixel detection using the processing operation of <cross-reference target="DRAWINGS">FIG. 5</cross-reference>; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a block diagram illustrating another operation for bad pixel processing in accordance with an embodiment of the present invention; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flow diagram illustrating another embodiment of a process for bad pixel detection using the processing operation of <cross-reference target="DRAWINGS">FIG. 9</cross-reference>; and </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is an ROC graph illustrating an improvement in bad pixel detection operation performance using the process of <cross-reference target="DRAWINGS">FIG. 10</cross-reference>.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE EXEMPLARY EMBODIMENTS OF THE INVENTION </heading>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a simplified schematic diagram of a sensor read-out operation in accordance with an embodiment of the present invention. A sensor array <highlight><bold>100</bold></highlight> includes a plurality of photodetectors <highlight><bold>102</bold></highlight>. Each photodetector <highlight><bold>102</bold></highlight> outputs a signal (referred to herein as &ldquo;pixel data&rdquo;) whose magnitude ideally has a predetermined monotonic relationship to the intensity of light incident on the photodetector. Although not explicitly shown, the generated signal for each pixel has a digital format (obtained through appropriate analog-to-digital conversion) normally ten to twelve bits in size. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> A read-out buffer <highlight><bold>104</bold></highlight> is used to read out and capture either a horizontal row or vertical column of individual pixel data that is generated from the photodetectors. In this context, a horizontal row or a vertical column is referred to as a &ldquo;line&rdquo; <highlight><bold>106</bold></highlight>. Following capture of a line <highlight><bold>106</bold></highlight> of pixel data in the buffer <highlight><bold>104</bold></highlight>, each individual piece of pixel data <highlight><bold>108</bold></highlight> is serially processed in a bad pixel processor <highlight><bold>110</bold></highlight>. The processor <highlight><bold>110</bold></highlight> operates to examine each piece of pixel data <highlight><bold>108</bold></highlight>, detect instances where that piece of pixel data has been output by a bad pixel, and in such cases effectuate a correction on the pixel data so that it more accurately represents the intensity of the light that is incident on the photodetector. Pixel data is then serially output <highlight><bold>112</bold></highlight> by the processor <highlight><bold>110</bold></highlight> for each pixel in either its original form <highlight><bold>114</bold></highlight> (i.e., as read out by the buffer <highlight><bold>104</bold></highlight>) or a modified form <highlight><bold>114</bold></highlight>&prime; (i.e., as corrected when a bad pixel is detected). </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows a block diagram illustrating an operation for bad pixel processing performed by processor <highlight><bold>110</bold></highlight> in accordance with an embodiment of the present invention. The bad pixel processor <highlight><bold>110</bold></highlight> processes the pixel data <highlight><bold>108</bold></highlight> captured by the buffer <highlight><bold>104</bold></highlight> for one line <highlight><bold>106</bold></highlight> (see, <cross-reference target="DRAWINGS">FIG. 4</cross-reference>) one pixel at a time (generically referred to as pixel &ldquo;X&rdquo;) in order to determine if each piece of pixel data under examination is generated by a bad pixel. To assist in the making of this determination, the processor <highlight><bold>110</bold></highlight> includes a data buffer <highlight><bold>116</bold></highlight> that stores the pixel data <highlight><bold>108</bold></highlight> (as currently captured in buffer <highlight><bold>104</bold></highlight>) not only for pixel X under examination, but also for the pixels Y and Z that neighbor (e.g., are immediately adjacent to, or nearby on the same line <highlight><bold>106</bold></highlight> as) the pixel X in the currently read-out line <highlight><bold>106</bold></highlight>(n). To further assist in the making of this determination, the processor <highlight><bold>110</bold></highlight> includes a feature buffer <highlight><bold>122</bold></highlight> storing a characteristic feature (F) <highlight><bold>124</bold></highlight> (to be described in more detail below) of each of the pixels in an adjacent previously read-out line <highlight><bold>106</bold></highlight>(n&minus;1). </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Generally speaking, the characteristic feature <highlight><bold>124</bold></highlight> for a pixel differs significantly from the pixel data for a pixel in that the characteristic feature is not indicative of the magnitude of the incident light, but is rather indicative of some non-magnitude characteristic relating to the pixel. As an example, the characteristic feature <highlight><bold>124</bold></highlight> may comprise a bad pixel identification, an edge direction identification, line transition identification, and the like. Importantly, the characteristic feature for a pixel requires less memory per pixel than pixel data (see, buffer <highlight><bold>32</bold></highlight>, <cross-reference target="DRAWINGS">FIG. 3</cross-reference>), thus allowing the feature buffer <highlight><bold>122</bold></highlight> to have as small a size as possible. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> A detection algorithm <highlight><bold>128</bold></highlight> processes both the pixel data <highlight><bold>108</bold></highlight> for pixels X, Y and Z in the currently read-out line as well as the characteristic features (F) <highlight><bold>124</bold></highlight> for the pixels in the previously read-out line <highlight><bold>106</bold></highlight>(n&minus;1) to determine whether pixel X is a bad pixel. It will be understood that the process performed by algorithm <highlight><bold>128</bold></highlight> may consider pixel data for other neighboring pixels, if desired. If the pixel is not bad, the pixel data <highlight><bold>108</bold></highlight> for pixel X is assumed to represent valid pixel data generated from a good pixel, and is output <highlight><bold>112</bold></highlight> in its original form <highlight><bold>114</bold></highlight>. If pixel X is determined to be a bad pixel, a correction algorithm <highlight><bold>130</bold></highlight> is executed to modify the pixel data <highlight><bold>108</bold></highlight> into modified pixel data <highlight><bold>114</bold></highlight>&prime; that more accurately represents the intensity of the light that is incident on the photodetector. Any selected one of a number of well known operations for correcting pixel data from bad pixels may be used. No matter what correction operation is used, however, it is preferred that as much pixel data as possible, including the pixel data for pixels Y and Z (and perhaps other neighbors) in the current line <highlight><bold>106</bold></highlight>(n) be considered in effectuating the correction. As a further enhancement to the invention, the correction operation may also consider the characteristic features (F) <highlight><bold>124</bold></highlight> for the pixels in the previous line <highlight><bold>106</bold></highlight>(n&minus;1), in effectuating the correction. Following correction, the modified data <highlight><bold>114</bold></highlight>&prime; for pixel X is passed to serial output <highlight><bold>112</bold></highlight>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows a flow diagram illustrating one embodiment of a process for bad pixel detection performed by the processor <highlight><bold>110</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. In this embodiment for the pixels in the previous line <highlight><bold>106</bold></highlight>(n&minus;1), the bad/good pixel decisions previously made by the detection algorithm <highlight><bold>128</bold></highlight> are used as the characteristic features (F) <highlight><bold>124</bold></highlight> that are stored in the feature buffer <highlight><bold>122</bold></highlight>. These characteristic features require only a binary (1/0) storage, i.e., only one bit per pixel. This serves to significantly reduce the size of the memory required for the feature buffer <highlight><bold>122</bold></highlight> in comparison to that required by the buffer <highlight><bold>32</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 3</cross-reference>) of the prior art. In step <highlight><bold>200</bold></highlight>, the detection algorithm <highlight><bold>128</bold></highlight> uses the pixel data stored in the buffer <highlight><bold>116</bold></highlight> and calculates an average or median value (V) for the pixel data <highlight><bold>108</bold></highlight> of the pixels Y and Z that are adjacent the pixel X under examination (in the same line <highlight><bold>106</bold></highlight>(n)) that is used as a reference value. It will be understood that the step <highlight><bold>200</bold></highlight> calculation may use pixel data for other neighbors in line <highlight><bold>106</bold></highlight>(n). </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The detection algorithm <highlight><bold>128</bold></highlight> then executes step <highlight><bold>202</bold></highlight> and processes the reference value (V) and the pixel data <highlight><bold>108</bold></highlight> for pixel X as stored in buffer <highlight><bold>116</bold></highlight>. More specifically, this step <highlight><bold>202</bold></highlight> processing subtracts the value V from the data <highlight><bold>108</bold></highlight> value of pixel X to obtain a difference value (D). The detection algorithm <highlight><bold>128</bold></highlight> then uses the characteristic features (F) <highlight><bold>124</bold></highlight> stored in the feature buffer <highlight><bold>122</bold></highlight> and determines in step <highlight><bold>204</bold></highlight> whether a pixel (P) having the same relative position in the previous line <highlight><bold>106</bold></highlight>(n&minus;1) as the pixel X under examination in the current line <highlight><bold>106</bold></highlight>(n) was previously detected as being a bad pixel. This pixel (P) is referred to herein as being a &ldquo;perpendicularly adjacent&rdquo; pixel. If NO, then the difference value (D) calculated in step <highlight><bold>202</bold></highlight> is compared against a first threshold (TH1) in step <highlight><bold>208</bold></highlight>. More specifically, this step <highlight><bold>208</bold></highlight> comparison determines whether the magnitude of the difference value (D) exceeds the first threshold (TH1). If, on the other hand, the determination in step <highlight><bold>204</bold></highlight> is YES, then the difference value (D) calculated in step <highlight><bold>202</bold></highlight> is compared against a second, different, threshold (TH2) in step <highlight><bold>210</bold></highlight>. More specifically, this step <highlight><bold>210</bold></highlight> comparison determines whether the magnitude of the difference value (D) exceeds the second threshold (TH2). </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> If the executed comparison operation of either steps <highlight><bold>208</bold></highlight> or <highlight><bold>210</bold></highlight> is satisfied (i.e., the appropriate threshold is exceeded), the detection algorithm <highlight><bold>128</bold></highlight> identifies the pixel X under examination as a &ldquo;bad pixel&rdquo; in step <highlight><bold>212</bold></highlight>. This identification of the pixel X as a bad pixel is recorded in the feature buffer <highlight><bold>122</bold></highlight> in step <highlight><bold>214</bold></highlight>. Operation with respect to pixel X then proceeds to the correction algorithm <highlight><bold>130</bold></highlight> to modify the pixel data <highlight><bold>108</bold></highlight> in accordance with a desired correction operation to produce modified pixel data <highlight><bold>114</bold></highlight>&prime; that more accurately represents the intensity of the light that is incident on the photodetector. If, on the other hand, the executed comparison operation of steps <highlight><bold>208</bold></highlight> or <highlight><bold>210</bold></highlight> is not satisfied, this indicates that the pixel is a &ldquo;good pixel&rdquo; data <highlight><bold>108</bold></highlight> for pixel X is assumed to represent valid pixel data generated from a good pixel for output <highlight><bold>112</bold></highlight> in its original form <highlight><bold>114</bold></highlight>. The process then returns (step <highlight><bold>214</bold></highlight>) to process a next pixel. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Although a specific implementation is shown for step <highlight><bold>200</bold></highlight> and <highlight><bold>202</bold></highlight> to obtain the difference value (D) for purposes of comparison to the thresholds TH1 or TH2, it will be understood that any suitable procedure may be used to obtain information that is indicative of a difference between the measured pixel X value (given by the pixel data) and a reference value. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> The second threshold (TH2) is preferably set higher than the first threshold (TH1) (i.e., TH2&gt;TH1). This makes it more difficult for the comparison operation of step <highlight><bold>210</bold></highlight> to be satisfied, and thus identify the pixel X that is under examination as a &ldquo;bad pixel&rdquo; when pixel X in line <highlight><bold>106</bold></highlight>(n) is perpendicularly adjacent to previously detected bad pixel in line <highlight><bold>106</bold></highlight>(n&minus;1). One reason for this is that it is statistically unlikely that two adjacent bad pixels in consecutive lines <highlight><bold>106</bold></highlight> exist. Another reason for this is that while the prior art single threshold process of <cross-reference target="DRAWINGS">FIG. 2</cross-reference> accurately identifies bad pixels in most cases, it has an unwanted side effect of erroneously identifying good pixels as bad pixels. A domino effect thus occurs where one erroneous bad pixel detection propagates among a few adjacent pixels in subsequent lines. The dual threshold approach of <cross-reference target="DRAWINGS">FIG. 6</cross-reference> acts to reduce this unwanted side effect by increasing the threshold level that must be satisfied for bad pixel identification when the pixel under examination is perpendicularly adjacent a pixel previously identified as being a bad pixel. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The effectiveness of the process for bad pixel identification illustrated in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> in reducing the unwanted side effect is graphically illustrated in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, which shows a receiver operating characteristics (ROC) graph. The ROC graph plots the false alarm rate, which indicates the number good pixels being unnecessarily corrected (i.e., the unwanted side effect), against the hit rate, which indicates the number of bad pixels being accurately corrected. Curve <highlight><bold>220</bold></highlight> is a representative ROC curve for the single threshold process shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, while curve <highlight><bold>222</bold></highlight> is a representative ROC curve for the dual threshold process shown in <cross-reference target="DRAWINGS">FIGS. 5 and 6</cross-reference>. Any shifting of the ROC curve towards the upper left hand corner of the graph (i.e., toward a hit rate of 1 and a false alarm rate of 0) represents an improvement in performance. As shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, the curve <highlight><bold>222</bold></highlight> is shifted in that direction relative to the curve <highlight><bold>220</bold></highlight>. It is accordingly concluded that there is a significant benefit in improved performance by utilizing different thresholds for the step <highlight><bold>208</bold></highlight> and <highlight><bold>210</bold></highlight> comparisons. This is made possible through the use of the characteristic features (F) <highlight><bold>124</bold></highlight> as described. It is also noted that, because the characteristic features (F) <highlight><bold>124</bold></highlight> require storage of only a single bit per pixel, the size of the buffer <highlight><bold>122</bold></highlight> is significantly reduced and performance is improved. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In an embodiment of the process of <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the second threshold (TH2) is set to be an integer multiple (n) of the first threshold (TH1) (i.e., TH2&equals;nTH1). More specifically, and in conjunction with the representative ROC curves <highlight><bold>220</bold></highlight> and <highlight><bold>222</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, the integer multiple is two (2). It will, of course, be understood that the multiple &ldquo;n&rdquo; need not necessarily comprise an integer value, and further that any suitable scaling factor could be used provided it produces improved performance as measured by its corresponding ROC curve. It will also be recognized that the multiple &ldquo;n&rdquo; may be variably set in other ways based on the stored characteristic feature data. As an example, in situations where the characteristic features record characteristics other than bad/good pixel, especially in situations where data has more than two possible values, a corresponding plurality of thresholds may be applied to give the detection determination a more robust response and perhaps better accuracy. For example, the characteristic feature may indicate whether the pixel has an associated edge direction (right edge, left edge, no edge smooth, no edge texture) in the overall image. In this scenario, it is possible for a different threshold to be associated with each edge direction. As another example, the characteristic feature may indicate whether the pixel has an associated line transition (peak, valley, ramp, flat) in the overall image. Similarly, in this scenario, as an example, it is possible for a different threshold to be associated with each line transition. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows a flow diagram illustrating another embodiment of a process for bad pixel detection performed by the processor <highlight><bold>110</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. In this embodiment, the bad/good pixel decisions previously made by the detection algorithm <highlight><bold>128</bold></highlight> for the pixels in the previous line <highlight><bold>106</bold></highlight>(n&minus;1) are used as the characteristic features (F) <highlight><bold>124</bold></highlight> for the pixels in the previous line <highlight><bold>106</bold></highlight>(n&minus;1) that are stored in the feature buffer <highlight><bold>122</bold></highlight>. These characteristic features (F) <highlight><bold>124</bold></highlight> require only a binary (1/0) storage feature, i.e., one bit per pixel. This serves to significantly reduce the size of the memory required for the feature buffer <highlight><bold>122</bold></highlight> in comparison to that required by the buffer <highlight><bold>32</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 3</cross-reference>) of the prior art. In step <highlight><bold>250</bold></highlight>, the detection algorithm <highlight><bold>128</bold></highlight> uses the characteristic features (F) <highlight><bold>124</bold></highlight> stored in the feature buffer <highlight><bold>122</bold></highlight> and determines whether a perpendicularly adjacent pixel (P) to the pixel X under examination was previously detected as being a bad pixel. If the determination in step <highlight><bold>250</bold></highlight> is YES, the process precludes a finding that pixel X could comprise a &ldquo;bad pixel&rdquo; and the pixel data <highlight><bold>108</bold></highlight> for pixel X is assumed to represent valid pixel data for output <highlight><bold>112</bold></highlight> in its original form <highlight><bold>114</bold></highlight>. The process then returns (step <highlight><bold>252</bold></highlight>) to process a next pixel. Put another way, if the process determines that the pixel (P) corresponding to pixel X a previous line <highlight><bold>106</bold></highlight>(n&minus;1) is a bad pixel (as indicated by the stored characteristic feature), then pixel X in a current line <highlight><bold>106</bold></highlight>(n) is not permitted to be identified as a bad pixel. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> If, on the other hand, the executed determination operation of step <highlight><bold>250</bold></highlight> is NO, the detection algorithm <highlight><bold>128</bold></highlight> uses the information stored in the buffer <highlight><bold>116</bold></highlight> and calculates (in step <highlight><bold>254</bold></highlight>) an average or median value (V) for the pixel data <highlight><bold>108</bold></highlight> of the pixels Y and Z that are adjacent the pixel X under examination (in the same line <highlight><bold>106</bold></highlight>(n)) as a reference value. It will be understood that the step <highlight><bold>254</bold></highlight> calculation may use pixel data for other neighbors in line <highlight><bold>106</bold></highlight>(n). The detection algorithm <highlight><bold>128</bold></highlight> then executes step <highlight><bold>256</bold></highlight> and processes the reference value (V) and the pixel data <highlight><bold>108</bold></highlight> for pixel X as stored in buffer <highlight><bold>116</bold></highlight>. More specifically, this step <highlight><bold>256</bold></highlight> processing subtracts the value V from the data <highlight><bold>108</bold></highlight> value of pixel X to obtain a difference value (D). </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> The difference value (D) calculated in step <highlight><bold>256</bold></highlight> is then compared against a threshold (TH) in step <highlight><bold>258</bold></highlight>. More specifically, this step <highlight><bold>258</bold></highlight> comparison determines whether the magnitude of the difference value (D) exceeds the threshold (TH). If YES, the detection algorithm <highlight><bold>128</bold></highlight> identifies the pixel X under examination as a &ldquo;bad pixel&rdquo; in step <highlight><bold>260</bold></highlight>. This identification of the pixel X as a bad pixel is recorded in the feature buffer in step <highlight><bold>262</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Operation with respect to pixel X then proceeds to the correction algorithm <highlight><bold>130</bold></highlight> to modify the pixel data <highlight><bold>108</bold></highlight> into modified pixel data <highlight><bold>114</bold></highlight>&prime; that more accurately represents the intensity of the light that is incident on the photodetector. If, on the other hand, the executed comparison operation of step <highlight><bold>258</bold></highlight> is not satisfied, this indicates that the pixel is a &ldquo;good pixel&rdquo; and the pixel data <highlight><bold>108</bold></highlight> for pixel X assumed to represent valid pixel data for output <highlight><bold>112</bold></highlight> in its original form <highlight><bold>114</bold></highlight>. The process (step <highlight><bold>252</bold></highlight>) then returns to process a next pixel. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Although a specific implementation is shown for step <highlight><bold>254</bold></highlight> and <highlight><bold>256</bold></highlight> to obtain the difference value (D) for purposes of comparison to the threshold TH, it will be understood that any suitable procedure may be used to obtain information that is indicative of a difference between the measured pixel X value (given by the pixel data) and a reference value. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Again, it will be understood that characteristic features other than bad/good pixel detection can be used to drive the preclusion determination of steps <highlight><bold>250</bold></highlight> and <highlight><bold>252</bold></highlight>. As an example, when the characteristic features record characteristics other than bad/good pixel, especially in situations where data has more than two possible values, only certain one(s) of the specific features may drive a preclusion determination where some relationship between that feature and faulty bad pixel detection has been noted. For example, the characteristic feature may indicate whether the pixel has an associated edge direction (right edge, left edge, no edge smooth, no edge texture) in the overall image. In this scenario, as an example, it is possible for only the right/left edge direction to preclude bad pixel identification. As another example, the characteristic feature may indicate whether the pixel has an associated line transition (peak, valley, ramp, flat) in the overall image. Similarly, in this scenario, as an example, it is possible for only the ramp transition to preclude bad pixel identification. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows a block diagram illustrating another operation for bad pixel processing performed by the processor <highlight><bold>110</bold></highlight> in accordance with an embodiment of the present invention. The bad pixel processor <highlight><bold>110</bold></highlight> processes the pixel data <highlight><bold>108</bold></highlight> captured by the buffer <highlight><bold>104</bold></highlight> for one line <highlight><bold>106</bold></highlight> (see <cross-reference target="DRAWINGS">FIG. 4</cross-reference>) one pixel at a time (generically referred to as pixel &ldquo;X&rdquo;) in order to determine if each piece of pixel data under examination is generated by a bad pixel. To assist in the making of this determination, the processor <highlight><bold>110</bold></highlight> includes a two line data buffer <highlight><bold>116</bold></highlight>&prime; that stores the pixel data <highlight><bold>108</bold></highlight> (as currently captured in buffer <highlight><bold>104</bold></highlight>) not only for pixel X under examination, but also for m neighboring pixels N that are located in the same line <highlight><bold>106</bold></highlight>(n) as pixel X and in the previous line <highlight><bold>106</bold></highlight>(n&minus;1). In an embodiment, m is set equal to thirteen (as illustrated in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>), to store pixel data for six pixels in line <highlight><bold>106</bold></highlight>(n) and seven pixels in line <highlight><bold>106</bold></highlight>(n&minus;1). It will be understood, however, that m can be set equal to any suitable integer value and any desired pieces of pixel data may be stored. To further assist in the making of this determination, the processor <highlight><bold>110</bold></highlight> includes a feature buffer <highlight><bold>122</bold></highlight> storing a characteristic feature (F) <highlight><bold>124</bold></highlight> (to be described in more detail below) of each of the pixels in an adjacent previously read-out line <highlight><bold>106</bold></highlight>(n&minus;1). </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> A detection algorithm <highlight><bold>128</bold></highlight> processes the pixel data <highlight><bold>108</bold></highlight> for pixel X and the pixels N as well as the characteristic features (F) <highlight><bold>124</bold></highlight> for the pixels in the previously read-out line <highlight><bold>106</bold></highlight>(n&minus;1) to determine whether pixel X is a bad pixel. If not, the pixel data <highlight><bold>108</bold></highlight> for pixel X is assumed to represent valid pixel data generated from a good pixel, and is output <highlight><bold>112</bold></highlight> in its original form <highlight><bold>114</bold></highlight>. If pixel X is determined to be a bad pixel, a correction algorithm <highlight><bold>130</bold></highlight> is executed to modify the pixel data <highlight><bold>108</bold></highlight> in accordance with a desired correction operation into modified pixel data <highlight><bold>114</bold></highlight>&prime; that more accurately represents the intensity of the light that is incident on the photodetector. Any selected one of a number of well known operations for correcting pixel data for bad pixels may be used. It is preferred, however, that whatever correction operation is used that as much data as possible, including the pixel data for pixels N in the current line <highlight><bold>106</bold></highlight>(n) and previous line <highlight><bold>106</bold></highlight>(n&minus;1) be considered in effectuating the correction. As a further enhancement to the invention, the correction operation may also consider the characteristic features (F) <highlight><bold>124</bold></highlight> for the pixels in the previous line <highlight><bold>106</bold></highlight>(n&minus;1) in effectuating the correction. Following correction, the modified pixel data <highlight><bold>114</bold></highlight>&prime; for pixel X is passed to serial output <highlight><bold>112</bold></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> shows a flow diagram illustrating one embodiment of a process for bad pixel detection performed by the processor <highlight><bold>110</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. In this embodiment, the bad/good pixel decisions previously made by the detection algorithm <highlight><bold>128</bold></highlight> for the pixels in the previous line <highlight><bold>106</bold></highlight>(n&minus;1) are used as the characteristic features (F) <highlight><bold>124</bold></highlight> stored in the feature buffer <highlight><bold>122</bold></highlight>. These characteristic features (F) <highlight><bold>124</bold></highlight> require only a binary (1/0) storage, i.e., one bit per pixel. This serves to significantly reduce the size of the memory required for the feature buffer <highlight><bold>122</bold></highlight> in comparison to that required by the buffer <highlight><bold>32</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 3</cross-reference>) of the prior art. In step <highlight><bold>350</bold></highlight>, the detection algorithm <highlight><bold>128</bold></highlight> uses the characteristic features (F) <highlight><bold>124</bold></highlight> stored in the feature buffer <highlight><bold>122</bold></highlight> and determines whether a perpendicularly adjacent pixel (P) to the pixel X under examination was previously detected as being a bad pixel. If the determination in step <highlight><bold>350</bold></highlight> is YES, the process precludes a finding that pixel X could be a &ldquo;bad pixel&rdquo; and the pixel data <highlight><bold>108</bold></highlight> for pixel X is assumed to represent valid pixel data for output <highlight><bold>112</bold></highlight> in its original form <highlight><bold>114</bold></highlight>. The process then returns (step <highlight><bold>352</bold></highlight>) to process a next pixel. Put another way, if the process determines that the pixel (P)in a previous line <highlight><bold>106</bold></highlight>(n&minus;1) that corresponds in position to pixel X is a bad pixel (as indicated by the stored characteristic feature), then the pixel X in the current line <highlight><bold>106</bold></highlight>(n) is not permitted to be identified as a bad pixel. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> If, on the other hand, the executed determination operation of step <highlight><bold>350</bold></highlight> is NO, the detection algorithm <highlight><bold>128</bold></highlight> uses the pixel data stored in the buffer <highlight><bold>116</bold></highlight>&prime; and calculates (in step <highlight><bold>354</bold></highlight>) local color correlation for the pixels X and N. From this determined color correlation, the algorithm <highlight><bold>128</bold></highlight> selects a threshold (TH) for bad pixel detection in step <highlight><bold>356</bold></highlight>. In this regard, it is noted that bad pixels tend to have a different color from neighboring pixels. For areas under examination where there is a high color correlation among the pixels N, identification of pixel X as a bad pixel can be accurately determined by color correlating to the neighboring pixels. Thus, the threshold (TH) for the comparison to pixel X is set relatively low. For areas, on the other hand, having a low correlation among the pixels N, it is more difficult to distinguish a bad pixel from an image feature using a comparison. Thus, the threshold (TH) for that comparison to pixel X is set relatively high. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> More specifically, the local color correlation process of step <highlight><bold>354</bold></highlight> involves splitting the pixels X and N in the buffer <highlight><bold>116</bold></highlight>&prime; into two types (for example, A and B, as shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> with an &ldquo;odd/even&rdquo; arrangement). Next, a calculation of a local variance (Var) and covariance (Cov) of the two pixel types is made for each line <highlight><bold>106</bold></highlight>(n) and <highlight><bold>106</bold></highlight>(n&minus;1) saved in the buffer <highlight><bold>116</bold></highlight>&prime;. The calculation may be made, for example, in accordance with the following: </paragraph>
<paragraph id="P-0053" lvl="2"><number>&lsqb;0053&rsqb;</number> Var(A)&equals;E(A<highlight><superscript>2</superscript></highlight>)&minus;E(A)<highlight><superscript>2 </superscript></highlight></paragraph>
<paragraph id="P-0054" lvl="2"><number>&lsqb;0054&rsqb;</number> Var(B)&equals;E(B<highlight><superscript>2</superscript></highlight>)&minus;E(B)<highlight><superscript>2 </superscript></highlight></paragraph>
<paragraph id="P-0055" lvl="2"><number>&lsqb;0055&rsqb;</number> Cov(A, B)&equals;E(AB)&minus;E(A)E(B); </paragraph>
<paragraph id="P-0056" lvl="7"><number>&lsqb;0056&rsqb;</number> wherein E( ) is defined as the mean or average value. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> With respect to step <highlight><bold>356</bold></highlight>, a conditional variance is calculated as follows: </paragraph>
<paragraph id="P-0058" lvl="2"><number>&lsqb;0058&rsqb;</number> Var(A&verbar;B)&equals;Var(A)&minus;Cov(A, B)<highlight><superscript>2</superscript></highlight>/Var(B). </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> The conditional variance measures the certainty of an estimate of the value of pixel X (see, the E(A&verbar;B) calculation below) given the values of the neighboring pixels. If the certainty is low, this would indicate that the threshold for comparison should be set relatively high, and vice versa. The standard deviation (S) of the conditional variance is then determined by taking the square root of the conditional variance in a well known manner. The threshold (TH) is then set to a value equal to n (generally a non-negative integer, or other suitable scaling factor) times the standard deviation as follows:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>TH&equals;n* S.</italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0060" lvl="7"><number>&lsqb;0060&rsqb;</number> The value of the threshold (TH) is accordingly set as a function of the determined conditional variance that measures certainty with respect to pixel X estimation. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> The foregoing may be better understood by reference to some examples. In a first case in which the image comprises flat areas having a high color correlation, the determined variance (Var) is low, the determined covariance (Cov) is low, and the determined conditional variance is also low. The resulting standard deviation is also low and the threshold is set to a relatively low value because bad pixels can relatively easily be identified in such an image having high color correlation. In a second case in which the image comprises edges and/or textures having some color correlation, the determined variance is high, the determined covariance is high, and the determined conditional variance is relatively low. The resulting standard deviation is medium and the threshold is set to a medium value because bad pixels in some image cases can be difficult to identify. In a third case in which the image comprises random noise having little color correlation, the determined variance is high, the determined covariance is low, and the determined conditional variance is high. The resulting standard deviation is high and the threshold is set to a relatively high value because bad pixels are very difficult to identify in such low color correlation images. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> The algorithm next executes step <highlight><bold>358</bold></highlight> and calculates an estimate of pixel X from the values of the same line <highlight><bold>106</bold></highlight>(n), adjacent pixels. More specifically, the value of pixel X is estimated from its left and right neighbors in line <highlight><bold>106</bold></highlight>(n) as follows:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>E</italic></highlight>(<highlight><italic>A&verbar;B</italic></highlight>)&equals;<highlight><italic>E</italic></highlight>(<highlight><italic>A</italic></highlight>)&plus;(Cov(<highlight><italic>A,B</italic></highlight>)/Var(<highlight><italic>B</italic></highlight>))*(<highlight><italic>B&minus;E</italic></highlight>(<highlight><italic>B</italic></highlight>)).</in-line-formula></paragraph>
<paragraph id="P-0063" lvl="7"><number>&lsqb;0063&rsqb;</number> It should be remembered that the conditional variance determination referenced above measures a level of confidence in this estimation that is used to determine the threshold (TH) to be applied. Next, in step <highlight><bold>360</bold></highlight>, the algorithm processes the pixel data <highlight><bold>108</bold></highlight> for pixel X as stored in buffer <highlight><bold>116</bold></highlight>&prime; and estimate determined in the step <highlight><bold>358</bold></highlight>. More specifically, this step <highlight><bold>360</bold></highlight> processing subtracts the step <highlight><bold>358</bold></highlight> estimate from the data <highlight><bold>108</bold></highlight> value of pixel X to obtain a difference value (D) in accordance with the following:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>D&equals;X&minus;E</italic></highlight>(<highlight><italic>A&verbar;B</italic></highlight>).</in-line-formula></paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> The difference value (D) calculated in step <highlight><bold>360</bold></highlight> is then compared in step <highlight><bold>362</bold></highlight> against the determined threshold (TH). More specifically, this step <highlight><bold>362</bold></highlight> comparison determines whether the magnitude of the difference value (D) exceeds the threshold (TH). If YES, the detection algorithm <highlight><bold>128</bold></highlight> identifies the pixel X under examination as a &ldquo;bad pixel&rdquo; in step <highlight><bold>364</bold></highlight>. This identification of pixel X as a bad pixel is recorded in the feature buffer <highlight><bold>122</bold></highlight> in step <highlight><bold>366</bold></highlight>. Operation with respect to pixel X then proceeds to the correction algorithm <highlight><bold>130</bold></highlight> to modify the pixel data <highlight><bold>108</bold></highlight> into modified pixel data <highlight><bold>114</bold></highlight>&prime; that more accurately represents the intensity of the light that is incident on the photodetector. If, on the other hand, the executed comparison operation of step <highlight><bold>362</bold></highlight> is not satisfied, this indicates that the pixel is a &ldquo;good pixel&rdquo; and the pixel data <highlight><bold>108</bold></highlight> for pixel X assumed to represent valid (i.e., good) pixel data for output <highlight><bold>112</bold></highlight> in its original form <highlight><bold>114</bold></highlight>. The process then returns (step <highlight><bold>352</bold></highlight>) to process a next pixel. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> The threshold (TH) varies with the calculated conditional variance in order to make it more difficult for the comparison operation of step <highlight><bold>362</bold></highlight> to be satisfied and identify the pixel X as a &ldquo;bad pixel&rdquo; when pixel X in line <highlight><bold>106</bold></highlight>(n) is located in area of the image having a low color correlation. Notwithstanding the enhanced accuracy in bad pixel detection that is provided by using such a variable image correlation based threshold value as illustrated in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, the local color correlation process by itself may produce an unwanted side effect of vertically propagating false bad pixel identifications which result in the elimination of photodetector pixel data <highlight><bold>108</bold></highlight> in vertical lines of the image. The use of the characteristic features (F) <highlight><bold>124</bold></highlight>, and more particularly the process of step <highlight><bold>350</bold></highlight> to force an exit from the bad pixel detection algorithm when a perpendicularly adjacent pixel in a previous line <highlight><bold>106</bold></highlight>(n&minus;1) is identified as a bad pixel, acts to reduce this unwanted side effect by preventing false bad pixel identifications from propagating vertically. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> The effectiveness of the process for bad pixel identification illustrated in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> in reducing the unwanted side effect is graphically illustrated in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, which shows a receiver operating characteristics (ROC) graph. The ROC graph plots the false alarm rate which indicates the number good pixels being inadvertently corrected (i.e., the unwanted side effect), against the hit rate, which indicates the number of bad pixels being accurately corrected. Curve <highlight><bold>224</bold></highlight> is a representative ROC curve for the process in which only local color correlation is used to identify bad pixels, while curve <highlight><bold>226</bold></highlight> is a representative ROC curve for the process shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. Any shifting of the ROC curve towards the upper left hand corner of the graph (i.e., toward a hit rate of <highlight><bold>1</bold></highlight> and a false alarm rate of <highlight><bold>0</bold></highlight>) represents an improvement in performance. As shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, the curve <highlight><bold>226</bold></highlight> is shifted in that direction relative to the curve <highlight><bold>224</bold></highlight>. It is accordingly concluded that there is a significant benefit in improved performance by applying the perpendicularly adjacent characteristic feature (F) <highlight><bold>124</bold></highlight> test. It is also noted that, because the characteristic features (F) <highlight><bold>124</bold></highlight> require storage of only a single bit per pixel, the size of the buffer <highlight><bold>122</bold></highlight> is significantly reduced and improved performance is obtained. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> While the present invention as disclosed is preferably implemented using CMOS technology with all (or substantially all) components and functionalities implemented on a single integrated circuit chip, it will be understood that other semiconductor fabrication techniques could be used, and further that components and functionalities may be split among and between multiple chips and/or devices. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> The processing operations of the disclosed methods concerning the detection and correction algorithms are preferably implemented using microprocessor or application specific integrated circuit (ASIC) techniques. It will, of course, be understood that separate processing devices may be interconnected in certain applications to the sensor array. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> It should also be recognized that the methods, systems and processes described herein are equally useful in connection with both color and black/white sensors. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The threshold values described herein may be changed and set in any of a number of ways depending on where a user desires to set operation with respect to the ROC curve. As an example, the device may be manufactured as a chip with settable values, and further include an input mechanism to allow the user preferentially change the set values. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> With respect to the implementations of <cross-reference target="DRAWINGS">FIGS. 5 and 9</cross-reference>, it will be understood by those skilled in the art that some instances may arise where the detection/correction functionalities (references <highlight><bold>128</bold></highlight> and <highlight><bold>130</bold></highlight>) are not desired. In these instances, the functionalities <highlight><bold>128</bold></highlight> and <highlight><bold>130</bold></highlight> may be selectively by-passed under user control to allow the raw output data from the buffer <highlight><bold>104</bold></highlight> to pass straight through for more sophisticated processing. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> The feature buffer <highlight><bold>122</bold></highlight> is disclosed as saving the characteristic features (F) for the pixels of a single preceding line <highlight><bold>106</bold></highlight>(n&minus;1). While this is an embodiment, it will be recognized that the feature buffer <highlight><bold>122</bold></highlight> may include sufficient memory to store characteristic features for the pixels of plural preceding lines (for example, <highlight><bold>106</bold></highlight>(n&minus;1) and <highlight><bold>106</bold></highlight>(n&minus;2), as shown in phantom in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>). Furthermore, it will be recognized that different characteristic features may be stored by the buffer for the pixels of different lines. As one example, the multi-line feature buffer <highlight><bold>122</bold></highlight> may store characteristic features comprising bad pixel identifications for the past two lines <highlight><bold>106</bold></highlight>(n&minus;1) and <highlight><bold>106</bold></highlight>(n&minus;2). As another example, the characteristic features stored by the multi-line feature buffer <highlight><bold>122</bold></highlight> for the immediately previous line <highlight><bold>106</bold></highlight>(n&minus;1) may include not only bad pixel identification, but also some other characteristic features, while the next previous line <highlight><bold>106</bold></highlight>(n&minus;2) includes only the bad pixel identification data. When storing additional previous line&apos;s worth of characteristic features (i.e., features for lines beyond line <highlight><bold>106</bold></highlight>(n&minus;1)), these additional features can be included and considered in the evaluations performed by the detection algorithm <highlight><bold>128</bold></highlight>. An advantage provided by such storage would include improvement in algorithm performance for catching &ldquo;corner cases&rdquo; with only a minimal increase in the amount of required data storage for the feature buffer <highlight><bold>122</bold></highlight>. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> It is recognized that the feature buffer <highlight><bold>122</bold></highlight> is used to save on computation. For example, consider the case where both current and previous line pixel data is stored along with the characteristic features for the pixels of those lines. Theoretically speaking, the stored previous line values could be used to generate the characteristic features. However, these computations are, generally speaking, similar to, if not identical to, those computations that performed in connection with the processing of the current line values to identify bad pixels. Accordingly, when scanning and processing the values for the current line, the bad pixel identifications are determined and stored in the feature buffer thus obviating the need to store previous line pixel data and perform the computations again. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> Although preferred embodiments of the method and apparatus of the present invention have been illustrated in the accompanying Drawings and described in the foregoing Detailed Description, it will be understood that the invention is not limited to the embodiments disclosed, but is capable of numerous rearrangements, modifications and substitutions without departing from the invention as set forth and defined by the following claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">We claim: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A sensor, comprising: 
<claim-text>an array of photodetectors, each photodector generating pixel data indicative of incident light thereon; and </claim-text>
<claim-text>a bad pixel processor including: </claim-text>
<claim-text>a first buffer storing pixel data for a certain pixel in a current line of the array and pixel data for pixels adjacent to the certain pixel; </claim-text>
<claim-text>a second buffer storing a characteristic feature for each of the pixels in a line of the array previous to the current line; and </claim-text>
<claim-text>a detector that processes the pixel data stored in the first buffer and the characteristic features stored in the second buffer to identify whether the certain pixel in the current line is a bad pixel. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including: 
<claim-text>a corrector that processes the pixel data stored in the first buffer to determine corrected pixel data for the certain pixel if the detector identifies the certain pixel as a bad pixel. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the determined corrected pixel data comprises pixel data stored in the first buffer for at least one pixel adjacent to the certain pixel in the current read out line. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the determined corrected pixel data comprises an average or median of the pixel data stored in the first buffer for the pixels adjacent to the certain pixel. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the characteristic feature comprises data identifying whether the pixel in the previous line was identified as a bad pixel. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> wherein the detector, in processing the characteristic features stored in the second buffer, precludes identification of the certain pixel in the current line as a bad pixel when the characteristic feature for a pixel in the previous line that is adjacent to the certain pixel in the current line identifies the adjacent pixel as being a bad pixel. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> wherein the detector processes the pixel data from the first buffer to determine a difference value that is indicative of a difference between the pixel data for the certain pixel and a reference pixel value. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein the reference pixel value comprises an average or median of the pixel data stored in the first buffer for the pixels adjacent to the certain pixel in the current line. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein the detector, when the characteristic feature for a pixel in the previous line that is adjacent to the certain pixel in the current line identifies the adjacent pixel as being a bad pixel, compares the difference value to a first threshold value when the adjacent pixel is a not a bad pixel, and compares the difference value to second threshold value, that is greater than the first threshold value, when the adjacent pixel is a bad pixel. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference> wherein the detector identifies the certain pixel in the current line as a bad pixel when either of the comparisons indicates the difference value to exceed the first/second threshold. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the characteristic feature is indicative of a characteristic of a pixel in the previous line that is not related to incident light. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The sensor as in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the first buffer further stores pixel data for pixels in the previous line. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A method for processing pixel data that is indicative of incident light that is output from pixels in a photodetector array, comprising the steps of: 
<claim-text>storing pixel data for a certain pixel in a current line of the array and pixel data for pixels adjacent to the certain pixel; </claim-text>
<claim-text>storing a characteristic feature for each of the pixels in a line of the array previous to the current line; and </claim-text>
<claim-text>processing the stored pixel data and the stored characteristic features to identify whether the certain pixel in the current line is a bad pixel. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, further including the step of: 
<claim-text>processing the pixel data stored in the first buffer to determine corrected pixel data for the certain pixel if the detector identifies the certain pixel as a bad pixel. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein the step of processing comprises the step of replacing the pixel data for the certain pixel with the pixel data for at least one of the pixels adjacent to the certain pixel in the current line. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein the step of processing comprises the step of replacing the pixel data for the certain pixel with an average or median of the pixel data for the pixels adjacent to the certain pixel. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference> wherein the characteristic feature comprise data identifying whether the pixel in the previous line was identified as a bad pixel. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> wherein the step of processing comprises the step of precluding identification of the certain pixel in the current line as a bad pixel when the characteristic feature for a pixel in the previous line that is adjacent to the certain pixel in the current line identifies the adjacent pixel as being a bad pixel. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> wherein the step of processing comprises the step of determining a difference value that is indicative of a difference between the pixel data for the certain pixel and a reference pixel value. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> wherein the reference pixel value comprises an average or median of the pixel data stored in the first buffer for the pixels adjacent to the certain pixel in the same current line. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> wherein the step of processing further includes the steps of: 
<claim-text>determining whether the characteristic feature for a pixel in the previous line that is adjacent to the certain pixel in the current line identifies the adjacent pixel as being a bad pixel; and </claim-text>
<claim-text>comparing the difference value to a threshold value; </claim-text>
<claim-text>wherein the threshold is a first threshold value if the adjacent pixel is a not a bad pixel, and is a second threshold value, that is greater than the first threshold value, when the adjacent pixel is a bad pixel. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference> wherein the step of processing further includes the step of identifying the certain pixel as a bad pixel when the comparison step indicates the difference value exceed the threshold. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference> wherein the characteristic feature is indicative of a characteristic of the pixel in the previous line that is not related to incident light. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The method as in <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference> wherein the step of storing pixel data further includes the step of storing pixel data for pixels in the previous line.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>5</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001078A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001078A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001078A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001078A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001078A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001078A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
