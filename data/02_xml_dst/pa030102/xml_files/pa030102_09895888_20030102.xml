<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005237A1-20030102-D00000.TIF SYSTEM "US20030005237A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005237A1-20030102-D00001.TIF SYSTEM "US20030005237A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005237A1-20030102-D00002.TIF SYSTEM "US20030005237A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005237A1-20030102-D00003.TIF SYSTEM "US20030005237A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005237A1-20030102-D00004.TIF SYSTEM "US20030005237A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005237A1-20030102-D00005.TIF SYSTEM "US20030005237A1-20030102-D00005.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005237</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09895888</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010629</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F013/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>711</class>
<subclass>146000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Symmetric multiprocessor coherence mechanism</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Sang</given-name>
<middle-name>Hoo</middle-name>
<family-name>Dhong</family-name>
</name>
<residence>
<residence-us>
<city>Austin</city>
<state>TX</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Harm</given-name>
<middle-name>Peter</middle-name>
<family-name>Hofstee</family-name>
</name>
<residence>
<residence-us>
<city>Austin</city>
<state>TX</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Charles</given-name>
<middle-name>Ray</middle-name>
<family-name>Johns</family-name>
</name>
<residence>
<residence-us>
<city>Austin</city>
<state>TX</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>John</given-name>
<middle-name>Samuel</middle-name>
<family-name>Liberty</family-name>
</name>
<residence>
<residence-us>
<city>Round Rock</city>
<state>TX</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Thuong</given-name>
<middle-name>Quang</middle-name>
<family-name>Truong</family-name>
</name>
<residence>
<residence-us>
<city>Austin</city>
<state>TX</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>International Business Machines Corp.</organization-name>
<address>
<city>Armonk</city>
<state>NY</state>
<country>
<country-code>US</country-code>
</country>
</address>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>BRACEWELL &amp; PATTERSON, L.L.P.</name-1>
<name-2></name-2>
<address>
<address-1>P.O. BOX 969</address-1>
<city>AUSTIN</city>
<state>TX</state>
<postalcode>78767-0969</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A processor-cache operational scheme and topology within a multi-processor data processing system having a shared lower level cache (or memory) by which the number of coherency busses is reduced and more efficient snoop resolution and coherency operations with the processor caches are provided. A copy of the internal (L1) cache directory is provided within the lower level (L2) cache or memory. The snoop operations and coherency maintenance operations of the L1 directory are completed by comparing the snoop addresses with the address tags of the copy of the L1 directory in the L2 cache. Updates to the coherency states of the copy of the L1 directory are mirrored in the L1 directory and L1 cache. This eliminates the need for the individual coherency buses of each processor that is coupled to the L2 cache and speeds up coherency operations because the snoops do not have to be transmitted to the L1 caches. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Technical Field </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to data processing systems in general and, in particular, to improved cache operations within a data-processing system. Still more particularly, the present invention relates to an improved method, system, and processor cache topology that more efficiently supports cache coherency operations within a data-processing system. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Prior Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> A data-processing system typically includes a processor coupled to a variety of storage devices arranged in a hierarchical manner. In addition to a main memory, a commonly employed storage device in the hierarchy includes a high-speed memory known as a cache memory (or cache). A cache speeds up the apparent access times of the relatively slower main memory by retaining the data or instructions that the processor is most likely to access again, and making the data or instructions available to the processor at a much lower latency. As such, caches enable relatively fast access to a subset of data and/or instructions that were recently transferred from the main memory to the processor, and thus improves the overall speed of the data-processing system. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Most contemporary high-performance data processing system architectures include multiple levels of cache memory within the memory hierarchy. Cache levels are typically employed in progressively longer access latencies. Smaller, faster caches are employed at levels within the storage hierarchy closer to the processor (or processors) while larger, slower caches are employed at levels closer to system memory. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> In a conventional symmetric multiprocessor (SMP) data processing system, all of the processors are generally identical, insofar as the processors all utilize common instruction sets and communication protocols, have similar hardware architectures, and are generally provided with similar memory hierarchies. For example, a conventional SMP data processing system may comprise a system memory, a plurality of processing elements that each include a processor and one or more levels of cache memory and a system bus coupling the processing elements to each other and to the system memory. Many such systems include at least one level of cache memory shared between two or more processors. To obtain valid execution results in a SMP data processing system, it is important to maintain a coherent memory hierarchy, that is, to provide a single view of the contents of memory to all of the processors. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> A coherent memory hierarchy is maintained through the use of a selected memory coherency protocol, such as the MESI protocol. In the MESI protocol, an indication of a coherency state is stored in association with each coherency granule (i.e., cache line) of at least all upper level (cache) memories. Each coherency granule can have one of four states, modified (M), exclusive (E), shared (S), or invalid (I), which can be encoded by two bits in the cache directory. Those skilled in the art are familiar with the MESI protocol and its use to ensure coherency among memory structures. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Each cache line (block) of data in a SMP system typically includes an address tag field, a state bit field, an inclusivity bit field, and a value/data field for storing the actual instruction or data. In current processing systems, both the address tag field and the state bit field are contained in a cache directory. This cache directory may be organized under any caching scheme available, such as fully associative, direct mapped, or set-associative, as are well-known in the art. A compare match of an incoming address with one of the tags within the address tag field indicates a cache &ldquo;hit.&rdquo;</paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Current implementation of a coherent Symmetric MultiProcessor (SMP) requires a coherence bus on which all memory transactions that change the state of any of the lines in the caches can be &ldquo;snooped&rdquo; (i.e., observed) by all processors. In response to a snoop operation by a processor, all the processors must interrogate their cache directories to identify if the line involved in the transaction was cached in that processor cache. This process may also involve broadcasting of the snoop out to the coherency buses. If a matching directory entry is found, indicating that the cache line is present, the cache line may have to be written back to the next level of cache, written back to main memory, or invalidated, depending on the transaction observed. This coherency scheme has the disadvantage that either the processors must arbitrate for a coherence bus, and thus incur delays, or that a separate coherence bus must be provided for each processor as illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>A, requiring the implementation of a large number of external connections (pins) on the limited real estate of the processor. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> As shown by <cross-reference target="DRAWINGS">FIG. 1</cross-reference>A, SMP comprises four processing modules <highlight><bold>101</bold></highlight>A-<highlight><bold>101</bold></highlight>D, each having a respective central processing unit (CPU) <highlight><bold>103</bold></highlight>A-<highlight><bold>103</bold></highlight>D and level 1 (L1) cache <highlight><bold>105</bold></highlight>A-<highlight><bold>105</bold></highlight>D. L1 caches <highlight><bold>105</bold></highlight>A-<highlight><bold>105</bold></highlight>D each have an associated L1 directory <highlight><bold>107</bold></highlight>A-<highlight><bold>107</bold></highlight>D, which are interconnected to each other via a series of cache coherency buses <highlight><bold>111</bold></highlight>. Cache coherency buses <highlight><bold>111</bold></highlight> extend from pins (connectors) of processing modules <highlight><bold>101</bold></highlight>A-<highlight><bold>101</bold></highlight>D to other pins of the other processing modules and to the L2 cache <highlight><bold>109</bold></highlight>. The number of pins required for the connections and the real estate required for the coherency buses are dependent on the number of processors within the multi-processing system that support coherency operations. Thus, with current 32-way, 64-way, and larger SMPs, the number of required pins and complexity of coherency buses may be prohibitive to further development of large SMPs on progressively smaller real estate. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> An alternative coherency scheme currently being utilized provides a &ldquo;directory-based coherence,&rdquo; by which the state information of the L1 directories is included in the L2 directory. <cross-reference target="DRAWINGS">FIG. 1B</cross-reference> illustrates this coherency scheme. As shown, L2 directory <highlight><bold>156</bold></highlight> contains the directory entries of L1 directory <highlight><bold>155</bold></highlight>A-<highlight><bold>155</bold></highlight>D. However, since there are typically many more lines in the L2 cache <highlight><bold>159</bold></highlight> than in the combined L1 caches or processors <highlight><bold>151</bold></highlight>A-<highlight><bold>151</bold></highlight>D, the directory-based scheme utilizes more chip area, requires a large amount of storage devoted to coherence, and therefore takes a longer time to interrogate (snoop) the L1 directory because the entire L2 directory <highlight><bold>155</bold></highlight> has to be viewed. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In light of the foregoing, the present invention recognizes that it would be desirable to provide a processor-cache configuration that supports more efficient coherency operations without requiring additional hardware. A processor-cache configuration that reduces the number of cache coherency buses and associated coherency bus transactions required to support coherency would be a welcomed improvement. These and other benefits are provided by the invention described herein. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Disclosed is a processor-cache configuration and operational scheme within a multi-processor data processing system having a shared lower level cache (or memory) by which the number of coherency busses is reduced and more efficient snoop resolution and coherency operations with the processor caches are provided. A copy of the processor&apos;s internal (L1) cache directory is provided within the lower level (L2) cache or memory. Lower level snoop operations and coherency operations directed to the L1 cache are evaluated and completed utilizing the copy of the L1 directory in the L2 cache. Updates to the coherency states of the copy of the L1 directory are mirrored in the L1 directory and L1 cache. The configuration and operational scheme eliminates the need for the individual coherency buses interconnecting each processor that is coupled to the L2 cache and speeds up coherency operations because the snoops do not have to be transmitted to the L1 caches for initial resolution. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> In the preferred embodiment, the L1 directory and L1 directory copy are initialized during system boot. A processor request for update is received and a check is made for a snoop hit in the L2 cache and in the copy of the L1 directory. That is, the snooped addressed is compared against the address tags of the copy of the L1 directory. If a snoop hit occurs in the L2 cache and in the copy of the L1 directory, then the snoop resolution utility of the L2 cache communicates with the processor to resolve the snoop and the L1 directory and the copy of the L1 directory are updated accordingly. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> All objects, features, and advantages of the present invention will become apparent in the following detailed written description. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> The invention itself, as well as a preferred mode of use, further objects, and advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawings, wherein: </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1A</cross-reference> is a block diagram of a data-processing system with coherency buses according to current multiprocessor systems; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1B</cross-reference> is a block diagram of a data-processing system with the L1 directory housed within the L2 directory according to another current multiprocessor system configuration; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram of a data processing system with modified lower level cache and coherency structure in accordance with a preferred embodiment of the present invention; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram of an exemplary cache configuration of <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrating the copy of individual L1 directory entries within L2 cache in accordance with a preferred embodiment of the invention; and </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flow chart illustrating the process of completing cache operations and utilizing the data processing system of <cross-reference target="DRAWINGS">FIG. 2</cross-reference> in accordance with a preferred embodiment of the present invention. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT </heading>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The present invention may be implemented in any data-processing system having a cache memory hierarchy that includes a primary, level one (L1) cache and a secondary, level two (L2) cache or memory. Preferably, the data processing system comprises multiple central processing units (CPUs) and associated caches. Referring now to the drawings and in particular to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, there is depicted a block diagram of processor-cache components of a data-processing system <highlight><bold>200</bold></highlight> according to a preferred embodiment of the present invention. Data-processing system <highlight><bold>200</bold></highlight> includes four processor chips <highlight><bold>201</bold></highlight>A-<highlight><bold>201</bold></highlight>D. Each processor chip <highlight><bold>201</bold></highlight>A-<highlight><bold>201</bold></highlight>D comprises a CPU (or processor) <highlight><bold>203</bold></highlight>A-<highlight><bold>203</bold></highlight>D and an L1 cache <highlight><bold>205</bold></highlight>A-<highlight><bold>205</bold></highlight>D. Thus, CPU <highlight><bold>203</bold></highlight>A is coupled to L1 cache <highlight><bold>205</bold></highlight>A, while CPU <highlight><bold>203</bold></highlight>D is coupled to L1 cache <highlight><bold>205</bold></highlight>D, etc. Each L1 cache <highlight><bold>205</bold></highlight>A-<highlight><bold>205</bold></highlight>D has an associated L1 directory <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>D. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> According to established configuration of multi-level cache hierarchy, each of L1 cache <highlight><bold>205</bold></highlight>A-<highlight><bold>205</bold></highlight>D is coupled to L2 cache <highlight><bold>209</bold></highlight>. The illustrated embodiment depicts a single L2 cache <highlight><bold>209</bold></highlight> providing the lower level memory cache for all four processing units <highlight><bold>201</bold></highlight>A-<highlight><bold>201</bold></highlight>D; however the invention is also applicable to configurations that includes separate lower level caches for each individual processing unit or for subgroups of processing units. Unlike the current processor configuration of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>A, in which the L1 caches <highlight><bold>105</bold></highlight>A-<highlight><bold>105</bold></highlight>D are interconnected to each other and to the L2 cache <highlight><bold>109</bold></highlight> via multiple cache coherency busses <highlight><bold>111</bold></highlight>, the illustrated processor configuration provides a single (point-to-point) bus connection running from each L1 cache <highlight><bold>205</bold></highlight>A-<highlight><bold>205</bold></highlight>D to the L2 cache <highlight><bold>209</bold></highlight>. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> As illustrated, L2 cache <highlight><bold>209</bold></highlight> includes a copy <highlight><bold>207</bold></highlight>A&prime;-<highlight><bold>207</bold></highlight>D&prime; of each L1 directory <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>D. In the preferred embodiment, a pre-determined portion of L2 cache <highlight><bold>209</bold></highlight> corresponding to the combined sizes of the L1 directories <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>D of the L1 caches <highlight><bold>205</bold></highlight>A-<highlight><bold>205</bold></highlight>D that are supported by the L2 cache <highlight><bold>209</bold></highlight> is allocated to storing copies <highlight><bold>207</bold></highlight>A&prime;-<highlight><bold>207</bold></highlight>D&prime; of the L1 directories <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>D. Precise images of L1 directories <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>D are maintained whenever the L1 cache <highlight><bold>205</bold></highlight>A-<highlight><bold>205</bold></highlight>D is modified, either by the local processor operations or other external operations. In another embodiment, the copies <highlight><bold>207</bold></highlight>A&prime;-<highlight><bold>207</bold></highlight>D&prime; of the L1 directories <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>D are stored in a congruent manner so that a single, continuous memory block <highlight><bold>213</bold></highlight> is allocated within L2 cache <highlight><bold>209</bold></highlight> for all L1 directories <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>D. In another embodiment, the continuous memory block <highlight><bold>213</bold></highlight> is partitioned to provide logical partitions for each L1 directory. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Although not illustrated, L2 cache <highlight><bold>209</bold></highlight> may be further connected to other L2 or lower level caches that support intervention amongst caches. L2 cache <highlight><bold>209</bold></highlight> may also be connected to a system memory via a system-level bus or switch. Thus, although a preferred embodiment of a data-processing system is described in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, it is understood that the present invention can be practiced within a variety of system configurations. It should also be noted that the features of the invention are applicable to both inclusive and non-inclusive cache structures, although the preferred implementation occurs within a non-inclusive cache structure. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> The present invention provides a new cache configuration and coherency operational characteristic that eliminates the need to issue coherency operations (e.g., snoops) directly to the L1 directories within the processor modules. The invention further reduces the hardware requirements for coherency buses connecting the multiple L1 directories to each other and to the L2 directory or maintaining of a L2 directory within the L2 cache. Specifically, the invention recognizes that coherency operations at the L1 cache are conducted from the lower level (L2) cache via the L1 directory entries and thus mirrors the L1 directory entries (i.e., the address tags and coherency states) within a pre-established memory block in the lower level cache. The processing logic, operating system (OS) kernel, and coherency protocols are modified to complete the following three major transactions: </paragraph>
<paragraph id="P-0027" lvl="2"><number>&lsqb;0027&rsqb;</number> (1) initialize the directories of each L1 cache and their copies in the lower level (L2) cache such that both are consistent; </paragraph>
<paragraph id="P-0028" lvl="2"><number>&lsqb;0028&rsqb;</number> (2) maintain the copies of the L1 directories by dynamically updating both copies in a consistent manner whenever a change occurs in the L1 directory; and </paragraph>
<paragraph id="P-0029" lvl="2"><number>&lsqb;0029&rsqb;</number> (3) check for data availability and coherency states of L1 caches during snoop operations, etc. by querying the copy of the L1 directory within the lower level cache. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Initialization of the directories may be completed by copying the initial directory values into a pre-set location in the L2 cache. Alternatively, in the preferred embodiment, the initialization is completed by OS kernel (or other specially provided utility, such as a directory utility) during system boot by marking all lines within the directory and directory copy as invalid. Also, the net result of the operations is the same as directly snooping the L1 directory but requires substantially less coherency bus transactions between the L1 and L2 directories. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> In one embodiment, a separate directory utility (or snoop resolution utility) is implemented that performs the copy of the directory and subsequent maintenance of the directory copy within the lower level cache when modifications are made within the L1 directory. Implementation of the directory utility made include some hardware and software aspects. In the preferred embodiment, software coded blocks are utilized to provide the required functionality. The specific coherency operations and/or responses are programmed within the coherency protocol being utilized. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> With reference now to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, there is illustrated a more detailed block diagram of the L2 cache <highlight><bold>209</bold></highlight> provided in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> with an outlay of L1 directory entries in accordance with a preferred embodiment of the invention. As shown, L2 cache <highlight><bold>209</bold></highlight> comprises 64 cache lines <highlight><bold>305</bold></highlight> (numbered 0 through 63) for data storage and memory block <highlight><bold>305</bold></highlight> with 32 L1 directory copy entries (numbered X0 through X31). Each L1 directory <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>D comprises 8 directory entries corresponding to the eight cache lines in the associated L1 cache <highlight><bold>205</bold></highlight>A-<highlight><bold>205</bold></highlight>D. The L1 directory <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>D may be organized under any caching scheme available, such as fully associative, direct mapped, or set-associative, as are well-known in the art. Each L1 directory <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>B contains address tag field <highlight><bold>301</bold></highlight> and state bit field <highlight><bold>303</bold></highlight>. The tag within address tag field <highlight><bold>301</bold></highlight> may be a full address for a fully associative directory. However, in the preferred embodiment, the tag is a partial address as provided for a direct-mapped directory or a set-associative directory. The bits within state bit field <highlight><bold>303</bold></highlight> are utilized to maintain cache coherency for the data-processing system. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Because the directory entry contains only a tag and cache state, each entry is made up of a relatively small number of bits of information. Thus, for example, each line may comprise 8 bits of information and storage of all 32 entries (i.e., 8 entries for each of the 4 L1 directories <highlight><bold>207</bold></highlight>A-<highlight><bold>207</bold></highlight>B) requires only (8*32) bits of space within the L2 cache. Assuming the L2 cache is only 128 bytes wide, storing the copies of the directories thus requires only two lines of storage space within L2 cache. The size of the directory store is proportional to the size of the L1 caches (i.e., the L1 directories), and not to the size of the L2, and thus, no significant burden is placed on the memory space available within L2 cache. Furthermore, the number of pins required for each processor to support coherency operations is significantly reduced. Additional space may be required for specific tagging information to delineate the directory entries of one L1 directory from the others. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Also, the state changes that occur in the L1 directory are preferably conservative in order to allow for transactions being presently undertaken to be mirrored prior to receipt of a snoop request. This may involve, a temporary holding of the snoop transactions until the present transaction is completed and mirrored within the directory copy. For example, the coherency state on an L1 cache miss for a line that has write permission is charged as follows. When such an operation is encountered, the processor creates room for the new line by invalidating an L1 entry and passing the request to the L2. The L2 resolves coherence on the requested line. Then, the L2 copy of the L1 directory is updated with the new line, and data is passed to the processor, which updates its copy of the L1 directory when the data is received. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> According to this invention, the L1 directories are copied in the cache structure, which is part of the L2 cache or main memory. Accordingly, the snoop operations are conducted on the copies of the L1 directories within the L2 cache. That is, the snoop operations are evaluated in the L2 cache and not in the directories located on the processor chips. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Also, because the combined directories can be implemented as one table, a single point of coherence is provided and the coherence protocols are simplified. If a snoop hits in one of the directories, the processors merely need to be instructed which line in their cache directory needs to change state, and the processor may then take the appropriate action. The action taken by the processor is dependent on the transition that occurs in the coherency states. For example, is the cache line transitions from Exclusive to Invalid, then the processor causes the line to be caste out to the L2 cache. Accordingly, transmitting the full associated address is unnecessary since only the tag address needs to be compared. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> L1 directories that support snoop operations are typically implemented as multi-port arrays to prevent delays of the processor (which must interrogate the directory for cache access) for snoop actions on that same directory. Since the area of a directory array is to first order proportional to the number of bits stored, multiplied by the number of ports on the array, no area is lost by implementing a multiport array as multiple distinct copies. The replication of the L1 directories thus provides noticeable benefits in performance, reduced numbers of pins to each processor, and more efficient coherency operations, without requiring any major increases in hardware real estate. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, there is depicted a flow chart of the process of completing a coherency procedure within the new configuration of the processor-cache hierarchy. The process begins at block <highlight><bold>401</bold></highlight> and thereafter proceeds to block <highlight><bold>403</bold></highlight>, which illustrates initializing the L1 directories and the copies of the L1 directories that are in the L2 cache. This initialization process is completed by the operating system (OS) kernel or a special directory utility executing within the processor and preferably occurs at system (or processor) boot-up or at some other relevant time such as the beginning of execution of a particular application. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Once the L1 directories and directory copies have been initialized, a determination is made as shown at block <highlight><bold>405</bold></highlight>, whether an external snoop (i.e., a snoop from another processor&apos;s cache) is requested. If an external snoop is requested, determination is made at block <highlight><bold>409</bold></highlight> whether a snoop hit occurs in the L2 cache. Following, a next determination is made at block <highlight><bold>411</bold></highlight> whether the snoop also hit in the copy of the L1 directory. The snoop request is checked against the copy of the L1 directory to determine if the cache line is present in the L1 cache. If a cache miss on the L1 directory occurs, the snoop is resolved on the L2 cache as shown at block <highlight><bold>413</bold></highlight>. If, however, a cache hit occurs on the L1 directory, then communication is established with the processor to resolve the snoop on the L1 cache as depicted at block <highlight><bold>415</bold></highlight>. Following, the L1 directories and L1 directory copies are updated, accordingly (i.e., the corresponding coherency state of the cache line in the L1 directory is updated) as shown at block <highlight><bold>417</bold></highlight>. The process then continues to track and respond to update requests from the processor(s). </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> If however, no snoop request is received then a next determination is made at block <highlight><bold>407</bold></highlight> whether a request to update a cache line has been issued from the processor. The processor issues the request to the lower level cache or memory whenever a miss occurs in the L1 cache. The processor(s) makes requests for lines to be read or written or otherwise change state to the L2 (including the L1 directories), and a snoop resolution utility associated with the L2 cache resolves these requests. Accordingly, the L2 cache is informed of any change in the coherency state of a cache line prior to the L1 cache. If the update request from the processor has been issued, then the requested change is made in the L2 cache and the L1 directory copy as indicated at block <highlight><bold>406</bold></highlight>. Then, if necessary, the data is provided to the processor as shown at block <highlight><bold>408</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> While the invention has been particularly shown and described with reference to a preferred embodiment, it will be understood by those skilled in the art that various changes in form and detail may be made therein without departing from the spirit and scope of the invention. For example, while examples are described with specific reference to the MESI coherency states the invention is applicable to any type of coherency protocol which requires lower level caches to communicate with higher level caches during processing operations. Also, the specific processing system topology having a single on-board processor cache interacting with a level 2 cache is provided only for simplification purposes, and the invention may be implemented within other processing system topologies. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A data processing system comprising: 
<claim-text>a processor; </claim-text>
<claim-text>a first level cache coupled to said processor and having an associated first level directory; </claim-text>
<claim-text>a second level cache coupled to said first level cache and having a copy of said first level directory; </claim-text>
<claim-text>a cache coherency utility that resolves snoop requests and completes coherency operations for said first level cache utilizing said copy of said first level directory within said second level cache. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The data processing system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said cache coherency utility further comprises means for dynamically maintaining consistent information between both said first level directory and said copy of said first level directory, wherein all changes within said first level directory are mirrored in said copy of said first level directory. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The data processing system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein, in response to a receipt of a snoop request that hits in both said second level cache and said copy of said first level directory, said cache coherency utility communicates with said processor to resolve said snoop request and update said first level directory and said copy of said first level directory. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The data processing system of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein said cache coherency utility further includes means for delaying a resolution of said snoop request until a previous modification of said copy of said L1 directory is completed. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The data processing system of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, further comprising a next first level cache with an associated first level directory, wherein said second level cache further includes a copy of the first level directory of said next first level cache. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The data processing system of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein said first level directories of said first level cache and said next first level cache are stored within a table of said second level cache. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The data processing system of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein said first level directories of said first level cache and said next first level cache are stored within said second level cache in a congruent manner. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The data processing system of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein said first level cache is an onboard processor cache of said processor, said next first level cache is an onboard processor cache of a next processor of said data processing system, and both said first level directories are each connected to said second level cache via a single coherency bus, wherein all coherency operation amongst said first level directories are transacted with said copies of said first level directories within the lower level cache. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The data processing system of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein said L1 directory is a multi-port array. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A cache memory configuration within a multiprocessor data-processing system comprising: 
<claim-text>multiple first level cache having cache directories and coupled to multiple processors; </claim-text>
<claim-text>a second level cache connected to said first level caches and having a copy of said first level cache directories of said first level caches; and </claim-text>
<claim-text>cache controlling mechanism that resolves snoop requests directed at said first level caches utilizing said copies of said cache directories, within said second level cache. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The cache memory configuration of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein further said cache controlling mechanism includes: 
<claim-text>means for comparing said snoop request with address tags within said copies of said cache directories; and </claim-text>
<claim-text>means, responsive to said comparing means for transmitting said snoop request up to an associated processor of one of first level caches only when a cache hit occurs at a copy of a cache directory of said one first level cache, wherein coherency operation is transmitted to said processor for completion only when required. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The cache memory configuration of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein said cache controlling mechanism is associated with said second level cache and further includes means for maintaining consistent information between said cache directories and said copies of said cache directories. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The cache memory configuration of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein said cache coherency mechanism includes means for delaying resolution of a received snoop request until an ongoing update to a copy of a cache directory is completed. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The cache memory configuration of <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein each of said cache directories is a multi-port array. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The cache memory configuration of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein said first level caches each has a single coherency bus by which it is connected to said second level cache and wherein all coherency and snoop operations of each said first level caches are transacted via said single coherency bus. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A method for providing improved cache operations within a multi-processor data processing system having a first level cache and a lower level cache, said method comprising: 
<claim-text>initializing a copy of a directory of said first level cache, wherein said copy of said directory is provided within said lower level cache; </claim-text>
<claim-text>subsequently transacting all snoop requests that is to be resolved at said first level cache utilizing said copy of said directory within said lower level cache. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, further comprising copying said directory into said lower level cache during system initialization. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein said initializing step includes concurrently initializing said directory along with said copy of said directory. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, further comprising: 
<claim-text>monitoring a receipt from a processor of an update request at said lower level cache; and </claim-text>
<claim-text>responsive to said receipt of said update request, which results in an operation that effects modifications to coherency states of said first level cache, dynamically updating said directory and said copy of said directory to reflect said modifications. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, further comprising, responsive to an indication that a present update to said copy of said L1 directory is being undertaken, delaying resolution of a received snoop request until said update is completed.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>2</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005237A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005237A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005237A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005237A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005237A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005237A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
