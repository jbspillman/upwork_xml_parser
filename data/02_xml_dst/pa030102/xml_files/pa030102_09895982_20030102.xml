<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005239A1-20030102-D00000.TIF SYSTEM "US20030005239A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005239A1-20030102-D00001.TIF SYSTEM "US20030005239A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005239A1-20030102-D00002.TIF SYSTEM "US20030005239A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005239A1-20030102-D00003.TIF SYSTEM "US20030005239A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005239A1-20030102-D00004.TIF SYSTEM "US20030005239A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005239A1-20030102-D00005.TIF SYSTEM "US20030005239A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030005239A1-20030102-D00006.TIF SYSTEM "US20030005239A1-20030102-D00006.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005239</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09895982</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010629</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F012/00</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G06F013/00</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>711</class>
<subclass>150000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Virtual-port memory and virtual-porting</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Lance</given-name>
<middle-name>W.</middle-name>
<family-name>Dover</family-name>
</name>
<residence>
<residence-us>
<city>Fair Oaks</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>BLAKELY SOKOLOFF TAYLOR &amp; ZAFMAN</name-1>
<name-2></name-2>
<address>
<address-1>12400 WILSHIRE BOULEVARD, SEVENTH FLOOR</address-1>
<city>LOS ANGELES</city>
<state>CA</state>
<postalcode>90025</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The present invention is in the field of memory. More particularly, embodiments of the present invention can enhance an interface of a memory device by processing more than one request at a time. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present invention is in the field of data storage. More particularly, the present invention provides a method, apparatus, system, and machine-readable medium to process more than one request at a time. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> A host requesting a read from a memory device, typically called a requester, can incur a significant amount of idle time as a result of the interface between the memory controller and the memory device. The memory controller may connect to multiple hosts via a bus to receive and respond to requests to read data from a memory device. The memory device may connect to the memory controller via a second bus such that the memory controller can forward a single read or write transaction from a requester to the memory device. The memory device can respond to the first request before accepting a second request. Before the memory controller forwards the request to the memory device, a second host may request a read from the same memory device, resulting in idle time for the second requester. For example, a second requester may request a read to obtain an address for a jump command within a software program. The code to execute at the address for the jump command may be critical data because the address may be in memory within the second requester, but the second requester may not execute the code until it receives the address. Further, the second requester will not receive that address until after the response to the first requester is complete. Thus, the second requester can remain idle from the moment it needs the address until the memory controller returns a complete response to the first requester and returns the critical data to the second requester. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> While the memory device may receive and process one request at a time, hardware within the memory device connected to memory units may remain idle during the processing of that request. For example, the memory device may have several partitions of memory and each partition may have several memory-sensing devices. However, a memory-sensing device in one partition may perform the entire request while memory sensing devices in the same partition and other partitions remain idle. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Systems may reduce the frequency of a host&apos;s idle time by attaching multiple memory devices to the memory controller or incorporating a very high performance memory device that can handle parallel requests, i.e. a multiple-port memory device. Using multiple memory devices, however, can be disadvantageous as a result of added component costs, complexity for the memory controller, costs in terms of modifying the data bus to connect the memory controller to the multiple memory devices, space used by the bus in the extra memory devices, and space within the host system. Similarly, a very high performance memory device can be cost-prohibitive from a design standpoint as well as complicated as a result of competition between hosts for lower latency access to the single memory device.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF FIGURE DESCRIPTIONS </heading>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In the accompanying drawings like references may indicate some similarities between elements: </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> depicts a digital data storage and retrieval system with multiple hosts. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> depicts a data storage and retrieval system. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> depicts a flow chart to sense critical and non-critical data. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> depicts a timing diagram for three requests to sense data. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> depicts a machine-readable medium comprising instructions to sense data. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> depicts a wireless communications device.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF EMBODIMENTS </heading>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> The following is a detailed description of example embodiments of the invention depicted in the accompanying drawings. The example embodiments are in such detail as to clearly communicate the invention. However, the amount of detail offered is not intended to limit the anticipated variations of embodiments. The variations of embodiments anticipated are too numerous to discuss individually so the detailed descriptions below are designed to make such embodiments obvious to a person of ordinary skill in the art. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, there is shown an example system embodiment. A first host <highlight><bold>100</bold></highlight> and a second host <highlight><bold>105</bold></highlight> couple to a memory controller <highlight><bold>120</bold></highlight> via a bus <highlight><bold>110</bold></highlight>. The first host <highlight><bold>100</bold></highlight> and second host <highlight><bold>105</bold></highlight> are microprocessor-based systems that can access the virtual-port memory device <highlight><bold>150</bold></highlight>. The bus <highlight><bold>110</bold></highlight> may be a data bus that can transmit a single transaction at a time from either the first host <highlight><bold>100</bold></highlight> or the second host <highlight><bold>105</bold></highlight> to the memory controller <highlight><bold>120</bold></highlight>. For the present example embodiment, the first host <highlight><bold>100</bold></highlight> and the second host <highlight><bold>105</bold></highlight> have equal access to bus <highlight><bold>110</bold></highlight> via a round robin type arbitration scheme. In some embodiments, memory controller <highlight><bold>120</bold></highlight> may also have access to bus <highlight><bold>110</bold></highlight> to respond to a transaction initiated by a host, to return a status of a transaction initiated by a host, or to return data retrieved from virtual-port memory <highlight><bold>150</bold></highlight> for a host. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Memory controller <highlight><bold>120</bold></highlight> may receive a transaction from first host <highlight><bold>100</bold></highlight> or second host <highlight><bold>105</bold></highlight> and forward that transaction to virtual-port memory device <highlight><bold>150</bold></highlight> via bus <highlight><bold>140</bold></highlight>. The memory controller <highlight><bold>120</bold></highlight> may be designed to interact with one or more data storage devices such as flash memory, random access memory, static random access memory, dynamic random access memory, read only memory, etc. . . . When bus <highlight><bold>140</bold></highlight> is busy with another transaction, memory controller <highlight><bold>120</bold></highlight> can store the transaction from a host until bus <highlight><bold>140</bold></highlight> is available. Similarly, memory controller <highlight><bold>120</bold></highlight> can store a transaction from either the first host <highlight><bold>100</bold></highlight> or the second host <highlight><bold>105</bold></highlight> when the virtual-port memory device <highlight><bold>150</bold></highlight> is busy with another transaction, typically referred to as a request. Memory controller <highlight><bold>120</bold></highlight> comprises a host response interpreter <highlight><bold>125</bold></highlight>, a host response queue <highlight><bold>130</bold></highlight>, and a host request queue <highlight><bold>135</bold></highlight>. The host request queue <highlight><bold>135</bold></highlight> may store a request from the first host <highlight><bold>100</bold></highlight> or the second host <highlight><bold>105</bold></highlight> until bus <highlight><bold>140</bold></highlight> and virtual-port memory device <highlight><bold>150</bold></highlight> are available to receive the request. For example, memory controller <highlight><bold>120</bold></highlight> may receive a read request from first host <highlight><bold>100</bold></highlight> and attempt to forward the transaction to the virtual-port memory device <highlight><bold>150</bold></highlight>. The virtual-port memory device <highlight><bold>150</bold></highlight> may reply to the request from the memory controller <highlight><bold>120</bold></highlight> with a busy or retry, and store the request from first host <highlight><bold>100</bold></highlight> in the host request queue <highlight><bold>135</bold></highlight>. In addition, the second host <highlight><bold>105</bold></highlight> may initiate a request for a read from virtual-port memory device <highlight><bold>150</bold></highlight> on bus <highlight><bold>110</bold></highlight>. Memory controller <highlight><bold>120</bold></highlight> may give a higher priority to the request from host <highlight><bold>100</bold></highlight> since it was first in time so the request from second host <highlight><bold>105</bold></highlight> may be stored in the host request queue <highlight><bold>135</bold></highlight> in a second priority position. In some embodiments, the memory controller <highlight><bold>120</bold></highlight> may store a priority tag with the transaction in the host request queue <highlight><bold>135</bold></highlight>. In other embodiments, the first host <highlight><bold>100</bold></highlight> or the second host <highlight><bold>105</bold></highlight> may attach a priority to the transaction forwarded to the memory controller <highlight><bold>120</bold></highlight>. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> When the virtual-port memory device <highlight><bold>150</bold></highlight> becomes available, the memory controller <highlight><bold>120</bold></highlight> may forward the first transaction, the highest priority transaction in the host request queue <highlight><bold>135</bold></highlight>, via bus <highlight><bold>140</bold></highlight>. Then, the memory controller <highlight><bold>120</bold></highlight> can forward the second request in the host request queue <highlight><bold>135</bold></highlight> to the virtual-port memory device <highlight><bold>150</bold></highlight> when the bus <highlight><bold>140</bold></highlight> and virtual-port memory device <highlight><bold>150</bold></highlight> are available to receive the request. The virtual-port memory device <highlight><bold>150</bold></highlight> may be available as soon as the bus <highlight><bold>140</bold></highlight> becomes available since the virtual-port memory device <highlight><bold>150</bold></highlight> can handle more than one request simultaneously. The virtual-port memory device <highlight><bold>150</bold></highlight> can comprise redundant circuitry to sense data to facilitate sensing data of more than one request simultaneously. In many embodiments, the virtual-port memory device <highlight><bold>150</bold></highlight> may sense critical data of a second request prior to completing a response to a first request. In particular, these embodiments may return critical data of a number of requests, e.g. the first and second request, prior to returning the non-critical data of those requests. Thus, the idle time of a host waiting to receive critical data may be attenuated. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Referring still to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the host response interpreter <highlight><bold>125</bold></highlight> may receive responses from virtual-port memory device <highlight><bold>150</bold></highlight> via bus <highlight><bold>140</bold></highlight>. The host response interpreter <highlight><bold>125</bold></highlight> may interpret the priority of the response to determine when a response should be forwarded immediately to the requester. When the response from the virtual-port memory device <highlight><bold>150</bold></highlight> comprises critical data, or high priority data, the host response interpreter <highlight><bold>125</bold></highlight> may initiate a transaction on bus <highlight><bold>110</bold></highlight> to return the critical data to the requester as soon as bus <highlight><bold>110</bold></highlight> becomes available. In some embodiments, the response received from the virtual-port memory device <highlight><bold>150</bold></highlight> contains a tag to identify a transaction of a sequence and the host response interpreter <highlight><bold>125</bold></highlight> may combine several responses from the virtual-port memory device <highlight><bold>150</bold></highlight> into a burst response transaction according to the tag to send to the requester. The response can be combined by the host response interpreter <highlight><bold>125</bold></highlight> in the host response queue <highlight><bold>130</bold></highlight>. Further, when bus <highlight><bold>110</bold></highlight> is busy, the memory controller <highlight><bold>120</bold></highlight> may be unable to initiate a transaction to return data to the host requester so the response may be stored in the host response queue <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> In some embodiments, the host response interpreter <highlight><bold>125</bold></highlight> may combine the responses into a burst response transaction as it stores the responses in host response queue <highlight><bold>130</bold></highlight>. In other embodiments, the critical data may be placed in the host response queue <highlight><bold>130</bold></highlight> and the requester, the first host <highlight><bold>100</bold></highlight> or the second host <highlight><bold>105</bold></highlight>, may retrieve the data from the host response queue <highlight><bold>130</bold></highlight>. Similarly, the requester may retrieve the burst transaction stored in host response queue <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The virtual-port memory device <highlight><bold>150</bold></highlight> may receive more than one request via bus <highlight><bold>140</bold></highlight>, sense the critical data for each request, and return the critical data to the memory controller <highlight><bold>120</bold></highlight> as soon as bus <highlight><bold>140</bold></highlight> is available. In some embodiments, the critical data is returned to the memory controller <highlight><bold>120</bold></highlight> in a chronological sequence of receipt. In other embodiments, the memory controller <highlight><bold>120</bold></highlight> may forward a priority indication along with each request and the critical data may be returned to the memory controller <highlight><bold>120</bold></highlight> in the order of priority. When the request from the memory controller <highlight><bold>120</bold></highlight> also comprises a transaction tag identifying the requester, the virtual-port memory device <highlight><bold>150</bold></highlight> may return the critical data in any order with that identification attached. For instance, the critical data for the second request received by the virtual-port memory device <highlight><bold>150</bold></highlight> may be available to return to the memory controller <highlight><bold>120</bold></highlight> before the critical data for the first request so the arbiter of the virtual-port memory device <highlight><bold>150</bold></highlight> can return the critical data for the second request first. In alternative embodiments, the memory controller <highlight><bold>120</bold></highlight> may continue to request the highest priority critical data from the virtual-port memory device <highlight><bold>150</bold></highlight> and read the critical data out of a queue in the virtual-port memory device <highlight><bold>150</bold></highlight> when it becomes available. The virtual-port memory device <highlight><bold>150</bold></highlight> may then sense non-critical data requested by a host. In many embodiments, the virtual-port memory device <highlight><bold>150</bold></highlight> can begin sensing non-critical data while or before completing a sense of critical data. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Data for more than one request may be sensed simultaneously or substantially simultaneously when more than one sensing device is available. For example, virtual-port memory device <highlight><bold>150</bold></highlight> may service a request from first host <highlight><bold>100</bold></highlight> and a request from second host <highlight><bold>105</bold></highlight>. The first host <highlight><bold>100</bold></highlight> may request a read of eight words of data from one partition and the second host <highlight><bold>105</bold></highlight> may request a read of eight words of data from a second partition within the virtual-port memory device <highlight><bold>150</bold></highlight>. Four words from each request may be performed simultaneously or substantially simultaneously because the memory sensing devices in each partition may handle four reads simultaneously or substantially simultaneously. Several embodiments comprise an arbiter that can determine when a request, such as a request for a critical word, should be in the first group of four words sensed for first and the second request. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> The output of each memory-sensing device in the virtual-port memory device <highlight><bold>150</bold></highlight> may be coupled to an output queue to facilitate a response to the memory controller <highlight><bold>120</bold></highlight>. In some embodiments, a pointer for the queue can determine the address in the queue for the data sensed by the memory-sensing device. Many of the embodiments increment a pointer each time new data is placed in the queue. In other embodiments, an arbiter can adjust the pointer to point at an address based on the priority determined for the data sensed or the pointer location may be based on the physical location of the memory-sensing device. For instance, the arbiter may reserve part of the queue for critical data or for an offset for each unit of critical data in the queue, determine the address for a pointer for a memory-sensing device, and comprise a priority determiner to determine the data to be treated as critical data. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Once data is available in the virtual-port memory device <highlight><bold>150</bold></highlight> to return to the memory controller <highlight><bold>120</bold></highlight>, the virtual-port memory device <highlight><bold>150</bold></highlight> may transmit the data in a time sliced manner. For example, the virtual-port memory device <highlight><bold>150</bold></highlight> may return a first word in response to the request from first host <highlight><bold>100</bold></highlight> since it was received first chronologically, then a second word in response to the request from second host <highlight><bold>105</bold></highlight>, then a third word in response to requests from first host <highlight><bold>100</bold></highlight> again, and continue to alternate between hosts in fixed time intervals until the complete requests for both the first host <highlight><bold>100</bold></highlight> and the second host <highlight><bold>105</bold></highlight> are returned to memory controller <highlight><bold>120</bold></highlight>. In several of these embodiments, the fixed time intervals can be selected based upon the priority of the request for the data. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> In alternate embodiments, a dedicated packet identification (ID) may be used to transmit an ID along with the transaction from the first host <highlight><bold>100</bold></highlight> or the second host <highlight><bold>105</bold></highlight> to the memory controller <highlight><bold>120</bold></highlight>. In many of these embodiments, the memory controller <highlight><bold>120</bold></highlight> may assign an abbreviated tag to forward to the virtual-port memory device <highlight><bold>150</bold></highlight>. For instance, when the virtual-port memory device <highlight><bold>150</bold></highlight> accepts two requests at any one time, the memory controller <highlight><bold>120</bold></highlight> can use a single binary digit to identify the transaction. A &ldquo;0&rdquo; may indicate the first request chronologically sent to the virtual-port memory device <highlight><bold>150</bold></highlight> and a &ldquo;1&rdquo; may indicate the second request chronologically sent the virtual-port memory device <highlight><bold>150</bold></highlight>. In other cases, the binary digit may just be alternated as a request is sent and received from memory controller <highlight><bold>120</bold></highlight>. In further embodiments, a multiplexing procedure may be implemented to return data from the virtual-port memory device <highlight><bold>150</bold></highlight> to the memory controller <highlight><bold>120</bold></highlight>. In many of these embodiments, a protocol for the virtual-port memory device <highlight><bold>150</bold></highlight> in the memory controller <highlight><bold>120</bold></highlight> to follow can coordinate the exchange of requests and responses such that the memory controller <highlight><bold>120</bold></highlight> can identify each response from virtual-port memory device <highlight><bold>150</bold></highlight> with a transaction from a host without additional communication. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, there is shown an example embodiment. The memory device <highlight><bold>200</bold></highlight> may comprise a response arbiter <highlight><bold>205</bold></highlight>, a response queue <highlight><bold>210</bold></highlight>, a request arbiter <highlight><bold>225</bold></highlight>, a request queue <highlight><bold>230</bold></highlight>, memory sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight>, and a memory unit <highlight><bold>220</bold></highlight>. The request arbiter <highlight><bold>225</bold></highlight> can be designed to receive requests to sense memory, assign requests or parts of requests to a group such that the data within that group can be sensed simultaneously or substantially simultaneously, and comprise a priority determiner to determine the sequence that each group should be acted upon. In many embodiments, the request arbiter <highlight><bold>225</bold></highlight> can forward read requests to an idle memory sensing device <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight>, and <highlight><bold>240</bold></highlight>, as soon as the request is received. Many embodiments comprising redundant circuitry to sense data simultaneously may handle more than one request efficiently since requests may focus on one area of memory, such as a partition or group of partitions. When requests received by an embodiment leave redundant circuitry idle, the embodiment may indicate that it is available for an additional transaction until either the redundant circuitry is used or the request queue to store requests reached full capacity. Several of these embodiments design the request queue <highlight><bold>230</bold></highlight> to store a number of requests based on the types of transactions typically received by the embodiment. In the present embodiment, the request arbiter <highlight><bold>225</bold></highlight> is coupled to the request queue <highlight><bold>230</bold></highlight> to store requests until memory can be sensed in response to the requests. Further, the request arbiter <highlight><bold>225</bold></highlight> is coupled to the memory sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight> to coordinate sensing of the groups of requests. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The request queue <highlight><bold>230</bold></highlight> may store the number of requests that can be handled by the memory device <highlight><bold>200</bold></highlight> at one time. The number of requests that can be handled by memory device <highlight><bold>200</bold></highlight> at one time may be based on the amount of redundant circuitry available, such as the memory sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight>, as well as, the number of these devices that can support simultaneous or substantially simultaneous transactions. For instance, memory sensing devices <highlight><bold>215</bold></highlight> and <highlight><bold>240</bold></highlight> may be able to sense data simultaneously but memory sensing devices <highlight><bold>215</bold></highlight> and <highlight><bold>235</bold></highlight> may not be able to sense data simultaneously. Many embodiments comprise parallel access to more than one request in the request queue <highlight><bold>230</bold></highlight>. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Memory sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight> can be designed to sense data in memory unit <highlight><bold>220</bold></highlight>. In the present embodiment, memory-sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight> are independently coupled to memory unit <highlight><bold>220</bold></highlight> to sense data simultaneously. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Memory unit <highlight><bold>220</bold></highlight> is designed to store data. Response arbiter <highlight><bold>205</bold></highlight> can receive data from memory sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight>, and store the data in response queue <highlight><bold>210</bold></highlight>, when the data cannot or need not be returned immediately to the requester. The response arbiter also comprises a priority determiner to determine the sequence that the data should be returned to the requester. Critical data may be marked by placing the critical data in an area of the response queue <highlight><bold>210</bold></highlight> reserved for critical data or by associating the data with a tag in the response queue <highlight><bold>210</bold></highlight> to indicate to the response arbiter <highlight><bold>205</bold></highlight> that the data is critical data. In some embodiments, the response arbiter <highlight><bold>205</bold></highlight> can combine data received from memory sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight> into burst transactions. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The response arbiter <highlight><bold>205</bold></highlight> can be coupled to the request arbiter <highlight><bold>225</bold></highlight> to correlate the data received from the memory sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight> with the transaction or request for that data. For instance, the request may be accompanied by a <highlight><bold>25</bold></highlight> transaction ID or packet ID and the response arbiter <highlight><bold>205</bold></highlight> may associate the packet ID or transaction ID with the data before returning the data. In alternative embodiments, the functions of the response arbiter <highlight><bold>205</bold></highlight> and the request arbiter <highlight><bold>225</bold></highlight> can be combined into one arbiter for the memory device <highlight><bold>200</bold></highlight>. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> Referring still to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, when one or more of the requests received by the memory device <highlight><bold>200</bold></highlight> comprise a request for critical data, a request arbiter <highlight><bold>225</bold></highlight> may mark the critical data requests as the highest priority requests to be sensed by memory sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight>. The response arbiter <highlight><bold>205</bold></highlight> can receive the critical data and return the critical data to the requester or memory controller as soon as possible or within a predetermined number of cycles. In some embodiments, the critical data is made available in the response queue <highlight><bold>210</bold></highlight> for the requester or memory controller to retrieve. Both critical data and non-critical data may be organized and transmitted by the response arbiter <highlight><bold>205</bold></highlight> to a host with burst granularity, in a serial manner, with word granularity in a time-sliced manner, or by mutual tracking by both the host and the memory device <highlight><bold>200</bold></highlight>. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Although <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates a single serial port memory device that accepts multiple requests, embodiments may have more than one serial port, each port accepting more than one request. In addition, each serial port can have two or more memory sensing devices <highlight><bold>215</bold></highlight>, <highlight><bold>235</bold></highlight> and <highlight><bold>240</bold></highlight> that can sense data from a memory unit simultaneously or substantially simultaneously. In many of these embodiments, the response queue <highlight><bold>210</bold></highlight> and the request queue <highlight><bold>230</bold></highlight> may be parts of the same memory. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 3, a</cross-reference> flowchart of an example embodiment is shown. The flowchart of the example embodiment comprises receiving more than one request for sensing data in a memory unit <highlight><bold>300</bold></highlight>, sensing data in the memory unit <highlight><bold>320</bold></highlight>, returning critical data in response to said receiving more than one request <highlight><bold>330</bold></highlight>, and returning non-critical data <highlight><bold>340</bold></highlight>. Receiving more than one request for sensing data in a memory unit <highlight><bold>300</bold></highlight> can receive more than one request from a single host or a request from more than one host. In some embodiments, receiving more than one request for sensing data in a memory unit <highlight><bold>300</bold></highlight> can comprise receiving a request via a memory controller and storing the request in a request queue. Receiving more than one request for sensing data in a memory unit <highlight><bold>300</bold></highlight> may comprise receiving a second transaction before completing a response to a first transaction <highlight><bold>305</bold></highlight> or receiving a request to read critical data <highlight><bold>310</bold></highlight> or both. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Receiving a second transaction before completing a response to a first transaction <highlight><bold>305</bold></highlight> can comprise receiving one full transaction then receiving a second full transaction from a host via a memory controller. A second transaction may be received prior to completing the response to the first transaction to make use of redundant circuitry, e.g. sensing hardware, within a memory device. The redundant circuitry may be able to sense simultaneously or substantially simultaneously, facilitating low latency, high bandwidth access to a memory of the memory device. In some embodiments, receiving a second transaction before completing a response to a first transaction <highlight><bold>305</bold></highlight> may comprise receiving part of a response of a first transaction, part of a response of a second transaction, and then the remainder of the response of the first and the second transaction from a host. For example, the critical data portion of a first request may be received first, a critical data portion of a second request may be received second, and the remainder of the first and second requests may be received subsequently. In other embodiments, a portion of more than one request may be grouped by priority or sequence by a host or memory controller and received in a serial transmission according to the priority or sequence. Thus, critical data that may cause delay or idle time for hosts may be returned to the hosts quickly. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> Receiving a request to read critical data <highlight><bold>310</bold></highlight> can comprise receiving a portion of a transaction or receiving a complete transaction. Levels of priority for critical data may be based on the priority of the function that the requester is performing, the priority of the requester, the amount of idle time incurred by the requester as a result of the delay, or a function of more than one of these factors. In some embodiments, receiving a request to read critical data <highlight><bold>310</bold></highlight> may comprise receiving groups of requests in descending priorities within a priority level range considered critical data. Many embodiments comprise receiving a transaction having a priority tag that indicates the request is for critical data. In other embodiments, receiving a request to read critical data <highlight><bold>310</bold></highlight> can distinguish priority levels for requests by receiving a transaction on the leading edge of the clock signal or the falling edge of the clock signal. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, sensing data in the memory unit <highlight><bold>320</bold></highlight> can comprise instructing more than one memory sensing device to sense data simultaneously or substantially simultaneously in one or more priority levels or in a particular sequence. Sensing data in the memory unit <highlight><bold>320</bold></highlight> can comprise determining an order to sense data based on available redundant circuitry <highlight><bold>325</bold></highlight>. Determining an order to sense data based on available redundant circuitry <highlight><bold>325</bold></highlight> can comprise immediately instructing memory sensing devices to sense the critical data or instructing memory sensing devices to sense the critical data as soon as memory sensing devices become available. Determining an order to sense data based on available redundant circuitry <highlight><bold>325</bold></highlight> can comprise ordering non-critical data according to chronological order of receipt of the requests for the non-critical data, ordering non-critical data according to a priority tag received with the request to sense the non-critical data, and ordering the non-critical data according to the ability to sense the data simultaneously or substantially simultaneously. In some embodiments, sensing data in the memory unit <highlight><bold>320</bold></highlight> can comprise instructing one or more memory sensing devices to sense the requested data. In further embodiments, sensing data in the memory unit <highlight><bold>320</bold></highlight> may also comprise storing the data in a response queue, combining the data into burst transactions, and/or forwarding the data immediately to the host, e.g. the memory controller or requester. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Returning critical data in response to said receiving more than one request <highlight><bold>330</bold></highlight> may apply a higher priority to a request for critical data than a response to a host that contains non-critical data. Interrupting a response to a first request comprising non-critical data to return critical data in response to a second request <highlight><bold>335</bold></highlight> may embody a result of the higher priority for critical data requests. Interrupting a response to a first request comprising non-critical data to return critical data in response to a second request <highlight><bold>335</bold></highlight> may forward critical data sensed in response to a second request to the corresponding host before completing a response to a first request having non-critical data. For example, a first request may be received from a host that comprises critical data and non-critical data. Sensing data in the memory unit <highlight><bold>320</bold></highlight> may sense the critical data and the critical data may be returned to the host. Then, sensing data in the memory unit <highlight><bold>320</bold></highlight> may begin sensing non-critical data. While non-critical data is being returned to the host in response to the first request, a second request may be received comprising a request for critical data. Returning critical data in response to said receiving more than one request <highlight><bold>330</bold></highlight> may interrupt the transaction returning the non-critical data in response to the first request to return the critical data in response to the second request. Then returning non-critical data <highlight><bold>340</bold></highlight> may return the remainder of the non-critical data for the first request and second request. In some embodiments, the remainder of the non-critical data for the first request can be returned before returning the non-critical data for the second request. In other embodiments, the non-critical data for the first request is broken into units and alternating units of non-critical data for the first request and second request are returned. The units can be words, double words or any other convenient granular size. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Returning non-critical data <highlight><bold>340</bold></highlight> can comprise returning non-critical data in accordance with a pre-defined protocol <highlight><bold>345</bold></highlight> and/or returning non-critical data in an order based upon a priority attached to the more than one request <highlight><bold>360</bold></highlight>. When returning non-critical data in accordance with a pre-defined protocol <highlight><bold>345</bold></highlight> many different methods of returning data for more than one request can be implemented including responding to each request of the more than one request with time-sliced burst data <highlight><bold>350</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Responding to each request of the more than one request with time-sliced burst data <highlight><bold>350</bold></highlight> can comprise returning one word per request each clock cycle and alternating between the first request and the second request each clock cycle. On the other hand, if a second request is received two clock cycles after a first request is received, responding to each request of the more than one request with time-sliced burst data <highlight><bold>350</bold></highlight> can comprise returning one word per clock cycle for two clock cycles for the first request, then returning one word per clock cycle for two clock cycles for the second request and so on, alternating between the first request and the second request until data completely responding to the first request and the second request is returned to the host. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> Returning non-critical data in an order based upon a priority attached to the more than one request <highlight><bold>360</bold></highlight> may include grouping data sensed in response to the first request into a first priority level, returning the data in a burst transaction to the host, then returning the sensed data in response to the second request at the same priority level to the host. Data sent in response to the first request and the second request can be returned in descending priority levels, in an alternating procedure, until all the data sensed in response to the first request and second request is returned to the host. Returning non-critical data in an order based upon a priority attached to the more than one request <highlight><bold>360</bold></highlight> can also comprise interpreting a priority tag attached to the request for the data. For example, while receiving a first request, a tag indicating the priority level of the data requested may be periodically received, classifying each data request within a transaction. The data may be sensed in a sequence from highest to lowest priority then returned to the host in the same highest to lowest priority sequence. When a second request is received containing the same and higher priority data request, the higher priority data request sensed in response to the second request may be returned to the host prior to returning data sensed in response to lower priority data requests in the first transaction. Then data sent in response to the first request may be returned in an alternating order according to descending priority with data sensed in response to the second request. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> In alternative embodiments, returning non-critical data in accordance with a pre-defined protocol <highlight><bold>345</bold></highlight> can comprise alternating between each pending request, every leading edge of a clock cycle or every falling edge of a clock cycle. In some of these embodiments, the priority level of a first request in a first transaction can be incremented as additional transactions are received to prevent the lowest priority request within the first transaction from being continually superseded by subsequent, higher priority requests in subsequent transactions. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> In still further embodiments, the first unit of data in a request may be defined as critical data and the remaining units of data requested may be defined as non-critical data. For example, a first requester may request two or more words of data in a transaction. The first word is defined as a critical word of data and the remaining one or more words requested in that transaction are defined as non-critical words. The first word can be sensed and transmitted back in a response as soon as possible. When a second transaction is received, the first word can be sensed and given priority to be transmitted higher than transmitting a response comprising the non-critical data of the first transaction. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, there is shown a timing diagram of example embodiments. The timing diagram illustrates actions of example embodiments to a specific set of requests in a time window from negative one to twenty-two clock cycles <highlight><bold>400</bold></highlight>. The clock signal (CLK) <highlight><bold>410</bold></highlight> is illustrated for each cycle. The valid address received signal (ADV&num;) <highlight><bold>420</bold></highlight> indicates that a valid address was received for Req. A <highlight><bold>422</bold></highlight> at cycle 0, Req. B <highlight><bold>425</bold></highlight> at cycle 1, and Req. C <highlight><bold>427</bold></highlight> at cycle 2. In addition, the timing diagram illustrates when the data is being transferred on the data signal line <highlight><bold>430</bold></highlight> as well as the status of requests A, B and C, on lines REQ A <highlight><bold>440</bold></highlight>, REQ B <highlight><bold>450</bold></highlight>, and REQ C <highlight><bold>460</bold></highlight>, respectively. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> Sensing data in the memory unit in response to request A commences upon receiving a valid address for request A <highlight><bold>422</bold></highlight>, as illustrated by complete sense A <highlight><bold>443</bold></highlight>. Returning the critical data in response to request A, critical word (CWA) <highlight><bold>431</bold></highlight>, can commence upon the completion of complete sense A <highlight><bold>443</bold></highlight> at the beginning of complete cycle A <highlight><bold>445</bold></highlight>. One cycle after receiving a valid address for request A <highlight><bold>422</bold></highlight>, a valid address for request B <highlight><bold>425</bold></highlight> is received. Complete sense B <highlight><bold>453</bold></highlight> is initiated upon receiving the valid address for request B <highlight><bold>425</bold></highlight> and completes one cycle after complete sense A <highlight><bold>443</bold></highlight>. Complete sense C <highlight><bold>463</bold></highlight> is initiated upon receiving a valid address for request C <highlight><bold>427</bold></highlight>, one cycle after receiving the valid address for request B <highlight><bold>425</bold></highlight>, and ends one cycle after complete sense B <highlight><bold>453</bold></highlight>. Thus, the critical word sensed in response to request B (CWB) <highlight><bold>432</bold></highlight> is returned to the host immediately after CWA <highlight><bold>431</bold></highlight> and the critical word sensed in response to request C (CWC) <highlight><bold>433</bold></highlight> is returned to the host immediately following CWB <highlight><bold>432</bold></highlight>. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> Upon returning the critical words of requests A, B and C to the host, the non-critical data for requests A, B and C, <highlight><bold>434</bold></highlight>, <highlight><bold>435</bold></highlight>, <highlight><bold>436</bold></highlight>, and <highlight><bold>437</bold></highlight>, are returned to the host. In the present embodiments, the sensing of data for requests A, B and C completes in cycles 5, 6 and <highlight><bold>7</bold></highlight>, respectively, so all the data requested by requests A, B and C are stored in a response queue awaiting transactions to return the data to the host. The non-critical data sensed in response to requests A, B and C, as illustrated by data groups <highlight><bold>434</bold></highlight>, <highlight><bold>435</bold></highlight>, <highlight><bold>436</bold></highlight> and <highlight><bold>437</bold></highlight>, return the non-critical data to the host in a time-sliced, one-word-burst transaction. More specifically, non-critical data sensed in response to request A are returned on the falling edge of cycles 8, 11, 14 and 17 in non-critical data groups <highlight><bold>434</bold></highlight>, <highlight><bold>435</bold></highlight>, <highlight><bold>436</bold></highlight> and <highlight><bold>437</bold></highlight>. Non-critical data sensed in response to request B are returned one cycle after each word of non-critical data is returned in response to request A. Further, non-critical data for request C is returned one cycle after non-critical data for request B is returned within the same data groups <highlight><bold>434</bold></highlight>, <highlight><bold>435</bold></highlight>, <highlight><bold>436</bold></highlight> and <highlight><bold>437</bold></highlight>. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Referring still to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, sensing data for more than one request simultaneously or substantially simultaneously is illustrated by the status lines complete sense A <highlight><bold>443</bold></highlight>, complete sense B <highlight><bold>453</bold></highlight> and complete sense C <highlight><bold>463</bold></highlight>. During cycles 2, 3 and 4, data is being sensed in response to requests A, B and C. During cycles 1 and 5, data is being sensed in response to requests A and B, and B and C, respectively. Under alternative conditions such as when a valid address is received for request B <highlight><bold>425</bold></highlight> more than one cycle after request A <highlight><bold>422</bold></highlight>, the critical word sensed in response to request B, CWB <highlight><bold>432</bold></highlight>, may be returned to the host more than one cycle CWA <highlight><bold>431</bold></highlight> is returned to the host. In alternative embodiments, data may be returned to the host on the rising edge of the clock signal <highlight><bold>410</bold></highlight>. Further, some embodiments allow more than one word to transfer back to the host during a single cycle. In still further embodiments, two or more requests may be received depending upon the availability of redundant circuitry. Redundant circuitry may be spread across more than one partition of memory so the number of transactions that may be handled simultaneously or substantially simultaneous may be dependent upon the location of the memory being sensed by each transaction. For instance, if a transaction focuses on one section of memory, other sections of the memory may be coupled to redundant circuitry that can remain idle unless an additional transaction is accepted. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 5, a</cross-reference> machine-readable medium embodiment is shown. A machine-readable medium includes any mechanism that provides (i.e. stores and or transmits) information in a form readable by a machine (e.g., a computer), that when executed by the machine, can perform the functions described herein. For example, a machine-readable medium may include read only memory (ROM); random access memory (RAM); magnetic disk storage media; optical storage media; flash memory devices; electrical, optical, acoustical or other form of propagated signals (e.g. carrier waves, infrared signals, digital signals, etc.); etc. . . . Several embodiments can comprise more than one machine-readable medium depending on the design of the machine. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> The machine-readable medium <highlight><bold>500</bold></highlight> can comprise instructions for receiving more than one request for sensing data in a memory unit <highlight><bold>510</bold></highlight>, sensing data in the memory unit <highlight><bold>530</bold></highlight>, returning critical data in response to said receiving more than one request <highlight><bold>540</bold></highlight>, and returning non-critical data <highlight><bold>550</bold></highlight>. Receiving more than one request for sensing data in a memory unit <highlight><bold>510</bold></highlight> may include receiving a first request and a second request and storing the requests within a request queue. When the first request comprises a request for critical data, sensing data in the memory unit <highlight><bold>530</bold></highlight> can include initiating the sensing of the critical data. When the second request to sense data comprises a request to sense critical data, the critical data for the second request may be sensed simultaneously, substantially simultaneously, or immediately following the sensing of critical data for the first request. Receiving more than one request for sensing data in a memory unit <highlight><bold>510</bold></highlight> may comprise receiving a second transaction before completing a response to a first transaction <highlight><bold>515</bold></highlight>. Receiving a second transaction before completing a response to a first transaction <highlight><bold>515</bold></highlight> may comprise receiving more than one transaction to read non-critical data and storing the non-critical read requests in a request queue. Instructions to receive a second transaction prior to completing a response to a first transaction can facilitate efficient use of redundant sensing hardware in a memory device. For example, a memory device may have sensing hardware that may remain idle while processing a first transaction when the first transaction requests data from the same partition or partitions of memory. Accepting a second transaction, or more, may allow hardware in other partitions of the memory device to sense data simultaneously or substantially simultaneously. Further, critical data requested in the second request may be sensed prior to completing a response to the first request to reduce the occurrence of idle time in a host resulting from waiting for critical data. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Sensing data in the memory unit <highlight><bold>530</bold></highlight> can comprise instructions for determining an order to sense data based on available redundant circuitry <highlight><bold>535</bold></highlight>. Determining an order to sense data based on available redundant circuitry <highlight><bold>535</bold></highlight> may give read requests a priority based upon an efficient use of the memory sensing devices, an effective way to facilitate returning non-critical data in accordance with a defined protocol <highlight><bold>555</bold></highlight>, and the chronological order that each memory request was received. When sensing data in the memory unit <highlight><bold>530</bold></highlight> finishes sensing critical data, determining an order to sense data based on available redundant circuitry <highlight><bold>535</bold></highlight> may then determine a priority for the non-critical data of each received request. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Returning critical data in response to said receiving more than one request <highlight><bold>540</bold></highlight> may return the critical data from each received request in a pipelined-burst transaction. Returning critical data in response to said receiving more than one request <highlight><bold>540</bold></highlight> can comprise interrupting a response to a first request comprising non-critical data to return critical data in response to a second request <highlight><bold>545</bold></highlight>. For example, upon returning the critical data for the first request, interrupting a response to a first request comprising non-critical data to return critical data in response to a second request <highlight><bold>545</bold></highlight> may comprise instructions to return the critical data to the second request rather than continuing to return the non-critical data of the first request. When critical data is not requested in a second request, some embodiments may continue to complete the first request, including the non-critical data, before initiating the return of data sensed in response to the second request. Many embodiments returning critical data in response to said receiving more than one request <highlight><bold>540</bold></highlight> may also comprise returning the critical data of each of the more than one request by multiplexing the critical data. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> Returning non-critical data <highlight><bold>550</bold></highlight> may comprise returning the non-critical data to the host in an order based upon priority. Returning non-critical data <highlight><bold>550</bold></highlight> can comprise instructions for returning non-critical data in accordance with a pre-defined protocol <highlight><bold>555</bold></highlight>. Returning non-critical data in accordance with a pre-defined protocol <highlight><bold>555</bold></highlight> may allow tracking of events by the host without requiring a status to be returned to the host for each event. For example, when a second request is received four cycles after a first request, a pre-defined protocol may provide instructions requiring that returning data to the host alternate every four cycles between data sent in response to the first request and data sent in response to the second request. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, there is shown an example system embodiment <highlight><bold>600</bold></highlight>. The embodiment <highlight><bold>600</bold></highlight> is designed to be a communication device, such as a cellular phone or personal digital assistant, and may have audio and digital messaging such as voice and electronic mail (email) functions. The embodiment <highlight><bold>600</bold></highlight> may comprise inputoutput devices such as an audio input device <highlight><bold>610</bold></highlight>, a visual output device <highlight><bold>640</bold></highlight>, an input device <highlight><bold>650</bold></highlight>, an audio output device <highlight><bold>660</bold></highlight>, and an antenna <highlight><bold>670</bold></highlight>, and comprise a microprocessor <highlight><bold>620</bold></highlight> and a virtual-port memory device <highlight><bold>630</bold></highlight>. The audio input device <highlight><bold>610</bold></highlight> may receive analog audio input, convert the input to a digital format with an analog to digital (A/D) converter, and transmit the converted input to the microprocessor <highlight><bold>620</bold></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> The microprocessor <highlight><bold>620</bold></highlight> may receive digital data and process the data according to instructions in the virtual-port memory device <highlight><bold>630</bold></highlight>. For example, the virtualport memory device may comprise protected memory or read-only memory comprising data representing instructions of basic functions for the embodiment <highlight><bold>600</bold></highlight>. In some embodiments, basic functions can comprise instructions to display characters on the visual output device <highlight><bold>640</bold></highlight>, interpret input from the input device <highlight><bold>650</bold></highlight>, activate the audio output device <highlight><bold>660</bold></highlight>, and receive and transmit data via the antenna device <highlight><bold>670</bold></highlight>. Instructions for more advanced functions, such as displaying messages, may be stored in memory locations that can be rewritten so the instructions may be updated to increase the functionality of the embodiment <highlight><bold>600</bold></highlight>. Many embodiments include instructions to switch between receiving and transmitting analog data and receiving and transmitting digital data. Further embodiments also comprise different instructions to optimize power consumption by the embodiment <highlight><bold>600</bold></highlight> depending upon whether data transmitted and received is digital or analog. For instance, an A/D converter in the audio input device <highlight><bold>610</bold></highlight> and a digital to analog (D/A) converter in the audio output <highlight><bold>660</bold></highlight> may be switched out of an active or powered circuit when the embodiment <highlight><bold>600</bold></highlight> is transmitting and receiving analog data, such as a person&apos;s voice as captured by a microphone and combined with a carrier wave. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> The virtual-port memory device <highlight><bold>630</bold></highlight> may receive more than one request to read data, place a priority on critical data, and return non-critical data to the microprocessor <highlight><bold>620</bold></highlight> by multiplexing or time-slicing the data. In alternative embodiments, the virtual-port memory device <highlight><bold>630</bold></highlight> may receive packet identifications, identifying the priority level of each read request. In some embodiments, each read request for an idle memory sensing device is forwarded immediately to the idle memory sensing device such that more than one sensing device can be sensing data at respective memory locations at one time. Also, by forwarding the read requests immediately to an idle sensing device, the virtual-port memory device can support low latency and high bandwidth data transfers of the microprocessor <highlight><bold>620</bold></highlight>. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Many embodiments include an N-deep, request queue in the virtual memory device <highlight><bold>630</bold></highlight> to service requests wherein N is the number of requests that can be handled in parallel by the virtual-port memory device <highlight><bold>630</bold></highlight>. In several embodiments, each request stored in the request queue can be accessed in parallel. Accessing the requests in parallel may allow the requests to be processed simultaneously or substantially simultaneously. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> When critical data is sensed, the data may be forwarded directly to a critical data location in an output burst queue of the virtual-port memory device <highlight><bold>630</bold></highlight>. The output burst queue may transmit the critical word to the microprocessor <highlight><bold>620</bold></highlight> as soon as a specified unit size is made available in the critical data section of the output burst queue and when the coupling between the virtual-port memory device <highlight><bold>630</bold></highlight> and the microprocessor becomes available. In alternative embodiments, a transmission, other than a critical data transmission to the microprocessor, may be interrupted to forward critical data to the microprocessor <highlight><bold>620</bold></highlight>. In many of these embodiments, the critical data is transmitted to the microprocessor <highlight><bold>620</bold></highlight> in one word or double word bursts. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Referring still to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the visual output device <highlight><bold>640</bold></highlight> can receive instructions from the microprocessor <highlight><bold>620</bold></highlight> to display messages, like email, alpha-numeric pages, phone book entries, and text-based web sites. An input device <highlight><bold>650</bold></highlight> can couple to the microprocessor <highlight><bold>620</bold></highlight> to allow a user to enter instructions or data, such as a phone number or email address. The input device <highlight><bold>650</bold></highlight> may be a transparent, capacitive switch grid incorporated in the visual output device <highlight><bold>640</bold></highlight> to allow a user to touch a part of the visual output device <highlight><bold>640</bold></highlight> to enter a character or select a function. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Still referring to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the audio output device <highlight><bold>660</bold></highlight> may comprise a speaker coupled to a D/A device and can output data received via the antenna device <highlight><bold>670</bold></highlight>. Further, the antenna device <highlight><bold>670</bold></highlight> may comprise a receiver and transmitter for high frequency, analog and digital data transmissions. For example, if the embodiment <highlight><bold>600</bold></highlight> is at a location where digital cellular services are available, the antenna device <highlight><bold>670</bold></highlight> may transmit and receive digital voice data, periodic digital time indications, and transmit digital voice data. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. An apparatus, comprising: 
<claim-text>a request queue coupled to a memory unit via a memory-sensing device; </claim-text>
<claim-text>a response queue coupled to the memory-sensing device; and </claim-text>
<claim-text>an arbiter coupled to said response queue. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the memory-sensing device comprises redundant circuitry capable of sensing memory in the memory unit substantially simultaneously. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said request queue comprises memory to store more than one request. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein the memory to store more than one request comprises memory to service more than one request substantially simultaneously. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said response queue comprises memory to store data for a response. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said arbiter comprises a response arbiter to determine a response to more than one request. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein the response arbiter comprises a priority determiner to determine a priority of a response to a request. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said arbiter comprises a request arbiter coupled to said request queue. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A method, comprising: 
<claim-text>receiving more than one request for sensing data in a memory unit; </claim-text>
<claim-text>sensing data in the memory unit; </claim-text>
<claim-text>returning critical data in response to said receiving more than one request; and </claim-text>
<claim-text>returning non-critical data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference> wherein said receiving more than one request for sensing data in a memory unit comprises receiving a second transaction before completing a response to a first transaction. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference> wherein said receiving more than one request for sensing data in a memory unit comprises receiving a request to read critical data. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference> wherein said sensing data in the memory unit comprises determining an order to sense data based on available redundant circuitry. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference> wherein said returning critical data comprises interrupting a response to a first request comprising non-critical data to return critical data in response to a second request. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference> wherein said returning non-critical data comprises returning non-critical data in accordance with a pre-defined protocol. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein returning non-critical data in accordance with a pre-defined protocol comprises responding to each request of the more than one request with time-sliced burst data. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> wherein returning non-critical data in accordance with a pre-defined protocol comprises returning non-critical data in an order based upon a priority attached to the more than one request. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A system, comprising: 
<claim-text>a virtual-port memory device; </claim-text>
<claim-text>a memory controller coupled to said virtual-port memory device; and </claim-text>
<claim-text>a host coupled to said memory controller. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, wherein said virtual-port memory device comprises: 
<claim-text>a request queue coupled to a memory unit via a memory sensing device; </claim-text>
<claim-text>a response queue coupled to the memory sensing device; and </claim-text>
<claim-text>an arbiter coupled to said response queue. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the arbiter comprises a response arbiter to determine a response to more than one request. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, wherein said memory controller comprises: 
<claim-text>a response interpreter coupled to said virtual-port memory device; </claim-text>
<claim-text>a host response queue coupled to the response interpreter; and a host request queue coupled to said host. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. A system, comprising: 
<claim-text>a virtual-port memory device coupled to a microprocessor; and </claim-text>
<claim-text>an input-output device coupled to the microprocessor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein said virtual-port memory device comprises: 
<claim-text>a request queue coupled to a memory unit via a memory sensing device; </claim-text>
<claim-text>a response queue coupled to the memory sensing device; and </claim-text>
<claim-text>an arbiter coupled to said response queue. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein said input-output device comprises an antenna device. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein said input-output device comprises an audio input device and an audio output device. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A machine-readable medium containing instructions, which when executed by a machine, cause said machine to perform operations, comprising: 
<claim-text>receiving more than one request for sensing data in a memory unit; </claim-text>
<claim-text>sensing data in the memory unit; </claim-text>
<claim-text>returning critical data in response to said receiving more than one request; and </claim-text>
<claim-text>returning non-critical data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The machine-readable medium of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein said receiving more than one request for sensing data in a memory unit comprises receiving a second transaction before completing a response to a first transaction. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The machine-readable medium of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein said receiving more than one request for sensing data in a memory unit comprises receiving a request to read critical data. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The machine-readable medium of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein said sensing data in the memory unit comprises determining an order to sense data based on available redundant circuitry. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The machine-readable medium of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein said returning critical data comprises interrupting a response to a first request comprising non-critical data to return critical data in response to a second request. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein said returning non-critical comprises returning non-critical data in accordance with a pre-defined protocol.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005239A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005239A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005239A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005239A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005239A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005239A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030005239A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
