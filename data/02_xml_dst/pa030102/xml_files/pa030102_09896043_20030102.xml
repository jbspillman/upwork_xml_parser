<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005257A1-20030102-D00000.TIF SYSTEM "US20030005257A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005257A1-20030102-D00001.TIF SYSTEM "US20030005257A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005257A1-20030102-D00002.TIF SYSTEM "US20030005257A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005257A1-20030102-D00003.TIF SYSTEM "US20030005257A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005257A1-20030102-D00004.TIF SYSTEM "US20030005257A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005257A1-20030102-D00005.TIF SYSTEM "US20030005257A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030005257A1-20030102-D00006.TIF SYSTEM "US20030005257A1-20030102-D00006.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005257</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09896043</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010628</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F012/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>711</class>
<subclass>205000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Memory table and memory manager for use in managing memory</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Kenneth</given-name>
<middle-name>Mark</middle-name>
<family-name>Wilson</family-name>
</name>
<residence>
<residence-us>
<city>San Jose</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Robert</given-name>
<middle-name>B.</middle-name>
<family-name>Aglietti</family-name>
</name>
<residence>
<residence-us>
<city>San Jose</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>HEWLETT-PACKARD COMPANY</name-1>
<name-2>Intellectual Property Administration</name-2>
<address>
<address-1>P.O. Box 272400</address-1>
<city>Fort Collins</city>
<state>CO</state>
<postalcode>80527-2400</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The present invention, in various embodiments, provides techniques for managing memory in computer systems. One embodiment uses a memory table having entries to locate data residing in different types of storage areas, such as physical memory, hard disc, file servers, storage devices, etc. Upon a program accessing memory for a particular piece of data, the memory table translates the data&apos;s physical address to an address used to find the table entry pointing to the requested data. In one embodiment, if the data is in physical memory, then the requested data is returned to the program. However, if the data is not in physical memory and it is determined that the data will be used frequently, then the data, in addition to being returned, is also brought to the physical memory for later use. This is because accessing the data from physical memory usually takes less time than accessing the data from other storage devices. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present invention relates generally to computer memory management and, more specifically, to a memory table and associated memory manager for use in such management. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Virtual memory, which is an imaginary memory area supported by the operating system of a computer, increases the set of addresses a program can use. Usually, this set of addresses is referred to as the address space and is divided into units or pages. While virtual addresses are used to access virtual memory, physical addresses are used to locate data stored in physical locations or physical memory corresponding to the virtual addresses. Contemporary computers commonly use translation look-aside buffers or tables to cache virtual to physical page address translations. As program applications grow in size and their data requirements increase, the number of pages required by the applications and hence the number of translations that need to be cached in the translation look-aside buffer increases. Unfortunately, the translation look-aside buffer is often the cycle-time limiter in processors and increasing its size exacerbates the problem. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> To limit the number of entries needed in a translation look-aside buffer and thereby reducing its cycle time, designers usually increase the size of memory pages, which decreases the number of entries the translation look-aside buffer needs to contain. This is because a given amount of memory can be represented by fewer pages. However, this approach also increases the time needed for moving a memory page and the number of page faults, which occur when a memory page is accessed but the page is not in memory. In addition, larger pages in memory, especially those of gigabyte sizes, result in more chance that large fractions of the page are not used by the portion of the applications currently executing. This leads to inefficient use of memory. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Some approaches have balanced the disparate needs of large page sizes, small number of translation look-aside buffer entries, and penalties due to moving or copying large pages. However, in these approaches, translation look-aside buffers are still cycle time limiters. &ldquo;Super pages&rdquo; have been investigated to combine multiple smaller pages to create one larger page, which combines several translation look-aside buffer entries into one and allows each individual page creating the super page to be stored in noncontiguous memory locations. Nevertheless, all pages are usually stored in system memory or swap memory, which refers to storage areas for data that is not in system memory. Normally, the operating system, during execution of a program, keeps as much data in the system memory as possible, and leaves the rest of the data somewhere else, e.g., in a hard disc. When the system needs the data, it swaps some of the data in system memory with some of the data in the disc. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Current approaches using the operating system to manage memory result in very complex systems and inefficient management of memory. The operating system has to deal with the discussed-above problems in trade-offs between page size and translation look-aside buffer misses. The operating system usually does not know the latency and/or bottleneck at the hardware level several layers away from the operating system, and it is yet responsible for managing the memory, especially memory swapping, which occurs at the hardware level. In many situations, memory swapping requires many complicated steps, but the processor has to wait for all the steps, and thus the swap, to complete before the processor can access the data in swap memory. The operating system commonly treats physical memory as a black box, and therefore in many situations cannot make informed decisions in managing the memory, including page placement. This also increases the complexity of the operating system. Based on the foregoing, it is clearly desirable that mechanisms be provided to solve the above deficiencies and related problems. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The present invention, in various embodiments, provides techniques for managing memory in computer systems. One embodiment uses a memory table having entries to locate data residing in different types of storage areas, such as physical memory, hard disc, file servers, storage devices, etc. Upon a program accessing memory for a particular piece of data, the memory table translates the data&apos;s physical address to an address used to find the table entry pointing to the requested data. In one embodiment, if the data is in physical memory, then the requested data is returned to the program. However, if the data is not in physical memory and it is determined that the data will be used frequently, then the data, in addition to being returned, is also brought to the physical memory for later use. This is because accessing the data from physical memory usually takes less time than accessing the data from other storage devices. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> In one embodiment, a memory manager in the form of a state machine or a processor is used in conjunction with the memory table. The memory manager manages various tasks such as storing the data, determining when, how and where to move the data between the system memory and a storage area, collecting statistic used to move a particular piece of data, etc. Normally, the memory manager performs its tasks in the background, e.g., independent from and/or in parallel with the system processor. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings in which like reference numerals refer to similar elements and in which: </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a processor system upon which embodiments of the invention may be implemented; </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows one embodiment of the memory table in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is used to illustrate converting a virtual address to a physical address and then a relocation address used to identify data blocks; </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flowchart illustrating a memory access; </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a flowchart detailing step <highlight><bold>420</bold></highlight> in the flowchart of <cross-reference target="DRAWINGS">FIG. 5</cross-reference>; and </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows an exemplary computer system upon which embodiments of the invention may be implemented. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The present invention, in various embodiments, provides techniques for managing memory in computer systems. One embodiment uses a memory table having entries to locate data residing in different types of storage areas, such as physical memory, hard disc, file servers, storage devices, etc. In the following description, for the purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the present invention. However, it will be apparent to one skilled in the art that the invention may be practiced without these specific details. In other instances, well-known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the invention. </paragraph>
</section>
<section>
<heading lvl="1">Hardware Overview </heading>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a uni-processor system <highlight><bold>100</bold></highlight> upon which embodiments of the invention may be implemented. System <highlight><bold>100</bold></highlight> includes, in relevant part, a central processing unit (CPU) <highlight><bold>102</bold></highlight>, a memory system <highlight><bold>104</bold></highlight>, and a hard disc <highlight><bold>130</bold></highlight>. CPU <highlight><bold>102</bold></highlight> in turns includes a processor <highlight><bold>105</bold></highlight>, cache memory <highlight><bold>140</bold></highlight>, and a translation look-aside buffer <highlight><bold>150</bold></highlight>, while memory system <highlight><bold>104</bold></highlight> includes a memory controller <highlight><bold>110</bold></highlight>, physical memory <highlight><bold>120</bold></highlight>, swap memory <highlight><bold>145</bold></highlight>, a memory table <highlight><bold>160</bold></highlight>, and a memory manager <highlight><bold>165</bold></highlight>. Swap memory <highlight><bold>145</bold></highlight> is shown with a dotted line in hard disc <highlight><bold>130</bold></highlight> to indicate that, in one embodiment, swap memory <highlight><bold>145</bold></highlight>, even though being part of memory system <highlight><bold>104</bold></highlight>, physically resides in hard disc <highlight><bold>130</bold></highlight>. Memory system <highlight><bold>104</bold></highlight> is commonly referred to as main memory from which program instructions are executed and program data are manipulated. System <highlight><bold>100</bold></highlight> normally runs by an operating system <highlight><bold>170</bold></highlight> resided in physical memory <highlight><bold>120</bold></highlight>. Processor <highlight><bold>105</bold></highlight>, memory controller <highlight><bold>110</bold></highlight>, physical memory <highlight><bold>120</bold></highlight>, hard disc <highlight><bold>130</bold></highlight>, cache memory <highlight><bold>140</bold></highlight>, translation look-aside buffer <highlight><bold>150</bold></highlight>, and operating system <highlight><bold>170</bold></highlight> are common computer components. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> In this document, the configuration of system <highlight><bold>100</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is used only as an example. Any other configuration of a processing system can be effectively used by the techniques disclosed herein. For example, either one or both of cache <highlight><bold>140</bold></highlight> and look-aside buffer <highlight><bold>150</bold></highlight> can be part of processor <highlight><bold>105</bold></highlight>, cache <highlight><bold>140</bold></highlight> may be outside of CPU <highlight><bold>102</bold></highlight> or part of memory system <highlight><bold>104</bold></highlight>, there may be more than one processor <highlight><bold>105</bold></highlight> in CPU <highlight><bold>102</bold></highlight> and different levels of cache <highlight><bold>140</bold></highlight>, etc. </paragraph>
</section>
<section>
<heading lvl="1">The Memory System </heading>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> In one embodiment, memory system <highlight><bold>104</bold></highlight> is designed independently from the size of translation look-aside buffer <highlight><bold>150</bold></highlight> or the size of the page used by operating system <highlight><bold>170</bold></highlight>. The page size can be set as large as needed and independent of performance issues relating to the overhead of moving and/or copying data between storage areas. Further, translation look-aside buffer <highlight><bold>150</bold></highlight>, working with memory table <highlight><bold>160</bold></highlight> in memory system <highlight><bold>104</bold></highlight>, has significantly fewer entries as compared to other approaches. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In one embodiment, program executions take place in physical memory <highlight><bold>120</bold></highlight>. Swap memory <highlight><bold>145</bold></highlight> physically resides in various storage areas including different memory types and/or storage devices, such as dynamic random access memory (DRAM), Rambus DRAM (RDRAM), magnetic RAM (MRAM), static RAM (SRAM), hard disc <highlight><bold>130</bold></highlight>, file servers, different levels of cache and memory, etc. In accordance with the techniques disclosed herein, the above list of storage areas is used as an example only, any device storing data can serve as storage areas. Further, pointers in memory table <highlight><bold>160</bold></highlight> point to those storage areas. However, operating system <highlight><bold>170</bold></highlight> sees memory system <highlight><bold>104</bold></highlight> as one single entity representing the amount of memory in the computer system. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Memory system <highlight><bold>104</bold></highlight>, through memory manager <highlight><bold>165</bold></highlight>, has complete control of all storage areas under it. Commonly, in other approaches, operating system <highlight><bold>170</bold></highlight> and different software routines control the storage areas. Memory system <highlight><bold>104</bold></highlight> is also assigned a set of addresses for accessing data. For example, memory system <highlight><bold>104</bold></highlight> is considered as one block of 1.64 Gb represented by 31-bits addresses, and these addresses cover, for example, 128 Mbs in physical memory <highlight><bold>120</bold></highlight>, 512 Mbs in hard disc <highlight><bold>130</bold></highlight>, and 1 Gbs in one or another variety of storage devices, etc. The size of the storage space for each storage area, in accordance with the techniques disclosed herein, can be conveniently chosen. Data storage covered by memory system <highlight><bold>104</bold></highlight> is divided into data blocks, each of which, in one embodiment, is 1K. In one embodiment, some storage space chosen in the available storage space is used for administration purposes. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> In one embodiment, processor <highlight><bold>105</bold></highlight>, upon an access to memory system <highlight><bold>104</bold></highlight> for some data, uses the data&apos;s virtual address on processor bus <highlight><bold>1005</bold></highlight>, which is translated by translation look-aside buffer <highlight><bold>150</bold></highlight> to a physical address on system bus <highlight><bold>1010</bold></highlight>. This physical address is used in various approaches to directly access data stored in physical memory corresponding to the virtual addresses on processor bus <highlight><bold>1005</bold></highlight>. However, in accordance with the techniques disclosed herein, memory table <highlight><bold>160</bold></highlight>, in one embodiment, converts the physical addresses on system bus <highlight><bold>1010</bold></highlight> to location addresses on memory bus <highlight><bold>1015</bold></highlight> used to locate the requested data in different storage areas. The requested data is then returned to processor <highlight><bold>105</bold></highlight> or the program accessing the data with the original physical address on system bus <highlight><bold>1010</bold></highlight>. </paragraph>
</section>
<section>
<heading lvl="1">The Memory Manager </heading>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> In one embodiment, a state machine is implemented as memory manager <highlight><bold>165</bold></highlight>. Alternatively, a processor or any other mechanism that can perform various tasks for efficient memory management can serve as memory manager <highlight><bold>165</bold></highlight>. These mechanisms include, for example, firmware, field programmable gate arrays (FPGAs), application specific integrated circuits (ASICs), etc., which can be modified easily and operated independent of operating system <highlight><bold>170</bold></highlight>. Memory manager <highlight><bold>165</bold></highlight>, determining appropriate locations for data blocks during program executions, analyzes where, why, and how a particular piece of data is located. Memory manager <highlight><bold>165</bold></highlight>, based on available information and other data sources, places the data so that, when needed, the data is ready in physical memory <highlight><bold>120</bold></highlight> to be executed, and does not have to be moved from some other locations. Consequently, processor <highlight><bold>105</bold></highlight> and operating system <highlight><bold>170</bold></highlight> do not have to be concerned about where the data actual is or how to manage the data. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Memory manager <highlight><bold>165</bold></highlight> also determines the movement of data blocks between various storage areas. For example, if the data block has been in physical memory <highlight><bold>120</bold></highlight> for a long time and memory manager <highlight><bold>165</bold></highlight> determines that the data will not be used in the near future, then memory manager <highlight><bold>165</bold></highlight> moves that data block out of physical memory <highlight><bold>120</bold></highlight>, e.g., to hard disc <highlight><bold>130</bold></highlight>. Similarly, if the data is to be used frequently, then memory manager <highlight><bold>165</bold></highlight> moves that data block to physical memory <highlight><bold>120</bold></highlight>. Before moving data to a particular location, memory manager <highlight><bold>165</bold></highlight> ensures that that location is available for use. For example, if memory manager <highlight><bold>165</bold></highlight> cannot find some free blocks for use in physical memory <highlight><bold>120</bold></highlight>, then memory manager <highlight><bold>165</bold></highlight>, to make room available, moves some blocks that will not be soon used out of physical memory <highlight><bold>120</bold></highlight>. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> In one embodiment, memory manager <highlight><bold>165</bold></highlight> monitors the movement of data between different storage areas and thus determines the movement pattern from which memory manager <highlight><bold>165</bold></highlight> stores the data accordingly. For example, if the data is to be processed only once during a program execution, then the data is not brought into physical memory <highlight><bold>120</bold></highlight>. In contrast, if the data is constantly used, then the data is moved to fastest memory, e.g., cache memory, etc. Depending on the situation, memory manager <highlight><bold>165</bold></highlight> can arrange for the data to be returned when it is needed or place the data in cache <highlight><bold>140</bold></highlight> or other locations without affecting physical memory <highlight><bold>120</bold></highlight>. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Memory manager <highlight><bold>165</bold></highlight> also collects information based on which to effectively manage memory system <highlight><bold>104</bold></highlight>. The information can be stored at various convenient locations such as in memory manager <highlight><bold>165</bold></highlight>, in memory table <highlight><bold>160</bold></highlight>, etc. Collected information includes any information that help memory manager <highlight><bold>165</bold></highlight> to manage the data effectively, such as the number of times a data block has been accessed, the time the data was last accessed, the time a particular piece of data stays at a particular location, etc. Memory manager <highlight><bold>165</bold></highlight>, based on available information, for example, moves the data between system memory <highlight><bold>104</bold></highlight> and other storage areas, determines if enough free pages are available for a memory access. If free pages are not enough, then memory manager <highlight><bold>165</bold></highlight> makes room available, e.g., by relocating the data, etc. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> In one embodiment, memory manager <highlight><bold>165</bold></highlight> is provided with information related to the structure of memory system <highlight><bold>104</bold></highlight> so that memory manager <highlight><bold>165</bold></highlight> can make informed decisions and effectively perform its tasks. Memory manager <highlight><bold>165</bold></highlight>, having the information, moves and stores data accordingly. If, for example, a particular RAM has a dual bus architecture, then memory manager <highlight><bold>165</bold></highlight> moves the data in parallel, utilizing both buses at the same time. In other cases, e.g., in a single bus architecture, memory manager <highlight><bold>165</bold></highlight> moves data serially, etc. Memory manager <highlight><bold>165</bold></highlight> also takes accounts of other factors, including, for example, the bandwidth of memory bus <highlight><bold>1015</bold></highlight>, the number of memory layers, the type, the bottleneck, and the latency of various memory components, the bus structure of memory types used for swap memory <highlight><bold>145</bold></highlight> and physical memory <highlight><bold>120</bold></highlight>, the various cache levels and cache locations, etc. In current approaches, operating system <highlight><bold>170</bold></highlight>, which is usually designed for general purposes, does not take into account the internal structure and bottleneck of various components in memory system <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> Normally, memory manager <highlight><bold>165</bold></highlight> performs its tasks in the background, e.g., independent from and/or in parallel with system processor <highlight><bold>105</bold></highlight> and operating system <highlight><bold>170</bold></highlight>. As memory manager <highlight><bold>165</bold></highlight> does not use processor <highlight><bold>105</bold></highlight>, processor bus <highlight><bold>1005</bold></highlight>, or other processor resources, memory manager <highlight><bold>165</bold></highlight> does not interfere with processor <highlight><bold>105</bold></highlight>&apos;s performance. In one embodiment, memory manager <highlight><bold>165</bold></highlight>, through memory table <highlight><bold>165</bold></highlight>, uses physical address on system bus <highlight><bold>1010</bold></highlight> to locate the data. In many situations, this physical address was translated from a virtual address. </paragraph>
</section>
<section>
<heading lvl="1">The Memory Table </heading>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> Memory table <highlight><bold>160</bold></highlight> includes entries to locate the requested data stored in different storage areas. In one embodiment, memory table <highlight><bold>160</bold></highlight> is part of memory controller <highlight><bold>110</bold></highlight>. However, memory table <highlight><bold>160</bold></highlight> can be at any convenient locations such as in a memory unit, physical memory, main memory, cache, part of the processor, etc. Further, memory manager <highlight><bold>165</bold></highlight> manages memory table <highlight><bold>160</bold></highlight>. Processor <highlight><bold>105</bold></highlight>, translation look-aside buffer <highlight><bold>150</bold></highlight>, or operating system <highlight><bold>170</bold></highlight> do not need to know that memory table <highlight><bold>160</bold></highlight> exists. This is because, in one embodiment, memory system <highlight><bold>104</bold></highlight>, receiving the physical address on system bus <highlight><bold>1010</bold></highlight>, returns the accessed data with the same physical address. In one embodiment, memory table <highlight><bold>160</bold></highlight> is implemented in hardware such as in random access memory (RAM) or memory controller <highlight><bold>110</bold></highlight>, which normally can be run at high speed and thus does not add significant delay to a memory access. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a memory table <highlight><bold>200</bold></highlight> as one embodiment of memory table <highlight><bold>160</bold></highlight>. Table <highlight><bold>200</bold></highlight>, being in use with memory system <highlight><bold>104</bold></highlight>, includes a plurality of table entries, e.g., <highlight><bold>210</bold></highlight>-<highlight><bold>1</bold></highlight> to <highlight><bold>210</bold></highlight>-N for N entries. If there is no reference to an actual data block, an entry <highlight><bold>210</bold></highlight> is &ldquo;NIL.&rdquo; However, if a data block has been allocated, a corresponding entry <highlight><bold>210</bold></highlight> points to that data block. In this <cross-reference target="DRAWINGS">FIG. 2</cross-reference> example, entries <highlight><bold>210</bold></highlight>-<highlight><bold>2</bold></highlight>, <highlight><bold>210</bold></highlight>-<highlight><bold>3</bold></highlight>, <highlight><bold>210</bold></highlight>-<highlight><bold>4</bold></highlight>, <highlight><bold>210</bold></highlight>-<highlight><bold>5</bold></highlight> point to data blocks located at various random locations in both physical memory <highlight><bold>120</bold></highlight> and hard disc <highlight><bold>130</bold></highlight>. Further, physical memory <highlight><bold>120</bold></highlight> and hard disc <highlight><bold>130</bold></highlight> are shown as only an example, the data blocks can be in various different storage areas, in accordance with the techniques disclosed herein. </paragraph>
</section>
<section>
<heading lvl="1">Entries of Memory Table </heading>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Normally, memory table <highlight><bold>160</bold></highlight> includes enough entries <highlight><bold>210</bold></highlight> to cover all data blocks of memory system <highlight><bold>104</bold></highlight> as seen by processor <highlight><bold>105</bold></highlight> and operating system <highlight><bold>170</bold></highlight>. For example, memory table <highlight><bold>160</bold></highlight> contains 1.64 million entries covering 1.64 million blocks resulted from a 1.64G memory system <highlight><bold>104</bold></highlight> having each data block of 1K. Further, each entry <highlight><bold>210</bold></highlight> corresponds to a block covering a physical address range. For example, entry <highlight><bold>1</bold></highlight> corresponds to block <highlight><bold>1</bold></highlight> covering physical addresses 0 to 1023, entry <highlight><bold>2</bold></highlight> corresponds to block <highlight><bold>2</bold></highlight> covering physical addresses 1024 to 2047, and entry <highlight><bold>3</bold></highlight> corresponds to block <highlight><bold>3</bold></highlight> covering physical addresses 2048 to 3071, etc. Additionally, 22 bits, e.g., bits <highlight><bold>10</bold></highlight> to <highlight><bold>31</bold></highlight> of physical address on system bus <highlight><bold>1010</bold></highlight> are used to perform a translation lookup, i.e., to find an entry, in memory table <highlight><bold>160</bold></highlight>. The example uses a simple addressing scheme to perform the translation table look-up, but, in accordance with the technique disclosed herein, a hash table or any other effective method can be used for such a translation lookup. Bits <highlight><bold>10</bold></highlight> to <highlight><bold>31</bold></highlight> actually address 2 million blocks; processor <highlight><bold>105</bold></highlight> should not send a memory access that is beyond the range of translation table <highlight><bold>160</bold></highlight>. If processor <highlight><bold>105</bold></highlight> does send such an access, then translation table <highlight><bold>160</bold></highlight> marks the access as invalid. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> In one embodiment, each entry <highlight><bold>210</bold></highlight> includes a &ldquo;valid&rdquo; bit, an &ldquo;updating location bit,&rdquo; and a &ldquo;static&rdquo; bit. The valid bit indicates whether the data block pointed to by the corresponding entry has been initialized. In one embodiment, if the data block is initialized, then the valid bit is set, e.g., having a logic &ldquo;one&rdquo; value, and if the data block is not initialized, then the valid bit is reset, e.g., having a logic &ldquo;zero&rdquo; value. The updating-location bit indicates whether an access to the data block is allowable. For example, if a table entry <highlight><bold>210</bold></highlight> is being modified or if the data block is being in transit from one location to another location, then the updating-location bit for that entry <highlight><bold>210</bold></highlight> is set, and a memory access to the data block is buffered during the time this updating-location bit is set. When this updating-location bit is reset, e.g., the table entry <highlight><bold>210</bold></highlight> is completely modified and the block is settled in its location, accessing the block is then allowable, and any buffered accesses are completed. The static bit indicates whether a particular data block must always be in physical memory <highlight><bold>120</bold></highlight>, and cannot moved to any other location. In one embodiment, if the static bit is set, then the data block cannot be moved out of physical memory <highlight><bold>120</bold></highlight>. In one embodiment, the valid bit can be replaced by using an invalid entry located in the memory table entry. Memory manager <highlight><bold>165</bold></highlight> detects invalid entries by testing the address stored in the memory table entry instead of using a special bit. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> In one embodiment, entries <highlight><bold>210</bold></highlight> also store statistical information about their corresponding data blocks, such as how long the data blocks have been staying at a particular location, the number of time the block has been accessed during some time period, etc. Memory manager <highlight><bold>165</bold></highlight> then uses the statistical information accordingly, e.g., to determine when and where to move the data blocks, etc. </paragraph>
</section>
<section>
<heading lvl="1">Translating from a Virtual Address to a Location Address </heading>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 3</cross-reference> for an illustration of converting a virtual address on processor bus <highlight><bold>1005</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> to a physical address on system bus <highlight><bold>1010</bold></highlight>, and then to a location address on memory bus <highlight><bold>1015</bold></highlight>, upon a memory access. A location address identifies a data block. In this example, the virtual address is 48 bits, memory system <highlight><bold>104</bold></highlight> is assigned 32 bits representing 1.64 Gb from addresses 0 to 1.64 Gb&minus;1 seen by processor <highlight><bold>105</bold></highlight> and operating system <highlight><bold>170</bold></highlight>. A page is 16K while a data block is 1K. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Box <highlight><bold>304</bold></highlight> shows the 48-bit virtual address represented by bits <highlight><bold>0</bold></highlight>-<highlight><bold>47</bold></highlight> in which bits <highlight><bold>0</bold></highlight>-<highlight><bold>13</bold></highlight> represent a 16K page. Each representation of bits <highlight><bold>0</bold></highlight>-<highlight><bold>13</bold></highlight> serves as an offset for accessing the page. Thirty four bits <highlight><bold>14</bold></highlight>-<highlight><bold>47</bold></highlight> represent the virtual page numbers covering all 2**34 pages in the virtual address space. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Box <highlight><bold>308</bold></highlight> shows a 40-bit physical address, represented by bits <highlight><bold>0</bold></highlight>-<highlight><bold>39</bold></highlight>. In other approaches, these bits are used to directly access data in physical memory <highlight><bold>120</bold></highlight>. Each representation of bits <highlight><bold>0</bold></highlight>-<highlight><bold>13</bold></highlight> also serves as an offset for accessing data in a 16K page. Bits <highlight><bold>14</bold></highlight>-<highlight><bold>39</bold></highlight> are translated from bits <highlight><bold>14</bold></highlight>-<highlight><bold>47</bold></highlight> in box <highlight><bold>304</bold></highlight>, using translation look-aside buffer <highlight><bold>150</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Box <highlight><bold>312</bold></highlight> shows a 32-bit location address used for finding data blocks covered by 1.64 Gb memory system <highlight><bold>104</bold></highlight>. Ten bits, e.g., bits <highlight><bold>0</bold></highlight>-<highlight><bold>9</bold></highlight>, are used to locate data in a data block of 1K. Bits <highlight><bold>10</bold></highlight>-<highlight><bold>31</bold></highlight>, being converted from bit <highlight><bold>10</bold></highlight>-<highlight><bold>31</bold></highlight> in box <highlight><bold>308</bold></highlight>, are used to lookup in memory table <highlight><bold>160</bold></highlight> to identify the location of a data block. In the example of memory system <highlight><bold>104</bold></highlight>, if bits <highlight><bold>10</bold></highlight>-<highlight><bold>31</bold></highlight> are translated to a location address from 0 to 128M&minus;1, 128M to 640M&minus;1, and 640M to 1.64 GB&minus;1, then the data block is in physical memory <highlight><bold>120</bold></highlight>, hard disc <highlight><bold>130</bold></highlight>, and other storage areas, respectively. Bits <highlight><bold>0</bold></highlight>-<highlight><bold>9</bold></highlight> are then used to convert to a location address in the identified data block. </paragraph>
</section>
<section>
<heading lvl="1">Creation of the Memory Table and Data Blocks </heading>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> In one embodiment, memory table <highlight><bold>160</bold></highlight> implemented in hardware is created when the computer system is designed, and memory manger <highlight><bold>165</bold></highlight> initializes it at boot time. In this embodiment, a certain amount of hardware space is allocated for table <highlight><bold>160</bold></highlight> and for entries <highlight><bold>210</bold></highlight>. In an alternative embodiment where table <highlight><bold>160</bold></highlight> is implemented in firmware or software, memory manager <highlight><bold>165</bold></highlight>, upon booting up, both creates and initializes table <highlight><bold>160</bold></highlight>. Table <highlight><bold>160</bold></highlight> can be created having a fixed size or a variable size in which some space is first allocated and additional space is appended as necessary. When table <highlight><bold>160</bold></highlight> is initially created, all entries <highlight><bold>210</bold></highlight> are &ldquo;NIL,&rdquo; indicating that entries <highlight><bold>210</bold></highlight> do not point to any data block. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> In one embodiment, memory manager <highlight><bold>165</bold></highlight> does not need to know the page size or the steps that operating system <highlight><bold>170</bold></highlight> does in preparation for allocating memory pages. In this embodiment, data blocks are created when operating system <highlight><bold>170</bold></highlight>, through its memory management routines, allocates memory pages, which occurs when operating system <highlight><bold>170</bold></highlight> first write data to that page. In subsequent writes, memory manager <highlight><bold>165</bold></highlight>, having the address of the data, performs a table lookup in memory table <highlight><bold>160</bold></highlight> to determine whether a data block corresponding to the data has been created. If the entry corresponding to the data is NIL, which indicates that the corresponding data block has not been created, then memory manager <highlight><bold>165</bold></highlight> creates the data block, and allows operating system <highlight><bold>170</bold></highlight> to write the data to that newly created block. However, if the data block has been created, then memory manger <highlight><bold>165</bold></highlight> allows operating system <highlight><bold>170</bold></highlight> to write the data to the already-created block without creating one. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> In an alternative embodiment, operating system <highlight><bold>170</bold></highlight>, upon initializing memory pages, provides memory manager <highlight><bold>165</bold></highlight> with the page-creation information, e.g., informs memory manager <highlight><bold>165</bold></highlight> that operating system <highlight><bold>170</bold></highlight> starts allocating a particular page having a particular size and being at a particular location, etc. In this embodiment, memory manager <highlight><bold>165</bold></highlight> creates all data blocks required to hold the newly allocated page. Memory manager <highlight><bold>165</bold></highlight>, knowing the size of the page, creates corresponding blocks having desired sizes. Further, memory manager <highlight><bold>165</bold></highlight>, having the physical address range of the page, corresponds the address ranges for each created data block, and as operating system <highlight><bold>170</bold></highlight> writes data to the page, memory manager <highlight><bold>165</bold></highlight>, having the physical address of the data, redirects the data to the corresponding data blocks. Memory manager <highlight><bold>165</bold></highlight> continuously creates data blocks as long as operating system <highlight><bold>170</bold></highlight> sends new addresses, since operating system <highlight><bold>170</bold></highlight> knows the combined size of all storage in memory system <highlight><bold>104</bold></highlight> and will not allocate more memory than can be held by the data blocks. In various embodiments, data blocks can be of the same size or different sizes, and operating system <highlight><bold>170</bold></highlight>, writing data to the data blocks, believes that it is writing data to a page. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> In one embodiment, memory manager <highlight><bold>165</bold></highlight> has total discretion to place data blocks in different locations, e.g., in physical memory <highlight><bold>120</bold></highlight>, hard disc <highlight><bold>130</bold></highlight>, or other storage areas, etc. For each data block that has been placed in a particular location, a corresponding table entry <highlight><bold>210</bold></highlight> is updated with information to locate the data block. In one embodiment, memory manager <highlight><bold>165</bold></highlight>, without sufficient information, places data blocks in fastest memory so that, when needed, the data can be quickly accessed. As additional information is available, memory manager <highlight><bold>165</bold></highlight> moves the data block to appropriate locations, in accordance with the techniques disclosed herein. </paragraph>
</section>
<section>
<heading lvl="1">Method Steps in Accordance with One Embodiment </heading>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flowchart illustrating a method for accessing memory system <highlight><bold>104</bold></highlight> in accordance with one embodiment. In step <highlight><bold>404</bold></highlight>, a program is performing a memory access for some data. In one embodiment, the program uses a virtual address of the data for this memory access. Those skilled in the art will recognize that a memory access includes finding a memory page having the address to be accessed. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> In step <highlight><bold>408</bold></highlight>, it is determined whether the accessed page is in translation look-aside buffer <highlight><bold>150</bold></highlight>. If the page is not in translation look-aside buffer <highlight><bold>150</bold></highlight>, then in step <highlight><bold>412</bold></highlight> operating system <highlight><bold>170</bold></highlight> finds the page, and in step <highlight><bold>416</bold></highlight> translation look-aside buffer <highlight><bold>150</bold></highlight> is updated to reflect that the page is in translation look-aside buffer <highlight><bold>150</bold></highlight>. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> In step <highlight><bold>418</bold></highlight>, it is determined whether the requested data is in cache <highlight><bold>140</bold></highlight>. If the data is in cache <highlight><bold>140</bold></highlight>, then the data is returned to the program in step <highlight><bold>424</bold></highlight>. However, if the data is not in cache <highlight><bold>140</bold></highlight>, then a memory access is performed in step <highlight><bold>420</bold></highlight>, and after a successful memory access the data is returned in step <highlight><bold>424</bold></highlight>. In one embodiment, the data is returned to the program with the original physical address provided to memory system <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> In the above illustration, determining whether the page is in translation look-aside buffer <highlight><bold>150</bold></highlight> and in cache <highlight><bold>140</bold></highlight> can be done in parallel. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a flowchart detailing the step <highlight><bold>420</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. In step <highlight><bold>504</bold></highlight>, memory table <highlight><bold>160</bold></highlight> is checked to identify the location of the requested data. It is determined in step <highlight><bold>506</bold></highlight> whether the data is in physical memory <highlight><bold>120</bold></highlight>. If the data is in physical memory <highlight><bold>120</bold></highlight>, then, in step <highlight><bold>508</bold></highlight>, the address in memory table <highlight><bold>160</bold></highlight> and the lower bits of physical address on system bus <highlight><bold>1010</bold></highlight> are used to find the data in such memory. The data is then returned in step <highlight><bold>512</bold></highlight> to the program requesting the data. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> However, if the data is not in physical memory <highlight><bold>120</bold></highlight>, then, in step <highlight><bold>516</bold></highlight>, the data is found in a storage device, e.g., hard disc <highlight><bold>130</bold></highlight>. It is determined in step <highlight><bold>520</bold></highlight> whether the data should be returned directly to the requesting program, without being loaded to physical memory <highlight><bold>120</bold></highlight>. If so, then the data is returned in step <highlight><bold>512</bold></highlight>. If the data should be loaded to physical memory <highlight><bold>120</bold></highlight>, then memory manager <highlight><bold>165</bold></highlight> in step <highlight><bold>524</bold></highlight> finds a location in physical memory <highlight><bold>120</bold></highlight> to hold the data block containing the requested data. In this step <highlight><bold>524</bold></highlight>, it is assumed that memory manager <highlight><bold>165</bold></highlight> is able to find a holding location. If a holding location is not initially available, then memory manager <highlight><bold>165</bold></highlight> takes appropriate actions to make such holding location available. In step <highlight><bold>528</bold></highlight>, memory manager <highlight><bold>165</bold></highlight> loads the data, e.g., from hard disc <highlight><bold>130</bold></highlight> to physical memory <highlight><bold>120</bold></highlight>. The data is then returned in step <highlight><bold>512</bold></highlight>, and memory manager <highlight><bold>165</bold></highlight> in step <highlight><bold>524</bold></highlight> updates memory table <highlight><bold>160</bold></highlight> to reflect the new location of the data. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> In accordance with the techniques disclosed herein, many of the above steps may be done in parallel. For example, returning the data in step <highlight><bold>512</bold></highlight> may be done in parallel with updating memory table <highlight><bold>160</bold></highlight> in step <highlight><bold>530</bold></highlight> or in parallel with loading the data in step <highlight><bold>528</bold></highlight>. Further, in the background, memory manager <highlight><bold>165</bold></highlight> moves the data to different storage areas as appropriate. Those skilled in the art will recognize that step <highlight><bold>512</bold></highlight> in this <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is equivalent to step <highlight><bold>424</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
</section>
<section>
<heading lvl="1">Benefit of the Invention </heading>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> The techniques disclosed herein significantly reduce the complexity of operating system <highlight><bold>170</bold></highlight>. Because memory system <highlight><bold>104</bold></highlight> in various embodiments works independently from processor <highlight><bold>105</bold></highlight> and operating system <highlight><bold>170</bold></highlight>, the pressure on the number of entries in translation look-aside buffer <highlight><bold>150</bold></highlight> and the conflicting effects of increasing or decreasing the memory page sizes are removed. Constructing translation look-aside buffer <highlight><bold>150</bold></highlight> with significantly fewer entries is also allowable. For example, hardware designers can fix the size of translation look-aside buffer <highlight><bold>150</bold></highlight>, and software engineers can fix the page size without taking into account the design of memory system <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> Accessing memory system <highlight><bold>104</bold></highlight> is much faster and simpler than in other approaches in which an operating system manages such an access. This is because operating system <highlight><bold>170</bold></highlight> in various embodiments does not manage and does not need to know where the returned data from memory system <highlight><bold>104</bold></highlight> comes from, e.g., physical memory <highlight><bold>120</bold></highlight>, hard disc <highlight><bold>130</bold></highlight>, or other storage areas, etc. In many current approaches, if the data is not in physical memory <highlight><bold>120</bold></highlight>, then the operating system usually has to go through various complicated managing scheme to determine the location of the data, e.g., in swap memory, etc. Once the location has been identified, the operating system also has to go through complex processes to load the data to physical memory to be used from there. The operating system also has to update appropriate data structures and/or link lists, and inform the system processor or the program requesting the data that the data is ready for use. In contrast, in various embodiments of the techniques disclosed herein, the data may be returned directly to the program without being loaded to physical memory <highlight><bold>120</bold></highlight>. Even if the data is to be loaded to physical memory <highlight><bold>120</bold></highlight>, loading is fast and can be done in background for maximum efficiency. By keeping the correct data blocks in physical memory <highlight><bold>120</bold></highlight>, the latencies of moving pages from other storage locations can be minimized, and the complications of the operating performing memory paging are also removed. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> Because the storage space in physical memory <highlight><bold>120</bold></highlight> can be combined with that of hard disc <highlight><bold>130</bold></highlight> and other storage areas to result in one memory entity, operating system <highlight><bold>170</bold></highlight> can see and thus behave as if there is a much larger memory system <highlight><bold>104</bold></highlight>. This relieves operating system <highlight><bold>170</bold></highlight> from complicated memory management issues including page movement. In the <cross-reference target="DRAWINGS">FIG. 1</cross-reference> example, physical memory <highlight><bold>120</bold></highlight> is only 128 Mb while operating system <highlight><bold>170</bold></highlight> sees memory system <highlight><bold>104</bold></highlight> as a 1.64 Gb memory entity. </paragraph>
</section>
<section>
<heading lvl="1">Computer System Overview </heading>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a block diagram showing a computer system <highlight><bold>600</bold></highlight> upon which an embodiment of the invention may be implemented. For example, computer system <highlight><bold>600</bold></highlight> may be implemented to include system <highlight><bold>100</bold></highlight>. In one embodiment, computer system <highlight><bold>600</bold></highlight> includes a processor <highlight><bold>604</bold></highlight>, random access memories (RAMs) <highlight><bold>608</bold></highlight>, read-only memories (ROMs) <highlight><bold>612</bold></highlight>, a storage device <highlight><bold>616</bold></highlight>, and a communication interface <highlight><bold>620</bold></highlight>, all of which are connected to a bus <highlight><bold>624</bold></highlight>. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Processor <highlight><bold>604</bold></highlight> controls logic, processes information, and coordinates activities within computer system <highlight><bold>600</bold></highlight>. In one embodiment, processor <highlight><bold>604</bold></highlight> executes instructions stored in RAMs <highlight><bold>608</bold></highlight> and ROMs <highlight><bold>612</bold></highlight>, by, for example, coordinating the movement of data from input device <highlight><bold>628</bold></highlight> to display device <highlight><bold>632</bold></highlight>. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> RAMs <highlight><bold>608</bold></highlight>, usually being referred to as main memory, temporarily store information and instructions to be executed by processor <highlight><bold>604</bold></highlight>. Information in RAMs <highlight><bold>608</bold></highlight> may be obtained from input device <highlight><bold>628</bold></highlight> or generated by processor <highlight><bold>604</bold></highlight> as part of the algorithmic processes required by the instructions that are executed by processor <highlight><bold>604</bold></highlight>. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> ROMs <highlight><bold>612</bold></highlight> store information and instructions that, once written in a ROM chip, are read-only and are not modified or removed. In one embodiment, ROMs <highlight><bold>612</bold></highlight> store commands for configurations and initial operations of computer system <highlight><bold>600</bold></highlight>. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Storage device <highlight><bold>616</bold></highlight>, such as floppy disks, disk drives, or tape drives, durably stores information for used by computer system <highlight><bold>600</bold></highlight>. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> Communication interface <highlight><bold>620</bold></highlight> enables computer system <highlight><bold>600</bold></highlight> to interface with other computers or devices. Communication interface <highlight><bold>620</bold></highlight> may be, for example, a modem, an integrated services digital network (ISDN) card, a local area network (LAN) port, etc. Those skilled in the art will recognize that modems or ISDN cards provide data communications via telephone lines while a LAN port provides data communications via a LAN. Communication interface <highlight><bold>620</bold></highlight> may also allow wireless communications. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Bus <highlight><bold>624</bold></highlight> can be any communication mechanism for communicating information for use by computer system <highlight><bold>600</bold></highlight>. In the example of <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, bus <highlight><bold>624</bold></highlight> is a media for transferring data between processor <highlight><bold>604</bold></highlight>, RAMs <highlight><bold>608</bold></highlight>, ROMs <highlight><bold>612</bold></highlight>, storage device <highlight><bold>616</bold></highlight>, communication interface <highlight><bold>620</bold></highlight>, etc. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Computer system <highlight><bold>600</bold></highlight> is typically coupled to an input device <highlight><bold>628</bold></highlight>, a display device <highlight><bold>632</bold></highlight>, and a cursor control <highlight><bold>636</bold></highlight>. Input device <highlight><bold>628</bold></highlight>, such as a keyboard including alphanumeric and other keys, communicates information and commands to processor <highlight><bold>604</bold></highlight>. Display device <highlight><bold>632</bold></highlight>, such as a cathode ray tube (CRT), displays information to users of computer system <highlight><bold>600</bold></highlight>. Cursor control <highlight><bold>636</bold></highlight>, such as a mouse, a trackball, or cursor direction keys, communicates direction information and commands to processor <highlight><bold>604</bold></highlight> and controls cursor movement on display device <highlight><bold>632</bold></highlight>. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Computer system <highlight><bold>600</bold></highlight> may communicate with other computers or devices through one or more networks. For example, computer system <highlight><bold>600</bold></highlight>, using communication interface <highlight><bold>620</bold></highlight>, communicates through a network <highlight><bold>640</bold></highlight> to another computer <highlight><bold>644</bold></highlight> connected to a printer <highlight><bold>648</bold></highlight>, or through the world wide web <highlight><bold>652</bold></highlight> to a server <highlight><bold>656</bold></highlight>. The world wide web <highlight><bold>652</bold></highlight> is commonly referred to as the &ldquo;Internet.&rdquo; Alternatively, computer system <highlight><bold>600</bold></highlight> may access the Internet <highlight><bold>652</bold></highlight> via network <highlight><bold>640</bold></highlight>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Computer system <highlight><bold>600</bold></highlight> may be used to implement the techniques described above. In various embodiments, processor <highlight><bold>604</bold></highlight> performs the steps of the techniques by executing instructions brought to RAMs <highlight><bold>608</bold></highlight>. In alternative embodiments, hard-wired circuitry may be used in place of or in combination with software instructions to implement the described techniques. Consequently, embodiments of the invention are not limited to any one or a combination of software, hardware, or circuitry. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Instructions executed by processor <highlight><bold>604</bold></highlight> may be stored in and carried through one or more computer-readable media, which refer to any medium from which a computer reads information. Computer-readable media may be, for example, a floppy disk, a hard disk, a zip-drive cartridge, a magnetic tape, or any other magnetic medium, a CD-ROM, a CD-RAM, a DVD-ROM, a DVD-RAM, or any other optical medium, paper-tape, punch-cards, or any other physical medium having patterns of holes, a RAM, a ROM, an EPROM, or any other memory chip or cartridge. Computer-readable media may also be coaxial cables, copper wire, fiber optics, acoustic, or light waves, etc. As an example, the instructions to be executed by processor <highlight><bold>604</bold></highlight> are in the form of one or more software programs and are initially stored in a CD-ROM being interfaced with computer system <highlight><bold>600</bold></highlight> via bus <highlight><bold>624</bold></highlight>. Computer system <highlight><bold>600</bold></highlight> loads these instructions in RAMs <highlight><bold>608</bold></highlight>, executes some instructions, and sends some instructions via communication interface <highlight><bold>620</bold></highlight>, a modem, and a telephone line to a network, e.g. network <highlight><bold>640</bold></highlight>, the Internet <highlight><bold>652</bold></highlight>, etc. A remote computer, receiving data through a network cable, executes the received instructions and sends the data to computer system <highlight><bold>600</bold></highlight> to be stored in storage device <highlight><bold>616</bold></highlight>. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Computer system <highlight><bold>600</bold></highlight> may be implemented to include system <highlight><bold>100</bold></highlight>. For example, CPU <highlight><bold>604</bold></highlight> may be implemented as CPU <highlight><bold>102</bold></highlight>, RAM <highlight><bold>608</bold></highlight> as memory system <highlight><bold>104</bold></highlight>, storage device <highlight><bold>616</bold></highlight> as hard disc <highlight><bold>130</bold></highlight>, etc. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> In the foregoing specification, the invention has been described with reference to specific embodiments thereof. However, it will be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention. Accordingly, the specification and drawings are to be regarded as illustrative rather than as restrictive. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method for managing a memory system, comprising the steps of: 
<claim-text>providing a memory table having entries pointing to data blocks that reside in various locations of different storage areas including physical memory; and </claim-text>
<claim-text>upon a program accessing memory for a particular piece of data, the memory table using a physical address of a memory page corresponding to the piece of data to convert to a location address corresponding to an entry pointing to the location of the piece of data; </claim-text>
<claim-text>wherein a memory manager managing the data blocks independent of an operating system and a processor unit executing the program accessing memory. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprises the step of allocating the data blocks corresponding to the memory page upon receiving information that the memory page is about to be initialized. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprises the step of allocating a data block corresponding to the memory page upon receiving a write to a physical address that does not correspond to data blocks that have been allocated. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprises the step of corresponding an entry of the memory table to a data block. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprises the step of presenting the physical memory and the different storage areas to the operating system and the processor unit as a single memory entity. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprises the steps of 
<claim-text>returning the piece of data to the program directly from the location storing the piece of data; and </claim-text>
<claim-text>skipping a step of loading the piece of data to the physical memory. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprises the step of the memory manager using collected information to determine the location of a data block. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> further comprises the step of selecting the collected information in one or a combination of 
<claim-text>the movement pattern of the data in the data block; </claim-text>
<claim-text>the structure of the memory system; </claim-text>
<claim-text>the cache-level architecture in the memory system; </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising the step of selecting the storage areas in one or a combination of different memory types and storage devices. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A device for managing a memory system, comprising: 
<claim-text>a memory table having entries pointing to data blocks that reside in various locations of different storage areas including physical memory; wherein upon a program accessing memory for a particular piece of data, the memory table uses a physical address of a memory page corresponding to the piece of data to convert to a location address corresponding to an entry pointing to the location of the piece of data; and </claim-text>
<claim-text>a memory manager managing the data blocks independent of an operating system and a processor unit executing the program accessing memory. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein the memory manager allocates the data blocks corresponding to the memory page upon receiving information that the memory page is about to be initialized. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein the memory manager allocates a data block corresponding to the memory page upon receiving a write to a physical address that does not correspond to data blocks that have been allocated. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein the memory manager corresponds an entry of the memory table to a data block. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein the processor and the operating system perceive the physical memory and the different storage areas to the operating system as a single memory entity. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein 
<claim-text>the memory manager returns the piece of data to the program directly from the location storing the piece of data; and </claim-text>
<claim-text>the memory manager skips loading the piece of data to the physical memory. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein the memory manager uses collected information to determine the location of a data block. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> wherein the collected information is selected in one or a combination of 
<claim-text>the movement pattern of the data in the data block; </claim-text>
<claim-text>the structure of the memory system; </claim-text>
<claim-text>the cache-level architecture in the memory system; </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein the storage areas are selected in one or a combination of different memory types and storage devices. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A computer-readable medium embodying instructions for a computer to perform a method for managing a memory system, the method comprising the steps of: 
<claim-text>providing a memory table having entries pointing to data blocks that reside in various locations of different storage areas including physical memory; and </claim-text>
<claim-text>upon a program accessing memory for a particular piece of data, the memory table using a physical address of a memory page corresponding to the piece of data to convert to a location address corresponding to an entry pointing to the location of the piece of data; </claim-text>
<claim-text>wherein a memory manager managing the data blocks independent of an operating system and a processor unit executing the program accessing memory. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The computer-readable medium of <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> wherein the method further comprises the step of presenting the physical memory and the different storage areas to the operating system and the processor unit as a single memory entity.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005257A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005257A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005257A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005257A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005257A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005257A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030005257A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
