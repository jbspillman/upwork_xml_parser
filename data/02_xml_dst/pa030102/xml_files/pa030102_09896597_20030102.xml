<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005226A1-20030102-D00000.TIF SYSTEM "US20030005226A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005226A1-20030102-D00001.TIF SYSTEM "US20030005226A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005226A1-20030102-D00002.TIF SYSTEM "US20030005226A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005226A1-20030102-D00003.TIF SYSTEM "US20030005226A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005226A1-20030102-D00004.TIF SYSTEM "US20030005226A1-20030102-D00004.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005226</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09896597</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010629</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F013/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>711</class>
<subclass>119000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>711</class>
<subclass>133000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Memory management apparatus and method</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Joseph</given-name>
<middle-name>N.</middle-name>
<family-name>Hong</family-name>
</name>
<residence>
<residence-us>
<city>Chandler</city>
<state>AZ</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<assignee>
<organization-name>Intel Corporation</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>Schwegman, Lundberg, Woessner &amp; Kluth, P.A.</name-1>
<name-2></name-2>
<address>
<address-1>P.O. Box 2938</address-1>
<city>Minneapolis</city>
<state>MN</state>
<postalcode>55402</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Cache memory systems, microprocessors, and computer systems, as well as methods of operating a cache memory system are described. The cache memory system includes a cache memory controller coupled to a dynamic cache memory and a static cache memory. The cache memory system provides the advantages of using dynamic memory (having a small circuit real estate requirement) for cache read operations, and static memory for cache write operations. Using the static memory for cache write operations allows the cache memory system to function as a write-back cache, instead of an instruction-only, or write-through cache. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present invention relates generally to methods and apparatus for managing access to computer memory. More particularly, the present invention relates to methods and apparatus which are used to cache computer memory for improved access speed. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> As computer circuit design clock speeds increase, the rate at which data in the main memory of a computer can be accessed becomes all-important in the final determination of system performance. In modem computers, cache memories, or &ldquo;caches&rdquo; are used to store a portion of the contents of main memory that are likely to be re-used. Caches are typically smaller and faster than main memory, and are used to hide the latencies involved in using the main memory for storing and retrieving memory operands. Typical cache access times are about five to thirty times faster than main memory access times, significantly increasing overall system performance. Thus, while cache memories are not limited to use with central processing units (CPUs), their primary application is to store memory operands required by one or more CPUs (as opposed to other users of data) for rapid recall, obviating the need to access the slower main memory. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> There can be more than one cache used to speed up access to main memory in a computer system. In fact, it is well known in the art to provide multiple levels of caches. For example, a CPU may be provided with a level one (L1) cache on the same integrated circuit as the CPU, and a larger, slower level two (L2) cache in the same module as the CPU. Alternatively, the L2 cache may be provided as a completely separate set of memory circuitry, apart from the CPU module. The L2 cache is typically used to speed up access to the main computer memory (i.e., accesses to the main memory are &ldquo;cached,&rdquo; or stored, by the L2 cache), while the L1 cache is typically used to speed up access to the L2 cache (i.e., accesses to the L2 cache are cached by the L1 cache). In the discussion that follows, it will be assumed that memory operands are loaded into a single cache from main memory. However, it should be understood that such operands may also be loaded from a lower level cache into a higher level cache, if appropriate. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Since cache memories are typically smaller than the main memories to which they are coupled, a strategy may be used to determine which contents of the main memory are to be stored in the cache. One of the simplest such cache organizations is the direct-mapped cache organization. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> A cache is usually organized in &ldquo;lines&rdquo; or groups of bytes, and not as a single group of individual bytes. Thus, each cache line is used to store a small contiguous range of main memory contents, such as 32 or 64 bytes. In a direct-mapped cache, a portion of the main memory address is used as an index, and the remainder of the main memory address (not including any bits of the main memory address that represent bytes within a cache line) is used as a tag. The number of bits used for the index corresponds to the size of the cache. For example, a direct-mapped cache having 64 cache lines will have a corresponding six-bit index (i.e., since 2<highlight><superscript>6</superscript></highlight>&equals;64). When a read operation occurs and the memory operand is not in the cache (i.e., the tag does not match, or there is a &ldquo;cache miss&rdquo;), the memory operand is fetched from main memory and stored in the cache line corresponding to the index, and the tag is stored in a tag field associated with the cache line. Assuming the memory operand is still in the cache (i.e., the tags match, or there is a &ldquo;cache hit&rdquo;) the next time a read operation occurs, the memory operand will be retrieved directly from the cache. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Continuing to use the example of a direct-mapped cache, for any given byte in the main memory, there is only one cache line in which the byte can be stored. Therefore, if the cache line is already in use, the old contents of the cache line are simply overwritten with the new contents. If the old contents are the result of a previous memory operand write operation, and have not yet been copied back to main memory, the cache line is known in the art as a &ldquo;dirty&rdquo; cache line, and must be written back to main memory before the new contents can be stored therein. This replacement process is effected by what is known as a &ldquo;write-back&rdquo; cache. However, if the old contents in the cache line are identical to the contents in main memory (because they were written to main memory about the same time they were written to the cache line), the old contents may be overwritten (i.e., evicted) directly, without having to write back to main memory. This process, which is slower, but provides a more up-to-date picture of the true main memory content, is effected by what is known as a &ldquo;write-through&rdquo; cache. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Designers have a choice of memory types which can be used to construct on-chip cache memory circuitry. As opposed to Static Random Access Memory (SRAM), on-chip Dynamic Random Access Memory (DRAM) may be chosen to save valuable chip surface area for other functions, but requires periodic refresh activity, which complicates the design. In addition, if refresh operations do not occur in a timely fashion, the entire cache is invalidated, which degrades processor performance and increases the number of cache misses. While the solution of selective invalidation using a REFRESH bit for each cache entry has been offered in an attempt to circumvent the need for refreshing a DRAM cache, such designs have been limited to instruction-only (i.e., read-only) or write-through caches, ensuring that an up-to-date copy of the cache always resides outside of the cache. Excluding the use of write-back operations in conjunction with a DRAM cache allows entry invalidation and/or refresh operations to proceed without considering the need for complicated write-back activity. However, in applications where performance is paramount, a write-back cache may be highly desirable, especially if no L2 cache is available. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Thus, there is a need in the art for methods and apparatus which foster the extensive use of DRAM as a part of cache memory to conserve valuable circuit real-estate. Such methods and apparatus should also provide cache designers with the option of using a write-back cache whenever that function is needed or desired, without undue interference in processor data processing activity.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a schematic block diagram of a cache memory system constructed according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 2A and 2B</cross-reference> are exemplary diagrams of the state of cache entry bits used in the read and write portions, respectively, of a cache memory system constructed according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a schematic block diagram of a microprocessor and computer system constructed according to an embodiment of the present invention; and </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flow chart diagram of a method of operating a cache memory system according to an embodiment of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> In the following detailed description of the embodiments, reference is made to the accompanying drawings which form a part hereof, and in which are shown by way of illustration, and not of limitation, specific embodiments in which the invention may be practiced. In the drawings, like numerals describe substantially similar components throughout the several views. The embodiments illustrated are described in sufficient detail to enable those skilled in the art to practice the invention. Other embodiments may be utilized and derived therefrom, such that structural, logical, and electrical circuit substitutions and changes may be made without departing from the scope of the invention. The following detailed description, therefore, is not to be taken in a limiting sense, and the scope of the invention is defined only by the appended claims, along with the full range of equivalents to which such claims are entitled. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> According to the teachings of the present invention, a cache memory system is described, and includes a cache memory controller coupled to a dynamic cache memory and a static cache memory. The cache memory system may provide the advantages of using dynamic memory (minimizing the use of circuit real estate) for cache read operations, and static memory for cache write operations. Since cache reads typically outnumber cache writes by a factor of about 3:1, the size (number of memory locations) of the static cache memory may be about one-third that of the dynamic memory. In addition, using the static memory for cache write operations may allow the cache memory system to function as a write-back cache, instead of merely an instruction-only, or write-through cache, as would be the case if dynamic memory was used to cache memory operands from both read and write operations. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> For clarity, the fundamental operational principles of the cache memory system will be explained briefly, prior to referring to the figures and describing the memory structure in detail. The following discussion assumes a 64 Mbyte main memory, a 512 KB direct-mapped cache memory (divided equally between dynamic cache memory and static cache memory), and 32 byte cache lines. Of course, while the direct-mapped cache is used here as part of a simplified example, there are other, more complicated ways of organizing a cache, such as the fully-associative cache and the set-associative cache, well-known to those skilled in the art. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> The cache memory system may operate whenever the associated processor reads from or writes to the main memory. Simultaneously, the cache memory controller begins to check if the information requested is in the cache memory system and also the process of either reading or writing from/to the main memory. If there is a cache hit (i.e., the information is in the cache memory system), the system will cancel the partially-completed request to operate on the main memory, if appropriate. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> The cache controller checks for a hit by looking at the address sent by the processor. The lowest five bits (A<highlight><bold>0</bold></highlight> to A<highlight><bold>4</bold></highlight>) may be ignored, because these differentiate between the 32 different bytes in the cache line (i.e., the cache will always return 32 bytes and let the processor decide which are truly required). The next 14 address lines (A<highlight><bold>5</bold></highlight> to A<highlight><bold>18</bold></highlight>) represent the line in the cache that will be checked. The cache memory controller then reads the tag memory at the address indicated by the address lines A<highlight><bold>5</bold></highlight> to A<highlight><bold>18</bold></highlight>. If the address line bits indicate address 10FFh, for example, the controller will examine the contents of tag memory entry number 10FFh, comparing the bits that it reads from the tag memory at this location to the address bits it receives from the processor. If they match (i.e., a cache hit), then the controller knows the entry in the cache at that line address is the one needed by the processor. If there is no match, then this is counted as a cache miss. The operations following such a miss will be discussed below. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> If there is a cache hit, for a read operation the cache controller reads the 32-byte contents of the dynamic memory cache data store at the same line address and sends them to the processor provided they are still valid, as will be explained below). The read underway from the system RAM is canceled and the process is complete. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> For a write operation, the cache controller writes 32 bytes to the data store at that same cache line location referenced previously, however, the static cache memory is used. Then, since the cache memory system of the present invention is a write-back cache, the pending write to main memory is canceled, and the dirty bit for this cache line is set to 1 to indicate that the static cache memory was updated, but the main memory was not. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> schematic block diagram of a cache memory system constructed according to the teachings of the present invention can be seen. The cache memory system <highlight><bold>100</bold></highlight> includes a cache memory controller <highlight><bold>130</bold></highlight> coupled to a dynamic cache memory <highlight><bold>110</bold></highlight> and a static cache memory <highlight><bold>120</bold></highlight>. The dynamic cache memory <highlight><bold>110</bold></highlight> further includes a plurality of addresses <highlight><bold>112</bold></highlight>, <highlight><bold>114</bold></highlight>, as does the static cache memory <highlight><bold>120</bold></highlight> (i.e., <highlight><bold>122</bold></highlight>, <highlight><bold>124</bold></highlight>). For the purposes of this document, a &ldquo;dynamic cache memory&rdquo; may mean a volatile memory which retains the value of stored (i.e., cached) content for less than about 1 second, or some other substantially finite time period, even when power is continuously supplied. In other words, a &ldquo;dynamic cache memory&rdquo; may be refreshed periodically by read or write operations, similar or identical to those operations required to refresh the stored content of DRAM memories, well-known to those skilled in the art. Similarly, for the purposes of this document, a &ldquo;static cache memory&rdquo; may mean a volatile memory which retains the value of stored (i.e., cached) content for a substantially infinite time period, as long as power is continuously supplied, or a non-volatile memory, such as a flash memory, or an electrically-erasable programmable read-only memory. In other words, a &ldquo;static cache memory&rdquo; typically does not need to be refreshed in a fashion similar to DRAM memories, and as such, may be similar to or identical to SRAM memories, well-known to those skilled in the art. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The most obvious problems with using dynamic cache memory is how to obviate the need to refresh the contents of the cache, or if this is impossible, how to minimize the amount of refresh circuitry required. For this reason, while using dynamic memory for a cache memory system has been considered in the past, such use has been limited to instruction caches (i.e., read-only caches) or write-through caches. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The solution to part of the problem can be derived from the concept of &ldquo;selective invalidation&rdquo;, as introduced by Messrs. Lee and Katz in their article titled &ldquo;Non-refreshing Dynamic RAM for On-chip Cache Memories&rdquo;, I.E.E.E. Symposium on VLSI Circuits, pgs 111-112, 1990. Selective invalidation, instead of periodically invalidating the entire content of the dynamic cache memory, invalidates only stale cache entries (entries which have not been read or written within a single refresh time period) without interrupting the processor execution stream, and without degrading cache performance due to excessive invalidation. The use of selective invalidation effectively eliminates the need to refresh dynamic cache memory. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> The scheme proposed by Lee and Katz relies on three assumptions. First, the cache is used as either an instruction-only or write-through cache (such that up-to-date copies of cache entries reside outside of the cache at all times). Second, each cache block contains one or more sub-blocks; associated with each sub-block is a VALID bit and a REFRESH bit (in Lee and Katz&apos;s paper, the cache &ldquo;sub-block&rdquo; is the unit of transfer into and out of the cache, and will be referred to hereinafter in the alternative as similar to or identical to a cache &ldquo;line&rdquo;). Thus, any subset of sub-blocks can be valid at any given time. Third, any access to the dynamic memory cache is considered as a refresh operation (i.e., this is because a read operation is always followed by a write-back operation for DRAM memory). </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> In the proposed scheme, an extra bit for each sub-block is added to the VALID bit to hold the refresh status. This bit (i.e., REFRESH) is set at the beginning of each refresh interval, and reset selectively whenever the corresponding sub-block is accessed, regardless of whether the access is a read operation or write operation. At the end of each refresh period, all of the REFRESH and VALID bits are examined. Only those of sub-blocks not accessed during the refresh interval (i.e., REFRESH still is set, or equal to &ldquo;1&rdquo;) and still valid (i.e., VALID is still set, or equal to &ldquo;1&rdquo;) are invalidated selectively (i.e., VALID is reset, or equal to &ldquo;0&rdquo;). It should be carefully noted that the &ldquo;refresh interval&rdquo;, or any discussion herein of a &ldquo;refresh timer&rdquo; do not refer to actually refreshing the dynamic cache memory. Rather, as will be seen hereinbelow, the dynamic cache memory is never refreshed explicitly, at least in the conventional sense. Only memory locations accessed as cache hits by reading from the dynamic cache memory, or written into the dynamic cache memory, are considered to be refreshed&mdash;the rest of the locations are invalidated at the end of the &ldquo;refresh period&rdquo;, which is typically selected to be about half of the time period wherein a classic refresh operation takes place (usually known as the &ldquo;refresh time&rdquo; or &ldquo;refresh cycle time&rdquo; by those skilled in the art), such that the dynamic memory capacitors lose charge and the memory contents become invalid. From this discussion, it should be apparent to those skilled in the art that the dynamic cache memory <highlight><bold>110</bold></highlight> is not connected to periodic refresh circuitry, as is used with conventional dynamic memories. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Thus, as can be seen in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the cache memory system <highlight><bold>100</bold></highlight> also may include a validity refresh timer <highlight><bold>139</bold></highlight> coupled to the cache memory controller (and, as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the validity refresh timer <highlight><bold>139</bold></highlight> may be included as an integral element of the cache memory controller <highlight><bold>130</bold></highlight>). The cache memory system <highlight><bold>100</bold></highlight> may also include validity comparison logic <highlight><bold>135</bold></highlight> coupled to the validity refresh timer <highlight><bold>139</bold></highlight> (the validity comparison logic <highlight><bold>135</bold></highlight> can also be included as an integral element of the cache memory controller <highlight><bold>130</bold></highlight>). </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Finally, as noted above, the dynamic cache memory <highlight><bold>110</bold></highlight> may have a plurality of addresses <highlight><bold>112</bold></highlight>, <highlight><bold>114</bold></highlight>, which may include a cached address (e.g., <highlight><bold>112</bold></highlight>) having a cached memory operand <highlight><bold>116</bold></highlight>. The cache memory system includes a tag memory <highlight><bold>132</bold></highlight> including a copy of the cached memory address <highlight><bold>134</bold></highlight>, an operand VALID bit <highlight><bold>136</bold></highlight>, and a validity REFRESH bit <highlight><bold>137</bold></highlight>. As will be explained hereinbelow, the tag memory <highlight><bold>132</bold></highlight> may further includes a DIRTY bit <highlight><bold>138</bold></highlight>. While not shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, those skilled in the art will realize that the cache memory controller <highlight><bold>130</bold></highlight> may communicate with (or include) one or more tag memories <highlight><bold>132</bold></highlight>. If more than one tag memory <highlight><bold>132</bold></highlight> is used, then it should be noted that the first tag memory can be used to track the dynamic memory cache content, while the second tag memory can be used to track the static memory cache content, for example. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The static cache memory <highlight><bold>120</bold></highlight>, as an element of the cache memory system <highlight><bold>100</bold></highlight> constructed according to the teachings of the present invention, is used exclusively for storing memory write operations. In other words, the dynamic cache memory <highlight><bold>110</bold></highlight> is never used to cache memory write operations with regard to the cache memory system <highlight><bold>100</bold></highlight>. Thus, the cache memory controller <highlight><bold>130</bold></highlight> may also include a DIRTY bit <highlight><bold>138</bold></highlight> as a part of the tag memory <highlight><bold>132</bold></highlight>, and may communicate with (or contain as an integral element) a write-back buffer <highlight><bold>131</bold></highlight>. This enables the cache memory system <highlight><bold>100</bold></highlight> to operate as a write-back cache, using the combination of a dynamic cache memory <highlight><bold>110</bold></highlight> for cache read operations, and a static cache memory <highlight><bold>120</bold></highlight> for cache write operations. This operative combination is unknown in the prior art, and operates to free cache memory system designers from the constraints imposed by Lee and Katz. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> As is well-known to those skilled in the art, the write-back buffer <highlight><bold>131</bold></highlight> is used to hold the content of each write operation to main memory <highlight><bold>160</bold></highlight> prior to actual recordation in the main memory <highlight><bold>160</bold></highlight>. And, according to the teachings of the present invention, the write-back buffer <highlight><bold>131</bold></highlight> is used specifically to hold the content of each write operation to the static cache memory <highlight><bold>120</bold></highlight>. The DIRTY bit <highlight><bold>138</bold></highlight> is set whenever a new operand is written to the static cache memory, but not yet recorded to the corresponding main memory location. For example, if the operand <highlight><bold>126</bold></highlight> has only been written to the static cache memory location <highlight><bold>122</bold></highlight>, but not to the corresponding main memory location <highlight><bold>162</bold></highlight>, then the DIRTY bit <highlight><bold>138</bold></highlight> will be set. However, after the operand <highlight><bold>126</bold></highlight> is written from the write-back buffer <highlight><bold>131</bold></highlight> to the corresponding address <highlight><bold>162</bold></highlight> of the main memory <highlight><bold>160</bold></highlight>, then the DIRTY bit <highlight><bold>138</bold></highlight> will be reset, since the cache memory address <highlight><bold>122</bold></highlight> now holds the same operand value as that held by the corresponding main memory address <highlight><bold>162</bold></highlight>. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Thus, while many features of the cache memory controller <highlight><bold>130</bold></highlight> may be similar to or identical to commonly available cache memory controllers, such as that included in the Intel SL385 or SL3V2 Pentium III Xeon&trade; series of microprocessors, the cache memory controller <highlight><bold>130</bold></highlight> constructed according to the teachings of the present invention makes use of several important additional features (and may include them as an integral part of the cache memory controller <highlight><bold>130</bold></highlight> circuit design, as well), such as the tag memory <highlight><bold>132</bold></highlight> having an address portion <highlight><bold>134</bold></highlight> (corresponding to one of the cached addresses <highlight><bold>112</bold></highlight>, <highlight><bold>114</bold></highlight>, <highlight><bold>122</bold></highlight>, or <highlight><bold>124</bold></highlight>, for example), and several associated bits (i.e., the VALID bit <highlight><bold>136</bold></highlight>, the REFRESH bit <highlight><bold>137</bold></highlight>, and the DIRTY bit <highlight><bold>138</bold></highlight>). As can be seen in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the cache memory controller <highlight><bold>130</bold></highlight> is in turn typically connected to a bus <highlight><bold>140</bold></highlight>, which places the cache memory controller <highlight><bold>130</bold></highlight> coupled to the processor module <highlight><bold>150</bold></highlight> and the main memory <highlight><bold>160</bold></highlight>. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> It should also be noted that the cache memory controller <highlight><bold>130</bold></highlight>, the dynamic cache memory <highlight><bold>110</bold></highlight>, and the static cache memory <highlight><bold>120</bold></highlight> may all be disposed on a single substrate <highlight><bold>170</bold></highlight>, or within a single integrated circuit package <highlight><bold>170</bold></highlight>. Also, as mentioned previously, the dynamic cache memory size (in terms of the number of dynamic cache memory locations) will typically be selected so as to be about three times the static memory size (in terms of the number of static cache memory locations). While this ratio of 3:1 is based on the proportion of read operations to write operations executed by typical microprocessors, the ratio may be selected to be whatever corresponds most closely to the proportion of read:write operations experienced for a particular data processing environment, in accordance with other design constraints. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> A particular protocol may be combined with the structure of the cache memory system <highlight><bold>100</bold></highlight> to make utilization more efficient. For example, when a write is performed by the processor <highlight><bold>150</bold></highlight>, the dynamic cache memory <highlight><bold>110</bold></highlight> can also checked for a hit in case the line to be written is present in the dynamic cache memory <highlight><bold>110</bold></highlight> (i.e., a previous memory read operation placed the line of data into the dynamic cache memory <highlight><bold>110</bold></highlight>). If the line is found in the dynamic cache memory <highlight><bold>110</bold></highlight>, the line may be transferred to the static cache memory <highlight><bold>120</bold></highlight>. This operation involves reading the entire line from the dynamic cache memory <highlight><bold>110</bold></highlight>, transferring the line to the static cache memory <highlight><bold>120</bold></highlight>, and then writing the new data into the static cache memory <highlight><bold>120</bold></highlight> using the processor <highlight><bold>150</bold></highlight>. The DIRTY bit <highlight><bold>138</bold></highlight> for the line in the static cache memory <highlight><bold>120</bold></highlight> may then be set, and the original line in the dynamic cache memory <highlight><bold>110</bold></highlight> can be invalidated, freeing that series of memory locations in the dynamic cache memory <highlight><bold>110</bold></highlight> for future use. In this manner, data is typically not duplicated in multiple locations. Further accesses to the data may occur within the static cache memory <highlight><bold>120</bold></highlight>, and an eviction from the static cache memory <highlight><bold>120</bold></highlight> can be handled in the conventional fashion, well known to those skilled in the art. If this protocol is used, data will typically never need to be evicted from the dynamic cache memory <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>A, exemplary diagrams of the state of entry bits <highlight><bold>312</bold></highlight> (i.e., the REFRESH and VALID bits) and tag memory addresses <highlight><bold>314</bold></highlight> corresponding to dynamic cache memory for read operations from main memory locations within a cache memory system constructed according to an embodiment of the present invention can be seen. In <cross-reference target="DRAWINGS">FIG. 2</cross-reference>A, table <highlight><bold>200</bold></highlight> represents the state of the cache memory entry bits <highlight><bold>212</bold></highlight> for each of the corresponding tag memory addresses <highlight><bold>214</bold></highlight> at the beginning of the refresh interval. For reference purposes, the REFRESH bits <highlight><bold>222</bold></highlight>, <highlight><bold>224</bold></highlight>, <highlight><bold>226</bold></highlight>, and <highlight><bold>228</bold></highlight> (relating to the state of the operands stored in the dynamic memory cache for the corresponding main memory addresses <highlight><bold>242</bold></highlight>, <highlight><bold>244</bold></highlight>, <highlight><bold>246</bold></highlight>, and <highlight><bold>248</bold></highlight>, respectively) are equivalent to the bit <highlight><bold>137</bold></highlight> (and the address <highlight><bold>134</bold></highlight>) shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. Similarly, the VALID bits <highlight><bold>232</bold></highlight>, <highlight><bold>234</bold></highlight>, <highlight><bold>236</bold></highlight>, and <highlight><bold>238</bold></highlight> (relating to the state of the operands stored in the dynamic cache memory addresses <highlight><bold>242</bold></highlight>, <highlight><bold>244</bold></highlight>, <highlight><bold>246</bold></highlight>, and <highlight><bold>248</bold></highlight>, respectively) are equivalent to the bit <highlight><bold>136</bold></highlight> (and the address <highlight><bold>134</bold></highlight>) shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Table <highlight><bold>210</bold></highlight> illustrates the cache state in the middle of the refresh interval, and table <highlight><bold>220</bold></highlight> illustrates the cache state at the end of the refresh interval. Each of the tables <highlight><bold>200</bold></highlight>, <highlight><bold>210</bold></highlight>, and <highlight><bold>220</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 2A</cross-reference> may represent, for example, the condition of the cache entry bits <highlight><bold>212</bold></highlight> as various operations are conducted using the dynamic cache memory. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Thus, with regard to the first table <highlight><bold>200</bold></highlight>, the VALID bits <highlight><bold>232</bold></highlight>, <highlight><bold>234</bold></highlight>, <highlight><bold>236</bold></highlight>, and <highlight><bold>238</bold></highlight> reflect the status of the operands contained within the memory locations of the dynamic cache memory corresponding to the main memory addresses referenced by ADD<highlight><bold>0</bold></highlight>, ADD<highlight><bold>1</bold></highlight>, ADD<highlight><bold>2</bold></highlight>, and ADD<highlight><bold>3</bold></highlight>, respectively. That is, the operands contained in the dynamic cache memory locations corresponding to ADD<highlight><bold>0</bold></highlight>, ADD<highlight><bold>2</bold></highlight>, and ADD<highlight><bold>3</bold></highlight> are invalid, while the operand contained in the dynamic cache memory location corresponding to ADD<highlight><bold>1</bold></highlight> is valid. Assuming that the entire dynamic cache memory has been accessed (read from or written to) recently, all of the REFRESH bits <highlight><bold>222</bold></highlight>, <highlight><bold>224</bold></highlight>, <highlight><bold>226</bold></highlight>, and <highlight><bold>228</bold></highlight> are set. As can be seen in table <highlight><bold>210</bold></highlight>, however, some time after the refresh operation has occurred, but before a new refresh operation is conducted, REFRESH bits <highlight><bold>222</bold></highlight>, <highlight><bold>224</bold></highlight>, and <highlight><bold>228</bold></highlight> are reset, indicating additional accesses (i.e., either read or write operations) to the dynamic cache memory locations corresponding to ADD<highlight><bold>0</bold></highlight>, ADD<highlight><bold>1</bold></highlight>, and ADD<highlight><bold>3</bold></highlight>. Thus, as can be seen in table <highlight><bold>220</bold></highlight>, just before the end of the refresh interval, the VALID bit <highlight><bold>236</bold></highlight> will be reset to indicate that the content of the dynamic cache memory location corresponding to ADD<highlight><bold>2</bold></highlight> is invalid (i.e., the content of the dynamic cache memory corresponding to ADD<highlight><bold>2</bold></highlight> has now been selectively invalidated), because there has been no read or write access to this location since the beginning of the current refresh interval. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>B, an exemplary diagram <highlight><bold>250</bold></highlight> of the state of the entry bits <highlight><bold>252</bold></highlight> (i.e., the DIRTY bit) and tag memory addresses <highlight><bold>254</bold></highlight> corresponding to the static cache memory locations of a cache memory system constructed according to the teachings of the present invention can be seen. For reference purposes, the DIRTY bit <highlight><bold>262</bold></highlight> (relating to the state of the operand stored in the static cache memory address <highlight><bold>364</bold></highlight>) corresponds to the bit <highlight><bold>137</bold></highlight> (and the address <highlight><bold>134</bold></highlight>) shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. Thus, when a new operand, destined eventually to be written to the main memory address referenced by ADDR is stored in the static cache memory, the DIRTY bit <highlight><bold>262</bold></highlight> will be set. After writing the stored operand from the write-back buffer to the main memory, however, the DIRTY bit will be reset. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> As mentioned above, the tag memory for the dynamic cache memory may include VALID, REFRESH, and DIRTY bits for tracking the content of both the dynamic cache memory and the static cache memory. In this case, the addresses <highlight><bold>214</bold></highlight>, <highlight><bold>254</bold></highlight> may correspond to locations in either cache memory, and the cache line <highlight><bold>215</bold></highlight>, for example, may be identical to the cache line <highlight><bold>260</bold></highlight>, for example. However, the invention may also be implemented such that there is a separate tag memory for the dynamic memory cache, and the static memory cache. In this case, the tag memory for the dynamic memory cache will not include a DIRTY bit. Likewise, the separate tag memory for the static cache memory will not include VALID or REFRESH bits. Thus, the cache lines <highlight><bold>215</bold></highlight>, <highlight><bold>216</bold></highlight>, <highlight><bold>217</bold></highlight>, and <highlight><bold>218</bold></highlight> may not correspond in any direct way to the cache line <highlight><bold>260</bold></highlight>, for example. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 3, a</cross-reference> schematic block diagram of a microprocessor and computer system constructed according to the teachings of the present invention can be seen. The microprocessor <highlight><bold>300</bold></highlight> includes a bus interface <highlight><bold>320</bold></highlight>, which facilitates communication with one or more peripheral buses <highlight><bold>305</bold></highlight>, such as the Peripheral Component Interconnect/interface (PCI) local bus architecture, the Industry Standard Architecture (ISA) bus, and the Extended Industry Standard Architecture (EISA) bus. Using the peripheral bus <highlight><bold>305</bold></highlight>, the microprocessor <highlight><bold>300</bold></highlight> can be placed into electronic communication with the main memory <highlight><bold>314</bold></highlight>, input devices <highlight><bold>312</bold></highlight>, such as a mouse and keyboard, and output devices <highlight><bold>316</bold></highlight>, such as a display and printer, so as to form a computer system <highlight><bold>318</bold></highlight>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The microprocessor <highlight><bold>300</bold></highlight> may include a unified (Level 2) L2 cache <highlight><bold>330</bold></highlight> to receive data and instructions from the bus interface <highlight><bold>320</bold></highlight>. The L2 cache <highlight><bold>330</bold></highlight>, in turn, may be connected to two Level 1 (L1) caches: an L1 data cache <highlight><bold>350</bold></highlight>, and an L1 instruction cache <highlight><bold>360</bold></highlight>. The L1 data cache receives and transmits all data from/to the bus interface <highlight><bold>320</bold></highlight>, while the L1 instruction cache is dedicated to receiving instructions from the bus interface <highlight><bold>320</bold></highlight>. The L2 cache is only accessed when there is a miss from one of the L1 caches <highlight><bold>350</bold></highlight>, <highlight><bold>360</bold></highlight>, and the L1 cache is only accessed if there is a miss from the microcache <highlight><bold>370</bold></highlight> (which can be considered a Level 0 or L0 cache). If the processor <highlight><bold>300</bold></highlight> is of the superscalar type, there will be multiple execution units to operate on data received from the bus <highlight><bold>320</bold></highlight>, including arithmetic logic units, registers, multiplexers, and microcode sequencers, etc., all represented by the logic block <highlight><bold>380</bold></highlight>. The multiple execution units within the logic block <highlight><bold>380</bold></highlight> are controlled, in turn, by multiple pipelines, formed by the instruction fetch, pre-decode, and decode units represented by the logic block <highlight><bold>362</bold></highlight>, and the scheduler <highlight><bold>364</bold></highlight>. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the microprocessor <highlight><bold>300</bold></highlight> includes a processor module <highlight><bold>390</bold></highlight>, such as the floating point unit (FPU) in direct or indirect electronic communication with the cache memory system, such as the L1 cache <highlight><bold>350</bold></highlight> and/or the L2 cache <highlight><bold>330</bold></highlight> constructed in accordance with the teachings of the present invention. Therefore, either one, or both the L1 and L2 caches <highlight><bold>350</bold></highlight> and <highlight><bold>330</bold></highlight> (and even the microcache <highlight><bold>370</bold></highlight>) may be similar to or identical to the cache memory system <highlight><bold>100</bold></highlight> illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, including the use of data entry bits and addresses <highlight><bold>212</bold></highlight>, <highlight><bold>252</bold></highlight> and <highlight><bold>214</bold></highlight>, <highlight><bold>254</bold></highlight>, respectively, shown in <cross-reference target="DRAWINGS">FIGS. 2A and 2B</cross-reference>. Thus either one, or both of the cache memory systems <highlight><bold>330</bold></highlight>, <highlight><bold>350</bold></highlight> may include a cache memory controller <highlight><bold>336</bold></highlight>, <highlight><bold>356</bold></highlight> coupled to a dynamic cache memory <highlight><bold>332</bold></highlight>, <highlight><bold>352</bold></highlight> and a static cache memory <highlight><bold>334</bold></highlight>, <highlight><bold>354</bold></highlight>. The microprocessor <highlight><bold>300</bold></highlight> may further include, as a separate element, or within the cache memory systems <highlight><bold>330</bold></highlight>, <highlight><bold>350</bold></highlight>, a validity refresh timer (which may be derived from, or taken directly from the master clock logic <highlight><bold>340</bold></highlight>) coupled to the cache memory controllers <highlight><bold>336</bold></highlight>, <highlight><bold>356</bold></highlight>. Similarly, the microprocessor <highlight><bold>300</bold></highlight> may include validity comparison logic (as a separate element, or as a distinct part of the cache memory systems <highlight><bold>330</bold></highlight>, <highlight><bold>350</bold></highlight>) coupled to the validity refresh timer, as shown and described for <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> As noted previously, the dynamic cache memories <highlight><bold>332</bold></highlight>, <highlight><bold>352</bold></highlight> will typically have a plurality of addresses for storing cached memory operands which result from read operations to the main memory <highlight><bold>314</bold></highlight>. Each cache memory system <highlight><bold>330</bold></highlight>, <highlight><bold>350</bold></highlight> will also include a tag memory with operand VALID and REFRESH bits corresponding to the operand status in each of the storage locations contained within the dynamic cache memories <highlight><bold>332</bold></highlight>, <highlight><bold>352</bold></highlight>. Similarly, each cache memory system <highlight><bold>330</bold></highlight>, <highlight><bold>350</bold></highlight> will also include a tag memory that has operand DIRTY bits corresponding to the operand status in each of the storage locations contained within the static cache memories <highlight><bold>334</bold></highlight>, <highlight><bold>354</bold></highlight>. Each cache memory system <highlight><bold>330</bold></highlight>, <highlight><bold>350</bold></highlight> may also include a write-back buffer for buffering operand writes back to the main memory <highlight><bold>314</bold></highlight> from the static cache memories <highlight><bold>334</bold></highlight>, <highlight><bold>354</bold></highlight>. As can be seen from <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the processor module <highlight><bold>390</bold></highlight> and the cache memory controller may be disposed on a single substrate <highlight><bold>300</bold></highlight>, or within a single circuit module package <highlight><bold>300</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> It will be understood by those of ordinary skill in the art that the embodiments shown in FIGS. <highlight><bold>1</bold></highlight>-<highlight><bold>3</bold></highlight> illustrate a cache memory system, microprocessor, and computer system which include a cache memory controller coupled to a dynamic cache memory and a static cache memory. Thus, one of ordinary skill in the art will understand, upon reading this description, that the memory management circuitry of the present invention can be used in applications other than for cache memory systems, microprocessors, and computer systems, and thus, the invention is not to be so limited. The illustrations of a cache memory system <highlight><bold>100</bold></highlight>, microprocessor <highlight><bold>300</bold></highlight>, and computer system <highlight><bold>318</bold></highlight> in <cross-reference target="DRAWINGS">FIGS. 1 and 3</cross-reference> are intended to provide a general understanding of some applications which may be served by the structure and circuitry of the present invention, and are not intended to serve as a complete description of all the elements and features of microprocessors or computer systems which make use of the novel memory management circuitry and structures described herein. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> Applications which may include the novel memory management circuitry of the present invention as described in this document include electronic circuitry used in high-speed computers, arrays of memory modules and other circuit cards, device drivers, power modules, communication circuitry, modems, processor modules, memory integrated circuits, embedded processors, and application-specific modules, including multilayer, multi-chip modules. Such circuitry may further be included as sub-components within a variety of electronic systems, such as televisions, cellular telephones, personal computers, aircraft, and others. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> FIGS. <highlight><bold>1</bold></highlight>-<highlight><bold>3</bold></highlight> are similarly useful in presenting the application of various methods which may be carried out according to the present invention. Those of ordinary skill in the art will realize that various elements of the cache memory systems, microprocessors, and computer systems of the present invention may be assembled and used in accordance with the structures described in the various figures. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> It should be noted that numerous methods of operating cache memory systems have been devised, and the specific method used often depends on a complex analysis of the usage environment and physical construction for the particular cache memory system being considered. Therefore the method described below may or may not be the best method to implement for a specific operating environment or physical arrangement of electronic devices in a circuit constructed according to the present invention. Thus, the following method is merely to be considered by way of example, and not by way of limitation. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 4, a</cross-reference> flow chart diagram of an exemplary method of operating a cache memory system according to the teachings of the present invention can be seen. The method <highlight><bold>400</bold></highlight> of operating a cache memory system begins with detecting an attempt to access a main memory location in step <highlight><bold>410</bold></highlight> in conjunction with an operand value to be written to, or read from, a location in the main memory. If a cache memory hit is detected (corresponding to the main memory location) in step <highlight><bold>420</bold></highlight>, then a determination is made as to whether the attempt is a memory read operation, or a memory write operation, in step <highlight><bold>430</bold></highlight>. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> If it is determined that the attempt is a memory read operation, then a determination is made as to whether the dynamic cached value in the dynamic cache memory location (corresponding to the main memory location) is valid in step <highlight><bold>440</bold></highlight>. At this point, the cache controller validity comparison logic will determine whether the VALID bit for the dynamic cache memory location is still set. If so, then the dynamic cached value is still valid, and the dynamic cached value may be assigned to the operand value by reading directly from the dynamic cache memory location into the operand value in step <highlight><bold>450</bold></highlight>. Since the dynamic cache memory location has been accessed in step <highlight><bold>450</bold></highlight>, the REFRESH bit corresponding to the dynamic cache memory location can be set in step <highlight><bold>460</bold></highlight>. The method then continues by returning to await detection of further attempts to access main memory in step <highlight><bold>410</bold></highlight>. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> If the cache controller validity comparison logic determines that the dynamic cached value is invalid in step <highlight><bold>440</bold></highlight> (i.e., the VALID bit has been reset), then the value of the operand is obtained by reading directly from the main memory location in step <highlight><bold>470</bold></highlight>, and the retrieved operand value is written to the dynamic memory cache in step <highlight><bold>480</bold></highlight>. The VALID bit corresponding to the newly-written dynamic cache memory location can then be set in step <highlight><bold>490</bold></highlight>, and the REFRESH bit can be set in step <highlight><bold>460</bold></highlight>, reflecting the updated status of the main memory and newly-accessed dynamic cache memory locations. At this point, the method continues by returning to await detection of further attempts to access main memory in step <highlight><bold>410</bold></highlight>. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> If it is determined that the attempt to access main memory is a memory write operation in step <highlight><bold>430</bold></highlight>, then the method continues with step <highlight><bold>432</bold></highlight> by assigning the operand value to a static cached value of a static cache memory location, over-writing the least-recently used static cache memory location (or some other location in the static cache memory determined by algorithms well known to those skilled in the art). This usually occurs by writing the operand value directly into the static cache memory. The DIRTY bit will then be set in step <highlight><bold>434</bold></highlight>, indicating that while the operand has been written into the static cache memory, it has not yet been written into the corresponding main memory location. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> The method then typically continues with writing the static cached value into a write-back buffer location in step <highlight><bold>436</bold></highlight>, and, when the opportunity presents itself, writing the static cached value from the write-back buffer into the main memory location at step <highlight><bold>438</bold></highlight>. The DIRTY bit can then be reset at step <highlight><bold>439</bold></highlight>. At this point, the method continues by returning to await detection of future attempts to access the main memory in step <highlight><bold>410</bold></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> If a cache memory miss corresponding to the attempted access of a main memory location is detected at step <highlight><bold>420</bold></highlight>, and the attempt is determined to be a memory read operation in step <highlight><bold>422</bold></highlight>, then the method continues with obtaining the value of the operand by reading directly from the main memory location in step <highlight><bold>470</bold></highlight>, and writing the operand value to the dynamic memory cache in step <highlight><bold>480</bold></highlight>. If necessary, the least-recently used dynamic cache memory location (or some other location in the dynamic cache memory determined by algorithms well known to those skilled in the art) can be overwritten with the operand value. The VALID bit corresponding to the newly-written dynamic cache memory location can then be set in step <highlight><bold>490</bold></highlight>, and the REFRESH bit can be set in step <highlight><bold>460</bold></highlight>, reflecting the updated status of the main memory and newly-accessed dynamic cache memory locations. At this point, the method continues by returning to await detection of further attempts to access the main memory in step <highlight><bold>410</bold></highlight>. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> If a cache memory miss corresponding to the main memory location is detected at step <highlight><bold>420</bold></highlight>, and the attempt is determined to be a memory write operation in step <highlight><bold>422</bold></highlight>, then the method continues with step <highlight><bold>424</bold></highlight> by assigning the operand value to a static cached value of a static cache memory location, over-writing the least-recently used static cache memory location (or some other location in the static cache memory determined by algorithms well known to those skilled in the art) if necessary. This usually occurs by writing the operand value directly into the static cache memory. If necessary, a copy of the over-written value may be first transferred to the write-back buffer, or even to main memory, depending on the write-back algorithm in use. The DIRTY bit will then be set in step <highlight><bold>426</bold></highlight>, indicating that while the new operand has been written into the static cache memory, it has not yet been written into the corresponding main memory location. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The method the typically continues with writing the static cached value into a write-back buffer location in step <highlight><bold>428</bold></highlight>, and, when the opportunity presents itself, writing the static cached value from the write-back buffer into the main memory location at step <highlight><bold>438</bold></highlight>. The DIRTY bit can then be reset at step <highlight><bold>439</bold></highlight>. At this point, the method continues by returning to await detection of further attempts to access the main memory in step <highlight><bold>410</bold></highlight>. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Although specific embodiments have been illustrated and described herein, it will be appreciated by those of ordinary skill in the art that any arrangement which is calculated to achieve the same purpose may be substituted for the specific embodiment shown. This application is intended to cover any and all adaptations or variations of the present invention. It is to be understood that the above description has been made in an illustrative fashion, and not a restrictive one. Combinations of the above embodiments, and other embodiments not specifically described herein will be apparent to those of skill in the art upon reviewing the above description. The scope of the invention includes any other applications in which the above structures, circuitry, and fabrication and assembly methods are used. The scope of the invention should be determined with reference to the appended claims, along with the full range of equivalents to which such claims are entitled. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A cache memory system, comprising: 
<claim-text>a cache memory controller; </claim-text>
<claim-text>a dynamic cache memory coupled to the cache memory controller; and </claim-text>
<claim-text>a static cache memory coupled to the cache memory controller. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the dynamic cache memory is not connected to periodic refresh circuitry. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including: 
<claim-text>a validity refresh timer coupled to the cache memory controller. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, further including: 
<claim-text>validity comparison logic coupled to the validity refresh timer. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the dynamic cache memory has a plurality of addresses including a cached address having a cached memory operand, further comprising: 
<claim-text>a tag memory location referenced to the cached memory address; </claim-text>
<claim-text>an operand VALID bit; and </claim-text>
<claim-text>an operand REFRESH bit. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein the tag memory further includes an operand DIRTY bit. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the static cache memory has a plurality of addresses including a cached address having a cached memory operand, further comprising: 
<claim-text>a tag memory referenced to the cached memory address; and </claim-text>
<claim-text>an operand DIRTY bit. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, further including: 
<claim-text>a write-back buffer coupled to the cache memory controller. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the cache memory controller, the dynamic cache memory, and the static cache memory are all disposed on a single substrate. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the cache memory controller, the dynamic cache memory, and the static cache memory are all disposed within a single integrated circuit package. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The cache memory system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the dynamic cache memory has a dynamic memory size, wherein the static cache memory has a static memory size, and wherein the dynamic memory size is about three times the static memory size. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A microprocessor, comprising: 
<claim-text>a processor module; and </claim-text>
<claim-text>a cache memory system coupled to the processor module, the cache memory system comprising: 
<claim-text>a cache memory controller; </claim-text>
<claim-text>a dynamic cache memory coupled to the cache memory controller; and </claim-text>
<claim-text>a static cache memory coupled to the cache memory controller. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The microprocessor of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, further including: 
<claim-text>a validity refresh timer coupled to the cache memory controller. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The microprocessor of <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, further including: 
<claim-text>validity comparison logic coupled to the validity refresh timer. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The microprocessor of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein the dynamic cache memory has a plurality of addresses including a cached address having a cached memory operand, further comprising: 
<claim-text>a tag memory location referenced to the cached memory address; </claim-text>
<claim-text>an operand VALID bit; and </claim-text>
<claim-text>an operand REFRESH bit. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The microprocessor of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, wherein the tag memory further includes an operand DIRTY bit. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The microprocessor of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein the static cache memory has a plurality of addresses including a cached address having a cached memory operand, further comprising: 
<claim-text>a tag memory location referenced to the cached memory address; and </claim-text>
<claim-text>an operand DIRTY bit. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The microprocessor of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, further including: 
<claim-text>a write-back buffer coupled to the cache memory controller. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The microprocessor of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the processor module and the cache memory controller are disposed on a single substrate. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A computer system, comprising: 
<claim-text>a main memory; and </claim-text>
<claim-text>a microprocessor coupled to the main memory, the microprocessor comprising: 
<claim-text>a processor module; and </claim-text>
<claim-text>a cache memory system coupled to the processor module, the cache memory system comprising: 
<claim-text>a cache memory controller; </claim-text>
<claim-text>a dynamic cache memory coupled to the cache memory controller; and </claim-text>
<claim-text>a static cache memory coupled to the cache memory controller. </claim-text>
</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The computer system of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the dynamic cache memory has a plurality of addresses including a cached address having a cached memory operand, further comprising: 
<claim-text>a tag memory location referenced to the cached memory address; </claim-text>
<claim-text>an operand VALID bit; and </claim-text>
<claim-text>an operand REFRESH bit. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The computer system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein the tag memory further includes an operand DIRTY bit. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A method of operating a cache memory system, comprising: 
<claim-text>detecting an attempt to access a main memory location in conjunction with an operand value; </claim-text>
<claim-text>if the attempt is a memory read operation, then: 
<claim-text>determining that a dynamic cached value in a dynamic cache memory location corresponding to the main memory location is valid; </claim-text>
<claim-text>assigning the dynamic cached value to the operand value; and </claim-text>
<claim-text>setting a REFRESH bit corresponding to the dynamic cache memory location; </claim-text>
</claim-text>
<claim-text>otherwise, if the attempt is a memory write operation: 
<claim-text>assigning the operand value to a static cached value of a static cache memory location; and </claim-text>
<claim-text>setting a DIRTY bit corresponding to the static cache memory location. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference>, further including: 
<claim-text>writing the static cached value into a write-back buffer location; and </claim-text>
<claim-text>writing the static cached value from the write-back buffer into the main memory location. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference>, further including: 
<claim-text>detecting a cache memory hit corresponding to the main memory location. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference>, further including: 
<claim-text>determining whether the attempt is a memory read operation or a memory write operation. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. A method of operating a cache memory system, comprising: 
<claim-text>detecting an attempt to access a main memory location in conjunction with an operand value; </claim-text>
<claim-text>detecting a cache memory miss corresponding to the main memory location: 
<claim-text>if the attempt is a memory read operation, then: 
<claim-text>reading the operand value from the main memory location; </claim-text>
<claim-text>assigning the operand value to a dynamic cached value in a dynamic cache memory location; and </claim-text>
<claim-text>setting a REFRESH bit corresponding to the dynamic cache memory location; </claim-text>
</claim-text>
<claim-text>otherwise, if the attempt is a memory write operation: 
<claim-text>assigning the operand value to a static cached value of a static cache memory location; and </claim-text>
<claim-text>setting a DIRTY bit corresponding to the static cache memory location. </claim-text>
</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 27</dependent-claim-reference>, further including: 
<claim-text>writing the static cached value into a write-back buffer location; and </claim-text>
<claim-text>writing the static cached value from the write-back buffer into the main memory location. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 27</dependent-claim-reference>, further including: 
<claim-text>determining whether the attempt is a memory read operation or a memory write operation.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005226A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005226A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005226A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005226A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005226A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
