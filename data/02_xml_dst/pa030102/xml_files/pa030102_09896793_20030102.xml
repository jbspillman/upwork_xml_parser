<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001851A1-20030102-D00000.TIF SYSTEM "US20030001851A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001851A1-20030102-D00001.TIF SYSTEM "US20030001851A1-20030102-D00001.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001851</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09896793</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010628</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06T001/20</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>345</class>
<subclass>506000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>System and method for combining graphics formats in a digital video pipeline</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Robert</given-name>
<middle-name>D.</middle-name>
<family-name>Bushey</family-name>
</name>
<residence>
<residence-us>
<city>San Diego</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>HEWLETT-PACKARD COMPANY</name-1>
<name-2>Intellectual Property Administration</name-2>
<address>
<address-1>P.O. Box 272400</address-1>
<city>Fort Collins</city>
<state>CO</state>
<postalcode>80527-2400</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Generally, graphics are displayed on a monitor or printed on an output device after a series of steps are performed, typically implemented in the form of a graphics pipeline, in the case of an object-oriented graphic image. Similarly, a digital picture or digital video image passes through a digital pipeline for the digital image or images to be displayed, printed, or otherwise processed. The present invention encompasses a system and method in which the stages of the graphics pipeline used to process a graphic object are interconnected to the stages of the digital pipeline used to process a bit-mapped image so that a single, interconnected pipeline can be used to process object-oriented graphic images, bit map images and/or images which contain graphics and bit map portions. This interconnected pipeline can be used to process images through various stages of the graphics pipeline followed by stages typically contained in the digital pipeline, or vice versa, to create desired effects. This interconnected pipeline includes a switch or a selectively configurable interconnection matrix which defines an image path which connects desired stages of the pipeline. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> Images can typically be represented and displayed using either of two types of imagery information: raster graphics (or bit map data) and graphic objects. Typically, digital images generated by a computer are displayed on a display device (monitor) using a color triad of red, green, and blue (RGB) phosphorous dots. A computer display is made up of rows and columns of pixels. Each pixel is a triad of phosphorous dots (RGB). The intensities of the red, green and blue in each pixel is controlled to simulate various colors on the computer display device. A digital picture is displayed on a computer display device by addressing each triad of three dots constituting a pixel and defining the RGB intensities. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The pixel illumination information is sent as raw raster data from the computer to the display and consists of intensities of the RGB pixels starting with, typically, the upper left hand pixel on the computer screen, followed by intensity values for the red, green, and blue pixels in each of the subsequent pixel groups in that first row along the top of the computer screen. Once the top row is completed, the raw raster data continues with the left most pixel in the second row of the computer screen and similarly each group of pixels contained within the computer screen is supplied with an intensity value for each of the pixels in the pixel group from the raw raster data. In this manner, the computer generates a digital picture which is displayed on the computer screen which appears as a picture to an observer. This pattern of pixel illumination information is typically referred to as a &ldquo;bit map&rdquo; or a &ldquo;bit-mapped&rdquo; image, in other words each pixel on the screen is mapped to a value stored in a two dimensional memory array corresponding to the pixel layout of the display, each memory element storing a corresponding pixel luminance value from 0 to 255. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> Input devices, such as digital cameras and camcorders may use a Bayer filter implementing a Bayer pattern of four color sensors grouped together with the upper left hand sensor being sensitive to green, the upper right hand sensor being sensitive to blue, the lower left hand sensor being sensitive to red and the lower right hand sensor being sensitive to green. The sensor elements repeat in a known pattern. The Bayer pattern described is a standard input sensor color format for the orientation of the red, green, and blue pixels but one of ordinary skill would understand that various permutations of this pattern are possible and used throughout the computer industry. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> The computer can perform a number of processes or steps on the raw bit map image captured from a sensor to increase the aesthetic value of the overall image. For instance, the color resulting from the field of four sensor Bayer groups (determined by the intensities of the sensors themselves) can be compared to the color of surrounding sensors and the derived RGB triad intensity values can be established and adjusted to ensure that a gradual changing of color occurs, for instance in the coloration of the face of a person, as would be eventually displayed as a digital picture. Together these individual steps in adjusting the color resulting from sensors or pixel groups, through adjusting the intensities of the color elements establish a bit map pipeline or raw raster pipeline. The bit map image which make up the digital image is, to the computer, a series or string of color intensity values. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> A computer may also typically generate a graphic image using object-oriented graphics to generate one or more graphic primitives such as points, lines, polygons, alphanumeric characters, special symbols and fonts, etc., and combine these basic graphic primitives to represent the overall image. For instance, a square, being a standard graphic primitive object would be represented as data required to construct such a square, such as size, location, line and fill color, etc., so as to constitute a square graphics image. However, a person included in a graphics image would be composed of a number of individual graphic primitives which, when grouped together, appear as a person or some other complex object consisting of a plurality of primitives. Recognition software exists today which will transform a bit map or raster graphics digital image into an object-oriented graphic representation of the digital image. These algorithm vary in capability and the graphical representation of the digital image is a direct function of the capability of the algorithm used in the conversion. For instance, if this algorithm is used on the digital image of a person, the quality of the appearance of the graphic image of the person is a direct function of the quality of the algorithms which convert the raster digital image of the person into an object-oriented graphical representation of the person. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Once a digital image is converted to an object-oriented graphical representation, the computer can alter the position and orientation of the various primitives which represent the digital image to simulate motion of the graphical representation. For instance, if a digital image of a person were converted to a graphical representation, the orientation of the object-oriented graphical primitive objects which are used to represent the legs of the person may be varied to simulate a person walking. As the complexity of the graphical images and the simulated motion improve, the quality of the overall graphic image approaches a real or non-synthetic image. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> The graphic data to be displayed on a computer screen passes through a number of stages in order to improve the overall appearance of the image. In other words, the graphic image can be passed through a graphics pipeline which will enhance the appearance of the resulting overall graphic image, perform various corrections and assemble primitive elements and constituent components into a unified image. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> As previously discussed, the images displayed on a computer screen normally result from either an object-oriented graphic image or a bit map (raster scan) image. If bit map images are displayed, a bit map or raster pipeline is used to adjust the color intensities of the pixels before the image is displayed on the computer screen. If graphic object-oriented images are displayed, the graphical images are passed through a graphics pipeline to assemble the primitives into a composite image for viewing. While prior art systems have segregated portions or windows on the screen in which a bit map image or an object-oriented graphic. image can be displayed, similar to the &ldquo;picture-in-picture&rdquo; feature of modern televisions, the image within an area or window of the screen is still either a bit map image or an object-oriented graphic image because those images come through different graphic pipes. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Problems exists when it is desired to effectively and efficiently process both object-oriented (i.e., vector) and bit map (i.e., raster) graphics and images interchangeably. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The need for effectively and efficiently processing both object-oriented and bit map graphics and images is achieved by a system for and method of combining both object-oriented (or &ldquo;vector&rdquo;) graphics and raster scan (or &ldquo;bit-mapped&rdquo; or &ldquo;bit map&rdquo; image) pipelines so that image data can be processed by selected stages of either and/or both pipelines. That is, an object-oriented graphics pipeline may include several processing stages configured to sequentially process graphics data, the graphics data may include data to generate one or more graphic primitives, such as points, lines, polygons, alphanumeric characters, special symbols and fonts, etc. Examples of possible graphic processing stages in the object-oriented graphic pipeline may include some combination or subcombination of scan conversion, clipping, windowing to viewport, projection, sorting and/or may include other or substitute functionalities and others. Similarly, a bit-mapped or raster scan pipeline may include several processing stages configured to sequentially process bit-mapped data representing an image as a plurality of pixel luminance values and/or other pixel characteristics. These bit-mapped or raster scan pipeline processing stages may include some combination or subcombination of demosaicing, color correction/white balancing, gamut mapping, tone correction, flare correction, color transformation, scaling and/or may include other or substitute functionalities and others. Advantageously, the processor provides for selective sequencing through each pipeline and for &ldquo;cross-over&rdquo; of data between stages of each pipeline including any necessary data conversion (e.g., polygon recognition and conversion of bit-mapped images to form object-oriented graphic data, and similar conversion of object-oriented graphic format data into a bit map data format.) </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWING </heading>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The FIGURE is a block diagram of a combined pipeline according to an embodiment of the invention in which stages of a bit map pipeline are interconnected with stages of a graphics pipeline. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> According to one aspect of the invention, an image processor may include an object-oriented graphics pipeline having a first plurality of stages configured to process a graphic object, and a bit map image pipeline having a second plurality of stages configured to process a bit map image. An interconnection may be selectively configurable to provide an output from one of the stages of one of the pipelines (i.e., either the graphics or the bit map image pipeline) to an input of a selected or default next stage (if any) of the same pipeline or to a selected stage (or stages) of the other pipeline. According to a feature of the invention, each of the first plurality of stages (i.e., stages of the graphics pipeline) may perform a different function, the functions including (but not necessarily limited to) one or more of the group including scan conversion, clipping, windowing to viewport, projection, and sorting. Similarly, according to another feature of the invention, each of the second plurality of stages (i.e., the stages of the bit map image pipeline) may perform a different function, the functions including (but not necessarily limited to) one or more of the group including: demosaicing, color correction/white balancing, gamut mapping, tone correction, flare correction, color transformation, and scaling. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> According to another feature of the invention, an output stage may be connected to an output from each of the pipelines (e.g., from a selected stage of both the graphic and bit map image pipelines). The interconnection between the pipelines may include a switching matrix configurable to route outputs from one or more of the first plurality of (graphics) stages to a designated or selected next one of the first plurality of (graphics) stages and to a selected one of the second plurality of (bit map image) stages. Similarly, the switching matrix may be configured to route outputs from some of the second plurality of (bit map image) stages to a next one of the second plurality of (bit map image) stages and to a selected one of the first plurality of (graphics) stages. According to another feature of the invention, the graphics pipeline is configured to receive graphics data including graphics identification and location data and the bit-mapped image pipeline is configured to receive a raster scanned image data representing pixel luminance information. A data format converter may be included and configured to convert between an object-oriented graphics data format and a bit map image data format, i.e., unidirectionally from one, or bidirectionally from either format to the other. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> According to another feature of the invention, an image recognition stage may be configured to identify and encode object-oriented graphic images within the bit-mapped image. For example, the recognition stage may recognize primitive elements and shapes including polygons, polyhedrons, lines, planes, curves, arcs, points, vectors, characters, symbols, and other primitives and composite graphic structures within a bit map or raster based representation and convert the same into an appropriate object-oriented graphic data representation. The conversion may include deletion of the converted portions from the original bit map image so that a remaining portion of the latter can be appropriately processed while the converted objects are subject to graphics pipeline processing. A common instruction decoder may be included, operable to control the interconnection (e.g., a switching matrix) to route at least one of the graphic objects and the bit-mapped image object between both the graphics and bit-mapped image pipelines. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> According to another aspect of the invention, a method of processing an image may include selective configuration of one or more stages of an object-oriented graphics pipeline and one or more stages of a bit map image pipeline. The resultant configuration may cause an output from one of the stages of one of the pipelines to be supplied to an input of one of the stages of the other of the pipelines and processing an image by transmission of the image through at least one of the stages of each pipeline. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> According to a feature of the invention, processing performed by each of the graphics pipeline stages may be different from processing performed by the other stages of that pipeline and may be selected from among (but is not limited to) the group of processing including scan conversion, clipping, windowing to viewport, projection, and sorting. Similarly, processing performed by each of the stages of the bit map image pipeline may be different from processing performed by the other stages and may be selected from among (but is not limited to) the group of processing including demosaicing, color correction/white balancing, gamut mapping, tone correction, flare correction, color transformation, and scaling. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> According to another feature of the invention, a combining step may form a merged output from signals or data supplied by outputs of both pipelines. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> According to another feature of the invention, the step of selectively configuring the pipelines may include alternatively routing outputs from one or more stages to a next one of the stages or to a selected one of the stages of the other pipeline. Object-oriented graphics data may be passed by the graphics pipeline in a format including graphics identification and location data, and/or raster scanned (or bit map) image data representing individual pixel characteristics (e.g., luminance, color, or other pixel display information, etc.) may be passed by the bit map image pipeline. A conversion step may be included to transform between an object-oriented graphics data format and a bit-mapped image data format (i.e., performs data conversion in either one or both directions). An image recognition step may provide for identification and encoding of the graphic images within the bit-mapped image. According to another feature of the invention, a step of controlling an interconnection provides routing of either (or both) of the graphic object and the bit-mapped image object between the graphics and bit map image pipelines. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> According to another aspect of the invention, a processor may include two pipelines means, a first pipeline means may include a plurality of graphic image processing means for processing an object-oriented graphic object, a second pipeline means including a plurality of a bit map image processing means for processing a bit-mapped image. Interconnection means may selectively connect an output from one of processing means of one of the pipeline means to an input of one of the processing means of the other of the pipeline means. Digital imaging requires processing a bit map image using a bit map or raster pipeline to obtain a displayable image including red, green and blue pixel information. The bit map pipeline includes a number of steps in which the resulting image is corrected or manipulated to ensure that an accurate, representative and pleasing image is displayed. For example, a digital video display typically displays thirty digital image frames per second with each digital image passing through the raster pipeline as described below. The computer displaying a digital image, or full or partial motion digital video, interprets the digital picture or pictures as a combination of intensity values for the pixels which make up the digital image to be displayed on the computer display monitor. Without additional processing, the computer does not recognize objects contained within the digital image or video. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> The computer can, however, perform limited modifications of bit map digital images. Since the computer interprets the digital image as a series of intensity values, the computer can increase or reduce intensity values to darken or reduce displayed resulting colors respectively. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The FIGURE illustrates a combined pipeline which includes the processing stages of both the bit map pipeline as well as the processing stages of the object-oriented graphics pipeline according to an embodiment of the invention. Interconnections are included within the combined pipeline which allow the output of one stage of the pipeline to be directed to another stage of the pipeline for further processing. For example, an image in the form of Bayer pattern bit map image <highlight><bold>101</bold></highlight> is shown entering a traditional bit map pipeline <highlight><bold>100</bold></highlight> at demosaic stage <highlight><bold>102</bold></highlight>. Demosaic stage <highlight><bold>102</bold></highlight> converts the Bayer pattern input elements red, green and blue triad intensities for each pixel and compensates for artifacts (the influence of previously supplied intensity values). In a traditional bit map pipeline the output intensity values of demosaic stage <highlight><bold>102</bold></highlight> would pass into color correction and white balance stage <highlight><bold>103</bold></highlight>. Within color correction and white balance stage <highlight><bold>103</bold></highlight> the processing software examines the overall white balance of the bit map to ensure that the constituent colors forming each pixel which are intended to be combined to appear white have the correct intensities for the combination to actually appear as white. Additionally, the intensities of other colors are corrected by adjusting the intensities of the red, green and blue components so the displayed color matches, as closely as possible, the actual colors intended. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> Different devices produce specific colors differently, and gamut mapping stage <highlight><bold>104</bold></highlight> corrects for coloring differences between various platforms. This compensation corrects differences between various devices, such as computer screens, printers, plotter, or any other device in which the image may be displayed or recorded. The purpose of gamut mapping <highlight><bold>104</bold></highlight> is to eliminate differences which may occur from one color space to another color space so that the resulting colors in the digital image are produced accurately. In other words, a digital image which is displayed on a computer screen should have the same coloring as a printed copy of the digital image; gamut mapping stage <highlight><bold>104</bold></highlight> is intended to enhance faithful rendering of the image. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Tone correction stage <highlight><bold>105</bold></highlight> is also included in the video pipeline to eliminate or reduce color variations from pixel to pixel when both pixels represent the same color. For instance, if in the center of a diagram is a square red box, where the color of the box is consistent throughout, tone correction will check the constituent pixel color components of the square red box and adjust the intensities of the red, green and blue components to be identical. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Flare correction stage <highlight><bold>106</bold></highlight> is also included in the raw image pipeline to control the effects of white light in the original image and how that white light effects the resultant image. For instance, if part of the square red box discussed above was illuminated with a white spotlight while another portion of the square red box was outside the light from the spotlight, the presence of the white spotlight should not affect the shade of red on the square red box, only the illumination of that portion of the red box itself. Flare correction stage <highlight><bold>106</bold></highlight> adjusts the intensities of each color component so that resulting colors remain proportionately correct between pixels in other lighting conditions. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Color transformation stage <highlight><bold>107</bold></highlight> compensates for variations in color in a single object and scaling stage <highlight><bold>108</bold></highlight> is included in the video pipeline to scale the digital image for the desired display or output device. It is important to note that the steps contained in bit map pipeline <highlight><bold>100</bold></highlight> of the combined pipeline are given by way of example of possible raster or bit map image processing and division of such processing into discrete stages as might be used to process a specific digital image may not be necessary during the processing of each and every digital image displayed. Additionally, bit map pipeline <highlight><bold>100</bold></highlight> included in the combined pipeline is but one sequence in which the processing steps may occur. For example, tone correction stage <highlight><bold>105</bold></highlight> may occur prior to gamut mapping stage <highlight><bold>106</bold></highlight>. Gamut mapping <highlight><bold>106</bold></highlight> requires information about the intended output devices. Gamut mapping may, in some instances, be the last step in bit map pipeline <highlight><bold>100</bold></highlight>. The sequence of stages, and even the number of stages, a specific digital image is processed through within the bit map pipeline is flexible. According to one embodiment, each of the discussed stages is preferably included in the bit map pipeline to provide a desired correction. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Also contained within the combined pipeline structure is object-oriented graphics pipeline <highlight><bold>109</bold></highlight>. An initial object-oriented graphics image, such as line <highlight><bold>110</bold></highlight>, defined through two end points x<highlight><bold>1</bold></highlight>, y<highlight><bold>1</bold></highlight> and z<highlight><bold>1</bold></highlight> and x<highlight><bold>2</bold></highlight>, y<highlight><bold>2</bold></highlight> and z<highlight><bold>2</bold></highlight>, enters graphics pipeline <highlight><bold>109</bold></highlight> at scan conversion stage <highlight><bold>111</bold></highlight>. For a line, scan conversion stage <highlight><bold>111</bold></highlight> would algorithmically draw an imaginary line which represents all points along line <highlight><bold>110</bold></highlight>. Once the line is algorithmically determined, the pixels constructing the image of the line are identified and rendered. Rendering is the term used to describe the creation of the image using geometric models and using color and shading to give the image a realistic look. The overall function of scan conversion stage <highlight><bold>111</bold></highlight> may also include the process of transforming a linkless geometric description of a shape, such as a polygon to render an image of a polygon. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> Clipping stage <highlight><bold>112</bold></highlight> occurs when an image window is defined and portions of the rendered image, which lie outside the specified image window, are removed from the rendered image. The clipping stage includes the application of a number of possible algorithms. Clipping can use windows of user defined size and shapes to intelligently remove portions of the image outside the defined space. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> Within window to viewport stage <highlight><bold>113</bold></highlight> orthogonal coordinates are defined, typically u and v, to define a space which encompasses the graphic image. Once the space is defined, the space is normalized by applying a set of algorithms which perform a geometric transformation on the defined space. The normalized space is used to minimize the complexity of the projection performed in projection stage <highlight><bold>114</bold></highlight>. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Projections stage <highlight><bold>114</bold></highlight> defines various projections, or viewpoints, for viewing a graphic object and the portion of the graphic object viewed from the various viewpoints. In projections stage <highlight><bold>114</bold></highlight> the normalized geometric shape is paired with a center of projection, from which a ray is projected and the portions of the geometric shape are identified that are visible from that center of projection. For instance, a back clipping plane may be defined in which a projection of the image is generated which includes the shape of the image as it would appear from the back or behind the image. Similarly, a front clipping plane may be defined in which a projection of the image, as it would appear from the front, is captured. These projections can be from a two dimensional point of view or from a three dimensional point of view. Typically a parallel projection is used in which the center projection is defined to be at infinity. The parallel projection allows the projection of the object to appear as if the viewpoint was a plane parallel to the surface of the object rather than from a single point in space. The center of projection may be predefined or determined by the user. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Sort stage <highlight><bold>115</bold></highlight> typically is placed after a view reference point is defined. The view reference point defines the point from which the projection of the object will be displayed on the display screen. Once the view reference point is defined, the projections of the image which have been created by projections stage <highlight><bold>114</bold></highlight> are sorted to identify the correct projection from the view reference point. For example, one of the algorithms used in sort stage <highlight><bold>115</bold></highlight> is a backface culling algorithm which eliminates surfaces which would be behind the graphical object from the reference viewpoint. Sort stage <highlight><bold>115</bold></highlight> represents the family of algorithms which determine the portions of the graphical image which will be shown. A depth sorting algorithm is typically also included to consider various depths of the graphical object and display as appropriate. The view reference point may be predefined or determined by the user. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> The outputs of the object-oriented graphic pipeline <highlight><bold>109</bold></highlight> and raster pipeline <highlight><bold>100</bold></highlight> are combined to form merged output <highlight><bold>116</bold></highlight>. The merged output may be either from the final output stage of the graphics pipeline <highlight><bold>109</bold></highlight> or the raster pipeline <highlight><bold>100</bold></highlight>. Alternatively, the merged output may be outputs from both the pipelines interleaved by appropriate means. Merged output <highlight><bold>116</bold></highlight> can then be displayed on the computer screen or by any other device. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The combined pipeline includes cross-connections <highlight><bold>117</bold></highlight>-<highlight><bold>139</bold></highlight> forming routing matrix <highlight><bold>140</bold></highlight> and which resides between the stages of the raster pipeline and the stages of the graphic pipeline. Routing matrix <highlight><bold>140</bold></highlight> is controlled by control logic <highlight><bold>141</bold></highlight> including configuration registers <highlight><bold>142</bold></highlight> used to define interconnections between and among pipeline stages as implemented in routing matrix <highlight><bold>140</bold></highlight>. Control logic <highlight><bold>141</bold></highlight> may include an automatic control of the path the specific image data may follow through the combined pipeline. This path may be controlled by application software settings (predefined or user controlled), operating systems setting (predefined or user controlled) or based on preestablished rules dependent on the characteristics of the image data, input device and/or the output device. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> These connections allow the image data from each pipeline to be converted into a combined image and processed by any of the stages contained in the combined pipeline. For example, once demosaic stage <highlight><bold>102</bold></highlight> has finished processing, the resulting bit map image data may be a sequence of color intensity values representing the digital image. These intensity values can be sent via path <highlight><bold>117</bold></highlight> to scan conversion stage <highlight><bold>111</bold></highlight>. At scan conversion stage <highlight><bold>111</bold></highlight> the image, consisting of a series of RGB values, will be processed in order for the software to recognize the object-oriented graphic objects contained within the bit map image. This object recognition software resides in stage <highlight><bold>143</bold></highlight> and is bidirectionally connected to the output of the stages contained in bit map pipeline <highlight><bold>100</bold></highlight>. For example, if the original digital image is that of a person, numerous pixels <highlight><bold>101</bold></highlight> are processed by demosaic stage <highlight><bold>102</bold></highlight>. This string of pixels can be sent to scan conversion stage <highlight><bold>111</bold></highlight> after processing of digital image and the image of the person contained in the digital image is transformed into a series of object-oriented geometric shapes (e.g., primitives) that approximate the original bit map digital image. Once the transformation has been performed, scan conversion stage <highlight><bold>111</bold></highlight> transforms the geometric objects into a three-dimensional representation of the person contained in the digital image. The three-dimensional representation can then be processed by any of the remaining stages of the graphics pipeline as appropriate. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Alternatively, instead of routing matrix <highlight><bold>140</bold></highlight>, routing of data between and among the various pipeline stages may be accomplished by including routing information appended to or otherwise associated with the image data to be processed, e.g., as a routing tag defining a path through the combined pipelines. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Conversely, when a graphic primitive in the form of line <highlight><bold>110</bold></highlight> is received by scan conversion stage <highlight><bold>111</bold></highlight>, a three dimensional representation of that line is typically the end result of the scan conversion. If the user would like to send that three dimensional line to color correction/white balance stage <highlight><bold>103</bold></highlight>, the three dimensional line would be converted to bit map representation which represents the line in a digital format. This conversion is preformed by data format converter <highlight><bold>144</bold></highlight> which is bidirectionally connected to the output of each stage of object-oriented graphics pipeline <highlight><bold>109</bold></highlight>. This RGB four pixel representation could then be sent through any of the remaining stages of the bit map pipeline <highlight><bold>100</bold></highlight> for enhancement. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Alternatively, and preferably, a combined format can be created which contains the favorable attributes of the two methods of representing images, the ability for the computer to recognize and manipulate objects of the object-oriented graphics format, and the ability to accurately depict the image on the computer screen through the bit map image format. This combined format would eliminate the necessity of converting the image from a graphical representation to an RGB pixel representation each time the user directs the image to a stage typically contained in the bit map pipeline and convert the image from an RGB bit map representation to an object-oriented graphical (or polygon) representation when using stages from the graphic pipeline. This combined format is preferably a mapping between the RGB raster space and the object-oriented graphic space, or may consist of a superset of the two formats. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. An image processor comprising: 
<claim-text>a graphics pipeline including a first plurality of stages configured to process a graphic object, </claim-text>
<claim-text>a bit map image pipeline including a second plurality of stages configured to process a bit-mapped image, and </claim-text>
<claim-text>a selectively configurable interconnection matrix defining an image path for providing selected outputs from one or more of said stages of one of said pipelines to selected inputs of one or more of said stages of the other of said pipelines. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The image processor according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein each of said first plurality of stages is different from the others and is selected from among the group of stages including scan conversion, clipping, windowing to viewport, projection, and sorting. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The image processor according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein each of said second plurality of stages is different from the others and is selected from among the group of stages including demosaicing, color correction/white balancing, gamut mapping, tone correction, flare correction, color transformation, and scaling. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The image processor according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising an output stage connected to an output from each of said pipelines. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The image processor according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein said interconnection comprises a switching matrix configurable to: 
<claim-text>route outputs from one or more of said first plurality of stages to a next one of said first plurality of stages or to a selected one of said second plurality of stages; and </claim-text>
<claim-text>route outputs from one or more of said second plurality of stages to a next one of said second plurality of stages or to a selected one of said first plurality of stages. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The image processor according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein said graphics pipeline is configured to receive graphics data including graphics identification and location data and said bit-mapped image pipeline is configured to receive a raster scanned image data representing pixel luminance information. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The image processor according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising a data format converter configured to convert between a graphics data format and a bit-mapped image data format. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The image processor according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising an image recognition stage configured to identify and encode graphic images within said bit-mapped image. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The image processor according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further including a common instruction decoder operable to control said interconnection to route at least one of said graphic object and said bit-mapped image object between both said graphics and bit-mapped image pipelines. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A method of processing an image comprising the steps of: 
<claim-text>selectively configuring a pipeline interconnection matrix to establish an image path through one or more stages of a graphics pipeline and one or more stages of a bit map image pipeline; and </claim-text>
<claim-text>processing an image by transmission along said image path through at least one stage of each pipeline. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein processing performed by each of said stages of said graphics pipeline is different from processing performed by the others and is selected from among the group of processing including scan conversion, clipping, windowing to viewport, projection, and sorting. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein processing performed by each of said stages of said bit map image pipeline is different from processing performed by the others and is selected from among the group of processing including demosaicing, color correction/white balancing, gamut mapping, tone correction, flare correction, color transformation, and scaling. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> further including a step of combining outputs from each of said pipelines into a merged output. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein said step of selectively configuring said pipelines includes one of: 
<claim-text>alternatively routing outputs from one or more stages of one of said pipelines to a next one of said stages or to a selected one of said stages of the other pipeline. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein further including steps of passing graphics data including graphics identification and location data to said graphics pipeline and passing raster scanned image data representing pixel characteristic information to said bit map image pipeline. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> further comprising a step of converting between a graphics data format and a bit-mapped image data format. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> further comprising a step of image recognition including identification and encoding of said graphic images within said bitmapped image. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> further including a step of controlling an interconnection to route at least one of said graphic object and said bit-mapped image object between both said graphics and bit map image pipelines. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. An image processor comprising: 
<claim-text>a first pipeline including a plurality of graphic image processors for processing a graphic object, </claim-text>
<claim-text>a second pipeline including a plurality of a bit map image processor for processing a bit-mapped image, and </claim-text>
<claim-text>a switch for selectively connecting an output from any one of said processors to an input of any other one of said processors. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The image processor according to <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> wherein: 
<claim-text>a processing function performed by each of said graphic processors is different from a processing function performed by any other graphic processor and at least one of said processing functions is selected from among the group of processes including scan conversion, clipping, windowing to viewport, projection, and sorting; and </claim-text>
<claim-text>a processing function performed by each of said bit map image processor is different from a processing function performed by any other bit map processors, processing functions is selected from among the group of processes including demosaicing, color correction/white balancing, gamut mapping, tone correction, flare correction, color transformation, and scaling.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001851A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001851A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
