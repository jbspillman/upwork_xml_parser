<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002086A1-20030102-D00000.TIF SYSTEM "US20030002086A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002086A1-20030102-D00001.TIF SYSTEM "US20030002086A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002086A1-20030102-D00002.TIF SYSTEM "US20030002086A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002086A1-20030102-D00003.TIF SYSTEM "US20030002086A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002086A1-20030102-D00004.TIF SYSTEM "US20030002086A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002086A1-20030102-D00005.TIF SYSTEM "US20030002086A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002086A1-20030102-D00006.TIF SYSTEM "US20030002086A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002086A1-20030102-D00007.TIF SYSTEM "US20030002086A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002086A1-20030102-D00008.TIF SYSTEM "US20030002086A1-20030102-D00008.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002086</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09896878</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010629</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04N001/40</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>358</class>
<subclass>448000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>System and method for capture and utilization of content and source information</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Tamra</given-name>
<middle-name>L.</middle-name>
<family-name>Thomason</family-name>
</name>
<residence>
<residence-us>
<city>Meridian</city>
<state>ID</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>HEWLETT-PACKARD COMPANY</name-1>
<name-2>Intellectual Property Administration</name-2>
<address>
<address-1>P.O. Box 272400</address-1>
<city>Fort Collins</city>
<state>CO</state>
<postalcode>80527-2400</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The present disclosure provides a system and method for capture and utilization of content source information. According to one aspect of the invention, the method comprises the steps of electronically capturing content, electronically capturing source information pertinent to the source of the captured content, associating the content and the source information; and transmitting the content and source information to a device for manipulation. According to another aspect of the invention, the method comprises the steps of receiving content and associated source information pertinent to the source of the content in electronic form, reconfiguring the content and associated source information for use in a user application, and automatically creating at least one source acknowledgement in the user application. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present disclosure relates to a system and method for capture and utilization of content and source information. More particularly, the disclosure relates to a system and method with which content contained within a hardcopy source, such as a book or magazine, can be captured and integrated with a user application, such as a word processing application, along with information about the source of the captured content. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Researchers often collect information (i.e., content) from various different sources when conducting research on a particular topic. Once this information is collected, the researcher often then creates a document describing his or her findings. For instance, students often consult various library books when conducting research for assignments in which the student is required to write a paper on a particular topic. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> Where the researcher relies upon information located in one or more sources in creating the research document, the researcher normally provides acknowledgements of the sources for the located information reflected in the document. For example, where general concepts found in a particular source are reflected in the document, the researcher may provide a bibliography identifying the source as providing the basis for the document. Where a quote is provided from the source or a particular piece of information (e.g., a fact or idea) expressed in the source is reproduced, the researcher may further provide a footnote or endnote that identifies the origin of the quote or other piece of information. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> When the research is conducted, the researcher typically records information located during the research on which the researcher may later rely in creating a document. For instance, the researcher may take handwritten notes of the content expressed in the source or may photocopy one or more pages of the source for future reference. In the former case, recordation of the information can be tedious, particularly where large amounts of content are being taken from the source. In the latter case, the researcher must normally tab the various passages of the sources, carry them to a copy machine, make the photocopies (typically in exchange for a fee), and then return the sources. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In addition to recording the content found in the sources, the researcher must normally further record bibliographic information concerning the sources so that, if this content is later used in creating the document, proper acknowledgement of the sources can be provided. Recordation of this information can also be tedious for the researcher whether the researcher is taking handwritten notes or using a photocopier. In the former case, the researcher must write down the bibliographic information of the source, including an identification of particular pages where particular quotes or other specific pieces of information were found. In recording this information, the researcher must be careful to collect all relevant bibliography information so that proper acknowledgement can later be provided. In the photocopying context, the researcher must photocopy the bibliographic information (e.g., contained on the title page of the source) and keep accurate records as to which photocopied bibliographic information pertains to which photocopied content. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Once the researcher has completed his or her research and is prepared to create a document describing his or her findings, the researcher must organize the content and attendant bibliographic information and then insert this information in the correct format within the document. In that this information is not in electronic form, this task involves manually reproducing the information in the document, for instance, by transcription using a keyboard. This manual transcription provides an opportunity for various mistakes to be made. For instance, where a quote from a particular source is to be used, it is possible for the researcher to incorrectly transcribe the quoted material. The researcher may also mis-transcribe the bibliographic information that pertains to the sources. Furthermore, where the user failed to record all such bibliographic information, the researcher may need to return to the source and rerecord this information. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> In view of the foregoing, it can be appreciated that it would be desirable to have a system and method that, at least partially, automates the process of collecting content and source information that identifies the origin of the content. Furthermore, it would be desirable to have a system and method that, at least partially, automates integration of the content and source information into a document. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The present disclosure provides a system and method for capture and utilization of content source information. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> In one arrangement, the method comprises the steps of electronically capturing content, electronically capturing source information pertinent to the source of the captured content, associating the content and the source information; and transmitting the content and source information to a device for manipulation. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> By way of example, this method can be practiced with a handheld scanning device. Such a device can comprise a housing configured as a pen, a scan head that is adapted to capture information from a source, and memory including an information association module that is configured to associate captured content with captured source information. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> In one arrangement, the method comprises the steps of receiving content and associated source information pertinent to the source of the content in electronic form, reconfiguring the content and associated source information for use in a user application, and automatically creating at least one source acknowledgement in the user application. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> Other methods, systems, features, and advantages of the invention will become apparent upon reading the following specification, when taken in conjunction with the accompanying drawings. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The invention can be better understood with reference to the following drawings. The components in the drawings are not necessarily to scale, emphasis instead being placed upon clearly illustrating the principles of the invention. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a schematic view of the inventive concept. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a schematic view of a system for capture and utilization of content and source information. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a schematic view of a scanning device shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a schematic view of memory of the scanning device shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a schematic view of a computing device shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 6A and 6B</cross-reference> provide a flow diagram that illustrates an example of operation of the scanning device shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> provides a flow diagram that illustrates an example of operation of an information manager of the computing device shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> As noted above, there are several disadvantages associated with conventional research and document preparation in the research context. Accordingly, the present disclosure describes a system and method that, at least partially, automates the process of collecting content and source information as well as integrating the information with a user application such as a word processing application. The general concept <highlight><bold>100</bold></highlight> of the invention is illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. As shown in this figure, while conducting his or her research, the researcher discovers various information <highlight><bold>102</bold></highlight> that the researcher may wish to use in creating a document that describes his or her findings. This information can include content <highlight><bold>104</bold></highlight>, source information <highlight><bold>106</bold></highlight> associated with the discovered content, and content location information <highlight><bold>108</bold></highlight> that identifies where (e.g., on what page) the content was found. The content <highlight><bold>104</bold></highlight> can comprise any information that the researcher may wish to use in creating the document. For instance, the content <highlight><bold>104</bold></highlight> can comprise text that the researcher will use to write the document and/or that will be inserted into the document, for example as a quotation. The source information <highlight><bold>106</bold></highlight> typically comprises bibliographic information used to acknowledge the source in the research document. Accordingly, this information <highlight><bold>106</bold></highlight> typically comprises a title of the source (e.g., book or periodical), author, publisher, publication date, etc. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> Once the content <highlight><bold>104</bold></highlight>, source information <highlight><bold>106</bold></highlight>, and content location information <highlight><bold>108</bold></highlight> is located by the researcher, it is recorded by the researcher so that he or she can later refer to this information and use it to prepare the research document. Due to the disadvantages associated with conventional methods of recordation of this type of information, the information <highlight><bold>100</bold></highlight> is electronically captured according to the present system and method. This is preferably accomplished by scanning the information <highlight><bold>100</bold></highlight>. As for the content <highlight><bold>104</bold></highlight>, various passages contained within the source can be scanned with an appropriate scanning device and stored within the scanning device. As for the source information <highlight><bold>106</bold></highlight>, this information can be captured by scanning data code information, such as bar code information, provided on the source. For instance, where the source comprises a book, a bar code containing all bibliographic information can be provided on the binder of the book or title page. Alternatively, the bar code information can comprise look-up information with which the bibliographic information can later be retrieved for integration into the research document. Finally, the content location information <highlight><bold>108</bold></highlight> pertaining to each piece of located content <highlight><bold>104</bold></highlight> can be captured with the scanning device. For instance, the page numbers that identify the pages on which the located content <highlight><bold>104</bold></highlight> was found can be captured, if desired. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Once the various information <highlight><bold>100</bold></highlight> is captured as described above, various data processing can be performed on or with the information, as indicated in block <highlight><bold>110</bold></highlight>. This processing can comprise character recognition <highlight><bold>112</bold></highlight>, information association <highlight><bold>114</bold></highlight>, information retrieval <highlight><bold>116</bold></highlight>, and data reconfiguration <highlight><bold>118</bold></highlight>. By way of example, character recognition <highlight><bold>108</bold></highlight> can comprise optical character recognition (OCR) of the captured content <highlight><bold>104</bold></highlight> and content location information <highlight><bold>108</bold></highlight> so that this information can later be directly imported in the research document, as desired. The information association <highlight><bold>112</bold></highlight> can comprise association of the content <highlight><bold>104</bold></highlight> with the source information <highlight><bold>106</bold></highlight> and content location information <highlight><bold>108</bold></highlight>. The information retrieval <highlight><bold>116</bold></highlight> can comprise retrieval of bibliographic information where the data code information comprises look-up information. Finally, data reconfiguration <highlight><bold>118</bold></highlight> can comprise reconfiguration of the captured and retrieved information for integration with a user application <highlight><bold>120</bold></highlight>. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Once the various data processing has been performed, the content <highlight><bold>104</bold></highlight>, bibliographic information and content location information <highlight><bold>108</bold></highlight> can be integrated into one or more user applications <highlight><bold>120</bold></highlight>. By way of example, the user application <highlight><bold>120</bold></highlight> can comprise a word processing application that the researcher uses to create the research document. In such a situation, the application <highlight><bold>120</bold></highlight> may exist and run on a separate computing device, for instance a personal computer (PC). Various options are available for this integration. For instance, the bibliographic information for one or more of the sources can be used to automatically create a bibliography for the document. In another example, content <highlight><bold>104</bold></highlight> can be imported directly into the body of the document in the form of a quotation and an acknowledgement automatically generated within the body of the document containing the relevant bibliographic information. Alternatively, such an acknowledgement for the imported content <highlight><bold>104</bold></highlight> can be automatically generated in the form of a footnote or endnote. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> As can be appreciated from the above description, a system and method that operate according to the above-described conceptualization greatly simplify the research and writing process for the researcher and would prevent transcription mistakes that can be made by the researcher when conventional research and writing techniques are used. The general concept of the invention having been described, an example system for capture and utilization of content and source information will be described with reference to FIGS. <highlight><bold>2</bold></highlight>-<highlight><bold>5</bold></highlight>. Although this system is provided by way of example, it will be appreciated that this system is described for purposes of illustration only and that various modifications are feasible without departing from the above-described inventive concept. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Referring now <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, illustrated is a system <highlight><bold>200</bold></highlight> for capture and utilization of content and source information. As indicated in this figure, the system <highlight><bold>200</bold></highlight> at least comprises a scanning device <highlight><bold>202</bold></highlight>. The scanning device <highlight><bold>202</bold></highlight> typically comprises a self-contained, portable scanning device that, for instance, can be carried by the researcher (i.e., user) to a location (e.g., library) at which various sources <highlight><bold>204</bold></highlight> (e.g., books) can be found. By way of example, the scanning device <highlight><bold>202</bold></highlight> can include a housing <highlight><bold>203</bold></highlight> that is similar in configuration to a pen or highlighter with which the user can scan across text contained within a source <highlight><bold>204</bold></highlight> (typically a single line at a time), and scan across one or more data codes <highlight><bold>206</bold></highlight> (e.g., bar codes) of the source to capture source information that comprises bibliographic information or look-up information used to retrieve the bibliographic information. As noted above, such a data code <highlight><bold>206</bold></highlight> can be provided on a binder of the source <highlight><bold>204</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 2</cross-reference>) or on a title page of the source. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> As is further indicated in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the system <highlight><bold>200</bold></highlight> can further include a computing device <highlight><bold>206</bold></highlight> with which the research document can be created and, as is described in greater detail below, the information captured by the scanning device <highlight><bold>202</bold></highlight> can be received. As indicated in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, this information can be, for example, wirelessly transmitted from the scanning device <highlight><bold>202</bold></highlight> to the computing device <highlight><bold>206</bold></highlight>. It will be appreciated, however, that this information can be transmitted through a direct electrical or optical connection, if desired. The computing device <highlight><bold>206</bold></highlight> can take many different forms. For instance, the computing device <highlight><bold>206</bold></highlight> can be configured as a desktop PC, laptop PC, or handheld computing device such as a tablet computing device, personal digital assistant (PDA), or mobile telephone. As will be appreciated by persons having ordinary skill in the art, the particular configuration of the computing device <highlight><bold>206</bold></highlight> is unimportant. The computing device <highlight><bold>206</bold></highlight> must merely be capable of receiving the information from the scanning device <highlight><bold>202</bold></highlight> such that it can be integrated into a research document or otherwise manipulated in some manner. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The computing device <highlight><bold>206</bold></highlight> can, optionally, be connected to a network <highlight><bold>208</bold></highlight> so that information contained within a remote computing device <highlight><bold>210</bold></highlight> can be accessed, if desired. The network <highlight><bold>208</bold></highlight> can comprise one or more sub-networks that are communicatively coupled to each other. By way of example, these networks can include one or more local area networks (LANs) and/or wide area networks (WANs). Typically, however, the network <highlight><bold>208</bold></highlight> comprises a set of networks that forms part of the Internet. As indicated in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the remote computing device <highlight><bold>210</bold></highlight> can comprise a network server. Although a network server is described and shown, it is to be appreciated that the server is provided as an example only and that this representation is not intended to limit the scope of the present disclosure. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a schematic view illustrating an example configuration for the scanning device <highlight><bold>202</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Although a particular configuration for the scanning device <highlight><bold>202</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> and described herein, it will be appreciated that alternative configurations are feasible and may even be preferable. Indeed, the scanning device <highlight><bold>202</bold></highlight> can comprise substantially any existing or yet to be produced portable scanning device. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> As indicated in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the scanning device <highlight><bold>202</bold></highlight> generally comprises a processing device <highlight><bold>300</bold></highlight> and scanning hardware <highlight><bold>302</bold></highlight>, one or more input/output devices <highlight><bold>304</bold></highlight>, memory <highlight><bold>306</bold></highlight>, a power supply <highlight><bold>308</bold></highlight>, and one or more user interface devices <highlight><bold>310</bold></highlight> that each are in electrical communication with the processing device. The processing device <highlight><bold>300</bold></highlight> is adapted to control operation of the other components of the scanning device <highlight><bold>202</bold></highlight> and execute commands stored in memory <highlight><bold>306</bold></highlight>. The processing device <highlight><bold>300</bold></highlight> can comprise a general-purpose processor, a microprocessor, one or more application-specific integrated circuits (ASICs), a plurality of suitably configured digital logic gates, and other well known electrical configurations that comprise discrete elements both individually and in various combinations to coordinate the overall operation of the scanning device <highlight><bold>202</bold></highlight>. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> The scanning hardware <highlight><bold>302</bold></highlight> comprises the various components used to capture and store image information such as content, source information, and content location information. As indicated in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the scanning hardware <highlight><bold>302</bold></highlight> normally comprises one or more scan heads <highlight><bold>312</bold></highlight> and one or more light sources <highlight><bold>314</bold></highlight>. As will be appreciated by persons having ordinary skill in the art, the scanning device <highlight><bold>202</bold></highlight> can comprise a single scan head <highlight><bold>312</bold></highlight> that is responsible for scanning (i.e., capturing) both text and data code information. In an alternative arrangement, the scanning device <highlight><bold>202</bold></highlight> can comprise two separate scan heads <highlight><bold>312</bold></highlight>, one provided at each end of the scanning device. In such an arrangement, one of the scan heads is used to capture text (for content) and the other scan head is used to read data codes (for source information). In any case, the scan heads <highlight><bold>312</bold></highlight> can comprise a photosensor such as a charge coupled device (CCD). </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> Where provided, the light sources <highlight><bold>314</bold></highlight> (e.g., one provided for each scan head <highlight><bold>312</bold></highlight>) can comprise a florescent, incandescent, or laser light source. Where the scanning device is used in environments in which enough ambient light exists, the light sources <highlight><bold>314</bold></highlight> may not be necessary. As is further identified in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the scanning hardware <highlight><bold>302</bold></highlight> typically further comprises an analog-digital (A/D) converter <highlight><bold>316</bold></highlight> that is used to convert the varying analog output of the scanning head(s) <highlight><bold>312</bold></highlight> into digital signals that can be manipulated by the scanning device <highlight><bold>202</bold></highlight> and/or the computing device <highlight><bold>206</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 2</cross-reference>). </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> In addition to the above-noted components, the scanning hardware may include other components that are not shown for purposes of simplicity. For instance, the scanning hardware <highlight><bold>302</bold></highlight> may further include a focusing mechanism comprising one or more lenses, mirrors, etc. Furthermore, the scanning hardware <highlight><bold>302</bold></highlight> may also include a position encoder that provides information as to position and velocity information about the scan head(s) <highlight><bold>312</bold></highlight>, and a compensation circuit for reducing image distortion which may occur during scanning. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> The input/output devices <highlight><bold>304</bold></highlight> can include a transceiver <highlight><bold>318</bold></highlight> and one or more communication ports <highlight><bold>320</bold></highlight> with which data can be transmitted to another device such as the computing device <highlight><bold>206</bold></highlight>. The transceiver <highlight><bold>318</bold></highlight> can be configured for wireless communication that is facilitated through infrared (IR) transmission, radio frequency (RF) transmission, microwave transmission, or substantially any other wireless communication scheme. In addition or in exception, the communication ports <highlight><bold>320</bold></highlight> can be used to directly link the scanning device <highlight><bold>202</bold></highlight> with the other device through an electrical or optical connection such that data can be transmitted to the other device and, optionally, received from the other device. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> The memory <highlight><bold>306</bold></highlight> can comprise a combination of volatile memory elements (e.g., random access memory (RAM, such as DRAM, SRAM, etc.)) and nonvolatile memory elements (e.g., ROM, hard drive, tape, CDROM, etc.) and is adapted to store various software (firmware) that comprises the various commands that, when executed by the processing device <highlight><bold>300</bold></highlight>, control operation of the scanning device <highlight><bold>202</bold></highlight>. The power supply <highlight><bold>308</bold></highlight> can comprise a portable power source that is integrated with the scanning device <highlight><bold>202</bold></highlight> such as a battery, or an external power supply that supplies the scanning device with direct current (DC) or alternating current (AC) power. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The one or more user interface devices <highlight><bold>310</bold></highlight> typically comprise interface tools with which scanning device settings can be changed and through which the user can communicate commands to the device <highlight><bold>202</bold></highlight>. By way of example, the user interface devices <highlight><bold>206</bold></highlight> can comprise one or more function keys <highlight><bold>322</bold></highlight> with which the operation of the scanning device <highlight><bold>202</bold></highlight> can be controlled and, optionally, a display <highlight><bold>324</bold></highlight> that is adapted to communicate graphical information to the user (e.g., a liquid crystal display (LCD)). </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> schematically illustrates an example configuration of scanning device memory <highlight><bold>306</bold></highlight> identified in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. To facilitate the description of the various software (firmware) disposed within memory <highlight><bold>306</bold></highlight>, various software modules (e.g., programs) are depicted. Although separate modules are shown and described herein, persons having ordinary skill in the art will appreciate that these modules are provided as an example only in attempt to explain operation of the scanning device <highlight><bold>202</bold></highlight>. Therefore, although specific modules are identified, one or more of these modules could be combined or divided as is deemed prudent. Furthermore, functions described herein as being performed by a particular module could be performed by other modules, as the software designer sees fit. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> As indicated in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, memory <highlight><bold>306</bold></highlight> can, for example, comprise an operating system <highlight><bold>400</bold></highlight> and an information capture module <highlight><bold>402</bold></highlight>. The operating system <highlight><bold>400</bold></highlight> contains the various commands used to control the general operation of the scanning device <highlight><bold>202</bold></highlight> as well as the various software modules of memory <highlight><bold>306</bold></highlight>. The information capture module <highlight><bold>402</bold></highlight> comprises software that is adapted to, in conjunction with the scanning hardware <highlight><bold>302</bold></highlight>, capture information that can be, at least temporarily, stored by the scanning device <highlight><bold>202</bold></highlight> in data storage <highlight><bold>408</bold></highlight> and/or transmitted to another device (e.g., computing device <highlight><bold>206</bold></highlight>) for further manipulation. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Further identified in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is an information association module <highlight><bold>404</bold></highlight> that, as is described in greater detail below, is adapted to associate various captured information (e.g., content) with other captured information (e.g., source information and content location information) so that the relationship between the various pieces of captured information can be tracked as data is manipulated in some manner (e.g., integrated into a user application). Finally, memory <highlight><bold>306</bold></highlight> can further comprise an optical character recognition (OCR) module <highlight><bold>406</bold></highlight> that is adapted to recognize raw text data and reconfigure the data into a format in which it can be imported into another application (e.g., word processing application) as text. Where the captured information is to be shared with another device, such as the computing device <highlight><bold>206</bold></highlight> provided with its own OCR module, the module <highlight><bold>406</bold></highlight> need not be provided to free up memory for other data and reduce the work for the processing device <highlight><bold>300</bold></highlight>. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a schematic view illustrating an example architecture for the computing device <highlight><bold>206</bold></highlight> that can be used to receive captured information transmitted from the scanning device <highlight><bold>202</bold></highlight> and, if desired, can be used to integrate the information into a user application such as a word processing application. As indicated in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the computing device <highlight><bold>206</bold></highlight> can comprise a processing device <highlight><bold>500</bold></highlight>, memory <highlight><bold>502</bold></highlight>, one or more user interface devices <highlight><bold>504</bold></highlight>, one or more communication devices <highlight><bold>506</bold></highlight>, and a local interface <highlight><bold>508</bold></highlight> to which each of the other components electrically connects. The local interface <highlight><bold>508</bold></highlight> may have additional elements, which are omitted for simplicity, such as controllers, buffers (caches), drivers, repeaters, and receivers to enable communications. Furthermore, the local interface <highlight><bold>508</bold></highlight> may include address, control, and/or data connections to enable appropriate communications among the aforementioned components. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The processing device <highlight><bold>500</bold></highlight> can include any custom made or commercially available processor, a central processing unit (CPU) or an auxiliary processor among several processors associated with the computing device <highlight><bold>206</bold></highlight>, a semiconductor based microprocessor (in the form of a microchip), or a macroprocessor. The memory <highlight><bold>502</bold></highlight>, like memory <highlight><bold>306</bold></highlight>, can include any one of a combination of volatile memory elements (e.g., random access memory (RAM, such as DRAM, SRAM, etc.)) and nonvolatile memory elements (e.g., ROM, hard drive, tape, CDROM, etc.). </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The user interface devices <highlight><bold>504</bold></highlight> typically comprise those normally used in conjunction with a computing device. For instance, the user interface devices <highlight><bold>504</bold></highlight> can comprise a keyboard, mouse, monitor or display screen, etc. The one or more communication devices <highlight><bold>506</bold></highlight> comprise the hardware with which the computing device <highlight><bold>206</bold></highlight> can interface with the scanning device <highlight><bold>202</bold></highlight>. By way of example, the communication devices <highlight><bold>506</bold></highlight> include a transceiver that is adapted to wirelessly transmit data to and wirelessly receive data from the scanning device <highlight><bold>202</bold></highlight>. In addition, the communication devices <highlight><bold>506</bold></highlight> can include a device used to connect with the network <highlight><bold>208</bold></highlight>, such as a modem. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The memory <highlight><bold>502</bold></highlight> comprises various software programs including an operating system <highlight><bold>510</bold></highlight>, a user application <highlight><bold>512</bold></highlight>, and an information manager <highlight><bold>514</bold></highlight>. The operating system <highlight><bold>510</bold></highlight> controls the execution of other software and provides scheduling, input-output control, file and data management, memory management, and communication control and related services. The user application <highlight><bold>512</bold></highlight> can comprise substantially any application in which the information received from the scanning device <highlight><bold>202</bold></highlight> can be used. For example, the user application <highlight><bold>512</bold></highlight> can comprise a word processing application such as Microsoft Word&trade; or WordPerfect&trade;. As is discussed in greater detail below, the information manager <highlight><bold>514</bold></highlight> is adapted to receive data transmitted from the scanning device <highlight><bold>202</bold></highlight> and integrate it into the user application <highlight><bold>512</bold></highlight>. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> The information manager <highlight><bold>514</bold></highlight> can include its own OCR module <highlight><bold>516</bold></highlight>, information retrieval module <highlight><bold>518</bold></highlight>, and a bibliographic database <highlight><bold>520</bold></highlight>. Where provided, the OCR module <highlight><bold>516</bold></highlight> can receive raw captured data from the scanning device <highlight><bold>202</bold></highlight> and perform a character recognition on the data such that text represented by the data can be imported into the user application <highlight><bold>512</bold></highlight> as text. The information retrieval module <highlight><bold>518</bold></highlight> is adapted to retrieve bibliographic information with reference to source information transmitted by the scanning device <highlight><bold>202</bold></highlight>. As described below, this bibliographic information can be retrieved from the remote computing device <highlight><bold>210</bold></highlight> via the network <highlight><bold>208</bold></highlight>. Alternatively, this information can be retrieved directly from the local bibliographic database <highlight><bold>520</bold></highlight> if this information is contained in the database. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> The remote computing device <highlight><bold>210</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 2</cross-reference>) can be configured in similar manner to the computing device <highlight><bold>206</bold></highlight>. Accordingly, a detailed description of the remote computing device <highlight><bold>210</bold></highlight> is not provided here. However, it suffices to say that the remote computing device <highlight><bold>210</bold></highlight> typically comprises memory in which a further database is stored that contains bibliographic information which can be accessed by the computing device <highlight><bold>206</bold></highlight> when needed. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Various software and/or firmware programs have been described herein. It is to be understood that these programs can be stored on any computer readable medium for use by or in connection with any computer related system or method. In the context of this document, a computer readable medium is an electronic, magnetic, optical, or other physical device or means that can contain or store a computer program for use by or in connection with a computer related system or method. These programs can be embodied in any computer-readable medium for use by or in connection with an instruction execution system, apparatus, or device, such as a computer-based system, processor-containing system, or other system that can fetch the instructions from the instruction execution system, apparatus, or device and execute the instructions. In the context of this document, a &ldquo;computer-readable medium&rdquo; can be any means that can store, communicate, propagate, or transport the program for use by or in connection with the instruction execution system, apparatus, or device. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> The computer readable medium can be, for example but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, device, or propagation medium. More specific examples (a nonexhaustive list) of the computer-readable medium include an electrical connection having one or more wires, a portable computer diskette, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM, EEPROM, or Flash memory), an optical fiber, and a portable compact disc read-only memory (CDROM). Note that the computer-readable medium can even be paper or another suitable medium upon which a program is printed, as the program can be electronically captured, via for instance optical scanning of the paper or other medium, then compiled, interpreted or otherwise processed in a suitable manner if necessary, and then stored in a computer memory. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> An example system <highlight><bold>200</bold></highlight> having been described above, operation of the system will now be discussed. In the discussion that follows, flow diagrams are provided. It is to be understood that any process descriptions contained in blocks of these flow diagrams represent modules, segments, or portions of code which include one or more executable instructions for implementing specific logical functions or steps of the inventive method, and that alternative implementations are feasible. Moreover, functions may be executed out of order from that shown or discussed, including substantially concurrently or in reverse order, depending on the functionality involved. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 6A and 6B</cross-reference> illustrate an example of operation of the scanning device <highlight><bold>202</bold></highlight> in capturing information located during research that can be used in some manner, for instance in creating a document. Beginning with block <highlight><bold>600</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 6</cross-reference>A, the scanning device <highlight><bold>202</bold></highlight> is enabled. This enablement can comprise the powering of the device through selection of a power button provided on the device <highlight><bold>202</bold></highlight> or other function key. Once the scanning device <highlight><bold>202</bold></highlight> is enabled, it can receive a capture source information command, as indicated in block <highlight><bold>602</bold></highlight>, entered with one or more of the function keys of the user interface devices <highlight><bold>310</bold></highlight>. Receipt of such a command indicates to the scanning device <highlight><bold>202</bold></highlight> that source information will be captured with the scan head <highlight><bold>312</bold></highlight> of the device. The source information typically is obtained from data code information that is provided on or in the source (e.g., book). The source information may comprise bibliographic information for the source such as a title, author, publisher, and publication date. Alternatively, the source information can comprise information that identifies where such bibliographic information can be found such that it may later be retrieved. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> The scan head <highlight><bold>312</bold></highlight> scans the source information, as indicated in block <highlight><bold>604</bold></highlight>, and, as indicated in block <highlight><bold>606</bold></highlight>, the source information is stored in memory <highlight><bold>306</bold></highlight>. As indicated above, the scanning device <highlight><bold>202</bold></highlight> can comprise a single scan head or separate text data code scan heads. Where two separate scan heads are provided, the scanning is conducted with the data code scan head. At this point, the scanning device <highlight><bold>202</bold></highlight> is then prepared to capture content contained within the source. Therefore, the scan head <highlight><bold>312</bold></highlight> then scans the content, as indicated in block <highlight><bold>608</bold></highlight>. Where two scan heads <highlight><bold>312</bold></highlight> are provided, this content capture can be accomplished with the text scan head. As with the captured source information, the captured content is stored in memory <highlight><bold>306</bold></highlight>, as identified in block <highlight><bold>610</bold></highlight>. Once the desired amount (e.g., a particular passage) of content has been captured and stored in this manner, content location information, for instance one or more page numbers on which the content was found, can further be captured and stored, if desired. To accomplish this, the scanning device <highlight><bold>202</bold></highlight> can switch capture modes, as indicated in block <highlight><bold>612</bold></highlight>, for example in response to a location information capture command received from the user. This way, the scanning device <highlight><bold>202</bold></highlight> will know that this information is to be used in creating the acknowledgment of the source when a document is later created. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> At this point, the scan head scans the content location information, as indicated in block <highlight><bold>614</bold></highlight>, and the information is stored, as identified in block <highlight><bold>616</bold></highlight>. Where the captured content begins on one page and continues onto another, the content location information can comprise a first page number and a second page number. In such a situation, the capture process may comprise first capturing the first page number, receiving an indication that the first page number has been captured, and then capturing the second page number. Alternatively, the scanning device <highlight><bold>202</bold></highlight> can be configured to automatically recognize when two separate page numbers have been captured. Although the content location information is described as being provided as text, it is to be appreciated that other indicia, such as further data code information, can be used to identify the location of the content, if desired. Furthermore, although the content location information is described as being captured after the content is captured, it will be appreciated by persons having ordinary skill in the art that these steps could be reversed, if desired. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Once the source information, content, and content location information have been captured in the manner described above, flow continues to block <highlight><bold>618</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> at which this information is linked such that the captured content is associated with a particular source as well as a particular content location (where applicable). This may comprise, for instance, the use of metadata tags applied to the various pieces of information. At this point, it can be determined whether OCR is to be performed on content and content location information, as identified in decision element <highlight><bold>620</bold></highlight>. As identified above, performance of OCR with the scanning device <highlight><bold>202</bold></highlight> may not be necessary where the computing device <highlight><bold>206</bold></highlight> has this capability. Where OCR is not to be performed, flow can continue down to decision element <highlight><bold>624</bold></highlight> described below. If OCR is to be performed, however, flow continues to block <highlight><bold>622</bold></highlight> at which the OCR module <highlight><bold>406</bold></highlight> processes the captured content and content location information to identify characters. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Referring now to decision element <highlight><bold>624</bold></highlight>, it can be determined whether more content, and its attendant content location information, is to be captured from the source. If so, flow returns to block <highlight><bold>608</bold></highlight> at which the scan head <highlight><bold>312</bold></highlight> scans the content as described above. If no further content is to be captured from the source, however, flow continues to decision element <highlight><bold>626</bold></highlight> at which it is determined whether content is to be captured from a different source. If not, flow continues to decision element <highlight><bold>628</bold></highlight> described below. If content from another source is to be captured, however, flow continues back to block <highlight><bold>602</bold></highlight> at which a capture source information command is again received. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> With reference now to decision element <highlight><bold>628</bold></highlight>, it can be determined whether the captured information is to be transmitted to another device such as the computing device <highlight><bold>206</bold></highlight>. By way of example, the transmission can occur immediately after the research is completed, for instance, where the user has brought a portable computing device (e.g., laptop PC) to the research location, or later where the user intends to transmit the information to a stationary computing device (e.g., desktop PC). If the information is to be transmitted, flow continues to block <highlight><bold>630</bold></highlight> at which the information is transmitted via the input/output devices <highlight><bold>304</bold></highlight>. If, on the other hand, the information is not to be transmitted at this time, the session is over and flow is terminated. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Reference is now made to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, which illustrates an example of operation of the information manager <highlight><bold>514</bold></highlight> of the computing device <highlight><bold>206</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. As indicated in block <highlight><bold>700</bold></highlight>, the data transmitted from the scanning device <highlight><bold>202</bold></highlight> is received. At this point, it can be determined whether OCR must be performed on the content and content location information that was captured in the research session, as indicated in decision element <highlight><bold>702</bold></highlight>. This determination can be made through analysis of the received data to determine whether OCR has already been performed and/or whether the content and content location information comprises raw data. If OCR is not required, flow continues to decision element <highlight><bold>706</bold></highlight> described below. If OCR is required, however, it is performed on the raw data, as indicated in block <highlight><bold>704</bold></highlight>. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> With reference to decision element <highlight><bold>706</bold></highlight>, it is determined whether the bibliographic information must be retrieved. Such retrieval is necessary where the source information only comprised an identification of where bibliographic information is stored versus the bibliographic information itself. The identification can comprise, for instance, information used to look-up the bibliographic information in the bibliographic database <highlight><bold>520</bold></highlight> or an address (e.g., universal resource locator (URL)) that identifies where the bibliographic information is stored out on the network <highlight><bold>208</bold></highlight>. If the source information comprises the bibliographic information, flow continues down to block <highlight><bold>710</bold></highlight> described below. If this information must be retrieved, however, flow continues to block <highlight><bold>708</bold></highlight> at which the bibliographic information is retrieved from the local database <highlight><bold>520</bold></highlight> or from a database of a remote device such as the remote computing device <highlight><bold>210</bold></highlight>. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> With reference to block <highlight><bold>710</bold></highlight>, the captured information (and retrieved bibliographic information where applicable) can then be reconfigured for integration into a user application such as a word processing application. This reconfiguration can take many different forms depending upon the user&apos;s wishes. For instance, the user can be provided with the choice of having the information manager <highlight><bold>514</bold></highlight> automatically create a bibliography for a document he or she is creating with the captured (and retrieved) information. In another example, the user can have the information manager <highlight><bold>514</bold></highlight> automatically generate footnotes or endnotes as specific pieces of content are imported into the document by the user. By way of example, these choices can be communicated by the user with a separate application itself associated with the information manager <highlight><bold>514</bold></highlight> or can be communicated with the user application itself where the application is configured to receive such choices. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> At this point, the content can be integrated into the user application, as indicated in block <highlight><bold>712</bold></highlight>. This integration can result from, for instance, selection by the user of one or more content portions for importation into the document. In such a scenario, the information manager <highlight><bold>514</bold></highlight> can, at the choice of the user, automatically generate an appropriate acknowledgement of the source in the form of a notation in the bibliography, footnote, and/or endnote. Such importation can continue in this manner until all captured content that the user wishes to use has been added to the document. At this point, flow for the information manager <highlight><bold>514</bold></highlight> is terminated. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> From the above, it can be appreciated that research and document creation can be greatly simplified with a system for content and source information capture and integration such as that described above. While particular embodiments of the invention have been disclosed in detail in the foregoing description and drawings for purposes of example, it will be understood by those skilled in the art that variations and modifications thereof can be made without departing from the scope of the invention as set forth in the following claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method for collecting information when conducting research, comprising the steps of: 
<claim-text>electronically capturing content; </claim-text>
<claim-text>electronically capturing source information pertinent to the source of the captured content; </claim-text>
<claim-text>associating the content and the source information; and </claim-text>
<claim-text>transmitting the content and source information to a device for manipulation. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the step of electronically capturing the content and source information comprises capturing the content and source information with a common scan head of a scanning device. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the step of electronically capturing the content and source information comprises capturing the content and source information with separate text and data code scan heads, respectively, of a scanning device. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the step of electronically capturing source information comprises scanning a bar code of the source. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the source information comprises bibliographic information pertinent to the source. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the source information comprises information that can be used to retrieve bibliographic information pertinent to the source. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising the step of capturing content location information that identifies where the content was found in the source. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the content location information comprises one or more page numbers. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising the step of performing optical character recognition on the content. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A device for recording information when conducting research, comprising: 
<claim-text>means for electronically capturing content; </claim-text>
<claim-text>means for electronically capturing source information pertinent to the source of the captured content; </claim-text>
<claim-text>means for associating the content and the source information; and </claim-text>
<claim-text>means for transmitting the content and source information to a device for manipulation. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A method for using captured information, comprising the steps of: 
<claim-text>receiving content and associated source information pertinent to the source of the content in electronic form; </claim-text>
<claim-text>reconfiguring the content and associated source information for use in a user application; and </claim-text>
<claim-text>automatically creating at least one source acknowledgement in the user application. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the step of receiving the content and associated source information comprises receiving the content and associated source information with a handheld scanning device. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the at least one source acknowledgement includes a bibliography. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the at least one source acknowledgement includes a footnote. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the at least one source acknowledgement includes an endnote. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, further comprising the step of receiving content location information pertinent to the location of the content within the source. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, further comprising the step of retrieving bibliographic information pertinent to the source using the source information. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, further comprising conducting optical character recognition on the content. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A system for using captured information, comprising: 
<claim-text>means for receiving content and associated source information pertinent to the source of the content in electronic form; </claim-text>
<claim-text>means for reconfiguring the content and associated source information for use in a user application; and </claim-text>
<claim-text>means for automatically creating at least one source acknowledgement in the user application. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A handheld scanning device, comprising: 
<claim-text>a housing configured as a pen; </claim-text>
<claim-text>a scan head that is adapted to capture information from a source; and </claim-text>
<claim-text>memory including an information association module that is configured to associate captured content with captured source information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the device comprises two separate scan heads, one provided at each end of the device, one of the scan heads being adapted to capture text and the other scan head being adapted to capture data code information. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, further comprising a transceiver that is adapted to transmit captured information to another device for manipulation. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, further comprising an optical character recognition module stored in memory. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The device of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the scan head comprises a charge-coupled device (CCD).</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>3</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002086A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002086A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002086A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002086A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002086A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002086A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002086A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002086A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002086A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
