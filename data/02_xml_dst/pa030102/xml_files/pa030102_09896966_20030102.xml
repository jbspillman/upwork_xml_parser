<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001881A1-20030102-D00000.TIF SYSTEM "US20030001881A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001881A1-20030102-D00001.TIF SYSTEM "US20030001881A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001881A1-20030102-D00002.TIF SYSTEM "US20030001881A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001881A1-20030102-D00003.TIF SYSTEM "US20030001881A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001881A1-20030102-D00004.TIF SYSTEM "US20030001881A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001881A1-20030102-D00005.TIF SYSTEM "US20030001881A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001881A1-20030102-D00006.TIF SYSTEM "US20030001881A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001881A1-20030102-D00007.TIF SYSTEM "US20030001881A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001881A1-20030102-D00008.TIF SYSTEM "US20030001881A1-20030102-D00008.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001881</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09896966</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010629</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G09G005/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>345</class>
<subclass>728000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method and system for providing an acoustic interface</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Steve</given-name>
<family-name>Mannheimer</family-name>
</name>
<residence>
<residence-us>
<city>Carmel</city>
<state>IN</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Barry</given-name>
<middle-name>Jay</middle-name>
<family-name>Weber</family-name>
</name>
<residence>
<residence-us>
<city>Carmel</city>
<state>IN</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Kerry</given-name>
<middle-name>Wayne</middle-name>
<family-name>Calvert</family-name>
</name>
<residence>
<residence-us>
<city>Indianapolis</city>
<state>IN</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Jonathan</given-name>
<middle-name>Paul</middle-name>
<family-name>Griffin</family-name>
</name>
<residence>
<residence-us>
<city>Greenfield</city>
<state>IN</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>JOSEPH S. TRIPOLI</name-1>
<name-2>PATENT OPERATIONS</name-2>
<address>
<address-1>THOMSON MULTIMEDIA LICENSING INC.</address-1>
<address-2>P.O. BOX 5312</address-2>
<city>PRINCETON</city>
<state>NJ</state>
<postalcode>08543-5312</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The present invention is directed towards a system and process for navigating through a large amount of information (e.g., audio files, text files, video files, device functions, etc.) using audio cues representative of the information. The audio cues are arranged in a multi-level tree data structure such that the user can select general categories (e.g., music classification) and navigate down to a specific data segment (e.g., a particular song or song list). Each audio cue is a brief burst of sound (e.g., a lyric from a particular song) representative of a predetermined number of additional audio cues or a particular data segment. The audio cues are selectable by a user and permit the user to navigate through the information or data segments without having to remember visual or alphanumeric elements (e.g., song title, artist name, or track number). The audio cues are stored in a storage device that can be accessed using a wireless device (e.g., a remote control or wireless mouse) or a wired device (e.g., keyboard, trackball, or touch pad). By manipulating the wireless or wired device, the user can navigate through the multi-level tree data structure of audio cues (generated by speakers) until a desired data segment is found. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present invention relates to user interfaces for information systems. More particularly, the invention relates to the use of an acoustic interface to assist in navigation and manipulation of data segments. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> A graphical user interface is often used to facilitate a user&apos;s ability to navigate through large amounts of data. For example, if a user has downloaded a large number of MP3 audio files onto a hard drive of a personal computer, it may be cumbersome for the user to find a desired file by searching through a displayed list of stored MP3 audio files. To facilitate the search process the user may use a graphical user interface that enables the user to store the audio files in various user-defined folders. Thus the user may store related audio files in predetermined folders in a predetermined order. For example, the user may identify all of the audio files that relate to country music and store the country music audio files in a &ldquo;Country Music&rdquo; folder. Furthermore, the user may generate sub-folders within the &ldquo;Country Music&rdquo; folder that further sort the country music by artist, album title, and/or song name. Afterwards, the user can quickly sort through a large amount of MP3 audio files to locate a particular audio file associated with a music genre, artist, album, and/or song. Although graphical user interfaces facilitate a user&apos;s ability to locate desired audio files, the graphical user interfaces suffer form a number of drawbacks. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> One such drawback is that graphical user interfaces relies on a user&apos;s ability to remember a visual or alphanumeric element associated with an audio file. In the case of music, a user typically must remember the genre, artist, album, and/or title of a desired vocal or instrumental. However, the user may only remember a few words of a song or a few notes of a tune. If this is the case, the user must guess as to which visual element represents the desired song until the desired song is located. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Another drawback is that the user may be in an environment where a graphical user interface is not provided or, even if provided, is not convenient to use. For example, many automobiles come equipped with a multi-CD storage device that enables a driver to play a plurality of compact disks. Sometimes these multi-CD storage devices have primitive graphical user interfaces that only display the number of compact disks in the storage device and the number of tracks on a given compact disk. As a result, if the driver has not memorized the numerical identification of each compact disk in the storage device and the track number of every song on every compact disk, the driver must blindly search through the tracks of the compact disks until the desired audio content is located. If a more advanced graphical user interface is provided, the driver must still remember a visual element (e.g., album, artist, and/or title) associated with a desired song. Moreover, even if the driver has memorized which visual element is associated with a desired song, the driver may not be able to safely remove his or her focus from the surrounding driving conditions to locate the visual element displayed on the graphical user interface. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> The present invention is directed to overcoming these drawbacks. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Briefly stated, the present invention is directed towards a system and process for navigating through a large amount of information (e.g., audio files, text files, video files, device functions, etc.) using audio cues representative of the information. The audio cues are arranged in a multi-level tree data structure such that the user can select general categories (e.g., music classification) and navigate down to a specific data segment (e.g., a particular song or song list). Each audio cue is a brief burst of sound (e.g., a lyric from a particular song) representative of a predetermined number of additional audio cues or a particular data segment. The audio cues are selectable by a user and permit the user to navigate through the information or data segments without having to remember visual or alphanumeric elements (e.g., song title, artist name, or track number). The audio cues are stored in a storage device that can be accessed using a wireless device (e.g., a remote control or wireless mouse) or a wired device (e.g., keyboard, trackball, or touch pad). By manipulating the wireless or wired device, the user can navigate through the multi-level tree data structure of audio cues (generated by speakers) until a desired data segment is found. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> A feature of the present invention includes a method of providing access to a plurality of data segments. The method includes storing a plurality of audio cues in a memory, each audio cue representing a predetermined number of stored audio cues or a data segment, providing access to a first predetermined number of stored audio cues, playing one of the first predetermined number of stored audio cues in response to a first user request, and retrieving one of a data segment or a second predetermined number of stored audio cues in response to a second user request. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Another feature of the present invention includes a user interface system. The user interface system includes a data segment interface communicatively connected to a source of data segments, a computer readable medium interface communicatively connected to a computer readable medium having a plurality of audio cues stored thereon, each audio cue being associated with a data segment, a device for transmitting a request in response to a user input, an audio interface communicatively connected to an audio system, and a processor for retrieving an audio cue from the computer readable medium and playing the retrieved audio cue on the audio system in response to a received request. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> A further feature of the present invention includes a multi-level data tree structure of audio cues stored in a computer readable medium. Each level containing a predetermined number of audio cues. Each audio cue of a given level being linked to another level in the multi-level data tree structure or to a data segment.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> In the drawings: </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram of an exemplary computer system configured to support the acoustic interface of the present invention; </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram illustrating the movement of a remote control of the system of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> along a virtual arc of the acoustic interface of the present invention; </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is an exemplary multi-level tree data structure for the audio cues of the acoustic interface of the present invention; </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is another exemplary multi-level tree data structure for the audio cues of the acoustic interface of the present invention; </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 5 and 6</cross-reference> are flowcharts illustrating a process of navigating through audio information using the acoustical interface of the present invention; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is an exemplary graphical user interface for managing the acoustical interface of the present invention; and </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a further exemplary multi-level tree data structure for the audio cues of the acoustic interface of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT </heading>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The characteristics and advantages of the present invention will become more apparent from the following description, given by way of example. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, some of the elements of a computer system <highlight><bold>10</bold></highlight> configured to support the invention are shown. Computer system <highlight><bold>10</bold></highlight> includes a processor <highlight><bold>12</bold></highlight> having a central processing unit (&ldquo;CPU&rdquo;) <highlight><bold>14</bold></highlight>, a memory section <highlight><bold>16</bold></highlight>, and an Input/Output (&ldquo;I/O&rdquo;) section <highlight><bold>18</bold></highlight>. Memory section <highlight><bold>16</bold></highlight> may be volatile or non-volatile and may include a removable flash card memory. The I/O section <highlight><bold>18</bold></highlight> is connected to an answering machine <highlight><bold>20</bold></highlight>, a display unit <highlight><bold>22</bold></highlight>, a keyboard <highlight><bold>24</bold></highlight>, a speaker system <highlight><bold>26</bold></highlight>, a compact disk (&ldquo;CD&rdquo;) unit <highlight><bold>28</bold></highlight> that can read data from a CD-ROM medium and preferably includes a CD storage unit for storage of a plurality of CDs, and a database <highlight><bold>30</bold></highlight> for storing files such as audio files read from a CD or downloaded from the internet. Processor <highlight><bold>12</bold></highlight> has a network interface <highlight><bold>32</bold></highlight> that enables computer system <highlight><bold>12</bold></highlight> to communicate over the internet <highlight><bold>34</bold></highlight> such that computer system <highlight><bold>12</bold></highlight> can retrieve audio files in a plurality of formats (e.g., MP3, MIDI, etc.) from remote databases. Network interface <highlight><bold>32</bold></highlight> also enables computer system <highlight><bold>12</bold></highlight> to receive audio content from internet radio sources. Processor <highlight><bold>12</bold></highlight> includes an RF receiver interface <highlight><bold>36</bold></highlight> that enables computer system <highlight><bold>10</bold></highlight> to receive signals from a remote control and/or pointing device <highlight><bold>40</bold></highlight> via a pair of RF receivers <highlight><bold>38</bold></highlight> in accordance with the present invention, as discussed in further detail below. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> One skilled in the art will understand that the invention described herein does not depend on the existence of all of the units of computer system <highlight><bold>10</bold></highlight> and may include additional sources of audio data. For example, the invention does not require a network interface connecting the computer system <highlight><bold>10</bold></highlight> to the internet since the audio data to be played to a user often resides in the memory of the computer accessing the information. Furthermore, one skilled in the art will understand that processor <highlight><bold>12</bold></highlight> may reside in one of a plurality of electronic devices such as a desk-top computer, a lap-top computer, a stereo system, a home entertainment center, an automobile music system, or a household device. As such, the acoustic interface of the present invention is not restricted to facilitating a user&apos;s navigation through audio data segments. The acoustic interface may also facilitate the user&apos;s manipulation of other data segments such as text and video files as well as the user&apos;s ability to remotely control various electronic devices. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the communication between pointing device <highlight><bold>40</bold></highlight> and RF receivers <highlight><bold>38</bold></highlight> as pointing device <highlight><bold>40</bold></highlight> travels along an acoustic interface virtual arc <highlight><bold>50</bold></highlight> is shown. As shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, pointing device <highlight><bold>40</bold></highlight> includes a pair of RF transmitters <highlight><bold>42</bold></highlight> and <highlight><bold>44</bold></highlight> on either end thereof. As pointing device <highlight><bold>40</bold></highlight> is moved along virtual arc <highlight><bold>50</bold></highlight> transmitters <highlight><bold>42</bold></highlight> and <highlight><bold>44</bold></highlight> generate RF signals <highlight><bold>46</bold></highlight> and <highlight><bold>48</bold></highlight>, respectively. RF receivers <highlight><bold>38</bold></highlight> receive these signals and, together with RF receiver interface <highlight><bold>36</bold></highlight> and CPU <highlight><bold>14</bold></highlight> (shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>), process the signals to determine the position of pointing device <highlight><bold>40</bold></highlight> along virtual arc <highlight><bold>50</bold></highlight>, as known by those skilled in the art. Alternatively, pointing device <highlight><bold>40</bold></highlight> may include four RF sensors that detect a single-source signal (i.e., a signal transmitted from a transmitter of computer system <highlight><bold>10</bold></highlight>) and a CPU that process the input from the sensors to determine the positioning of pointing device <highlight><bold>40</bold></highlight> along virtual arc <highlight><bold>50</bold></highlight>. The positioning data may then be transmitted back to computer system <highlight><bold>10</bold></highlight> such that computer system <highlight><bold>10</bold></highlight> can track the positioning of pointing device <highlight><bold>40</bold></highlight> along virtual arc <highlight><bold>50</bold></highlight>. Although pointing device <highlight><bold>40</bold></highlight> is illustrated as the preferred remote control, use of a conventional remote control having directional arrows, a track ball, or the like, is considered within the scope of the present invention. It should be noted that if a conventional remote control is used, the user would merely manipulate the directional buttons or track ball in a horizontal or vertical manner to navigate along a virtual configuration such as a virtual grid or matrix. It should also be noted that the use of wired controls (e.g., control pads, touch pads, joysticks, trackballs and the like) are considered within the scope of the present invention. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> Pointing device <highlight><bold>40</bold></highlight> preferably includes a plurality of functional buttons, toggles, thumb wheels and the like. Some exemplary buttons are a &ldquo;select&rdquo; button permitting the user to select a given virtual arc point <highlight><bold>52</bold></highlight>-<highlight><bold>60</bold></highlight> on virtual arc <highlight><bold>50</bold></highlight>, &ldquo;navigation&rdquo; buttons allowing a user to go up or down through the audio cue levels in an audio cue tree (shown in <cross-reference target="DRAWINGS">FIGS. 3 and 4</cross-reference>), a thumbed wheel to adjust volume, a &ldquo;pause&rdquo; button, a &ldquo;fast-forward&rdquo; button, a &ldquo;rewind&rdquo; button, a &ldquo;skip&rdquo; button, and a &ldquo;power&rdquo; button. The use of other buttons for additional conventional audio controls is considered within the scope of the present invention. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Virtual arc <highlight><bold>50</bold></highlight> includes a plurality of points <highlight><bold>52</bold></highlight>-<highlight><bold>60</bold></highlight> corresponding to audio cues stored in a memory of computer system <highlight><bold>10</bold></highlight>. The audio cues are arranged in a multi-level tree data structure such that the user can select general categories (e.g., music classification) and navigate down to a specific segment of audio information (e.g., a particular song or song list), as discussed in further detail below. Virtual arc <highlight><bold>50</bold></highlight> roughly corresponds to the natural sweep of the user&apos;s arm moving as if shining a flashlight in an arc of roughly 90-120 degrees centered on a virtual point <highlight><bold>56</bold></highlight> directly in front of the user. When processor <highlight><bold>12</bold></highlight> determines that pointing device <highlight><bold>40</bold></highlight> is in the vicinity of one of the points <highlight><bold>52</bold></highlight>-<highlight><bold>56</bold></highlight> of virtual arc <highlight><bold>50</bold></highlight>, processor <highlight><bold>12</bold></highlight> retrieves an audio cue stored in a storage device (e.g., memory <highlight><bold>16</bold></highlight>, database <highlight><bold>30</bold></highlight>, or a remote database accessed over Internet <highlight><bold>34</bold></highlight>) and processes the audio cue such that speakers <highlight><bold>26</bold></highlight> generate the audio cue. The audio cue is preferably a brief (2-5 seconds) burst of sound representative of the audio content assigned to a given point <highlight><bold>52</bold></highlight>-<highlight><bold>56</bold></highlight> on virtual arc <highlight><bold>50</bold></highlight>. The audio cues may be selected by a user or provided by the supplier of the audio content, as discussed in further detail below. One exemplary audio cue is a snippet of a favorite music (e.g., the four opening notes of Beethoven&apos;s 5<highlight><superscript>th </superscript></highlight>Symphony) to serve as the identifier for a music category (e.g., classical music), song (Beethoven&apos;s 5<highlight><superscript>th </superscript></highlight>Symphony), song list (a compilation of Beethoven&apos;s symphonies), or artist (Beethoven). Another exemplary audio cue may be a computer-generated voice indicating music category, song, or artist. A further exemplary audio cue may be a stored version of the user&apos;s own voice describing a music category, song, or artist. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Processor <highlight><bold>12</bold></highlight> may raise or lower the sound of an audio snippet being generated by speakers <highlight><bold>26</bold></highlight> as pointing device <highlight><bold>40</bold></highlight> approaches or departs from a given point <highlight><bold>52</bold></highlight>-<highlight><bold>60</bold></highlight> on virtual arc <highlight><bold>50</bold></highlight>. Processor <highlight><bold>12</bold></highlight> also preferably provides audio feedback (e.g., an electronic beep or tone) via speakers <highlight><bold>26</bold></highlight> when a user selects a given point <highlight><bold>52</bold></highlight>-<highlight><bold>60</bold></highlight> on virtual arc <highlight><bold>50</bold></highlight>. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, an exemplary multi-level tree data structure <highlight><bold>70</bold></highlight> of audio cues <highlight><bold>82</bold></highlight> is shown. The multi-level tree data structure <highlight><bold>70</bold></highlight> is created by a user using conventional data management software and is stored in a storage device (e.g., memory <highlight><bold>16</bold></highlight>, database <highlight><bold>30</bold></highlight>, or a remote database accessed over Internet <highlight><bold>34</bold></highlight>), as discussed above. Audio cues <highlight><bold>82</bold></highlight> are arranged in levels <highlight><bold>72</bold></highlight>-<highlight><bold>80</bold></highlight> of multi-level tree data structure <highlight><bold>70</bold></highlight> such that the user can select general categories and navigate down to a specific segment of audio information. For example, in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, level <highlight><bold>72</bold></highlight> contains user-selected audio cues <highlight><bold>82</bold></highlight> that are representative of the source (e.g., the user&apos;s CD music collection) of the desired audio information. Level <highlight><bold>74</bold></highlight> contains user-selected audio cues <highlight><bold>82</bold></highlight> representative of different styles of music (e.g., Rock and Roll music). Level <highlight><bold>76</bold></highlight> contains user-selected audio cues <highlight><bold>82</bold></highlight> that are representative of specific artists or groups (e.g., artist/group <highlight><bold>3</bold></highlight>). Level <highlight><bold>78</bold></highlight> contains user-selected audio cues <highlight><bold>82</bold></highlight> representative of specific albums (e.g., Album <highlight><bold>3</bold></highlight>). Level <highlight><bold>78</bold></highlight> contains user-selected audio cues <highlight><bold>82</bold></highlight> representative of a specific song (e.g., song <highlight><bold>4</bold></highlight>). It should be noted that the number of audio cues <highlight><bold>82</bold></highlight> per level <highlight><bold>72</bold></highlight>-<highlight><bold>80</bold></highlight> should correspond to the number of points <highlight><bold>52</bold></highlight>-<highlight><bold>60</bold></highlight> on virtual arc <highlight><bold>50</bold></highlight> (shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>). It should also be noted that each level may contain a different number of audio cues and that the number of points on the virtual arc may dynamically change to reflect the number of audio cues in a given level. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, another exemplary multi-level tree data structure <highlight><bold>90</bold></highlight> of audio cues <highlight><bold>96</bold></highlight> is shown. Multi-level tree data structure <highlight><bold>90</bold></highlight> illustrates that a user can link an audio cue <highlight><bold>103</bold></highlight> of one level <highlight><bold>102</bold></highlight> to audio cues <highlight><bold>95</bold></highlight> and <highlight><bold>101</bold></highlight> of other levels <highlight><bold>94</bold></highlight> and <highlight><bold>100</bold></highlight>. This permits a user to navigate to a desired segment of audio information using different pathways in the multi-level tree data structure <highlight><bold>90</bold></highlight>. More specifically, a user can access and play &ldquo;song <highlight><bold>5</bold></highlight>&rdquo; though the &ldquo;classical music&rdquo; pathway or the &ldquo;personal moods&rdquo; pathway, as shown. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIGS. 5 and 6</cross-reference>, a process <highlight><bold>110</bold></highlight> of navigating through audio information using the acoustic interface of the present invention is shown. Initially, at step <highlight><bold>112</bold></highlight>, the user turns system <highlight><bold>10</bold></highlight> on by actuating the power button on pointing device <highlight><bold>40</bold></highlight>. Afterwards the user, at step <highlight><bold>114</bold></highlight>, initializes the acoustic interface by double clicking the &ldquo;select&rdquo; button on pointing device <highlight><bold>40</bold></highlight>. In response, pointing device <highlight><bold>40</bold></highlight> transmits an initializing signal to processor <highlight><bold>12</bold></highlight> via RF receivers <highlight><bold>38</bold></highlight> and RF receiver interface <highlight><bold>36</bold></highlight>. Processor <highlight><bold>12</bold></highlight>, in turn, assigns the current position of pointing device <highlight><bold>40</bold></highlight> as the center point <highlight><bold>56</bold></highlight> of virtual arc <highlight><bold>50</bold></highlight> and maps the highest level of audio cues in the multi-level tree data structure (e.g., level <highlight><bold>72</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 3</cross-reference>) to points <highlight><bold>52</bold></highlight>-<highlight><bold>60</bold></highlight> of virtual arc <highlight><bold>50</bold></highlight>. Processor <highlight><bold>12</bold></highlight> may also check the availability of audio data segment sources (e.g., Internet <highlight><bold>34</bold></highlight>, CD-ROM unit <highlight><bold>28</bold></highlight>, database <highlight><bold>30</bold></highlight> and/or memory <highlight><bold>16</bold></highlight>). Next, at step <highlight><bold>116</bold></highlight>, processor <highlight><bold>12</bold></highlight> determines if the initialization has been completed. If not, processor <highlight><bold>12</bold></highlight> returns to step <highlight><bold>114</bold></highlight> and continues the initialization process. If so, processor <highlight><bold>12</bold></highlight>, at step <highlight><bold>118</bold></highlight>, begins tracking the movement of pointing device <highlight><bold>40</bold></highlight> along virtual arc <highlight><bold>50</bold></highlight> as discussed in greater detail above. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> Next, at step <highlight><bold>120</bold></highlight>, processor <highlight><bold>12</bold></highlight> determines if pointing device <highlight><bold>40</bold></highlight> is within a predetermined distance from a virtual arc point <highlight><bold>52</bold></highlight>-<highlight><bold>60</bold></highlight>. If not, processor <highlight><bold>12</bold></highlight> returns to step <highlight><bold>118</bold></highlight> and continues to track the movement of pointing device <highlight><bold>40</bold></highlight> along virtual arc <highlight><bold>50</bold></highlight>. If so, processor <highlight><bold>12</bold></highlight>, at step <highlight><bold>122</bold></highlight>, retrieves the audio cue assigned to the virtual arc point <highlight><bold>52</bold></highlight>-<highlight><bold>60</bold></highlight> from a storage device (e.g., memory <highlight><bold>16</bold></highlight> or database <highlight><bold>30</bold></highlight>) and plays it via speakers <highlight><bold>26</bold></highlight>. Afterwards, at step <highlight><bold>124</bold></highlight>, processor <highlight><bold>12</bold></highlight> determines if the user has actuated the &ldquo;select&rdquo; button on pointing device <highlight><bold>40</bold></highlight>. If not, processor <highlight><bold>12</bold></highlight> returns to step <highlight><bold>118</bold></highlight> and continues to track the movement of pointing device <highlight><bold>40</bold></highlight> along virtual arc <highlight><bold>50</bold></highlight>. If so, processor <highlight><bold>12</bold></highlight>, at step <highlight><bold>126</bold></highlight>, provides audio feedback (e.g., an electronic beep or tone) to the user and, at step <highlight><bold>128</bold></highlight>, determines if the user is currently at the lowest level of the multi-level tree data structure (e.g., level <highlight><bold>80</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 3</cross-reference>). </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> If the user is not at the lowest level, processor <highlight><bold>12</bold></highlight>, at step <highlight><bold>130</bold></highlight>, maps the current level of audio cues (e.g., level <highlight><bold>74</bold></highlight>, <highlight><bold>76</bold></highlight> or <highlight><bold>78</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 3</cross-reference>) to points <highlight><bold>52</bold></highlight>-<highlight><bold>60</bold></highlight> of virtual arc <highlight><bold>50</bold></highlight> and returns to step <highlight><bold>118</bold></highlight> to track the movement of pointing device <highlight><bold>40</bold></highlight> along virtual arc <highlight><bold>50</bold></highlight>. If the user is at the lowest level of the tree data structure, processor <highlight><bold>12</bold></highlight>, at step <highlight><bold>132</bold></highlight>, retrieves the audio data segment (e.g., song or song list) associated with the audio cues from a source of audio data segments (e.g., Internet <highlight><bold>34</bold></highlight>, CD-ROM unit <highlight><bold>28</bold></highlight>, database <highlight><bold>30</bold></highlight> and/or memory <highlight><bold>16</bold></highlight>) and plays the segment via speakers <highlight><bold>26</bold></highlight>. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, an exemplary graphical user interface (&ldquo;GUI&rdquo;) <highlight><bold>140</bold></highlight> for managing the acoustical interface of the present invention is shown. GUI <highlight><bold>140</bold></highlight> includes an &ldquo;Audio Cue Tree&rdquo; pull-down menu <highlight><bold>142</bold></highlight>, an &ldquo;Audio Segment&rdquo; pull-down menu <highlight><bold>144</bold></highlight>, an &ldquo;Audio Segment List&rdquo; pull-down menu <highlight><bold>146</bold></highlight>, an &ldquo;Audio Cue List&rdquo; pull-down menu <highlight><bold>148</bold></highlight> and a &ldquo;Help&rdquo; pull-down menu <highlight><bold>150</bold></highlight> for allowing a user to manipulate various audio cue trees, audio cues, and audio data segments, as discussed in further detail below. GUI <highlight><bold>140</bold></highlight> also includes a window section <highlight><bold>152</bold></highlight> that allows a user to view textual and/or graphical data (e.g., names, identifiers, file sizes) associated with selected audio information (e.g., audio cue trees, audio cues, audio data segments), as discussed in further detail below. GUI <highlight><bold>140</bold></highlight> further includes controls <highlight><bold>154</bold></highlight>-<highlight><bold>164</bold></highlight> facilitating the user&apos;s control of selected audio cues or audio data segments. Some exemplary controls include, but are not limited to, a &ldquo;volume&rdquo; icon <highlight><bold>154</bold></highlight>, a &ldquo;play&rdquo; icon <highlight><bold>156</bold></highlight>, a &ldquo;rewind&rdquo; icon <highlight><bold>158</bold></highlight>, a &ldquo;fast forward&rdquo; icon <highlight><bold>160</bold></highlight>, a &ldquo;pause&rdquo; icon <highlight><bold>162</bold></highlight>, and a &ldquo;stop&rdquo; icon <highlight><bold>164</bold></highlight>. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> In operation, the user may run the acoustical interface software associated with GUI <highlight><bold>140</bold></highlight> on system <highlight><bold>12</bold></highlight>. The software may be stored on any computer readable medium such as, but not limited to, a floppy disk, smart card, CD, or DVD, or may be downloaded from a remote server via an intranet (not shown) or internet <highlight><bold>34</bold></highlight>. The user preferably views GUI on display <highlight><bold>22</bold></highlight> and manipulates the GUI pull-down-menus and icons using keyboard <highlight><bold>24</bold></highlight>, a mouse (not shown), pointing device <highlight><bold>40</bold></highlight>, or a similar hardware device. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> If the user selects &ldquo;Audio Cue Tree&rdquo; pull-down menu <highlight><bold>142</bold></highlight>, the following GUI icons, inter alia, are presented to the user. A &ldquo;View Tree List&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to display a list of existing audio cues trees in window section <highlight><bold>152</bold></highlight>. A &ldquo;Create Tree&rdquo; icon that, when selected, causes processor to display an input screen in window section <highlight><bold>152</bold></highlight> wherein the user can input an audio tree name, the number of levels in the audio tree, the number of cues per level, and other relevant data. A &ldquo;Download Tree&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to download a pre-existing audio cues tree provided by the supplier of audio content (e.g., a pre-existing audio cue tree of audio cues that are representative of satellite radio stations and are provided by the satellite service provider). A &ldquo;Select Tree&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to point to the memory location of the selected audio cue tree such that the user navigates through the selected audio tree the next time the acoustical interface is used. A &ldquo;Link Tree&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to link selected levels of selected audio cue trees together such that the user can quickly create larger audio cue trees and/or create multiple pathways to a segment of audio information. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> If the user selects &ldquo;Audio Segment&rdquo; pull-down-menu <highlight><bold>144</bold></highlight>, the following GUI icons, inter alia, are presented to the user. A &ldquo;Create Audio Segment&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to tag an audio data segment (e.g., a song in a stored MP3 file or on a compact disk track) in a storage device (e.g., CD-ROM unit <highlight><bold>28</bold></highlight>, database <highlight><bold>30</bold></highlight>, remote server connected to Internet <highlight><bold>34</bold></highlight>) such that processor <highlight><bold>12</bold></highlight> can quickly retrieve the audio segment when the user selects the audio segment using the acoustical interface of the present invention. A &ldquo;Play Audio Segment&rdquo; icon that, when selected, causes processor to retrieve a selected audio data segment from a storage device and play it via speakers <highlight><bold>26</bold></highlight>. (It should be noted that the user can control the playback of the selected audio data segment via control icons <highlight><bold>154</bold></highlight>-<highlight><bold>164</bold></highlight>). A &ldquo;Delete Audio Segment&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to erase an existing tag for a selected audio data segment. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> If the user selects &ldquo;Audio Segment List&rdquo; pull-down menu <highlight><bold>146</bold></highlight>, the following GUI icons, inter alia, are presented to the user. A &ldquo;View Audio Segment List&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to display audio data segment lists in window section <highlight><bold>152</bold></highlight>. (It should be noted that the displayed audio data segment lists, or audio data segments within a selected audio data segment list, may be sorted by artist name, album title, song title, source (e.g., CD-ROM unit <highlight><bold>28</bold></highlight>, Database <highlight><bold>30</bold></highlight>, Internet <highlight><bold>34</bold></highlight>, etc.) or the like). A &ldquo;Create Audio Segment List&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to display an input screen in window section <highlight><bold>152</bold></highlight> wherein the user can input, inter alia, an audio data segment list name and input the names of the audio data segments to be included in the created audio data segment list. An &ldquo;Audio Segment Source&rdquo; icon that, when selected, causes processor to display in window section <highlight><bold>140</bold></highlight> a list of available audio data segment sources (e.g., CD-ROM unit <highlight><bold>28</bold></highlight>, Database <highlight><bold>30</bold></highlight>, Internet <highlight><bold>34</bold></highlight>, Memory <highlight><bold>16</bold></highlight>, etc.) to which the user can add or remove audio data segment sources. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> If the user selects &ldquo;Audio Cue List&rdquo; pull-down-menu <highlight><bold>148</bold></highlight>, the following GUI icons, inter alia, are presented to the user. A &ldquo;Create Audio Cue&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to display an input screen in window section <highlight><bold>152</bold></highlight> wherein the user can input the name of the audio cue and the source of the audio cue (i.e., a snippet of an audio segment, a microphone input, a computer-generated sound, or the like). A &ldquo;Store Audio Cue&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to store a created audio cue in a storage device such as memory <highlight><bold>16</bold></highlight>, local database <highlight><bold>30</bold></highlight>, or a remote database via Internet <highlight><bold>34</bold></highlight>. A &ldquo;Play Audio Cue&rdquo; icon that, when selected, causes processor to retrieve a selected audio cue from the storage device and play it via speakers <highlight><bold>26</bold></highlight>. (It should be noted that the user can control the playback of the selected audio cue via control icons <highlight><bold>154</bold></highlight>-<highlight><bold>164</bold></highlight>). A &ldquo;Delete Audio Cue&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to erase the selected audio cue from the storage device. A &ldquo;View Audio Cue List&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to list in window section <highlight><bold>152</bold></highlight> a list of existing audio cues linked audio segments. A &ldquo;Link Audio Cue&rdquo; icon that, when selected, causes processor <highlight><bold>12</bold></highlight> to display an input screen in window section <highlight><bold>152</bold></highlight> such that a user can enter the audio segment, audio cue tree, and audio cue tree level to which the selected audio cue is to be linked. An &ldquo;Unlink Audio Cue&rdquo; Icon that, when selected, causes processor <highlight><bold>12</bold></highlight> display an input screen in window section <highlight><bold>152</bold></highlight> such that a user can enter the audio segment, audio cue tree, and/or audio cue tree level from which the linked audio cue is to be deleted. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> If the user selects &ldquo;Help&rdquo; pull-down menu <highlight><bold>150</bold></highlight>, a plurality of &ldquo;How To&rdquo; icons are displayed to the user to enable the user to efficiently utilize GUI <highlight><bold>140</bold></highlight> of the acoustic interface of the present invention. It should be noted that alternative GUI displays, pull-down menus, icons, and controls for enabling the management of the audio, textual, and graphical data, as know by those skilled in the art, are considered within the scope of the present invention. For example, there may also be a &ldquo;Data Segment&rdquo; pull down menu in GUI <highlight><bold>140</bold></highlight> that facilitates a user&apos;s ability to link audio cues and/or audio cue trees to data segments other than audio data segments (e.g., linking audio cues or audio cue trees to text files, video files, and device functions). </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> Turning to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, another exemplary multi-level audio cue tree <highlight><bold>170</bold></highlight> is shown. Multi-level audio cue tree <highlight><bold>170</bold></highlight> illustrates that different levels <highlight><bold>172</bold></highlight> and <highlight><bold>184</bold></highlight>-<highlight><bold>192</bold></highlight> in audio cue tree <highlight><bold>170</bold></highlight> may have a different number of audio cues contained therein. Audio cue tree <highlight><bold>170</bold></highlight> also illustrates that audio cues may be linked to data segments that are not purely audio data segments. For example, level <highlight><bold>176</bold></highlight> contain an audio cue <highlight><bold>176</bold></highlight> that is representative of a source of text files, an audio cue <highlight><bold>178</bold></highlight> that is representative of a source of video files, an audio cue <highlight><bold>180</bold></highlight> that is representative of the controls of an answering machine, and an audio cue <highlight><bold>182</bold></highlight> that is representative of the controls of a VCR. Furthermore, level <highlight><bold>186</bold></highlight> contains additional audio cues that are representative of text files, level <highlight><bold>188</bold></highlight> contains audio cues (e.g., famous movie lines) that are representative of movies provided by the source of video files, and levels <highlight><bold>190</bold></highlight> and <highlight><bold>192</bold></highlight> contain cues that represent the individual controls of an answering machine an a VCR, respectively. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Level <highlight><bold>172</bold></highlight> also contains an audio cue <highlight><bold>174</bold></highlight> that is representative of a satellite radio service provider. The satellite service provider can potentially provide hundreds of radio stations to a user. As a result, the satellite service provider may also provide metadata about the stations to the user such that the user could use the metadata to generate audio cue trees. Alternatively, the service provider may provide downloadable audio cues and/or audio cue trees that the user can access. It should be noted that the bottom level <highlight><bold>184</bold></highlight> in an audio cue tree that is representative of a satellite radio station would not be a particular song or song list, but rather a pointer to a stream of audio content that will be arriving in the future. It should also be noted that Internet, DSL, cable, and other service providers may provide similar services and the use of these services to provide audio cues, audio cue trees, or data that facilitates the generation of audio cues or audio cue trees is considered within the scope of the invention. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> While the present invention has been described with reference to the preferred embodiments, it is apparent that various changes may be made in the embodiments without departing from the spirit and the scope of the invention, as defined by the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of providing access to a plurality of data segments, the method comprising the steps of: 
<claim-text>storing a plurality of audio cues in a memory, each audio cue representing a predetermined number of stored audio cues or a data segment; </claim-text>
<claim-text>providing access to a first predetermined number of stored audio cues; </claim-text>
<claim-text>playing one of the first predetermined number of stored audio cues in response to a first user request; and </claim-text>
<claim-text>retrieving one of a data segment or a second predetermined number of stored audio cues in response to a second user request. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the retrieved data segment is one of an audio data segment, a video, textual or graphical data segment, or a data segment utilized for controlling the operation of a device. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, further comprising the step of: 
<claim-text>processing the retrieved data segment such that the audio data segment is played, the video, textual or graphical data segment is displayed, or the operation of the device is initiated. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the step of storing the plurality of audio cues further includes the step of: 
<claim-text>storing the plurality of audio cues in a data tree structure having multiple levels, each level containing a predetermined number of audio cues. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein the step of providing access to the first predetermined number of stored audio cues includes providing access to a first level of audio cues in the stored data tree structure, and the step of providing access to the second predetermined number of stored audio cues includes providing access to a second level of audio cues in the stored data tree structure, the second level being linked to the first level. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the step of storing the plurality of audio cues further includes the step of: 
<claim-text>creating the plurality of audio cues, prior to storage thereof, by sampling an audio data segment, recording a user voice, or recording a computer-generated voice. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the step of storing the plurality of audio cues further includes the step of: 
<claim-text>downloading a plurality of pre-existing audio cues. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the step of providing access to the first predetermined number of stored audio cues includes the step of: 
<claim-text>mapping the first predetermined number of audio cues onto a plurality of points on a virtual configuration. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein the step of playing one of the first predetermined number of stored audio cues includes the step of: 
<claim-text>tracking a user&apos;s navigation along the virtual configuration such that an audio cue is played when user has navigated within a predetermined distance from a point on the virtual configuration, the point being associated with the played audio cue. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the method is embedded in one of a computer system, a stereo system, a home entertainment center, an automobile music system, or an electronic device. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A user interface system, comprising: 
<claim-text>a data segment interface communicatively connected to a source of data segments; </claim-text>
<claim-text>a computer readable medium interface communicatively connected to a computer readable medium having a plurality of audio cues stored thereon, each audio cue being associated with a data segment; </claim-text>
<claim-text>a device for transmitting a request in response to a user input; </claim-text>
<claim-text>an audio interface communicatively connected to an audio system; and </claim-text>
<claim-text>a processor for retrieving an audio cue from the computer readable medium and playing the retrieved audio cue on the audio system in response to a received request. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the processor, after playing the retrieved audio cue, retrieves a data segment, associated with the played audio cue, from the source of data segments via the data segment interface in response to a second request. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the data segment is one of an audio data segment, a video, textual or graphical data segment, or a data segment utilized for controlling the operation of a device. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the computer readable medium is one of a local memory device, a remote memory device, or a removable memory device. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the device for transmitting is one of a wired device or a wireless device. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the audio cues are stored in the computer readable medium in a data tree structure having multiple levels containing a predetermined number of audio cues. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the audio cues are created by the user prior to the storage on the computer readable memory. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the audio cues are created by the provider of the source of data segments. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the audio cues and source of data segments reside on the same computer readable medium. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the system is integrated with one of a computer system, a stereo system, a home entertainment center, an automobile music system, or an electronic device. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. A system for providing an acoustic interface, the system comprising: 
<claim-text>means for storing a plurality of audio cues in a memory, each audio cue representing a predetermined number of stored audio cues or a data segment; </claim-text>
<claim-text>means for providing access to a first predetermined number of stored audio cues; </claim-text>
<claim-text>means for playing one of the first predetermined number of stored audio cues in response to a first user request; and </claim-text>
<claim-text>means for retrieving one of a data segment or a second predetermined number of stored audio cues in response to a second user request. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein the retrieved data segment is one of an audio data segment, a video, textual or graphical data segment, or a data segment utilized for controlling the operation of a device. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further comprising: 
<claim-text>means for processing the retrieved data segment such that the audio data segment is played, the video, textual or graphical data segment is displayed, or the operation of the device is initiated. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The system <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein means for storing the plurality of audio cues further comprises: 
<claim-text>means for storing the plurality of audio cues in a data tree structure having multiple levels, each level containing a predetermined number of audio cues. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference>, wherein the means for providing access to the first predetermined number of stored audio cues includes means for providing access to a first level of audio cues in the stored data tree structure, and the means for providing access to the second predetermined number of stored audio cues includes means for providing access to a second level of audio cues in the stored data tree structure, the second level being linked to the first level. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein the means for storing the plurality of audio cues further comprises: 
<claim-text>means for creating the plurality of audio cues, prior to storage thereof, by sampling an audio data segment, recording a user voice, or recording a computer-generated voice. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein the means for storing the plurality of audio cues further comprises: 
<claim-text>means for downloading a plurality of pre-existing audio cues. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein the means for providing access to the first predetermined number of stored audio cues comprises: 
<claim-text>means for mapping the first predetermined number of audio cues onto a plurality of points on a virtual configuration. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, wherein means for playing one of the first predetermined number of stored audio cues comprises: 
<claim-text>means for tracking a user&apos;s navigation along the virtual configuration such that an audio cue is played when user has navigated within a predetermined distance from a point on the virtual configuration, the point being associated with the played audio cue. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein the system is integrated with one of a computer system, a stereo system, a home entertainment center, an automobile music system, or an electronic device. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. In a computer readable medium, a data structure comprising: 
<claim-text>a multi-level data tree structure of audio cues, each level containing a predetermined number of audio cues, each audio cue of a given level being linked to another level in the multi-level data tree structure or to a data segment. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. The computer readable medium of <dependent-claim-reference depends_on="CLM-00033">claim 31</dependent-claim-reference>, wherein the data segment resides in the computer readable medium. </claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. The computer readable memory of <dependent-claim-reference depends_on="CLM-00033">claim 31</dependent-claim-reference>, wherein the data segment resides outside of the computer readable medium.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>7</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001881A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001881A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001881A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001881A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001881A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001881A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001881A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001881A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001881A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
