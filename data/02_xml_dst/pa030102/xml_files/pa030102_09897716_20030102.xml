<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002747A1-20030102-D00000.TIF SYSTEM "US20030002747A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002747A1-20030102-D00001.TIF SYSTEM "US20030002747A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002747A1-20030102-D00002.TIF SYSTEM "US20030002747A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002747A1-20030102-D00003.TIF SYSTEM "US20030002747A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002747A1-20030102-D00004.TIF SYSTEM "US20030002747A1-20030102-D00004.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002747</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09897716</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010702</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06K009/40</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>H04N001/58</ipc>
</classification-ipc-secondary>
<classification-ipc-secondary>
<ipc>H04N001/409</ipc>
</classification-ipc-secondary>
<classification-ipc-secondary>
<ipc>G06T005/00</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>382</class>
<subclass>260000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>382</class>
<subclass>275000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>358</class>
<subclass>533000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>358</class>
<subclass>003260</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Moire correction in images</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Krzystof</given-name>
<middle-name>Antoni</middle-name>
<family-name>Zaklika</family-name>
</name>
<residence>
<residence-us>
<city>Saint Paul</city>
<state>MN</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Nikolai</given-name>
<middle-name>Vasil?apos;evich</middle-name>
<family-name>Markov</family-name>
</name>
<residence>
<residence-non-us>
<city>Pushkin</city>
<country-code>RU</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>JASC Software,Inc</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>MARK A. LITMAN &amp; ASSOCIATES, P.A.</name-1>
<name-2>York Business Center</name-2>
<address>
<address-1>Suite 205</address-1>
<address-2>3209 West 76th Street</address-2>
<city>Edina</city>
<state>MN</state>
<postalcode>55435</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Image defects in a digital image are reduced by a process comprising: </paragraph>
<paragraph id="A-0002" lvl="2">providing a digital image data set in the form of a matrix of pixels; </paragraph>
<paragraph id="A-0003" lvl="2">selecting a sub-matrix comprising at least a 5&times;5 matrix of pixels; </paragraph>
<paragraph id="A-0004" lvl="2">identifying a pixel within the sub-matrix to be treated as a central pixel; </paragraph>
<paragraph id="A-0005" lvl="2">determining a value for at least one optical property in the central pixel; </paragraph>
<paragraph id="A-0006" lvl="2">selecting at least four pixels around the central pixel as averaging pixels, at least two of the averaging pixels being in a position in the sub-matrix that is not adjacent the position in the matrix of the central pixel; </paragraph>
<paragraph id="A-0007" lvl="2">determining a value for the at least one optical property for the at least four averaging pixels; </paragraph>
<paragraph id="A-0008" lvl="2">averaging the values for the at least one optical property for more than one of the at least four averaging pixels to provide an average treatment value for the central pixel; </paragraph>
<paragraph id="A-0009" lvl="2">assigning the average treatment value for the central pixel to the central pixel; and </paragraph>
<paragraph id="A-0010" lvl="2">storing the average treatment value assigned to the central pixel. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to image data, particularly image data that is provided as an image file, and particularly image data that generates an image and may contain moir&eacute; patterns, particularly color images that display moir&eacute; patterns in virtual or real images. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Background of the Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Recorded images comprise a spatial, normally planar, representation of either spatially or temporally variable original signals. A large proportion of such recordings, such as copies of documents and pictures, represent a one-to-one relationship with an original document or scene, frequently with magnification or reduction involved. Radiographic film images in medicine represent a class of images where the original is not visible to the human eye and must be formed by a combination of invisible radiation (e.g., x-rays) and a suitable transducer (fluorescent screen). </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In all image forming systems, degradation of the original information occurs which normally manifests itself in at least three forms: (1) blurring of edges (reduced resolution, lower sharpness); (2) random irregularities (noise, fog); and (3) image format artifacts (e.g., smudging, spreading, moir&eacute; patterns, blocking and trapping). In normal photographic images, it has long been known that edge sharpness can be enhanced and noise reduced by masking the original with a negative unsharp mask of suitable contrast (usually with lower contrast than that of the original). Early work by J. A. C. Yule is representative of this photographic masking approach (U.S. Pat. Nos. 2,407,211, 2,420,636, 2,455,849) and more complex approaches are represented by Blearson et al. in U.S. Pat. No. 3,615,433. An early attempt to use a raster scanning of the image while measuring the instantaneous light values photoelectrically and attenuating the beam according to a predetermined relationship with the light value is disclosed by Folse in U.S. Pat. No. 3,011,395. The rapid development of the Space Program lead to the emergence of high efficiency digital means of analyzing, reconstituting and enhancing images. Median filtering as a means of enhancing edge contrast has also been studied (e.g., B. R. Frieden JOSA 66. 280-283 (1976)). In the medical radiography field this stimulated the development of computerized tomography and the digital processing of radiographs in general (S. R. Amety et al, SPIE 207, 210-211 (1979), and C. R. Wilson et al, SPIE 314, 327-330 (1981)). In these approaches the image has been divided into a large number of &ldquo;pixels&rdquo; by scanning. A moving window consisting of n&times;m pixels centered on pixel i with image value D<highlight><subscript>i </subscript></highlight>is investigated by an on line computer as pixels i are scanned. The arithmetic average D of the pixels within the window is then used to modify the central pixel value D<highlight><subscript>i </subscript></highlight>to a filtered value D&prime;<highlight><subscript>i </subscript></highlight>by the algorithm:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>D&prime;</italic></highlight><highlight><subscript>i</subscript></highlight><highlight><italic>&equals;aD</italic></highlight><highlight><subscript>i</subscript></highlight><highlight><italic>&minus;bD</italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0006" lvl="7"><number>&lsqb;0006&rsqb;</number> The parameters a and b are chosen to give specific image characteristics but are constant over the scan of a single image. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> The concept of varying parameters similar to a and b throughout the scan of the image based on certain local properties of the image has been studied and these patents (H. Kato et al U.S. Pat. Nos. 4,315,318 and 4,317,179 and M. Ishida et al U.S. Pat. No. 4,346,409) have disclosed particular relationships between the parameters and the values of D<highlight><subscript>i </subscript></highlight>or D which can give further image enhancement. These techniques do not however distinguish between noise and image edges as far as enhancement is concerned, and the higher the density D<highlight><subscript>i </subscript></highlight>or D the greater the enhancement. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> In other imaging technology areas, similar approaches have been made. Thus in E. Alparslau and F. Ince, IEEE Vol SMC-11, 376-384 (1981), images are treated with an edge enhancement algorithm based in part on an adaptive parameter based on the difference between the maximum and minimum pixel values in the window at any point. In U.S. Pat. No. 4,237,481 final image data for printing plate production is treated by electronic circuits according to algorithms that combine sharp and unsharp image data with pixel parameters. U.S. Pat. No. 4,334,244 treats video signal images electronically according to algorithms based on the fixed average and wherein values acting on the instantaneous gradient of the image signal, the degree of edge enhancement being partly controlled by the dynamic noise of the system. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> U.S. Pat. No. 4,571,635 describes a method of displaying or recording an image showing enhanced detail (particularly edge detail) relative to an original image or record comprising: </paragraph>
<paragraph id="P-0010" lvl="2"><number>&lsqb;0010&rsqb;</number> (a) making a point by point record of the original image by scanning it in a manner to select successive pixels in a logical array, </paragraph>
<paragraph id="P-0011" lvl="2"><number>&lsqb;0011&rsqb;</number> (b) storing the pixel values in such a way and for such a period that a window comprising a sub-array of adjacent pixels can be selected and analyzed statistically, said window comprising between 5 and 225 pixels, </paragraph>
<paragraph id="P-0012" lvl="2"><number>&lsqb;0012&rsqb;</number> (c) analyzing the pixel values of the window surrounding each pixel in turn to give the average value D and the standard deviation sigma, </paragraph>
<paragraph id="P-0013" lvl="2"><number>&lsqb;0013&rsqb;</number> (d) processing the central fixed value D<highlight><subscript>c </subscript></highlight>to give an improved value D&prime;<highlight><subscript>c </subscript></highlight>such that</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>D</italic></highlight><highlight><subscript>c</subscript></highlight><highlight><italic>&prime;&equals;kD</italic></highlight><highlight><subscript>c</subscript></highlight>&plus;(1<highlight><italic>&minus;k</italic></highlight>)<highlight><italic>D</italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0014" lvl="7"><number>&lsqb;0014&rsqb;</number> wherein k is a variable having a value between 0 and 0.99 which varies from pixel to pixel based on the value of sigma, said value of k being related monotonically to sigma in such a way as to have an upper and lower bound within the said range 0 to 0.99, and </paragraph>
<paragraph id="P-0015" lvl="2"><number>&lsqb;0015&rsqb;</number> (e) displaying or recording the enhanced image based on the derived values D<highlight><subscript>c</subscript></highlight>&prime;. In effect, the process averages optical density values, establishes a trend adjacent an edge, and then adjusts the density of individual pixels to continue the established trend. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Each of these references relates to image correction of edge defects through the use of software embodying algorithms that assist in the visual correction of the specifically identified region of defects, edges in the image. However, there arises a problem in reading an original image such as a photograph or a painting having thick portions and thin portions provided as a dot image by a half tone etching method. More specifically, because of the relation between the pitch between each of the dots and the reading pitch by the image pickup device, or of a subtle deviation of phase based on the period and the like in half tone processing, a periodical pattern of thick and thin portions called moir&eacute; pattern is generated, providing trouble in viewing. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> Moir&eacute; patterns result from the interaction of the spatial frequencies of at least two spatially extended periodic patterns when they are superimposed. The visual effect varies widely depending on the relative angular orientation, translation and frequency distribution in two the patterns. In some cases moir&eacute; can lead to pleasing design effects but in most situations in graphic arts moir&eacute; is to be avoided. Examples of undesirable moir&eacute; patterns are those formed in computer monitors or by overlap of color separations in color printing. One area in which moir&eacute; is a particular problem is in digital imaging, where images are formed as regular grids of picture elements or pixels. Such grids are associated with particular spatial frequencies that can interact with other spatial frequencies of components present in devices that are part of the imaging chain. A commonly encountered situation involves the scanning of colored halftone printed media, such as those composed of regularly spaced dots of colored ink of varying size. Typically, the scanner contains a detector such as a CCD (Charge Coupled Device) array and the spacing of the array interacts with the spacing of ink dots to produce an undesirable moir&eacute; pattern in the scanned image. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The occurrence of such moir&eacute; patterns is well known in digital imaging. One commonly found form of moir&eacute; is of high spatial frequency in which the separation between elements of the moir&eacute; pattern is comparable to the size of the smallest details in the image. It is common to remove this type of moir&eacute; pattern with some form of smoothing or blurring. In this procedure a compromise is made between elimination of the moir&eacute; pattern and the loss of authentic fine detail in the image. There have been attempts to eliminate the moir&eacute; in the scanner itself by optical blurring, as described in U.S. Pat. No 5,159,469, U.S. Pat. No. 5,121,213, U.S. Pat. No. 4,987,496 European Patent 1,022,912 or Japanese Patent 8/149,358, or by adding noise or jitter to the scanning process, as described in U.S. Pat. No. 4,336,558 or Japanese Patent 51/45,757. Other attempts include matching the scanning frequency to spatial frequency elements in the material to be scanned as disclosed in U.S. Pat. No. 5,253,046, U.S. Pat. No. 4,965,599 or European Patent 960,523 or in Shu, J. S.-P., Springer, R. and Yeh, C. L., <highlight><italic>Optical Engineering</italic></highlight>, v.28(7), 805-12 (1989). There have also been efforts to combine multiple scans of the same subject in order to reduce moir&eacute; as is disclosed in U.S. Pat. No. 6,100,929, Ohyama, N., Yamaguchi, M., Tsujiuchi, J., Honda, T. and Hiratsuka, S., <highlight><italic>Optics Communications</italic></highlight>, v.60(6), 364-8 (1986) or Yang, C.-Y. and Tsai, W.-H., <highlight><italic>Pattern Recognition Letters, </italic></highlight>v.18(3), 213-27 (1997). Actions performed mechanically or electrically within the scanner can also be accomplished by digital computation. Thus, for example, U.S. Pat. No. 5,225,915 teaches the enhancement of image noise in order to mask moir&eacute; patterns. Scanners have been designed including computational means for blurring noise. For example, Japanese Pat. Wei 10/276,331 discloses an averaging circuit, Japanese Pat. Wei 11/275,367 the use of a moving average and U.S. Pat. No. 5,821,915 the use of a weighted average filter, while Japanese Patent &lsqb;2,000/023,085&rsqb; teaches the use of a median filter for moir&eacute; suppression in a digital camera. Further, U.S. Pat. No. 5,239,390 teaches a descreening method using an iterative smoothing filter tuned to the frequency of the halftone screen, while U.S. Pat. No. 5,166,810 discloses the removal of halftone mesh patterns by a combination of a smoothing filter and edge emphasis, and U.S. Pat. No. 4,907,096 claims descreening by filtering in the Fourier (or spatial frequency) domain. In addition to such low-pass filtering methods, there have been attempts to blur the image using specially shaped or directional filters. Thus, Japanese Pat. 1972/95,961 describes a 2D filter with an axially symmetric impulse response, Japanese Wei Patent 10/003,539 discloses smoothing in the direction of minimum brightness variation, U.S. Pat. No. 5,351,312 teaches a spatial filter with positive coefficients in the main scan and cross-scan directions with negative coefficients in the diagonal directions, U.S. Pat. No. 5,649,031 claims a smoothing filter with maximum smoothing in a direction slanted with respect to the scan direction, and U.S. Pat. No. 5,798,846 discusses the use of modified median filter with a specially shaped (e.g., cross-shaped) filter window. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Another variant of moir&eacute; defect occurs as widely spaced color bands or blotches when colored halftone images are scanned. The spacing between these bands is very much larger than the scale of the finest authentic details in the image. Thus, approaches for removing moir&eacute; using blurring are completely unsuitable for removing this type of defect since blurring sufficient to reduce the bands will completely destroy small, and often medium scale, detail in the image. This moir&eacute; color banding is not unusual in scans produced by consumer scanners and there is a need for a method to eliminate it. No generally applicable and straightforward methods exist for achieving this objective. One method has been described by Kai Krause, originally in an electronic Compuserve Forum, and now available on the world wide web at http://www.pixelfoundry.com/Tips/ under the title &ldquo;Tip 10: Litter Removal: Moire Removal&rdquo;. This article teaches a method of removal of fine moir&eacute; patterns using Gaussian blurring. Additionally, it discloses an approach for reducing color bands. This latter method relies on splitting the image into color channels such as red, green and blue and editing a look-up table that transforms each of these colors. The principle involves manually examining each of the bands for the range of color intensities present in a given channel and then manually editing a linear look-up table in such a way that this range of input intensities becomes equal to a single average intensity after color transformation using this table. This approach does not admit automation and requires that there must first be available a method of editing look-up tables, something not normally found in consumer software. In practice it is very difficult to accomplish the disclosed correction in a way that leaves the edges of bands looking natural and blended with the image. If the color bands are not contained in a single color channel, multiple channels must be edited in the way described. This is the situation in the common case of skin tones, which can be accompanied by yellow banding, and would therefore require at least the red and green channels to be edited. Another disadvantage of this method of band elimination is that, while the alteration may lead to reduction in banding, it also influences the same color channel in regions of the image where there is no banding. This introduces new defects. To cope with this problem, it is necessary to select separate regions of the image and correct these regions individually. A further disadvantage of this approach is that it reduces the total number of colors in the image. In summary, the success of the published procedure depends very much on the specific image content, requires great skill and familiarity with image processing concepts, must be accomplished by time-consuming region-by-region correction of the image, and cannot be automated. There remains, therefore, a need for a simple process for removing moir&eacute;-related color bands that can operate rapidly on a complete image. The current widespread availability of inexpensive consumer scanners exacerbates this need. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> The line screen that determines the ink dot spacing in halftone printing varies with the print medium. It can, for example, be about 80 lines per inch for newspapers, about 133 or 150 lines per inch for magazines and books, and as high as about 200 lines per inch or more for high quality art reproduction, posing a wide variation in halftone spatial frequencies. At the same time scanners and their hardware components differ widely. In some examples of consumer scanners (as noted in X. Liu and R. Erich, <highlight><italic>Image Vis. Comput., </italic></highlight>v.18(10), 843-8 (2000)) non-uniform resampling of the image in the scanner introduces extra aliasing components and complicates the moir&eacute; pattern. It can be expected that combinations of different printed media with different scanner hardware will produce widely differing moir&eacute; patterns of the color band type. It is, therefore, surprising that the present invention can, in a simple way, reduce such moir&eacute; color bands in a broad variety of images from such sources. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> A method has been proposed to prevent the generation of the moir&eacute; pattern, in which dimension or pattern of a dither matrix is changed in half tone processing. However, the moir&eacute; pattern cannot be eliminated by this method when the reading pitch (the pitch between pixels in the image pickup device) itself is the cause of the moir&eacute; pattern. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> Under another method, the moir&eacute; pattern has been eliminated by arranging a filter for eliminating the moir&eacute; pattern in a light path in reading the original image and by gradation of the image by dispersing the image focused on one pixel of the image pickup device onto adjacent pixels. However, the moir&eacute; pattern cannot be eliminated in all of the images having thick portions and thin portions even by this method when a plurality of images with thick portions and thin portions having different dot pitches are included in the original image. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> In image forming apparatus, such as copy machines, an image is read by an image-reading unit as a digital signal, and the digital signal is supplied to a recording unit so as to obtain a reproduced image on a hard copy. In such an image-reading unit, an original is read out by an image sensor such as a CCD (Charge Coupled Device) image sensor by dividing the image into small areas, that is, pixels. An analog electric signal obtained by the image sensor is converted into a digital signal, and then various image-processing operations are applied to the digital signal so as to obtain optimum image data in accordance with the image characteristics thereof. In this type of image forming apparatus, an original is read out by a line sensor or the like having a small pixel size. Accordingly, when intensity change of the original image has periodicity such as in a half tone image, there is a possibility of formation of moir&eacute; in a recorded image due to interference of the periodicity of the intensity change of the original image with the pitch of the image sensor arranged in the line sensor, that is, the sampling period. This moir&eacute; can be eliminated by suppressing the periodicity of the intensity change through a plurality of pixels by averaging the intensity of the pixels. However, when intensities of a plurality of pixels are averaged to eliminate a moir&eacute;, the resultant character image or continuous-tone image may be undesirably blurred. Therefore, there is a problem in that when a mesh image and a character image or a continuous-tone image are mixed in one original image, the averaging process must be applied only to the mesh image area. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The reproduction of intermediate tone in such digital copying machines is generally achieved by a dither method or a density pattern method. However, such methods have been associated with the following drawbacks: (1) if the original image is a screen-tone image such as a printed image, the copied image may show stripe patterns which do not exist in the original image; and (2) if the original image contains line-tone images or characters, the image quality may be deteriorated as the edges are broken by the dither method. The phenomenon (1) is called Moir&eacute; moir&eacute; and is induced by: </paragraph>
<paragraph id="P-0025" lvl="2"><number>&lsqb;0025&rsqb;</number> (a) a frequency phenomenon between the screen-tone original image and the input sampling; or </paragraph>
<paragraph id="P-0026" lvl="2"><number>&lsqb;0026&rsqb;</number> (b) a frequency phenomenon between the screen-tone original image and the dither threshold matrix. </paragraph>
<paragraph id="P-0027" lvl="7"><number>&lsqb;0027&rsqb;</number> The phenomenon (b) becomes particularly evident when the dither threshold values are arranged in a dot concentrated pattern. In such case the reproduced image has a pseudo-screentone structure, which generates a frequency phenomenon with the screentone structure of the input image, thus creating moir&eacute; patterns. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> U.S. Pat. No. 4,926,267 describes a method for use in reducing moir&eacute; patterns during reproducing a halftone original having extent along first and second directions, the original being formed from halftone dots situated along a screen direction and having a spatial frequency f<highlight><subscript>SCR </subscript></highlight>and period P<highlight><subscript>SCR </subscript></highlight>in the screen direction comprising: </paragraph>
<paragraph id="P-0029" lvl="2"><number>&lsqb;0029&rsqb;</number> providing gray level values for an array of pixels extending over the original, the pixels having a first spatial frequency f<highlight><subscript>SCR1 </subscript></highlight>in said first direction and a corresponding first period P<highlight><subscript>SCR1 </subscript></highlight>in said first direction; </paragraph>
<paragraph id="P-0030" lvl="2"><number>&lsqb;0030&rsqb;</number> developing a first gray level value for each pixel of the array whose gray level value equals or exceeds a threshold gray level value and developing a second gray level value for each pixel of the array whose gray level value is less than the threshold gray level value, said first and second gray level values defining a set of thresholded gray level values for said pixels; </paragraph>
<paragraph id="P-0031" lvl="2"><number>&lsqb;0031&rsqb;</number> determining from said set of thresholded gray level values adjacent pairs of pixels of the array in the first direction whose thresholded gray level values are different, each adjacent pair of pixels bordering a corresponding halftone dot; </paragraph>
<paragraph id="P-0032" lvl="2"><number>&lsqb;0032&rsqb;</number> determining from the gray level values of the pixels an edge error e<highlight><subscript>1</subscript></highlight>equal to d<highlight><subscript>1</subscript></highlight>/P<highlight><subscript>SCR1 </subscript></highlight>where d<highlight><subscript>1 </subscript></highlight>is the approximate distance along the first direction between the center of the pixel the pair whose thresholded value is equal to said first gray level value and the closest edge of the corresponding halftone dot; </paragraph>
<paragraph id="P-0033" lvl="2"><number>&lsqb;0033&rsqb;</number> and processing said thresholded gray level values of said pixels of said array including: (a) using a processing window to define successive sub-arrays of said pixels and for each sub-array of pixels: (i) adding the edge errors e<highlight><subscript>1 </subscript></highlight>for the determined adjacent pairs of pixels included in the sub-array to form a sum S<highlight><subscript>1</subscript></highlight>; and (ii) for the pixels having thresholded second gray level values and being in the determined adjacent pairs of pixels, starting with the pixel of the adjacent pair of pixels having the highest edge error and continuing with further pixels of the adjacent pairs of pixels in the order of descending edge error, changing the thresholded gray level values of the pixels from said second to said first threshold gray level value until the thresholded gray level values of M pixels have been changed, where M is the closest integer to the sum S<highlight><subscript>1</subscript></highlight>. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> U.S. Pat. No. 5,408,337 describes an image processing apparatus in which a moir&eacute; pattern occurring in a half tone area can be eliminated by a suitable filter. A plurality of data blocks comprising N*N pixel data are transformed by means of a two-dimensional orthogonal transform so as to obtain an N*N matrix transformation factor block. An evaluation block is prepared which comprises N*N transformation factors each of which is the mean value of the absolute values of corresponding factors from a data block being considered and data blocks surrounding the data block to be determined. Mean values A&lsqb;i&rsqb; and B&lsqb;i&rsqb; (i&equals;0 to L&minus;1) of predetermined transformation factors are calculated, A&lsqb;i&rsqb; being mean values of factors included in a number L of first areas consecutively positioned along a diagonal line of the evaluation block, B&lsqb;i&rsqb; being mean values of factors included in a number L of second areas positioned adjacent to and lower in frequency to the corresponding first areas. A filter selection signal is generated which corresponds to the number i when a condition is satisfied where A&lsqb;i&rsqb;&gt;B&lsqb;i&rsqb; and A&lsqb;i&rsqb;&gt;threshold value th1. The pixel data corresponding to the evaluation block is smoothed by the selected filter. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> As noted above, moir&eacute; patterns can also be generated in monitors or other cathode ray tubes. Color cathode ray tubes (&ldquo;CRTs&rdquo;) are commonly used as visual display devices, employing up to three electrodes, typically one for each primary color: red, green, and blue. Most color CRTs use a shadow mask to selectively illuminate a matrix of each electrode&apos;s respective colored phosphors (i.e., red, green, and blue). CRTs normally will have a shadow mask placed behind a phosphor-coated screen. The shadow mask is usually a metal foil with numerous perforations which allow the electron beam sourced by a particular electrode to selectively strike its respective phosphor dot. The electron-beam is focused by magnetic lenses in the CRT neck into a small spot before the electron-beam reaches the shadow mask. The electron beam from the green cathode is partially occluded by the shadow mask such that the electron beam only strikes the corresponding green phosphor after passing through the shadow mask. The beam is typically larger than the shadow mask perforation size, so the shadow mask blocks part of the beam and casts a smaller shadow of the original beam onto the desired phosphor. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The dot pitch, or spacing, between adjacent shadow mask perforations, and their corresponding phosphor dots, must be as small as possible for the highest resolution. For mechanical and economic reasons, the dot pitch is generally limited to about 0.2 millimeters (&ldquo;mm&rdquo;) to 0.3 mm for a typical high resolution display CRT. As the electron beam traverses the screen, the shadow mask includes a periodic illumination pattern depending on whether the beam either impinges upon a perforation, and consequently the phosphor, or strikes the metal foil of the shadow mask separating the perforations. Because the sweep rate of the electron beam is known, an equivalent frequency for the resulting sinusoid can be calculated, and is referred to as the spatial frequency of the shadow mask, &ngr;<highlight><subscript>spatial</subscript></highlight>. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> To increase the resolution of the display, the spot size of the incident electron beam must be made as small as possible. As the electron beam spot size is reduced and begins to approach the dimensions of the phosphor dot pitch, the amount of a particular phosphor that is actually struck by the beam is a function of how well the electron beam spot is aligned to the shadow mask aperture corresponding to the intended phosphor. Moreover, it must be noted that the electron beam spot shape is not constant as the beam traverses the CRT screen. In particular, the beam spot varies from a circular shape at small angles of deflection, e.g., near the center of the CRT screen, becoming more eccentric or ovaloid at higher angles of beam deflection, e.g., near the screen perimeter. If a video pattern of alternating on-off phosphors (&ldquo;pixels&rdquo;) is displayed, some of the pixels will be seen to be exactly aligned with the shadow mask and therefore will have uniform phosphor brightness across the dot, whereas other phosphors will exhibit a nonuniform brightness, a consequence of misalignment between electron beam and shadow mask aperture. The repeating pattern of varyingly bright pixels also is seen to be of sinusoidal form, with a frequency &ngr;<highlight><subscript>spot </subscript></highlight>equivalent to half the pixel clock frequency, where one pixel clock cycle turns on the spot, and the next pixel clock cycle turns off the pixel. As the spot size of the electron beam is reduced while viewing the on-off pattern, a periodic visual interference pattern known as moir&eacute; is produced in each video line scanned across the CRT. The frequency &ngr;<highlight><subscript>Moir&eacute;</subscript></highlight>of the moir&eacute; interference pattern is the difference between the spatial frequency of the shadow mask &ngr;<highlight><subscript>spatial</subscript></highlight>, and the frequency of the electron beam spot &ngr;<highlight><subscript>spot</subscript></highlight>, or</paragraph>
<paragraph lvl="0"><in-line-formula>&ngr;<highlight><subscript>Moire</subscript></highlight>&equals;&ngr;<highlight><subscript>spatial</subscript></highlight>&minus;&ngr;<highlight><subscript>spot</subscript></highlight>.</in-line-formula></paragraph>
<paragraph id="P-0038" lvl="7"><number>&lsqb;0038&rsqb;</number> If the two frequencies &ngr;<highlight><subscript>spatial </subscript></highlight>and &ngr;<highlight><subscript>spot </subscript></highlight>were identical and in-phase, the moir&eacute; frequency &ngr;<highlight><subscript>Moire </subscript></highlight>would zero out. A moir&eacute; frequency of zero is the ideal case, where each phosphor has a corresponding shadow mask aperture through which the corresponding electron beam travels. From a particular standpoint, however, the spot size varies as a function of the electron beam deflection angle and focus voltage. Therefore, there may be a significant variation of electron beam spot size depending on the age of the CRT and position of the electron beam on the screen. Hence, the ideal case typically cannot practicably be realized. In fact, the closer the spatial frequency and the spot frequencies are to each other, the lower the moir&eacute; beat frequency &ngr;<highlight><subscript>Moire </subscript></highlight>and the more visible and objectionable the moir&eacute; interference pattern becomes. In addition, because the electron beam spot size varies across the face of the CRT, the individually scanned video lines will each produce a slightly different moir&eacute; interference, and therefore the moir&eacute; pattern itself varies as a function of electron beam position. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> From an operating standpoint, the moir&eacute; interference phenomenon poses a serious aesthetic problem, since the best electron beam focus and highest image resolution results in unacceptably noticeable moir&eacute; patterns if the video signal being displayed includes alternating pixel patterns, which is a common occurrence. From the prior art teachings, the moir&eacute; interference problem has been addressed in three ways. First, the shadow mask and phosphor dot pitch can be reduced, which raises the effective spatial frequency of the CRT, thereby raising the moir&eacute; beat frequency so that it is less visible. The result is that in order to reduce the moir&eacute; effect, much lower resolution images must be displayed on a CRT that is inherently capable of significantly higher resolution. Second, the electron beam can be defocused so that the spot size of the electron beam is increased, thereby decreasing the amplitude of the phosphor illumination, which in turn reduces the amplitude of the phosphor spot frequency. The lower amplitude spot sinusoid results in a decrease of the amplitude, and therefore visibility, of the resulting moir&eacute; interference. Again, significant reduction in resolution and image quality are exchanged for only moderate reduction in moir&eacute; interference. A third option is to avoid displaying video signals with alternating pixel or phosphor illumination patterns, and to simply tolerate the resultant moir&eacute; interference patterns when they occur. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> U.S. Pat. No. 5,107,188 describes how visible moir&eacute; interference is eliminated by alternately shifting the phase of the horizontal sync signal or video signals such that the phase of each video line, and hence the phase of the resulting moir&eacute; interference associated with that video line, is also alternately shifted. The phase of the moir&eacute; interferences are shifted such that persistence of vision in the human eye averages oppositely phased phosphor intensity variations occurring on alternating scan lines and/or vertical fields. When viewed by a user of the CRT, optical cancellation of the moir&eacute; interference patterns results. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> U.S. Pat. No. 6,094,018 describes another method of addressing moir&eacute; patterns in a display monitor. A horizontal synchronization signal having a horizontal scanning frequency is received by a first circuit. A vertical synchronization signal having a vertical scanning frequency is received by a second circuit. A moir&eacute; correction signal that is proportional to a horizontal resolution of the displayed image is generated by dividing the horizontal scanning frequency by the vertical scanning frequency. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> As can be seen, the main emphasis on the reduction of moir&eacute; patterns, both in printed and monitor images has been directed towards breaking up the relative frequencies between overlying or contiguous patterns. It is desirable to find alternative methods of reducing moir&eacute; in images, particularly within software solutions. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> A matrix of pixels within an electronic image in which moir&eacute; patterns are present is treated to modify pixel densities to reduce visible moir&eacute; patterns without damaging the quality of the image content. A grid or matrix of pixels for the entire image or a section of the image is created. Sub-matrices, comprising a minimum of 7&times;7 pixels are used to compare optical density values of systematically located pixels that are not adjacent to a relatively central pixel within the matrix (e.g., there is at least one pixel between the central pixel and the non-adjacent pixel). For example, in a 7&times;7 matrix of pixels, the central pixel would preferably be compared to the four corner pixels, and the four outside row centered pixels. The optical density value of the matrix-centered pixel (or other specific optical value such as CIE L*a*b*, CIE L*u*v*, tristimulus values, color content, etc.) would be compared to the eight preferred pixels specified above. A number of the pixels, preferably less than all of the compared pixels, would be selected on the basis of their compared values being the closest within the group to the measured optical value of the sub-matrix-centered pixel. The average or mean value of the selected pixels would then be used as the optical value for the sub-matrix-centered pixel. That value would then be stored in a program for later use in generating a final image. The process would then be performed again by selecting another pixel as the sub-matrix-centered pixel. When a sufficient number (or all of the pixels) within the area to be cleansed of moir&eacute; pattern have been treated by the process and the complete image data saved in the program, the image data may then be presented in a visual form with reduced moir&eacute; pattern thereon.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE FIGURES </heading>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a sub-matrix array of pixels with a 7&times;7 matrix with a matrix-center pixel and edge-centered pixels identified. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shoes a 13&times;13 sub-matrix array of pixels with a matrix-center pixel and edge-centered pixels identified. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a collection of sub-matrices of pixels that are used for moir&eacute; correction within a general matrix of pixels. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a sub-matrix where the pixels to be averaged are selected in a rotated asymmetry around the central pixel in a parallelogram.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> It is at least a desirable objective in the provision of images to provide images without flaws. In professional image-provision fields, such as advertising, web-page design, printing, sign-making, and photography, a first measure of the quality of the work is the appearance of the pictures/images provided. Certain types of flaws tend to be more obvious to visual observance than others, and the presence of moir&eacute; patterns is one of the most obvious observable technical flaws. The reason that moir&eacute; patterns tend to be so readily observable is the pseudo-pattern, or density frequency of the defect. Rather than occurring only at random independent dots (half-tone imaging), points (e.g., monitor display) or pixels (raster imaging or monitor display), moir&eacute; patterns occur over areas of the image, occur over multiple areas, and tend to cover relatively large areas of an image so that the pattern is readily observed on first viewing the image. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> The correction of moir&eacute; defects has been addressed by image-makers at least since the time that half-tone imaging was first introduced and the problem occurred. The advent of digital imaging, inherently digital CRT screens, the increased use of computer imaging, and other technical advances have increased the occurrence of moir&eacute; patterns in regular business and private practice. The inherent limitation in the ability to control the image medium where a fixed spatially distributed medium is used (such as a CRT or monitor screen) requires new methodologies for correcting or at least redressing or minimizing moir&eacute; effects. It has been determined by the inventors that the use of only adjacent pixel-by-pixel analysis is insufficient to satisfactorily address the moir&eacute; effect. Although the moir&eacute; effect can be softened, adjacent pixel-by-pixel analysis still may leave a significantly visible pattern </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> It has been found that the use of a system of pixel adjustments in which at least some distal pixel weighting in the adjustment of individual and collective pixels within the image provides a much more even and smooth reduction in the appearance of moir&eacute; patterns in the image. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> To appreciate the practice of the invention, some understanding of the structure of images is desirable. All images, at some level, are constructed of sub-elements of the image. Even with what is considered an analog image (e.g., a painting created with a brush spreading paint across a surface), microscopic or sub-microscopic analysis would show pigments distributed over the surface of the substrate or canvas. Still, digital imaging is recognized as distinct from analog imaging and is defined by the existence of a collection of distinct areas of approximately equal size (e.g., half-tone imaging usually comprises dots varying in size from about 3% dots to 98% dots) that are organized in a relatively matrix pattern of columns and rows. These sub-elements or smallest image components are known in the art as pixels. The pixels themselves, especially when produced by laser imaging or other high-resolution exposure systems, may itself be formed by smaller units (e.g., in laser imaging, a pixel may be composed of a large number of spots, each spot being approximately the incident area of the laser, and in CRT displays, a pixel could comprise an area comprising a multiplicity of phosphor particles comprising either a single color or a multiplicity of colors). However, within each imaging field, the pixel is usually accepted as a specific unit of the image. For example, in laser imaging, the software program defines how many spots (including zero energy spots to reduce the image density of a pixel) will constitute a pixel and how those spots will be distributed over the pixel area. Therefore the unit of the pixel is a common working tool well understood by the imaging artisan. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> In providing a computer-based image, the image is stored as a digital image, which inherently defines a system or matrix of pixels. The data is stored in a digital format, which inherently considers the image surface as a distribution of columns and rows of pixels or image components. Therefore digital or computer-based imaging is inherently subject to moir&eacute; effects and is also susceptible to a uniform mechanism of correction that cannot as readily depend upon adjustment of the pattern of lay-down of the image and must look in another direction of adjustment in the image content to overcome a moir&eacute; defect. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> The present invention provides a unique basis of pixel-by-pixel adjustment to correct moir&eacute; defects in digital imaging, especially images generated from computer-stored digital data. The process comprises providing a digital image comprising a matrix of pixels; dividing the matrix into smaller sub-matrices of pixels; selecting an approximately statistically or physically central pixel or group of pixels within the sub-matrix for adjustment for correction of moir&eacute; effects; selecting at least some pixels that are distal from the central pixel or central group of pixels (distal means non-adjacent, e.g., at least one pixel is present between the central pixel or any group of central pixels and any selected distal pixel or distal group of pixels) and are generally distributed around the central pixel or central group of pixels (e.g., symmetry, near symmetry or surrounding distribution is desired); at least four distal pixels (or pixel groups), preferably at least six distal pixels (or pixel groups), and preferably at least 8 distal pixels (or pixel groups) are selected; an image property (e.g., optical density, specific color optical density, optical reflectance, hue, tone, etc, preferably some quality of optical density) is compared between all or most of the selected distal pixels and the central pixel or central group of pixels; preselecting a number of distal pixels that will be used in creating an adjusting value for the central pixel or central group of pixels (the preselected number may be the number of all of the distal pixels, but is preferably a number less than all of the distal pixels, e.g., between 40% and 75% of all distal pixels); determining which preselected number of distal pixels are the distal pixels with the closest values/properties to the central pixel or central group of pixels to define a relative group of values/properties; averaging the values/properties of the relative group; assigning the average value to the central pixel or central group of pixels; storing the assigned value for that central pixel or central group of pixels; and repeating the analysis and value storage for a different sub-matrix of pixels or for a different pixel or pixel group considered as the central pixel or central group of pixels within the original sub-matrix. This process would be repeated for the same property or for other properties (e.g., the optical density for each color in the image, e.g., cyan, magenta, yellow and black) until a user satisfactory treatment of the image has been performed, including treatment of most or all pixels within the image or repeated treatment of all or most pixels within the image. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> The present invention relates to a method of removing defects from a scanned image or digitized image. In particular it refers to a virtual filter for removing moir&eacute; color bands. The virtual filter (hereinafter merely referred to as a filter or filter window) is in the form of a window that is successively centered over each pixel in the image and the values of various pixels within the window are used to compute a new, corrected value for the central pixel of the window. This new value can conveniently be written to a new output image array in order to leave unaffected the original pixel values of the image, so retaining them for calculations at different positions of the window in the input image. More specifically, the invention concerns a filter window whose size is determined by specific mathematical relationships. Additionally, only certain specific groups of pixels within this filter window are used in the calculation of the corrected pixel value. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The filter window of the invention is a square whose sides are preferably positioned parallel to the horizontal and vertical edges of the image (although skewed, rotated, parallelogram orientations may be used). An example of a non-square, non-rectangular orientation of averaging pixels in the shape of a parallelogram is shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> where the eight averaging pixels in a an eight pixel selection from a 7&times;7 matrix have been rotated from a square symmetrical orientation to form the parallelogram. It is also envisaged that the horizontal axis of the filter window may be oriented at an angle to the horizontal axis of the image, for instance at angles commonly used as screen angles in printing (e.g. 0, 15, 45, 75, 108, 162 degrees). It is further envisaged that different orientations may be used for processing different color channels, or the same orientation may be used for all colors. The width and height of the window is an odd number of pixels such that the window can be approximately or exactly positioned symmetrically and centered on the pixel being corrected. The width and height of the window in pixels is preferably given by the formula 6k&plus;1, where k is an integer greater than zero. Thus, the defined window sizes increase in the series 7, 13, 19, 25, 31, 37, 43, 49, 55 . . . . Within this series of filter windows, along with the center pixel, only the pixels at the comers of the square and the centers of the sides are used to compute corrected pixel values. Thus, for a central pixel p(i,j) having image row and column coordinates i and j respectively, the corner pixels are defined as:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>p</italic></highlight>(<highlight><italic>i&minus;</italic></highlight>3<highlight><italic>k,j&minus;</italic></highlight>3<highlight><italic>k</italic></highlight>), <highlight><italic>p</italic></highlight>(<highlight><italic>i&minus;</italic></highlight>3<highlight><italic>k,j&plus;</italic></highlight>3<highlight><italic>k</italic></highlight>), <highlight><italic>p</italic></highlight>(<highlight><italic>i&plus;</italic></highlight>3<highlight><italic>k,j&minus;</italic></highlight>3<highlight><italic>k</italic></highlight>), <highlight><italic>p</italic></highlight>(<highlight><italic>i&plus;</italic></highlight>3<highlight><italic>k,j&plus;</italic></highlight>3<highlight><italic>k</italic></highlight>)</in-line-formula></paragraph>
<paragraph id="P-0056" lvl="7"><number>&lsqb;0056&rsqb;</number> and the pixels at the centers of the edges of the window are defined as:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>p</italic></highlight>(<highlight><italic>i,j&minus;</italic></highlight>3<highlight><italic>k</italic></highlight>), <highlight><italic>p</italic></highlight>(<highlight><italic>i,j&plus;</italic></highlight>3<highlight><italic>k</italic></highlight>), <highlight><italic>p</italic></highlight>(<highlight><italic>i&minus;</italic></highlight>3<highlight><italic>k,j</italic></highlight>), <highlight><italic>p</italic></highlight>(<highlight><italic>i&plus;</italic></highlight>3<highlight><italic>k,j</italic></highlight>).</in-line-formula></paragraph>
<paragraph id="P-0057" lvl="7"><number>&lsqb;0057&rsqb;</number> The filter window is successively positioned in the image at locations corresponding to i from 1 to h inclusive and, independently, j from 1 to w inclusive, where h is the height of the image in pixels and w is the width of the image in pixels. However, it is not required to use positions corresponding to all combinations of i and j. For example, combined values of i and j can be chosen such that the filter is applied only in regions of the image where color banding is especially visible. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> In a color image, at least three components are required to describe the color, for example a) red, green and blue or b) hue angle, saturation and lightness, though it is possible to use more colors, such as cyan, magenta, yellow and black with subtractive color components. In general, pixel colors can be represented in one of many color spaces, which can be transformed one space to the other. However, it is typical to transform the final image color representation to red, green and blue for display on a monitor or to cyan, magenta, yellow and black for printing. For the practice of this invention, it is advantageous to convert the image to a color space that is an opponent color space prior to applying the window filter. Such a color space has two color axes that approximately correspond to human color vision. Thus, one axis represents approximately colors ranging from yellow to blue and a second axis colors ranging from red to green. The remaining third axis is a measure of the brightness of the color. Such color axes are termed opponent since humans cannot see colors such as yellowish-blue, bluish-yellow, reddish-green or greenish-red. It will be understood by those skilled in the art that there are many color spaces with an approximately opponent property. For the practice of this invention it is sufficient that the color space has only an approximately opponent character and not an exact match to the characteristics of human vision. Examples of such color spaces include YUV, YIQ, YCC, YC<highlight><subscript>b</subscript></highlight>C<highlight><subscript>r </subscript></highlight>and YES. It is also possible to define suitable color spaces by simple arithmetic manipulation of the red (R), green (G) and blue (B) color channels. Thus, a first color axis can be defined as R&minus;G, a second color axis as 0.5(R&plus;G)&minus;B, and a third as 0.33(R&plus;G&plus;B). However, it is desired that the axes of the color space should correspond to similar perceptual color distances. Particularly preferred for the practice of the invention are opponent color spaces with good perceptual uniformity such as CIE L*u*v* or CIE L*a*b*. Most especially preferred is CIE L*a*b*. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> During the operation of the filter, the four pixels at the corners and the four pixels at the centers of the sides of the window are ranked by similarity of color relative to the color of the central pixel p(i,j). Various measures of color difference can be used in a color space with three orthogonal dimensions, such as the Manhattan or city block distance and the Mahalanobis distance. However, it is preferred to use a simple Euclidean or Pythagorean distance computed as the square root of the sum of the squares of the color differences along each of the three axes. In the case of the CIE L*a*b* color space, this Euclidean distance corresponds to the measure known as &Dgr;E, and is particularly preferred. Other variants of &Dgr;E, such as &Dgr;E<highlight><subscript>CMC </subscript></highlight>or &times;E94, are known to represent color differences more according to human perception than does &Dgr;E and can also be used as measures of color difference. However, it has been found that the extra computational effort required to calculate such more perceptually accurate distances does not normally justify itself in improved performance of the filter. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Once the eight pixels have been ranked in order of increasing color difference from the central pixel p(i,j), the colors of a certain number of the pixels with the most similar color to that at p(i,j) are averaged. While it is possible to average from two to seven of the most similar colors, it is preferred to average from three to five of the most similar colors. It is especially preferred to average the four colors that are most similar to the color at p(i,j). This average color becomes the replacement or corrected color at the central pixel p(i,j). While it is possible to compute a weighted average of the selected pixels, it has been found preferable to compute a simple average. In this way, colors can be transferred from one region of the image to another, over large distances, without destroying image detail. The specific differences selected may be based on preselected criteria. For example, if a pixel difference exceeds a specific amount (e.g., the central pixel has a gray scale value of 200, seven of the pixels have gray scale values between 100 and 220, and one pixel has a gray scale value of 10, the software selection criteria may effectively assume that an edge or boundary condition is present and exclude any pixel with such an egregious difference as compared to the other relative differences. With eight pixels or pixel groups selected, the middle six values, the six highest values, the five lowest values, or any other preselected combination may be chosen as the basis for choosing the four, five, six or seven averaging pixels. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Because colors are transferred over large distances the perceived saturation or vividness of the image color can change somewhat, especially when very large filter window sizes are used. For this reason it is preferred to use the smallest window that will remove the color banding. The most usual setting is k 3. In an opponent color space, saturation is approximately represented by the distance of a color from the lightness axis measured perpendicular to this axis. In the CIE L*a*b* color space this distance is referred to as chroma. For the purpose of further discussion the word chroma will be used to describe this distance in any opponent color space. Saturation may also be represented as chroma divided by lightness. It is possible to restore any decreased saturation in a variety of ways, for instance by constructing look-up tables based on the initial chroma histogram and that after processing with the disclosed filter. However, it has been found adequate to restore the saturation in a simpler way as follows. After operation of the disclosed filter, for every pixel in the image the chroma, C, is calculated and the maximum chroma in the image, C<highlight><subscript>max</subscript></highlight>, is estimated. Then corrected chroma values, C<highlight><subscript>corr</subscript></highlight>, are calculated according to: C<highlight><subscript>corr</subscript></highlight>&equals;C<highlight><subscript>max</subscript></highlight>&middot;(C/C<highlight><subscript>max</subscript></highlight>)<highlight><superscript>1/x</superscript></highlight>. The quantity x can range from about 1.01 to about 1.60, but the preferred value is around 1.2. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Reference to the Figures will assist in a further understanding and appreciation of the present invention. <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a very simple sub-matrix for use in adjusting individual pixel density according to the present invention. <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a 7&times;7 sub-matrix. A central pixel C is shown within the 7&times;7 sub-matrix. Eight surrounding distal pixels X (which are shown as symmetrically disposed, but they may be somewhat weighted, as discussed later, or not completely symmetrical, as discussed later) are shown. A simple performance of the process of the invention would be to measure the optical density of C and the optical density of each X. The optical densities of each X would be compared to the optical density of C. Either all of the optical densities of the X pixels would be averaged to produce a relative property value, or less than the number of all of the distal pixels X would be used and averaged to define a relative property value. The number may be preselected in a number of different ways, such as choosing from N distal pixels, N&minus;1 pixels, N&minus;2 pixels, N&minus;3 pixels, N&minus;4 pixels, N/2 pixels, N/2&plus;1 pixels, N/2&minus;1 pixels, or the like. The basis of selecting the specific pixels used in effecting the relative property value could be the selection of those pixels having the closest property value to that of the central pixel, the farthest value from the value of the central pixel, or weighted values tending towards a lower value (e.g., in selecting six distal pixels, selecting the closest four lower values and the two closest higher values) or towards higher values (e.g., in selecting four distal pixels, selecting the closest higher three value pixels and the closest lower one value pixel). The selected pixels would then be number averaged or weight averaged for the property to define a relative value for the central pixel C. That value would then be assigned to the stored data for the sub-matrix and for the image of which the sub-matrix and the pixel is a component. The procedure would be repeated for as many pixels as desired, as many matrices as desired, a percentage of pixels or all of the pixels within the image or a defined image area (e.g., a section where moir&eacute; appears). </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is very similar to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, showing a 13&times;13 matrix with the center pixel C identified and eight distal pixels X identified. Again, the distribution of distal pixels X is shown as symmetric, but that is not essential although it is desirable. For example, all or some of the distal pixels could be shifted (0,1), (1,0), (1,1), (1,&minus;1), (0,2) or (2,0) units or the like along Cartesian coordinates. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a matrix that includes a number of sub-matrices. The distal pixels X relate to central pixel C. The distal pixels B<highlight><subscript>4 </subscript></highlight>relate to central pixel C<highlight><subscript>4</subscript></highlight>. The distal pixels B<highlight><subscript>3 </subscript></highlight>relate to central pixel C<highlight><subscript>3</subscript></highlight>. The distal pixels B<highlight><subscript>2 </subscript></highlight>relate to central pixel C<highlight><subscript>2</subscript></highlight>. The distal pixels B<highlight><subscript>1 </subscript></highlight>relate to central pixel C<highlight><subscript>1</subscript></highlight>. As mentioned earlier, rather than selecting only single central pixels (e.g., C), central groups of pixels could be used in the moir&eacute; reduction process of the invention. As shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, this could be done by selecting all of pixels C, C<highlight><subscript>1</subscript></highlight>, C<highlight><subscript>2</subscript></highlight>, C<highlight><subscript>3</subscript></highlight>, and C<highlight><subscript>4 </subscript></highlight>(and or other closely positioned or adjacent pixels) as a central pixel group, and assigning a relative value determined by averaging values from distal pixels that may comprise all distal pixels shown (e.g., X, X<highlight><subscript>1</subscript></highlight>, X<highlight><subscript>2</subscript></highlight>, X<highlight><subscript>3</subscript></highlight>, and X<highlight><subscript>4</subscript></highlight>), or less than all distal pixels (e.g., only one of X, X<highlight><subscript>1</subscript></highlight>, X<highlight><subscript>2</subscript></highlight>, X<highlight><subscript>3</subscript></highlight>, and X<highlight><subscript>4</subscript></highlight>, more than one but less than all of (e.g., X, X<highlight><subscript>1</subscript></highlight>, X<highlight><subscript>2</subscript></highlight>, X<highlight><subscript>3</subscript></highlight>, and X<highlight><subscript>4</subscript></highlight>), or other combinations of these or other distal pixels. It is also possible to have some adjacent pixels considered in the averaging, as where in treating C<highlight><subscript>1</subscript></highlight>, one or more of C and C<highlight><subscript>3 </subscript></highlight>could be used as an averaging pixel. It is preferred that at least half, at least &frac23;, at least &frac34;, at least &frac78; or all averaging pixels are distal pixels as defined in the present invention. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of reducing image defects in a digital image comprising: 
<claim-text>providing a digital image data set in the form of a matrix of pixels; </claim-text>
<claim-text>selecting a sub-matrix comprising at least a 5&times;5 matrix of pixels; </claim-text>
<claim-text>identifying a pixel within the sub-matrix to be treated as a central pixel; </claim-text>
<claim-text>determining a value for at least one optical property in the central pixel; </claim-text>
<claim-text>selecting at least four pixels around the central pixel as averaging pixels, at least two of the averaging pixels being in a position in the sub-matrix that is not adjacent the position in the matrix of the central pixel; </claim-text>
<claim-text>determining a value for the at least one optical property for the at least four averaging pixels; </claim-text>
<claim-text>averaging the values for the at least one optical property for more than one of the at least four averaging pixels to provide an average treatment value for the central pixel; </claim-text>
<claim-text>assigning the average treatment value for the central pixel to the central pixel; and </claim-text>
<claim-text>storing the average treatment value assigned to the central pixel. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the matrix is an at least 7&times;7 matrix of pixels. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein at least six averaging pixels are selected. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein at least eight averaging pixels are selected. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein more than one but less than all averaging pixels are used to determine the average treatment value. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference> wherein more than one but less than all averaging pixels are used to determine the average treatment value. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein at least three averaging pixels are pixels that are not in a position adjacent in the matrix to the central pixel. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein at least four averaging pixels are pixels that are not in a position adjacent in the matrix to the central pixel. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein all averaging pixels are pixels that are not in a position adjacent in the matrix to the central pixel. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein all averaging pixels are pixels that are not in a position adjacent in the matrix to the central pixel. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein average treatment values are defined, assigned and stored for at least 20% of the pixels in the digital image. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference> wherein average treatment values are defined, assigned and stored for at least 20% of the pixels in the digital image. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein average treatment values are defined, assigned and stored for at least 20% of the pixels in the digital image. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein average treatment values are defined, assigned and stored for at least 80% of the pixels in the digital image. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein average treatment values are defined, assigned and stored for at least 80% of the pixels in the digital image. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the central pixel comprises a group of pixels that is less than all pixels in the sub-matrix. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein the central pixel comprises a group of pixels that is less than all pixels in the sub-matrix. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> wherein the central pixel comprises a group of pixels that is less than all pixels in the sub-matrix. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein for at least some pixels in the image, the saturation of the at least some pixels is further modified following assigning the average treatment value for the central pixel to the central pixel. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein for at least some pixels in the image, the chroma, C, is calculated and the maximum chroma in the image, C<highlight><subscript>max</subscript></highlight>, is estimated, using C<highlight><subscript>max </subscript></highlight>to determine corrected chroma values C<highlight><subscript>corr </subscript></highlight>according to the formula:</claim-text>
<claim-text><in-line-formula><highlight><italic>C</italic></highlight><highlight><subscript>corr</subscript></highlight><highlight><italic>&equals;C</italic></highlight><highlight><subscript>max</subscript></highlight>&middot;(<highlight><italic>C/C</italic></highlight><highlight><subscript>max</subscript></highlight>)<highlight><superscript>1/x</superscript></highlight>.,</in-line-formula></claim-text>
<claim-text>wherein x is from about 1.01 to about 1.60, and these corrected chroma values are stored as at least part of stored image data. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference> wherein all C<highlight><subscript>corr </subscript></highlight>for all pixels in the image are determined and stored. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein selecting a sub-matrix comprising at least a 5&times;5 matrix of pixels comprises selecting a square filter of width 6k&plus;1 pixels, where k is an integer greater than zero, positioned approximately centrally on an image pixel. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference> wherein 6k&plus;1 is 7, and wherein from 2 to 7 pixels are selected from the group of 8 pixels constituting comers and centers of the sides of the square, and the 2 to 7 pixels are used to compute a new corrected color value for the image pixel. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference> wherein 6k&plus;1 is selected from the group consisting of 7, 13, 19, and 25 and wherein from 2 to 13 pixels are selected from the group of total pixels in the square and the <highlight><bold>2</bold></highlight> to <highlight><bold>13</bold></highlight> pixels comprise at least some comers and centers of the sides of the square, and the 2 to 7 pixels are used to compute a new corrected color value for the image pixel. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference> wherein corrected values are determined by averaging values from the 2 to 7 pixels. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein from 4 to 13 pixels are averaged to determine the corrected values. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein at least 8 pixels are averaged to determine corrected values. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. A computer with imaging system associated therewith, the computer containing software therein that directs a process for improving image defects comprising: 
<claim-text>providing a digital image data set in the form of a matrix of pixels; </claim-text>
<claim-text>selecting a sub-matrix comprising at least a 5&times;5 matrix of pixels; </claim-text>
<claim-text>identifying a pixel within the sub-matrix to be treated as a central pixel; </claim-text>
<claim-text>determining a value for at least one optical property in the central pixel; </claim-text>
<claim-text>selecting at least four pixels around the central pixel as averaging pixels, at least two of the averaging pixels being in a position in the sub-matrix that is not adjacent the position in the matrix of the central pixel; </claim-text>
<claim-text>determining a value for the at least one optical property for the at least four averaging pixels; </claim-text>
<claim-text>averaging the values for the at least one optical property for more than one of the at least four averaging pixels to provide an average treatment value for the central pixel; </claim-text>
<claim-text>assigning the average treatment value for the central pixel to the central pixel; </claim-text>
<claim-text>storing the average treatment value assigned to the central pixel; and </claim-text>
<claim-text>displaying the image with the stored average treatment value displayed in the image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The computer with imaging system of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> wherein the matrix is an at least 7&times;7 matrix of pixels and at least eight averaging pixels are selected. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The computer with imaging system of <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> wherein the matrix is an at least 7&times;7 matrix of pixels and average treatment values are defined, assigned and stored for at least 80% of the pixels in the digital image. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. The computer with imaging system of <dependent-claim-reference depends_on="CLM-00033">claim 30</dependent-claim-reference> wherein the central pixel comprises a group of pixels that is less than all pixels in the sub-matrix. </claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. The computer with imaging system of <dependent-claim-reference depends_on="CLM-00033">claim 30</dependent-claim-reference> wherein average treatment values are defined, assigned and stored for at least 80% of the pixels in the digital image and the central pixel comprises a group of pixels that is less than all pixels in the sub-matrix. </claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. The computer with imaging system of <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference> wherein the matrix is an at least 7&times;7 matrix of pixels, average treatment values are defined, assigned and stored for approximately 100% of pixels in the digital image and eight averaging pixels are selected for each pixel for which average treatment values are assigned. </claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. A method of reducing moir&eacute; defects in a digital image comprising: 
<claim-text>providing a digital image data set in the form of a matrix of pixels; </claim-text>
<claim-text>selecting a sub-matrix comprising at least a 5&times;5 matrix of pixels; </claim-text>
<claim-text>identifying a pixel within the sub-matrix to be treated as a central pixel; </claim-text>
<claim-text>determining a value for at least one optical property in the central pixel; </claim-text>
<claim-text>selecting at least four pixels around the central pixel as averaging pixels, at least two of the averaging pixels being in a position in the sub-matrix that is not adjacent the position in the matrix of the central pixel; </claim-text>
<claim-text>determining a value for the at least one optical property for the at least four averaging pixels; </claim-text>
<claim-text>averaging the values for the at least one optical property for more than one of the at least four averaging pixels to provide an average treatment value for the central pixel; </claim-text>
<claim-text>assigning the average treatment value for the central pixel to the central pixel; and </claim-text>
<claim-text>storing the average treatment value assigned to the central pixel.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002747A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002747A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002747A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002747A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002747A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
