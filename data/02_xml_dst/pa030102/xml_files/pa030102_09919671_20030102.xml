<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002732A1-20030102-D00000.TIF SYSTEM "US20030002732A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00001.TIF SYSTEM "US20030002732A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00002.TIF SYSTEM "US20030002732A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00003.TIF SYSTEM "US20030002732A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00004.TIF SYSTEM "US20030002732A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00005.TIF SYSTEM "US20030002732A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00006.TIF SYSTEM "US20030002732A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00007.TIF SYSTEM "US20030002732A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00008.TIF SYSTEM "US20030002732A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00009.TIF SYSTEM "US20030002732A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00010.TIF SYSTEM "US20030002732A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00011.TIF SYSTEM "US20030002732A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00012.TIF SYSTEM "US20030002732A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00013.TIF SYSTEM "US20030002732A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00014.TIF SYSTEM "US20030002732A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030002732A1-20030102-D00015.TIF SYSTEM "US20030002732A1-20030102-D00015.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002732</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>09919671</doc-number>
</application-number>
<application-number-series-code>09</application-number-series-code>
<filing-date>20010731</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06K009/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>382</class>
<subclass>164000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method and apparatus for digital image segmentation using an iterative method</title-of-invention>
</technical-information>
<continuity-data>
<non-provisional-of-provisional>
<document-id>
<doc-number>60222834</doc-number>
<document-date>20000804</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Phil</given-name>
<family-name>Gossett</family-name>
</name>
<residence>
<residence-us>
<city>Mountain View</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Edward</given-name>
<family-name>Ratner</family-name>
</name>
<residence>
<residence-us>
<city>Sunnyvale</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>TOWNSEND AND TOWNSEND AND CREW, LLP</name-1>
<name-2></name-2>
<address>
<address-1>TWO EMBARCADERO CENTER</address-1>
<address-2>EIGHTH FLOOR</address-2>
<city>SAN FRANCISCO</city>
<state>CA</state>
<postalcode>94111-3834</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A digital image is divided into segments, wherein the digital image comprises an array of pixels each having a pixel location and a pixel color value. A method comprises obtaining an image frame comprising an array of pixels each having a pixel color value, assigning an initial segment identifier to each pixel in the image frame independent of each pixel&apos;s pixel color value, testing, using an appropriateness test, pixels for possible reassignment from a current segment to a neighboring segment, and if the appropriateness test indicates a pixel should be reassigned, reassigning the segment identifier of the pixel. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">CROSS-REFERENCES TO RELATED APPLICATIONS </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present disclosure is related to the following: </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> U.S. Pat. No. ______ &lsqb;U.S. patent application Ser. No. 09/550,705, filed Apr. 17, 2000 and entitled &ldquo;Method and Apparatus for Efficient Video Processing&rdquo;&rsqb; (hereinafter &ldquo;Prakash I&rdquo;). </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> U.S. Pat. No. ______ &lsqb;U.S. patent application Ser. No. 09/591,438, filed Jun. 9, 2000 and entitled &ldquo;Method and Apparatus for Digital Image Segmentation&rdquo;&rsqb; (hereinafter &ldquo;Prakash II&rdquo;). </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> The present disclosure claims priority from: </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> U.S. Provisional Patent Application No. 60/222,834, filed Aug. 4, 2000 and entitled &ldquo;Grid-Based Segmentation.&rdquo;</paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The disclosures of each of the above are hereby incorporated by reference for all purposes.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Image segmentation is the process of partitioning an image into a set of non-overlapping parts, or segments, that together constitute the entire image. Image segmentation is useful for many applications, one of which is compression. For example, it is well known that if an image made up of pixels with the image represented by pixel color values for each of the pixels, the image representation can be compressed if contexts for the pixels can be extracted and used in representing the pixel color values. Thus, if a pixel color value can be one of 256 color values, it can be represented by eight bits, but if a pixel color value is more likely to be a given color value in view of surrounding color values (e.g., in many images, a pixel surrounded by a field of blue pixels is likely to be a blue pixel), then those pixel color values can be represented, on average, in fewer than eight bits. Compression results are likely to be improved if the pixels used for context are actually the context of the pixel being compressed and not pixels that are independent of the pixel being compressed. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Segmentation is helpful in determining which pixels are likely to be related enough to other pixels such that related pixels are used for context with more weight than unrelated pixels. While segmentation is useful for compression, segmentation is also useful for other applications, some of which are mentioned here. For example, a computer program that is not doing compression might process each segment of an image in a manner specific to that segment or associate different data, such as labels, with different segments. In any case, correctly segmenting the image is important for proper operation of the process being performed on the image. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> As the terms are used herein, an image is an array of pixel color values such that pixels placed in an array and colored according to each pixel&apos;s color value would represent the image. Each pixel has a location and can be thought of as being a point at that location or as a shape that fills the area around the pixel such that any point within the image is considered to be &ldquo;in&rdquo; a pixel&apos;s area or considered to be part of the pixel. The image itself might be a multidimensional pixel array on a display, on a printed page, an array stored in memory, or a data signal being transmitted and representing the image. The multidimensional pixel array can be a two-dimensional array for a two-dimensional image, a three-dimensional array for a three-dimensional image, or some other number of dimensions. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The image can be an image of a physical space or plane or an image of a simulated and/or computer-generated space or plane. In the computer graphic arts, a common image is a two-dimensional view of a computer-generated three-dimensional space (such as a geometric model of objects and light sources in a three-space). An image can be a single image or one of a plurality of images that, when arranged in a suitable time order, form a moving image, herein referred to as a video sequence. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> When an image is segmented, the image is represented by a plurality of segments. The degenerate case of a single segment comprising the entire image is within the definition of segment used here, but the typical segmentation divides an image into at least two segments. In many images, the segmentation divides the image into a background segment and one or more foreground segments. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In one segmentation method, an image is segmented such that each segment represents a region of the image where the pixel color values are more or less uniform within the segment, but dramatically change at the edges of the image. In that implementation, the regions are connected, i.e., it is possible to move pixel-by-pixel from any one pixel in the region to any other pixel in the region without going outside the region. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Pixel color values can be selected from any number of pixel color spaces. One color space in common use is known as the YUV color space, wherein a pixel color value is described by the triple (Y, U, V), where the Y component refers to a grayscale intensity or luminance, and U and V refer to two chrominance components. The YUV color space is commonly seen in television applications. Another common color space is referred to as the RGB color space, wherein R, G and B refer to the Red, Green and Blue color components, respectively. The RGB color space is commonly seen in computer graphics representations, along with CYMB (cyan, yellow, magenta, black) often used with computer printers. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> An example of image segmentation is illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. There, an image frame <highlight><bold>10</bold></highlight> contains an oval <highlight><bold>12</bold></highlight>, a rectangle <highlight><bold>14</bold></highlight> and a triangle <highlight><bold>16</bold></highlight> on a background <highlight><bold>18</bold></highlight>. The image can be segmented into segments based on colors (the shading of the oval <highlight><bold>12</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> represents a color distinct from the colors of the rectangle <highlight><bold>14</bold></highlight>, the triangle <highlight><bold>16</bold></highlight> or the background <highlight><bold>18</bold></highlight>). Thus, the oval <highlight><bold>12</bold></highlight>, the rectangle <highlight><bold>14</bold></highlight>, the triangle <highlight><bold>16</bold></highlight> and the background <highlight><bold>18</bold></highlight> are segmented into separate segments in this example. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In this example, if each segment has a very distinct color and the objects in the image <highlight><bold>10</bold></highlight> end cleanly at pixel boundaries, segmentation is a simple process. In general, however, generating accurate image segments is a difficult problem and there is much open research on this problem, such as in the field of &ldquo;computer vision&rdquo; research. One reason segmentation is often difficult is that a typical image includes noise introduced from various sources including, but not limited to, the digitization process when the image is captured by physical devices and the image also includes regions that do not have well-defined boundaries. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> There are several ways of approaching the task of image segmentation, which can generally be grouped into the following: 1) histogram-based segmentation; 2) traditional edge-based segmentation; 3) region-based segmentation; and 4) hybrid segmentation, in which several of the other approaches are combined. Each of these approaches is described below. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> 1. Histogram-Based Segmentation </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> Segmentation based upon a histogram technique relies on the determination of the color distribution in each segment. This technique uses only one color plane of the image, typically an intensity color plane (also referred to as the greyscale portion of the image), for segmentation. To perform the technique a processor creates a histogram of the pixel color values in that plane. A histogram is a graph with a series of &ldquo;intervals&rdquo; each representing a range of values arrayed along one axis and the total number of occurrences of the values within each range shown along the other axis. The histogram can be used to determine the number of pixels in each segment, by assuming that the color distribution within each segment will be roughly a Gaussian, or bell-shaped, distribution and the color distribution for the entire image will be a sum of Gaussian distributions. Histogram-based techniques attempt to recover the individual Gaussian curves by varying the size of the intervals, i.e., increasing or decreasing the value range, and looking for high or low points. Once the distributions have been ascertained, the each pixel is assigned to the segment with its corresponding intensity range. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> The histogram method is fraught with errors. The fundamental assumption that the color distribution is Gaussian is at best a guess, which may not be accurate for all images. In addition, two separate regions of identical intensity will be considered the same segment. Further, the Gaussian distributions recovered by the histogram are incomplete in that they cut off at the ends, thus eliminating some pixels. Further, this method of segmentation is only semi-automatic, in that the technique requires that the number of segments are previously known and that all of the segments are all roughly the same size. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> 2. Traditional Edge-Based Segmentation </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Traditional edge-based segmentation uses differences in color or greyscale intensities to determine edge pixels that delineate various regions within an image. This approach typically assumes that when edge pixels are identified, the edge pixels will completely enclose distinct regions within the image, thereby indicating the segments. However, traditional edge detection techniques often fail to identify all the pixels that are in fact edge pixels, due to noise in images or other artifacts. If some edge pixels are missed, some plurality of distinct regions might be misidentified as being a single segment. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> 3. Region-Based Segmentation </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Region based segmentation attempts to detect homogenous regions and designate them as segments. One class of region-based approaches starts with small uniform regions within the image and tries to merge neighboring regions that are of very close color value in order to form larger regions. Conversely, another class of region-based approaches starts with the entire image and attempts to split the image into multiple homogeneous regions. Both of these approaches result in the image being split at regions where some homogeneity requirements are not met. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The first class of region based segmentation approaches is limited in that the segment edges are approximated depending on the method of dividing the original image. A problem with the second class of region based approaches is that the segments created tend to be distorted relative to the actual underlying segments. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> 4. Hybrid Segmentation </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> The goal of hybrid techniques is to combine processes from multiple previous segmentation processes to improve image segmentation. Most hybrid techniques are a combination of edge segmentation and region-based segmentation, with the image being segmented using one of the processes and being continued with the other process. The hybrid techniques attempt to generate better segmentation than a single process alone. However, hybrid methods have proven to require significant user guidance and prior knowledge of the image to be segmented, thus making then unsuitable for applications requiring fully automated segmentation. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The present invention provides an exemplary method and apparatus for digital image segmentation. For example, in one embodiment, a plurality of segments are created from a digital image frame using grid-based segmentation. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> Accordingly, in one embodiment, a digital image comprised of an array of pixels each having a pixel location and a pixel color value, is divided into regularly ordered segments. A method comprises obtaining an image frame, assigning an initial segment identifier to each pixel in the image frame independent of each pixel&apos;s color value, testing, using an appropriateness test, pixels for possible reassignment from a current segment to a neighboring segment, and if the appropriateness test indicates a pixel should be reassigned, reassigning the segment identifier of the pixel. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> In another embodiment, a digital image is divided into segments, wherein the digital image comprises an array of pixels each having a pixel location and a pixel color value. A method comprises obtaining an image frame comprising an array of pixels each having a pixel color value, overlaying a logical grid over the image data such that initially each subsection of the grid encompasses at least two pixels, and adjusting the grid subsection boundaries to create at least one segment. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> A further understanding of the nature and advantages of the inventions herein may be realized by reference to the remaining portions of the specification and the attached drawings.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF DRAWINGS </heading>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates an example of a digital image segmentation. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates an example of an overlaid grid. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates an example of a partially adjusted overlaid grid. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates an example of an adjusted overlaid grid. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is an image frame with an overlaid grid. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates two subsections and how average pixel values can be computed. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7A</cross-reference> illustrates border pixels which are to be considered for reassignment. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7B</cross-reference> illustrates a logical grid being changed in shape. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8A</cross-reference> illustrates a border pixel of intermediate value </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8B</cross-reference> illustrates a logical grid being changed in shape due to inclusion of a border pixel of intermediate value </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8C</cross-reference> illustrates a logical grid remaining unchanged due to the value of the border pixel </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9A</cross-reference> illustrates an outlier problem. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9B</cross-reference> illustrates one outlier pixel being identified. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9C</cross-reference> illustrates an outlier pixel in an adjacent segment being identified. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> illustrates a resulting segment identifier map.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE EMBODIMENTS </heading>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> With reference to the exemplary drawings wherein like reference numerals indicate like or corresponding elements among the figures, embodiments of a system according to the present invention will now be described in detail. In one aspect, segmentation is used as an integral portion of a video delivery platform fully described in Prakash I and Prakash II. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Referring to FIGS. <highlight><bold>2</bold></highlight>-<highlight><bold>4</bold></highlight>, one embodiment of a grid-based segmentation process is illustrated. A method and apparatus are provided for the creation of segments from a digital image. The method includes obtaining a digital image comprising an array of pixels, each pixel being described by a location, a color value and an initial segment identifier (i.e., something that indicates to which segment each pixel belongs). </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> A given digital frame is first divided into a grid of segments independent of the image contents. In one embodiment, the grid comprises a plurality of rectangles. For purposes of illustration, 16 rectangles are shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>; however, in practice the frame may be divided into any number of rectangles. For example, the frame may be divided into 2000 rectangles. A process is then applied, as described in more detail below, to adjust the boundaries of the grid rectangles based on the underlying pixel values. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a partial adjustment of the boundaries and <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a final adjustment of the boundaries such that the boundaries define segments and pixels within a given segment have substantially uniform color values. A segmentation mask is thus produced. It should be noted that a segmentation mask, also referred to as a logical mask or simply a mask for the purposes of this patent, can be of the shape of the initial grid or it can take on various different shapes. In one embodiment, the rectangles take on amorphous shapes by adjusting pixels on the boundaries one at a time, as will be described below. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates a digital image comprising white and black image pixels. In one specific embodiment, white pixels have a value of 255, while black pixels have a value of 0. It should be noted that embodiments according to the present invention are not limited to black and white pixels, but may relate to pixels of varying colors. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> A logical mask <highlight><bold>51</bold></highlight> is overlaid on the image. The logical mask divides the image frame into at least one image region and likely a plurality of image regions, the sum of which equals the original image frame. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> In one embodiment, the boundaries of the logical mask exist between the image pixels. In another embodiment of the invention, some mask boundaries intersect pixels. The logical mask can be a grid or take on other arrangements. Within each subsection of the grid preferably at least two image pixels are initially contained. Each subsection is assigned a unique identifier, shown in the upper left corner of each subsection. Since each pixel is within a given subsection, each pixel has associated with it one of the unique identifiers. In one embodiment, the unique identifier is represented numerically. In embodiments where subsection boundaries can intersect pixels, those intersected pixels are assigned to one subsection according to a predefined rule. For example, a pixel might be assigned to the leftmost subsection it is at least partially in and to the upper subsection it is in when the pixel is intersected by a horizontal boundary. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates how pixels are reassigned to different subsections. The illustration relates to two adjacent subsections, namely subsections <highlight><bold>60</bold></highlight> and <highlight><bold>61</bold></highlight>. Subsection <highlight><bold>60</bold></highlight> comprises nine pixels, each having a pixel value of 255 (show as white pixels). Subsection <highlight><bold>61</bold></highlight> comprises two pixels having pixel values of 0 and seven having pixel values of 255 (shown as black pixels and white pixels, respectively). </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> In one embodiment, an image processor computes a representative value (median, average, etc.) of the pixel values in subsection <highlight><bold>60</bold></highlight>. This average value is 255. Similarly, the average pixel value of subsection <highlight><bold>61</bold></highlight> is computed to be approximately 198. In this case, the black pixels (each having a value of 0) are not reassigned because 198 is closer to 0 than is 255. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> In another embodiment, the image processor takes a representative value of the pixel values in subsections <highlight><bold>60</bold></highlight> and <highlight><bold>61</bold></highlight>, which are sufficiently proximate to a border pixel to be considered. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7A</cross-reference> illustrates border pixels which are to be considered for identifier reassignment. The white border pixels marked <highlight><bold>73</bold></highlight> each have a value of 255, which is closer to the average pixel value of subsection <highlight><bold>70</bold></highlight> than the average pixel value of subsection <highlight><bold>71</bold></highlight>. Similarly, the black border pixels marked <highlight><bold>74</bold></highlight> each have a value of zero, which is closer to the average pixel value of subsection <highlight><bold>71</bold></highlight> than subsection <highlight><bold>70</bold></highlight>. Thus pixels <highlight><bold>73</bold></highlight> and <highlight><bold>74</bold></highlight> retain their original subsection identifiers. However, pixel <highlight><bold>75</bold></highlight>, a white pixel in subsection <highlight><bold>71</bold></highlight>, has a value of 255, which is closer to the average values in subsection <highlight><bold>70</bold></highlight>. Therefore, the segment identifier of pixel <highlight><bold>75</bold></highlight> is changed to reflect inclusion in subsection <highlight><bold>70</bold></highlight>. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7B</cross-reference> illustrates the new shape of the logical mask. Pixel <highlight><bold>75</bold></highlight> is now within grid <highlight><bold>70</bold></highlight>. This is repeated until the process converges, i.e., until the boundaries do not change in an adjustment pass over the image anymore or the boundaries change less than a threshold amount. These subsections are now known as segments. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 8A, B</cross-reference> and C illustrate the method assigning segment identifiers to pixels that are intermediate in value. One embodiment of a gray pixel is illustrated in <cross-reference target="DRAWINGS">FIG. 8A</cross-reference> where, pixel <highlight><bold>82</bold></highlight> has a value closer to the average value of the pixels in subsection <highlight><bold>80</bold></highlight> than in subsection <highlight><bold>81</bold></highlight>. Hence, as illustrated in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>B, pixel <highlight><bold>82</bold></highlight> is assigned to subsection <highlight><bold>80</bold></highlight> and the shape of subsection <highlight><bold>80</bold></highlight> is changed as result of the inclusion of pixel <highlight><bold>82</bold></highlight>. In another embodiment, the gray pixel <highlight><bold>85</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>C, has a value closer to the average value of subsection <highlight><bold>84</bold></highlight> than that of subsection <highlight><bold>83</bold></highlight>. Hence the segment identifier of pixel <highlight><bold>85</bold></highlight> is not changed and pixel <highlight><bold>85</bold></highlight> remains a part of subsection <highlight><bold>84</bold></highlight>. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9A</cross-reference> illustrates the outlier problem. In this case Pixel <highlight><bold>93</bold></highlight> has a value close to the average pixel value of segment <highlight><bold>92</bold></highlight>, while Pixel <highlight><bold>94</bold></highlight> has a value close to the average pixel value of segment <highlight><bold>91</bold></highlight>. In this case pixel <highlight><bold>93</bold></highlight> is temporarily assigned to subsection <highlight><bold>92</bold></highlight> as depicted in <cross-reference target="DRAWINGS">FIG. 9B</cross-reference>. At the same time, pixel <highlight><bold>94</bold></highlight> is temporarily assigned to subsection <highlight><bold>91</bold></highlight> as depicted in <cross-reference target="DRAWINGS">FIG. 9C</cross-reference>. It is important to note that this the segment assignment illustrated in <cross-reference target="DRAWINGS">FIGS. 9B and 9C</cross-reference> is only temporary and they occur simultaneously. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> In one embodiment, an outlier pass is performed subsequent to the temporary segment assignment depicted in <cross-reference target="DRAWINGS">FIGS. 9 B and C</cross-reference>. This process checks for segment boundaries that are not continuous. This is precisely the case that arises in segment <highlight><bold>91</bold></highlight> and segment <highlight><bold>92</bold></highlight> where pixel <highlight><bold>93</bold></highlight> temporarily belongs to subsection <highlight><bold>92</bold></highlight> although it is not connected to segment <highlight><bold>92</bold></highlight> and pixel <highlight><bold>94</bold></highlight> temporarily belongs to subsection <highlight><bold>91</bold></highlight> although it is not connected to segment <highlight><bold>91</bold></highlight>. Such disconnected segments are not allowable. This step corrects the situation of disconnected segments by reassigning the segment boundaries and returning pixel <highlight><bold>93</bold></highlight> to segment <highlight><bold>91</bold></highlight> and pixel <highlight><bold>94</bold></highlight> to segment <highlight><bold>92</bold></highlight>. Thus the segment assignment illustrated in <cross-reference target="DRAWINGS">FIG. 9A</cross-reference> is restored. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> illustrates the resulting segment identifier map from the original image. All of the black pixels are together with a certain segment identifier. The white pixels are in a plurality of subsections. Any outliers have been changed appropriately. In one embodiment, the invention employs a gluing pass to reduce the number of segments by gluing segments of similar pixel value characteristics together. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> The above description is illustrative and not restrictive. The scope of the invention should, therefore, be determined not with reference to the above description, but instead should be determined with reference to the appended claims along with their full scope of equivalents. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of dividing a digital image into segments, wherein the digital image comprises an array of pixels each having a pixel location and a pixel color value, the method comprising: 
<claim-text>obtaining an image frame comprising an array of pixels each having a pixel color value; </claim-text>
<claim-text>assigning an initial segment identifier to each pixel in the image frame independent of each pixel&apos;s pixel color value; </claim-text>
<claim-text>testing, using an appropriateness test, pixels for possible reassignment from a current segment to a neighboring segment; and </claim-text>
<claim-text>if the appropriateness test indicates a pixel should be reassigned, reassigning the segment identifier of the pixel. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising reassigning the pixel color of outlier pixels to the representative color of the immediately adjacent pixels. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the pixel segment identifier is based upon the pixel&apos;s location with a logical grid, the logical grid having a unique segment identifier corresponding initially to a logical grid section. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein reassigning comprises: 
<claim-text>obtaining a boundary pixel, wherein a boundary pixel is a pixel located proximate to a pixel having a different segment identifier than that of the boundary pixel; </claim-text>
<claim-text>considering pixel values in a neighborhood adjacent to the boundary pixel; </claim-text>
<claim-text>logically grouping the neighboring pixels by commonality of segment identifiers; </claim-text>
<claim-text>computing a representative color value for each pixel group; and </claim-text>
<claim-text>reassigning the segment identifier of the boundary pixel to match the group whose representative color value most closely matches the color of the boundary pixel. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising repeating the steps of testing and reassigning until the segment boundaries converge such that the testing step results in no possible reassignments. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising repeating the steps of testing and reassigning until the segment boundaries converge such that the testing step results in less than a threshold amount of reassignment. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein the threshold amount of reassignment is measured as a predetermined number of pixels. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A method of dividing a digital image into segments, wherein the digital image comprises an array of pixels each having a pixel location and a pixel color value, the method comprising: 
<claim-text>obtaining an image frame comprising an array of pixels each having a pixel color value; </claim-text>
<claim-text>overlaying a logical grid over the image data such that initially each subsection of the grid encompasses at least two pixels; and </claim-text>
<claim-text>adjusting the grid subsection boundaries to create at least one segment. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein moving further comprises the steps of: 
<claim-text>obtaining a boundary pixel; </claim-text>
<claim-text>considering pixel values in the grid subsections adjacent to and including the boundary pixel; </claim-text>
<claim-text>computing a representative pixel color value for each considered grid subsection; and </claim-text>
<claim-text>adjusting the grid subsection boundaries such that the considered boundary pixel is associated with the grid subsection with the closest color value to the boundary pixel&apos;s color value. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, the method further comprising reassigning the pixel color of outlier pixels to a representative color of immediately adjacent pixels. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein considering the pixels comprises considering only the pixels within a given neighborhood of the boundary pixel.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>3</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002732A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002732A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002732A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002732A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002732A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002732A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002732A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002732A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002732A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030002732A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030002732A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030002732A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030002732A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030002732A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030002732A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030002732A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
