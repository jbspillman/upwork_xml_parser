<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001852A1-20030102-D00000.TIF SYSTEM "US20030001852A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00001.TIF SYSTEM "US20030001852A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00002.TIF SYSTEM "US20030001852A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00003.TIF SYSTEM "US20030001852A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00004.TIF SYSTEM "US20030001852A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00005.TIF SYSTEM "US20030001852A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00006.TIF SYSTEM "US20030001852A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00007.TIF SYSTEM "US20030001852A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00008.TIF SYSTEM "US20030001852A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00009.TIF SYSTEM "US20030001852A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00010.TIF SYSTEM "US20030001852A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00011.TIF SYSTEM "US20030001852A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00012.TIF SYSTEM "US20030001852A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00013.TIF SYSTEM "US20030001852A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030001852A1-20030102-D00014.TIF SYSTEM "US20030001852A1-20030102-D00014.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001852</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10013050</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20011112</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F013/14</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G09G005/39</ipc>
</classification-ipc-secondary>
<classification-ipc-secondary>
<ipc>G06T001/20</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>345</class>
<subclass>531000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>345</class>
<subclass>506000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>3-D rendering engine with embedded memory</title-of-invention>
</technical-information>
<continuity-data>
<non-provisional-of-provisional>
<document-id>
<doc-number>60248159</doc-number>
<document-date>20001112</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Mika</given-name>
<middle-name>Henrik</middle-name>
<family-name>Tuomi</family-name>
</name>
<residence>
<residence-non-us>
<city>Soormarkku</city>
<country-code>FI</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>HOWISON, THOMA &amp; ARNOTT, L.L.P</name-1>
<name-2></name-2>
<address>
<address-1>P.O. BOX 741715</address-1>
<city>DALLAS</city>
<state>TX</state>
<postalcode>75374-1715</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A 3-D rendering engine with embedded memory a graphics engine. A graphics engine is disclosed that includes a rendering engine for receiving graphics primitives and converting them to pixel information for transfer to a display, The rendering engine is operable to access memory locations with multiple memory access requests for a Read or a Write operation and operable in a first address space. A plurality of memory blocks are provided, each individually accessible and all configured in a virtual address space different than said first address space. A memory mapping device is provided for mapping each of the memory requests to the virtual address space. A pipeline engine is operable to pipeline the mapped memory access requests for both Read and Write operations in accordance with a predetermined pipelining scheme. The memory access requests are received in parallel and processed asynchronously, such that access to more than one of the memory blocks can occur at substantially the same time. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">CROSS-REFERENCE TO RELATED APPLICATIONS </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application claims priority to U.S. Provisional Application Serial No. 60/248,159, Atty, Dkt. No. BBOY-25,521, entitled &ldquo;3-D RENDERING ENGINE WITH EMBEDDED MEMORY,&rdquo; filed Nov. 12, 2000.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">TECHNICAL FIELD OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention pertains in general to 3-D graphics engines and more particularly, to a 3-D graphics engine that utilizes embedded DRAM for processing information internal to a graphics integrated circuit. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> Due to recent advances in computer performance in the area of processing speeds, graphic systems have been improved to provide more realistic graphical images to operate with such things as home video games and the such. In these graphic systems, the data is processed to &ldquo;render&rdquo; or draw graphic primitives to the display of a system. These graphic primitives constitute the basic components of a graphics picture, such as a triangle or any type of polygon. It is the combination of these graphic primitives that is utilized to perform this rendering operation. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> During the rendering operation, a frame buffer is utilized to store all the information for a given frame, the frame being mapped substantially to the display of the user. This frame buffer will therefore include all of the information that is necessary to interface with the display and allow the display to be written in the desired manner. During the rendering operation, these frame buffers must be accessed a number of times in order to create the final values that are to be output to the display. In the rendering operation, there are multiple operations that must be undertaken. Each of these operations requires access to the frame buffer or memory to Write data thereto or Read data therefrom. As the graphic systems become more complex, and more complex algorithms are utilized, access to the memory becomes the &ldquo;bottleneck&rdquo; to the overall operation of the system. Typically, there will be provided some type of bus structure that will interface with the memory. As the resolution increases in the graphic systems, more and more memory is required for storing the various information required for the rendering process. This memory tends to be external to the rendering engine and there is typically only provided a single bus that provides access to the memory, which bus usually has a defined width and data rate. Further, when a substantial amount of processing is provided on a single integrated circuit, the bus width becomes more problematic due to the number of pins on the integrated circuit that must be dedicated to interface with the external memory. Even though some memory could be included on the integrated circuit, as the memory requirements increase, they tend to exceed the capabilities of the semiconductor processing technology required for this 3-D rendering engine. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> The present invention disclosed and claimed herein, in one aspect thereof, comprises a graphics engine. The graphics engine includes a rendering engine for receiving graphics primitives and converting them to pixel information for transfer to a display, The rendering engine is operable to access memory locations with multiple memory access requests for a Read or a Write operation and operable in a first address space. A plurality of memory blocks are provided, each individually accessible and all configured in a virtual address space different than said first address space. A memory mapping device is provided for mapping each of the memory requests to the virtual address space. A pipeline engine is operable to pipeline the mapped memory access requests for both Read and Write operations in accordance with a predetermined pipelining scheme. The memory access requests are received in parallel and processed asynchronously, such that access to more than one of the memory blocks can occur at substantially the same time. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> For a more complete understanding of the present invention and the advantages thereof, reference is now made to the following description taken in conjunction with the accompanying Drawings in which: </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates an overall diagrammatic view of the graphics integrated circuit with embedded memory; </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates a simplified schematic of the combination of the memory with the 3-D core; </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates a diagrammatic view of the 3-D core interfacing with the memory via a memory map; </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates an overall diagrammatic view of the graphics integrated circuit of the present disclosure; </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 5 and 6</cross-reference> illustrate a diagrammatic view of the memory management unit; </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 7A and 7B</cross-reference> illustrate a more detailed diagram of the data flow path for two memories through the memory management unit; </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates a more detailed diagrammatic view of the memory and the memory controller; </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates a diagrammatic view of the output Read FIFO; </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> illustrates a diagrammatic view of the data receiver; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> illustrates a flow chart depicting the color operation for the address calculations; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> illustrates a diagrammatic view of the AIFO; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> illustrates a diagrammatic view of the pipelining path through the graphics integrated circuit of the present disclosure; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> illustrates a diagrammatic view of an embodiment utilizing external memory and embedded memory; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> illustrates an embodiment for selectively organizing the output of multiple memories; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> illustrates a diagrammatic view of an architecture for handling multiple requests to a memory; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> illustrates a diagrammatic view of an embodiment illustrating the operation of buffering requests to a memory and then processing the output thereof; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> illustrates a diagrammatic view of the multiple memory modules and the organization of data therein; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> illustrates a diagrammatic view of the way in which columns are laid out; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> illustrates a diagrammatic view of a display and the organization of tiles thereon; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> illustrates a detail of a group of tiles and mapping thereof to the banks in the memory; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 22</cross-reference> illustrates a diagrammatic view of the address that is generated by the MMU; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> illustrates a diagrammatic view of a single bank and the mapping thereof to the memory; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 24</cross-reference> illustrates a detail of tiles and the associated banks and associated rows; </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 25</cross-reference> illustrates a diagrammatic view of the display and the manner in which the tiles are traversed; </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 26</cross-reference> illustrates a diagrammatic view of the different planes for a pixel; </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 27</cross-reference> illustrates a diagrammatic view of the access to the banks in a given memory; and </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 28</cross-reference> illustrates the timing diagram for access to the banks. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, there is illustrated a diagrammatic view of a graphics integrated circuit <highlight><bold>102</bold></highlight> for performing a rendering operation which is operable to receive data and provide a video output. The graphic chip includes a number of sections. A 3-D core <highlight><bold>104</bold></highlight> is provided which is operable to receive input data from an application and rasterize that data into pixels for storage in memory; i.e., it receives graphics primitives and converts them into pixels. There is provided a memory section <highlight><bold>106</bold></highlight> which comprises the embedded DRAM (eDRAM) S&amp;R. The 3-D core <highlight><bold>104</bold></highlight> interfaces with the memory section <highlight><bold>106</bold></highlight> with a memory management unit (MMU) <highlight><bold>108</bold></highlight>. There is also provided an input/output (I/O) section <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> The integrated circuit <highlight><bold>102</bold></highlight> is operable to interface with various external resources. The I/O section <highlight><bold>110</bold></highlight> interfaces with an Accelerated Graphics Port (AGP) bus <highlight><bold>112</bold></highlight> via a PCI and AGP interface block <highlight><bold>114</bold></highlight>. Additionally, there is provided a custom bus interface <highlight><bold>116</bold></highlight> in the <highlight><bold>10</bold></highlight> interface <highlight><bold>110</bold></highlight> interfacing with a custom bus. A Static Random Access Memory (SDRAM) interface <highlight><bold>118</bold></highlight> is provided for interfacing with external SDRAM, as indicated by a block <highlight><bold>120</bold></highlight>. The SDRAM interface <highlight><bold>118</bold></highlight> is interfaced with the MMU <highlight><bold>108</bold></highlight>. This SDRAM <highlight><bold>120</bold></highlight> is indicated as being associated with texture information. However, this could be associated with any portion of the frame buffer, etc., that is utilized in the rendering process. This merely provides additional memory. The SDRAM <highlight><bold>120</bold></highlight> is interfaced through a <highlight><bold>128</bold></highlight> pin port and bus <highlight><bold>122</bold></highlight> that is connected to the SDRAM interface <highlight><bold>118</bold></highlight>. Therefore, the integrated circuit <highlight><bold>102</bold></highlight> is operable to interface with external memory via the bus <highlight><bold>122</bold></highlight> that has a width of <highlight><bold>128</bold></highlight> (although specific lens widths are disclosed by way of example in the present disclosure, it should be understood that this is not a limitation and a bus width of any size is contemplated). There is also provided a video input on a port <highlight><bold>124</bold></highlight> that interfaces with the MMU <highlight><bold>108</bold></highlight> through a Video Interface Port (VIP) block <highlight><bold>126</bold></highlight>. Video output is provided on a port <highlight><bold>128</bold></highlight> that is operable to provide both digital and analog video output, which is generated by a video refresh VGA/DAC block <highlight><bold>130</bold></highlight> that interfaces with the MMU <highlight><bold>108</bold></highlight> and also with an internal auxiliary bus <highlight><bold>132</bold></highlight> in the I/O section <highlight><bold>110</bold></highlight>. The MMU <highlight><bold>108</bold></highlight> also interfaces with the bus <highlight><bold>132</bold></highlight>, as well as does the 3-D core <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The <highlight><bold>3</bold></highlight>-D core <highlight><bold>104</bold></highlight> is operable to receive data through the host interface section, which is comprised of a bus interface portion <highlight><bold>138</bold></highlight>, from the PCI and AGP interfaces <highlight><bold>114</bold></highlight> and also through the custom bus interface <highlight><bold>116</bold></highlight>. This data is buffered in a FIFO and there is also provided the coding of the data string. This data can be input to the MMU <highlight><bold>108</bold></highlight> through the register bus <highlight><bold>132</bold></highlight>, or it can be input through a triangle setup engine <highlight><bold>140</bold></highlight> for processing thereof. The triangle setup engine <highlight><bold>140</bold></highlight> is a floating point CPU with four ALUs. Each ALU contains a floating point adder and a floating point multiplier. One floating point divider is shared between the ALUs. Data is received from the stream decode portion of the interface <highlight><bold>138</bold></highlight>, the data processed to define all the triangles or polygons and then output this information to the rasterizer <highlight><bold>142</bold></highlight>. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> The rasterizer <highlight><bold>142</bold></highlight> is operable to work in variable-sized tiles (e.g., 8&times;8, 16&times;16, 32&times;32, 32&times;128, 64&times;64, 64&times;256 pixels). The rasterizer <highlight><bold>142</bold></highlight> traverses a primitive tile-by-tile and generates 4-pixel packets for the color generation stage of all pixels in a primitive belonging to the current tile. Each pixel is 32-bits in length (four 8-bit words). The tile width and height can be configured separately in powers of 2. The rasterizer <highlight><bold>142</bold></highlight> will rasterize all pixels in a triangle. Although not described herein, the rasterizer also supports anti-aliasing. This is the subject of U.S. Patent Application Serial No. ______, entitled &ldquo;Antialiasing Method And Apparatus For Video Applications,&rdquo; filed Nov. 12, 2000 (Atty Dkt No. BBOY-25,415), which is incorporated herein by reference. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> In general, the tile rasterization order depends on orientation of the primitive. Rasterization starts from the top and traverses downwards row-by-row. The first tile encountered on the row, (the tile with the left X-coordinate of the first valid scanline hits) is rasterized first, then the rest of the tiles from left to right. A tile tracker is provided which sends Y-coordinates of each rasterized row one or more times to an &ldquo;xfinder&rdquo; which is operable to calculate the start and end points on a scanline. A &ldquo;walker-unit&rdquo; is responsible for deciding which horizontal tile is currently being rasterized and an &ldquo;edgetracker&rdquo; communicates back to the tile tracker the information on how many tiles there are on the current row. A &ldquo;clip-unit&rdquo; clips the scanline to the tile and, finally, a &ldquo;scanline processor&rdquo; splits the scanlines into 4-pixel packets and calculates the anti-aliasing coverage factor. A rasterizer FIFO is utilized to keep a few scanlines available for the scanline processor, in the event that it requires a few cycles to obtain new scanlines through the pipeline. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> The rasterizer <highlight><bold>142</bold></highlight> also supports scissoring, clipping the primitive to a scissor rectangle, defined by left, top, right and bottom edges. It also allows negative X- and Y-coordinates to be utilized, such that guard-band clipping can be implemented. The X- and Y-coordinates are represented in S14 bit values, allowing the numeric range of &minus;8192 to 8191. The delta values for the non-clipped primitive are also in the same range, such that this limits the guard band to &minus;4096 to 8191. The maximum rendered primitive size is 4096&times;4096, represented with U12 values in the scanline processor and in the block renderer. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The rasterizer <highlight><bold>142</bold></highlight> is operable to interface with a color generation stage <highlight><bold>146</bold></highlight> which is operable to generate four pixels for each operation or process cycle. This will essentially determine what color is associated with a given pixel in the display space. In generating this color, various information such as texture is utilized. This texture information is obtained from one of two texture caches <highlight><bold>148</bold></highlight> and <highlight><bold>150</bold></highlight>. The texture caches <highlight><bold>148</bold></highlight> and <highlight><bold>150</bold></highlight> are interfaced with the MMU <highlight><bold>108</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The color generation stage <highlight><bold>146</bold></highlight>, after generating information, feeds it to a frame buffer stage <highlight><bold>152</bold></highlight> via a frame buffer interface <highlight><bold>154</bold></highlight>. The frame buffer <highlight><bold>154</bold></highlight> interfaces with the MMU, as well as the frame buffer stage <highlight><bold>152</bold></highlight>. Information is received from the MMU via the frame buffer interface and directly input to the MMU <highlight><bold>108</bold></highlight> from the frame buffer stage <highlight><bold>152</bold></highlight>. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> There are provided four embedded memories <highlight><bold>156</bold></highlight>, <highlight><bold>158</bold></highlight>, <highlight><bold>160</bold></highlight> and <highlight><bold>162</bold></highlight> in the illustrated embodiment. Each of these embedded memories is comprised of dynamic random access memory, which is embedded within the integrated circuit <highlight><bold>102</bold></highlight> and is referred to as &ldquo;eDRAM.&rdquo; Each of these eDRAMs <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> are interfaced with the MMU <highlight><bold>108</bold></highlight> and are accessible by the 3-D core <highlight><bold>104</bold></highlight>, as will be described in more detail hereinbelow. However, it should be understood that more than four embedded memories can be utilized. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> As will be described in more detail hereinbelow, the 3-D core is operable to provide various memory accesses for different operations required during the rendering operation. The 3-D core <highlight><bold>104</bold></highlight> will access the embedded memory and also the external memory <highlight><bold>120</bold></highlight>, for the operations required thereby. These operations occur substantially simultaneously with each other and are pipelined in an asynchronous manner to allow a request to Write data to be sent to the memory along with the data to be written, and a request-to-Read sent to the memory for return of information therefrom, these requests handled in an asynchronous manner. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, there is illustrated a diagrammatic view of the memory access operation. The 3-D core <highlight><bold>104</bold></highlight> is illustrated as providing a plurality of memory access operations, which were indicated by a plurality of horizontal lines <highlight><bold>202</bold></highlight> disposed between the 3-D core and the MMU <highlight><bold>108</bold></highlight>. These accesses can be for Read operations or for Write operations. The MMU then interfaces with the memory portion <highlight><bold>106</bold></highlight> which is comprised of a plurality of memories, indicated as memory blocks <highlight><bold>204</bold></highlight>. These blocks <highlight><bold>204</bold></highlight> represent the eDRAM memories <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> and also the SDRAM memory <highlight><bold>120</bold></highlight>. It should be understood that multiple memory blocks can be accessed in this manner. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, there is illustrated an example of a memory access from the 3-D core <highlight><bold>104</bold></highlight> illustrating two access operations. There is provided a first access operation <highlight><bold>302</bold></highlight> and a second access operation <highlight><bold>304</bold></highlight>. There are provided two memory blocks <highlight><bold>306</bold></highlight> and <highlight><bold>308</bold></highlight> (for illustration purposes, although there could be any number). In between the 3-D core <highlight><bold>104</bold></highlight> and the memory <highlight><bold>306</bold></highlight> and <highlight><bold>308</bold></highlight> is provided a memory mapping function <highlight><bold>310</bold></highlight>. This memory mapping function is provided by the MMU <highlight><bold>108</bold></highlight>, as will be described in more detail hereinbelow. The memory accesses, since there are two, operate at twice the rate of the memory access to each of the memories <highlight><bold>306</bold></highlight> and <highlight><bold>308</bold></highlight>. Therefore, the accesses can be generated at the same time, accounting for the 2&times;access rate, with each of the memories being accessed in accordance with the mapping function provided by the memory map <highlight><bold>310</bold></highlight>. It may be that memory access <highlight><bold>302</bold></highlight> accesses the upper memory <highlight><bold>306</bold></highlight> and memory access <highlight><bold>304</bold></highlight> accesses the lower memory <highlight><bold>308</bold></highlight>. Both of these memories could, in that condition, be accessed at the same time. However, the memory map <highlight><bold>310</bold></highlight> may be configured such that both memory accesses <highlight><bold>302</bold></highlight> and <highlight><bold>304</bold></highlight> access the same memory, and as such, the memory accesses would then be pipelined and priority would be determined, since multiple memory accesses can be accommodated, different speed accesses can be facilitated. This is necessary for graphics rendering engines, since the graphics operation is subject to a screen refresh of the screen or display being viewed by the user. Therefore, all necessary processing must be done within a finite length of time. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, there is illustrated a more detailed diagrammatic view of the graphics integrated circuit <highlight><bold>102</bold></highlight>. The 3-D core <highlight><bold>104</bold></highlight> is operable to receive data via an I/O port <highlight><bold>402</bold></highlight>. There are provided in the 3-D core a plurality of core applications <highlight><bold>404</bold></highlight>, <highlight><bold>406</bold></highlight>, <highlight><bold>408</bold></highlight> and <highlight><bold>410</bold></highlight>, respectively, labeled core app A, core app B, core app C and core app D. Each of these core applications <highlight><bold>404</bold></highlight>-<highlight><bold>410</bold></highlight>, it being recognized that there could be more, are operable to independently generate requests to either Write data to the memory or to Read data therefrom. The request is illustrated by command information that is generated at the core application on a line <highlight><bold>412</bold></highlight> and data transmitted on a data bus <highlight><bold>414</bold></highlight>. Each of the data buses <highlight><bold>414</bold></highlight> is operable to carry a 128-bit data value representing <highlight><bold>4</bold></highlight> pixels of data during a Write operation. Additionally, the data bus <highlight><bold>414</bold></highlight> will also carry a 24-bit address and a 16-bit enable signal. During a Read operation, the bus <highlight><bold>414</bold></highlight> will carry an address, a 24-bit value, and a Primitive ID (PID), a 10-bit value. The use of this PID during a Read operation is for steering purposes, as will be described in more detail hereinbelow. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> During a Write operation, the request and data is received by the MMU <highlight><bold>108</bold></highlight>. The address represents the native address base of the 3-D core <highlight><bold>104</bold></highlight>, which is comprised of x and y coordinates. The MMU <highlight><bold>108</bold></highlight> is operable to receive the request in the x-y coordinates and map this to the virtual address space of the memory. Although there are provided multiple blocks of memory, the mapping function of the MMU <highlight><bold>108</bold></highlight> directs this to the particular area of each of the eDRAMS <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> or SRAM <highlight><bold>120</bold></highlight> as necessary. In a Read operation, the MMU <highlight><bold>108</bold></highlight> is also operable to receive a request in the form of an x-y coordinate and map the Read request to a particular memory. However, during a Read operation, the data output is directed to one of a plurality of unique FIFO type devices <highlight><bold>420</bold></highlight>, which are referred to as &ldquo;AIFOs,&rdquo; which stand for an &ldquo;any-in-first-out device.&rdquo; This will be described in more detail hereinbelow. Each of the AIFOs <highlight><bold>420</bold></highlight> is operable to receive data and commands from the MMU <highlight><bold>108</bold></highlight> and provide data output therefrom to the 3-D core <highlight><bold>104</bold></highlight> on a plurality of buses <highlight><bold>422</bold></highlight>. Each of the buses <highlight><bold>422</bold></highlight> carries 128 bits of data and, in the present disclosure, is comprised of four 32-bit buses. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> As will be described in more detail hereinbelow, each of the requests is processed in a pipelined manner and proceeds through many stages of elastic storage buffers, FIFOs. As such, there will be a plurality of Read pointers and Write pointers associated with each elastic storage buffer and also signals representing the availability of data and capacity status, i.e., whether it is full or there is a memory location available. With the use of the elastic storage, the pipelining can therefore be somewhat asynchronous. Further, as will be described hereinbelow, the AIFOs will provide the ability to input the data in a location in a sequence, with the sequence predetermined. In that predetermined sequence, the data will be pulled out in a predetermined manner, but the input can be a random access input. Therefore, the inputs of the AIFOs <highlight><bold>420</bold></highlight> will be random access, whereas the output is sequentially accessed. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIGS. 5 and 6</cross-reference>, there is illustrated a detailed diagrammatic view of the MMU <highlight><bold>108</bold></highlight>. The embodiment of <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is directed toward the portion of the MMU <highlight><bold>108</bold></highlight> for mapping the address from the 3-D core <highlight><bold>104</bold></highlight> to the memory portion <highlight><bold>106</bold></highlight> and for writing data to the memory, in addition to generating the Read instructions. The portion of the MMU <highlight><bold>108</bold></highlight> that is illustrated in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is directed toward the data receive portion of the MMU <highlight><bold>108</bold></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> With specific reference to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, there are illustrated a plurality of input FIFOs. Each of these FIFOs is associated with a different function associated with a number of accesses from the 3-D core <highlight><bold>104</bold></highlight>. There is provided a Write FIFO <highlight><bold>502</bold></highlight> that is provided for receiving information from the 3-D core <highlight><bold>104</bold></highlight> that is associated with writing of the color value and the Z-value. The color value is a 128-bit length word associated with 4 pixels. Similarly, the Z-value is also a 128-bit word associated with four pixels. As described hereinabove, each of the pixels is 32-bits in length, representing four 8-bit words (a byte), one for each color. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> The output of the FIFO <highlight><bold>502</bold></highlight> provides two outputs, a first output <highlight><bold>504</bold></highlight> and a second output <highlight><bold>506</bold></highlight>, one for the color value and one for the X-value. There are also provided three group Write buffers, a buffer <highlight><bold>508</bold></highlight> for the BLIT Write, a buffer <highlight><bold>510</bold></highlight> for the VIP Write operation, and a buffer <highlight><bold>512</bold></highlight> for a Host Write operation. These buffers, FIFO <highlight><bold>502</bold></highlight>, and buffers <highlight><bold>508</bold></highlight>, <highlight><bold>510</bold></highlight> and <highlight><bold>512</bold></highlight>, constitute the Write portion of the memory access. The Read portion is provided by FIFOs and buffers also. A FIFO <highlight><bold>514</bold></highlight> is provided for the color and Z-value Read operation and provides a single address output <highlight><bold>516</bold></highlight>. There are provided two texture cache Read buffers <highlight><bold>518</bold></highlight> and <highlight><bold>520</bold></highlight> for texture cache <highlight><bold>1</bold></highlight> (tcr<highlight><bold>1</bold></highlight>) and texture cache <highlight><bold>2</bold></highlight> (tcr<highlight><bold>2</bold></highlight>) for a Read operation. The output <highlight><bold>10</bold></highlight> of buffer <highlight><bold>518</bold></highlight> is provided on a bus <highlight><bold>522</bold></highlight>, the output of buffer <highlight><bold>520</bold></highlight> is provided on output <highlight><bold>524</bold></highlight>, it being recognized that these are addresses. As described hereinabove, these addresses are not necessarily in the address space of the memories, as they must be mapped thereto. Typically, these will be in the X-Y coordinate system of the display. There are also provided two buffers <highlight><bold>526</bold></highlight> and <highlight><bold>528</bold></highlight> for the Host Read and <highlight><bold>15</bold></highlight> the BLIT operations, having respective output buses <highlight><bold>530</bold></highlight> and <highlight><bold>532</bold></highlight>. There are also provided two buffers for a video Read operation, buffers <highlight><bold>534</bold></highlight> and <highlight><bold>536</bold></highlight>, having output address buses <highlight><bold>538</bold></highlight> and <highlight><bold>540</bold></highlight>. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The Write operations are associated with different mapping operations. Each of the mapping operations for either the Write or the Read operations are provided by address calculators (ACALC), which are operable to provide specific mapping for a specific function. The FIFO <highlight><bold>502</bold></highlight> for the color and Z-values has associated therewith ACALC block <highlight><bold>542</bold></highlight> which is operable to map the color and Z-values to the memory space of the eDRAM and is operable to receive the output of the FIFO <highlight><bold>502</bold></highlight> on buses <highlight><bold>504</bold></highlight> and <highlight><bold>506</bold></highlight> and provide appropriate mapping as will be described hereinbelow. This Write mapping maps the X- and Y-coordinates to a specific location in memory in a predetermined manner depending upon the operation that is being performed during the rendering operation. The information on the buses <highlight><bold>504</bold></highlight> and <highlight><bold>506</bold></highlight> constitutes <highlight><bold>128</bold></highlight>-bit data words in addition to the X-, Y-coordinate address. This is converted into respective address/data couplets on buses <highlight><bold>544</bold></highlight> and <highlight><bold>546</bold></highlight> output from ACALC block <highlight><bold>542</bold></highlight>. The Write buses <highlight><bold>544</bold></highlight> and <highlight><bold>546</bold></highlight> contain a 128-bit data word, and an associated 24-bit address and an associated 16-bit write enable signal. For each of the memories <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> and the external memory <highlight><bold>120</bold></highlight>, there are provided respective Write buffers <highlight><bold>548</bold></highlight>, <highlight><bold>550</bold></highlight>, <highlight><bold>552</bold></highlight>, <highlight><bold>554</bold></highlight> and <highlight><bold>556</bold></highlight>, respectively. The bus <highlight><bold>546</bold></highlight> is connected to each of the Write input buffers <highlight><bold>548</bold></highlight>-<highlight><bold>560</bold></highlight> on a single input and the bus <highlight><bold>544</bold></highlight> is connected to each of the Write input buffers <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight> by separate inputs. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> The buffers <highlight><bold>508</bold></highlight>-<highlight><bold>512</bold></highlight> are each input to a group ACALC block <highlight><bold>558</bold></highlight> by buses <highlight><bold>560</bold></highlight>, <highlight><bold>562</bold></highlight> and <highlight><bold>564</bold></highlight>, each of the buses <highlight><bold>560</bold></highlight>-<highlight><bold>564</bold></highlight> carrying the x- and y-coordinates of the pixel information, in addition to the 128-bit 4-pixel information. The ACALC <highlight><bold>558</bold></highlight> is operable to calculate the address in the memory space of the eDRAM and output this on a bus <highlight><bold>566</bold></highlight> to each of the Write input buffers <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight> on a separate input. Although there are illustrated three inputs to each of the Write buffers <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight>, it should be understood that each of the input buffers could have a separate input and a separate ACALC block, as is also the situation with the ACALC block <highlight><bold>542</bold></highlight>, which could be divided into two ACALC blocks, one for the color and one for the Z-values. In general, the ACALC blocks <highlight><bold>542</bold></highlight> and <highlight><bold>558</bold></highlight> and the Write buffers <highlight><bold>548</bold></highlight> and <highlight><bold>556</bold></highlight> all incorporate, in addition to the memory mapping functionality, elastic storage buffers in the form of FIFOs and such. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Each of the Write buffers <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight> is connected to a memory and control block for the respective memories <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> and the external SDRAM memory <highlight><bold>120</bold></highlight>. These are represented by reference numerals <highlight><bold>568</bold></highlight>, <highlight><bold>570</bold></highlight>, <highlight><bold>572</bold></highlight>, <highlight><bold>574</bold></highlight> and <highlight><bold>576</bold></highlight>. Each of the Write buffers <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight> provide the outputs therefrom on respective *data/address/control buses <highlight><bold>578</bold></highlight>, <highlight><bold>580</bold></highlight>, <highlight><bold>582</bold></highlight>,<highlight><bold>584</bold></highlight> and <highlight><bold>586</bold></highlight>, respectively. Each of the blocks <highlight><bold>568</bold></highlight>-<highlight><bold>576</bold></highlight> is comprised of a controller for interfacing with the associated memory. This will be described in more detail hereinbelow. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> In operation, data to be written to the memory is received by the respective ACALC block, and mapped to the appropriate location, i.e., the address in the virtual address space of the memories is determined. This information is then input to all of the Write input blocks <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight>, but directed to a particular one of the memories <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> and <highlight><bold>120</bold></highlight>. The eDRAM Write buffers <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight> will determine which buffer handles the received input directed or mapped to the appropriate location in the appropriate one of the memory blocks. By utilizing the elastic storage, multiple inputs can be received and be handled by the Write buffers <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight>. This is a pipelining operation and, therefore, once one location is written, the next location can be written. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> In the Read operation, the color value and Z-value FIFO <highlight><bold>514</bold></highlight> is associated with a Read ACALC block <highlight><bold>590</bold></highlight> which is operable to generate the address for the appropriate memory location in virtual memory space as determined to be associated with the X- and Y-coordinates of the address bus <highlight><bold>516</bold></highlight> by the ACALC block <highlight><bold>590</bold></highlight>. The ACALC block <highlight><bold>590</bold></highlight> will provide on two output address buses <highlight><bold>592</bold></highlight> and <highlight><bold>594</bold></highlight> addresses for the respective color and Z-values. This information will contain both a 24-bit address in the virtual memory space of the memories and also a 10-bit primitive ID (PID). This PID will define the &ldquo;destination&rdquo; of the data after it has been accessed, whereas the address defines the location of the desired information within the virtual memory space of the memories. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Each of these buses <highlight><bold>592</bold></highlight> and <highlight><bold>594</bold></highlight> is input to one of five Read buffers <highlight><bold>595</bold></highlight>, <highlight><bold>596</bold></highlight>, <highlight><bold>597</bold></highlight>, <highlight><bold>598</bold></highlight> and <highlight><bold>599</bold></highlight>, respectively. Each of the Read buffers <highlight><bold>595</bold></highlight>-<highlight><bold>599</bold></highlight> are connected by respective buses <highlight><bold>521</bold></highlight>, <highlight><bold>523</bold></highlight>, <highlight><bold>525</bold></highlight>, <highlight><bold>527</bold></highlight> and <highlight><bold>529</bold></highlight> to the inputs of respective memory/control blocks <highlight><bold>568</bold></highlight>-<highlight><bold>576</bold></highlight>. Each of the buses <highlight><bold>521</bold></highlight>, <highlight><bold>523</bold></highlight>, <highlight><bold>525</bold></highlight>, <highlight><bold>527</bold></highlight> and <highlight><bold>529</bold></highlight> carry both address and PID information. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> The buffers <highlight><bold>518</bold></highlight>-<highlight><bold>528</bold></highlight> are all grouped together and are input into a single group ACALC block <highlight><bold>531</bold></highlight> which is operable to generate the mapped address for all of the buffers <highlight><bold>518</bold></highlight>-<highlight><bold>528</bold></highlight> and associated functions to the appropriate address in the memory space and output this on a bus <highlight><bold>533</bold></highlight> in the form of an address and a PID. This bus <highlight><bold>533</bold></highlight> is input to each of the Read buffers <highlight><bold>595</bold></highlight>-<highlight><bold>599</bold></highlight>. This is a pipelined operation, such that each of the buffers <highlight><bold>518</bold></highlight>-<highlight><bold>528</bold></highlight> could be associated with a separate ACALC and a separate input bus to the buffers <highlight><bold>595</bold></highlight>-<highlight><bold>599</bold></highlight>. This, again, is a pipelined operation that utilizes various elastic storage buffers in the pipeline. The bus <highlight><bold>533</bold></highlight>, in addition to being input to the Read buffers <highlight><bold>595</bold></highlight>-<highlight><bold>599</bold></highlight>, is also input to an AGP Read buffer <highlight><bold>535</bold></highlight>, which is input to an AGP memory/control block <highlight><bold>537</bold></highlight>. This is for storage of AGP information in the memory space for reading therefrom. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Each of the memory/control blocks <highlight><bold>568</bold></highlight>-<highlight><bold>576</bold></highlight> and <highlight><bold>537</bold></highlight> are each operable to have information written thereto and read therefrom. However, on the Read operation, the data read therefrom is output on a separate bus. Control block <highlight><bold>568</bold></highlight> has a Read bus <highlight><bold>600</bold></highlight> associated therewith, control block <highlight><bold>570</bold></highlight> has a Read bus <highlight><bold>602</bold></highlight> associated therewith, control block <highlight><bold>572</bold></highlight> has a Read bus <highlight><bold>604</bold></highlight> associated therewith, control block <highlight><bold>574</bold></highlight> has a Read bus <highlight><bold>606</bold></highlight> associated therewith, control block <highlight><bold>576</bold></highlight> has a Read bus <highlight><bold>608</bold></highlight> associated therewith and control block <highlight><bold>537</bold></highlight> has a Read bus <highlight><bold>610</bold></highlight> associated therewith. Each of the Read buses <highlight><bold>600</bold></highlight>-<highlight><bold>610</bold></highlight> carries the data that is read from the memories <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> and <highlight><bold>120</bold></highlight> associated with the memory/control blocks <highlight><bold>568</bold></highlight>-<highlight><bold>576</bold></highlight> and <highlight><bold>537</bold></highlight>, respectively, and is also operable to transmit the 10-bit PID. This PID, as will be described in more detail hereinbelow, provides the &ldquo;steering&rdquo; for the output data, such that the data is eventually output to one of the AIFOs <highlight><bold>420</bold></highlight>, as described hereinabove with respect to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Referring specifically to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, there is illustrated the Read output portion of the MMU <highlight><bold>108</bold></highlight>, including the AIFOs <highlight><bold>420</bold></highlight>. Each of the buses <highlight><bold>600</bold></highlight>-<highlight><bold>608</bold></highlight> are connected to respective inputs of eight data receivers, <highlight><bold>612</bold></highlight>, <highlight><bold>614</bold></highlight>, <highlight><bold>616</bold></highlight>, <highlight><bold>618</bold></highlight>, <highlight><bold>620</bold></highlight>, <highlight><bold>622</bold></highlight>, <highlight><bold>624</bold></highlight> and <highlight><bold>626</bold></highlight>. Each of the data receivers <highlight><bold>612</bold></highlight>-<highlight><bold>626</bold></highlight> is operable to receive the address and PID. Each PID has two fields associated therewith, one field for the respective data receiver, and the second field for AIFO <highlight><bold>420</bold></highlight>, as will be described hereinbelow. With respect to the first field, this determines which of the data receivers <highlight><bold>612</bold></highlight> will actually receive the data transmitted from the respective memory. In addition, the bus <highlight><bold>610</bold></highlight> is connected to one input of the data receivers <highlight><bold>616</bold></highlight> and <highlight><bold>618</bold></highlight>, these associated with the texture cache operation. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Each of the data receivers <highlight><bold>612</bold></highlight>-<highlight><bold>626</bold></highlight> is connected to the data input of one of the ALFOs <highlight><bold>420</bold></highlight>. These are labeled as data FIFOs (DFIFOs), these beings referred to by reference numerals <highlight><bold>628</bold></highlight>, <highlight><bold>630</bold></highlight>, <highlight><bold>632</bold></highlight>,<highlight><bold>634</bold></highlight>, <highlight><bold>636</bold></highlight>, <highlight><bold>638</bold></highlight>, <highlight><bold>640</bold></highlight> and <highlight><bold>642</bold></highlight>, associated with the respective ones of the data receivers <highlight><bold>612</bold></highlight>-<highlight><bold>626</bold></highlight>. DFIFO <highlight><bold>628</bold></highlight> is associated with the color data and has an ID of &ldquo;1,&rdquo; DFIFO <highlight><bold>630</bold></highlight> is associated with the Z-value and has an ID of &ldquo;2,&rdquo; DFIFO <highlight><bold>632</bold></highlight> and DFIFO <highlight><bold>634</bold></highlight> are associated with the texture cache operation and have IDS of &ldquo;3&rdquo; and &ldquo;4,&rdquo; DFIFO <highlight><bold>636</bold></highlight> is associated with the host operation and has an ID of &ldquo;6,&rdquo; DFIFO <highlight><bold>638</bold></highlight> is associated with the BLITTER operation and has an ID of &ldquo;7&rdquo; and is associated with the 2-D operation, DFIFO <highlight><bold>640</bold></highlight> is associated with the video operation and has an ID of &ldquo;8&rdquo; and DFIFO <highlight><bold>642</bold></highlight> is associated with a second video operation that has an ID of &ldquo;9.&rdquo;</paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Each of the DFIFOs <highlight><bold>628</bold></highlight>-<highlight><bold>642</bold></highlight> has an associated signal line output therefrom indicating that data is available. The DFIFO <highlight><bold>620</bold></highlight>s and <highlight><bold>630</bold></highlight> have data available output lines <highlight><bold>644</bold></highlight> and <highlight><bold>646</bold></highlight>, respectively, and are input to the ACALC block <highlight><bold>590</bold></highlight> associated with the Read mapping operation for the color and Z-values. The DFIFOs <highlight><bold>636</bold></highlight>-<highlight><bold>638</bold></highlight> each have an output line indicating the availability of a data location, on lines <highlight><bold>648</bold></highlight>, which are input to the ACALC block <highlight><bold>531</bold></highlight> associated with the group Read operation, as described hereinabove with respect to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. The DFIFOs <highlight><bold>640</bold></highlight> and <highlight><bold>642</bold></highlight> have associated therewith two output lines, one for each of the DFIFOs <highlight><bold>640</bold></highlight> and <highlight><bold>642</bold></highlight>, indicating the availability of a data location therein, on lines <highlight><bold>650</bold></highlight>. Each of the data available lines indicates that a data location is available for storing information therein. When information is received by a respective one of the ACALC blocks during a Read operation, the respective ACALC block is operable to map this particular operation through to the destination one of the AIFOs <highlight><bold>420</bold></highlight>. However, before this request is &ldquo;serviced&rdquo; and placed into the pipeline, a determination has to be made that there is an available location for storage therein. As will be described hereinbelow, the process pipeline is 32 cycles long, such that <highlight><bold>32</bold></highlight> requests can be serviced for data to be written to the memories or read therefrom. If all of the processes in the pipeline are Read operations and all the Read operations are directed toward a particular one of the AIFOs <highlight><bold>420</bold></highlight>, it is important that the AIFOs <highlight><bold>420</bold></highlight> are &ldquo;deeper&rdquo; than the process pipeline. Therefore, if more requests come in than the pipeline is long, these requests are held until at least a free memory location in the AIFO <highlight><bold>420</bold></highlight> can be cleared out by a Read operation therefrom. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIGS. 7A and 7B</cross-reference>, there is illustrated a detailed logic diagram for the data flow path for both the Read and the Write operation to the data receivers. There is illustrated one Write FIFO <highlight><bold>702</bold></highlight> and one Read FIFO <highlight><bold>704</bold></highlight>. The Write FIFO <highlight><bold>702</bold></highlight> is operable to receive four 32-bit data words representing four pixels on four separate data buses <highlight><bold>706</bold></highlight>, with the address being received on an address bus <highlight><bold>708</bold></highlight>, a 24-bit wide bus. The Write FIFO <highlight><bold>702</bold></highlight> is operable to assemble the data into a single 128-bit word (4 pixels) and output this on a data bus <highlight><bold>710</bold></highlight>. Similarly, the address is provided on an address bus <highlight><bold>712</bold></highlight>. The x-y coordinates are output from the Write FIFO <highlight><bold>702</bold></highlight> on a 24-bit bus <highlight><bold>713</bold></highlight>. The X- and Y-coordinates are received by FIFO <highlight><bold>702</bold></highlight> on a bus <highlight><bold>709</bold></highlight>, which is a 22-bit data bus, 10 bits for the X value and <highlight><bold>12</bold></highlight> bits for the Y value. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Similarly, the Read FIFO <highlight><bold>704</bold></highlight> is operable to receive the base address, a 24-bit value, on an address bus <highlight><bold>714</bold></highlight> and the X- and Y-coordinates on a 22-bit bus <highlight><bold>716</bold></highlight>. The output of the Read FIFO <highlight><bold>704</bold></highlight> is provided as a 24-bit base address on a bus <highlight><bold>716</bold></highlight> and the X- and Y-coordinates on a bus <highlight><bold>718</bold></highlight>. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> The buses <highlight><bold>710</bold></highlight>, <highlight><bold>712</bold></highlight> and <highlight><bold>713</bold></highlight> from the Write FIFO <highlight><bold>702</bold></highlight> are input to an appropriate Write address calculation block <highlight><bold>720</bold></highlight> which is operable to map these addresses from the x-y coordinates to the appropriate address of the eDRAMs and then routed to the Write or Read buffers. The Write ACALC block <highlight><bold>720</bold></highlight> has associated therewith elastic storage locations therein and is operable to receive from the AIFOs <highlight><bold>420</bold></highlight> on the data available signal or signal lines <highlight><bold>644</bold></highlight>, <highlight><bold>646</bold></highlight>, <highlight><bold>648</bold></highlight> or <highlight><bold>650</bold></highlight> and a Next signal on a signal line <highlight><bold>722</bold></highlight>. The Write ACALC block <highlight><bold>720</bold></highlight> is operable to output data on a 128-bit bus <highlight><bold>724</bold></highlight> and address information on a 24-bit address bus <highlight><bold>726</bold></highlight>. In addition, a memory select output <highlight><bold>728</bold></highlight> is provided, which is a signal representing which of the Write buffers <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight> will receive the data and address, i.e., which one of the paths for the associated memory will be enabled to read the data and the address. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> The output of the FIFO <highlight><bold>704</bold></highlight> on the buses <highlight><bold>716</bold></highlight> and <highlight><bold>718</bold></highlight> is input to a Read ACALC block <highlight><bold>730</bold></highlight>, which is operable to perform the memory mapping operation. The 24-bit address on bus <highlight><bold>716</bold></highlight> and the X- and Y-coordinates on bus <highlight><bold>718</bold></highlight> will be converted or mapped into the virtual memory space and an address provided on a bus <highlight><bold>732</bold></highlight>, a 24-bit bus. The PID for the particular Read operation is also generated on an ID bus <highlight><bold>734</bold></highlight>. As was the case with the Write ACALC block <highlight><bold>720</bold></highlight>, a memory select is output on a 5-bit bus <highlight><bold>736</bold></highlight>. This will select which of the Read buffers the address is directed toward. Note that this is independent of the PID on bus <highlight><bold>734</bold></highlight>, which is utilized to direct the retrieved data from any of the memories to a select one of the data receivers and also a select location within the associated one of the AIFOs <highlight><bold>420</bold></highlight>. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> There are illustrated two memory paths in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. The first memory path is that associated with memory M<highlight><bold>1</bold></highlight> (<highlight><bold>156</bold></highlight>) and the second is associated with memory M<highlight><bold>2</bold></highlight> (<highlight><bold>158</bold></highlight>). Each of the paths have associated therewith a Read buffer <highlight><bold>740</bold></highlight> and a Write buffer <highlight><bold>742</bold></highlight>. The Read buffers are operable to all receive the PID information on bus <highlight><bold>734</bold></highlight> and the address information on bus <highlight><bold>732</bold></highlight>. Note that, in the pipeline, each data transfer from one block to the other will typically involve FIFOs. This will typically require some intercommunication between the FIFOs to indicate that a memory location is available and that data is available on the transmitting end. These are not illustrated for simplicity purposes. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> The Read buffers are operable to output the address on an address bus <highlight><bold>742</bold></highlight> and the PID information on a bus <highlight><bold>744</bold></highlight>. It is important to note that there is provided a Read buffer associated with each input path of the buffer <highlight><bold>702</bold></highlight> and the buffer <highlight><bold>704</bold></highlight>. As noted hereinabove, each bus coming out of any of the ACALCs is associated with one input on the Read buffer for an associated memory path. Therefore, there would be three Read buffers <highlight><bold>740</bold></highlight> provided for the memory path associated with memory M<highlight><bold>1</bold></highlight> (<highlight><bold>156</bold></highlight>). Similarly, there would be provided three Write buffers <highlight><bold>742</bold></highlight>. Only one is illustrated for simplicity purposes. The output of the Write buffer <highlight><bold>742</bold></highlight> provides a data output on a bus <highlight><bold>748</bold></highlight> and an address bus <highlight><bold>750</bold></highlight>. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> The output of the Read buffer and Write buffer <highlight><bold>740</bold></highlight> for each of the memory paths is input to an arbiter <highlight><bold>752</bold></highlight>. The arbiter <highlight><bold>752</bold></highlight> is operable to determine priority from the multiple inputs thereto, it being understood that multiple Read addresses and PIDs will be received for the different Read buffers <highlight><bold>740</bold></highlight> associated therewith and multiple Write operations will be operable to be received and serviced thereby from the multiple Write buffers <highlight><bold>742</bold></highlight> associated therewith. The arbiter <highlight><bold>752</bold></highlight> determines the priority of which of these operations are to be handled, and forwards them on a single data bus <highlight><bold>754</bold></highlight>, a single address bus <highlight><bold>756</bold></highlight> and a single control bus <highlight><bold>758</bold></highlight> to a memory controller <highlight><bold>760</bold></highlight>. The memory controller <highlight><bold>760</bold></highlight> is interfaced with the respective one of the memories <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> and <highlight><bold>120</bold></highlight>, it being noted that there is provided an arbiter <highlight><bold>752</bold></highlight> and memory control block <highlight><bold>760</bold></highlight> for each of the memories. These buses <highlight><bold>754</bold></highlight>-<highlight><bold>758</bold></highlight> represent one of the buses <highlight><bold>578</bold></highlight>-<highlight><bold>586</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. Additionally, the Write buffers <highlight><bold>548</bold></highlight>-<highlight><bold>556</bold></highlight> and the Read buffers <highlight><bold>595</bold></highlight>-<highlight><bold>599</bold></highlight> and <highlight><bold>535</bold></highlight> are represented by the combination of the Read buffer <highlight><bold>740</bold></highlight>, Write buffer <highlight><bold>742</bold></highlight> and the arbiter <highlight><bold>752</bold></highlight>. As such, the buses <highlight><bold>754</bold></highlight>-<highlight><bold>756</bold></highlight> represent the Read buses <highlight><bold>521</bold></highlight>-<highlight><bold>529</bold></highlight> and <highlight><bold>539</bold></highlight>, respectively, with the exception that the data bus carries the PID information during a Read operation. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The memory controller <highlight><bold>760</bold></highlight> is operable to interface with the associated one of the memories <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> and <highlight><bold>120</bold></highlight> via data, address and control buses, with the exception that the memory <highlight><bold>120</bold></highlight> is actually interfaceable through the I/O <highlight><bold>118</bold></highlight> (not shown.) The memory controller <highlight><bold>760</bold></highlight> includes the circuitry for processing the PID, which is illustrated as being passed around the memory controller through a delay block <highlight><bold>764</bold></highlight>, illustrating that three cycles are required in order to process the Read data. The reason for this is that it takes approximately three cycles to access the data and provide it for output from the memory controller <highlight><bold>760</bold></highlight>. The PID is therefore passed out with the data after a three cycle delay. This data is provided on an output data bus <highlight><bold>766</bold></highlight> to a FIFO <highlight><bold>768</bold></highlight>. The FIFO <highlight><bold>768</bold></highlight> is also operable to receive the PID information from the delay block <highlight><bold>764</bold></highlight>, this being a 10-bit word. The FIFO <highlight><bold>768</bold></highlight> is inoperable to output the PID information on a bus <highlight><bold>770</bold></highlight> and the data on a bus <highlight><bold>772</bold></highlight>. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> These buses <highlight><bold>768</bold></highlight> and <highlight><bold>770</bold></highlight> are input to an output distribution FIFO <highlight><bold>774</bold></highlight>, which is operable to distribute the data to one of a plurality of the data receivers <highlight><bold>612</bold></highlight>-<highlight><bold>626</bold></highlight>, represented by a block <highlight><bold>776</bold></highlight>. Each of the FIFOs <highlight><bold>774</bold></highlight> provides on the output thereof a single data bus <highlight><bold>778</bold></highlight>, which is connected to one input of each of the data receivers <highlight><bold>776</bold></highlight>, each of the data receivers <highlight><bold>776</bold></highlight> operable to interface with data bus <highlight><bold>778</bold></highlight> for each of the FIFOs <highlight><bold>774</bold></highlight> for each of the memory data paths. Each of the FIFOs <highlight><bold>774</bold></highlight> also has to provide from the output thereof a PID on a PID bus <highlight><bold>780</bold></highlight>, which is a 10-bit bus. This is provided to each of the data receivers <highlight><bold>776</bold></highlight>, wherein the first four bits of the PID indicate which of the data receivers is to receive the data. The data receiver <highlight><bold>776</bold></highlight> has associated therewith on the input for each of the FIFOs <highlight><bold>774</bold></highlight> an elastic storage region, such that data will not be transferred to the associated data receiver <highlight><bold>776</bold></highlight> until a signal is received therefrom. Each of the FIFOs <highlight><bold>774</bold></highlight> will provide on the output thereof (not shown) a data available signal and will receive a Next signal from each of the data receivers <highlight><bold>776</bold></highlight>. The FIFOs <highlight><bold>774</bold></highlight> will be able to determine how much data can be stored therein, depending upon whether data can be output therefrom. The arbiter stage determines whether the Read data associated with a particular memory location is to be directed to the associated memory. If it is to be directed to the associated memory, the arbiter <highlight><bold>752</bold></highlight> will service that request and address, and then pass it through to the FIFO <highlight><bold>774</bold></highlight> for &ldquo;steering&rdquo; thereof in accordance with the first field and the PID. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, there is illustrated a more detailed diagrammatic view of the memory controller <highlight><bold>760</bold></highlight>. The arbiter <highlight><bold>752</bold></highlight> is operable to pass the 128-bit data through on the data bus <highlight><bold>754</bold></highlight>. However, the address illustrated as being output on address bus <highlight><bold>756</bold></highlight> is output as row and column address, the row address being a 9-bit address and the column address being a 7-bit address. Further, the arbiter is operable to divide the memory into three different banks, such that the arbiter <highlight><bold>752</bold></highlight> will provide three different addresses, ADD <highlight><bold>1</bold></highlight> on a bus <highlight><bold>802</bold></highlight>, ADD <highlight><bold>2</bold></highlight> on a bus <highlight><bold>804</bold></highlight> and ADD <highlight><bold>3</bold></highlight> on a bus <highlight><bold>806</bold></highlight>. The data bus and each of the address bus <highlight><bold>802</bold></highlight>, <highlight><bold>804</bold></highlight> and <highlight><bold>806</bold></highlight> are input to three respective banks of FIFOs <highlight><bold>808</bold></highlight>, <highlight><bold>810</bold></highlight> and <highlight><bold>812</bold></highlight>. Bank <highlight><bold>1</bold></highlight> is associated with the FIFO <highlight><bold>808</bold></highlight>, Bank <highlight><bold>2</bold></highlight> is associated with FIFO <highlight><bold>810</bold></highlight> and FIFO <highlight><bold>810</bold></highlight> is associated with Bank <highlight><bold>3</bold></highlight>. Each of the banks <highlight><bold>808</bold></highlight> is selected by a separate select input <highlight><bold>814</bold></highlight>, <highlight><bold>816</bold></highlight> and <highlight><bold>818</bold></highlight>, respectively, which is generally divided arbiter <highlight><bold>752</bold></highlight>. Each of the FIFOs <highlight><bold>808</bold></highlight>-<highlight><bold>812</bold></highlight> provides a feedback to the arbiter <highlight><bold>752</bold></highlight> indicating that a memory location is available. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> Each of the FIFOs <highlight><bold>808</bold></highlight>-<highlight><bold>812</bold></highlight> is operable to output the stored data to a memory controller core <highlight><bold>820</bold></highlight> which is operable to receive an elastically store the contents of the FIFOs <highlight><bold>808</bold></highlight>-<highlight><bold>812</bold></highlight>. The information that is passed from the arbiter <highlight><bold>752</bold></highlight> through the FIFOs <highlight><bold>808</bold></highlight>-<highlight><bold>812</bold></highlight> to the controller core <highlight><bold>820</bold></highlight> are the row and column data for addressing purposes, the 128-bit data, the 16-byte Write enable signal and also a Type signal, indicating whether this is a Read or Write operation. The base address that addresses the arbiter is converted to the row and column data in a predecode operation. The arbiter <highlight><bold>752</bold></highlight> will recognize where in the virtual memory space the arbiter exists, recognizing that each of the memories <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight> and <highlight><bold>120</bold></highlight> occupy a defined portion of the virtual memory space. Once this is recognized, then the portion of the address associated with the memory will be &ldquo;stripped&rdquo; off. In addition, the arbiter selects which of the banks <highlight><bold>808</bold></highlight>-<highlight><bold>812</bold></highlight> will be selected in a further predecoding operation. The banks <highlight><bold>808</bold></highlight>-<highlight><bold>812</bold></highlight> allow three accesses to occur to the banks, which can then be input to the memory controller. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> The memory controller core <highlight><bold>820</bold></highlight> is operable to elastically store the information from the banks <highlight><bold>808</bold></highlight>-<highlight><bold>812</bold></highlight> and then access the memory M<highlight><bold>1</bold></highlight> (<highlight><bold>156</bold></highlight>), in this example. The memory <highlight><bold>156</bold></highlight>, in the disclosed embodiment, includes two banks. Therefore, an address in the form of the row and column information requiring a 9-bit row address and a 7-bit column address, is output on a bus <highlight><bold>824</bold></highlight> to the memory <highlight><bold>156</bold></highlight>. The memory <highlight><bold>156</bold></highlight> will then receive data on two data buses, a 64-bit data bus <highlight><bold>826</bold></highlight> and a 64-bit data bus <highlight><bold>828</bold></highlight>. These data buses are input to the two separate banks. Read data will come back on separate data buses, a data bus <highlight><bold>830</bold></highlight> and a data bus <highlight><bold>832</bold></highlight>. During a Read operation, the core <highlight><bold>820</bold></highlight> is operable to combine the two 64-bit data fields into a single 128-bit data field for output on a 128-bit data bus <highlight><bold>128</bold></highlight>. The PID information is output on a data bus <highlight><bold>838</bold></highlight>, data bus <highlight><bold>838</bold></highlight> and <highlight><bold>836</bold></highlight> comprising the data bus <highlight><bold>600</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, there is illustrated a more detailed diagrammatic view of the FIFOs <highlight><bold>768</bold></highlight> and <highlight><bold>774</bold></highlight> for receiving the output of the controller <highlight><bold>760</bold></highlight> and steering the data to the appropriate data receiver. The FIFO <highlight><bold>768</bold></highlight> is operable to receive the data on the bus <highlight><bold>766</bold></highlight> and the PID information on a bus <highlight><bold>902</bold></highlight>. The output data is provided on a bus <highlight><bold>772</bold></highlight> with the PID information provided on a 10-bit bus <highlight><bold>770</bold></highlight>. The FIFO <highlight><bold>776</bold></highlight> is operable to interface with the FIFO <highlight><bold>768</bold></highlight> to indicate that it is full and also to receive information as to whether data is available. The output of the FIFO <highlight><bold>776</bold></highlight> provides data on a bus <highlight><bold>778</bold></highlight>, this data provided to each of the data receivers <highlight><bold>776</bold></highlight>. Additionally, the PID information is sent to each of the data receivers <highlight><bold>776</bold></highlight> on a separate bus <highlight><bold>780</bold></highlight>, there being a separate data bus <highlight><bold>778</bold></highlight> and a separate PID bus <highlight><bold>780</bold></highlight> for each of the FIFOs <highlight><bold>776</bold></highlight> for each of the memories. In addition, each of the data receivers <highlight><bold>776</bold></highlight> is operable to provide on an associated signal line <highlight><bold>904</bold></highlight> information regarding the availability of a storage location therein. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, there is illustrated a diagrammatic view of a data receiver <highlight><bold>1002</bold></highlight>. Data receiver <highlight><bold>1002</bold></highlight>, as described hereinabove, is operable to receive from each of the FIFOs <highlight><bold>776</bold></highlight> data, PID information and a data available signal on a line <highlight><bold>1004</bold></highlight>. The Next signal is output on signal line <highlight><bold>904</bold></highlight>. The data receiver <highlight><bold>1002</bold></highlight> is operable to recognize the four Most Significant Bits (MSBs) and the address thereof. If the address is correct, then data will be received and elastically stored therein for output to the associated AIFO <highlight><bold>420</bold></highlight>. This will be in the form of the 128-bit data and the 6-bit AIFO ID portion of the overall PID, as will be described hereinbelow. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, there is illustrated a flow chart for depicting how ACALC blocks assign a PID. As described hereinabove, there are <highlight><bold>32</bold></highlight> processes that are operable to be stored in the pipeline at any one given time. As such, each time a new process is serviced, the system must determine if the process counter is equal to 32. If so, then the process will not be serviced until at least one of the first services is cleared out of the pipeline. Once cleared out, the process counter is decremented and then a new process is received and the process counter increased. In addition, each time a new process is received, it is assigned a PID for the associated AIFO it is designated for. This PID indicates where in the pipeline sequences that the particular process in that particular AIFO is being serviced. As noted hereinabove, the four most significant bits of the PID indicate the data receiver to which data is to be directed. The remaining 6-bits indicate the position within the portion of the process pipeline that the process is inserted for the associated AIFO. The reason for this will be described hereinbelow. This flow chart is initiated at a start block <highlight><bold>1102</bold></highlight> and then proceeds to a decision block <highlight><bold>1104</bold></highlight> to determine if a new memory access has been initiated. If not, the program will return along a loop and wait. When a memory access is received, the program will flow along a &ldquo;Y&rdquo; path to a decision block <highlight><bold>1106</bold></highlight> to determine if the overall process counter is less than a value of 32. If not, this indicates that the pipeline is fall and the program will flow to a function block <highlight><bold>1108</bold></highlight> to wait for the counter to decrease. This will continue in a loop until the counter has been cleared of at least one process and this program will flow along a &ldquo;Y&rdquo; path to a function block <highlight><bold>1112</bold></highlight> wherein the process counter will be incremented and then to a function block <highlight><bold>1114</bold></highlight> to increment the ID counter. At this point in the process, a PID is assigned to the process, such that it is uniquely identified within the pipeline for an associated AIFO. The flow then proceeds to a function block <highlight><bold>1116</bold></highlight> to assemble the data and then process it through the pipe line, as described hereinabove, and then the program returns to the input of decision block <highlight><bold>1104</bold></highlight> of the AIFO </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 12</cross-reference>, there is illustrated a diagrammatic view of the AIFO <highlight><bold>420</bold></highlight>. The AIFO <highlight><bold>420</bold></highlight> has at the core thereof a plurality of memory registers <highlight><bold>1202</bold></highlight> that are individually accessible. On the input thereof is provided a Write multiplexer <highlight><bold>1204</bold></highlight> which is operable to Write into each memory location, based upon an address received on ID bus <highlight><bold>1206</bold></highlight> and data received on a 128-bit data bus <highlight><bold>1208</bold></highlight>. The address, as described hereinabove, constitutes the six least significant bits of the PID. Therefore, the input to the AIFO core <highlight><bold>1202</bold></highlight> is a random access input. As such, whenever the data is received, the location thereof is determined by its location within the process. Further, if another process step which was later in the pipeline occurred prior to the current storage operation, this would be stored in a location out of sequence to that normally incurred in a FIFO operation. Additionally, the address bus <highlight><bold>1206</bold></highlight> is input to a data valid block <highlight><bold>1210</bold></highlight>, which determines if the data at the location addressed by the address bus <highlight><bold>1206</bold></highlight> has been read out. If not, then the system will not store that data. When data is read out, a reset signal on a line <highlight><bold>1214</bold></highlight> from a Read control block <highlight><bold>1216</bold></highlight> will reset the data valid bit. When data is written to a location, the data valid bit is set. This data valid block <highlight><bold>1210</bold></highlight> provides a Write enable signal to the AIFO. The control for the Write operation is provided by Write control block <highlight><bold>1218</bold></highlight> which is operable to determine if data is available from the associated data receiver and process that data and, when a location becomes available, a signal can be output to the data receiver indicating that it is ready for the next data value. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> During the Read operation, an output multiplexer <highlight><bold>1220</bold></highlight> is provided for selectively accessing each of the AIFO locations in the core <highlight><bold>1202</bold></highlight>. This is in conjunction with a Read pointer generated by Read control circuit <highlight><bold>1216</bold></highlight>, which is a circulating pointer. Therefore, each location in the core <highlight><bold>1202</bold></highlight> will be rotated through cyclically. The output multiplexer <highlight><bold>1220</bold></highlight> receives the 128-bit wide data words, each representing four pixels, and provides on the output thereof four 32-bit words on four data buses <highlight><bold>1224</bold></highlight>. The Read control <highlight><bold>1216</bold></highlight> interfaces with the Read side of the memory controller <highlight><bold>752</bold></highlight> to indicate when data is available, i.e., there is data stored therein, and also to receive information when the particular ACALC associated therewith can receive this information. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> In the processing sequence, as described hereinabove, a rotating PID counter is provided which has a value from 0 to 32. Of course, it should be understood that there is a requirement for the AIFO to be deeper than the process. When a PID is assigned to the process, this PID is associated with both the data receiver to which the data is steered and also a 6-bit ID for the 32-bit location AIFO. This is a rotating value such that each PID for a given AIFO will have the 6-bit value thereof incremented for each process step generated, there being one PID counter for each AIFO. For example, if the first process is received, it may be assigned the value &ldquo;24&rdquo; for one of the AIFOs and the next process received for that AIFO will be the AIFO ID &ldquo;25.&rdquo; Even though the locations in the AIFO associated with the AIFO IDS 1-15 may be cleared out, leaving location 16-22 full, i.e., associated with a process in the pipeline not yet carried out, the system will still operate in the same sequence, without a reset operation. By doing such, it is possible to actually process the request or memory access associated with the AIFO ID &ldquo;23&rdquo; for a given AIFO prior to processing the memory access associated with AIFO ID &ldquo;15&rdquo; for that AIFO even though the process associated with AIFO ID &ldquo;15&rdquo; for that AIFO was an earlier received process. Note that the ACALC has no knowledge of when and in what order the processes were carried out; rather, the ACALC that requested the memory access requested it in a predetermined order and it expects the data to be output in that order. It defines the order of output by the PID. By providing the random access input to the AIFO, the process can actually be asynchronous to the pipeline order, without reordering the output and apprising the ACALC of the reorder. This in effect prevents the system from &ldquo;stalling&rdquo; to process a lower priority or earlier memory access prior to providing the output thereof, which would be the case with a normal FIFO. This allows the processing to handle a process that was later requested prior to an earlier requested memory access, and then essentially reorder them when they are stored in the AIFO. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 13</cross-reference>, there is illustrated a diagrammatic view of the overall steering operation. The 3-D core <highlight><bold>104</bold></highlight> is operable to generate multiple memory accesses, in this example, MA<highlight><bold>1</bold></highlight>, MA<highlight><bold>2</bold></highlight>, MA<highlight><bold>3</bold></highlight> and MA<highlight><bold>4</bold></highlight>. These are input to a memory mapping block <highlight><bold>1302</bold></highlight>, which comprises the ACALC blocks and Read and Write buffers described hereinabove. The memory map <highlight><bold>1302</bold></highlight> is operable to map these to the particular memory and direct them to the particular memory. Additionally, the memory map block <highlight><bold>1302</bold></highlight> is operable to order the various accesses, since the memory is linear. Once ordered, the memories <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight>, representing memories M<highlight><bold>1</bold></highlight>, M<highlight><bold>2</bold></highlight>, M<highlight><bold>3</bold></highlight> and M<highlight><bold>4</bold></highlight> are accessed for a Write operation or a Read operation. The Read operation only proceeds on the Write of the memory <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight>. Write operations terminate thereat. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> For Read operation, the data will be output to a separate distribution block <highlight><bold>1308</bold></highlight> comprised of the data receivers and the various FIFOs <highlight><bold>768</bold></highlight> and <highlight><bold>776</bold></highlight>. These will receive and handle the output of the associated memory on a given path and distribute them to the appropriate AIFO <highlight><bold>440</bold></highlight>. There are illustrated in this example <highlight><bold>6</bold></highlight> AIFOs, AIFO<highlight><subscript>1</subscript></highlight>, AIFO<highlight><subscript>2 </subscript></highlight>. . . AIFO<highlight><subscript>6. </subscript></highlight>There are illustrated four memory accesses, which memory accesses are simultaneously generated from the 3-D core <highlight><bold>104</bold></highlight> to the memory map block <highlight><bold>1302</bold></highlight> for handling and redirecting. The memory map block <highlight><bold>1302</bold></highlight> recognizes that the access from MA<highlight><bold>1</bold></highlight> and MA<highlight><bold>2</bold></highlight> are directed toward memory M<highlight><bold>1</bold></highlight>. These two memory accesses are directed thereto, but the redistribution block <highlight><bold>1308</bold></highlight> will steer them to different AIFOs <highlight><bold>440</bold></highlight>. The access MA<highlight><bold>1</bold></highlight> is steered toward AIFO, and the first access from MA<highlight><bold>2</bold></highlight> is steered through memory M<highlight><bold>1</bold></highlight> to AIFO<highlight><subscript>5</subscript></highlight>. There is also provided a second access from MA<highlight><bold>2</bold></highlight>, this being the functional accessing block, that is steered to memory M<highlight><bold>2</bold></highlight>. Since this is typically the same function, both memory accesses are accessing different portions of the memory space and can handle a simultaneous access of the two separate memories. However, they must both be directed to the AIFO<highlight><subscript>5</subscript></highlight>. In order to be directed to this AIFO<highlight><subscript>5</subscript></highlight>, the PID must be assigned to indicate the associated data receiver in the four MSBs. However, the AIFO ID will be different and will represent the position in the process for that AIFO wherein the particular accesses were received. It is noted that the process pipeline operation is associated with the AIFO and not the overall process. Therefore, there will be a separate AIFO ID counter for each AIFO. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> Continuing on, the memory access MA<highlight><bold>3</bold></highlight> is routed through memory M<highlight><bold>4</bold></highlight> to AIFO<highlight><subscript>4 </subscript></highlight>and a memory access from MA<highlight><bold>4</bold></highlight> is routed through memory M<highlight><bold>3</bold></highlight> to AIFO<highlight><subscript>6</subscript></highlight>. It can be seen that the ACALC blocks will direct the memory access requests to the appropriate memory block, depending upon the address associated therewith in the virtual address space. Once addressed, the data can then be transferred along the appropriate path through the various FIFOs or elastic storage regions. During a Read operation, it is again redirected through the use of the PID to the appropriate output elastic storage device. This can then be returned to the 3-D core via the return buses. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 14</cross-reference>, there is illustrated a diagrammatic view of the overall graphics chip <highlight><bold>102</bold></highlight> having disposed therein a rendering engine, which forms a portion of the 3D core <highlight><bold>104</bold></highlight> as a rendering engine <highlight><bold>1402</bold></highlight>. The rendering engine <highlight><bold>1402</bold></highlight> is operable to generate an address that is mapped to the X and Y coordinates in a given display by the MMU <highlight><bold>108</bold></highlight> to access embedded memory <highlight><bold>1404</bold></highlight> in the integrated circuit <highlight><bold>102</bold></highlight>. Additionally, there is provided the external memory <highlight><bold>120</bold></highlight> that is accessed through an I/O port <highlight><bold>1406</bold></highlight> which has a data bus <highlight><bold>1408</bold></highlight> connected from port <highlight><bold>1406</bold></highlight> to the memory <highlight><bold>120</bold></highlight> and a data bus <highlight><bold>1410</bold></highlight> internal to the chip <highlight><bold>102</bold></highlight> that connects the MMU <highlight><bold>108</bold></highlight> to the port <highlight><bold>1406</bold></highlight>. Additionally, there is provided an internal bus <highlight><bold>1412</bold></highlight> that is operable to connect the MMU <highlight><bold>108</bold></highlight> to the embedded memory <highlight><bold>1404</bold></highlight>. As described hereinabove, the bus <highlight><bold>1412</bold></highlight> has a first width, noted herein as &ldquo;A&rdquo; and the bus <highlight><bold>1408</bold></highlight> has a width of less than &ldquo;A.&rdquo; Thus, more data can be forwarded to the embedded memory <highlight><bold>1404</bold></highlight>, due to the wider bus width. This necessarily indicates that data transfer between the MMU <highlight><bold>1108</bold></highlight> and the embedded memory <highlight><bold>1404</bold></highlight> will be at a higher rate than the external memory <highlight><bold>120</bold></highlight>. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, there is illustrated another embodiment of the architecture illustrating the rendering engine <highlight><bold>1402</bold></highlight> as accessing multiple and discrete memories with the assistance of the MMU <highlight><bold>108</bold></highlight>. These memories are illustrated as being two memories <highlight><bold>1502</bold></highlight> and <highlight><bold>1506</bold></highlight>, although there could be any number of memories. Each of the memories is independently addressable and accessible such that the information thereof can be output from each of the respective memories <highlight><bold>1502</bold></highlight> on separate and distinct data buses <highlight><bold>1508</bold></highlight> and <highlight><bold>1510</bold></highlight>, respectively. These data buses <highlight><bold>1508</bold></highlight> and <highlight><bold>1510</bold></highlight> are input to a data organizer <highlight><bold>1512</bold></highlight>, which is the AIFO described hereinabove. This data is organized in a particular pipeline and output on a single bus <highlight><bold>1514</bold></highlight>. Each of the memories <highlight><bold>1502</bold></highlight> and <highlight><bold>1506</bold></highlight> can have various requests input thereto and output the data in any order. Both of the memories <highlight><bold>1502</bold></highlight> and <highlight><bold>1506</bold></highlight> can be accessed independently. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, there is illustrated a diagrammatic view of an architecture wherein the rendering engine <highlight><bold>1402</bold></highlight> is operable to generate multiple memory requests which are then input to a request buffer <highlight><bold>1602</bold></highlight> as separate and distinct requests, there being illustrated three separate requests <highlight><bold>1604</bold></highlight>, <highlight><bold>1606</bold></highlight> and <highlight><bold>1608</bold></highlight> in the request buffer <highlight><bold>1602</bold></highlight>. These requests are then handled in a predetermined order as determined by the MMU <highlight><bold>108</bold></highlight> and the associated arbiter (not shown) for output to the memory <highlight><bold>1404</bold></highlight>. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 17</cross-reference>, there is illustrated a simplified diagram of the manner of handling the request. The rendering engine <highlight><bold>1402</bold></highlight> is operable to, again, output requests to the request buffer <highlight><bold>1602</bold></highlight> which then accesses the memory <highlight><bold>1404</bold></highlight> in the predetermined sequence that the requests were received, it being understood that the requests may be received in an order that can be different than the logical pipeline and potentially different than the actual order in which they are executed. The output data is then forwarded to a data receiver/FIFO <highlight><bold>1702</bold></highlight> for buffering the data and then subsequently forwarded to a data processor <highlight><bold>1704</bold></highlight>. The buffering of the requests allows the pipeline to be more efficiently handled. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 18</cross-reference>, there is illustrated a diagrammatic view of the embedded memory and the organization thereof. This illustration will be utilized for describing how data is written to and read from memory during an update of a display. There are illustrated eight separate memory devices <highlight><bold>1802</bold></highlight>. These are essentially the embedded memory blocks referred to in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> as eDRAM <highlight><bold>156</bold></highlight>-<highlight><bold>162</bold></highlight>. Although there were only four eDRAMs illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, there are eight in this embodiment, these labeled M<highlight><bold>0</bold></highlight>, M<highlight><bold>1</bold></highlight> , . . . M<highlight><bold>7</bold></highlight>. Each of the memories <highlight><bold>1802</bold></highlight> is separately accessible and addressable. They each have a common address input <highlight><bold>1804</bold></highlight>, a row address input <highlight><bold>1806</bold></highlight> and an enable line <highlight><bold>1808</bold></highlight>. Each of the memories <highlight><bold>1802</bold></highlight> is referred to as a &ldquo;Channel.&rdquo; There are eight memories and, therefore, eight channels labeled CH<highlight><bold>0</bold></highlight>, CH<highlight><bold>1</bold></highlight>, . . . CH<highlight><bold>7</bold></highlight>. The MMU <highlight><bold>108</bold></highlight> can separately address each memory with a row and column address and separately enable each memory. Each memory <highlight><bold>1802</bold></highlight> also has a separate data output <highlight><bold>1810</bold></highlight>. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> Each of the memories <highlight><bold>1802</bold></highlight> is divided into three banks, B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight> with each bank having the columns thereof separately addressed. The banks in each of the memories are organized such that they are partitioned into the three banks with a defined &ldquo;0&rdquo; for each. As such, there will be a row address and a bank address that defines the actual address within the particular memory <highlight><bold>1802</bold></highlight>. The bank address is a partitioning address within the given memory. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 19</cross-reference>, there is illustrated a diagrammatic view of how the column addresses are organized. As will be described hereinbelow, there are four planes for each pixel, the color plane, the Z-value plane, the antialiasing (AA) plane and the Front/Back (F/B) buffer plane. There are provided in the memory <highlight><bold>64</bold></highlight> columns of addressable locations, each addressable location comprised of 32 bits. Each pixel has four planes for a maximum of 128 bits. The first color plane is associated with the column addresses C<highlight><subscript>0</subscript></highlight>-C<highlight><subscript>7</subscript></highlight>, the Z-value plane associated with the column addresses C<highlight><subscript>8</subscript></highlight>-C<highlight><subscript>15</subscript></highlight>, the AA plane associated with the column addresses C<highlight><subscript>16</subscript></highlight>-C<highlight><subscript>23 </subscript></highlight>and F/B plane associated with column addresses C<highlight><subscript>24</subscript></highlight>-C<highlight><subscript>31</subscript></highlight>. However, the columns are arranged such that, for each pixel, the first column address in each of the planes are disposed adjacent to each other. For example, column C<highlight><subscript>0</subscript></highlight>, C<highlight><subscript>8</subscript></highlight>, C<highlight><subscript>16 </subscript></highlight>and C<highlight><subscript>24 </subscript></highlight>are disposed adjacent each other in the first group, with the next group being column addresses C<highlight><subscript>1</subscript></highlight>, C<highlight><subscript>9</subscript></highlight>, C<highlight><subscript>17 </subscript></highlight>and C<highlight><subscript>25</subscript></highlight>. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 20</cross-reference>, there is illustrated a diagrammatic view of a display <highlight><bold>2002</bold></highlight> having disposed thereon a plurality of tiles <highlight><bold>2004</bold></highlight>. The tiles are arranged in such a manner that there are an even number of tiles for each row and for each column, such that there are a plurality of rows and columns. Each of these tiles is mapped to the memory. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 21</cross-reference>, there is illustrated a more detailed view of the tiles <highlight><bold>2004</bold></highlight>. The tiles in a given row are illustrated as being <highlight><bold>64</bold></highlight> in number, denoted as T<highlight><bold>0</bold></highlight>, T<highlight><bold>2</bold></highlight>, T<highlight><bold>3</bold></highlight>, . . . , T<highlight><bold>63</bold></highlight>, although there could be any umber of tiles in a row. The first tile in the second row would be T<highlight><bold>64</bold></highlight> and so on. These tiles are mapped such that each tile is associated with a bank in the memory and, as will be described hereinbelow, each bank is associated with a given row, such that access to a single row in a single bank will allow the pixel data to be output merely by changing the column address and the Channel address. The banks are organized such that the first three tiles, T<highlight><bold>0</bold></highlight>, T<highlight><bold>2</bold></highlight> and T<highlight><bold>3</bold></highlight> are mapped to banks B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight>, with the next three tiles, T<highlight><bold>4</bold></highlight>, T<highlight><bold>5</bold></highlight> and T<highlight><bold>6</bold></highlight> also mapped to banks B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight>, albeit to different rows, as will be described hereinbelow. Also, the number of tiles in a given row is an even number whereas the number of banks is an odd number. This will result in the ability to sequence through sequential banks in either a horizontal or a vertical direction. This is due to the fact that the bank number at the beginning of the row is the same as the bank number at the end of the row with the bank number in the first position of the next lower adjacent row being sequenced by a value of 1. Thus, the first three bank numbers in the first row are B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight> and the first three numbers in the first column are B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight>. Therefore, the memory can be traversed either across a row or down a column in the same manner, as will be described hereinbelow. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 22</cross-reference>, there is illustrated a diagrammatic view of the address that is generated by the MMU which maps the X-Y coordinate from the rendering engine to the memory space. As described hereinabove, the memory is divided into columns in each memory, all the columns being common for each individual channel, banks&mdash;there being three banks, B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight>&mdash;and row addresses in each of the banks. The column address is a five bit address, the bank address is a two bit address, the row address in each bank is a ten bit address and the channel address is a three bit address. Thus, each location in memory is defined by its channel, its bank, its row and its column, such that it will be defined as a &ldquo;CBRC&rdquo; address. The actual address is organized such that the first two bits are the most significant bits of the column address, the next ten bits are the row address, the next two bits are the bank address, the next three address bits are the three least significant bits of the column address and the last three bits being the channel address or the actual physical memory selection address referred to as &ldquo;M&rdquo; for each bit. Although, for each plane, there are only eight columns, the four planes will comprise thirty two columns such that a five column address is required. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 23</cross-reference>, there is illustrated a diagrammatic view of a bank and the CBRC address for each location therein and how it is organized in the bank. In the bank illustrated, there will be 64 addressable locations for 64 pixels, it being understood that only one plane is illustrated. This is the first plane or the color plane. This is illustrated for the top left corner tile in the display, one tile being represented by a single bank, which bank is addressed with a single common row address and the only difference being changing the column address from C<highlight><subscript>0 </subscript></highlight>through C<highlight><subscript>7 </subscript></highlight>and changing the channel from CH<highlight><bold>0</bold></highlight> to CH<highlight><bold>7</bold></highlight>. The first pixel value in the illustrated bank has a CBRC address of 0.0.0.0 illustrating the channel CH<highlight><bold>0</bold></highlight>, the bank B<highlight><bold>0</bold></highlight>, the row R<highlight><subscript>0 </subscript></highlight>and column C<highlight><subscript>0</subscript></highlight>. The next adjacent pixel will have a CBRC address of 1.0.0.0 for the next channel CH<highlight><bold>1</bold></highlight>. For the column value set at C<highlight><subscript>0</subscript></highlight>, it is only necessary to sequence through all of the eight memories from channel CH<highlight><bold>0</bold></highlight> through CH<highlight><bold>7</bold></highlight> to access the first eight pixels. Thereafter, the column number is changed from C<highlight><subscript>0 </subscript></highlight>to C<highlight><subscript>1 </subscript></highlight>and then the channel sequenced through from CH<highlight><bold>0</bold></highlight> through CH<highlight><bold>7</bold></highlight> with the row remaining unchanged. This continues down until column C<highlight><subscript>7 </subscript></highlight>is processed for a total of 64 pixels. Note that all of this is achieved with only a single row address. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 24</cross-reference>, there is illustrated a diagrammatic view of how the row addresses are associated with each of the banks in each of the tiles. The first row of pixels is illustrated as having the first three banks B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight> associated with row R<highlight><bold>0</bold></highlight> in the memory. The second three pixels are associated with banks B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight> in the second row of the memory R<highlight><bold>1</bold></highlight>. As such, a single row address will allow three adjacent banks of data or three adjacent tiles to be accessed. Therefore, for a single row address, the first step is to sequence through the column and channel addresses and then increment the bank address and again sequence through the channel and column addresses followed by a third increment of the bank address to the channel and column addresses therefor. The row can then be changed and the sequence repeated. Along a given row, for 64 tiles, this will be repeated 21 times and one third. The one third is for the first tile or bank in the 22nd row address, R<highlight><bold>21</bold></highlight>. It can be seen that in the second row, the first two banks are B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight> in row <highlight><bold>21</bold></highlight>, with the next bank, B<highlight><bold>0</bold></highlight>, being in row <highlight><bold>22</bold></highlight> with row address R<highlight><bold>21</bold></highlight>. However, as illustrated in <cross-reference target="DRAWINGS">FIG. 25</cross-reference>, the traversal of the display space actually requires at the end of the first row of tiles a change of row address to bank B<highlight><bold>1</bold></highlight> in memory row R<highlight><bold>41</bold></highlight> and then it traverses the second row of the tiles in the opposite direction. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 26</cross-reference>, there is illustrated a diagrammatic view of the multiple planes for each pixel. There are illustrated four planes, a plane <highlight><bold>2602</bold></highlight> for the color plane, a plane <highlight><bold>2604</bold></highlight> for the Z-value plane, a plane <highlight><bold>2606</bold></highlight> for the AA plane and a plane <highlight><bold>2608</bold></highlight> for the F/B plane. For the first tile, the T<highlight><bold>0</bold></highlight> tile <highlight><bold>2004</bold></highlight>, there will be associated therewith information in bank B<highlight><bold>0</bold></highlight>. This will result in 64 pixels, in the disclosed embodiment, wherein the first pixel in the upper lefthand corner in the color plane <highlight><bold>2602</bold></highlight> will have a CBRC address of 0.0.0.0 and the tile <highlight><bold>2004</bold></highlight> in the Z-value plane <highlight><bold>2604</bold></highlight> will have as the first pixel in the upper lefthand comer thereof a pixel with the CBRC address of 0.0.0.8. This is due to the fact that the column addresses for each pixel in the color plane <highlight><bold>2602</bold></highlight> will range from C<highlight><subscript>0</subscript></highlight>-C<highlight><subscript>7</subscript></highlight>, whereas the column address for the pixels in the Z-value plane <highlight><bold>2604</bold></highlight> will range from C<highlight><subscript>8</subscript></highlight>-C<highlight><subscript>15</subscript></highlight>. Each of the pixel values is a 32 bit value with the total storage space for a given pixel having a bit value of 128 bits. Although not illustrated, there will be an associated bank B<highlight><bold>0</bold></highlight> for each of the tiles <highlight><bold>2004</bold></highlight> in the planes <highlight><bold>2606</bold></highlight> and <highlight><bold>2608</bold></highlight>. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 27</cross-reference>, there is illustrated a diagrammatic view of the banks B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight> and the access thereto and buffering of the outputs thereof. The banks B<highlight><bold>0</bold></highlight>, B<highlight><bold>1</bold></highlight> and B<highlight><bold>2</bold></highlight> are illustrated as being three adjacent banks, it being recognized that these banks exist in eight different memories, depending upon the channel selected. Illustrated is the situation where the first row, R<highlight><bold>0</bold></highlight>, is selected for each of the banks. This, again, as described hereinabove, is the partitioning aspect of each of the memories. For the column C<highlight><bold>0</bold></highlight>, this will result in the output from B<highlight><bold>0</bold></highlight> of information stored therein, followed by the output of information in bank B<highlight><bold>1</bold></highlight>, followed by the output of information in bank B<highlight><bold>2</bold></highlight>. This merely requires sending the address in a respective one of the banks and then sequencing through the column addresses. The information from the bank B<highlight><bold>0</bold></highlight> is output to a B<highlight><bold>0</bold></highlight> register <highlight><bold>2702</bold></highlight>, the output of the bank B<highlight><bold>1</bold></highlight> is output to a B<highlight><bold>1</bold></highlight> register <highlight><bold>2704</bold></highlight> and the output of bank B<highlight><bold>2</bold></highlight> is input to a B<highlight><bold>2</bold></highlight> register <highlight><bold>2706</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 28</cross-reference> illustrates a timing diagram for the bank access and the fact that each bank must be sequenced through before the other bank is sequenced through, it being understood that only a single row address is required for three adjacent tiles. At the end of sequencing through the bank B<highlight><bold>2</bold></highlight>, the row will be incremented. This, of course, will change when traversing from one row of tiles to the other, wherein a row address decrement in the memory will occur at B<highlight><bold>0</bold></highlight> after an initial jump in row value. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> It can also be seen that each of the banks can be individually addressed for output of data therefrom. This can be utilized when reading and writing wherein there is a latency between the Read and Write operations. For example, if there were a Read operation being performed on a bank B<highlight><bold>0</bold></highlight> for row R<highlight><bold>1</bold></highlight>, a Write operation could be performed on bank B<highlight><bold>2</bold></highlight> or B<highlight><bold>1</bold></highlight> in row R<highlight><bold>0</bold></highlight>, but not in bank B<highlight><bold>0</bold></highlight> in row R<highlight><bold>0</bold></highlight>. As such, this allows for access of two different rows in the memory at the same time. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> Although the preferred embodiment has been described in detail, it should be understood that various changes, substitutions and alterations can be made therein without departing from the spirit and scope of the invention as defined by the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A graphics engine, comprising: 
<claim-text>a rendering engine for receiving graphics primitives and converting them to pixel information for transfer to a display, said rendering engine operable to access memory locations with multiple memory access requests for a Read or a Write operation and operable in a first address space; </claim-text>
<claim-text>a plurality of memory blocks, each individually accessible and all of said plurality of memory blocks configured in a virtual address space different than said first address space; </claim-text>
<claim-text>a memory mapping device for mapping each of said memory requests to the virtual address space; and </claim-text>
<claim-text>a pipeline engine for pipelining said mapped memory access requests for both Read and Write operations in accordance with a predetermined pipelining scheme, said memory access requests received in parallel and processed asynchronously, such that access to more than one of said memory blocks can occur at substantially the same time. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The graphics engine of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said rendering engine, said memory mapping device, said pipeline engine and at least a portion of said plurality of memory blocks are contained within a common bounded space with limited connectivity to external peripheral devices. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The graphics engine of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein said plurality of memory blocks includes at least one block of external memory external to said common bounded space. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The graphics engine of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein said common bounded space comprises an integrated circuit chip with a limited number of interface pins associated therewith for input/output functions. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The graphics engine of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein said pins include an external memory access bus of a finite bit width for transferring data thereacross, and wherein said at least a portion of said plurality of memory blocks comprise embedded memory, and wherein said embedded memory is accessible with an effectively wider memory bus than said external memory bus to allow higher speed access thereto. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A graphics engine, comprising: 
<claim-text>a rendering engine for receiving graphics primitives and converting them to pixel information for transfer to a display, said rendering engine operable to access memory locations with multiple memory access requests for a Read or a Write operation and operable in a first address space; </claim-text>
<claim-text>at least one memory, accessible by said rendering engine and configured in a virtual address space different than said first address space; </claim-text>
<claim-text>a memory mapping device for mapping each of said memory requests to the virtual address space; and </claim-text>
<claim-text>a pipeline engine for pipelining said mapped memory access requests for both Read and Write operations in accordance with a predetermined pipelining scheme, said memory access requests received in parallel and processed asynchronously, such that said memory access requests can be delivered to said memory in an order different than said predetermined pipelining scheme. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The graphics engine of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein said rendering engine, at least a portion of said memory, said memory mapping device and said pipeline engine are contained within a common bounded space with limited connectivity to external peripheral devices. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The graphics engine of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein said memory includes at least one block of external memory external to said common bounded space. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The graphics engine of <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein said common bounded space comprises an integrated circuit chip with a limited number of interface pins associated therewith for input/output functions. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The graphics engine of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein said pins include an external memory access bus of a finite bit width for transferring data thereacross, and wherein said at least a portion of said memory comprise embedded memory, and wherein said embedded memory is accessible with an effectively wider memory bus than said external memory bus to allow higher speed access thereto.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001852A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001852A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001852A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001852A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001852A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001852A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001852A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001852A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001852A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001852A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001852A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030001852A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030001852A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030001852A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030001852A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
