<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002578A1-20030102-D00000.TIF SYSTEM "US20030002578A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002578A1-20030102-D00001.TIF SYSTEM "US20030002578A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002578A1-20030102-D00002.TIF SYSTEM "US20030002578A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002578A1-20030102-D00003.TIF SYSTEM "US20030002578A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002578A1-20030102-D00004.TIF SYSTEM "US20030002578A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002578A1-20030102-D00005.TIF SYSTEM "US20030002578A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002578A1-20030102-D00006.TIF SYSTEM "US20030002578A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002578A1-20030102-D00007.TIF SYSTEM "US20030002578A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002578A1-20030102-D00008.TIF SYSTEM "US20030002578A1-20030102-D00008.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002578</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10014732</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20011211</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04B001/66</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>H04N007/12</ipc>
</classification-ipc-secondary>
<classification-ipc-secondary>
<ipc>H04N011/02</ipc>
</classification-ipc-secondary>
<classification-ipc-secondary>
<ipc>H04N011/04</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>375</class>
<subclass>240010</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>375</class>
<subclass>240000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>348</class>
<subclass>384100</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>System and method for timeshifting the encoding/decoding of audio/visual signals in real-time</title-of-invention>
</technical-information>
<continuity-data>
<non-provisional-of-provisional>
<document-id>
<doc-number>60254951</doc-number>
<document-date>20001211</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
<non-provisional-of-provisional>
<document-id>
<doc-number>60254831</doc-number>
<document-date>20001211</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Ikuo</given-name>
<family-name>Tsukagoshi</family-name>
</name>
<residence>
<residence-us>
<city>Tokyo</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Klaus</given-name>
<family-name>Zimmermann</family-name>
</name>
<residence>
<residence-non-us>
<city>Deizisau</city>
<country-code>DE</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>Sony Electronics Inc.</name-1>
<name-2>Intellectual Property Department</name-2>
<address>
<address-1>16450 West Bernardo Drive, MZ 7190</address-1>
<city>San Diego</city>
<state>CA</state>
<postalcode>92127-1898</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A system and method for timeshifting the encoding and decoding of a compressed audio/video bitstream are described. In one embodiment, the compressed audio/video bitstream is encoded and stored. After a period of time, the encoded bitstream is retrieved and decoded. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">RELATED APPLICATIONS </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present application claims the benefit of U.S. Provisional Patent Applications Serial No. 60/254,951, filed on Dec. 11, 2000, and entitled &ldquo;DISPLAY SWITCH CONTROL FOR TIME SHIFTING APPLICATION&rdquo; and U.S. patent application Ser. No. 60/254,831, filed on Dec. 11, 2000, and entitled &ldquo;SOFTWARE TIME SHIFTING ON ONE-CHIP PLATFORM&rdquo;, which are herein incorporated by reference in their entirety.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present intention relates to the design of encoding/decoding systems. More specifically, the present invention pertains to a software timeshifting system. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The ever-increasing demand for high-quality audio video media has fueled the advent of audio and video storage and retrieval technology. In particular, one popular set of standards for audio and video compression is the MPEG (moving pictures experts group) standard. Today, there are several versions of the MPEG standard, each designed for different applications. Specifically, MPEG-2 is designed for high bandwidth applications such as broadcast television including high-definition television (HDTV). In order to listen and to view the content in an MPEG-2 transport stream, a system capable of encoding and decoding the compressed audio video data is essential. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Recently, digital recording of audiovisual broadcast signals on nonvolatile storage media such as hard disk drives has become highly popular. The storage medium allows one to decode the stored information in a time delayed fashion. These recorders are commonly referred to as timeshifting systems. The absolute delay or shift in time is determined by the storage capacity and recording format of the system. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Conventional real-time timeshifting systems make use of separate encoder an decoder hardware devices. The use of these dedicated devices result in a commitment to the coding and storage formats used by these devices. For example, an encoder device might store the encoded signal as an MPEG-2 transport stream on the storage medium. However, this type of system cannot support different stream formats. Additionally, a host CPU must control these separate devices and the storage medium for simultaneous encoding and time-shifted decoding in real-time. Also, the different hardware devices all require their own memory block. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> There are several PC-based timeshifting system solutions available. These timeshifting systems require several external input/output devices (video capture card, soundcard, graphics card, and video output card) together with the main CPU. Furthermore, PC-based timeshifting systems cannot be regarded as true real-time systems as they lack the fundamental concept of &ldquo;time&rdquo;. Due to this lack, PC-based timeshifting systems cannot handle time stamps. In addition, the processing and presentation time of individual data blocks is nondeterministic on these timeshifting systems. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> What is required is a system and method that combines all functional blocks of real-time timeshifting systems. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> A system and method for timeshifting the encoding and decoding of a compressed audio/video bitstream are described. In one embodiment, the compressed audio/video bitstream is encoded and stored. After a period of time, the encoded bitstream is retrieved and decoded. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Other features and advantages of the present invention will be apparent from the accompanying drawings and from the detailed description that follows. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a </italic></highlight>is a block diagram of one embodiment for a computer architecture. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b </italic></highlight>is a block diagram of one embodiment for a timeshifting system. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram of one embodiment for an encoder module of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b. </italic></highlight></paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram of one embodiment of storage or transmission medium of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b. </italic></highlight></paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a block diagram of one embodiment of the decoder module of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b. </italic></highlight></paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a thread execution diagram showing the interaction between different temporal relationships of the timeshifting system of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b. </italic></highlight></paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a control flow diagram illustrating exemplary control flow among functional modules in the software-based timeshifting system of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b. </italic></highlight></paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flow diagram of one embodiment for the timeshifting of the encoding and decoding of a bitstream. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> A system and method for timeshifting the encoding and decoding of a compressed audio/video bitstream are described. In one embodiment, the compressed audio/video bitstream is encoded and stored. After a period of time, the encoded bitstream is retrieved and decoded. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In the following detailed description of the present invention, numerous specific details are set forth in order to provide a thorough understanding of the present invention. However, it will be apparent to one skilled in the art that the present invention may be practiced without these specific details. In some instances, well-known structures and devices are shown in block diagram form, rather than in detail, in order to avoid obscuring the present invention. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Some portions of the detailed descriptions that follow are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here, and generally, conceived to be a self-consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussion, it is appreciated that throughout the description, discussions utilizing terms such as &ldquo;processing&rdquo; or &ldquo;computing&rdquo; or &ldquo;calculating&rdquo; or &ldquo;determining&rdquo; or &ldquo;displaying&rdquo; or the like, refer to the action and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (electronic) quantities within the computer system&apos;s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The present invention also relates to apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, and magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general-purpose systems may be used with programs in accordance with the teachings herein, or it may prove convenient to construct more specialized apparatus to perform the required method steps. The required structure for a variety of these systems will appear from the description below. In addition, the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a </italic></highlight>is a block diagram of one embodiment for a computer architecture. Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a</italic></highlight>, computer system <highlight><bold>180</bold></highlight> includes an address/data bus <highlight><bold>182</bold></highlight> for communicating information, central processing unit (CPU) <highlight><bold>184</bold></highlight> coupled with bus <highlight><bold>182</bold></highlight> for processing information and instructions, volatile memory <highlight><bold>186</bold></highlight> (e.g., random access memory RAM) coupled with bus <highlight><bold>182</bold></highlight> for storing information and instructions for CPU <highlight><bold>184</bold></highlight> any nonvolatile memory <highlight><bold>188</bold></highlight> (e.g., read-only memory ROM) coupled with bus <highlight><bold>182</bold></highlight> for storing static information and instructions for CPU <highlight><bold>184</bold></highlight>. In accordance with the embodiments described herein, CPU <highlight><bold>184</bold></highlight> is a single processor having a single instruction pointer. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Computer system <highlight><bold>180</bold></highlight> also includes a data storage device <highlight><bold>190</bold></highlight> (&ldquo;disk subsystem&rdquo;) such as, for example, a magnetic or optical disk or any storage device coupled with bus <highlight><bold>182</bold></highlight> for storing information instructions. Data storage device <highlight><bold>190</bold></highlight> includes one or more removable magnetic or optical storage media (for example, diskettes, tapes, or the like) which are computer readable memories. In accordance of the embodiments described herein, data storage device <highlight><bold>190</bold></highlight> may contain a bitstream of encoded information. Memory units of system <highlight><bold>180</bold></highlight> include <highlight><bold>186</bold></highlight>, <highlight><bold>188</bold></highlight>, and <highlight><bold>190</bold></highlight>. Computer system <highlight><bold>180</bold></highlight> may also include a signal input output communication device <highlight><bold>192</bold></highlight> (for example, modem, network interface card NIC) coupled to bus <highlight><bold>182</bold></highlight> for interfacing with other computer systems. In accordance with the embodiments described herein, signal input/output communication device <highlight><bold>192</bold></highlight> may receive an incoming encoded bitstream. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Also included in computer system <highlight><bold>180</bold></highlight> is an optional alphanumeric input device <highlight><bold>194</bold></highlight> including alphanumeric and function keys coupled to bus <highlight><bold>182</bold></highlight> for communicating information and command selections to CPU <highlight><bold>184</bold></highlight>. Computer system <highlight><bold>180</bold></highlight> also includes an optional cursor control or directing device <highlight><bold>196</bold></highlight> coupled to bus <highlight><bold>182</bold></highlight> for communicating user input information and command selections to CPU <highlight><bold>184</bold></highlight>. An optional display device <highlight><bold>198</bold></highlight> may also be coupled to bus <highlight><bold>182</bold></highlight> for displaying information to the computer user. Display device <highlight><bold>198</bold></highlight> may be a liquid crystal device, other flat-panel display, cathode ray tube, or other display device suitable for creating graphic images and alphanumeric characters recognizable to the user. Cursor control device <highlight><bold>196</bold></highlight> allows the computer user to dynamically signal a two-dimensional movement of a visible symbol (cursor) on a display screen or display device <highlight><bold>198</bold></highlight>. Many implementations of cursor control device <highlight><bold>196</bold></highlight> are well-known in the art including a trackball, mouse, touchpad, joystick, or special keys on alphanumeric input device <highlight><bold>194</bold></highlight> capable of signaling movement of a given direction or manner of displacement. Alternatively, it will be appreciated that the cursor may be directed or activated via input from alphanumeric input device <highlight><bold>194</bold></highlight> using special keys in key sequence commands. The present invention is also well suited to direct a cursor by other means such as, for example, voice commands. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> It is appreciated the computer system <highlight><bold>180</bold></highlight> described herein illustrates an exemplary configuration of an operational platform upon which embodiments described herein may be implemented. Nevertheless, other computer systems with different configurations may also be used to place a computer system <highlight><bold>180</bold></highlight> within the scope of the embodiments. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b </italic></highlight>is a block diagram of one embodiment for a software-based, timeshifting system <highlight><bold>100</bold></highlight>. Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b</italic></highlight>, an analog or digital input signal <highlight><bold>102</bold></highlight> is received at signal input <highlight><bold>110</bold></highlight>. Analog signals <highlight><bold>108</bold></highlight> are received and encoded by encoder system <highlight><bold>165</bold></highlight> and stored in storage or transmission medium <highlight><bold>160</bold></highlight>. Encoded signals are retrieved from storage or transmission medium <highlight><bold>160</bold></highlight> and transferred to decoder system <highlight><bold>170</bold></highlight>. Decoder signals are transferred to video and audio output <highlight><bold>150</bold></highlight>. Control of the system is handle by system control <highlight><bold>130</bold></highlight>. In one embodiment, timeshifting system <highlight><bold>100</bold></highlight> may be implemented on a single processor requiring only one unified memory block <highlight><bold>160</bold></highlight>. In addition, timeshifting system <highlight><bold>100</bold></highlight> accepts a variety of different input signal formats such as, for example, MPEG-2, MPEG-4, digital video (DV), and the like. Input signal <highlight><bold>102</bold></highlight> may be either analog or digital. Storage transmission medium <highlight><bold>160</bold></highlight> may be volatile or nonvolatile storage media. Timeshifting system <highlight><bold>100</bold></highlight> consists of multiple functional blocks. In one embodiment, the basic system <highlight><bold>100</bold></highlight> depends on the system configuration and environment as described in Table 1 below.  
<table-cwu id="TABLE-US-00001">
<number>1</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="4">
<colspec colname="1" colwidth="49PT" align="left"/>
<colspec colname="2" colwidth="56PT" align="left"/>
<colspec colname="3" colwidth="56PT" align="left"/>
<colspec colname="4" colwidth="56PT" align="left"/>
<thead>
<row>
<entry namest="1" nameend="4" align="center">TABLE 1</entry>
</row>
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="4" align="center" rowsep="1"></entry>
</row>
<row>
<entry>System</entry>
<entry></entry>
<entry></entry>
<entry></entry>
</row>
<row>
<entry>Configuration</entry>
<entry>Audio Only</entry>
<entry>Video Only</entry>
<entry>Audio and Video</entry>
</row>
<row><entry namest="1" nameend="4" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry>Analog</entry>
<entry>Audio Input,</entry>
<entry>Video Input</entry>
<entry>Audio Input,</entry>
</row>
<row>
<entry>Timeshift</entry>
<entry>Audio Encoder,</entry>
<entry>Video Encoder,</entry>
<entry>Video Input,</entry>
</row>
<row>
<entry></entry>
<entry>Multiplexer,</entry>
<entry>Multiplexer,</entry>
<entry>Audio Encoder,</entry>
</row>
<row>
<entry></entry>
<entry>Demultiplexer,</entry>
<entry>Demultiplexer,</entry>
<entry>Video Encoder,</entry>
</row>
<row>
<entry></entry>
<entry>Audio Decoder,</entry>
<entry>Video Decoder,</entry>
<entry>Multiplexer,</entry>
</row>
<row>
<entry></entry>
<entry>Audio Output</entry>
<entry>Video Output</entry>
<entry>Demultiplexer,</entry>
</row>
<row>
<entry></entry>
<entry></entry>
<entry></entry>
<entry>Audio Decoder,</entry>
</row>
<row>
<entry></entry>
<entry></entry>
<entry></entry>
<entry>Video Decoder,</entry>
</row>
<row>
<entry></entry>
<entry></entry>
<entry></entry>
<entry>Audio Output,</entry>
</row>
<row>
<entry></entry>
<entry></entry>
<entry></entry>
<entry>Video Output</entry>
</row>
<row>
<entry>Digital</entry>
<entry>Stream Input,</entry>
<entry>Stream Input,</entry>
<entry>Stream Input,</entry>
</row>
<row>
<entry>Timeshift</entry>
<entry>Demultiplexer,</entry>
<entry>Demultiplexer,</entry>
<entry>Demultiplexer,</entry>
</row>
<row>
<entry></entry>
<entry>Audio Decoder,</entry>
<entry>Video Decoder,</entry>
<entry>Audio Decoder,</entry>
</row>
<row>
<entry></entry>
<entry>Audio Output</entry>
<entry>Video Output</entry>
<entry>Video Decoder,</entry>
</row>
<row>
<entry></entry>
<entry></entry>
<entry></entry>
<entry>Audio Output,</entry>
</row>
<row>
<entry></entry>
<entry></entry>
<entry></entry>
<entry>Video Output</entry>
</row>
<row><entry namest="1" nameend="4" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Individual functional blocks makeup system modules. In one embodiment, there are two functional modules in the A/V timeshifting system: encoder module <highlight><bold>165</bold></highlight> and decoder module <highlight><bold>170</bold></highlight>. Encoder module <highlight><bold>165</bold></highlight> consists of audio input, audio encoder <highlight><bold>120</bold></highlight>, video input, video encoder <highlight><bold>115</bold></highlight> and multiplexer <highlight><bold>125</bold></highlight>. Decoder module <highlight><bold>170</bold></highlight> consists of demultiplexer <highlight><bold>135</bold></highlight>, audio decoder <highlight><bold>140</bold></highlight>, audio output, video decoder <highlight><bold>145</bold></highlight>, and video output. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> In one embodiment, encoder <highlight><bold>165</bold></highlight> process the incoming baseband signals <highlight><bold>108</bold></highlight> and converts the input signals into a digital bitstream according to the specific coding format for the audio data and video data, respectively. Encoder module <highlight><bold>165</bold></highlight> processes and writes segments of data to storage or transmission medium <highlight><bold>160</bold></highlight>. In one embodiment, these segments of data are called access units. There is one access unit generated per audio/video frame. Depending on the coding format of the output data from encoder <highlight><bold>165</bold></highlight>, the bitstream may contain additional stream information such as time stamps and program tables. In one embodiment, timeshifting system <highlight><bold>100</bold></highlight> employs at delay module, which is suitable to handle all types encoder module <highlight><bold>165</bold></highlight> output formats. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram of one embodiment for encoder module <highlight><bold>165</bold></highlight>. Referring to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, analog video input is received at analog-to-digital (A/D) converter <highlight><bold>205</bold></highlight>. A/D converter <highlight><bold>205</bold></highlight> converts the analog video signal from analog to digital format. The digital output from A/D converter <highlight><bold>205</bold></highlight> is transferred to input check <highlight><bold>210</bold></highlight> and subsequently sent to video encoder <highlight><bold>115</bold></highlight>. Analog audio input is received in A/D converter <highlight><bold>225</bold></highlight> and converted from analog to digital format. The converted audio data is sent to input check <highlight><bold>230</bold></highlight> and subsequently to audio encoder <highlight><bold>120</bold></highlight>. Encoded video data and encoded audio data are multiplexed by multiplexer <highlight><bold>125</bold></highlight> and stored in storage or transmission medium <highlight><bold>160</bold></highlight>. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> While encoder module <highlight><bold>165</bold></highlight> is writing the bitstream into storage or transmission medium <highlight><bold>160</bold></highlight>, encoder module <highlight><bold>165</bold></highlight> generates additional control information to support timeshifting. During encoding, encoder module <highlight><bold>165</bold></highlight> assembles the characteristics for every access unit and access unit descriptor. These characteristics include, for example, the access unit type, the access unit size, the recording bitrate for the access unit, a scene change flag for video signals, and the position of the first byte of the access unit in storage or transmission medium <highlight><bold>160</bold></highlight>. Encoder module <highlight><bold>165</bold></highlight> stores the individual descriptors into a dynamic data structure. In one embodiment, there is a one-to-one correspondence between the access unit descriptors and the access units in the bitstream. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> In addition, descriptors contain links to their predecessors and successors within the list. These links allow instant access to all access units within the bitstream. In addition, an individual descriptor might also contain links to several predecessors and successors depending on the supported search criteria of timeshifting system <highlight><bold>100</bold></highlight>. In one embodiment, timeshifting system <highlight><bold>100</bold></highlight> supports searching for every frame, only anchor frames, and only seen change frames. For example, if it is desired to access scene changes only, descriptors will have additional links to the next and previous access unit descriptors, which represent the first encoded video frames after a scene change. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram of one embodiment of storage or transmission medium <highlight><bold>160</bold></highlight>. Encoder module <highlight><bold>165</bold></highlight> sends stream control information to access unit descriptors <highlight><bold>305</bold></highlight> through <highlight><bold>320</bold></highlight>. In addition, encoder module <highlight><bold>165</bold></highlight> writes the bitstream to access unit storage area <highlight><bold>325</bold></highlight>. Upon playback, decoder system <highlight><bold>170</bold></highlight> accesses access unit descriptors <highlight><bold>305</bold></highlight> through <highlight><bold>320</bold></highlight> to determine the stream position to begin decoding. In one embodiment, the user may specify the starting position by choosing the desired delay between the recording and playback or by scanning the storage media <highlight><bold>160</bold></highlight> in one of the trick-play modes available within timeshifting system <highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a block diagram of one embodiment of decoder module <highlight><bold>170</bold></highlight>. Referring to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, decoder module <highlight><bold>170</bold></highlight> includes demultiplexer <highlight><bold>135</bold></highlight>, video decoder <highlight><bold>145</bold></highlight>, audio decoder <highlight><bold>140</bold></highlight>, video and audio output <highlight><bold>150</bold></highlight>, video DAC <highlight><bold>410</bold></highlight>, and audio DAC <highlight><bold>420</bold></highlight>. In one embodiment, the decode position within storage or transmission medium <highlight><bold>160</bold></highlight> is determined every time the demultiplexer <highlight><bold>135</bold></highlight> is activated. Demultiplexer <highlight><bold>135</bold></highlight> begins processing the bitstream at the location specified in the selected access unit descriptor <highlight><bold>305</bold></highlight> through <highlight><bold>320</bold></highlight>. Demultiplexer <highlight><bold>135</bold></highlight> output is fed to audio decoder <highlight><bold>140</bold></highlight> and video decoder <highlight><bold>145</bold></highlight>. Audio decoder <highlight><bold>140</bold></highlight> and video decoder <highlight><bold>145</bold></highlight> operate independently. Decoded video data is transferred to video and audio output <highlight><bold>150</bold></highlight> and subsequently output as video data <highlight><bold>410</bold></highlight>. Decoded audio data is transferred to video output <highlight><bold>150</bold></highlight> and subsequently output as audio data <highlight><bold>420</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a thread execution diagram showing the temporal relationships between the different functional blocks of timeshifting system <highlight><bold>100</bold></highlight>. Referring to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, in one embodiment, every functional block listed in Table 1 above is implemented as an individual thread within timeshifting system <highlight><bold>100</bold></highlight>. Task execution for each system module <highlight><bold>515</bold></highlight> is shown as a thread and is indicated as a horizontal solid line. The concept of multiple threading is applied to timeshifting system <highlight><bold>100</bold></highlight>. In one embodiment, a single processor with a single instruction pointer is used such that only one thread may be run at a time. However, execution is perceived as if multiple threads are executed in parallel. In one embodiment, a real-time operating system kernel schedules the processing of the threads. In one embodiment, the system kernel contains four interrupt service routines (ISR) <highlight><bold>505</bold></highlight> for controlling the timeshifting between each system module <highlight><bold>515</bold></highlight>. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> In one embodiment, timeshifting system <highlight><bold>100</bold></highlight> is completely input/output driven. Individual threads are executed based on the arrival of interrupts <highlight><bold>532</bold></highlight> through <highlight><bold>558</bold></highlight> generated by ISRs <highlight><bold>505</bold></highlight>. Note that only one thread of execution may be performed at any given time as the CPU of system <highlight><bold>100</bold></highlight> has a single instruction pointer. Thus, in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, there exists no overlap of horizontal time segments, indicating that only one functional module <highlight><bold>515</bold></highlight> may be executing a task at any given time. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a control flow diagram illustrating exemplary control flow among functional modules in a software-based timeshifting system <highlight><bold>100</bold></highlight>. Referring to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, in one embodiment, if timeshifting system <highlight><bold>100</bold></highlight> processes audio and video input signals simultaneously, four I/O devices <highlight><bold>602</bold></highlight>, <highlight><bold>604</bold></highlight>, <highlight><bold>606</bold></highlight>, and <highlight><bold>608</bold></highlight> are active and running in parallel. The input devices <highlight><bold>602</bold></highlight> and <highlight><bold>608</bold></highlight> generate interrupts whenever frame buffer has been filled with data. Similarly, the output devices <highlight><bold>604</bold></highlight> and <highlight><bold>606</bold></highlight> generate interrupts whenever the frame buffer has been output through the input devices <highlight><bold>602</bold></highlight> and <highlight><bold>608</bold></highlight>. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> In one embodiment, there is strict separation between the audio and video processing threads. The separation is achieved by maintaining two independent time bases in timeshifting system <highlight><bold>100</bold></highlight>, one for audio and one for video. The audio interfaces establish the audio time base whereas the video interfaces establish the video time base. In this embodiment, the two different time bases are inherently different due to the nature of the formats. The different time bases are depicted in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. Due to this time-based independence, system <highlight><bold>100</bold></highlight> is able to support audio only, video only, and mixed (audio and video) signal configurations. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> Individual threads communicate with each other through message queues. In one embodiment, because the system is purely input/output driven, the interrupts generated by the input/output interfaces and message queues (A<highlight><bold>0</bold></highlight>, V<highlight><bold>0</bold></highlight>, and V<highlight><bold>1</bold></highlight>) control the execution of the input/output threads. Timeshifting system <highlight><bold>100</bold></highlight> uses a static configuration that is passed from background thread <highlight><bold>618</bold></highlight> via message queue MST <highlight><bold>622</bold></highlight> at system startup. The configuration parameters are then distributed to the individual threads through message queues originating in the A/V output thread. This thread also collects all the threads&apos; feedback status messages and reports then to the background thread. The background thread reacts to the status messages by reconfiguring the system through subsequent MST messages. Table 2 lists examples of the message queues employed by timeshifting system <highlight><bold>100</bold></highlight>.  
<table-cwu id="TABLE-US-00002">
<number>2</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="70PT" align="left"/>
<colspec colname="2" colwidth="77PT" align="left"/>
<colspec colname="3" colwidth="70PT" align="left"/>
<thead>
<row>
<entry namest="1" nameend="3" align="center">TABLE 2</entry>
</row>
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="3" align="center" rowsep="1"></entry>
</row>
<row>
<entry>Message Queue Name</entry>
<entry>Function</entry>
<entry>Message Data</entry>
</row>
<row><entry namest="1" nameend="3" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry>MST</entry>
<entry>System (static)</entry>
<entry>System configuration</entry>
</row>
<row>
<entry></entry>
<entry>configuration</entry>
<entry>parameters</entry>
</row>
<row>
<entry>MSTF</entry>
<entry>System feedback</entry>
<entry>System status</entry>
</row>
<row>
<entry>A0</entry>
<entry>Audio input execution</entry>
<entry>Time stamp</entry>
</row>
<row>
<entry></entry>
<entry>timing</entry>
</row>
<row>
<entry>V0</entry>
<entry>Video input execution</entry>
<entry>Time stamp</entry>
</row>
<row>
<entry></entry>
<entry>timing</entry>
</row>
<row>
<entry>V1</entry>
<entry>Audio/Video output</entry>
<entry>Time stamp</entry>
</row>
<row>
<entry></entry>
<entry>execution timing</entry>
</row>
<row>
<entry>A1</entry>
<entry>Audio input</entry>
<entry>Input configuration</entry>
</row>
<row>
<entry></entry>
<entry>configuration</entry>
<entry>parameters</entry>
</row>
<row>
<entry>AIF</entry>
<entry>Audio input thread</entry>
<entry>Status, data buffer</entry>
</row>
<row>
<entry></entry>
<entry>feedback</entry>
<entry>information</entry>
</row>
<row>
<entry>VI</entry>
<entry>Video input</entry>
<entry>Input configuration</entry>
</row>
<row>
<entry></entry>
<entry>configuration</entry>
<entry>parameters</entry>
</row>
<row>
<entry>VIF</entry>
<entry>Video input thread</entry>
<entry>Status, data buffer</entry>
</row>
<row>
<entry></entry>
<entry>feedback</entry>
<entry>information</entry>
</row>
<row>
<entry>EA</entry>
<entry>Audio encoder thread</entry>
<entry>Command (initialize,</entry>
</row>
<row>
<entry></entry>
<entry>control</entry>
<entry>encode, etc.)</entry>
</row>
<row>
<entry>EAF</entry>
<entry>Audio encoder thread</entry>
<entry>Status, data buffer</entry>
</row>
<row>
<entry></entry>
<entry>feedback</entry>
<entry>information</entry>
</row>
<row>
<entry>EV</entry>
<entry>Video encoder thread</entry>
<entry>Command (initialize,</entry>
</row>
<row>
<entry></entry>
<entry>control</entry>
<entry>encode, etc.)</entry>
</row>
<row>
<entry>EVF</entry>
<entry>Video encoder thread</entry>
<entry>Status, data buffer</entry>
</row>
<row>
<entry></entry>
<entry>feedback</entry>
<entry>information</entry>
</row>
<row>
<entry>M</entry>
<entry>Multiplexer thread</entry>
<entry>Command (initialize,</entry>
</row>
<row>
<entry></entry>
<entry>control</entry>
<entry>multiplex, etc.), data</entry>
</row>
<row>
<entry></entry>
<entry></entry>
<entry>buffer information</entry>
</row>
<row>
<entry>MF</entry>
<entry>Multiplexer thread</entry>
<entry>Status, data buffer</entry>
</row>
<row>
<entry></entry>
<entry>feedback</entry>
<entry>information</entry>
</row>
<row>
<entry>DM</entry>
<entry>Demultiplexer thread</entry>
<entry>Command (initialize,</entry>
</row>
<row>
<entry></entry>
<entry>control</entry>
<entry>demultiplex, etc.), data</entry>
</row>
<row>
<entry></entry>
<entry></entry>
<entry>buffer information</entry>
</row>
<row>
<entry>DMF</entry>
<entry>Demultiplexer thread</entry>
<entry>Status, data buffer</entry>
</row>
<row>
<entry></entry>
<entry>feedback</entry>
<entry>information</entry>
</row>
<row>
<entry>DA</entry>
<entry>Audio decoder thread</entry>
<entry>Command (initialize,</entry>
</row>
<row>
<entry></entry>
<entry>control</entry>
<entry>decode, etc.)</entry>
</row>
<row>
<entry>DAF</entry>
<entry>Audio decoder thread</entry>
<entry>Status, data buffer</entry>
</row>
<row>
<entry></entry>
<entry>feedback</entry>
<entry>information</entry>
</row>
<row>
<entry>DV</entry>
<entry>Video decoder thread</entry>
<entry>Command (initialize,</entry>
</row>
<row>
<entry></entry>
<entry>control</entry>
<entry>decode, etc.)</entry>
</row>
<row>
<entry>DVF</entry>
<entry>Video decoder thread</entry>
<entry>Status, data buffer</entry>
</row>
<row>
<entry></entry>
<entry>feedback</entry>
<entry>information</entry>
</row>
<row><entry namest="1" nameend="3" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In one embodiment, video input ISR <highlight><bold>608</bold></highlight> receives an interrupt from system control <highlight><bold>130</bold></highlight> that input data has been received by signal input <highlight><bold>110</bold></highlight>. Video input ISR <highlight><bold>608</bold></highlight> sends message V<highlight><bold>0</bold></highlight> via message queue V<highlight><bold>0</bold></highlight> <highlight><bold>674</bold></highlight> to video input manager <highlight><bold>634</bold></highlight> to begin processing the video input stream. Video input manager <highlight><bold>634</bold></highlight> sends feedback message VIF via message queue VIF <highlight><bold>628</bold></highlight> to video output control <highlight><bold>632</bold></highlight>. Video output control <highlight><bold>632</bold></highlight> sends message EV via message queue EV <highlight><bold>652</bold></highlight> to video encoder <highlight><bold>668</bold></highlight> to begin the video encoding thread once the data input buffer is full. Feedback message EVF is sent via message queue EVF <highlight><bold>654</bold></highlight> to video output control <highlight><bold>632</bold></highlight> with status and buffer information. Video encoder <highlight><bold>115</bold></highlight> begins video encoder thread <highlight><bold>668</bold></highlight> to encode the input video stream. Video encoder <highlight><bold>115</bold></highlight> processes the input video stream for a set period of time set by message MST. Parameters within message MST are set either at system start-up or by the user during the encoding/decoding process. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> Once the time period for video input has elapsed, audio input ISR <highlight><bold>602</bold></highlight> sends message A<highlight><bold>0</bold></highlight> via message queue A<highlight><bold>0</bold></highlight> <highlight><bold>610</bold></highlight> to audio input manager <highlight><bold>612</bold></highlight> for audio input manager <highlight><bold>612</bold></highlight> to begin processing the audio input stream. Audio input manager <highlight><bold>612</bold></highlight> sends feedback message AIF via message queue AIF <highlight><bold>616</bold></highlight> to audio output control <highlight><bold>630</bold></highlight>. Audio output control <highlight><bold>630</bold></highlight> sends feedback message A<highlight><bold>1</bold></highlight> via message queue A<highlight><bold>1</bold></highlight> <highlight><bold>614</bold></highlight> to audio input manager <highlight><bold>612</bold></highlight> and sends message EA via message queue EA <highlight><bold>640</bold></highlight> to audio encoder <highlight><bold>120</bold></highlight> to begin processing audio encoder thread <highlight><bold>662</bold></highlight>. Audio encoder thread <highlight><bold>662</bold></highlight> sends feedback message EAF via message queue EAF <highlight><bold>642</bold></highlight> to audio output control <highlight><bold>630</bold></highlight> and processes the audio input for a set period of time set by message MST. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Once the time period for audio input has elapsed, audio output control <highlight><bold>630</bold></highlight> sends message M via message queue M <highlight><bold>644</bold></highlight> to multiplexer <highlight><bold>125</bold></highlight> for multiplexer <highlight><bold>125</bold></highlight> to begin multiplexing thread <highlight><bold>664</bold></highlight>. Multiplexing thread <highlight><bold>664</bold></highlight> sends feedback message MF via message queue MF <highlight><bold>648</bold></highlight> to audio output control <highlight><bold>630</bold></highlight> and multiplexes the encoded video and audio streams, sending the multiplexed bitstream to storage or transmission medium <highlight><bold>160</bold></highlight>. Multiplexing thread <highlight><bold>664</bold></highlight> continues multiplexing the streams for a set period of time set by MST. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> After the multiplexing thread <highlight><bold>664</bold></highlight> time period has elapsed, system control <highlight><bold>130</bold></highlight> sends an interrupt to the encoder <highlight><bold>165</bold></highlight> to stop processing and sends message V<highlight><bold>1</bold></highlight> via message queue V<highlight><bold>1</bold></highlight> <highlight><bold>672</bold></highlight> to video output control <highlight><bold>632</bold></highlight>. Video output control <highlight><bold>632</bold></highlight> sends message DM via message queue DM <highlight><bold>648</bold></highlight> to demultiplexer <highlight><bold>135</bold></highlight> to begin demultiplexing thread <highlight><bold>666</bold></highlight>. Demultiplexing thread <highlight><bold>666</bold></highlight> sends feedback message DMF via message queue DMF <highlight><bold>650</bold></highlight> to video output control <highlight><bold>632</bold></highlight>. Demultiplexing thread <highlight><bold>666</bold></highlight> retrieves the access unit <highlight><bold>325</bold></highlight> pointed to by the access unit pointer together with the access unit descriptor information for the access unit from storage or transmission medium <highlight><bold>160</bold></highlight>. Demultiplexing thread <highlight><bold>666</bold></highlight> processes the access unit <highlight><bold>325</bold></highlight> for a given period of time set by MST. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> After the time period for demultiplexing has elapsed, control is transferred to video decoder <highlight><bold>145</bold></highlight>. Video output control <highlight><bold>632</bold></highlight> sends message DV via message queue DV <highlight><bold>658</bold></highlight> to video decoder <highlight><bold>145</bold></highlight> for video decoder <highlight><bold>145</bold></highlight> to begin video decoder thread <highlight><bold>670</bold></highlight>. Video decoder thread <highlight><bold>670</bold></highlight> processes the demultiplexed output video stream for a period of time set by MST. Video decoder thread <highlight><bold>670</bold></highlight> sends feedback message DVF via message queue DVF <highlight><bold>656</bold></highlight> to video output control <highlight><bold>632</bold></highlight> and processes the video stream. The output video stream is sent to video and audio output <highlight><bold>150</bold></highlight>. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> After the time period for output video decoding has elapsed, control is transferred to audio decoder <highlight><bold>140</bold></highlight>. Audio output control <highlight><bold>630</bold></highlight> sends audio decoder <highlight><bold>140</bold></highlight> message DA via message queue DA <highlight><bold>636</bold></highlight> for audio decoder <highlight><bold>140</bold></highlight> to begin audio decoder thread <highlight><bold>660</bold></highlight>. Audio decoder thread <highlight><bold>660</bold></highlight> processes the demultiplexed audio stream for a period of time set by message MST. Audio decoder thread <highlight><bold>660</bold></highlight> sends the output audio to video and audio output <highlight><bold>150</bold></highlight>. Audio decoder thread <highlight><bold>660</bold></highlight> sends feedback message DAF via message queue DAF <highlight><bold>638</bold></highlight> to audio output control <highlight><bold>630</bold></highlight>. Audio decoder thread <highlight><bold>660</bold></highlight> continues processing the output audio until the time period set by MST has elapsed. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Video and audio output <highlight><bold>150</bold></highlight> outputs the video stream <highlight><bold>114</bold></highlight> and the audio stream <highlight><bold>116</bold></highlight> to output display devices at a given frame rate for the output devices. Thus, in one embodiment, an input frame of data is encoded for a given period of time set by MST at system startup by background <highlight><bold>618</bold></highlight>. The encoded input stream is stored in storage or transmission medium <highlight><bold>160</bold></highlight>. After a period of time set by MST, the decoding process begins and a frame of encoded data (access unit) is retrieved from storage or transmission medium <highlight><bold>160</bold></highlight>, decoded by decoder device <highlight><bold>170</bold></highlight>, and sent to video and audio output <highlight><bold>150</bold></highlight>. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> The input interfaces and the corresponding output interfaces are synchronized by mechanism described in application serial number ___/___,___, entitled &ldquo;System and Method for Effectively Performing an Audio/Video Synchronization Procedure&rdquo; which is herein incorporated by reference. This synchronization mechanism, in combination with the independence of audio and video processing, prevents the buffer from over- or under-flowing within timeshifting system <highlight><bold>100</bold></highlight> as long as real-time requirements are met. Both input threads (the audio input thread <highlight><bold>662</bold></highlight> and the video input thread <highlight><bold>668</bold></highlight>) may detect a valid input signal at their respective I/O interfaces (<highlight><bold>602</bold></highlight>, <highlight><bold>608</bold></highlight>). If there is no signal or an invalid input signal, the particular input thread will not pass any data to the encoder thread (<highlight><bold>662</bold></highlight> and <highlight><bold>668</bold></highlight> respectively). The input thread data passing will resume once the input logic detects a valid signal at the input device. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> In one embodiment, a user may interact with timeshifting system <highlight><bold>100</bold></highlight> by specifying a system parameter string during runtime. The modifiable parameters may be, for example, time delay, recording bitrate, and output channel. Timeshifting system <highlight><bold>100</bold></highlight> scans these parameters each time the A/V output thread <highlight><bold>630</bold></highlight>, <highlight><bold>632</bold></highlight> is active. The output thread <highlight><bold>630</bold></highlight>, <highlight><bold>632</bold></highlight> responds to the user input by reconfiguring timeshifting system <highlight><bold>100</bold></highlight> according to the user request. For example, if the user changes the time delay, the A/V output thread <highlight><bold>630</bold></highlight>, <highlight><bold>632</bold></highlight> scans this parameter. The A/V output thread <highlight><bold>630</bold></highlight>, <highlight><bold>632</bold></highlight> then passes the delay parameter to demultiplexer thread <highlight><bold>666</bold></highlight>. Demultiplexer thread <highlight><bold>666</bold></highlight> modifies the position from where it is reading in the stored bitstream according to the specified time delay. In one embodiment, the user input time delay of this polling mechanism may not exceed one video frame, which equals 33 milliseconds for the NTSC format. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> System <highlight><bold>100</bold></highlight> may be implemented in a microprocessor, microcontroller or signal processor with integrated video and audio output interfaces. The processor should be able to handle the schedule threads in real-time. A real-time operating system is running on a processor supporting interrupts, message queues, and task switches. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> Timeshifting system <highlight><bold>100</bold></highlight> has been implemented using MPEG-2 standard to either generate compliant transport stream output or elementary stream outputs (one for audio and one for video) on storage or transmission medium <highlight><bold>160</bold></highlight>. The video Codec utilizing the MPEG-2 video format to generate an MPEG-2 video elementary output stream has also been implemented. The audio Codec utilizes the PC and data format. In one implementation, dynamic input of user parameters to the timeshifting system <highlight><bold>100</bold></highlight> is handled by an interrupt-based mechanism. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Timeshifting system <highlight><bold>100</bold></highlight> may be used to perform timeshifting using a variety of different coding schemes and system formats such as, for example, MPEG-1, MPEG-4, DV (digital video), JPEG, Motion JPEG-2000, and the like. For example, it is possible to use a swapout of the audio Codec and replace it by a different Codec. Further, timeshifting system <highlight><bold>100</bold></highlight> may write to any format external storage or transmission medium <highlight><bold>160</bold></highlight>. For example, timeshifting system <highlight><bold>100</bold></highlight> may output MPEG-2 A/V elementary streams, if desired. Timeshifting system <highlight><bold>100</bold></highlight> may also be configured to make use of a volatile storage device (for example, RAM-based recorders). </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flow diagram of one embodiment for the timeshifting of the encoding and decoding of a bitstream. At processing block <highlight><bold>705</bold></highlight>, a compressed domain bitstream is encoded. Initially, a static configuration is passed from background thread <highlight><bold>618</bold></highlight> via message queue MST <highlight><bold>622</bold></highlight> at system startup. Configuration parameters are distributed to the individual threads through message queues originating in the A/V output thread. In one embodiment, if timeshifting system <highlight><bold>100</bold></highlight> processes audio and video input signals simultaneously, four I/O devices <highlight><bold>602</bold></highlight>, <highlight><bold>604</bold></highlight>, <highlight><bold>606</bold></highlight>, and <highlight><bold>608</bold></highlight> are active and running in parallel. The input devices <highlight><bold>602</bold></highlight> and <highlight><bold>608</bold></highlight> generate interrupts whenever frame buffer has been filled with data. Similarly, the output devices <highlight><bold>604</bold></highlight> and <highlight><bold>606</bold></highlight> generate interrupts whenever the frame buffer has been output through the input devices <highlight><bold>602</bold></highlight> and <highlight><bold>608</bold></highlight>. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> In one embodiment, there is strict separation between the audio and video processing threads. The separation is achieved by maintaining two independent time bases in timeshifting system <highlight><bold>100</bold></highlight>, one for audio and one for video. The audio interfaces establish the audio time base whereas the video interfaces establish the video time base. In this embodiment, the two different time bases are inherently different due to the nature of the formats. The different time bases are depicted in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. Due to this time-based independence, system <highlight><bold>100</bold></highlight> is able to support audio only, video only, and mixed (audio and video) signal configurations. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> In one embodiment, video input ISR <highlight><bold>608</bold></highlight> receives an interrupt from system control <highlight><bold>130</bold></highlight> that input data has been received by signal input <highlight><bold>110</bold></highlight>. Video input ISR <highlight><bold>608</bold></highlight> sends message V<highlight><bold>0</bold></highlight> via message queue V<highlight><bold>0</bold></highlight> <highlight><bold>674</bold></highlight> to video input manager <highlight><bold>634</bold></highlight> to begin processing the video input stream. Video input manager <highlight><bold>634</bold></highlight> sends feedback message VIF via message queue VIF <highlight><bold>628</bold></highlight> to video output control <highlight><bold>632</bold></highlight>. Video output control <highlight><bold>632</bold></highlight> sends message EV via message queue EV <highlight><bold>652</bold></highlight> to video encoder <highlight><bold>668</bold></highlight> to begin the video encoding thread once the data input buffer is full. Feedback message EVF is sent via message queue EVF <highlight><bold>654</bold></highlight> to video output control <highlight><bold>632</bold></highlight> with status and buffer information. Video encoder <highlight><bold>115</bold></highlight> begins video encoder thread <highlight><bold>668</bold></highlight> to encode the input video stream. Video encoder <highlight><bold>115</bold></highlight> processes the input video stream for a set period of time set by message MST. Parameters within message MST are set either at system start-up or by the user during the encoding/decoding process. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> Once the time period for video input has elapsed, audio input ISR <highlight><bold>602</bold></highlight> sends message A<highlight><bold>0</bold></highlight> via message queue A<highlight><bold>0</bold></highlight> <highlight><bold>610</bold></highlight> to audio input manager <highlight><bold>612</bold></highlight> for audio input manager <highlight><bold>612</bold></highlight> to begin processing the audio input stream. Audio input manager <highlight><bold>612</bold></highlight> sends feedback message AIF via message queue AIF <highlight><bold>616</bold></highlight> to audio output control <highlight><bold>630</bold></highlight>. Audio output control <highlight><bold>630</bold></highlight> sends feedback message A<highlight><bold>1</bold></highlight> via message queue A<highlight><bold>1</bold></highlight> <highlight><bold>614</bold></highlight> to audio input manager <highlight><bold>612</bold></highlight> and sends message EA via message queue EA <highlight><bold>640</bold></highlight> to audio encoder <highlight><bold>120</bold></highlight> to begin processing audio encoder thread <highlight><bold>662</bold></highlight>. Audio encoder thread <highlight><bold>662</bold></highlight> sends feedback message EAF via message queue EAF <highlight><bold>642</bold></highlight> to audio output control <highlight><bold>630</bold></highlight> and processes the audio input for a set period of time set by message MST. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Once the time period for audio input has elapsed, audio output control <highlight><bold>630</bold></highlight> sends message M via message queue M <highlight><bold>644</bold></highlight> to multiplexer <highlight><bold>125</bold></highlight> for multiplexer <highlight><bold>125</bold></highlight> to begin multiplexing thread <highlight><bold>664</bold></highlight>. Multiplexing thread <highlight><bold>664</bold></highlight> sends feedback message MF via message queue MF <highlight><bold>648</bold></highlight> to audio output control <highlight><bold>630</bold></highlight> and multiplexes the encoded video and audio streams, sending the multiplexed bitstream to storage or transmission medium <highlight><bold>160</bold></highlight>. Multiplexing thread <highlight><bold>664</bold></highlight> continues multiplexing the streams for a set period of time set by MST. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> At processing block <highlight><bold>710</bold></highlight>, the encoded bitstream is stored in storage or transmission medium <highlight><bold>160</bold></highlight>. In one embodiment, output from multiplexer <highlight><bold>125</bold></highlight> is stored in storage or transmission medium <highlight><bold>160</bold></highlight>. Encoder module <highlight><bold>165</bold></highlight> processes and write segments of data to storage or transmission medium <highlight><bold>160</bold></highlight>. In one embodiment, these segments of data are called access units. There is one access unit generated per audio/video frame. Depending on the coding format of the output data from encoder <highlight><bold>165</bold></highlight>, the bitstream may contain additional stream information such as time stamps and program tables. In one embodiment, timeshifting system <highlight><bold>100</bold></highlight> employs at delay module, which is suitable to handle all types encoder module <highlight><bold>165</bold></highlight> output formats. Encoder module <highlight><bold>165</bold></highlight> sends stream control information to access unit descriptors <highlight><bold>305</bold></highlight> through <highlight><bold>320</bold></highlight>. In addition, encoder module <highlight><bold>165</bold></highlight> writes the bitstream to access unit storage area <highlight><bold>325</bold></highlight>. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> At processing block <highlight><bold>715</bold></highlight>, the encoded bitstream is retrieved from storage or transmission medium <highlight><bold>160</bold></highlight> after a period of time. Upon playback, decoder system <highlight><bold>170</bold></highlight> accesses access unit descriptors <highlight><bold>305</bold></highlight> through <highlight><bold>320</bold></highlight> to determine the stream position to begin decoding. In one embodiment, the user may specify the starting position by choosing the desired delay between the recording and playback or by scanning the storage media <highlight><bold>160</bold></highlight> in one of the trick-play modes available within timeshifting system <highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> At processing block <highlight><bold>720</bold></highlight>, the retrieved bitstream is decoded. In one embodiment, the decode position within storage or transmission medium <highlight><bold>160</bold></highlight> is determined every time the demultiplexer <highlight><bold>135</bold></highlight> is activated. Demultiplexer <highlight><bold>135</bold></highlight> begins processing the bitstream at the location specified in the selected access unit descriptor <highlight><bold>305</bold></highlight> through <highlight><bold>320</bold></highlight>. Demultiplexer <highlight><bold>135</bold></highlight> output is fed to audio decoder <highlight><bold>140</bold></highlight> and video decoder <highlight><bold>145</bold></highlight>. Audio decoder <highlight><bold>140</bold></highlight> and video decoder <highlight><bold>145</bold></highlight> operate independently. Decoded video data is transferred to video and audio output <highlight><bold>150</bold></highlight> and subsequently output as video data <highlight><bold>410</bold></highlight>. Decoded audio data is transferred to video output <highlight><bold>150</bold></highlight> and subsequently output as audio data <highlight><bold>420</bold></highlight>. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> The specific arrangements and methods herein are merely illustrative of the principles of this invention. Numerous modifications in form and detail may be made by those skilled in the art without departing from the true spirit and scope of the invention. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method comprising: 
<claim-text>encoding a compressed domain bitstream; </claim-text>
<claim-text>storing the encoded bitstream; </claim-text>
<claim-text>retrieving the encoded bitstream after a period of time; and </claim-text>
<claim-text>decoding the retrieved bitstream. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the period of time is programmable. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the period of time depends upon the quality of the bit rate of encoding. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the period of time depends upon the complexity of the encoded image. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the compressed bitstream comprises audio data, video data, and audio and video data. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein encoding further comprises maintaining two independent time bases for audio and video input. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein encoding further comprises: 
<claim-text>encoding an input video stream for a set period of time to generate an encoded video bitstream; </claim-text>
<claim-text>encoding an input audio stream for a set period of time to generate an encoded audio bitstream; and </claim-text>
<claim-text>multiplexing the encoded video bitstream and encoded audio bitstream to generate the compressed bitstream. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein decoding further comprises: 
<claim-text>demultiplexing the compressed bitstream into a demultiplexed video stream and a demultiplexed audio stream; </claim-text>
<claim-text>decoding the demultiplexed video stream into an output video stream; and </claim-text>
<claim-text>decoding the demultiplexed audio stream into an output audio stream. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein retrieving the encoded bitstream beginning at an access unit pointer. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference> further comprising: 
<claim-text>setting the position of the access unit pointer via a system start-up parameter. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference> wherein a position of the access unit pointer defines a specified time delay. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A system comprising: 
<claim-text>an encoder for encoding a compressed domain bitstream; </claim-text>
<claim-text>a storage medium for storing the encoded bitstream; and </claim-text>
<claim-text>a decoder for retrieving the encoded bitstream after a period of time and decoding the retrieved bitstream. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> wherein the period of time is programmable. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> wherein the period of time depends upon the quality of the bit rate of encoding. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> wherein the period of time depends upon the complexity of the encoded image. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> wherein the compressed bitstream comprises audio data, video data, and audio and video data. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> wherein the encoder further maintains two independent time bases for audio and video input. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> wherein the encoder further encodes an input video stream for a set period of time to generate an encoded video bitstream, encodes an input audio stream for a set period of time to generate an encoded audio bitstream, and multiplexes the encoded video bitstream and encoded audio bitstream to generate the compressed bitstream. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> wherein the decoder further demultiplexes the compressed bitstream into a demultiplexed video stream and a demultiplexed audio stream, decodes the demultiplexed video stream into an output video stream, and decodes the demultiplexed audio stream into an output audio stream. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> wherein the decoder retrieves the encoded bitstream beginning at an access unit pointer. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference> wherein a background thread sets the position of the access unit pointer via a system start-up parameter. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference> wherein a position of the access unit pointer defines a specified time delay. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A system comprising: 
<claim-text>means for encoding a compressed domain bitstream; </claim-text>
<claim-text>means for storing the encoded bitstream; </claim-text>
<claim-text>means for retrieving the encoded bitstream after a period of time; and </claim-text>
<claim-text>means for decoding the retrieved bitstream. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A computer readable medium comprising instructions, which when executed on a processor, perform a method for timeshifting the encoding and decoding of a bitstream, the system comprising: 
<claim-text>means for encoding a compressed domain bitstream; </claim-text>
<claim-text>means for storing the encoded bitstream; </claim-text>
<claim-text>means for retrieving the encoded bitstream after a period of time; and </claim-text>
<claim-text>means for decoding the retrieved bitstream.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002578A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002578A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002578A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002578A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002578A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002578A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002578A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002578A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002578A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
