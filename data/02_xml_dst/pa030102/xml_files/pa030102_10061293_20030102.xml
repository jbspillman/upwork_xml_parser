<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001958A1-20030102-M00001.NB SYSTEM "US20030001958A1-20030102-M00001.NB" NDATA NB>
<!ENTITY US20030001958A1-20030102-M00001.TIF SYSTEM "US20030001958A1-20030102-M00001.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-M00002.NB SYSTEM "US20030001958A1-20030102-M00002.NB" NDATA NB>
<!ENTITY US20030001958A1-20030102-M00002.TIF SYSTEM "US20030001958A1-20030102-M00002.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-M00003.NB SYSTEM "US20030001958A1-20030102-M00003.NB" NDATA NB>
<!ENTITY US20030001958A1-20030102-M00003.TIF SYSTEM "US20030001958A1-20030102-M00003.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-M00004.NB SYSTEM "US20030001958A1-20030102-M00004.NB" NDATA NB>
<!ENTITY US20030001958A1-20030102-M00004.TIF SYSTEM "US20030001958A1-20030102-M00004.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00000.TIF SYSTEM "US20030001958A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00001.TIF SYSTEM "US20030001958A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00002.TIF SYSTEM "US20030001958A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00003.TIF SYSTEM "US20030001958A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00004.TIF SYSTEM "US20030001958A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00005.TIF SYSTEM "US20030001958A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00006.TIF SYSTEM "US20030001958A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00007.TIF SYSTEM "US20030001958A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00008.TIF SYSTEM "US20030001958A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00009.TIF SYSTEM "US20030001958A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00010.TIF SYSTEM "US20030001958A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00011.TIF SYSTEM "US20030001958A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00012.TIF SYSTEM "US20030001958A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00013.TIF SYSTEM "US20030001958A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00014.TIF SYSTEM "US20030001958A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00015.TIF SYSTEM "US20030001958A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030001958A1-20030102-D00016.TIF SYSTEM "US20030001958A1-20030102-D00016.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001958</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10061293</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020204</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2001-155514</doc-number>
</priority-application-number>
<filing-date>20010524</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04N009/73</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>H04N003/14</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>348</class>
<subclass>223100</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>348</class>
<subclass>229100</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>348</class>
<subclass>280000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>348</class>
<subclass>348000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>348</class>
<subclass>366000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>White balance adjustment method, image processing apparatus and electronic camera</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Hideo</given-name>
<family-name>Hoshuyama</family-name>
</name>
<residence>
<residence-non-us>
<city>Kawasaki-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<assignee>
<organization-name>Nikon Corporation</organization-name>
<address>
<address-1>2-3, Marunouchi 3-chome</address-1>
<address-2>Chiyoda-ku</address-2>
<city>Tokyo</city>
<postalcode>100-8331</postalcode>
<country>
<country-code>JP</country-code>
</country>
</address>
<assignee-type>03</assignee-type>
</assignee>
<correspondence-address>
<name-1>OLIFF &amp; BERRIDGE, PLC</name-1>
<name-2></name-2>
<address>
<address-1>P.O. BOX 19928</address-1>
<city>ALEXANDRIA</city>
<state>VA</state>
<postalcode>22320</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">An image-capturing device captures a subject image through an exchangeable lens. A white balance sensor that is set at a position conjugate with the position of the image-capturing device relative to the exchangeable lens to receive the light from the subject image and outputs color signals. A white balance adjustment signal calculation circuit calculates white balance adjustment basic signals based upon the color signals output from the white balance sensor and weighting points in conformance to the photographic range, the number of sets of red color data and the subject brightness value. Adjustment signals to be used for white balance adjustment are determined based upon the weighting points and the adjustment basic signals. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">INCORPORATION BY REFERENCE </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The disclosure of the following priority application is incorporated herein by reference: </paragraph>
<paragraph id="P-0002" lvl="2"><number>&lsqb;0002&rsqb;</number> Japanese Patent Application No. 2001-155514 filed May 24, 2001 </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> The present invention relates to an electronic camera that captures a subject image and records image data. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> There are electronic cameras in the known art having an image-capturing device and an image processing circuit. The image capturing device captures a subject image having passed through a photographic lens with a CCD or the like and outputs image data. The image processing circuit implements image processing such as white balance adjustment and &ggr; control by adjusting the amplification gain to be applied to the image data output by the image-capturing device. In the image processing circuit, the image processing is performed by calculating parameters such as the R-gain and the B-gain for the white balance adjustment, the gradation curve for the &ggr; control or the like using predetermined algorithms based upon the image data output from the image-capturing device. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> The white balance adjustment may be performed in an electronic camera by adopting one of the following three methods in the known art, for instance. The first method is disclosed in Japanese Laid-Open Patent Publication No. S56-36292. A white balance adjustment coefficient is calculated so that the average value of color information corresponding to the main subject, the background and the like obtained through an image-capturing operation becomes an achromatic color that may be white or gray. Then, a white balance adjustment is implemented on the image data by using the adjustment coefficient thus calculated. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The second method is disclosed in Japanese Laid-Open Patent Publication No. H 5-292533. An image plane to be photographed is divided into a plurality of small areas and a small area whose average value of the color information is within a predetermined range is extracted. Then, a white balance adjustment coefficient is calculated so that the average value of the color information corresponding to the extracted small area to indicate an achromatic color and a white balance adjustment is implemented on the image data using the adjustment coefficient thus calculated. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> The third method is disclosed in Japanese Laid-Open Patent Publication No. 2000-224608. A small area indicating a specific color is extracted from the photographic image plane, a white balance adjustment coefficient is calculated so as to set the color in the extracted small area to a specific color and a white balance adjustment is performed on the image data using the adjustment coefficient thus calculated. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> While each of the white balance adjustment methods described above has its advantages, they all have problems to be addressed. Accordingly, Japanese Laid-Open Patent Publication No. H 6-98335 discloses a technology through which one of the three white balance adjustment signal calculation methods is selected. However, there is a concern that as the white balance adjustment value may change greatly over an area where a borderline of judgment performed to select one of the methods is present, the image having undergone the white balance adjustment may appear unnatural in such a case. In addition, an image with unnatural color results from an error in the selection judgment process and thus, a white balance adjustment failure occurs readily. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The present invention is directed to a technique to prevent a white balance adjustment failure by weighting a plurality of white balance adjustment gains through an analysis of the scene being photographed. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In a white balance adjustment method according to the present invention, chromaticity of a subject is detected by using an image-capturing signal of an image of the subject that has been photographed, a scene is analyzed by using the image-capturing signal, a white balance adjustment gain for the image-capturing signal is calculated based upon the detected chromaticity of the subject and the results of analyzing the scene, and a white balance adjustment is performed by applying the white balance adjustment gain to the image-capturing signal. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> An image processing apparatus according to the present invention comprises a chromaticity detection unit that detects chromaticity of a subject by using an image-capturing signal of an image of the subject that has been photographed, a scene analysis unit that analyzes a scene by using the image-capturing signal, a gain calculation unit that calculates a white balance adjustment gain for the image-capturing signal based upon detected chromaticity of the subject and the results of analyzing the scene, and a white balance adjustment unit that performs a white balance adjustment by applying the white balance adjustment gains to the image-capturing signal. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> An electronic camera according to the present invention comprises an image-capturing device that captures a subject image passing through a photographic lens and outputs an image-capturing signal, and the above-noted image processing apparatus. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> An electronic camera according to the present invention comprises an image-capturing device that captures a subject image passing through a photographic lens and outputs an image-capturing signal, a chromaticity detection unit that detects chromaticity of the subject by using the image-capturing signal, a gain calculation unit that calculates first and second gains by using different algorithms based upon the chromaticity detected by the chromaticity detection unit, a scene analysis unit that analyzes a scene to be photographed, a weighting value calculation unit that calculates first and second weighting values each for the first and second gains based on the results of analyzing the scene, a final gain calculation unit that calculates a white balance adjustment gain for the image-capturing signal based upon the first and second gains to which the first and second weighting values have been applied respectively, and a white balance adjustment unit that performs a white balance adjustment by applying the white balance adjustment gains to the image-capturing signal. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> The weighting value calculation unit calculates the weighting values so as to give dominance to either the first gain or the second gain. In this case, the weighting value calculation unit weights the first gain and the second gain by providing different coefficients for the first gain and the second gain, with a positive coefficient set for one of the gains that is to be given dominance and a negative coefficient with a larger absolute value than the positive coefficient provided for the other gain. The weighting value calculation unit may include a table of a relationship between results of analyzing the scene being photographed and weighting values. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> The gain calculation unit may be constituted so as to calculate a first gain by using a white balance adjustment signal calculating method achieved by averaging color signals over an entire image plane, a second gain by using a white balance adjustment signal calculating method achieved through multiple division white detection, and a third gain by using a white balance adjustment signal calculating method achieved through multiple division skin color detection. The weighting value calculation unit analyzes a scene to be photographed by using a photographic range analysis method, a red color area analysis method and a brightness value analysis method, respectively and calculates, for the individual results of analyzing the scene, a first weighting value for a first gain, a second weighting value for a second gain and a third weighting value for a third gain. The final gain calculation unit calculates the white balance gain to the image-capturing signals based upon the first gain to which the first weighting value has applied the second gain to which the second weighting value has applied and the third gain to which the third weighting value has applied. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The present invention can apply to a computer-readable computer program product containing a control program for white balance adjustment. The control program comprises instruction for detecting chromaticity of a subject by using an image-capturing signal of an image of the subject that has been photographed, instruction for analyzing the scene by using the image-capturing signal, instruction for calculating a white balance adjustment gain for the image-capturing signal based upon the detected chromaticity of the subject and the results of analyzing the scene, and instruction for performing a white balance adjustment by applying the white balance adjustment gain to the image-capturing signal. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> A computer-readable computer program product may be a recording medium or a carrier wave in which the control program is embodied.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows the structure adopted in an embodiment of the single lens reflex electronic still camera. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram schematically illustrating the structure of the electronic still camera. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is an illustration of the white balance sensor. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flowchart of the processing for generating a white balance adjustment signal. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> FIGS. <highlight><bold>5</bold></highlight>A-<highlight><bold>5</bold></highlight>C show tables of the first weighting points. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a diagram of a chromaticity coordinate system. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> FIGS. <highlight><bold>7</bold></highlight>A-<highlight><bold>7</bold></highlight>F show tables of the second weighting points. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows a table of the third weighting points. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a block diagram showing an image processing apparatus to which the present invention is applied.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> The following is an explanation of an embodiment of the present invention, given in reference to the drawings. <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates a single lens reflex electronic still camera achieved in the embodiment of the present invention. The electronic still camera in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> includes a camera main body <highlight><bold>70</bold></highlight>, a viewfinder device <highlight><bold>80</bold></highlight> detachably mounted at the camera main body <highlight><bold>70</bold></highlight> and an exchangeable lens <highlight><bold>90</bold></highlight> that is internally provided with a lens <highlight><bold>91</bold></highlight> and an aperture <highlight><bold>92</bold></highlight> and is detachably mounted at the camera main body <highlight><bold>70</bold></highlight>. Subject light having passed through the exchangeable lens <highlight><bold>90</bold></highlight> and entered the camera main body <highlight><bold>70</bold></highlight> is then guided to the viewfinder device <highlight><bold>80</bold></highlight> by a quick-return mirror <highlight><bold>71</bold></highlight> which is set at the position indicated by the dotted line prior to a shutter release, forms an image at a finder mat <highlight><bold>81</bold></highlight> and also forms an image at a focal point detection device <highlight><bold>36</bold></highlight>. The subject light having formed the image at the finder mat <highlight><bold>81</bold></highlight> is then guided to an eyepiece lens <highlight><bold>83</bold></highlight> by a pentaprism <highlight><bold>82</bold></highlight>, and is also allowed to pass through a prism <highlight><bold>84</bold></highlight> and an image-forming lens <highlight><bold>85</bold></highlight> to reach a white balance sensor <highlight><bold>86</bold></highlight> on which a subject image is formed. Following the shutter release, the quick-return mirror <highlight><bold>71</bold></highlight> swings to the position indicated by the solid line and the subject light forms an image on a photographic image-capturing device <highlight><bold>73</bold></highlight> via a shutter <highlight><bold>72</bold></highlight>. It is to be noted that the white balance sensor <highlight><bold>86</bold></highlight> is arranged at a position which is conjugate with the image-capturing device <highlight><bold>73</bold></highlight> relative to the photographic lens <highlight><bold>91</bold></highlight>. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram schematically illustrating the structure of the electronic still camera. A half-stroke signal and a full-stroke signal are input to a CPU <highlight><bold>21</bold></highlight> respectively from a half-stroke switch <highlight><bold>22</bold></highlight> and a full-stroke switch <highlight><bold>23</bold></highlight> which interlock with a shutter release button. The focal point detection device <highlight><bold>36</bold></highlight> (see <cross-reference target="DRAWINGS">FIG. 1</cross-reference>) detects the focal adjustment state at the photographic lens <highlight><bold>91</bold></highlight> in response to a command issued by means of the CPU <highlight><bold>21</bold></highlight>. The CPU <highlight><bold>21</bold></highlight> drives a lens drive device (not shown) in correspondence to the focal adjustment state to move the lens <highlight><bold>91</bold></highlight> to a focus position so that the subject light entering the exchangeable lens <highlight><bold>90</bold></highlight> forms an image in focused state on a CCD <highlight><bold>26</bold></highlight> of the image-capturing device <highlight><bold>73</bold></highlight>. In addition, the CPU <highlight><bold>21</bold></highlight> drives a timing generator <highlight><bold>24</bold></highlight> and a driver <highlight><bold>25</bold></highlight> and implements drive control on the CCD <highlight><bold>26</bold></highlight> of the image-capturing device <highlight><bold>73</bold></highlight>. The timing with which an analog processing circuit <highlight><bold>27</bold></highlight> and an A/D conversion circuit <highlight><bold>28</bold></highlight> are engaged in operation is controlled by the TG (timing generator) <highlight><bold>24</bold></highlight>. A lens information input circuit <highlight><bold>37</bold></highlight> provides setting information with regard to the exchangeable lens <highlight><bold>90</bold></highlight> such as the focal length and the aperture value to the CPU <highlight><bold>21</bold></highlight>. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> When the full-stroke switch <highlight><bold>23</bold></highlight> is turned on after an ON operation at the half-stroke switch <highlight><bold>22</bold></highlight>, the quick-return mirror <highlight><bold>71</bold></highlight> swings upward and the subject light from the exchangeable lens <highlight><bold>90</bold></highlight> forms an image on the light-receiving surface of the CCD <highlight><bold>26</bold></highlight>. The CCD <highlight><bold>26</bold></highlight> accumulates a charge in correspondence to the brightness of the subject image. The charge accumulated at the CCD <highlight><bold>26</bold></highlight> is swept out by the driver <highlight><bold>25</bold></highlight> and is then input to the analog processing circuit <highlight><bold>27</bold></highlight>, which includes an AGC circuit, and a CDS circuit. The analog image signal thus input undergoes analog processing such as gain control, noise removal and the like at the analog processing circuit <highlight><bold>27</bold></highlight> and then is converted to a digital signal at the A/D conversion circuit <highlight><bold>28</bold></highlight>. The digitized image signal is supplied to an image-processing CPU <highlight><bold>29</bold></highlight> which may be constituted as, for instance, an ASIC to undergo image preprocessing including white balance adjustment, contour correction and gamma control to be detailed later. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The image data having undergone the image preprocessing further undergo format processing for JPEG compression, and the image data having undergone the format processing are output to a buffer memory (not shown) for storage. The image data stored in the buffer memory are compressed at a predetermined rate through the JPEG method or the like at a compression circuit (not shown) and are then recorded into a recording medium (not shown). </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The white balance adjustment is performed at the image-processing CPU <highlight><bold>29</bold></highlight>. Image signals corresponding to R, G and B colors output from the A/D conversion circuit <highlight><bold>28</bold></highlight> first undergo flaw correction at a flaw correction circuit <highlight><bold>29</bold></highlight>A and then undergo clamp processing at a digital clamp circuit <highlight><bold>29</bold></highlight>B. A gain circuit <highlight><bold>29</bold></highlight>C applies a specific gain to the image signals having undergone the clamp processing, and then the image signals are input to a white balance circuit <highlight><bold>29</bold></highlight>D. The white balance circuit <highlight><bold>29</bold></highlight>D multiplies the R-color image signal and the B-color image signal with respect to the R, G and B color image signals respectively by an R-gain and a B-gain calculated based upon a white balance adjustment signal. These white balance adjustment R-gain and B-gain are determined at a white balance adjustment signal calculation circuit <highlight><bold>35</bold></highlight>, are transferred to the CPU <highlight><bold>21</bold></highlight> and stored at a register within the CPU <highlight><bold>21</bold></highlight> in advance. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> The white balance adjustment signal calculation circuit <highlight><bold>35</bold></highlight> includes a white balance sensor <highlight><bold>35</bold></highlight>A (corresponds to <highlight><bold>86</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>) that detects the subject color, and A/D conversion circuit <highlight><bold>35</bold></highlight>B that converts an analog color signal output by the white balance sensor <highlight><bold>35</bold></highlight>A to a digital color signal and a CPU <highlight><bold>35</bold></highlight>C that generates a white balance adjustment signal based upon the digital color signal resulting from the conversion. The CPU <highlight><bold>35</bold></highlight>C generates the white balance adjustment R-gain and the white balance adjustment B-gain based upon the color signals detected by the white balance sensor <highlight><bold>86</bold></highlight> and transfers the gains to the CPU <highlight><bold>21</bold></highlight>. The setting information with regard to the exchangeable lens <highlight><bold>90</bold></highlight> is input to the CPU <highlight><bold>35</bold></highlight>C via the CPU <highlight><bold>21</bold></highlight>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> In the embodiment the CPU <highlight><bold>35</bold></highlight>C generates three sets of white balance adjustment basic signals through three different generating methods and calculates white balance adjustment signals by individually weighting the three sets of white balance adjustment basic signals in conformance to the photographic scene. Then, the image-processing CPU <highlight><bold>29</bold></highlight> performs a white balance adjustment using the three sets of white balance adjustment signals having been weighted by the CPU <highlight><bold>35</bold></highlight>C. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The white balance sensor <highlight><bold>86</bold></highlight> is constituted of a single two-dimensional image-capturing element having, for instance, 480 separate pixels arrayed along 24 columns (across)&times;20 rows (down) as illustrated in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. At the surface of the image-capturing element <highlight><bold>86</bold></highlight>, a color filter <highlight><bold>861</bold></highlight> having R, G and B color filters each provided in correspondence to one of the 480 pixels is provided. With the subject light captured at the white balance sensor <highlight><bold>86</bold></highlight> through the color filter <highlight><bold>861</bold></highlight>, an image of the subject light which is separated into R-color signals, G-color signals and B-color signals is captured. Color signals for 160 pixels along, for instance, 8 columns (across)&times;20 rows (down), with each pixel constituted of three adjacent pixels that output an R-color signal, a G-color signal and a B-color signal, are output from the white balance sensor <highlight><bold>86</bold></highlight>. In other words, the color signals are output from small areas obtained by dividing the image-capturing surface of the white balance sensor <highlight><bold>86</bold></highlight> into 160 portions. The image-capturing surface of the white balance sensor <highlight><bold>86</bold></highlight> is constituted so as to receive the optical image of the entire photographic field. In addition, the color signals output from the white balance sensor <highlight><bold>86</bold></highlight> are utilized when calculating the subject brightness as well. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> Using the color signals output from the white balance sensor <highlight><bold>86</bold></highlight>, white balance adjustment basic signals CT<highlight><bold>1</bold></highlight>&tilde;CT<highlight><bold>3</bold></highlight> are calculated through three different methods. In the embodiment, the white balance adjustment basic signals are calculated through the following three methods. </paragraph>
<paragraph id="P-0038" lvl="7"><number>&lsqb;0038&rsqb;</number> 1. White Balance Adjustment Signal Calculating Method Achieved by Averaging the Entire Image Plane </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> A white balance adjustment basic signal is calculated so as to set the average value of the 160 sets of color signals output from the 160 areas at the white balance sensor <highlight><bold>86</bold></highlight> to an achromatic color, i.e., so as to set the average value of the color signals over the entire image plane captured at the white balance sensor <highlight><bold>86</bold></highlight> to an achromatic color. The CPU <highlight><bold>35</bold></highlight>C calculates the averages of the ratios R/G of the R-color signals and the G-color signals and the ratios B/G of the B-color signals and the G-color signals with respect to the R, G and B color signals from the 160 individual areas at the white balance sensor <highlight><bold>86</bold></highlight> through the following formulae (1) and (2).  
<math-cwu id="MATH-US-00001">
<number>1</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mfrac>
          <mn>1</mn>
          <mn>160</mn>
        </mfrac>
        <mo>&it;</mo>
        <mrow>
          <munderover>
            <mo>&Sum;</mo>
            <mrow>
              <mi>i</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mn>160</mn>
          </munderover>
          <mo>&it;</mo>
          <mrow>
            <mi>Fi</mi>
            <mo>&af;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>R</mi>
                <mo>/</mo>
                <mi>G</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>1</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mfrac>
          <mn>1</mn>
          <mn>160</mn>
        </mfrac>
        <mo>&it;</mo>
        <mrow>
          <munderover>
            <mo>&Sum;</mo>
            <mrow>
              <mi>i</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mn>160</mn>
          </munderover>
          <mo>&it;</mo>
          <mrow>
            <mi>Fi</mi>
            <mo>&af;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>B</mi>
                <mo>/</mo>
                <mi>G</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>2</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00001" file="US20030001958A1-20030102-M00001.NB"/>
<image id="EMI-M00001" wi="216.027" he="54.00675" file="US20030001958A1-20030102-M00001.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0040" lvl="7"><number>&lsqb;0040&rsqb;</number> with Fi (R/G) representing the ratio of the R signal and the G signal at a target pixel i on the white balance sensor <highlight><bold>86</bold></highlight> and Fi (B/G) representing the ratio of the B signal and the G signal at the target pixel i on the white balance sensor <highlight><bold>86</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The CPU <highlight><bold>35</bold></highlight>C calculates a white balance adjustment basic signal so that the results of a calculation performed by using formulae (1) and (2) above both indicate a value of 1. Consequently, a white balance adjustment basic signal CT<highlight><bold>1</bold></highlight> is calculated so as to set the color obtained by averaging all the 160 areas closer to white. </paragraph>
<paragraph id="P-0042" lvl="7"><number>&lsqb;0042&rsqb;</number> 2. White Balance Adjustment Signal Calculating Method Achieved Through Multiple Division White Detection </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The 160 areas (each representing an area RE<highlight><bold>1</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> constituted of 1 (row)&times;3 (columns) of pixels) at the white balance sensor <highlight><bold>86</bold></highlight> are grouped into, for instance, 4 (along the horizontal direction)&times;5 (along the vertical direction) &equals;20 small areas (each representing an area RE<highlight><bold>2</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> constituted of 4 (rows)&times;6 (columns) pixels). Each small area RE<highlight><bold>2</bold></highlight> in this case is constituted of 2 RE<highlight><bold>1</bold></highlight>s (along the horizontal direction)&times;4 RE<highlight><bold>1</bold></highlight> (along the vertical direction)&equals;8 RE<highlight><bold>1</bold></highlight>s. For each of the 20 small areas RE<highlight><bold>2</bold></highlight>, the average of the 8 sets of color signals individually output from the 8 areas RE<highlight><bold>1</bold></highlight> contained within the small area RE<highlight><bold>2</bold></highlight> is calculated, and then, a small area RE<highlight><bold>2</bold></highlight> having a color signal average value within a predetermined range and thus assumed to indicate white is extracted. Next a white balance adjustment basic signal is calculated so as to set the average value of the color signals in the extracted small area RE<highlight><bold>2</bold></highlight> assumed to indicate white even closer to white. The following is a detailed explanation of the process. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> The CPU <highlight><bold>35</bold></highlight>C calculates the averages of the ratios R/G of the R-color signals and the G-color signals and the ratios B/G of the B-color signals and the G-color signals in each of the 20 small areas RE<highlight><bold>2</bold></highlight> with respect to the R, G and B color signals from the white balance sensor <highlight><bold>86</bold></highlight> through the following formulae (3) and (4).  
<math-cwu id="MATH-US-00002">
<number>2</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mfrac>
          <mn>1</mn>
          <mn>8</mn>
        </mfrac>
        <mo>&it;</mo>
        <mrow>
          <munderover>
            <mo>&Sum;</mo>
            <mrow>
              <mi>j</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mn>8</mn>
          </munderover>
          <mo>&it;</mo>
          <mrow>
            <mi>Fj</mi>
            <mo>&af;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>R</mi>
                <mo>/</mo>
                <mi>G</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>3</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mfrac>
          <mn>1</mn>
          <mn>8</mn>
        </mfrac>
        <mo>&it;</mo>
        <mrow>
          <munderover>
            <mo>&Sum;</mo>
            <mrow>
              <mi>j</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mn>8</mn>
          </munderover>
          <mo>&it;</mo>
          <mrow>
            <mi>Fj</mi>
            <mo>&af;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>B</mi>
                <mo>/</mo>
                <mi>G</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>4</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00002" file="US20030001958A1-20030102-M00002.NB"/>
<image id="EMI-M00002" wi="216.027" he="55.93455" file="US20030001958A1-20030102-M00002.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0045" lvl="7"><number>&lsqb;0045&rsqb;</number> with Fj (R/G) representing the ratio of the R signal and the G signal at a target pixel j in each small area and Fj (B/G) representing the ratio of the B signal and the G signal at the target pixel j in each small area. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> The CPU <highlight><bold>35</bold></highlight>C uses the 8 sets of R/G and B/G calculated through formulae (3) and (4) above to detect a small area RE<highlight><bold>2</bold></highlight>W assumed to indicate white with its values falling within ranges expressed below in (5) and (6), for instance. </paragraph>
<paragraph lvl="0"><in-line-formula>0.9&lt;Fj (R/G)&lt;1.1&emsp;&emsp;(5)</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>0.9&lt;Fj (B/G)&lt;1.1&emsp;&emsp;(6) </in-line-formula></paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Once a small area RE<highlight><bold>2</bold></highlight>W that satisfies the two expressions is detected, the CPU <highlight><bold>35</bold></highlight>C calculates the averages of the ratios R/G of the R-color signals and the G-color signals and the ratios B/G of the B-color signals and the G-color signals by using all the color signals contained in the small area RE<highlight><bold>2</bold></highlight>W through the following formulae (7) and (8). m represents the quantity of small areas RE<highlight><bold>2</bold></highlight>W that have been detected.  
<math-cwu id="MATH-US-00003">
<number>3</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mfrac>
          <mn>1</mn>
          <mi>m</mi>
        </mfrac>
        <mo>&it;</mo>
        <mrow>
          <munderover>
            <mo>&Sum;</mo>
            <mrow>
              <mi>k</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mi>m</mi>
          </munderover>
          <mo>&it;</mo>
          <mrow>
            <mi>Fk</mi>
            <mo>&af;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>R</mi>
                <mo>/</mo>
                <mi>G</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>7</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mfrac>
          <mn>1</mn>
          <mi>m</mi>
        </mfrac>
        <mo>&it;</mo>
        <mrow>
          <munderover>
            <mo>&Sum;</mo>
            <mrow>
              <mi>k</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mi>m</mi>
          </munderover>
          <mo>&it;</mo>
          <mrow>
            <mi>Fk</mi>
            <mo>&af;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>B</mi>
                <mo>/</mo>
                <mi>G</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>8</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00003" file="US20030001958A1-20030102-M00003.NB"/>
<image id="EMI-M00003" wi="216.027" he="52.07895" file="US20030001958A1-20030102-M00003.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0048" lvl="7"><number>&lsqb;0048&rsqb;</number> with Fk (R/G) representing the ratio of the R signal and the G signal at of target pixel k within the small area satisfying the expressions (5) and (6) above and Fk (B/G) representing the ratio of the B signal and the G signal at the target pixel k within the small area satisfying the expressions (5) and </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> The CPU <highlight><bold>35</bold></highlight>C calculates a white balance adjustment basic signal so that the results of a calculation performed by using formulae (7) and (8) both indicate a value of 1. Consequently, a basic signal CT<highlight><bold>2</bold></highlight> is calculated so as to set the color obtained by averaging the small areas RE<highlight><bold>2</bold></highlight>W assumed to indicate white even closer to white. </paragraph>
<paragraph id="P-0050" lvl="7"><number>&lsqb;0050&rsqb;</number> 3. White Balance Adjustment Signal Calculating Method Achieved Through Multiple Division Skin Color Detection </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> The average value of the 8 sets of color signals individually output from the 8 areas RE<highlight><bold>1</bold></highlight> within, for instance, each of the 20 small areas RE<highlight><bold>2</bold></highlight> mentioned above is calculated to extract a small area RE<highlight><bold>2</bold></highlight>S having a color signal average value within a predetermined range and assumed to indicate skin color. Then, a white balance adjustment basic signal is calculated so as to set the color signal average value of the extracted small area RE<highlight><bold>2</bold></highlight>S assumed to indicate skin color even closer to skin color. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The CPU <highlight><bold>35</bold></highlight>C calculates the averages of the ratios R/G of the R-color signals and the G-color signals and the ratios B/G of the B-color signals and the G-color signals in each of the 20 small areas RE<highlight><bold>2</bold></highlight> with respect to the R, G and B color signals from the white balance sensor <highlight><bold>86</bold></highlight> through the formulae (3) and (4) presented earlier. The CPU <highlight><bold>35</bold></highlight>C uses the 8 sets of R/G and B/G signals calculated through formulae (3) and (4) above to detect a small area RE<highlight><bold>2</bold></highlight>S assumed to indicate skin color with its values falling within ranges expressed below in (9) and (10). </paragraph>
<paragraph lvl="0"><in-line-formula>0.9&lt;Fj (R/G)&lt;1.1&emsp;&emsp;(9)</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>0.7&lt;Fj (B/G)&lt;0.9&emsp;&emsp;(10) </in-line-formula></paragraph>
<paragraph id="P-0053" lvl="7"><number>&lsqb;0053&rsqb;</number> Once a small area RE<highlight><bold>2</bold></highlight>S that satisfies the two expressions is detected, the CPU <highlight><bold>35</bold></highlight>C calculates the averages of the ratios R/G of the R-color signals and the G-color signals and the ratios B/G of the B-color signals and the G-color signals by using all the color signals contained in the small area RE<highlight><bold>2</bold></highlight>S through the formulae (7) and (8) presented earlier. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> The CPU <highlight><bold>35</bold></highlight>C calculates a white balance adjustment basic signal so that the results of calculation performed by using formulae (7) and (8) respectively indicate a value of 1 and a value of 0.8. Consequently, a white balance adjustment basic signal CT<highlight><bold>3</bold></highlight> is calculated so as to set the color obtained by averaging the signal values in the small area RE<highlight><bold>2</bold></highlight>S assumed to indicate skin color even closer to skin color. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Three weighting points Sp<highlight><bold>1</bold></highlight>&tilde;Sp<highlight><bold>3</bold></highlight> are provided as explained below for each of the three sets of white balance adjustment basic signals CT<highlight><bold>1</bold></highlight> CT<highlight><bold>3</bold></highlight> calculated as explained above, and three weighting values a<highlight><bold>1</bold></highlight>&tilde;a<highlight><bold>3</bold></highlight> are calculated by normalizing the weighting points Sp<highlight><bold>1</bold></highlight>&tilde;Sp<highlight><bold>3</bold></highlight>. The three sets of white balance adjustment basic signals CT<highlight><bold>1</bold></highlight> CT<highlight><bold>3</bold></highlight> are respectively multiplied by the three weighting values a<highlight><bold>1</bold></highlight>&tilde;a<highlight><bold>3</bold></highlight> thus calculated, and the three sets of white balance adjustment signals resulting from the multiplication operations are added together to obtain a white balance adjustment signal CT to be used in the white balance adjustment. <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flowchart of the processing implemented to generate the white balance adjustment signal CT in the embodiment. The processing in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is implemented in two primary units, i.e., a weighting calculation unit <highlight><bold>100</bold></highlight> and a white balance adjustment signal calculation unit <highlight><bold>200</bold></highlight>, and is repeatedly executed prior to a shutter release at the electronic still camera. The weighting calculation unit <highlight><bold>100</bold></highlight> analyzes a scene being photographed and calculates the three weighting values a<highlight><bold>1</bold></highlight>&tilde;a<highlight><bold>3</bold></highlight> for the three sets of white balance adjustment basic signals CT<highlight><bold>1</bold></highlight>&tilde;CT<highlight><bold>3</bold></highlight>. The white balance adjustment signal calculation unit <highlight><bold>200</bold></highlight> individually calculates the three individual sets of white balance adjustment basic signals CT<highlight><bold>1</bold></highlight>&tilde;CT<highlight><bold>3</bold></highlight> as described earlier. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> The weighting calculation unit <highlight><bold>100</bold></highlight> implements three different scene analyses, i.e., photographic range analysis processing in step S<highlight><bold>101</bold></highlight>, red color area analysis processing in step S<highlight><bold>102</bold></highlight> and brightness analysis processing in step S<highlight><bold>103</bold></highlight>, and calculates weighting points Sp<highlight><bold>1</bold></highlight>&tilde;Sp<highlight><bold>3</bold></highlight> through the individual analyses. In weighting calculation processing implemented in step S<highlight><bold>104</bold></highlight>, the weighting points Sp<highlight><bold>1</bold></highlight>&tilde;Sp<highlight><bold>3</bold></highlight> calculated through the individual analyses are normalized to calculate the weighting values a<highlight><bold>1</bold></highlight>&tilde;a<highlight><bold>3</bold></highlight>. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> First Scene Analysis </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> In step S<highlight><bold>101</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the CPU <highlight><bold>35</bold></highlight>C calculates the first weighting points in conformance to the focal length of the photographic lens <highlight><bold>91</bold></highlight> and the photographing distance. The photographing distance between the subject and the camera is obtained by performing a specific arithmetic operation using the information indicating the position of the focus lens of the photographic lens <highlight><bold>91</bold></highlight> having been driven to the focus position. The focal length set at the photographic lens <highlight><bold>91</bold></highlight> and the focus lens position information are input to the CPU <highlight><bold>35</bold></highlight>C via the CPU <highlight><bold>21</bold></highlight>. Once the focal length of the photographic lens <highlight><bold>91</bold></highlight> and the photographing distance are ascertained, the range over which an image is photographed, i.e., the photographic range, can be estimated. The CPU <highlight><bold>35</bold></highlight>C calculates the weighting points for the three sets of white balance adjustment basic signals in conformance to the estimated photographic range. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Each of FIGS. <highlight><bold>5</bold></highlight>A-<highlight><bold>5</bold></highlight>C shows a table of the first weighting points calculated in step S<highlight><bold>101</bold></highlight>. Weighting points are set for the three different white balance adjustment signal calculating methods described earlier, in correspondence to a given set of the focal length and the photographing distance. The first weighting point calculated through the photographic range analysis in step S<highlight><bold>101</bold></highlight> has the following characteristics. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>A, the white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane assumes that various colors are evenly distributed within the photographic image plane. Under normal circumstances, the likelihood of the various colors contained in the photographic image plane is high when the photographic range is large and the likelihood of the various colors contained in the photographic image plane is lowered as the photographic range becomes smaller. Accordingly, the first weighting point is set to 0 if the photographic range is large (the focal length is small and the photographing distance is large) and a negative value is set for the first weighting point when the photographic range is small (the focal length is large and the photographing distance is small) The weight of the weighting point increases as the absolute value of a positive value increases and becomes smaller as the absolute value of a negative value increases. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>B, in the white balance adjustment signal calculating method achieved through multiple division white detection, it is assumed that white (an achromatic color) is contained somewhere within the photographic image plane. Generally speaking, the likelihood of an achromatic color contained in the photographic image plane is not greatly dependent upon the photographic range. Accordingly, the first weighting point is set to 0 regardless of the focal length setting and the photographing distance. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>C, the white balance adjustment signal calculating method achieved through multiple division skin color detection assumes that skin color is contained somewhere within the photographic image plane. Under normal circumstances, the color of the skin of a person is distributed over a specific range. For instance, when utilizing a lens with an 85 mm focal length for a portrait photographing operation, the photographing distance is often set to 1&tilde;2 m. In this case, the color of the skin of the person constituting the main subject does not cover the entire photographic image plane, or the area of the skin color is not too small to make the facial features of the person indiscernible. Accordingly, a positive value is set for the first weighting point only when a specific relationship is achieved between the focal length and the photographing distance and otherwise, a negative value is set for the first weighting point. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> Second Scene Analysis </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Instep S<highlight><bold>102</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the CPU <highlight><bold>35</bold></highlight>C calculates the second weighting points in correspondence to the number of red color signals output from the white balance sensor <highlight><bold>86</bold></highlight>. The ratios R/G of the R-color signals and the G-color signals and the ratios B/G of the B-color signals and the G-color signals with respect to the R, G and B color signals in the 160 individual areas RE<highlight><bold>1</bold></highlight> at the white balance sensor <highlight><bold>86</bold></highlight> are calculated and the 160 sets of data are plotted on the chromaticity coordinate plane shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. In <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the horizontal axis represents R/G and the vertical axis represents B/G. The 160 sets of data are plotted on the chromaticity coordinate plane and the number of sets of data in the first quadrant of the coordinate system in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is counted for red color hue data. The CPU <highlight><bold>35</bold></highlight>C calculates the subject brightness by using the color signals and calculates the weighting points for the three sets of white balance adjustment basic signals in conformance to the number of sets of red color data and the subject brightness. It is to be noted that the relationship between the color signal level and the subject brightness value BV is stored in advance as a table at the CPU <highlight><bold>35</bold></highlight>C, and that the subject brightness value BV is read out from the table by using the color signal level as an argument </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Each of FIGS. <highlight><bold>7</bold></highlight>A-<highlight><bold>7</bold></highlight>F shows a table of the second weighting points calculated in step S<highlight><bold>102</bold></highlight>. Weighting points are set for the three different white balance adjustment signal calculating methods described above in correspondence to a given set of the number of sets of red color data and subject brightness value BV. The second weighting points calculated through the red color area analysis in step S<highlight><bold>102</bold></highlight> have the following characteristics. When numerous sets of red color data are present, it is difficult to distinguish red color data attributable to a light source from red color data attributable to a red subject photographed over a significant area. However, such distinction may be made possible by detecting the subject brightness at the same time. For instance, if the subject brightness value BV is equal to or larger than 7, it can be safely assumed that there is hardly any chance of a light source with a red hue being present. Accordingly, if the subject achieves a high level of brightness and numerous sets of red color data are present, the color of the subject can be assumed to be predominantly red. The white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane, which assumes that various colors are evenly distributed in the photographic image plane, is not suitable in a situation in which the color of the subject is predominantly red. For this reason, a negative value with a large absolute value is set as the second weighting point for the white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane if there are numerous sets of red color data present. Each of FIGS. <highlight><bold>7</bold></highlight>A-<highlight><bold>7</bold></highlight>B shows an example of the second weighting points for the white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> In the white balance adjustment signal calculating method achieved through multiple division white detection and the white balance adjustment signal calculating method achieved through multiple division skin color detection, adjustment signals can be calculated by detecting white color and skin color respectively even when a great deal of red color is present in the background, for instance. Accordingly, since the predominance of red color in the subject does not present a problem as it does in the white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane, 0 or a positive/negative value with a small absolute value is set as the second weighting points in correspondence to the white balance adjustment signal calculating method achieved through multiple division white detection and the white balance adjustment signal calculating method achieved through multiple division skin color detection. Tables shown in <cross-reference target="DRAWINGS">FIGS. 7C and 7D</cross-reference>, <cross-reference target="DRAWINGS">FIGS. 7E and 7F</cross-reference> show the first through the third weighting points for the white balance adjustment signal calculating method achieved through multiple division white detection, respectively. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Third Scene Analysis </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> In step S<highlight><bold>103</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the CPU <highlight><bold>35</bold></highlight>C calculates the third weighting points in correspondence of the subject brightness value BV. <cross-reference target="DRAWINGS">FIG. 8</cross-reference> presents a table of the third weighting points calculated in step S<highlight><bold>103</bold></highlight>. Weighting points are set for the three white balance adjustment signal calculating methods described above, in correspondence to a given subject brightness value BV. The third weighting points calculated through the brightness value analysis in step S<highlight><bold>103</bold></highlight> have the following characteristics. It has been confirmed through experience that the likelihood of a correct white balance adjustment signal being calculated through the white balance adjustment signal calculating method by averaging the color signals over the entire image plane is low (the accuracy rate is low) when a photographing operation is performed under very bright artificial light such as a fluorescent light or a mercury lamp. Accordingly, a larger positive value is set for the third weighting point corresponding to the white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane when the brightness level is low compared to the value set when the brightness value is high. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> It has been confirmed through experience that the accuracy rate of the white balance adjustment signal calculating method achieved through multiple division skin color detection is low when a photographing operation is performed under low bright artificial light. Accordingly, a smaller value is set for the third weighting point corresponding to the white balance adjustment signal calculating method achieved through multiple division skin color detection when the brightness level is low compared to the value set when the level of the brightness is high. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> In step S<highlight><bold>104</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the CPU <highlight><bold>35</bold></highlight>C calculates the weighting values a<highlight><bold>1</bold></highlight>&tilde;a<highlight><bold>3</bold></highlight> through the following formulae (11)&tilde;(13) by normalizing the first&tilde;third weighting points calculated in steps S<highlight><bold>101</bold></highlight>&tilde;S<highlight><bold>103</bold></highlight> as explained above.  
<math-cwu id="MATH-US-00004">
<number>4</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>a1</mi>
        <mo>=</mo>
        <mfrac>
          <mrow>
            <mo>&Sum;</mo>
            <mi>Sp1</mi>
          </mrow>
          <mrow>
            <mrow>
              <mo>&Sum;</mo>
              <mi>Sp1</mi>
            </mrow>
            <mo>+</mo>
            <mrow>
              <mo>&Sum;</mo>
              <mi>Sp2</mi>
            </mrow>
            <mo>+</mo>
            <mrow>
              <mo>&Sum;</mo>
              <mi>Sp3</mi>
            </mrow>
          </mrow>
        </mfrac>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>11</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>a2</mi>
        <mo>=</mo>
        <mfrac>
          <mrow>
            <mo>&Sum;</mo>
            <mi>Sp2</mi>
          </mrow>
          <mrow>
            <mrow>
              <mo>&Sum;</mo>
              <mi>Sp1</mi>
            </mrow>
            <mo>+</mo>
            <mrow>
              <mo>&Sum;</mo>
              <mi>Sp2</mi>
            </mrow>
            <mo>+</mo>
            <mrow>
              <mo>&Sum;</mo>
              <mi>Sp3</mi>
            </mrow>
          </mrow>
        </mfrac>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>12</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>a3</mi>
        <mo>=</mo>
        <mfrac>
          <mrow>
            <mo>&Sum;</mo>
            <mi>Sp3</mi>
          </mrow>
          <mrow>
            <mrow>
              <mo>&Sum;</mo>
              <mi>Sp1</mi>
            </mrow>
            <mo>+</mo>
            <mrow>
              <mo>&Sum;</mo>
              <mi>Sp2</mi>
            </mrow>
            <mo>+</mo>
            <mrow>
              <mo>&Sum;</mo>
              <mi>Sp3</mi>
            </mrow>
          </mrow>
        </mfrac>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>13</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00004" file="US20030001958A1-20030102-M00004.NB"/>
<image id="EMI-M00004" wi="216.027" he="77.0553" file="US20030001958A1-20030102-M00004.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0071" lvl="7"><number>&lsqb;0071&rsqb;</number> with each Sp<highlight><bold>1</bold></highlight> representing the weighting point for the white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane calculated in step S<highlight><bold>101</bold></highlight>, S<highlight><bold>102</bold></highlight> or S<highlight><bold>103</bold></highlight>, and each Sp<highlight><bold>2</bold></highlight> representing the weighting point for the white balance adjustment signal calculating method achieved through multiple division white detection calculated in step S<highlight><bold>101</bold></highlight>, S<highlight><bold>102</bold></highlight> or S<highlight><bold>103</bold></highlight> and each Sp<highlight><bold>3</bold></highlight> representing the weighting point for the white balance adjustment signal calculating method achieved through multiple division skin color detection calculated in step S<highlight><bold>101</bold></highlight>, S<highlight><bold>102</bold></highlight> or S<highlight><bold>103</bold></highlight>. In addition, a<highlight><bold>1</bold></highlight>, a<highlight><bold>2</bold></highlight> and a<highlight><bold>3</bold></highlight> respectively represent the weighting values for the white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane, the white balance adjustment signal calculating method achieved through multiple division white detection and the white balance adjustment signal calculating method achieved through multiple division skin color detection, obtained through the normalization. 0 is set for any of the terms in formulae (11)&tilde;(13), in which a negative value results from the calculation. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> In step S<highlight><bold>201</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the CPU <highlight><bold>35</bold></highlight>C calculates the white balance adjustment basic signal CT<highlight><bold>1</bold></highlight> through the white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane as described above and the operation then proceeds to step S<highlight><bold>202</bold></highlight>. In step S<highlight><bold>202</bold></highlight>, the CPU <highlight><bold>35</bold></highlight>C calculates the white balance adjustment basic signal CT<highlight><bold>2</bold></highlight> by implementing the white balance adjustment signal calculation method through multiple division white detection as described earlier, and then the operation proceeds to step S<highlight><bold>203</bold></highlight>. In step S<highlight><bold>203</bold></highlight>, the CPU <highlight><bold>35</bold></highlight>C calculates the white balance adjustment basic signal CT<highlight><bold>3</bold></highlight> by implementing the white balance adjustment signal calculation method through multiple division skin color detection as described earlier, and then the operation proceeds to step S<highlight><bold>300</bold></highlight>. Individual operations in S<highlight><bold>201</bold></highlight>-S<highlight><bold>203</bold></highlight> are termed the first through the third white balance adjustment signal calculation operations. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> In step S<highlight><bold>300</bold></highlight>, the CPU <highlight><bold>35</bold></highlight>C calculates a white balance adjustment signal CT to be used in the white balance adjustment through the following formula (14) with the white balance adjustment basic signals CT<highlight><bold>1</bold></highlight> CT<highlight><bold>3</bold></highlight>. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>CT&equals;a</italic></highlight>1&middot;<highlight><italic>CT</italic></highlight>1&plus;<highlight><italic>a</italic></highlight>2&middot;<highlight><italic>CT</italic></highlight>2&plus;<highlight><italic>a</italic></highlight>3&middot;<highlight><italic>CT</italic></highlight>3&emsp;&emsp;(14) </in-line-formula></paragraph>
<paragraph id="P-0074" lvl="7"><number>&lsqb;0074&rsqb;</number> with CT<highlight><bold>1</bold></highlight> representing the adjustment signal calculated through the white balance adjust signal calculating method achieved by averaging the color signals over the entire image plane in step S<highlight><bold>201</bold></highlight>, CT<highlight><bold>2</bold></highlight> representing the adjustment signal obtained by implementing the white balance adjustment signal calculating method through multiple division white detection in step S<highlight><bold>202</bold></highlight> and CT<highlight><bold>3</bold></highlight> representing the adjustment signal obtained by implementing the white balance adjustment signal calculating method through multiple division skin color detection in step S<highlight><bold>203</bold></highlight>. The white balance adjustment signal and the white balance adjustment basic signals are each constituted of a single value, i.e., CT, CT<highlight><bold>1</bold></highlight>, CT<highlight><bold>2</bold></highlight> or CT<highlight><bold>3</bold></highlight>. These signal values are equivalent to, for instance, color temperature values, mired values or the like. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> In step S<highlight><bold>301</bold></highlight>, the CPU <highlight><bold>35</bold></highlight>C converts the value of the white balance adjustment signal CT calculated through formula (14) to an R-gain value and a B-gain value. The relationship between the white balance adjustment signal CT, and the R-gain and the B-gain is stored in the memory of the CPU <highlight><bold>35</bold></highlight>C in advance as a table, and the R-gain and the B-gain are read out from the table by using the calculated CT value as an argument. The CPU <highlight><bold>35</bold></highlight>C provides the R-gain and the B-gain to the CPU <highlight><bold>21</bold></highlight> and then the processing in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> ends. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> The R-gain and the B-gain provided to the CPU <highlight><bold>21</bold></highlight> are then transmitted to the white balance circuit <highlight><bold>29</bold></highlight>D mentioned earlier where they are used during a white balance adjustment performed by the white balance circuit <highlight><bold>29</bold></highlight>D on image data obtained through a subsequent image-capturing operation performed at the CCD <highlight><bold>26</bold></highlight>. The white balance adjustment is achieved by incorporating the R-signals and the B-signals over the entire range where the image-capturing operation is performed by the CCD <highlight><bold>26</bold></highlight> with the R-gain and the B-gain, bearing no relation to the color signal detection areas corresponding to the 160 pixels at the white balance sensor <highlight><bold>86</bold></highlight>. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> Now, the features of the embodiment are summarized. </paragraph>
<paragraph id="P-0078" lvl="2"><number>&lsqb;0078&rsqb;</number> (1) The white balance adjustment basic signal CT<highlight><bold>1</bold></highlight> is calculated through the white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane with the color signal output from the white balance sensor <highlight><bold>86</bold></highlight> which corresponds to 160 pixels. Thus, a white balance adjustment basic signal CT<highlight><bold>1</bold></highlight> , which will set the color obtained by averaging the color signals from all the 160 areas even closer to white, is obtained through the calculation. </paragraph>
<paragraph id="P-0079" lvl="2"><number>&lsqb;0079&rsqb;</number> (2) The light-receiving areas corresponding to 160 pixels at the white balance sensor <highlight><bold>86</bold></highlight> are grouped into a total of 20 small areas RE<highlight><bold>2</bold></highlight> , and the average of the 8 sets of color signals individually output from the 8 areas RE<highlight><bold>1</bold></highlight> contained in each of the 20 small areas RE<highlight><bold>2</bold></highlight> is calculated. Then, a small area RE<highlight><bold>2</bold></highlight>W achieving a color signal average value within a predetermined range and assumed to indicate white is extracted, and a white balance adjustment basic signal CT<highlight><bold>2</bold></highlight> which will set the average value of the color signals in the extracted small area RE<highlight><bold>2</bold></highlight>W even closer to white is calculated. As a result, a white balance adjustment basic signal CT<highlight><bold>2</bold></highlight> which will set white color detected in a portion of the photographic image plane even closer to white is obtained through the calculation. </paragraph>
<paragraph id="P-0080" lvl="2"><number>&lsqb;0080&rsqb;</number> (3) The light-receiving areas corresponding to 160 pixels at the white balance sensor <highlight><bold>86</bold></highlight> are grouped into a total of 20 small areas RE<highlight><bold>2</bold></highlight>, and the average of the 8 sets of color signals individually output from the 8 areas RE<highlight><bold>1</bold></highlight> contained in each of the 20 small areas RE<highlight><bold>2</bold></highlight> is calculated. Then, a small area RE<highlight><bold>2</bold></highlight>S achieving a color signal average value within a predetermined range and assumed to indicate skin color is extracted, and a white balance adjustment basic signal CT<highlight><bold>3</bold></highlight> which will set the average value of the color signals in the extracted small area RE<highlight><bold>2</bold></highlight>S even closer to skin color is calculated. As a result, a white balance adjustment basic signal CT<highlight><bold>3</bold></highlight> which will set skin color detected in a portion of the photographic image plane even closer to skin color is obtained through the calculation. </paragraph>
<paragraph id="P-0081" lvl="2"><number>&lsqb;0081&rsqb;</number> (4) The photographic range is estimated based upon the focal length set at the photographic lens <highlight><bold>91</bold></highlight> and the photographing distance, and the first weighting points are provided each in correspondence to one of the white balance adjustment basic signals CT<highlight><bold>1</bold></highlight>&tilde;CT<highlight><bold>3</bold></highlight> calculated through the calculating methods described in (1)&tilde;(3) above in conformance to the photographic range. By setting a high weighting point for the skin color detection method in (3) above if the photographic range is suited for a portrait photographing operation, a high weighting rate is allocated to the adjustment method with a high likelihood of calculating a correct white balance adjustment signal (with a high accuracy rate) . By setting a low weighting point for the skin color detection method in (3) when the photographic range is too large for a portrait photographing operation, on the other hand, an erroneous white balance adjustment can be prevented as detailed below. Namely, when there is a large achromatic color subject illuminated by a light source with a low color temperature, the level of the adjustment obtained through the skin color detection adjustment signal method is set low even if a skin color is erroneously detected through the skin color detection method, and thus, erroneous white balance adjustment which would set the achromatic color subject to skin color is prevented. </paragraph>
<paragraph id="P-0082" lvl="2"><number>&lsqb;0082&rsqb;</number> (5) The chromaticity data (R/G and B/G) for the 160 pixels at the white balance sensor <highlight><bold>86</bold></highlight> are plotted on a chromaticity coordinate plane and the second weighting points are provided each for one of the white balance adjustment basic signals CT<highlight><bold>1</bold></highlight>&tilde;CT<highlight><bold>3</bold></highlight> calculated through the calculating methods in (1)&tilde;(3) above in conformance to the number of sets of red color data contained in the first quadrant and the subject brightness value BV. For instance, by setting the weighting point corresponding to the calculating method achieved by averaging the color signals over the entire image plane in (1) when the color of the subject is predominantly red, the weighting rate of the adjustment method with a low accuracy rate can be reduced. As a result, a high-quality color image is obtained. </paragraph>
<paragraph id="P-0083" lvl="2"><number>&lsqb;0083&rsqb;</number> (6) The third weighting points are provided each for one of the white balance adjustment basic signals CT<highlight><bold>1</bold></highlight>&tilde;CT<highlight><bold>3</bold></highlight> calculated through the calculating methods in (1)&tilde;(3) above in correspondence to the subject brightness value BV. For instance, by setting a lower weighting point for the calculating method achieved by averaging the color signals over the entire image plane in (1) when a photographing operation is performed under artificial light with a high level of brightness such as a fluorescent light or a mercury lamp compared to that set when the brightness level is low, it is possible to reduce the weighting rate of the adjustment method with a low accuracy rate. As a result, a high-quality color image is obtained. </paragraph>
<paragraph id="P-0084" lvl="2"><number>&lsqb;0084&rsqb;</number> (7) The first weighting points&tilde;third weighting points calculated in (4)&tilde;(6) above are normalized to calculate the weighting values a<highlight><bold>1</bold></highlight>, a<highlight><bold>2</bold></highlight> and a<highlight><bold>3</bold></highlight> for the adjustment basic signals CT<highlight><bold>1</bold></highlight>, CT<highlight><bold>2</bold></highlight> and CT<highlight><bold>3</bold></highlight> obtained through the calculating methods in (1)&tilde;(3). As a result, the ratio of dominance of the adjustment basic signal obtained through calculating method with a high accuracy rate among a plurality of calculating methods can be increased in conformance to the type of photographic scene, regardless of the number of calculating methods employed to calculate white balance adjustment basic signals or the number of scene analyses performed to provide weighting points. At the same time, by lowering the proportion of the adjustment basic signal obtained through a calculating method with a low accuracy rate in conformance to the type of photographic scene, its influence can be eliminated. </paragraph>
<paragraph id="P-0085" lvl="2"><number>&lsqb;0085&rsqb;</number> (8) A negative value with a larger absolute value is set for the weighting point whose weighting rate is to be lowered, and thus, the extent to which the adjustment basic signal obtained through a calculating method with a low accuracy rate influences the white balance adjustment can be further reduced. </paragraph>
<paragraph id="P-0086" lvl="2"><number>&lsqb;0086&rsqb;</number> (9) Since the weighting points are provided in tables, the volume of the arithmetic operation that the CPU <highlight><bold>35</bold></highlight>C has to execute is reduced to achieve a reduction in the length of the processing time. </paragraph>
<paragraph id="P-0087" lvl="2"><number>&lsqb;0087&rsqb;</number> (10) Since the relationship between the white balance adjustment signal CT and the R-gain and B-gain is stored in the memory at the CPU <highlight><bold>35</bold></highlight>C as a table in advance, the length of time required for the arithmetic processing is reduced. </paragraph>
<paragraph id="P-0088" lvl="2"><number>&lsqb;0088&rsqb;</number> (11) As the white balance sensor <highlight><bold>86</bold></highlight> is provided within the viewfinder device <highlight><bold>80</bold></highlight>, it is possible to provide the white balance adjustment R-gain and the white balance adjustment B-gain to the CPU <highlight><bold>21</bold></highlight> before the mirror <highlight><bold>71</bold></highlight> is raised in response to an operation of the full-stroke switch <highlight><bold>23</bold></highlight>. Thus, since it is not necessary to calculate the white balance adjustment gains during the photographing sequence executed in response to the operation of the full-stroke switch <highlight><bold>23</bold></highlight>, a reduction in the photographing processing time is achieved compared to the length of processing time required when calculating the white balance adjustment gains are calculated during the photographing sequence. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> While an explanation is given above on an example in which the present invention is adopted in a single lens reflex electronic still camera, the present invention may be also adopted in an electronic still camera which is not a single lens reflex camera and a digital video camera capable of taking in dynamic images. In such a case, subject images are separately formed at the CCD <highlight><bold>26</bold></highlight> and the white balance sensor <highlight><bold>86</bold></highlight> by using a beam splitter, a half mirror and the like. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> In addition, while the CCD <highlight><bold>26</bold></highlight> and the white balance sensor <highlight><bold>86</bold></highlight> are provided as components independent of each other in the explanation given above, the CCD <highlight><bold>26</bold></highlight> may also function as the white balance sensor <highlight><bold>86</bold></highlight>. In such a case, the white balance adjustment gains are determined as described above by using the data obtained through an image-capturing operation at the CCD <highlight><bold>26</bold></highlight>. Then, a white balance adjustment is implemented using the white balance adjustment gains on subject image data obtained through an image-capturing operation performed in response to a shutter release operation. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> While the white balance sensor <highlight><bold>86</bold></highlight> is constituted of a two-dimensional image-capturing element having <highlight><bold>480</bold></highlight> separate pixels provided along 48 columns (across)&times;10 rows (down), and includes the RGB color filter <highlight><bold>861</bold></highlight> to output color signals for 160 pixels, the present invention may be adopted in conjunction with pixel structures other than this. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> While three white balance adjustment signal calculation methods are implemented in the explanation given above, the present invention may be adapted to a white balance adjustment as long as two or more white balance adjustment signal calculating methods are employed. The present invention may be adopted when a white balance adjustment signal calculated by employing a white balance sensor internally provided at the camera and a white balance adjustment signal calculated by employing a white balance sensor provided outside are used in combination. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> While an explanation is given above on an example in which white balance adjustment basic signals are calculated through </paragraph>
<paragraph id="P-0094" lvl="2"><number>&lsqb;0094&rsqb;</number> 1 a white balance adjustment signal calculating method achieved by averaging the color signals over the entire image plane; </paragraph>
<paragraph id="P-0095" lvl="2"><number>&lsqb;0095&rsqb;</number> 2 a white balance adjustment signal calculating method achieved through multiple division white detection; and </paragraph>
<paragraph id="P-0096" lvl="2"><number>&lsqb;0096&rsqb;</number> 3 a white balance adjustment signal calculating method achieved through multiple division skin color detection, methods other than the above may be implemented, instead. For instance, a white balance adjustment signal calculating method achieved through multiple division specific color detection that detects green or sky blue may be executed. When detecting a sky blue, the likelihood of detecting sky blue is assumed to be higher over a larger photographic range. Accordingly, when the white balance adjustment signal calculating method achieved through multiple division sky blue detection is adopted, the weighting point should be raised as the photographic range becomes larger during the weighting point calculation through photographic range analysis. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> While the light-receiving areas at the white balance sensor <highlight><bold>86</bold></highlight> are grouped into 20 areas when calculating a white balance adjustment signal through multiple division specific color detection, the number of area groups does not need to be 20. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> While the photographic scene is analyzed through </paragraph>
<paragraph id="P-0099" lvl="2"><number>&lsqb;0099&rsqb;</number> 1 photographic range analysis </paragraph>
<paragraph id="P-0100" lvl="2"><number>&lsqb;0100&rsqb;</number> 2 red color area analysis; and </paragraph>
<paragraph id="P-0101" lvl="2"><number>&lsqb;0101&rsqb;</number> 3 brightness value analysis, in the explanation given above, it is not always necessary to implement these three scene analyses, and any one of the three types of analyses above or two of the three types of analyses may be implemented. In addition, another scene analysis such as green color area analysis may be implemented. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> The subject brightness value utilized in the brightness value analysis may be a brightness value obtained by averaging brightness values over the photographic image plane, a brightness value obtained by weighting the center of the photographic image plane or a brightness value corresponding to a given area within the photographic image plane. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> Weighting points shown in FIGS. <highlight><bold>5</bold></highlight>A-<highlight><bold>5</bold></highlight>C, FIGS. <highlight><bold>7</bold></highlight>A-<highlight><bold>7</bold></highlight>F and <cross-reference target="DRAWINGS">FIG. 8</cross-reference> are one example. Each weighting point may be varied according to individual photographing modes such as a portrait photography and a landscape photography, etc. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> The above mentioned embodiments are explained with an electronic camera, however, the present invention can be applied to an image processing apparatus constituted of a personal computer or the like that receives an image captured by an electronic camera to performs a white balance adjustment operation to the captured image. In this case, the electronic camera outputs image-capturing data, which are raw data, to a recording medium which the image-capturing data is recorded therein as it is. The recorded raw image data are transferred to the image processing apparatus that performs various operations including a detection of chromaticity of a subject, a scene analysis, a gain calculation, a weighting value calculation, a white balance adjustment gain calculation and a white balance adjustment. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> An image processing apparatus may be constituted of a personal computer. In this case, control programs for aforementioned various operations are installed in the personal computer in advance. These control programs can be provided by means of data signals stored in a recording medium such as CD-ROM or received through an Internet. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows an example of receiving data signals. A personal computer <highlight><bold>300</bold></highlight> receives a program through a CD-ROM <highlight><bold>304</bold></highlight>. The personal computer <highlight><bold>300</bold></highlight> is provided with a communication device connected to a communication line <highlight><bold>301</bold></highlight>. A computer <highlight><bold>302</bold></highlight> is a server computer providing the programs mentioned above and provided with a hard disc storing the programs therein. The communication line <highlight><bold>303</bold></highlight> may be an Internet, a personal computer communication line, an exclusive communication line and the like. The computer <highlight><bold>302</bold></highlight> reads out the program through the hard disc <highlight><bold>303</bold></highlight> and forwards the program to the personal computer <highlight><bold>300</bold></highlight>. A program is embodied as a data signal on a carrier wave that is transmitted through the communication line <highlight><bold>301</bold></highlight>. In this way, a program may be supplied in various types of computer readable computer program products including a recording medium, a carrier wave and the like. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> The above-described embodiments are examples, and various modifications can be made without departing from the spirit and scope of the invention. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A white balance adjustment method comprising: 
<claim-text>detecting chromaticity of a subject by using an image-capturing signal of an image of the subject that has been photographed, </claim-text>
<claim-text>analyzing a scene by using the image-capturing signal, </claim-text>
<claim-text>calculating a white balance adjustment gain for the image-capturing signal based upon the detected chromaticity of the subject and the results of analyzing the scene, and performing a white balance adjustment by applying the white balance adjustment gain to the image-capturing signal. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. An image processing apparatus comprising: 
<claim-text>a chromaticity detection unit that detects chromaticity of a subject by using an image-capturing signal of an image of the subject that has been photographed; </claim-text>
<claim-text>a scene analysis unit that analyzes a scene by using the image-capturing signal, </claim-text>
<claim-text>a gain calculation unit that calculates a white balance adjustment gain for the image-capturing signal based upon detected chromaticity of the subject and the results of analyzing the scene, and </claim-text>
<claim-text>a white balance adjustment unit that performs a white balance adjustment by applying the white balance adjustment gains to the image-capturing signal. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. An electronic camera comprising: 
<claim-text>an image-capturing device that captures a subject image passing through a photographic lens and outputs an image-capturing signal; and </claim-text>
<claim-text>an image processing apparatus in <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. An electronic camera comprising: 
<claim-text>an image-capturing device that captures a subject image passing through a photographic lens and outputs an image-capturing signal; </claim-text>
<claim-text>a chromaticity detection unit that detects chromaticity of the subject by using the image-capturing signal; </claim-text>
<claim-text>a gain calculation unit that calculates first and second gains by using different algorithms based upon the chromaticity detected by the chromaticity detection unit; </claim-text>
<claim-text>a scene analysis unit that analyzes a scene to be photographed, </claim-text>
<claim-text>a weighting value calculation unit that calculates first and second weighting values each for the first and second gains based on results of analyzing the scene; </claim-text>
<claim-text>a final gain calculation unit that calculates a white balance adjustment gain for the image-capturing signal based upon the first and second gains to which the first and second weighting values have been applied respectively; and </claim-text>
<claim-text>a white balance adjustment unit that performs a white balance adjustment by applying the white balance adjustment gains to the image-capturing signal. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. An electronic camera according to <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein: 
<claim-text>the weighting value calculation unit calculates the weighting values so as to give dominance to either the first gain or the second gain. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. An electronic camera according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein: 
<claim-text>the weighting value calculation unit weights the first gain and the second gain by providing different coefficients for the first gain and the second gain, with a positive coefficient set for one of the gains that is to be given dominance and a negative coefficient with a larger absolute value than the positive coefficient provided for the other gain. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. An electronic camera according to <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein: 
<claim-text>the weighting value calculation unit includes a table of a relationship between results of analyzing the scene being photographed and the weighting values. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. An electronic camera according to <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>,wherein; 
<claim-text>the gain calculation unit calculates a first gain by using a white balance adjustment signal calculating method achieved by averaging color signals over an entire image plane, a second gain by using a white balance adjustment signal calculating method achieved through multiple division white detection, and a third gain by using a white balance adjustment signal calculating method achieved through multiple division skin color detection, </claim-text>
<claim-text>the weighting value calculation unit analyzes a scene to be photographed by using a photographic range analysis method, a red color area analysis method and a brightness value analysis method, respectively and calculates a first weighting value for a first gain, a second weighting value for a second gain and a third weighting value for a third gain for each analysis methods for the individual results of analyzing the scene, and </claim-text>
<claim-text>the final gain calculation unit calculates the white balance gain to the image-capturing signals based upon the first gain to which the first weighting value has applied, the second gain to which the second weighting value has applied and the third gain to which the third weighting value has applied. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A computer-readable computer program product containing a control program for white balance adjustment, the control program comprising: 
<claim-text>instruction for detecting chromaticity of a subject by using an image-capturing signal of an image of the subject that has been photographed, </claim-text>
<claim-text>instruction for analyzing the scene by using the image-capturing signal, </claim-text>
<claim-text>instruction for calculating a white balance adjustment gain for the image-capturing signal based upon the chromaticity of the subject and the results of analyzing the scene, and </claim-text>
<claim-text>instruction for performing a white balance adjustment by applying the white balance adjustment gain to the image-capturing signal. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A computer-readable computer program product according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein; 
<claim-text>the program product comprises a recording medium. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A computer-readable computer program product according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein; 
<claim-text>the program product comprises a carrier wave in which the control program is embodied.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>2</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001958A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001958A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001958A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001958A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001958A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001958A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001958A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001958A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001958A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001958A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001958A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030001958A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030001958A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030001958A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030001958A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030001958A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030001958A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
