<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001836A1-20030102-M00001.NB SYSTEM "US20030001836A1-20030102-M00001.NB" NDATA NB>
<!ENTITY US20030001836A1-20030102-M00001.TIF SYSTEM "US20030001836A1-20030102-M00001.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00000.TIF SYSTEM "US20030001836A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00001.TIF SYSTEM "US20030001836A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00002.TIF SYSTEM "US20030001836A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00003.TIF SYSTEM "US20030001836A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00004.TIF SYSTEM "US20030001836A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00005.TIF SYSTEM "US20030001836A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00006.TIF SYSTEM "US20030001836A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00007.TIF SYSTEM "US20030001836A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00008.TIF SYSTEM "US20030001836A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00009.TIF SYSTEM "US20030001836A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001836A1-20030102-D00010.TIF SYSTEM "US20030001836A1-20030102-D00010.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001836</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10094122</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020308</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>01200911.4</doc-number>
</priority-application-number>
<filing-date>20010312</filing-date>
<country-code>EP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06T015/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>345</class>
<subclass>419000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Reconstructor for and method of generating a three-dimensional representation and image display apparatus comprising the reconstructor</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Fabian</given-name>
<middle-name>Edgar</middle-name>
<family-name>Ernst</family-name>
</name>
<residence>
<residence-non-us>
<city>Eindhoven</city>
<country-code>NL</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Cornelius</given-name>
<middle-name>Wilhelmus Antonius Marie</middle-name>
<family-name>Van Overveld</family-name>
</name>
<residence>
<residence-non-us>
<city>Eindhoven</city>
<country-code>NL</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Piotr</given-name>
<family-name>Wilinski</family-name>
</name>
<residence>
<residence-non-us>
<city>Eindhoven</city>
<country-code>NL</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>U.S. Philips Corporation</name-1>
<name-2></name-2>
<address>
<address-1>580 White Plains Road</address-1>
<city>Tarrytown</city>
<state>NY</state>
<postalcode>10591</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A method of generating a three-dimensional representation (<highlight><bold>904</bold></highlight>) of at least one object (<highlight><bold>916</bold></highlight>) from multiple two-dimensional images (<highlight><bold>912</bold></highlight>) of the object makes use of an octree (<highlight><bold>902</bold></highlight>) of cells (<highlight><bold>903</bold></highlight>) to hold the three-dimensional representation (<highlight><bold>904</bold></highlight>), with each cell comprising vertices (<highlight><bold>906</bold></highlight>) and edges (<highlight><bold>910</bold></highlight>) connecting the vertices. The method is based on a process of splitting cells of the octree into smaller cells. A stop criterion for the process of splitting cells is based on inspecting which of the vertices of the cell are inside and which of the vertices are outside the object. Another stop criterion for the process of splitting a cell is based on inspecting whether the vertices of neighboring cells, are inside or outside the object. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The invention relates to a method of generating a three-dimensional representation of an object from a plurality of two-dimensional images of the object, by creating an octree of cells to hold the three-dimensional representation of the object, with each cell comprising vertices, whereby the octree of cells is created by means of a process of recursively splitting the cells of the octree into smaller cells of a next lower level of hierarchy. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The invention further relates to a reconstructor designed to generate a three-dimensional representation of an object from a plurality of two-dimensional images of the object, comprising an octree of cells to hold the three-dimensional representation of the object, with each cell comprising vertices, and the reconstructor being able to perform a process of recursively splitting the cells of the octree into smaller cells of a next lower level of hierarchy. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The invention further relates to an image display apparatus comprising: </paragraph>
<paragraph id="P-0004" lvl="2"><number>&lsqb;0004&rsqb;</number> a reconstructor designed to generate a three-dimensional representation of an object from a plurality of two-dimensional images of the object, comprising an octree of cells to hold the three-dimensional representation of the object, with each cell comprising vertices, and the reconstructor being able to perform a process of recursively splitting the cells of the octree into smaller cells of a next lower level of hierarchy. </paragraph>
<paragraph id="P-0005" lvl="2"><number>&lsqb;0005&rsqb;</number> a renderer to generate two-dimensional images from three-dimensional representations; and </paragraph>
<paragraph id="P-0006" lvl="2"><number>&lsqb;0006&rsqb;</number> a display device to display two-dimensional images. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> A method of the kind described in the opening paragraph is known from T. L. Kunii et al., &ldquo;A graphics compiler for a 3-dimensional captured image database and captured image reusability,&rdquo; in Proceedings of IFIP workshop on Modeling and Motion Capture Techniques for Virtual Environments (CAPTECH98), Heidelberg, 1998. Springer. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The generation of three-dimensional representations out of depth data has generated a large amount of interest in the vision community. In volume-based approaches, a so-called &ldquo;universe&rdquo; is divided into volume elements, called voxels. Subsequent depth maps are used to decide which voxels are &ldquo;empty space&rdquo;, and which voxels consist of &ldquo;objects&rdquo;. The size of the voxels is either defined globally, or refined recursively and stored in a tree-based structure. For scenes with a lot of curved surfaces, a large amount of voxels is needed to obtain the required resolution, making storage expensive. In the cited article it is described to partially overcome these limitations by defining the essential information in the scenes as the location of the singularities and storing those in an octree. An octree is the three-dimensional equivalent of a binary tree. In an octree, each cell can be split into <highlight><bold>8</bold></highlight> child cells. The singularities are the vertices, edges and bounding surfaces of the objects in the scene. Each object is bounded by surfaces. The surfaces are bounded by edges. These in turn have as end points vertices. In this way each object can be built from a hierarchy of singularities, with vertices at the lowest level, then edges, then surfaces and finally the object itself. Note, however, that the hierarchy does not have to start at the vertex level, e.g. in the case of a ball. An advantage of the known method is that the subdivision stage of the octree is terminated at an early level: As soon as the structure within the cell is simple enough, i.e. if a cell contains only one singularity of the lowest order, and not only when a cell is completely inside or outside an object as with other methods. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> A major obstacle in applying the known method for generating a three-dimensional representation from multiple two-dimensional images is the extraction of the singularities, i.e. essential features from the depth maps. This is a &ldquo;hard&rdquo; problem. First of all, accurate localization of vertices and edges from images or depth maps has already generated a vast amount of literature on, e.g., corner detectors, edge detectors and segmentation algorithms, but no suitable general purpose algorithm exists yet. Even if an adequate detector of singularities were available in two-dimensional data, these singularities might be just apparent singularities and not real ones. All locations on a curved surface seen under an angle of 90 degrees seem to be singularities in the image. Consider the situation of a ball in front of a wall. The ball has no singularity like an edge or vertex, however, in the depth map, there will seem to be a singularity at the locations which are observed under an angle of 90 degrees. From this example it can be concluded that the extraction of singularities can not be done just from a single image. The known method is interactive which means that a human operator is required. For a real-time or near real-time application, identification of singularities by a human operator is no viable solution. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> It is a first object of the invention to provide a method of generating a three-dimensional representation of the kind described in the opening paragraph that is fully automatic and hence does not require interactive user input. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> It is a second object of the invention to provide a reconstructor being able to generate three-dimensional representations, of the kind described in the opening paragraph fully automatic. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> It is a third object of the invention to provide an image display apparatus comprising a reconstructor being able to generate three-dimensional representations, of the kind described in the opening paragraph, fully automatic. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The first object of the invention is achieved in that stopping the process of splitting a particular cell is based on inspecting which of the vertices of the particular cell are inside and which of the vertices are outside the object. This avoids the problem of singularity extraction and hence allows for a completely automatic procedure without requiring user interaction for the singularity extraction. The essence of the approach according to the prior art is that the subdivision of the octree is already halted at an early stage: as soon as the description of the object within a cell can be uniquely specified: single-singularity criterion. In the method of the invention the single-singularity criterion is replaced by: A cell should not be split if the topology of the surface within the cell can be derived uniquely from the information at the cell vertices. This is called the uniqueness criterion. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> An advantage of the method according to the invention is that the storage is extremely efficient through use of the octree. Another advantage is that it allows incremental updates of the three-dimensional representation with the arrival of new images. This is very beneficial if video streams are to be processed. Another advantage is that the computational complexity is relatively low. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In an embodiment of the method according to the invention, the vertices of the particular cell are divided into a first set with vertices which are inside the object and a second set with vertices which are outside the object, with the first set and the second set comprising: </paragraph>
<paragraph id="P-0016" lvl="2"><number>&lsqb;0016&rsqb;</number> zero vertices; </paragraph>
<paragraph id="P-0017" lvl="2"><number>&lsqb;0017&rsqb;</number> one vertex; or </paragraph>
<paragraph id="P-0018" lvl="2"><number>&lsqb;0018&rsqb;</number> more than one vertex, with each vertex being connected to every other vertex of the same set by means of a set of edges, with both vertices of each of these edges belonging to the same set of vertices. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> The uniqueness criterion is based on the following criterion and assumptions: </paragraph>
<paragraph id="P-0020" lvl="2"><number>&lsqb;0020&rsqb;</number> Connectivity criterion: Connectivity of vertices within the sets. </paragraph>
<paragraph id="P-0021" lvl="2"><number>&lsqb;0021&rsqb;</number> The assumption that each face and each edge of the cell is crossed by the surface not more than once. </paragraph>
<paragraph id="P-0022" lvl="2"><number>&lsqb;0022&rsqb;</number> The assumption that each object should be contained in at least two cells. This avoids cells completely containing an object. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> The connectivity of vertices within the sets, augmented with the checking of the above assumptions, can therefore be used as the criterion to decide whether a cell should be subdivided or not. To illustrate the uniqueness criterion, an example is given for the most simple case. In <cross-reference target="DRAWINGS">FIG. 3</cross-reference> this will be explained in more detail. Assume there is an octree with cells each having <highlight><bold>8</bold></highlight> vertices. Further it is assumed that for each cell it is known which of the <highlight><bold>8</bold></highlight> vertices of the cell are inside or outside an object. Then <highlight><bold>14</bold></highlight> basic configurations can be discerned for each cell. Of these configurations, only <highlight><bold>8</bold></highlight> configurations can correspond to a single-singularity cell in the sense of the prior art approach. It can be shown that for the configurations where the topology of the surface of the object can be uniquely reconstructed, the first set of vertices and the second set of vertices both form a connected set. Suppose the vertices 0, 2, 4 and 6 are in a first vertical oriented plane and the vertices 1, 3, 5 and 7 are in a second plane which is parallel with the first plane. E.g., if vertices 0, 2, 4 and 6 are inside an object, and 1, 3, 5 and 7 are outside the same object, then the surface of the object crosses the cell substantially vertically. If, in another case, vertices 0, 3, 4 and 7 are inside an object, and 1, 2, 5 and 6 are outside an object, then there are two possible configurations, i.e. ways how surfaces can intersect the cell. If either the first set or the second set is empty, the cell is completely inside or outside an object, respectively. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> In an embodiment of the method according to the invention a second stop criterion for the process of splitting the particular cell is based on inspecting whether a vertex of a neighboring cell, being a cell that share either a face or an edge with the particular cell, is inside or outside the object. If neighboring cells in the octree have unequal sizes, it is known for the larger cell not only whether its vertices are inside or outside an object. It is also known for the larger cell that portions of the edges or faces are inside or outside an object. This information is based on the vertices of neighboring cells. A very important assumption in the generation of the three-dimensional representation according to the invention, is that each edge of a cell intersects the object surface at maximum once. The information of these extra points might lead to the conclusion that the single-singularity criterion is no longer satisfied. If such a situation is encountered, the larger cell has to be split; this splitting criterion is an additional criterion to the connectivity criterion discussed previously. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> In an embodiment of the method according to the invention, the determination whether a vertex is inside or outside the object is based on depth-maps extracted from the two-dimensional projections. The three-dimensional representation can be created by combining information from a series of depth maps, which associate with each point on the image plane a most likely depth value. These depth maps can be created from two images using structure-from-motion algorithms, through active acquisition techniques, e.g. structured light, or passive acquisition techniques, e.g. laser scanning. Furthermore, it is assumed that the position and orientation of the camera is known, i.e. calibrated cameras are present, or have been obtained by a camera calibration algorithm. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> In an embodiment of the method according to the invention, for a vertex of the particular cell a distance to a boundary of the object is calculated for generating the three-dimensional representation. If in each vertex of a cell it is stored whether it is inside or outside an object, the topology of the surface can be recovered uniquely. However, its exact location within the cell is only determined with an accuracy of the cell size. In this embodiment of the method of generating a three-dimensional representation the information in the vertex of a cell is extended with quantitative information to locate the object boundaries with higher accuracy. A way to do this is computing a signed-distance function, u from available depth maps, where u({right arrow over (x)})&equals;0 at the boundary of an object; u({right arrow over (x)})&gt;0 inside an object and u({right arrow over (x)})&lt;0 outside an object, with {right arrow over (x)} a vertex of an octree cell. The absolute value &verbar;u&verbar; denotes the distance to the nearest point of an object boundary, which may lie in any direction. The boundaries of the object can completely be reconstructed by computing the iso-surface u&equals;0. This results in a gain in accuracy of the order of the cell size compared to just binary labeling: inside or outside. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> In an embodiment of the method according to the invention, for a vertex of the particular cell a distance to the boundary of the object is estimated for generating the three-dimensional representation. So far, deterministic values of depth and signed-distance functions have been discussed. In reality, however, depth maps may have a stochastic nature in the sense that upper and lower bounds of the depth are given, together with the most likely depth value d<highlight><subscript>ML</subscript></highlight>. The lower and the upper bound of this uncertainty interval are denoted with d<highlight><subscript>l </subscript></highlight>and d<highlight><subscript>u </subscript></highlight>respectively. The depth uncertainty information allows to mitigate the effects of errors and outliers in the depth information. For each depth measurement three regions can be defined along the depth axis: </paragraph>
<paragraph id="P-0028" lvl="2"><number>&lsqb;0028&rsqb;</number> A region which is definitely outside, for d&lt;d<highlight><subscript>l </subscript></highlight></paragraph>
<paragraph id="P-0029" lvl="2"><number>&lsqb;0029&rsqb;</number> a region containing an object boundary, the so-called &ldquo;thick wall&rdquo; region, for d<highlight><subscript>l</subscript></highlight>&lE;d&lE;d<highlight><subscript>u </subscript></highlight>and; </paragraph>
<paragraph id="P-0030" lvl="2"><number>&lsqb;0030&rsqb;</number> a region which is behind the object boundary when seen from this view point. Note that it is not definitely inside, since this region might not even contain points which are inside objects: basically there is not enough information on this region since it can not be seen from the point of view. The only thing that is known, and which might be used, is that the distance from an outside point to the object is not larger than the distance to the point corresponding with the upper bound of the depth interval.</paragraph>
</summary-of-invention>
<brief-description-of-drawings>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> These and other aspects of the reconstructor for and method of generating a three-dimensional representation and the image display apparatus according to the invention will become apparent from and will be elucidated with reference with respect to the implementations and embodiments described hereinafter and with reference to the accompanying drawings, wherein: </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> schematically shows a quad-tree; </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> schematically shows the process of splitting cells; </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates the uniqueness criterion; </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates the splitting criterion; </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> schematically shows the relation between real objects and a depth-map; </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> schematically shows the process of categorizing vertices based on depth-maps; </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7A</cross-reference> shows a signed distance function; </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7B</cross-reference> illustrates the distance between vertices and an object boundary for two different views; </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7C</cross-reference> shows three isosurfaces; </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates the regions defined for depth measurements; </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates the reconstructor; and </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> shows the image display apparatus. </paragraph>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> schematically shows the two-dimensional variant of an octree: a quad-tree. The root of the tree is a two dimensional box <highlight><bold>100</bold></highlight>. This box has four branches, i.e. is split into four smaller boxes <highlight><bold>102</bold></highlight>-<highlight><bold>108</bold></highlight>. Box <highlight><bold>108</bold></highlight> on its turn has four branches, i.e. is split into four smaller boxes <highlight><bold>110</bold></highlight>-<highlight><bold>116</bold></highlight>. Box <highlight><bold>116</bold></highlight> on its turn has four branches, i.e. is split into four smaller boxes <highlight><bold>118</bold></highlight>-<highlight><bold>122</bold></highlight>. Box <highlight><bold>122</bold></highlight> on its turn has four branches, i.e. is split into four smaller boxes, e.g. <highlight><bold>126</bold></highlight>-<highlight><bold>132</bold></highlight>. In the tree shown in this Fig. each time one of the boxes is split. However, each box can be split in four smaller boxes. In three-dimensions a similar tree can be created, which is called an octree. In that case a cell, instead of a box, is split into <highlight><bold>8</bold></highlight> smaller cells. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> schematically illustrates four phases: A,B,C and D of the process of splitting cells. In the initial state A the surface <highlight><bold>202</bold></highlight> is completely inside cell <highlight><bold>200</bold></highlight>. After a first splitting action, leading to state B, cell <highlight><bold>200</bold></highlight> gets four children cells <highlight><bold>204</bold></highlight>-<highlight><bold>208</bold></highlight>. After a subsequent group of splitting actions, leading to state C, three of these four children cells <highlight><bold>204</bold></highlight>, <highlight><bold>206</bold></highlight> and <highlight><bold>210</bold></highlight> are split in four children cells each, e.g. <highlight><bold>212</bold></highlight>-<highlight><bold>218</bold></highlight> are four children cells of cell <highlight><bold>204</bold></highlight>. One last splitting action leads to state D: Cell <highlight><bold>220</bold></highlight> is split into four child cells. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates the uniqueness criterion. The cell <highlight><bold>300</bold></highlight> has 8 vertices 0-7. The cell <highlight><bold>300</bold></highlight> is depicted four times in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>: A,B,C and D. Assume that for this cell <highlight><bold>300</bold></highlight>, it is known for each of its 8 vertices whether they are inside or outside an object. It can be shown that for the configurations where the topology of the surface can be uniquely reconstructed, the set of &ldquo;inside&rdquo; vertices and the set of &ldquo;outside&rdquo; vertices both form a connected set. The following table shows the basic configurations. For each configuration the set of inside points is indicated and it is indicated whether the subsets are connected sets or not.  
<table-cwu id="TABLE-US-00001">
<number>1</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="OFFSET" colwidth="14PT" align="left"/>
<colspec colname="1" colwidth="91PT" align="left"/>
<colspec colname="2" colwidth="112PT" align="left"/>
<thead>
<row>
<entry></entry>
<entry></entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="2" align="center" rowsep="1"></entry>
</row>
<row>
<entry></entry>
<entry>Positions of inside points</entry>
<entry>Connectivity of subsets</entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="2" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry></entry>
<entry>&mdash;</entry>
<entry>Connected, respectively empty</entry>
</row>
<row>
<entry></entry>
<entry>0</entry>
<entry>Connected</entry>
</row>
<row>
<entry></entry>
<entry>0,1</entry>
<entry>Connected</entry>
</row>
<row>
<entry></entry>
<entry>0,5</entry>
<entry>Non-Connected</entry>
</row>
<row>
<entry></entry>
<entry>0,7</entry>
<entry>Non-Connected</entry>
</row>
<row>
<entry></entry>
<entry>1,2,3</entry>
<entry>Connected</entry>
</row>
<row>
<entry></entry>
<entry>0,1,6</entry>
<entry>Non-Connected</entry>
</row>
<row>
<entry></entry>
<entry>1,4,6</entry>
<entry>Non-Connected</entry>
</row>
<row>
<entry></entry>
<entry>0,1,2,3</entry>
<entry>Connected</entry>
</row>
<row>
<entry></entry>
<entry>0,2,3,6</entry>
<entry>Connected</entry>
</row>
<row>
<entry></entry>
<entry>0,3,4,7</entry>
<entry>Non-Connected</entry>
</row>
<row>
<entry></entry>
<entry>0,2,3,7</entry>
<entry>Connected</entry>
</row>
<row>
<entry></entry>
<entry>1,2,3,4</entry>
<entry>Non-Connected</entry>
</row>
<row>
<entry></entry>
<entry>0,3,5,7</entry>
<entry>Non-Connected</entry>
</row>
<row>
<entry></entry>
<entry>1,2,3,6</entry>
<entry>Connected</entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="2" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0047" lvl="7"><number>&lsqb;0047&rsqb;</number> E.g., if vertices 0, 2, 4 and 6 are inside, and 1, 3, 5 and 7 outside, the surface crosses the cell more or less vertically. This is illustrated with case B. If, on the other hand, vertices 0, 3, 4 and 7 are inside, and 1, 2, 5 and 6 are outside there are two possible configurations: C and D. With surface <highlight><bold>304</bold></highlight> in combination with <highlight><bold>306</bold></highlight> this can be achieved but also with surface <highlight><bold>308</bold></highlight> in combination <highlight><bold>310</bold></highlight>. In other words, although the configuration of inside: 0, 3, 4, 7 and outside: 1, 2, 5, 6 cell vertices is exactly the same, there are two possible ways how the surfaces can intersect the cell. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates the splitting criterion. In <cross-reference target="DRAWINGS">FIG. 4</cross-reference> three neighboring cells are depicted: cell <highlight><bold>400</bold></highlight> and two smaller ones <highlight><bold>402</bold></highlight> and <highlight><bold>404</bold></highlight>. For all vertices it is known whether they are inside or outside an object. E.g. vertices <highlight><bold>406</bold></highlight> and <highlight><bold>410</bold></highlight> are outside an object and vertex <highlight><bold>408</bold></highlight> is inside. A portion of a surface <highlight><bold>412</bold></highlight> of an object is shown. A consequence of the uniqueness assumptions is that each face and each edge of a cell may not be crossed by the surface more than once. In <cross-reference target="DRAWINGS">FIG. 4</cross-reference> it can be seen that one face of cell <highlight><bold>400</bold></highlight> is crossed twice by the surface <highlight><bold>412</bold></highlight> of an object. For cell <highlight><bold>400</bold></highlight> its is not only known whether its vertices are inside or outside an object, but this type of information is also available at another location on the edge connecting vertices <highlight><bold>410</bold></highlight> and <highlight><bold>406</bold></highlight>: at the location of the vertex <highlight><bold>408</bold></highlight>. The information of this extra vertex, from other cells, leads to the conclusion that the single-singularity criterion is no longer satisfied. In this case the larger cell <highlight><bold>400</bold></highlight> has to be split. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5A</cross-reference> shows a wall <highlight><bold>504</bold></highlight> with a cube <highlight><bold>506</bold></highlight> in front of it. The wall <highlight><bold>504</bold></highlight> and the cube <highlight><bold>506</bold></highlight> are imaged multiple times by a moving camera <highlight><bold>500</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows the camera <highlight><bold>500</bold></highlight> at position {right arrow over (e)} &ldquo;watching&rdquo; in direction &thgr;. Point {right arrow over (x)} is a point on the surface of the cube <highlight><bold>506</bold></highlight>. The depth-map <highlight><bold>502</bold></highlight> for this camera position is also shown. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> schematically illustrates three phases: A,B and C of the process of categorizing vertices of cells, e.g. <highlight><bold>600</bold></highlight>. In the initial state A the vertices, e.g. <highlight><bold>602</bold></highlight>-<highlight><bold>606</bold></highlight>, are categorized as &ldquo;inside&rdquo;. This is depicted with a dot for each vertex. Depth-map <highlight><bold>608</bold></highlight> is used to categorize the vertices. After a first processing step, leading to state B, a number of vertices are categorized as &ldquo;outside&rdquo;. This is depicted with crosses. Depth-map <highlight><bold>610</bold></highlight> is used to categorize the vertices further. After the second processing step, leading to state C, another number of vertices are categorized as &ldquo;outside&rdquo;, e.g. <highlight><bold>604</bold></highlight> and <highlight><bold>606</bold></highlight>. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7A</cross-reference> shows a signed distance function, i.e. a function that defines for each vertex of a cell the distance to the nearest surface of an object. In <cross-reference target="DRAWINGS">FIG. 7A</cross-reference> a portion of a surface <highlight><bold>703</bold></highlight> is located inside cell <highlight><bold>701</bold></highlight>. The arrows <highlight><bold>705</bold></highlight>, <highlight><bold>707</bold></highlight>, <highlight><bold>709</bold></highlight> and <highlight><bold>711</bold></highlight> indicate the distance between vertices and the surface <highlight><bold>703</bold></highlight>. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7B</cross-reference> illustrates the distance between vertices and an object boundary for two different views. The surface <highlight><bold>700</bold></highlight> of the object is seen from two different camera positions. For the first view the distances from the vertices <highlight><bold>708</bold></highlight>, <highlight><bold>710</bold></highlight> and <highlight><bold>712</bold></highlight> to the surface <highlight><bold>700</bold></highlight> is indicated with the arrows <highlight><bold>702</bold></highlight>, <highlight><bold>704</bold></highlight> respectively <highlight><bold>706</bold></highlight>. For the second view the distances from the vertices <highlight><bold>708</bold></highlight>, <highlight><bold>710</bold></highlight> and <highlight><bold>712</bold></highlight> to the surface <highlight><bold>700</bold></highlight> is indicated with the arrows <highlight><bold>718</bold></highlight>, <highlight><bold>716</bold></highlight> respectively <highlight><bold>714</bold></highlight>. It is clear that the distances, i.e. length of the arrows, in the second view are shorter than in the first view. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7C</cross-reference> shows three isosurfaces <highlight><bold>713</bold></highlight>, <highlight><bold>715</bold></highlight> and <highlight><bold>717</bold></highlight>. All points of such surface have the same distance to a boundary of an object: </paragraph>
<paragraph id="P-0054" lvl="2"><number>&lsqb;0054&rsqb;</number> isosurface <highlight><bold>715</bold></highlight> corresponds to an object boundary: u({right arrow over (x)})&equals;0; </paragraph>
<paragraph id="P-0055" lvl="2"><number>&lsqb;0055&rsqb;</number> isosurface <highlight><bold>713</bold></highlight> is located outside the object: u({right arrow over (x)})&equals;&minus;1; </paragraph>
<paragraph id="P-0056" lvl="2"><number>&lsqb;0056&rsqb;</number> isosurface <highlight><bold>717</bold></highlight> is located inside the object: u({right arrow over (x)})&equals;1; </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> To compute the signed distance function u, u({right arrow over (x)}&verbar;&thgr;) is defined as the signed distance at vertex of a cell {right arrow over (x)} watched in direction &thgr;. That means that u({right arrow over (x)}&verbar;&thgr;) is only related to the closest surface in direction &thgr;. It originates from a one dimensional ray through the volume. Assume there is a depth map of a single camera with the eye at {right arrow over (e)}, then the camera is watching in direction &thgr;&equals;{right arrow over (x)}&minus;{right arrow over (e)}. Then an approximation of the signed distance function u({right arrow over (x)}&verbar;{right arrow over (x)}&minus;{right arrow over (e)}) is given by:  
<math-cwu id="MATH-US-00001">
<number>1</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>u</mi>
          <mo>&af;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mover>
                <mi>x</mi>
                <mo>-></mo>
              </mover>
              <mo>&VerticalSeparator;</mo>
              <mrow>
                <mover>
                  <mi>x</mi>
                  <mo>-></mo>
                </mover>
                <mo>-</mo>
                <mover>
                  <mi>e</mi>
                  <mo>-></mo>
                </mover>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mrow>
            <mo>&LeftDoubleBracketingBar;</mo>
            <mrow>
              <mover>
                <mi>x</mi>
                <mo>-></mo>
              </mover>
              <mo>-</mo>
              <mover>
                <mi>e</mi>
                <mo>-></mo>
              </mover>
            </mrow>
            <mo>&RightDoubleBracketingBar;</mo>
          </mrow>
          <mo>-</mo>
          <mrow>
            <mrow>
              <msub>
                <mi>d</mi>
                <mi>ML</mi>
              </msub>
              <mo>&af;</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mrow>
                    <mi>&xi;</mi>
                    <mo>&af;</mo>
                    <mrow>
                      <mo>(</mo>
                      <mover>
                        <mi>x</mi>
                        <mo>-></mo>
                      </mover>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>,</mo>
                  <mrow>
                    <mi>v</mi>
                    <mo>&af;</mo>
                    <mrow>
                      <mo>(</mo>
                      <mover>
                        <mi>x</mi>
                        <mo>-></mo>
                      </mover>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>&it;</mo>
            <mfrac>
              <mrow>
                <mo>&LeftDoubleBracketingBar;</mo>
                <mrow>
                  <mover>
                    <mi>x</mi>
                    <mo>-></mo>
                  </mover>
                  <mo>-</mo>
                  <mover>
                    <mi>e</mi>
                    <mo>-></mo>
                  </mover>
                </mrow>
                <mo>&RightDoubleBracketingBar;</mo>
              </mrow>
              <mrow>
                <mover>
                  <mi>k</mi>
                  <mo>-></mo>
                </mover>
                <mo>&CenterDot;</mo>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mover>
                      <mi>x</mi>
                      <mo>-></mo>
                    </mover>
                    <mo>-</mo>
                    <mover>
                      <mi>e</mi>
                      <mo>-></mo>
                    </mover>
                  </mrow>
                  <mo>)</mo>
                </mrow>
              </mrow>
            </mfrac>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>1</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00001" file="US20030001836A1-20030102-M00001.NB"/>
<image id="EMI-M00001" wi="216.027" he="29.0304" file="US20030001836A1-20030102-M00001.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0058" lvl="7"><number>&lsqb;0058&rsqb;</number> where &xgr; and &ngr; are the image-plane co-ordinates of the projections of x on the image plane, k is normal of the image plane and d<highlight><subscript>ML </subscript></highlight>the most likely depth value. Note that u is only defined if (&xgr;,&ngr;) lies within the image plane. This approximation of the signed-distance function is related to the first object boundary seen from the camera eye {right arrow over (e)} in direction {right arrow over (x)}&minus;{right arrow over (e)}. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> With a number of depth-maps a signed-distance function u can be computed incrementally, where u({right arrow over (x)})&equals;0 at the boundary of an object; u({right arrow over (x)})&gt;0 inside an object and u({right arrow over (x)})&lt;0 outside an object. The absolute value &verbar;u&verbar; denotes the distance to the nearest point of an object boundary, which may lie in any direction. To combine the information from multiple depth maps, it must be defined how to merge the information for u({right arrow over (x)}&verbar;&thgr;) into a single value for u({right arrow over (x)}). The following two observations can be made: </paragraph>
<paragraph id="P-0060" lvl="2"><number>&lsqb;0060&rsqb;</number> The signed-distance function is defined as the distance to the closest surface in any direction (See <cross-reference target="DRAWINGS">FIG. 7A</cross-reference>). Hence, </paragraph>
<paragraph lvl="0"><in-line-formula>&boxH;u(x)l &equals;minlu(-x&verbar;&thgr;)I (<highlight><bold>2</bold></highlight>) </in-line-formula></paragraph>
<paragraph id="P-0061" lvl="2"><number>&lsqb;0061&rsqb;</number> If a point is, from a certain camera view point, behind the first object boundary, it gets with equation (1) a positive value for the signed distance. However, it is not known whether the point is inside, or behind the object. On the other hand, if u({right arrow over (x)})&lt;0 it is known for certain that the point is outside an object: one is able to see through it. Therefore a negative value of the signed-distance function prevails over a positive one. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Even in the case where one changes from a positive to a negative value of u the absolute value should be the smaller of both: If u({right arrow over (x)})&gt;0, it is known that the point x is at a distance of &verbar;u&verbar; behind a boundary. If the camera would have looked from point {right arrow over (x)} in direction &minus;({right arrow over (x)}&minus;{right arrow over (e))} the camera would at the latest encounter an object boundary at distance &verbar;u&verbar;. The new best approximation &verbar;u&verbar; given the current approximation of the signed-distance function u<highlight><subscript>k </subscript></highlight>and a new candidate v<highlight><subscript>k </subscript></highlight>is then the following: </paragraph>
<paragraph lvl="0"><in-line-formula>&verbar;u&verbar;&equals;min(&verbar;u<highlight><subscript>k</subscript></highlight>&verbar;,&verbar;v<highlight><subscript>k</subscript></highlight>&verbar;) with </in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>sign(u)&equals;1 if u<highlight><subscript>k</subscript></highlight>&gt;0, v<highlight><subscript>k</subscript></highlight>&gt;0 and else sign(u)&equals;&minus;1&emsp;&emsp;(3) </in-line-formula></paragraph>
<paragraph id="P-0063" lvl="7"><number>&lsqb;0063&rsqb;</number> In tabular form:  
<table-cwu id="TABLE-US-00002">
<number>2</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="77PT" align="left"/>
<colspec colname="2" colwidth="56PT" align="left"/>
<colspec colname="3" colwidth="84PT" align="left"/>
<thead>
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="3" align="center" rowsep="1"></entry>
</row>
<row>
<entry>Current value of signed</entry>
<entry></entry>
<entry>Resulting value of signed</entry>
</row>
<row>
<entry>distance function</entry>
<entry>Measurement</entry>
<entry>distance function</entry>
</row>
<row><entry namest="1" nameend="3" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry>u<highlight><subscript>k </subscript></highlight>&lt; 0</entry>
<entry>V<highlight><subscript>k </subscript></highlight>&lt; 0</entry>
<entry>&minus;min(&verbar;u<highlight><subscript>k</subscript></highlight>&verbar;,&verbar;v<highlight><subscript>k</subscript></highlight>&verbar;)</entry>
</row>
<row>
<entry>u<highlight><subscript>k </subscript></highlight>&lt; 0</entry>
<entry>V<highlight><subscript>k </subscript></highlight>&gt; 0</entry>
<entry>&minus;min(&verbar;u<highlight><subscript>k</subscript></highlight>&verbar;,&verbar;v<highlight><subscript>k</subscript></highlight>&verbar;)</entry>
</row>
<row>
<entry>u<highlight><subscript>k </subscript></highlight>&gt; 0</entry>
<entry>V<highlight><subscript>k </subscript></highlight>&lt; 0</entry>
<entry>&minus;min(&verbar;u<highlight><subscript>k</subscript></highlight>&verbar;,&verbar;v<highlight><subscript>k</subscript></highlight>&verbar;)</entry>
</row>
<row>
<entry>u<highlight><subscript>k </subscript></highlight>&gt; 0</entry>
<entry>V<highlight><subscript>k </subscript></highlight>&gt; 0</entry>
<entry>min(&verbar;u<highlight><subscript>k</subscript></highlight>&verbar;,&verbar;v<highlight><subscript>k</subscript></highlight>&verbar;)</entry>
</row>
<row><entry namest="1" nameend="3" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates the regions defined for depth measurements. For each depth measurement three regions can be defined along the depth axis: </paragraph>
<paragraph id="P-0065" lvl="2"><number>&lsqb;0065&rsqb;</number> a region which is definitely outside. This is called the outside region <highlight><bold>801</bold></highlight> </paragraph>
<paragraph id="P-0066" lvl="2"><number>&lsqb;0066&rsqb;</number> a region containing an object boundary. This is called the thick wall region <highlight><bold>802</bold></highlight> </paragraph>
<paragraph id="P-0067" lvl="2"><number>&lsqb;0067&rsqb;</number> a region which is behind the object boundary when seen from this view point. It is called the inside region <highlight><bold>808</bold></highlight>. </paragraph>
<paragraph id="P-0068" lvl="7"><number>&lsqb;0068&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 8</cross-reference> two measurements are shown. Camera <highlight><bold>800</bold></highlight> is watching objects. In case A the surface of the object is referenced with <highlight><bold>806</bold></highlight>. In case B the surface of the object is referenced with <highlight><bold>810</bold></highlight>. The measurement is referenced with <highlight><bold>804</bold></highlight>. In case A the inside region <highlight><bold>808</bold></highlight> extends beyond the object bounded by surface <highlight><bold>806</bold></highlight>. On the other hand, case B shows that the inside region <highlight><bold>808</bold></highlight> does not have to contain any points inside the object: due to the large error bound the complete object is already contained in the thick wall region. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Uncertainty can be incorporated by assigning to each vertex a region value which is based on the uncertainty interval bounds. This region value can be found in a similar way to the sign of the signed distance function. A table to update the region values incrementally is shown in the following table:  
<table-cwu id="TABLE-US-00003">
<number>3</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="4">
<colspec colname="OFFSET" colwidth="14PT" align="left"/>
<colspec colname="1" colwidth="70PT" align="left"/>
<colspec colname="2" colwidth="56PT" align="left"/>
<colspec colname="3" colwidth="77PT" align="left"/>
<thead>
<row>
<entry></entry>
<entry></entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="3" align="center" rowsep="1"></entry>
</row>
<row>
<entry></entry>
<entry>Current region value</entry>
<entry>Measurement</entry>
<entry>Resulting region value</entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="3" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry></entry>
<entry>Outside</entry>
<entry>Outside</entry>
<entry>Outside</entry>
</row>
<row>
<entry></entry>
<entry>Outside</entry>
<entry>Thick wall</entry>
<entry>Outside</entry>
</row>
<row>
<entry></entry>
<entry>Outside</entry>
<entry>Inside</entry>
<entry>Outside</entry>
</row>
<row>
<entry></entry>
<entry>Thick wall</entry>
<entry>Outside</entry>
<entry>Outside</entry>
</row>
<row>
<entry></entry>
<entry>Thick wall</entry>
<entry>Thick wall</entry>
<entry>Thick wall</entry>
</row>
<row>
<entry></entry>
<entry>Thick wall</entry>
<entry>Inside</entry>
<entry>Thick wall</entry>
</row>
<row>
<entry></entry>
<entry>Inside</entry>
<entry>Outside</entry>
<entry>Inside</entry>
</row>
<row>
<entry></entry>
<entry>Inside</entry>
<entry>Thick wall</entry>
<entry>Thick wall</entry>
</row>
<row>
<entry></entry>
<entry>Inside</entry>
<entry>Inside</entry>
<entry>Inside</entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="3" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The reasoning underlying this table is the following: If a point is seen from anywhere as being outside any object, it has been seen through it and it can not be anything else than free space. Since there is no information on the inside region, this information is overruled by thick wall information, since that means that there is an object boundary in that region. If the depth uncertainty is zero, this reduces to the signed-distance ordering relation. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> Two kinds of properties on the cell vertices are specified: A signed-distance function u which is related to the maximum likelihood value of the depth, and a region value, which is related to the bounds of the depth uncertainty interval. The signed-distance function defines for each vertex of a cell the distance to the nearest surface of an object. The region value allows to deal with uncertainty, by specifying whether a vertex of a cell is outside all objects, inside an object, or in a region containing an object boundary, a so-called &ldquo;thick-wall&rdquo; region. The region values and signed-distance function values for the vertices are stored in one octree for efficiency. However it is possible to store the information in two separate octrees with equal structure. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> The procedure to generate the three-dimensional representation is as follows. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> During initialization, the boundaries of the universe to operate in are set; this is the root of the octree. Initially, the signed-distance function at each vertex of a cell in the initial structure is set to infinity and its region value to &ldquo;inside&rdquo;. For every depth map, the following processing sequence is then applied: </paragraph>
<paragraph id="P-0074" lvl="2"><number>&lsqb;0074&rsqb;</number> Read new depth map d, and corresponding camera parameters for image i. </paragraph>
<paragraph id="P-0075" lvl="2"><number>&lsqb;0075&rsqb;</number> Update the values for the cell vertices in the octree: </paragraph>
<paragraph id="P-0076" lvl="3"><number>&lsqb;0076&rsqb;</number> For each vertex of a cell {right arrow over (x)}<highlight><subscript>k </subscript></highlight>in the octree, compute v<highlight><subscript>k</subscript></highlight>&equals;u({right arrow over (x)}<highlight><subscript>k</subscript></highlight>&verbar;{right arrow over (x)}<highlight><subscript>k</subscript></highlight>&minus;{right arrow over (e)}<highlight><subscript>i</subscript></highlight>) according to Equation (1). </paragraph>
<paragraph id="P-0077" lvl="3"><number>&lsqb;0077&rsqb;</number> Update u<highlight><subscript>k </subscript></highlight>by finding the new best approximation from u<highlight><subscript>k </subscript></highlight>and v<highlight><subscript>k </subscript></highlight>using Equation (3) </paragraph>
<paragraph id="P-0078" lvl="2"><number>&lsqb;0078&rsqb;</number> Check for each cell whether it needs to be split according to the uniqueness criteria. If so, it is split and the vertex of a cell values are updated. This continues until no more cells need to be split. </paragraph>
<paragraph id="P-0079" lvl="2"><number>&lsqb;0079&rsqb;</number> Finally, update the region values for all cell vertices. Since this does not influence the octree structure, this can be done after all splitting has taken place. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates the reconstructor <highlight><bold>900</bold></highlight> in its context. An object <highlight><bold>916</bold></highlight> having a boundary <highlight><bold>914</bold></highlight> between its inside and its outside is imaged from multiple directions. The two-dimensional images of the object, e.g. <highlight><bold>912</bold></highlight>, are labeled with depth-values for each pixel. The reconstructor <highlight><bold>900</bold></highlight> is designed to generate a three-dimensional representation <highlight><bold>904</bold></highlight> of the object <highlight><bold>916</bold></highlight> from these images. The reconstructor <highlight><bold>900</bold></highlight> comprises an octree <highlight><bold>902</bold></highlight> of cells, e.g. <highlight><bold>903</bold></highlight> to hold the three-dimensional representation <highlight><bold>904</bold></highlight>. Each cell comprises vertices, e.g. <highlight><bold>906</bold></highlight> and <highlight><bold>908</bold></highlight> and edges connecting the vertices, e.g. <highlight><bold>910</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 10</cross-reference> shows an image display apparatus <highlight><bold>1000</bold></highlight> which comprises: </paragraph>
<paragraph id="P-0081" lvl="2"><number>&lsqb;0081&rsqb;</number> a depth-map generator <highlight><bold>1002</bold></highlight>; </paragraph>
<paragraph id="P-0082" lvl="2"><number>&lsqb;0082&rsqb;</number> a reconstructor <highlight><bold>900</bold></highlight>; </paragraph>
<paragraph id="P-0083" lvl="2"><number>&lsqb;0083&rsqb;</number> a renderer <highlight><bold>1006</bold></highlight>; and </paragraph>
<paragraph id="P-0084" lvl="2"><number>&lsqb;0084&rsqb;</number> a display device <highlight><bold>1008</bold></highlight>. </paragraph>
<paragraph id="P-0085" lvl="7"><number>&lsqb;0085&rsqb;</number> The input of the image display apparatus <highlight><bold>1000</bold></highlight> is a sequence of images. These images are processed in a number of steps. First depth-maps are generated for these images, e.g. by making use of parallax. The depth-maps are input for the reconstructor <highlight><bold>900</bold></highlight> which is designed to generate a three-dimensional representation of objects in the imaged scene. The incoming images represent these objects. The output of the reconstructor <highlight><bold>900</bold></highlight>, being a three-dimensional representation of objects is input for the renderer <highlight><bold>1006</bold></highlight>. The renderer <highlight><bold>1006</bold></highlight> is able to generate two-dimensional images from three-dimensional representations. These generated images may correspond to views which have not originally been made by the camera capturing the scene. The generated two-dimensional images are displayed by the display device <highlight><bold>1008</bold></highlight>. The display device <highlight><bold>1008</bold></highlight> might be a regular display device but it might also be a type that is able to display pairs or groups of images representing views from slightly different angles: a stereoscopic display device respectively a &ldquo;multiscopic&rdquo; display device with e.g. a lenticular screen. For performance reasons the depth-map generator <highlight><bold>1002</bold></highlight>, reconstructor <highlight><bold>900</bold></highlight> and renderer <highlight><bold>1006</bold></highlight> might be implemented on silicon, i.e. dedicated hardware. In case of less performance critical circumstances a programmable hardware platform might be sufficient to realize these three devices. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> It should be noted that the above-mentioned embodiments illustrate rather than limit the invention and that those skilled in the art will be able to design alternative embodiments without departing from the scope of the appended claims. In the claims, any reference signs placed between parentheses shall not be constructed as limiting the claim. The word &ldquo;comprising&rdquo; does not exclude the presence of elements or steps not listed in a claim. The word &ldquo;a&rdquo; or &ldquo;an&rdquo; preceding an element does not exclude the presence of a plurality of such elements. The invention can be implemented by means of hardware comprising several distinct elements and by means of a suitable programmed computer. In the unit claims enumerating several means, several of these means can be embodied by one and the same item of hardware. </paragraph>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of generating a three-dimensional representation (<highlight><bold>904</bold></highlight>) of an object (<highlight><bold>916</bold></highlight>) from a plurality of two-dimensional images (<highlight><bold>912</bold></highlight>) of the object, by creating an octree (<highlight><bold>902</bold></highlight>) of cells (<highlight><bold>903</bold></highlight>) to hold the three-dimensional representation of the object (<highlight><bold>904</bold></highlight>), with each cell (<highlight><bold>903</bold></highlight>) comprising vertices (<highlight><bold>906</bold></highlight>), whereby the octree of cells is created by means of a process of recursively splitting the cells (<highlight><bold>903</bold></highlight>) of the octree (<highlight><bold>902</bold></highlight>) into smaller cells of a next lower level of hierarchy, characterized in that stopping the process of splitting a particular cell (<highlight><bold>903</bold></highlight>) is based on inspecting which of the vertices (<highlight><bold>906</bold></highlight>) of the particular cell (<highlight><bold>903</bold></highlight>) are inside and which of the vertices (<highlight><bold>906</bold></highlight>) are outside the object (<highlight><bold>916</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A method as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, characterized in that the vertices (<highlight><bold>906</bold></highlight>) of the particular cell (<highlight><bold>903</bold></highlight>) are divided into a first set with vertices which are inside the object (<highlight><bold>916</bold></highlight>) and a second set with vertices which are outside the object (<highlight><bold>916</bold></highlight>), with the first set and the second set comprising: 
<claim-text>zero vertices; </claim-text>
<claim-text>one vertex; or </claim-text>
<claim-text>more than one vertex, with each vertex being connected to every other vertex of the same set by means of a set of edges, with both vertices of each of these edges belonging to the same set of vertices. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A method as claimed in <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, characterized in that a second stop criterion for the process of splitting the particular cell (<highlight><bold>400</bold></highlight>) is based on inspecting whether a vertex (<highlight><bold>408</bold></highlight>) of a neighboring cell (<highlight><bold>402</bold></highlight>), is inside or outside the object (<highlight><bold>412</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A method as claimed in <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, characterized in that the vertex (<highlight><bold>408</bold></highlight>) of the neighboring cell (<highlight><bold>402</bold></highlight>) is inspected if the neighboring cell (<highlight><bold>402</bold></highlight>) is smaller than the particular cell (<highlight><bold>400</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A method as claimed in <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, characterized in that depth-maps (<highlight><bold>502</bold></highlight>), extracted from the two-dimensional images(<highlight><bold>912</bold></highlight>), are used as a bases for determining whether a vertex (<highlight><bold>906</bold></highlight>) is inside or outside the object (<highlight><bold>916</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A method as claimed in <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, characterized in that for a vertex of the particular cell (<highlight><bold>701</bold></highlight>) a distance (<highlight><bold>705</bold></highlight>) to a boundary (<highlight><bold>703</bold></highlight>) of the object is calculated for generating the three-dimensional representation (<highlight><bold>904</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A method as claimed in <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, characterized in that for a vertex of the particular cell a distance to the boundary of the object (<highlight><bold>806</bold></highlight>) is estimated for generating the three-dimensional representation (<highlight><bold>904</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A reconstructor (<highlight><bold>900</bold></highlight>) designed to generate a three-dimensional representation (<highlight><bold>904</bold></highlight>) of an object (<highlight><bold>916</bold></highlight>) from a plurality of two-dimensional images (<highlight><bold>912</bold></highlight>) of the object (<highlight><bold>916</bold></highlight>), comprising an octree (<highlight><bold>902</bold></highlight>) of cells (<highlight><bold>903</bold></highlight>) to hold the three-dimensional representation of the object (<highlight><bold>904</bold></highlight>), with each cell (<highlight><bold>903</bold></highlight>) comprising vertices (<highlight><bold>906</bold></highlight>), and the reconstructor being able to perform a process of recursively splitting the cells (<highlight><bold>903</bold></highlight>) of the octree (<highlight><bold>902</bold></highlight>) into smaller cells of a next lower level of hierarchy, characterized in that the reconstructor (<highlight><bold>900</bold></highlight>) is designed to inspect which of the vertices (<highlight><bold>906</bold></highlight>) of a particular cell (<highlight><bold>903</bold></highlight>) are inside and which of the vertices are outside the object (<highlight><bold>916</bold></highlight>) in order to be able to decide to stop the process of splitting the particular cell (<highlight><bold>903</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A reconstructor (<highlight><bold>900</bold></highlight>) as claimed in <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, characterized in being designed to inspect whether a vertex (<highlight><bold>408</bold></highlight>) of a neighboring cell (<highlight><bold>402</bold></highlight>), is inside or outside the object in order to be able to decide to stop the process of splitting the particular cell (<highlight><bold>400</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A reconstructor (<highlight><bold>900</bold></highlight>) as claimed in <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, characterized in being designed to determine whether a vertex is inside or outside the object based on depth-maps (<highlight><bold>502</bold></highlight>) extracted from the two-dimensional images(<highlight><bold>912</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A reconstructor as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, characterized in being designed to calculate for a vertex of the particular cell (<highlight><bold>701</bold></highlight>) a distance (<highlight><bold>705</bold></highlight>) to the boundary (<highlight><bold>703</bold></highlight>) of the object for generating the three-dimensional representation (<highlight><bold>904</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A reconstructor (<highlight><bold>900</bold></highlight>) as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, characterized in being designed to estimate for a vertex of the particular cell a distance to the boundary of the object for generating the three-dimensional representation (<highlight><bold>904</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. An image display apparatus (<highlight><bold>1000</bold></highlight>) comprising: 
<claim-text>a reconstructor (<highlight><bold>900</bold></highlight>) designed to generate a three-dimensional representation (<highlight><bold>904</bold></highlight>) of an object (<highlight><bold>916</bold></highlight>) from a plurality of two-dimensional images (<highlight><bold>912</bold></highlight>) of the object (<highlight><bold>916</bold></highlight>), comprising an octree (<highlight><bold>902</bold></highlight>) of cells (<highlight><bold>903</bold></highlight>) to hold the three-dimensional representation of the object (<highlight><bold>904</bold></highlight>), with each cell (<highlight><bold>903</bold></highlight>) comprising vertices (<highlight><bold>906</bold></highlight>), and the reconstructor being able to perform a process of recursively splitting the cells (<highlight><bold>903</bold></highlight>) of the octree (<highlight><bold>902</bold></highlight>) into smaller cells of a next lower level of hierarchy; </claim-text>
<claim-text>a renderer (<highlight><bold>1006</bold></highlight>) to generate two-dimensional images from three-dimensional representations; and </claim-text>
<claim-text>a display device (<highlight><bold>1008</bold></highlight>) to display two-dimensional images, characterized in that the reconstructor (<highlight><bold>900</bold></highlight>) is designed to inspect which of the vertices of a particular cell are inside and which of the vertices are outside the object in order to be able to stop the process of splitting the particular cell.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>9</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001836A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001836A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001836A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001836A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001836A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001836A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001836A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001836A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001836A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001836A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001836A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
