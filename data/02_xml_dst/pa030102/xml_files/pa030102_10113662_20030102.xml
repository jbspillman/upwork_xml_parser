<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004774A1-20030102-D00000.TIF SYSTEM "US20030004774A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00001.TIF SYSTEM "US20030004774A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00002.TIF SYSTEM "US20030004774A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00003.TIF SYSTEM "US20030004774A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00004.TIF SYSTEM "US20030004774A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00005.TIF SYSTEM "US20030004774A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00006.TIF SYSTEM "US20030004774A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00007.TIF SYSTEM "US20030004774A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00008.TIF SYSTEM "US20030004774A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00009.TIF SYSTEM "US20030004774A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00010.TIF SYSTEM "US20030004774A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00011.TIF SYSTEM "US20030004774A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00012.TIF SYSTEM "US20030004774A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00013.TIF SYSTEM "US20030004774A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00014.TIF SYSTEM "US20030004774A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00015.TIF SYSTEM "US20030004774A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00016.TIF SYSTEM "US20030004774A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00017.TIF SYSTEM "US20030004774A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00018.TIF SYSTEM "US20030004774A1-20030102-D00018.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00019.TIF SYSTEM "US20030004774A1-20030102-D00019.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00020.TIF SYSTEM "US20030004774A1-20030102-D00020.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00021.TIF SYSTEM "US20030004774A1-20030102-D00021.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00022.TIF SYSTEM "US20030004774A1-20030102-D00022.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00023.TIF SYSTEM "US20030004774A1-20030102-D00023.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00024.TIF SYSTEM "US20030004774A1-20030102-D00024.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00025.TIF SYSTEM "US20030004774A1-20030102-D00025.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00026.TIF SYSTEM "US20030004774A1-20030102-D00026.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00027.TIF SYSTEM "US20030004774A1-20030102-D00027.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00028.TIF SYSTEM "US20030004774A1-20030102-D00028.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00029.TIF SYSTEM "US20030004774A1-20030102-D00029.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00030.TIF SYSTEM "US20030004774A1-20030102-D00030.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00031.TIF SYSTEM "US20030004774A1-20030102-D00031.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00032.TIF SYSTEM "US20030004774A1-20030102-D00032.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00033.TIF SYSTEM "US20030004774A1-20030102-D00033.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00034.TIF SYSTEM "US20030004774A1-20030102-D00034.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00035.TIF SYSTEM "US20030004774A1-20030102-D00035.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00036.TIF SYSTEM "US20030004774A1-20030102-D00036.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00037.TIF SYSTEM "US20030004774A1-20030102-D00037.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00038.TIF SYSTEM "US20030004774A1-20030102-D00038.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00039.TIF SYSTEM "US20030004774A1-20030102-D00039.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00040.TIF SYSTEM "US20030004774A1-20030102-D00040.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00041.TIF SYSTEM "US20030004774A1-20030102-D00041.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00042.TIF SYSTEM "US20030004774A1-20030102-D00042.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00043.TIF SYSTEM "US20030004774A1-20030102-D00043.TIF" NDATA TIF>
<!ENTITY US20030004774A1-20030102-D00044.TIF SYSTEM "US20030004774A1-20030102-D00044.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004774</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10113662</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020329</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F017/60</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>705</class>
<subclass>008000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method and system for realizing an avatar in a management operations center implemented in a global ecosystem of interrelated services</title-of-invention>
</technical-information>
<continuity-data>
<division-of>
<parent-child>
<child>
<document-id>
<doc-number>10113662</doc-number>
<kind-code>A1</kind-code>
<document-date>20020329</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09863456</doc-number>
<document-date>20010522</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>PENDING</parent-status>
</parent-child>
</division-of>
<non-provisional-of-provisional>
<document-id>
<doc-number>60206564</doc-number>
<document-date>20000522</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>William</given-name>
<middle-name>S.</middle-name>
<family-name>Greene</family-name>
</name>
<residence>
<residence-us>
<city>Fairview</city>
<state>TX</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Matthew</given-name>
<middle-name>C.</middle-name>
<family-name>Pierret</family-name>
</name>
<residence>
<residence-us>
<city>Plano</city>
<state>TX</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Christine</given-name>
<family-name>Coffey</family-name>
</name>
<residence>
<residence-us>
<city>McKinney</city>
<state>TX</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>WORLDCOM, INC.</name-1>
<name-2>TECHNOLOGY LAW DEPARTMENT</name-2>
<address>
<address-1>1133 19TH STREET NW</address-1>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20036</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">In accordance with an exemplary embodiment of the present invention, an avatar object is presented which is well-suited for the NewWave service platform. An avatar is a virtual representation of an individual or group as a Global Information Bus (GIB) software service with which other services can interact (i.e., proxy of person). Thus, a service needing to contact a person need not know who that person is. Each avatar includes means for reaching and communicating with the individual wherever they are in the global ecosystem. An avatar is the virtualization of service methods translated to user actions. In short, an avatar is an object personification of the attributes of a person, team, group, or the like, which represents specific qualities associated with the subject of the avatar. Operators, provisions, customer contacts, service support staff and any other management-tasked staff in the customer and network care environment will have an avatar(s) for a network management task manager, such as a Management Operations Canter (MOC). An avatar&apos;s virtual image may also represent a history of past work, interactions, success ratings associated with personification of the subject of the avatar. along with its current workload and contact information for forwarding all communications, messages and work to the contact via the appropriate contact mean(s)interacting with the avatar. Initially, an avatar object registers itself as, for example as a contact entity within a DataBus, with a registry within the domain of a service which may need the contact data. Any service requesting information associated with the avatar object locates this proxy using existing NewWave protocols, and then communicates with the avatar through its proxy. In accordance with one embodiment, a service invite a person to participate in a work group based on the needs of the service and attributes of the avatar and then bind their avatar to an associated work document. As the work proceeds, the avatar attributes are updated to reflect its workload and upon completion of the task the avatar&apos;s its history is updated to reflect the its association with the particular task and the success rating of the completion of the task. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">CROSS REFERENCES TO RELATED APPLICATIONS </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present application is a divisional application of, and claims priority from, co-pending U.S. patent application Ser. No. 09/863,456 entitled &ldquo;METHOD AND SYSTEM FOR MANAGING PARTITIONED DATA RESOURCES,&rdquo; filed on May 22, 2001, currently pending which claims priority from provisional U.S. patent application No. 60/206,564 filed on May 22, 2000 and is a divisional application of the following non-provisional U.S. patent applications: &ldquo;METHOD AND SYSTEM FOR IMPLEMENTING A GLOBAL ECOSYSTEM OF INTERRELATED SERVICES,&rdquo; Attorney Docket No. RIC-01-005 filed on Mar. 29, 2002; &ldquo;METHOD AND SYSTEM FOR IMPLEMENTING A MANAGEMENT OPERATIONS CENTER IN A GLOBAL ECOSYSTEM OF INTERRELATED SERVICES,&rdquo; Attorney Docket No. RIC-01-006 filed on Mar. 29, 2002; &ldquo;METHOD AND SYSTEM FOR REALIZING AN AGGREGATOR IN A MANAGEMENT OPERATIONS CENTER IMPLEMENTED IN A GLOBAL ECOSYSTEM OF INTERRELATED SERVICES,&rdquo; Attorney Docket No. RIC-01-007 filed on Mar. 29, 2002; &ldquo;METHOD AND SYSTEM FOR REALIZING A RENDEZVOUS SERVICE IN A MANAGEMENT OPERATIONS CENTER IMPLEMENTED IN A GLOBAL ECOSYSTEM OF INTERRELATED SERVICES,&rdquo; Attorney Docket No. RIC-01-009 filed on Mar. 29, 2002; &ldquo;METHOD AND SYSTEM FOR IMPLEMENTING IMPROVED CONTAINERS IN A GLOBAL ECOSYSTEM OF INTERRELATED SERVICES,&rdquo; Attorney Docket No. RIC-01-010 filed on Mar. 29, 2002; &ldquo;METHOD AND SYSTEM FOR IMPLEMENTING A GLOBAL LOOKUP IN A GLOBAL ECOSYSTEM OF INTERRELATED SERVICES,&rdquo; Attorney Docket No. RIC-01-01 filed on Mar. 29, 2002; &ldquo;METHOD AND SYSTEM FOR USING MOBILE CODE IN A GLOBAL ECOSYSTEM OF INTERRELATED SERVICES,&rdquo; Attorney Docket No. RIC-01-012 filed on Mar. 29, 2002; &ldquo;METHOD AND SYSTEM FOR IMPLEMENTING A DATA BUS IN A GLOBAL ECOSYSTEM OF INTERRELATED SERVICES&rdquo; Attorney Docket No. RIC-01-013 filed on Mar. 29, 2002; and &ldquo;METHOD AND SYSTEM FOR IMPLEMENTING A GLOBAL INFORMATION BUS IN A GLOBAL ECOSYSTEM OF INTERRELATED SERVICES,&rdquo; Attorney Docket No. RIC-01-014 filed on Mar. 29, 2002; which are assigned to the assignee of the present invention. The above identified applications are incorporated by reference in their entirety. </paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The present invention relates to providing ubiquitous access to data resources even where such data resources are maintained in separate stores and by entirely separate processes. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> 2. Description of Related Art </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> The operation of a modern large business enterprise relies heavily upon the processing, storing, communicating and manipulation of vast amounts of information. This is particularly true of a large service company, such as a global telecommunications company. The types of information vary widely and may include, for example, customer data, employee data, account information, traffic and revenue statistics, and engineering data such as network topology and provisioning data. The vital information that supports a large enterprise may even include the software instructions that drive various elements and systems in a telecommunications network. Some information is relatively static, such as the name or address of a customer, whereas other forms of information, such as the momentary operational status of a network element, can change abruptly and must be communicated as quickly as possible to points where the information is needed. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Traditionally, the various types of information that support a large enterprise have been treated separately. Each principal function in the company, such as human resources, customer service, or engineering, has been self-contained in its use and maintenance of the data needed by that function. Each function typically selects its own tools (software applications and hardware platforms), populates its own data store, and institutes its own procedures with little regard to the remainder of the enterprise. In cases where there has been limited sharing of data between functions, the implementation has often been an ad hoc gateway between divergent systems and approaches. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> It is becoming widely recognized in the field of information technology that it is not only advantageous, but essential to use a comprehensive approach to managing the data in a large enterprise. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Various approaches have been applied in an attempt to achieve ubiquitous access to data. One approach is to maintain all of the data in one central location. As the amount of data grows, this approach rapidly leads to a bottleneck at the servers as many &ldquo;clients&rdquo; attempt to simultaneously access the body of data. Furthermore, the remote access to the data requires a communications infrastructure and may consume considerable bandwidth. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> To relieve these constraints, a different approach involves replicating the data at many distributed sites. In most cases, it is usually not known beforehand what particular data may be needed at a given site, so the entire data store must be replicated at each site. While this divides the demands upon the access to the data, this approach introduces problems in maintaining synchronization among the copies of the data. Furthermore, the replication multiplies the overall storage resources needed, which can be very substantial. If a design is chosen that replicates the data as needed to maintain a certain level of performance in accessing the data, then the overall storage may actually grow as the square of the data size. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> As a compromise between centralization and replication, a caching approach can be used wherein local data stores are used to partially duplicate only those portions of the overall data that are needed locally. Typically, in response to requests from points of use that rely on the cache, the local cache selectively downloads data only on an as-needed basis. The cache will accumulate a self-forming subset of the overall data. Once loaded, a particular data item in the local cache may be held indefinitely or may be discarded after a time according to a caching algorithm. Schemes have also been deployed for ensuring that data in the cache is kept current as changes occur in the corresponding data in the master data store. Although a distributed approach introduces some complexities, there are some advantages to be gained. </paragraph>
</section>
<section>
<heading lvl="1">BRIEF SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The present invention is directed to a method and system whereby data entities, even in a highly distributed and partitioned environment, may be readily accessed by client applications across an enterprise. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> A new approach is required in the context of a partitioned body of data wherein separate data stores are maintained by separate computing processes and separate business functions and are usually physically separated. When data resides in a single space, such as data tables in a relational database, it is easy to represent relationships among data elements. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> For example, in a database, a first table may contain employee information and each record might have as separate fields, an employee number, a social security number, a hire date, and a salary grade. There may be a second table wherein each record maps an employee number to a (project number) department number and internal mail location. Yet, a third table may have social security numbers mapped to an employee&apos;s name and home address. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> It is even possible to express (or enforce) that a one-for-one or a one-for-many relationship exists between the corresponding data elements. For example, a relationship may be built that enforces a one-for-one relationship between employee number and social security number. Another relationship may allow the same department number to be claimed for many different employees. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> Once a correspondence among data fields is established, useful information may be extracted drawing upon the collective set of tables. In the above example, a database designer may explicitly establish that the employee number field in the first table corresponds to the employee number field in the second table and that, where matching values are found in these two fields, the remainder of the fields in the associated records can be effectively joined to form a composite record. Thereafter, a report may be easily created listing the salary grades of the employees in a given department, despite the fact that the pieces of information are maintained in separate tables. Properly designed, this separation of data into related tables lends advantages in efficiency and flexibility as is well known in the field of relational database technology. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Combining table contents based on a correspondence among fields is referred to as a &ldquo;table join&rdquo; and is fairly easy to accomplish when the tables are maintained in a common file or are accessible by a common application or process. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> Beyond the realm of relating tables in a database, it is also necessary to cause data objects in a computing environment to be associated with one another in some fashion so that they can cooperatively provide a desired function. As is well known in computing science, an association among two data objects may be formed by, for example, having either or both of the objects contain a reference or handle or pointer to the other object. This tends to happen inherently where a first object causes the dynamic creation or &ldquo;instantiation&rdquo; of a second object. After the second object is created, the first object maintains a memory address for the newly-created second object for the purpose of subsequently accessing the data or invoking the methods of the second object and for ensuring that the second object is properly removed from the memory space when it is no longer needed. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> Associations among data entities, such as database tables or streamable data objects in a distributed computing environment, may also be formed and maintained externally without the associations being imbedded in the objects themselves. Externalized associations have been proposed whereby a first data object and a second data object may be associated by an external entity which maintains a reference to both objects and has a description of how the objects are related. This implies the use of an external association engine which must be involved whenever a computing task involves cooperation between the first data object and the second data object. In this approach, the first and second objects need not &ldquo;know&rdquo; about one another nor contain any provisions for pointing to one another. Indeed, the association among the first and second data objects may occur well after the objects have been designed and implemented. Associations may later be formed as needed, as in response to requirements that were not apparent at the time the data objects were initially implemented. Of course, this enables tremendous flexibility in the growth of a distributed computing environment. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In a large computing domain, such as a global enterprise or a government, data objects may be highly partitioned. To fulfill a needed function, an application may need to draw upon data and functionality from many sources that are separately maintained and often logically or geographically remote from one another. In fact, even a single data object, offering some particular useful functionality or a particular view of the global data, may itself be partitioned and distributed among many sources. In the context of highly-partitioned data, there is a desire to support the creation of such composite objects which transcend being located in any one data store. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> While an externalized association engine may at first be contemplated to fulfill this need, the aforementioned problems with centralization make the externalized association engine impractical for large scale implementations. Recall that the externalized association engine must support the interaction among objects, including the assembly of composite partitioned objects, for the entire computing environment. It is foreseen that even attempts to moderately distribute the function of a unified, externalized association engine will introduce difficulties and invite the potential for catastrophic failures. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Therefore, there is a need for a method and system which supports ubiquity of data access, subject to security constraints, of course, across a large enterprise wherein the data may be highly distributed and partitioned. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> Overall resources may be conserved and availability of data enhanced if the data store is allowed to remain naturally partitioned, with each portion of the data store maintained nearest the original source of the data or nearest the highest volume of interaction with the data. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> It is an important advantage of the present invention that an application needing access to data anywhere in the enterprise does not need to know where such data may be located. The application calls for the data without having to specify where to look. Furthermore, the data needed is readily accessed without undue delays, as if all of the data were local to the application. The mechanism taught by the present invention automatically handles the finding and retrieval of requested data without burdening the application. This readily-available and seemingly-ubiquitous access to the data at large has been referred to as a &ldquo;data dial tone&rdquo; by the present inventors, drawing an analogy to the ability of a telephone caller to place a call to anyone without knowing how the call will be routed nor even exactly where the call will be received. The term &ldquo;data layer&rdquo; has also been inspired to refer to this style of accessing the enterprise-wide collection of data without regard for location. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> A further advantage of the present invention is that, due to the manner in which associations are made and data objects are found, associations may transcend simple object-object linkages. Associations may be defined by &ldquo;fuzzy&rdquo; criteria and may cause useful information to be retrieved beyond what a requesting application would have known to explicitly ask for. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> In accordance with an exemplary embodiment of the present invention, association forming entities are a) maintained as objects in a like manner to the data objects being associated, and are b) themselves partitioned objects comprising two or more association fragments, each association fragment being mostly concerned with the interfaces to a particular data object participating in the association. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> In accordance with an exemplary embodiment of the present invention, each association fragment affiliated with a particular data object is stored in a location that enhances the ease of interaction between the association fragment and the data object. For example, where a first data object and second data object are maintained in data stores at some distance from one another, physically or logically, then a first association fragment will be located with or near to the first data object and a second association fragment will be located with or near the second data object, at least within the same partition. This arrangement may be preferable because the volume of interaction between a data object and its respective association fragment may far outweigh the interaction needed among the two association fragments. This arrangement may also be preferable as the volume of interaction between a client application and both the data object and respective association fragment may exceed the interaction needed among the two association fragments. Some interactions will employ only one of the association fragments with the net result being a reduction in communications requirements and an improvement in performance. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The present invention further provides for defining logical domains which are arbitrary and entirely orthogonal to partitions. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The novel features believed characteristic of the invention are set forth in the appended claims. The invention itself, however, as well as an exemplary mode of use, further objectives and advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawings, wherein: </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> The present invention is illustrated by way of example, and not by way of limitation, in the Figures of the accompanying drawings and in which like reference numerals indicate similar elements and in which: </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1A</cross-reference> depicts a point-to-point architecture where applications message one another directly according to prior art messaging techniques; </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a representative diagram of an application; </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a logical diagram of an enterprise network containing CORBA-enabled processes distributed in both domain <highlight><bold>1</bold></highlight> and domain <highlight><bold>2</bold></highlight>; </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a diagram representing independent systems&apos; stovepipe relationships as might be expected in a telecommunications enterprise according to the prior art; </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a diagram of the NewWave network management concept in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a diagram illustrating the concept of many, small generic servers in many geographic locations distributed for enterprise use in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a diagram illustrating various typical configurations of the small servers running various operating systems in which VM containers are running on host servers in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a conceptual diagram of distributive concepts for managing an ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a diagram of service platform infrastructure of interrelated services relating to an enterprise is illustrated in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10A</cross-reference> is a diagram depicting launching and registering service in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10B</cross-reference> is a diagram depicting finding and implementing a local service in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10C</cross-reference> is a diagram depicting finding and implementing a non-local service in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11A</cross-reference> is a flowchart depicting a process for launching and registering service in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11B</cross-reference> is a flowchart depicting a process for finding and implementing a local service in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11C</cross-reference> is a flowchart depicting a process for finding and implementing a non-local service in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12A</cross-reference> is a flowchart depicting the process employed by the registrar for registering services in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12B</cross-reference> is a flowchart depicting the process for enterprise leasing in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12C</cross-reference> is a flowchart depicting a process employed by the registrar for looking up a service in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> FIGS. <highlight><bold>13</bold></highlight>A-<highlight><bold>13</bold></highlight>B are flowcharts depicting the transaction process employed by the transaction manager is illustrated in accordance with a preferred embodiment of the present invention; </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a diagram depicting a service failure and re-homing the service to a different server and further depicting self-healing a proxy reference using a smart proxy in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention, and further illustrates self-healing a proxy reference using a smart proxy; </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15A</cross-reference> is a flowchart depicting a service restarting process in a global ecosystem of interrelated services in accordance with the present invention; </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15B</cross-reference> is a flowchart depicting a process se for self-healing stale references using a smart proxy in accordance with the present invention; </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a diagram depicting a conceptual realization of the DataBus two-tier infrastructure concept for mediating data transactions and an enterprise-wide data persistence layer which allows clients to access shared enterprise data in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17A</cross-reference> is a traditional representation of an E-R diagram; </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17B</cross-reference> is a representation of nodes and arcs of the E-R diagram being mapped onto entity engine processes and association engine processes; </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a diagram illustrating three entities, entity A <highlight><bold>1802</bold></highlight>, entity B <highlight><bold>1804</bold></highlight> and entity C <highlight><bold>1806</bold></highlight> partitioned in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is a diagram illustrating three container-database partition pair in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is a diagram depicting DataBus components necessary for creating an entity instance in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> is a flowchart depicting a process for creating an entity instance in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 22</cross-reference> is a diagram showing a read/write copy of the entity instance being streamed directly to the client in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> show the cache server approach where a copy of the entity instance is streamed to a cache server rather than the copy being directly steamed to the client in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 24</cross-reference> is a diagram showing the event notification approach where the client is using only read-only copies of the entity instance and receiving change notifications whenever an update is received in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 25</cross-reference>, on the other hand, the optimistic concurrency approach depicts the client using a read/write copy that must stay in sync with a master copy in order for updates to be accepted in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 26</cross-reference> is a diagram depicting DataBus components necessary for performing the multi-hop find process in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 27</cross-reference> is a flowchart depicting a multi-hop find process in accordance with exemplary of the present invention; </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 28</cross-reference> is a diagram representing a logical domain boundary defined from partitions in each of several entities in accordance with one embodiment of the present invention; </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 29</cross-reference> is a diagram of NW service platform infrastructure of interrelated services relating to an enterprise is illustrated in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 30</cross-reference> is a flowchart depicting a process for finding entity instances that are associated with an instance in accordance with exemplary of the present invention; </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 31</cross-reference> is a diagram showing external central association engine 3102 which consists of a plurality of link records which describe associative relationships between Customer entity instances and Account entity instances; </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 32</cross-reference> is a diagram of NW service platform infrastructure of interrelated services relating to an enterprise is illustrated in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 33</cross-reference> is a flowchart depicting a process for getting all accounts instances that are associated with an identified customer instance in accordance with an exemplary embodiment of the present invention; and </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 34</cross-reference> is a flowchart depicting a process for getting all accounts instances that are associated with an identified customer instance using smart proxies in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 35</cross-reference> is a diagram of the MOC and associated NewWave service necessary for collecting events into policy-based work documents, and then directly routing work to the best currently available operations staff that is automatically assembled based on the individual staff members&apos; aptitude for particular tasks in a process flow in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 36</cross-reference> is a functional diagram of the MOC depicting interactions between key MOC components interact in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 37</cross-reference> is a diagram of an assessor for assessing events based on organizational rules in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 38</cross-reference> is a diagram illustrating a basic design of an aggregator in accordance with an exemplary embodiment of the present invention; </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 39</cross-reference> is a diagram of a simplified version of a state machine in accordance with an exemplary embodiment of the present invention; and </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 40</cross-reference> which depicts a user avatar lookup in accordance with an exemplary embodiment of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> Other features of the present invention will be apparent from the accompanying drawings and from the detailed description which follows. </paragraph>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> The present invention relates to data processing. More particularly, the present invention relates to the management of information technologies. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> The automation of manual business processes was one of the first important tasks for which computers were employed. Prior to integrating the business processes in computer applications for execution on computer-implemented systems, business processes were typically segmented along departmental lines, so naturally the computer business process applications that automated those business processes were likewise segmented along departmental lines. The resulting computer-implemented applications/systems were characterized as having narrow scope, rarely doing little more than automating the same steps and procedures that comprised the manual business process. Because of a lack of interoperability, they seldom integrated with other systems which likewise made sharing resources impossible. Normally, this way of providing answers to an enterprise can only tailor the answer from the perspective of the department that manages the stovepipe. An enterprise answer, or a solution to an enterprise level problem, might require that an enterprise user access several, or even all departmental stovepipe applications for the departmental perspective view in order to get a &ldquo;piece&rdquo; of the entire enterprise level solution. It would then be left to the user to coalesce the departmental answers from the respective stovepipe applications into a unified enterprise level solution by integrating the disparate departmental perspective answers into an enterprise level solution. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> Currently, within enterprises exist many stovepipe applications that address and solve very narrow problems within departments. For example, human resources, finance, timekeeping and even resume-tracking applications within human resources are natural stovepipe applications that address particular problems within an enterprise. Moreover, vendors of specialized stovepipe applications often become extremely proficient at solving penumbra issues that cross enterprise boundaries and are adopted by widely-diverse enterprises. An enterprise might be thought of as consisting of having umbra and penumbra functions, umbra being methods, processes and the associated resources necessary for accomplishing core enterprise charter goals, and penumbra being methods, processes and the associated resources necessary for accomplishing and supporting the charter goals. Alternatively, an enterprise&apos;s core functions can be described as revenue centers, while support functions can be characterized as cost centers. Examples of umbra stovepipe applications include inventory control applications and sales tracking applications that exist within a sales organization; reservoir management applications, downhole logging applications and production and field control applications that exist within an oil production company; admissions and discharge applications, medical record keeping applications and laboratory applications that exist within a healthcare provider; and even legal instrument-drafting applications, docketing applications and litigation toolkit applications that exist within a law firm. These applications came about when traditional mainframe systems failed to solve individual departmental problems or, more likely, were not flexible enough to solve the problems in a timely fashion. Because of this failure, a &ldquo;departmentalized&rdquo; solution ensued and critical, mission-critical departments implemented their own systems. These systems owned, maintained and protected the applications, hardware and resources necessary to efficiently perform their missions, resulting in an enterprise made up of independent &ldquo;islands&rdquo; of special purpose applications, hardware and resources. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> Even though departments were protective toward their stovepipe systems, that did not mean that departmental users did not want to share information or resources with the remainder of the enterprise. Instead, it was merely indicative of the processes, data and resources existing within a single department. Incontrovertibly, this reality demonstrated that the enterprise parts, or departments, were automated without regard for the enterprise level needs. Information, process and resource sharing among enterprise departments were rarely considered when selecting a vendor&apos;s stovepipe application/system. As a result, there were no open application programming interfaces (APIs), open architectures, or other mechanisms that allowed for ready access to the processes and data existing within these stovepipe systems. In order to achieve acceptable results with a department&apos;s stovepipe system, an enterprise user had to be proficient with a department&apos;s stovepipe application, system and GUI, as well as understand how the application managed its resources. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> Traditional systems (also known as &ldquo;legacy systems&rdquo;) are applications that exist as stovepipes, such as departmental or vendor stovepipes, in a centralized enterprise environment. Mainframe-based systems make up a majority of traditional systems, while minicomputers and large UNIX-based systems might also be correctly referred to as traditional systems. The characteristics that define the traditional system include centralized processing, unshared resources and terminal-based access. Traditional systems typically support a large user and processing load on both database and business processes that exist together within the same environment. While these systems may support thousands of users concurrently accessing the same application, sharing processes and resources between applications is uncommon. Moreover, sharing processes and resources to applications outside the system is unheard of; however, simultaneous access to an application across a single platform is a powerful incentive for businesses. The total cost on ownership (TCO) for these systems is relatively low when compared to PCs and workstations. Therefore, rather than becoming extinct, these systems not only continue to sell, but older applications leveraging traditional systems have demonstrated significantly more staying power than originally anticipated. The prior art&apos;s answer to the shortcomings of stovepipe applications was to implement Enterprise Application Integration (EAI) between stovepipe applications. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> In general, applications serve two primary purposes: (1) they perform routine business processes that support a business function; and (2) they access, process, and/or display data. At the highest level of abstraction, applications can be organized by the functions they perform and the data they process. EAI, in its most idealistic form, involves the unrestricted sharing of business processes throughout an enterprise&apos;s networked applications or data sources. Software programs in areas such as inventory control, human resources, sales automation and database management which were custom built in the technology of the day were designed to run independently for addressing a specific need and do not share. Many times the applications were implemented as proprietary systems, with no interaction between the systems and thus did not share. EAI&apos;s popularity can be attributed, in part, to the need for maintaining the older stovepipe applications, while simultaneously integrating them within a new enterprise application infrastructure. As the enterprises grow and recognize the need for their information and applications to have the ability to be transferred across and shared between systems, companies invest in EAI in order to streamline processes and keep all the elements of the enterprise interconnected. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> The focus of EAI is primarily directed into four major categories: database linking, application linking, data warehousing and virtual systems approach. Database linking involves implementing EAIs between departmental databases for sharing information with each other and duplicating information as needed based on a set of rules. Application linking involves the enterprise sharing business processes and data between two or more applications. Data warehousing involves data being extracted from a variety of resources (data sources) and compiled in a specific database for analysis. This unified collection of data better supports management decision making by allowing enterprise users to view resource data from a variety of stovepipes from an enterprise perspective. Data warehouses contain a wide variety of data that present a coherent picture of business conditions for the enterprise at a single point in time. The final category of EAI is a common virtual system which involves using EAI in all aspects of enterprise computing, tying applications, resources and data together so that they appear as a unified application to a client. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> EAI is often referred to as &ldquo;middleware&rdquo; because EAI software functions as a conversion or translation layer. It is also a consolidator and integrator. Custom-programmed middleware solutions have been developed for decades to enable one application to communicate with another that either runs on a different platform or comes from a different vendor or both. Middleware is software that translates commands or data between different software programs. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> EAI exists in two popular architectures, point-to-point and hub and spoke. Typically, point-to-point architectures are referred to as messaging EAIs, while hub and spoke architectures are referred to as middleware EAIs. Both variants allow existing enterprise applications to supply existing business processes and resources to other enterprise applications. With respect to the first type of architecture, point-to-point applications directly access data and resource data from other applications. <cross-reference target="DRAWINGS">FIG. 1A</cross-reference> depicts a point-to-point architecture where applications <highlight><bold>102</bold></highlight>-<highlight><bold>116</bold></highlight> message one another directly. Each enterprise application must be modified with a messaging agent, a queue and a relationship application table for listing other enterprise applications and the data and resources that they own. Java applications may require further modification with a multi-valued attribute, a &ldquo;codebase,&rdquo; for storing the location of the object&apos;s class definition. An application interacts with the messaging agent whenever the application determines that it needs access to data or resources that it does not own. The messaging agent accesses the relationship table for the location of an application that owns the needed resource. An initial request message is sent to the application that owns the resource for specific resource data. Here, several potential transitions may take place depending on the requestor application (e.g., temporary use of the resource, updating the resource, etc.) However, the resource owner application might be busy at the time the request is received, so the request is queued until the application is free to process the request. Once the response message is sent to the recipient, the recipient application might also be too busy to process the incoming message thread. In that case, the resource data in the response is also queued in anticipation of a processor freeing up and the process thread needing the resource being executed. At some point, the thread is executed in accordance with the application&apos;s processes. The messaging agent is responsible for the message and data integrity that it sends and/or receives, so if the transaction is not completed, the messaging agent must repeat the transaction. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> As can be understood from the foregoing, each application requires significant modifications for point-to-point EAI to be effective. If an enterprise application is upgraded, modified or even migrated to a different physical location, it and any application that it relies on, or that relies on it, must also be modified for subsequent point-to-point messaging transactions to be successful. In addition, each individual enterprise stovepipe application is a potential bottleneck as the individual applications are usually not scalable for messaging responses. Finally, inter-application messages can either be in the form of some proprietary messaging protocol or may, instead, take advantage of existing messaging protocols and messaging specification. If the enterprise utilizes proprietary messaging protocols, the protocol specification must be formalized within the enterprise and maintained and a corresponding message transport devised. If, on the other hand, existing protocols are to be used, then the enterprise&apos;s existing message transports that utilize those protocols will be called on for handling the added burden of the point-to-point messages. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> The second EAI architecture improves on existing point-to-point middleware by utilizing a message broker that manages communications among all enterprise stovepipe applications. The message broker communicates directly with each participating application and thus forms the &ldquo;hub&rdquo; of a hub and spoke messaging architecture. Message-broker processing is a mixture of schema and content transformation, rules processing, message splitting and combining, as well as message routing. Once the processing is complete, the information is sent to any target system that needs to receive that information using whatever native format the target application can understand (e.g., eXtensible Markup Language (XML), IDoc, Java Message Service (JMS) message, proprietary, etc.). </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1B</cross-reference> depicts a hub and spoke messaging architecture wherein messaging middleware <highlight><bold>140</bold></highlight> serves as a central point of communication between enterprise applications <highlight><bold>122</bold></highlight>-<highlight><bold>136</bold></highlight> for transferring messages between applications. Hub and spoke architecture has the advantage that the participating applications require somewhat less custom programming because messaging middleware <highlight><bold>140</bold></highlight> acts as a messaging broker for providing an interface between stovepipe applications, thus allowing them to asynchronously send data back and forth to each other. Data sent by one application is stored in a middleware queue and then forwarded to a receiving application when that application becomes available to process it. In addition to a transport means, the messaging broker provides stovepipe applications with distribution rules for forwarding messages and formatting rules for reformatting data from a sending application&apos;s format to a receiving application&apos;s format. A rules engine analyzes incoming messages and makes routing decisions, while a formatting engine converts the data into the structure required by the receiving application. The messaging broker provides disparate stovepipe applications with a common message transport and queuing system, thereby relieving applications from the responsibility of ensuring that the data sent is properly received. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> In practice, a messaging broker can be either a complete messaging system or software that works with existing messaging transports in order to add routing intelligence and data conversion capabilities. While the hub and spoke architecture represents a significant advancement over independent stovepipes and an improvement over point-to-point messaging, the hub-and-spoke EAI solution is resource-constrained because all the processing takes place on a single server. Eventually, the number of connected systems and the information traffic will saturate the available resources of the integration server (memory, processor, and disk) resulting in reduced performance. Bottlenecks can and do occur and scheduling can become problematic for enterprise applications. Moreover, once an application signals its intent to process resource data from the messaging queue in the hub, the messaging broker may be busy and thus unavailable to pass the necessary resource data to the requesting application prior to the receiving application timing out. In that case, the application thread is held up waiting for the resource data to arrive and might in fact timeout prior to the messaging broker responding to the application. If a timeout occurs, the resource data remains queued until the application is again freed up. Overloads on the messaging broker have led to the development of a &ldquo;federated architecture&rdquo; wherein the applications connect to a single integration server or hub statically and are able to exchange information with each other. This means that all information produced or consumed from a particular application is available only for processing within a particular hub. Since the hubs are interconnected, each hub appears to the other hubs as connected applications, thus producing and consuming messages. However, messages produced from a single application may process only on a single hub because they are statically bound to that hub. This architecture does not allow hubs to share the message-processing load, or nor does it allow other hubs to process messages from applications that are not directly connected. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> In general, applications serve two primary purposes: (1) they perform routine business functions that support a business process; and (2) they access, process, and/or display data. At the highest level of abstraction, applications can then be organized by the functions they perform and the data they process. A representative diagram of an application is depicted on <cross-reference target="DRAWINGS">FIG. 2</cross-reference> as any of applications <highlight><bold>202</bold></highlight>A-<highlight><bold>202</bold></highlight>N. Since an application is the building block of an information system, it can be expressed as a collection of software programs that execute user interface <highlight><bold>204</bold></highlight>A, business rules <highlight><bold>206</bold></highlight>A, and data access operations <highlight><bold>208</bold></highlight>A, all of which are necessary to execute a business process. Typically, application <highlight><bold>202</bold></highlight>A consists of a plurality of services that perform these operations. Services are any predefined, specialized results which are produced from specific software programs designed to perform explicit data processing operations when called upon. Services might be considered as either business logic services or infrastructure services. Business application services are designed and developed to provide specific computational, input/output, or data access operations when called upon at execution time, while infrastructure services provide computer platform operating systems, database management systems, or network platforms for supporting business applications. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> Returning to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, application <highlight><bold>202</bold></highlight>A uses business rules <highlight><bold>206</bold></highlight>A as a logical specification for the business&apos; requirements. Business rules <highlight><bold>206</bold></highlight>A define computational algorithms and operations to perform explicit data processing operations that are necessary to implement a business process. Also shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a logical representation of another prior art mechanism utilizing the aforementioned messaging architecture for handling stovepipe applications. Stovepipe applications <highlight><bold>202</bold></highlight>A-N are the defined logical layers that provide practical boundaries for physically segmenting the application into smaller, more manageable program segments. The interactions between logical layers of an application can be accomplished through messaging and middleware services as described above. The logical layers of an application are defined as a user interface layer, a business logic layer and a data access layer. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> The user interface layer of an application interacts directly with end-user input/output devices (e.g., Windows workstations or a printer/fax device). The user interface layer is the most visible aspect of the business process supporting the end user. It encompasses a variety of operations, such as window or screen management, keyboard and mouse handling, end-user help functions, general input editing and data type validation, or formatting data for output to a laser printer or plotter device. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> The business process (logic) layer of an application implements the particular requirements of a business process based on a set of business rules. The business rules may be no more than developer guidelines, but more often are generic algorithms that can be tailored to a business&apos; needs by the user selection of values for parametric constraint variables. Typical operations at this layer consist of controlling the logical flow of interaction between the end user (via the user interface layer), access and manipulation of data or information (via the data access layer), and specific computational algorithms to be performed (via the business logic layer). </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> Finally, the data access of an application includes the operations needed to store, access and maintain data or information necessary to support a business process. The data accessed within this layer can include both structured and unstructured formats, depending upon the application requirements. For the most part, a commercial relational database management (RDBMS), or proprietary file access system, provides the services performed within this layer. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> The division of applications A-N into logical layers and the inherent physical program design characteristics necessitate services that enable communication between logical and physical layers via messaging services and data access middleware and operate fundamentally as described above. The intent of the logical layer concept is to stratify applications by their analogous functional levels while maintaining the unique character of each application A-N. Application management becomes more of a concern because the natural tendency of programmers is to offload processing tasks to other, more capable applications while focusing their efforts on the core functional aspects of an application. This distributed concept tends to centralize certain services at key applications. Failures and modifications of those key applications can result in disastrous effects across the enterprise. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> Separating an application into discrete layers permits application services to be scaled and positioned where appropriate and reduces the complexity inherent in single-platform solutions. Specialized application components can be combined to achieve the best results, and similarly, different combinations of clients and servers allow for a computing fix to these specialized application components. However, the layered application approach suffers from all of the above-described shortcomings attributable to the messaging and middleware EAIs. The user interface and business process application levels must be internally modified for messaging interfaces, user interface messaging interface <highlight><bold>220</bold></highlight>, and business process messaging interface <highlight><bold>222</bold></highlight> for communications between the respective application levels, while data resources are handled by a completely different architecture. Data, while being accessible to any application within the enterprise, is still owned by a single application. Resource access bottlenecks become more prevalent at the enterprise level so data access middleware <highlight><bold>224</bold></highlight>A-<highlight><bold>224</bold></highlight>N is regularly configured as federated architectures. In short, while the layered application concept somewhat distributes services in layers across an enterprise, the stovepipe application structure is maintained because each application remains responsible for providing its own necessary services and managing its own resources and data. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> Another prior art means for sharing services between applications is through the use of distributed object systems such as Common Object Request Broker Architecture (CORBA)-enabled processes. CORBA-enabled processes can be placed and run on the same machine or on any machine in a network enterprise differing from messaging middleware in that they cause processes (components/objects) to be executed in real-time rather than sending data. Examples of these CORBA applications and other similar distributed object systems include System Object Model (SOM) and Distributed System Object Model (DSOM) from IBM Corporation, One New Orchard Road, Armonk, N.Y. 10504; or Component Object Model (COM) and Distributed Component Object Model (DCOM) from Microsoft Corporation, One Microsoft Way, Redmond, Wash. 98052. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> CORBA provides a way to execute programs (objects) written in different programming languages running on different platforms no matter where they reside in the network using an &ldquo;object bus&rdquo; or &ldquo;software bus,&rdquo; a software-based communications interface through which objects are located and accessed. Objects reside on various machines throughout the distributed environment and are tasked with performing duties defined by their implementation. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a logical diagram of an enterprise network containing CORBA-enabled processes distributed in both domain <highlight><bold>1</bold></highlight> and domain <highlight><bold>2</bold></highlight>. CORBA objects are defined by an Interface Definition Language (IDL) that describes the processing (methods) the object performs and the format of the data sent and returned. IDL definitions are stored in an interface repository (not shown) which can be queried by client application <highlight><bold>312</bold></highlight> to determine what objects are available on the bus. However, unlike such standard servers, objects have the ability to move around if needed. A client communicates with an object through an object reference. This is a pointer to the object that allows requests for operations and data access to be sent from the client to the server via an object request broker (ORB). In the Figure, the ORB is depicted as client ORB <highlight><bold>316</bold></highlight> and server ORB <highlight><bold>322</bold></highlight>, but could be conceptually represented as an ORB bus between client <highlight><bold>310</bold></highlight> and server <highlight><bold>320</bold></highlight> and connected to a plurality of objects (or object implementation). At runtime, CORBA client <highlight><bold>310</bold></highlight> makes requests to remote CORBA object <highlight><bold>328</bold></highlight> via an ORB <highlight><bold>316</bold></highlight>. ORB <highlight><bold>316</bold></highlight> provides a proxy object in the client&apos;s address space which creates the illusion that remote object <highlight><bold>328</bold></highlight> is a local service or process. ORBs <highlight><bold>316</bold></highlight> and <highlight><bold>322</bold></highlight> manage the interactions between client <highlight><bold>310</bold></highlight> and object implementation <highlight><bold>328</bold></highlight>. Client <highlight><bold>310</bold></highlight> issues a request and invokes methods of object implementations. Client <highlight><bold>310</bold></highlight> and server <highlight><bold>320</bold></highlight> communicate by exchanging messages defined by the General Inter-ORB Protocol (GIOP). When client <highlight><bold>310</bold></highlight> calls a CORBA operation, client ORB <highlight><bold>316</bold></highlight> sends a GIOP message to server <highlight><bold>320</bold></highlight>. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> The client-side architecture provides client <highlight><bold>310</bold></highlight> with interfaces to ORB <highlight><bold>316</bold></highlight> and object implementations. A dynamic invocation (not shown) allows for the specification of requests at runtime whenever the object interface is not known at runtime and utilizes the interface repository. Each CORBA implementation comes with one or more IDL compilers (not shown) that know the language mapping for the language in which they were designed (i.e., that used by client application <highlight><bold>312</bold></highlight>). It is the IDL compiler&apos;s job to turn the IDL into stub and skeleton files <highlight><bold>314</bold></highlight> and <highlight><bold>326</bold></highlight>, respectively. These files are used in distributed applications to make object communication almost transparent. Stubs and skeletons are all language- and ORB-dependent so the same IDL file is used to generate the stubs and skeletons for each language and ORB implementation. IDL stub <highlight><bold>314</bold></highlight> is used in client processes to communicate with server <highlight><bold>320</bold></highlight>. Stub files <highlight><bold>214</bold></highlight> consists of functions generated by the IDL interface definitions and linked into client application <highlight><bold>312</bold></highlight> for a mapping between client application <highlight><bold>312</bold></highlight> and ORB <highlight><bold>316</bold></highlight>. Client application <highlight><bold>312</bold></highlight> uses stub <highlight><bold>314</bold></highlight> to make calls to the server objects. Functions needed by client <highlight><bold>312</bold></highlight> are called just as if they were local objects. However, stub object acts only as a proxy that forwards requests to and responses from a CORBA process on a remote server. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> The implementation-side interface consists of server ORB <highlight><bold>322</bold></highlight>, IDL skeleton files <highlight><bold>326</bold></highlight> and object adapter <highlight><bold>324</bold></highlight>. Skeleton files <highlight><bold>326</bold></highlight> are the converse of stub files <highlight><bold>312</bold></highlight>. They are what the server-side applications use to seamlessly receive distributed requests. It is the skeleton&apos;s job to receive requests from ORB <highlight><bold>322</bold></highlight>, call the proper implementation, which in this case is object implementation <highlight><bold>328</bold></highlight>, and return the results. ORB <highlight><bold>322</bold></highlight> calls method skeletons to invoke the methods that were requested from client application <highlight><bold>312</bold></highlight>. Object adapter <highlight><bold>324</bold></highlight> provides the means by which object implementation <highlight><bold>328</bold></highlight> accesses most ORB services. Object adapter <highlight><bold>324</bold></highlight> isolates object implementation <highlight><bold>328</bold></highlight> from ORB <highlight><bold>322</bold></highlight>. A server may have a variety of object adapter types, each providing specific services. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> In short, client application <highlight><bold>312</bold></highlight> connects directly to ORB <highlight><bold>316</bold></highlight> through its stub <highlight><bold>314</bold></highlight>. Object implementation <highlight><bold>328</bold></highlight> on server <highlight><bold>320</bold></highlight> connects directly to object adapter <highlight><bold>324</bold></highlight> through skeleton files <highlight><bold>326</bold></highlight>. Object adapter <highlight><bold>324</bold></highlight> then connects to server ORB <highlight><bold>322</bold></highlight>. A request from client application <highlight><bold>312</bold></highlight> is next sent through client stub <highlight><bold>314</bold></highlight>, across ORBs <highlight><bold>316</bold></highlight> and <highlight><bold>322</bold></highlight> to the proper object adapter and through server <highlight><bold>320</bold></highlight>&apos;s object adapter <highlight><bold>324</bold></highlight> and skeleton files <highlight><bold>326</bold></highlight>, eventually reaching implementation <highlight><bold>328</bold></highlight>. The return value of the implementation follows the same route in reverse. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> Every object on the ORB has an Interoperable Object Reference (IOR) which is a global identifier string that identifies the machine on which its associated object is located and the interface that the object supports. It has encapsulated the IP, PID and other values required by the client to connect. Client <highlight><bold>310</bold></highlight> can use IOR for an object and standard function calls on ORB <highlight><bold>316</bold></highlight> to find an object reference. Client ORB <highlight><bold>316</bold></highlight> uses the IOR to determine what type of object is being referenced and the identity of the server for routing requests. In single machine domains, the client can write its own IOR to a file and get all server objects on the ORB since the ORB stays within the domain of the client machine. The client could then read the IOR from this file and have the ORB resolve it into an object reference. However, when the server object is in a different domain from that of the client machine, the client must receive a reference to the object from an independent service. Usually, this is accomplished by writing server <highlight><bold>320</bold></highlight>&apos;s IOR to a Server IOR File and placing it in a well-known location, using http, shared file system or ftp. At start up, client <highlight><bold>310</bold></highlight> merely accesses the file system for the server&apos;s IOR. This method for bootstrapping, although simple to understand and test, has several disadvantages, notably the need for the client and the server to share access to a file system. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> Another method for locating an object server is for the enterprise to employ naming service <highlight><bold>302</bold></highlight>. Naming service <highlight><bold>302</bold></highlight> uses a standard CORBA object which contains operations that bind, resolve, and unbind human-readable names with an IOR. When a service object is created, it binds its IOR with a name in naming service <highlight><bold>302</bold></highlight>. By looking up the associated name, any other object on the ORB, or with access to the naming service, can retrieve that object reference from the naming service server. Client application <highlight><bold>312</bold></highlight>, needing a connection to server <highlight><bold>320</bold></highlight>, merely retrieves a reference to naming service <highlight><bold>302</bold></highlight> and accesses server <highlight><bold>320</bold></highlight>&apos;s IOR by the server&apos;s name. Then, server <highlight><bold>320</bold></highlight>&apos;s IOR is resolved into the identity of the server for routing requests. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> A stovepipe application is a stand-alone program. It implies an application that does not integrate with or share data or resources with other applications. Many current systems have been built as &ldquo;stovepipe&rdquo; applications, meaning that they do not communicate easily with other enterprise systems. Moreover, these stovepipe applications form their own system &ldquo;islands&rdquo; with their own hardware platforms, development languages, protocols and resources (e.g., rules, databases, etc.) Corporations are demanding new systems changes at an astounding rate, and unfortunately, these old legacy systems do not adapt well to change. A telecommunications company, for example, might have had separate systems for plain-old telephone service (POTS) customers, inter-exchange carrier (IXC) customers and wireless customers. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a diagram representing independent systems&apos; stovepipe relationships as might be expected in a telecommunications enterprise according to the prior art. Current day &ldquo;independent systems&apos;&rdquo; stovepipes are represented in the Figure as stovepipes A-N. Telecommunications enterprises implement specific telecommunications systems in a effort to provide their customers with profit-generating services. The telecommunications services provided to the enterprise&apos;s customers are represented in the Figure as Digital Subscriber Line service (DSL <highlight><bold>410</bold></highlight>A), Asynchronous Transfer Mode network services (ATM <highlight><bold>410</bold></highlight>B<highlight><bold>1</bold></highlight> and <highlight><bold>410</bold></highlight>B<highlight><bold>2</bold></highlight>), Synchronous Optical NETwork (SONET) fiber-optic transmission system services (vendor &ldquo;A&rdquo; <highlight><bold>410</bold></highlight>C and vendor &ldquo;B&rdquo; <highlight><bold>410</bold></highlight>D), and Internet Protocol services (IP). As will be understood from the figure, each of the enterprise&apos;s services <highlight><bold>410</bold></highlight>A-<highlight><bold>410</bold></highlight>N must be managed by its own specialized management applications, represented in the Figure as management applications <highlight><bold>408</bold></highlight>A to <highlight><bold>408</bold></highlight>N. The combination of the services and management applications define the enterprise&apos;s profit centers. While many of the management applications <highlight><bold>408</bold></highlight>A to <highlight><bold>408</bold></highlight>N may own services and/or resources identical to those owned by any of the other management applications in the enterprise, the enterprise&apos;s management applications are tightly coupled and therefore do not share services and resources. As discussed above, this happens because a particular management application, for instance management application <highlight><bold>408</bold></highlight>A, is developed for a unique enterprise service, which in this case is DSL <highlight><bold>410</bold></highlight>A, without any thought of sharing the application&apos;s resources and services with any other management application within the enterprise. Other enterprise management applications were developed for enterprise systems in a similar ad hoc fashion. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> Each of management applications <highlight><bold>408</bold></highlight>A-<highlight><bold>408</bold></highlight>N performs specific management tasks associated with a corresponding service provided by the enterprise to its customers; however, rarely does a management application provide the services necessary to cost center applications (i.e., tracking and billing customers and accounts for the service usage). Therefore, in addition to developing a management application <highlight><bold>408</bold></highlight>A for specific enterprise services, it was often necessary for an enterprise to stovepipe a business application, represented in the Figure by business application <highlight><bold>406</bold></highlight>A, to the management application for providing cost center services and functionality not provided by the profit center application. The combination of corresponding independent cost center applications and profit center applications form independent systems&apos; stovepipe applications. Events and information are communicated between individual management and business application stovepipe systems using point-to-point messaging architectures as described above. However, each application owns the resources and data necessary to carry out its functionality. Application services are not shared between business and management applications but instead, data and events are merely passed up the stovepipe system. For the most part, information is transferred to and from an administrator working in Operations Center (Ops) <highlight><bold>404</bold></highlight>A on client <highlight><bold>402</bold></highlight>A through either business application <highlight><bold>406</bold></highlight>A or management application <highlight><bold>408</bold></highlight>A. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> Notice that the stovepipe systems for DSL <highlight><bold>410</bold></highlight>A and IP <highlight><bold>410</bold></highlight>N are fairly analogous and symmetric. However, as discussed above, in certain situations, EAI is possible between the business applications and the management applications. Notice, for instance, that the administrator on client <highlight><bold>402</bold></highlight>B may receive an integrated presentation from each of business applications <highlight><bold>406</bold></highlight>B and <highlight><bold>406</bold></highlight>C. Notice also that rather than business applications <highlight><bold>406</bold></highlight>B and <highlight><bold>406</bold></highlight>C being stovepiped directly to a separate management application, that each of business applications <highlight><bold>406</bold></highlight>B and <highlight><bold>406</bold></highlight>C communicate directly to each of management applications <highlight><bold>408</bold></highlight>B-D. This is possible through the use of enterprise application integration between independent stovepipe systems for similar enterprise services as management application <highlight><bold>408</bold></highlight>B handles a synchronous transfer mode routers through ATMs <highlight><bold>410</bold></highlight>B<highlight><bold>1</bold></highlight> and <highlight><bold>410</bold></highlight>B<highlight><bold>2</bold></highlight>, while management application <highlight><bold>408</bold></highlight>C manages a particular vendor&apos;s version of synchronous optical networks (SONET) and management application <highlight><bold>408</bold></highlight>E handles a second vendor&apos;s SONET <highlight><bold>410</bold></highlight>E. Here, rather than each management application having its own stovepipe business application, the enterprise is able to consolidate business applications from three independent stovepipe business applications to only two, <highlight><bold>406</bold></highlight>B and <highlight><bold>406</bold></highlight>C. Thus, the enterprises achieved processing and storage efficiency by handling only two independent stovepipes for the three management applications. Notice, however, that true resource integration has not been accomplished. In fact, the only point at which resource data is truly integrated is in the integrated presentation <highlight><bold>404</bold></highlight>B to client <highlight><bold>402</bold></highlight>B. Thus, while the enterprise has realized a certain amount of reduction in scale due to reducing the duplicative business application processes and resources, none of management applications <highlight><bold>408</bold></highlight>A to <highlight><bold>408</bold></highlight>E share any services or resources whatsoever. In fact, with regard to the telecommunications enterprise depicted in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, it should be apparent that the only true data integration occurs at the presentation level. For instance, by integrated presentation means <highlight><bold>404</bold></highlight>B for client <highlight><bold>402</bold></highlight>B. Thus, rather than applications <highlight><bold>406</bold></highlight>B and <highlight><bold>406</bold></highlight>C sharing resource data, the data is actually fed to integrated presentation means <highlight><bold>404</bold></highlight>B. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> From the representative stovepipe relationships in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, it is apparent that any of management applications <highlight><bold>408</bold></highlight>A to <highlight><bold>408</bold></highlight>N may have duplicative services from any of the other management applications, as none of the management applications communicate with one another, and instead communicate only along their own independent stovepipe lines. Those services would be under-utilized with respect to the enterprise and require that more enterprise resources be devoted for housing those services. The same is true of resources needed for the execution of the services within management applications <highlight><bold>408</bold></highlight>A to <highlight><bold>408</bold></highlight>N. While it is true that the various enterprise services <highlight><bold>410</bold></highlight>A to <highlight><bold>410</bold></highlight>N may require different resources be available to the management applications, it may also be true that various resources may be common among the various management applications. Network elements compound the stovepipe issue by requiring multiple control interfaces at the element. For example, Juniper routers require both Simple Network Management Protocol (SNMP) and XML to perform a full suite of network management functions. Therefore, the enterprise must again house and manage duplicative management resources only because the independent stovepipe systems&apos; own services, resources and data do not share with one another. </paragraph>
</section>
<section>
<heading lvl="1">NewWave Concepts </heading>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> NewWave (NW) network management is a next generation management concept that adapts the most advanced concepts from distributed computing to build a global application infrastructure. NW fuses virtual machine spontaneous networking, mobile code, directories, rules engines, and eXtended transAction (XA) transaction standards to deliver a fine-grained set of services on which management applications are re-engineered. NW leverages leading edge technologies for achieving a cross-domain technology management system which separates applications from technology. The individual stovepipe systems that evolved for network equipment, hosts and servers, and applications can all be integrated into a coherent management regime. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a diagram of the NW network management concept in accordance with an exemplary embodiment of the present invention. NW might be analogized to a schema for presenting services to a service user, such as client <highlight><bold>550</bold></highlight>. The term &ldquo;client&rdquo; will be understood to represent any consumer or user of a service, notably, many clients or other services, but may instead be any application, software module or tool that utilizes the processes of a service. NW network management service platform <highlight><bold>500</bold></highlight> (NewWave NM) is comprised of Global Information Bus <highlight><bold>510</bold></highlight> (GIB) is necessary to make services (along with the resources needed by the services) available to client <highlight><bold>550</bold></highlight>. DataBus <highlight><bold>520</bold></highlight> is a mechanism for decoupling data from the applications that have historically owned the data and make the data available to all authorized users, such as making all data in an enterprise owned by the enterprise and then available to all (authorized) enterprise uses. Finally, Management Operations Center <highlight><bold>530</bold></highlight> (MOC) utilizes service provided by both GIB <highlight><bold>510</bold></highlight> and DataBus <highlight><bold>520</bold></highlight> for monitoring and operating a network. NewWave NM service platform <highlight><bold>500</bold></highlight> itself consists of a group of NW infrastructure services and procedures necessary to support NW services. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> GIB <highlight><bold>510</bold></highlight> is best described as a global ecosystem of interrelated services. The GIB architecture is an infrastructure for deploying and managing individual services on a global scale. GIB <highlight><bold>510</bold></highlight> provides an infrastructure on which to build services that can run on many platforms. The physical infrastructure is high scalable allowing for new capacity to be easily added, almost invisibly, with a low cost-per-capacity. GIB <highlight><bold>510</bold></highlight> deployment infrastructure enables software distribution and service configuration and deployment to be accomplished without direct access to the physical servers within the enterprise. Distribution, configuration and deployment are centralized operations, but the effect to consumers is distributed. GIB <highlight><bold>510</bold></highlight> also utilizes a runtime infrastructure for distributed computing, including discovery of services, distributed transaction management and self-healing and also incorporates a management infrastructure for keeping the state of the ecosystem stable. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> Finally, GIB <highlight><bold>510</bold></highlight> includes a distributed communication infrastructure which supports multiple types of interaction between services. These interactions may be totally decoupled, message-based communication in which sender and receiver are unaware of the existence of the other, slightly coupled, wherein message-based communication in which the sender and receiver are aware of each other, but never gain direct access to each other. Also, GIB <highlight><bold>510</bold></highlight> distributed communication infrastructure supports generic coupling, event-based communication in which the receiver registers interest in certain events with the sender (the sender is physically coupled to the receiver, but does not know anything specific about it) and fully coupled, remote-procedure call communication in which the sender must find the receiver to make the call (GIB <highlight><bold>510</bold></highlight> also supports methodologies for finding each other). </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> DataBus <highlight><bold>520</bold></highlight> is a data management architecture for NW service platform <highlight><bold>500</bold></highlight>. It presents an architecture for creating a consistent, enterprise-wide data persistence layer which allows clients to access shared enterprise data. DataBus <highlight><bold>520</bold></highlight> achieves this enterprise-wide look by decoupling shared enterprise data from specific applications (breaking down the stovepipes) and opening up the data layer to across-the-enterprise access (given proper authorization). DataBus <highlight><bold>520</bold></highlight> architecture is designed from the ground up for global scalability and accommodation of evolving business data models in a highly-distributed physical deployment. Scaling is realized predominantly through the partitioning, while individual partitions are mapped to logical data domains that are defined along more relevant dimensions than entity-type dimensions (e.g, geography, line of business, etc.), and cut across traditional entity boundaries. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> MOC <highlight><bold>530</bold></highlight> is a set of NW-enabled services intended to provide support for addressing problems similar to those handled in a Network Operations Center (NOC), but not limited to only network problems. As such, it is intended to support problem management in many forms, including those typically handled by customer support centers and tactical assistance centers. MOC <highlight><bold>530</bold></highlight> represents a tool that assumes a fundamental re-engineering of the processes and tools used in these environments. MOC <highlight><bold>530</bold></highlight> is an example of the NW approach to designing and managing applications. Rather than building monolithic stovepipe application systems, the &ldquo;application&rdquo; is a collaboration of many smaller services acting on common objects, possibly without knowledge of each other, but with their actions affecting each other. MOC <highlight><bold>530</bold></highlight> makes extensive use of rules external to code executed by rules engines. These rules, being uncoupled from specific applications&apos; processes and code, can be presented in a more human-readable form. Additionally, novel uses of finite state-machines and logic gates are used to integrate information and provide behavioral responses to a follow of events and/or data. This allows for changing the system&apos;s behavior without changing the code. Those behaviors which represent organizational policy are removed into rules which can then be managed by experts in those organizations. Those rules which encode structural information can be managed, augmented and altered separate from the overall system&apos;s responses and actions. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> Fundamental to the concept is a behavioral approach to rules and application logic. Behavioral in this context means that &ldquo;events generate responses.&rdquo; Instead of elaborately designed processes and procedures, which must be successively decomposed into more and more refined detail, individual use cases are directly programmed (in isolation) using only their own context scope of applicability and the domain of their effect. This results in a bottom up aggregation of behavior from small to large (instead of from large to small). Change can proceed without overarching knowledge and with lessened effect on surrounding applications (increased isolation of design and development). This is achieved via re-use of common framework services with different procedural behaviors attached. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> NewWave NM service platform <highlight><bold>500</bold></highlight>, largely through the use of GIB infrastructure services <highlight><bold>510</bold></highlight>, spawns many small components (services and resources) that act largely independently of each other rather than a single monolithic application. These services may directly interact with shared resources by, for example, registering for notification of updates to shared resources. The small services find each other and communicate by using GIB infrastructure services <highlight><bold>510</bold></highlight>, (specifically registration and lookup services) and may also publish messages using the GIB&apos;s publish/subscribe services. In general, without directly modifying existing components, the overall behavior of any NW-supported architecture can be changed by adding new components. Sometimes this will be a whole new framework service, at other times a specialization of a common service with specific behavior and scope. Since all components, services in particular, are NW-enabled services utilizing registration, lookup and enterprise lookup services, new services, such as services <highlight><bold>540</bold></highlight>, can be added to NewWave NM service platform <highlight><bold>500</bold></highlight> from outside vendors and entrepreneurs. Moreover, because new added services <highlight><bold>540</bold></highlight> may unknowingly invoke existing enterprise cost center services, such as customer tracking and billing, vendor-supplied services provide a rich source of revenue for an enterprise without adding infrastructure normally associated with traditional stovepipe systems. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> The NW network management service platform relies on the ability to deploy services on many different platforms that run on many different server types. Java (a trademark of and available from Sun Micro Systems, Inc., Palo Alto, Calif.) is a programming language designed to generate applications that can run on all hardware platforms, small, medium and large, without modification and thus provide a means to develop on one platform, but deploy on many. In practice, the Java 2 platform (JDK 1.2) has been the basis for this multi-platform deployment, but one skilled in the art would readily recognize that other developer kits are available for specific platforms. The Java programming language allows developers of services to be unconcerned with the platform on which the service will be deployed. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> The NewWave architecture exists separate and apart from the Information Technology used to build the architecture. The architecture and design predate the selection of deployment technology. The reference application uses Java language and Jini distributed applications infrastructure, both Sun technology. There are many reasons why this technology is especially adapted to the NewWave architecture and its reliance on &ldquo;plug and play&rdquo; and code mobility. However, other systems can implement this architecture and several have been used in the Worldcom Lab including Sun JMX, IBM Aglets, IBM WebSphere EJB, and Objectstream Voyager products. Nevertheless, there are real and distinct synergies between design and the target implementation technology. Many aspects of NewWave would be much more laborious to achieve on technologies other than Java and Jini. Further, we expect application infrastructures to evolve and in a few years, better implementations technologies will arrive. NewWave anticipates these and expects to deploy on each successive wave of distributed computing that achieves product status. </paragraph>
</section>
<section>
<heading lvl="1">The Physical Machine Layer&mdash;Ubiquitous Server Machines </heading>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> The NW network management service platform is deployed on large numbers of small, rack-mounted servers of varying platforms. Some exemplary platforms include Solaris for Netra (available from Sun Microsystems, Inc.), IBM AIX (available from International Business Machines Corporation), HP UX all of which are UNIX-based platforms. UNIX is a trademark of the American Telephone and Telegraph Company Corporation of New York, N.Y. NT and Linix systems are also in use. The NW network management service platform could be deployed on larger servers as well. However, the cost of scale may go up with larger servers, as those physical boxes are on an entirely different cost curve. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> The NW physical environment consists of thousands of these small to medium size servers deployed throughout the physical boundaries of an enterprise. These servers could, in the case of a telecommunications enterprise, be deployed on the edges of the network in Point of Presence connections (POPs) as close to the user as possible and even on user premises in user enterprise domains. Data centers and major network hub intersections are also used in the physical deployment model. A NW-enabled server is configured with one of a small number of standard configurations. Standard configurations include generic servers with no special features, and resident application servers with Commercial Off the Shelf Technology (COTS). Resident servers in use include, but are not limited to: database servers with specific database products installed, directory servers with directory applications installed, security servers with security applications and rules servers with a rules engine installed. Basically, native services are relocatable and can migrate to any generic container. Integration with resident applications (each fixed to a specific server or servers) is achieved by representing the interface to the service a NewWave service. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a diagram illustrating the NW concept of many, small generic servers in many geographic locations distributed for enterprise use. For example, an exemplary territory is exhibited in the state of Virginia where three sites have been designated for the distribution of physical hardware denoted hereon in the Figure as geographic sites A, B and C. Each geographic site contains racks of physical hardware, racks <highlight><bold>1</bold></highlight>-<highlight><italic>n</italic></highlight>, including various servers <highlight><bold>604</bold></highlight>A-C available from a variety of original equipment manufacturers (OEMs). In accordance with the exemplary embodiment of the present invention, servers <highlight><bold>604</bold></highlight>A-C are not larger multi-processor servers, but instead are smaller rack-mounted servers which may support various platforms such as Solaris, IBMAIX, Windows NT, Linux, etc. However, larger servers can be easily configured in accordance with the exemplary embodiments. For instance, at location A, racks <highlight><bold>1</bold></highlight>-<highlight><italic>n</italic></highlight>, <highlight><bold>602</bold></highlight>A contain a plurality of servers <highlight><bold>604</bold></highlight>A. Each of servers <highlight><bold>604</bold></highlight>A may be from a single vendor or instead might be from multiple vendors. Associated with one or more of servers <highlight><bold>640</bold></highlight>A are particular resources managed by that particular server. For instance, databases <highlight><bold>610</bold></highlight>A are particular vendor&apos;s databases, while database <highlight><bold>612</bold></highlight>A is another vendor&apos;s database, each of which are managed by a server in a rack at location A. Another resource, which will be discussed in more detail below, is a rules engine <highlight><bold>614</bold></highlight>A which may also be managed by one or more servers <highlight><bold>604</bold></highlight>A. Notice that racks <highlight><bold>602</bold></highlight>B at geographic location B and <highlight><bold>602</bold></highlight>C at geographic location C are similarly configured as those at geographic location A, thereby having large numbers of small generic servers <highlight><bold>604</bold></highlight>B and <highlight><bold>604</bold></highlight>C, respectively. Similarly, some of servers <highlight><bold>604</bold></highlight>B and <highlight><bold>604</bold></highlight>C may host various vendor&apos;s data resources <highlight><bold>610</bold></highlight>B, <highlight><bold>610</bold></highlight>C or <highlight><bold>612</bold></highlight>B, along with the rules engines <highlight><bold>614</bold></highlight>B and <highlight><bold>614</bold></highlight>C. The importance of this concept is that any server in any geographic location can process any service needed by any client in any other geographic area. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> In its broadest sense, NewWave releases the application and the data from the physical server and also from the bounds of that single location. NewWave produces a global scale computing system where the telecommunications data network replaces the traditional computer backplane and the individual server and the containers on it substitute for each of the chips in a multi-processor enterprise system. Immense scalability is archived at greatly improved efficiency for organizations that require large scope business activities. </paragraph>
</section>
<section>
<heading lvl="1">The Virtual Machine Layer </heading>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> The operating system of each physical server is not used directly in the NW operating environment. Instead, each server must have the capability of running a platform-independent programming language virtual machine (VM) on top of the operating system that converts Java bytecode into machine language and executes it. The Java Virtual Machine (JAM) (a trademark of and available from Sun Microsystems, Inc.) is currently the most popular software that converts the Java intermediate language into machine language, but other vendors supply their own versions. For example, the Microsoft Virtual Machine (available from Microsoft Corporation in Redmond, Wash.) is also a Java interpreter. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> A VM is a multi-threaded processing environment that encapsulates all access to the underlying computing platform. As such, a Solaris Netra looks the same as a Windows NT to a process being executed by the VM. A VM is, in fact, a single computing process, but it supports the running of many &ldquo;mini&rdquo; processes (threads) within. Thus, the NW operating environment is actually thousands of VMS deployed on small physical server machines throughout the world. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> Other approaches to abstraction of the application environment from the underlying system were explored, most notably IBM&apos;s Aglets. Java and the DIV have provided the best platform to date. Other platforms used the VM approach in the past, most notable the IBM VM system and the Honeywell Multicast systems. In the future, NewWave expects to use other platforms as these reach the market and provide similar dynamics. </paragraph>
</section>
<section>
<heading lvl="1">Containers </heading>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> In the NW environment, services are remote processing entities that are managed remotely, configured remotely, load their code remotely, and found and communicated with remotely. To facilitate these requirements, the NW service platform includes a container technology for providing a runtime operating environment for services. At the heart of the container scheme is the concept of a generic service container&mdash;a CPU process into which arbitrary software services may be homed to a host server at runtime. Each VM runs a small set of code which identifies it as a VM container and makes the VM container able to be found and communicated with remotely. VM containers are realized as VM heavy-weight processes which are launched from boot scripts as the server is booted. VM service containers are the multi-threaded servers that provide a place in which multiple-service instances reside, each executing its own thread or threads of execution. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> A VM container is also a service itself. More correctly, a VM container may be thought of as a &ldquo;service container service running on a VM.&rdquo; The service provided by a VM container is the launching of other services within itself. It behaves much like the services it contains in the way it can be found remotely and communicated with. Thus, like any other service, a VM container must register itself with a domain registrar and/or enterprise repository to be visible in its home domain and with the enterprise repository to be visible to services across the enterprise. The registration and finding of services will be discussed in greater specificity below. The salient point is that, like services, VM containers can be found remotely from anywhere in the world and requests can be programmatically made of them. VM containers report their own statistics and can be asked to shut down. </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> The main difference between a VM container and all other services supported by the NW service platform is in how a VM container, or more properly, the container service, is launched. A VM container is launched from the operating system and not from within another container. It cannot be launched from a remote location programmatically according to the NW conventions. In a similar fashion as other services, containers are not intended to be launched by NW clients. Rather, conceptually it could be considered as an integral part of the operating environment and launched by one of the following means: </paragraph>
<paragraph id="P-0132" lvl="2"><number>&lsqb;0132&rsqb;</number> 1. manually, by telneting into the server and running a script; </paragraph>
<paragraph id="P-0133" lvl="2"><number>&lsqb;0133&rsqb;</number> 2. as part of the startup of the host server&apos;s operating system; </paragraph>
<paragraph id="P-0134" lvl="2"><number>&lsqb;0134&rsqb;</number> 3. using an operating system-specific scheduling mechanism, such as Unix crontab or Windows services; or </paragraph>
<paragraph id="P-0135" lvl="2"><number>&lsqb;0135&rsqb;</number> 4. using Remote Method Invocation (RMI) activation (a Java-specific remote procedural call that requires the RMI Daemon to be running), which itself would have to be started via operating system-specific means. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> Once running, a VM container must register itself to be visible to clients, services and administrators in the enterprise that may need the VM container for running a service. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> Although every VM container is truly generic in nature, a VM container runs a small set of code in which the VM container can designate itself as a particular type of container. Some containers might designate themselves for running essential NW infrastructure services or other enterprise services such as GIB, DataBus or MOC services, or perhaps the container designation may relate to the type of host server running the VM container. Designating a container as being of a particular type might also be based on the server resources available in a logical domain. Depending upon the total quantity of VM containers in a domain, their reliability and domain loading factors, an administrator can designate a pre-defined number of containers as being NW infrastructure-type, GIB infrastructure-type, and so on. The composition of VM container-type designations is based on the priority of the hosting center and intended to assure that VM containers are always available for crucial enterprise objectives, such as re-homing services that are essential to the enterprise. Therefore, key services, while they may run in a generic-type VM container, do not depend on a generic-type VM container being available for self-healing of dead or dying services because other VM containers have been pre-designated for restarting those services. Thus, in the case of an essential infrastructure service, or any service for that matter, a predetermined quantity of VM containers can be pre-designated for running only those essential infrastructure services (self-healing capabilities will be discussed in greater detail below). </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> A key technical aspect is the storage of the configuration of the system and the container off board of the system and the container. In NW systems, this occurs in the registry. This is implemented in this generation via Jini Lookup and Directory (LDAP) services. However, any abstract and external service can implement the off board registration. By being separate from the container, all or part of the configuration can be transferred efficiently to another container as needed. Enterprise wide operations can occur on the configuration, without reference to the physical/server location it describes. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> It should be understood at this point that a logical domain within the enterprise may be of at least two types&mdash;management and network&mdash;and these domain types are not necessarily synonymous. A management domain is generally defined from servers that are physically located at a physical hosting facility. On the other hand, a logical network domain is based on the transmission topology of a network defined around, for instance, a unicast or multicast routing table and may not be physically located at a single facility. Furthermore, some self-healing services use service lookup services that utilize management domains, while others use service lookup services that utilize network domains. Therefore, if the intent of the VM container is to designate itself as a type compatible with self-healing services, the VM container must ensure that it is listed in the lookup service being used by the particular self-healing service monitoring the services to be run by the VM container. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> With respect to still another criteria, a VM container can designate itself as a particular type of container based on the resources available from the host server running the container. Services must be run in a container, but some services need additional resources aside from the container, such as a particular type of database, rules engine, etc. A service provider must be apprised of the resources available at a server host before attempting to launch a service on a host that is not equipped to run the provider&apos;s service. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> Finally, a VM service container amounts to a heavyweight CPU process. Allowing service threads belonging to different service suppliers to coexist in the same process space is an open invitation to adverse interactions (e.g., modification of a non-final static variable used by both services). For the sake of isolation, each VM container is uniquely owned by a single service supplier business entity. While APIs might be used by a customer who supplies services to lease a service container, the container may also designate itself as a container type to be used by a particular supplier. In that way, only services supplied by a single-service supplier business entity will be able to run in a particular container. Thus, a VM container can be designated to services supplied by a particular supplier. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> Note that domain registrar and/or enterprise registry are not the only means for finding a handle to a service container. Another option is to register the service containers within RMI registry. The URL address for connecting to a specific service container (e.g., &ldquo;rmi://lambic.wcomnet.corn/serviceContainer13/&rdquo;) is stored within the inventory database. A service supplier would query the inventory database for the URL address and then perform a conventional RMI lookup against that URL address. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a diagram illustrating various typical configurations of the small servers running various operating systems in which VM containers are running on host servers in accordance with an exemplary embodiment of the present invention. Here, four servers <highlight><bold>702</bold></highlight>A, B, C and N are shown, each having a unique operating system platform such as operating systems A, B, C and N. Running on each of servers <highlight><bold>702</bold></highlight>A to N are one or more generic VM containers <highlight><bold>704</bold></highlight>. Every CPU host in an enterprise hosting facility will run at least one VM container processes such as servers <highlight><bold>702</bold></highlight>N and <highlight><bold>702</bold></highlight>A). Service deployers may inject the code for their services at any one of the VM containers. As can be seen from the Figure, it is expected that the VM containers <highlight><bold>704</bold></highlight> are multi-threaded, multi-tasked containers allowing for the concurrent execution of various services <highlight><bold>706</bold></highlight> on each container <highlight><bold>704</bold></highlight>. Further, each server platform <highlight><bold>7021</bold></highlight>A-N may run multiple VM containers <highlight><bold>712</bold></highlight>. </paragraph>
</section>
<section>
<heading lvl="1">High Level Overview of the NewWave Platform </heading>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> With respect to <cross-reference target="DRAWINGS">FIG. 8, a</cross-reference> conceptual diagram of NW distributive concepts is illustrated in accordance with an exemplary embodiment of the present invention. General Information Bus (GIB), also called the Global Information Bus (GIB), <highlight><bold>802</bold></highlight> can be conceptually described as an information bus containing NW-enabled services and mobile applications available for use by clients as needed. Essentially, the GIB is a set of specific, yet extensible, Framework Services, implemented on a scoped (local, regional, global) distributed computing infrastructure. </paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> The heart of GIB <highlight><bold>802</bold></highlight> is the manner in which it allows deployment of services into the operating environment in a very flexible and easy-to-administer manner. GIB <highlight><bold>802</bold></highlight> is a series of services that may change from one execution to another, finding and collaborating with other services dynamically. This system of collaborating services starts to resemble an ecosystem, and the job of the GIB architecture is to maintain the interconnectedness and stability of this ecosystem as it continually changes. Almost all GIB components are implemented as services, even if they support no externally-available requests because all components must support certain administrative requests mandated by the NW. The administration and management of the ecosystem depends upon this capability. Although the component is acting as a service in the traditional sense of the word, it is deployed as a service. For this reason, even though GIB components come in many different flavors, at one level they all appear as services and follow many of the same conventions. The different flavors include the following and are depicted in the Figure below: </paragraph>
<paragraph id="P-0146" lvl="2"><number>&lsqb;0146&rsqb;</number> services that are part of the GIB infrastructure; </paragraph>
<paragraph id="P-0147" lvl="2"><number>&lsqb;0147&rsqb;</number> services that are parts of applications; </paragraph>
<paragraph id="P-0148" lvl="2"><number>&lsqb;0148&rsqb;</number> services that provide access to persistent DataBus objects; and </paragraph>
<paragraph id="P-0149" lvl="2"><number>&lsqb;0149&rsqb;</number> services that act as agents representing external entities such as devices, gateways to external (non-GIB) systems and even people, or are built directly into devices. </paragraph>
</section>
<section>
<heading lvl="1">Services </heading>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> All services must conform to certain conventions to be a well-behaved service. These include the following: </paragraph>
<paragraph id="P-0151" lvl="2"><number>&lsqb;0151&rsqb;</number> a service must exhibit the greatest degree of mobility possible; </paragraph>
<paragraph id="P-0152" lvl="2"><number>&lsqb;0152&rsqb;</number> a service must discover and register with all local registrars, renewing its own registration lease; </paragraph>
<paragraph id="P-0153" lvl="2"><number>&lsqb;0153&rsqb;</number> a service should register with a proxy which can handle simple loss of connection to the service, re-finding the service and continuing processing without interruption; </paragraph>
<paragraph id="P-0154" lvl="2"><number>&lsqb;0154&rsqb;</number> a service must implement certain management-related requests, including ping( ), healthCheck( ), shutdown( ), quiesce( ), reset( ); and </paragraph>
<paragraph id="P-0155" lvl="2"><number>&lsqb;0155&rsqb;</number> a service must accept requests for notification of events, and notify listeners, at a minimum, of certain administrative events; additionally, the service could define other types of events. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> To the greatest extent possible, a service must be mobile, which is the single most important characteristic of a service. This is to say that there are as few restrictions as possible to the deployment of a service on any machine anywhere as quickly as possible without human intervention. The limitations of this goal are primarily the provisioning of a service by: </paragraph>
<paragraph id="P-0157" lvl="2"><number>&lsqb;0157&rsqb;</number> installing software needed for the service to run; </paragraph>
<paragraph id="P-0158" lvl="2"><number>&lsqb;0158&rsqb;</number> establishing local configuration parameters; </paragraph>
<paragraph id="P-0159" lvl="2"><number>&lsqb;0159&rsqb;</number> installing resources upon which the service depends; and </paragraph>
<paragraph id="P-0160" lvl="2"><number>&lsqb;0160&rsqb;</number> performing the actual launching of the service on a particular machine (requiring human intervention or establishing scheduling options on the machine running the service). </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> Services in the NW environment must overcome these limitations. As such, NW services must be able to be launched on a server without any code specific to the service and without any configuration information being pre-installed on the server. All resources used by the service, if possible, must be able to be remotely accessed and not depend upon the resource being present on the local machine. Databases used by NW services must be able to be created on the fly by the service. So, while a service might depend on the existence of a local database server, it cannot depend on that database having been configured to have certain tables. It must be able to create the tables from a schema which is remotely loadable and to populate the database from remote sources. If the data cannot be remotely loaded, then the database must have a mirror copy which the service can re-home to. Finally, a NW service must be able to be launched on a server without a human logging onto the server to initiate the launch and, in the event of a failure, a service must be able to be re-homed at runtime from one server to another without human intervention. </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> The NW infrastructure provides an operating environment for services which is similar to the public Internet or an intranet. Instead of many client machines, the NW service platform is deployed on large numbers of small, rack-mounted servers. Instead of web browsers running Virtual Machines, there are VM containers, and instead of running applets in the web browser VM, there are services running in container VMs. When an applet is launched from a web page, it has a &ldquo;codebase&rdquo; identifying the location of the class files (server) that need to be loaded before the applet can run. In the NW infrastructure, each service has a codebase identifying from where its class files should be loaded from. To create this environment, the NW service platform deploys many HyperText Transport Protocol (HTTP) servers in place to serve up code, that is, Java class files and resources. The class files and resources are installed on the HTTP servers. An HTTP server which is employed to serve up code is called a &ldquo;code server.&rdquo;</paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> When a service is launched in a VM container, the container is provided with certain configuration information, including the service&apos;s codebase. The codebase contains the address(es) (usually URL(s), but it could be URI(s)) of the code servers which are able to serve up the service&apos;s code. So, when the service is launched, its code is loaded from a remotely-located code server. As services are generally long-running, code located remotely, even if it is a large amount of code, is a reasonable cost. Additionally, caching techniques are used to locally store the class files, checking each time to ensure that they have not been modified on the code server. In this way, installing a new version of a service&apos;s classes does not involve any type of software distribution technique involving the servers on which the services will run. Instead, it involves only pushing the new software out to the HTTP servers, which is a much more manageable task. </paragraph>
<paragraph id="P-0164" lvl="0"><number>&lsqb;0164&rsqb;</number> Consumers of services must run software that is consistent with the service. Whenever a service is used, there is a piece of code, the proxy, which is used to access the service. The proxy is referred to herein as a client proxy, proxy object and service object alternatively and will be more fully described below. In some environments, notably the CORBA environment described above, the proxy is the Achilles&apos; heel to software distribution. However, in the NW environment, the proxy is also remotely downloaded. When a proxy is registered with an enterprise registrar, it too is given a codebase from which any client using the proxy should load the code. In this way, the client and the service always use consistent copies of the service and the proxy. In implementation, the Java Jini proxy is used with specific semantics and augmentation for NewWave service inter-working. </paragraph>
<paragraph id="P-0165" lvl="0"><number>&lsqb;0165&rsqb;</number> Regardless, a client must have initially loaded an &ldquo;interface&rdquo; for interacting with the proxy. This code also must be consistent with the interface presented by the service. One solution is to launch client applications that use NW services with a similar remote loading approach. Specifically, an &ldquo;Application Launcher&rdquo; that launches an application using a specified remote codebase. One such application launching tool is Web Start (available from Sun Microsystems, Inc.). </paragraph>
<paragraph id="P-0166" lvl="0"><number>&lsqb;0166&rsqb;</number> A service must be mobile from the point of view of class and resource files, as well as from the point of view of configuration information. Configuration information, like class and resource files, cannot be tied to a specific machine. To accomplish this, configuration information is made available at the enterprise level, thus NW services can be launched using configuration information that is not local to the service. As will be more fully described below, all configuration information is stored in an enterprise level repository (the enterprise repository) and then replicated to identical repositories throughout the geographic extent of the enterprise. Application launchers access the configuration information in the repository, and then forward the configuration information to the VM container selected for running the service. The information includes both configuration information needed by the container to launch the service and information needed by the service itself. </paragraph>
<paragraph id="P-0167" lvl="0"><number>&lsqb;0167&rsqb;</number> The NW infrastructure provides for remotely-located resources. Reference files and other resources used by a service are remotely loaded at runtime using the same techniques described above used for class loading. These resources may include EXtensible Markup Language (XML) files, properties files, images and the like. These resources are installed on the HTTP code servers in a similar manner as the class files. However, some services that use a resource require a local resource to be local, therefore the local resource must be provisioned automatically to accommodate the reference files and other resources that will be loaded remotely at runtime. For example, a service that uses a database locally, must be able to start with a completely empty database, and then add the necessary database tables, remotely and on the fly. However, the local resource must be prepared for the remotely-loaded tables with suitable database definitions for the structure and the type of contents that each data element that the local resource can contain (i.e., the database schema). An HTTP server could be used for storing schema information in a similar fashion as the resources and code files. Another solution is to use an enterprise level directory that is visible to all services. The schema information can then be remotely loaded from the enterprise directory, after which the source data for populating the newly-defined tables is loaded from a remotely-located HTTP server. </paragraph>
<paragraph id="P-0168" lvl="0"><number>&lsqb;0168&rsqb;</number> Returning to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, the functionality of GIB <highlight><bold>802</bold></highlight> requires certain services to be available for all other services. These services are generally referred to as GIB infrastructure services including registrar, enterprise repository and lookup services <highlight><bold>804</bold></highlight>; distributed transaction services and semantics <highlight><bold>806</bold></highlight>; policy rule services <highlight><bold>808</bold></highlight>; messaging and publication subscription services <highlight><bold>814</bold></highlight>; rendezvous services <highlight><bold>812</bold></highlight>; and self-management services <highlight><bold>812</bold></highlight>. The GIB is designed to be extensible, and additional framework services are continuously being defined; these incorporate seamlessly. Enterprise repository and lookup services <highlight><bold>804</bold></highlight> provide a means for client to locate a needed service without knowing where that service is currently running. Whenever a service is launched in a container, that service registers itself with its domain registrar in order to make itself visible to the client in its own domain. A service registered with a domain registrar is visible only in the domain the service is running, so in order for a service to be visible to all clients in the enterprise, a service must register with an enterprise level registry, the enterprise repository. Clients needing a particular service do not need to know where the service is running or even if the service is available in the client&apos;s own domain. Instead the client merely looks the service up with the registrar. If the needed service is not listed in the registrar, the client can be directed to a enterprise repository lookup for the location of an enterprise repository within the enterprise. Registrar, enterprise repository and lookup services <highlight><bold>804</bold></highlight> also manage VM container leases. These and other functions of registrar, enterprise repository and lookup services <highlight><bold>804</bold></highlight> will be described in more detail below. </paragraph>
<paragraph id="P-0169" lvl="0"><number>&lsqb;0169&rsqb;</number> Distributed transaction services and semantics <highlight><bold>806</bold></highlight> manage transactions between the NW services running in the enterprise, with distributed transaction coordination and without the heavy, monolithic character of traditional Transaction Processing (TP) monitors. Distributed transaction services and semantics <highlight><bold>806</bold></highlight> ensure that processes which need transactional atomicity (several operations complete in their entirety or not at all) can get it. The transaction manager oversees a two-phase commit protocol to coordinate the commit of all containers and association engines that joined the transaction. </paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> Policy rule services <highlight><bold>808</bold></highlight>, or behavior services, are employed by GIB <highlight><bold>802</bold></highlight> for applying policy outside of the normal flow of processing logic to interactions between services. This is accomplished through the use of rules engines that allow the specification of policy-based rules outside of the processing logic. This allows organizations knowledgeable of operations support, instead of programming organizations, to be in control of the behaviors implementing operations support policy. </paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> NW messaging and publication subscription services <highlight><bold>814</bold></highlight> provide NW components the means for communicating between NW services. There is no single answer as to how services should communicate. There are different levels of coupling between services desired, depending on the type of service. Services publish events, subscribe to event topics and receive events to which they have subscribed for notification of various events which may need service. Generally, the communication service is dynamic with run-time announcements of producer and consumer registrations, including topics. (Traditionally, these communications&apos; channels were fixed by the logical, initial configuration and physical deployment of a distributed system.) </paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> Rendezvous services <highlight><bold>812</bold></highlight> recognize and combine patterns of events which may require further service. One important factor when processing events is to know if the event is already being handled. Rendezvous services <highlight><bold>812</bold></highlight> recognize that events are being handled, thus preventing an event which has gone directly to a state machine from also creating a new state machine. Event patterns are also recognized which allows work documents already started to be merged together. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> NW services, once substantiated, must remain running on a server, or at least some server, and register for clients needing the services to be located. Therefore, GIB <highlight><bold>802</bold></highlight> also employs a group of self-management services <highlight><bold>816</bold></highlight> for monitoring the state of essential NW infrastructure services, or any services for that matter, on their separate servers. Notification of a dead service to a re-homing service (&ldquo;arch-angel&rdquo; service) is primarily a function of the leasing service provided by the domain registrar. The re-homing service then re-launches the dead service in another container, possibly on another server. Clients using a dead or dying service are left in the lurch as they cannot then complete processing even though the dead service might have been restarted in another container. The solution involves the use of self-healing proxy references that look to the registrar whenever a request to a service results in a stale exception. Here again, each of the GIB infrastructure services will be discussed in greater detail with respect to the Figures below. </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> One feature of the present invention involves separating data and resources that have been traditionally tied or owned by a particular application, from that application, thus breaking down the stovepipe. These resources are managed by persistent services <highlight><bold>818</bold></highlight>, particularly DataBus services, and may be used by clients and enterprise users via GIB <highlight><bold>802</bold></highlight>. However, persistent services <highlight><bold>818</bold></highlight> make enterprise data directly available to the enterprise users, depending on authorizations, and not from a data-owning application. Data can be organized by broad business domains such as the classification based on &ldquo;tiles&rdquo; or the TeleManagement Forum&apos;s BAC/SIM classification. However, any organization principle can be used. Current implementation uses the DMTF CIM/DEN information model. Deployment of data is generally &ldquo;holographic&rdquo; and randomly distributed within a named domain. &lsqb;But policy-based distribution and resource capacity is also used&rsqb; Domain names are based on geography, technology, and line-of-business; yet, any number of domain dimensions can be created allowing business extensibility. </paragraph>
<paragraph id="P-0175" lvl="0"><number>&lsqb;0175&rsqb;</number> Although data objects and data storage tiers are shared across the enterprise and de-coupled from applications, they are still available via simple, transactional APIs. Essentially, each kind of data is a service. Although finding data is somewhat more complex that finding a running service, the method is similar to the two-hop method employed with services. First, look to a local domain registrar for the location of a data object. If the data is not local, then look to an enterprise directory for the data object. The present invention achieves enormous scalability via a high degree of partitioning where data is flexibly mapped to a persistence layer of hundreds of mixed vendor databases and occasionally to other persistence technologies such as directories and tuple spaces. File storage is also supported via integration of Jiro (Sun product) or other Jini enabled disks. This provides for development of remote storage products such as NSPs and similar services within the NW infrastructure. </paragraph>
<paragraph id="P-0176" lvl="0"><number>&lsqb;0176&rsqb;</number> Finally, enterprise devices and heritage systems are provided access to NW services and resources via heritage system gateway <highlight><bold>820</bold></highlight> which translates heritage services into NW services. This is accomplished by implementing NW services acting as agents which represent external entities enterprise devices to other NW services. A similar mechanism is used for enterprise network elements. Enterprise network elements access NW services on GIB <highlight><bold>802</bold></highlight> in either of two ways by: 1) being NW-enabled themselves (i.e., by incorporating NW distributive intelligence services onboard that can directly access GIB <highlight><bold>802</bold></highlight>); or 2) utilizing distributed intelligent agents <highlight><bold>822</bold></highlight> which are similar to non-network devices described above and that interact with the resident protocol for the network elements to access NW services on GIB <highlight><bold>802</bold></highlight>. </paragraph>
</section>
<section>
<heading lvl="1">The GIB Infrastructure Architecture </heading>
<paragraph id="P-0177" lvl="0"><number>&lsqb;0177&rsqb;</number> The GIB is an ecosystem of NW services interacting in a highly-distributed fashion requiring special technologies to help services discover each other and keep the ecosystem healthy and stable. As independent stovepipe systems are deconstructed, new challenges are unearthed that are unaddressed by the prior art. Neither the EAI initiatives, the CORBA and EJB standards nor Sun&apos;s J2EE platform and Jini technology provide a holistic solution to the problems encountered in such a highly interactive-distributed environment as NW. </paragraph>
</section>
<section>
<heading lvl="1">NewWave Service Platform Infrastructure </heading>
<paragraph id="P-0178" lvl="0"><number>&lsqb;0178&rsqb;</number> Before discussing <cross-reference target="DRAWINGS">FIG. 9</cross-reference> in depth, a brief discussion of the underlying principle of the glue that binds the NW infrastructure would be helpful. NewWave, unlike prior art attempts, is a highly distributive environment based on an enterprise (or global) model and is not merely a domain level model of service distributions. Virtually every NewWave component can be embodied as a NewWave service so the NewWave principles described below apply to most, if not all NewWave components. &lsqb;When a non-native application is integrated into the NewWave service environment, a surrogate or proxy NewWave service is created which maintains the specialized interface /communication; the marketplace of other NW services sees only another NW service interface.&rsqb; In order for the ecosystem to remain in balance, whenever a service is launched, that service finds all services with which it needs to interact and also makes itself visible to all clients (service consumers, usually other services) that need to interact with it. Clients and services running in a domain are listed in all local lookup directories (directory services running in that domain). So, a newly-launched service spontaneously discovers all domain directories for registering itself to be found by services needing to interact with it, and finding services with which it needs to interact. The present invention, in contrast to the prior art, utilizes a &ldquo;two-hop&rdquo; discovery process to discover all local directory services and all enterprise level directory services. Through this two-hop process, a newly-launched service can discover and register with all local directories. Having discovered the local directories, the service can &ldquo;find&rdquo; any and all local services with which its needs to interact. One service is a &ldquo;find&rdquo; service which is used by a newly-launched service to find non-local directories (enterprise level directories) to make itself visible to non-local service consumers. Similarly, the local directory and find services can be used to look up services the newly-launched service needs, locally from the local directory and globally via the find service. </paragraph>
<paragraph id="P-0179" lvl="0"><number>&lsqb;0179&rsqb;</number> This method is generally extensible and can be extended to three or more hop implementations if extremely large or extremely refined scope delineations are required by business circumstance or by the specifics of an alternate/future implementation technology. For instance, extension of the NewWave domain beyond a single global company to a marketplace of many global companies can be realized via an &ldquo;extranet&rdquo; service registrar which could be implemented as a third hop. In this manner, the NW infrastructure could be extended to a pandemic, global computing platform treating applications and data similarly to how the international financial infrastructure deals with products and money. Data in the system could be traded, deposited, withdrawn and even willed to heirs. Application services can be found via service directories (like phone numbers are today) and leased to other users. These service extensions and products are in development. </paragraph>
<paragraph id="P-0180" lvl="0"><number>&lsqb;0180&rsqb;</number> Returning to <cross-reference target="DRAWINGS">FIG. 9, a</cross-reference> diagram of NW service platform infrastructure of interrelated services relating to an enterprise is illustrated in accordance with an exemplary embodiment of the present invention. It is expected that an enterprise network is geographically widespread and serviced by a plurality of logical network domains, represented as network domains A-N. Logical domains are conceptually &ldquo;local&rdquo; to all services and clients within the domain. Everything not in a domain is &ldquo;not local&rdquo; to that domain and those services and clients. Local NW components in domain A (<highlight><bold>902</bold></highlight>A) include all locally-running VM containers <highlight><bold>918</bold></highlight>A and other NW services <highlight><bold>910</bold></highlight>A, domain registrar(s) <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN, transaction managers(s) <highlight><bold>912</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>912</bold></highlight>AN and enterprise repository lookup <highlight><bold>916</bold></highlight>A. &ldquo;Local,&rdquo; from the perspective of a component, means it is in the same multicast radius. Therefore, network domains A-N define separate multicast domains. NW components in domain A would be local to other components in domain A but non-local to NW components in any of logical domains B-N. Enterprise repository(ies) <highlight><bold>926</bold></highlight>, on the other hand, is non-local to all other services and resources, no matter the domain. It should be understood that the enterprise consists of a plurality of domains, local and non-local, but the present invention of the invention will be described, heretofore, with respect to NW components in logical domain A (<highlight><bold>902</bold></highlight>A). The term &ldquo;client&rdquo; will be understood to represent any consumer or user of a service, notably, many clients are other services, especially another service that builds upon more primitive services, but may instead be any application, software module or tool that utilizes the processes of a service or might even be an end-user in the enterprise. </paragraph>
<paragraph id="P-0181" lvl="0"><number>&lsqb;0181&rsqb;</number> In each logical domain, such as domain A, services <highlight><bold>910</bold></highlight>A are deployed on a plurality of host servers, <highlight><bold>904</bold></highlight>A, <highlight><bold>904</bold></highlight>A<highlight><bold>1</bold></highlight> and <highlight><bold>904</bold></highlight>A<highlight><bold>2</bold></highlight> and running in a plurality of VM containers <highlight><bold>906</bold></highlight> (as described above with respect to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>). When deployed, servers <highlight><bold>904</bold></highlight> are loaded only with Java and the container code, these servers being &ldquo;generic hosts,&rdquo; depicted as server A <highlight><bold>904</bold></highlight>A<highlight><bold>1</bold></highlight> and server B <highlight><bold>904</bold></highlight>A<highlight><bold>2</bold></highlight>. However, special resources such as database <highlight><bold>908</bold></highlight> and rules engines (not shown), can be locally added to generic servers that transform the generic host into a &ldquo;specialized host&rdquo; or server, such as that depicted server <highlight><bold>904</bold></highlight>A. Within each of VM containers <highlight><bold>906</bold></highlight>A, one or more services <highlight><bold>910</bold></highlight> may be launched and continue running while awaiting requests from clients. However, enterprise clients must be able to find a service in order to utilize its functionality. While prior art technology makes the client responsible for knowing where to look for the service, by address usually, the present invention utilizes domain registrar(s) <highlight><bold>914</bold></highlight>A for tracking the addresses (URL address, URI addresses or host name) of services in accordance with an exemplary embodiment of the present invention. </paragraph>
</section>
<section>
<heading lvl="1">Domain Registrars </heading>
<paragraph id="P-0182" lvl="0"><number>&lsqb;0182&rsqb;</number> Each of domains A-N has at least one domain registrar, but as many as N registrars may be located in any one domain. A domain registrar can be embodied as a service and thus launch, discover and be discovered as any other service. Domain registrar <highlight><bold>914</bold></highlight> provides up to four primary services for the NW infrastructure: 1) a listing/lookup service for NW services running in its local domain, the services being listed and looked up in a lookup table by type and attribute, a proxy to the service is also listed that is streamed out to clients that lookup the corresponding service; 2) a leasing service for services running to lease resources in their local domain; 3) an enterprise level listing/lookup service allowing local services an client to bridge the gap to the enterprise level; and 4) a replicating service to replicate its tables or merely change in its tables to other registrars, or in fact to any service that has a need for registration or leasing information, for example, re-start services, trawling services, find services, enterprise level listing/lookup service, and other registrars in the local domain. </paragraph>
<paragraph id="P-0183" lvl="0"><number>&lsqb;0183&rsqb;</number> 1. Discovery and Registration </paragraph>
<paragraph id="P-0184" lvl="0"><number>&lsqb;0184&rsqb;</number> In the NW environment, when service <highlight><bold>910</bold></highlight>A is launched, it spontaneously &ldquo;discovers&rdquo; all nearby registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN (i.e., all domain registrars in its local domain). The newly-launched service <highlight><bold>910</bold></highlight>A then registers itself with the all newly-discovered domain registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN. In accordance with one exemplary embodiment of the present invention, the NW infrastructure uses multicast packets to allow both services and consumer services (clients) to spontaneously discover any of domain registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN within a local domain defined by a multicast radius, thus bootstrapping the process of finding and registering services. Thus, discovery is accomplished without obtaining any specific information about domain registrars <highlight><bold>914</bold></highlight>A, such as a URL address or host name. Similarly, whenever a new domain registrar is deployed, the domain registrar signals its availability for registering services within the local domain by broadcasting a multicast message to all nodes in the multicast domain (this is expected because a registrar is a NW service). All services <highlight><bold>910</bold></highlight>A running in domain A strive to remain registered with all local domain registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN, and so upon receiving the broadcast message, all services in the domain register with the newly-launched registrar. </paragraph>
<paragraph id="P-0185" lvl="0"><number>&lsqb;0185&rsqb;</number> This method utilizes Java Jini functional facilities. Other lookup methods can be supported in specific circumstances or environments. One such method utilizes a mobile agent approach where an active mobile service agent deposits information in each lookup or enterprise registration facility. Circumstances which can invoke these alternate methods are generally the result of technical or logical barricades such as company boundaries, security domains, or non-IP transport networks. </paragraph>
<paragraph id="P-0186" lvl="0"><number>&lsqb;0186&rsqb;</number> A. Local Registration </paragraph>
<paragraph id="P-0187" lvl="0"><number>&lsqb;0187&rsqb;</number> Once local domain registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN have been discovered, local registration is a two-step process, providing registration information about the service and making an enterprise lease for resources needed by the service. Local registration makes service <highlight><bold>910</bold></highlight>A visible to other NW services and clients (collectively service consumers or merely consumers) in the local domain. When a service registers itself, it provides a number of attributes in the registration that makes it easier for others (potential consumers) to find. These attributes may include one or more names, domain-type information, the interfaces which the service implements (i.e., what function a service can be requested to do). Thus, a client can match a service listed in registrar <highlight><bold>914</bold></highlight>A according to their interface type or by matching one or more attributes with which service <highlight><bold>910</bold></highlight>A registered itself. </paragraph>
<paragraph id="P-0188" lvl="0"><number>&lsqb;0188&rsqb;</number> Additionally, service <highlight><bold>910</bold></highlight>A can also include administrative information in the registration information provided to registrar <highlight><bold>914</bold></highlight>A (i.e., administrative information for interacting with the service administratively, such as an icon for display or a user interface object). </paragraph>
<paragraph id="P-0189" lvl="0"><number>&lsqb;0189&rsqb;</number> Finally, service <highlight><bold>910</bold></highlight>A must provide registrars <highlight><bold>914</bold></highlight>A an object which is a proxy, or a service object, to service <highlight><bold>910</bold></highlight>A, during registration. The proxy is an object (or objects) that allows clients to access a service. The proxy is streamed to registrar <highlight><bold>914</bold></highlight>A where it is stored in serialized form. When a consumer of service <highlight><bold>910</bold></highlight>A looks up that service, the proxy is, in turn, streamed out to the consumer. A proxy contains codebase with a URL of an HTTP server, the service code (usually Java byte-code) that implements the proxy object can be served up from that HTTP server by its URL, which is located arbitrarily in or outside the geographical domain of the enterprise. </paragraph>
<paragraph id="P-0190" lvl="0"><number>&lsqb;0190&rsqb;</number> The above-described approach to registering a service proxy in a local service registrar that employs a leasing approach to registration constitutes prior art, specifically embodied by the Jini technology suite from Sun Microsystems. This approach to proximity-based, local service lookup is itself not a part of the present invention, but is used by the present invention in conjunction with novel techniques that expand the visibility of network services to enterprise scope. </paragraph>
<paragraph id="P-0191" lvl="0"><number>&lsqb;0191&rsqb;</number> B. Proxies </paragraph>
<paragraph id="P-0192" lvl="0"><number>&lsqb;0192&rsqb;</number> In its simplest form, a proxy merely forwards requests from a consumer, for instance, on to service <highlight><bold>910</bold></highlight>A. However, the proxy might also contain any code that could be executed in a client environment before, after or instead of forwarding the request. Such a proxy is known as a &ldquo;smartproxy.&rdquo; This model is in sharp contrast to CORBA, where a registry simply stores a reference (a sort of address) that allows a consumer of a CORBA service to make a connection to some remotely-deployed service process. The present invention allows proxies that implement the service interface to be moved out to consumers at runtime. </paragraph>
<paragraph id="P-0193" lvl="0"><number>&lsqb;0193&rsqb;</number> The technique of using smart proxies in the context of distributed object systems was known within the CORBA development community (and explicitly discussed in Iona CORBA documentation). However, the approach taken to implementing smart proxies within a CORBA context was highly constrained and awkward. A developer needed to manually insert source-code modifications into the stubs that were generated by the IDL compiler, an inelegant work-around. The Jini technology from Sun Microsystems, greatly added to the state-of-the-art with regard to the usefulness, power and practicality of smart proxies. This storage of serialized smart proxies within service lookup engines, and the streaming of such proxies to service consumer processes obviated the need to manually modify generated stub code, as well as freeing client applications from the requirement to link in required stub implementation code at program build time. The current invention makes extensive use of smart proxies, for example, in its handles to remote entity instances and the interfaces to logical association engines (discussed in depth below). However, such smart proxy techniques themselves are part of the prior art that is used in novel ways to support and enable the current invention. </paragraph>
<paragraph id="P-0194" lvl="0"><number>&lsqb;0194&rsqb;</number> The proxy that gets stored in domain registrar <highlight><bold>914</bold></highlight>A, and subsequently streamed out to clients, can be absolutely any object that is serializable. A smart proxy can do anything that can be done in Java code. This model of moving smart proxies and service code to clients at runtime is different from CORBA, where a stub object can only act as a proxy that forwards requests to and responses from a remote server process. According to the one embodiment of the present invention, a smart proxy may perform computations that are purely local within the client&apos;s process space. According to another embodiment of the present invention, it might store state information local to the client. Alternatively, and in accordance with still another embodiment of the present invention, it might interact with a remote server process (outside its local domain)&mdash;the real implementor of a service. </paragraph>
<paragraph id="P-0195" lvl="0"><number>&lsqb;0195&rsqb;</number> Essentially, the client proxy hides code from the client, thus when the client makes a request for a NW service, a smart proxy will be returned with service interaction code that is hidden from the client. The client might &ldquo;think&rdquo; it is interacting with the requested service, while in fact the smart proxy provides the client with a means for executing the service locally, or interacting with the requested service, or interacting with services, sequentially or concurrently, without the client being aware of the interactions. The client proxy can hide any code, thus allowing the client to communicate with a remote service using any protocol or middleware or many services. Alternatively, client proxy can hide any code allowing the client to perform all logic locally or even implement an entire client application, including GUI. </paragraph>
<paragraph id="P-0196" lvl="0"><number>&lsqb;0196&rsqb;</number> It should be understood that even in the degenerate case, where the service object simply forwards requests to a remote process, NewWave services become roughly equivalent to CORBA or RMI services. One of the most common forms of NW services uses an RMI stub object as the proxy object that is downloaded from a domain registrar&apos;s lookup to a client. But this is simply the most common case. A smart proxy encapsulates code that interacts with a remote service using any one of a variety of protocols or middleware, such as sockets, RMI, CORBA, IBM MQSeries, and the like. Or a smart proxy interacts with two or more remote services using the same or even different middleware or protocols. Or a smart proxy interacts with zero remote processes, implementing the entire service interface locally within the client&apos;s process space. Over the course of time, a smart proxy might have an implementation that changes to a different communications protocol, unbeknownst to the client. For example, as vendors and vendor services evolve, the implementation code in the smart proxy changes to reflect new services. Alternatively, the proxy might communicate with one or another remote server processes, depending upon the time of day, lading or other configurable factors. In still another example, the proxy might parasitically use the communication channel of an object that is passed to it as an argument, not using its own communication channel. </paragraph>
<paragraph id="P-0197" lvl="0"><number>&lsqb;0197&rsqb;</number> Recall that looking up a service means fetching the service code for the service from a code server located remotely. The proxy contains a codebase that includes the address(es) (URL(s)) of code server(s) <highlight><bold>922</bold></highlight>A which are able to serve up the code for the proxy. Thus, the proxy code is loaded remotely in the client space through its codebase. Through this proxy clients can access the service via the remotely-located service code that is streamed to the client. In contrast with the prior art, looking up a service means fetching the service&apos;s proxy from registrar <highlight><bold>914</bold></highlight> and the proxy&apos;s service code is streamed out to the client from HTTP server <highlight><bold>920</bold></highlight>A. </paragraph>
<paragraph id="P-0198" lvl="0"><number>&lsqb;0198&rsqb;</number> C. Non-local Registration </paragraph>
<paragraph id="P-0199" lvl="0"><number>&lsqb;0199&rsqb;</number> Once a service has registered in a local domain (and acquired an enterprise lease), the service is visible to any local client looking for a service of a similar type of attributes (potential service consumers) listed in domain registrar <highlight><bold>914</bold></highlight>A&apos;s lookup. Non-local clients have no mechanism for perusing registrar directories that are non-local to themselves (i. e., in a non-local domain). Therefore, registration with a registrar only ensures that a service is visible to local clients. Registering in non-local domains requires that a service list itself with an enterprise level directory that is accessible by all clients in the enterprise. In accordance with an exemplary embodiment of the present invention, a service that wishes to be visible to non-local passes the URL address(es) local registrar(s) to enterprise repository <highlight><bold>926</bold></highlight> to make itself visible to clients in non-local domains. The present invention envisions multiple methods of registering with enterprise repository <highlight><bold>926</bold></highlight>. One mechanism involves the use of enterprise repository trawler services that trawl all the registrars&apos; lookups for services that indicate the intention to be visible non-locally. The trawler service then returns the registration information, at least the service&apos;s attributes, and the registrar&apos;s URL address, to the enterprise repository(ies). Another mechanism involves the service itself finding an enterprise repository lookup service. The enterprise repository lookup service then finds an enterprise level repository and registers the service with it by depositing registration information and the registrar&apos;s URL address, to the enterprise repository(ies). However, a salient point here with regard to non-local registration is that enterprise repository <highlight><bold>926</bold></highlight> lists, at least, the service&apos;s attributes and a URL to a local registrar that contains other registration information, such as administrative information and the proxy. </paragraph>
<paragraph id="P-0200" lvl="0"><number>&lsqb;0200&rsqb;</number> Finally, there might be cases when a service is running and yet must become invisible to potential consumers, for instance, when a service is executing processes on all available threads. Therefore, in accordance with another embodiment, registrars <highlight><bold>914</bold></highlight> track the amount of services running on threads of another service, especially container services, in the local domain. Once a threshold number of running services is reached, registrar <highlight><bold>914</bold></highlight> makes the service unavailable for potential consumers of the service and notifies the enterprise repository, using one of the techniques described above, that the service is no longer available to clients. Of course, this may be run on a separate service that communicates with the registrar directly. Services that need a service with the particular attributes of a service that is unavailable must either find another service with those attributes, wait for the service to free up, or initiate a process to start another instance of the service on another (or possibly the same) VM container. </paragraph>
<paragraph id="P-0201" lvl="0"><number>&lsqb;0201&rsqb;</number> 2. Enterprise Leasing </paragraph>
<paragraph id="P-0202" lvl="0"><number>&lsqb;0202&rsqb;</number> Another important facet of the NW service architecture is the notion of enterprise leasing. The leasing mechanism, in general, allows enterprise resources to be reserved on behalf of a requesting client (or any consumer of the resource) in the enterprise. These enterprise resources may include services, databases, enterprise engines (rules, etc.), transaction managers, and communications (publish and subscribe, messaging, event, etc.). With respect to registrars <highlight><bold>914</bold></highlight>, the enterprise leasing mechanism allow services <highlight><bold>910</bold></highlight> to bind themselves to the registrar&apos;s directory and lookup, and then periodically renew their binding to the directories of registrars <highlight><bold>914</bold></highlight>. It should be understood that if the client is responsible for registering with all registrars in a domain, it is also responsible for contracting with each registrar for an enterprise lease. The act of enterprise leasing reserves registrar resources to the service that are necessary for the service to make itself visible to service consumers. </paragraph>
<paragraph id="P-0203" lvl="0"><number>&lsqb;0203&rsqb;</number> Any time resources are reserved on behalf of some participant in the enterprise, the reservation of those resources adheres to a leasing convention, sometimes known as time-limited resource allocation. In accordance with one embodiment, the client that requests the reservation of resources may specify a lease duration, a time period over which a client-party can assume the resource reservation will be maintained. The requesting client will be issued a lease object that indicates the amount of time for which the lease has been granted (a duration that might be shorter than that requested). Alternatively, the enterprise lease duration is set at a default time period which is known to all participants in a domain. Once a lease is established with a resource, it is the responsibility of the client reserving the resource to know the lease duration and then to renew the lease, if necessary, prior to the known time period elapsing. Whenever it is necessary to maintain the resource past the term of the original lease, the requesting party should always request a lease renewal before the lease expires. In practice, this might entail requesting several lease renewals from various registrars in the local domain. If the requesting party should fail to renew the lease and it expires, the provider of the resource will do whatever cleanup is appropriate. For registrars <highlight><bold>914</bold></highlight>, cleanup includes deleting the service from the lookup table, including removing all attributes, administrative information and proxies (service objects). </paragraph>
<paragraph id="P-0204" lvl="0"><number>&lsqb;0204&rsqb;</number> This technique of enterprise leasing facilitates the implementation of self-healing services. If a process, on whose behalf a resource is leased, should abruptly crash, the lease will eventually expire and the system can de-allocate the resource. Things get cleaned up all by themselves. Moreover, with respect to the registrar, whenever an enterprise lease for service expires, the registrar can notify the self-healing services of the lease expiration. The self-healing services can then attempt to restart the service, either in the same or different container. In certain cases, a process might include several transactions that are dependent on one another. If, as will be discussed below, a transaction has not been completed, the participants will be instructed by transaction manager <highlight><bold>912</bold></highlight> to roll back the process to a state prior to the commencement of the transaction, thus the participants are unaffected by a failure during a transaction. However, if several transactions have been successfully accomplished, the results of those transactions might be cached to a storage resource awaiting further processing. If the service hosting the resource fails, or even if a service fails that is crucial to the remaining transactions, it is likely that the cached data will not be recoverable. In the best case, the client can restart the process for the beginning and reestablish the data. In the worst case, the states of the service resources being used have been changed during the previous transactions making restarting the process impossible. The solution is a mirror resource that mirrors inter-process results for a running process. In case of a failure resulting in a lease expiration (service, communications or resource), the client or the client proxy maintains an object for the mirror and when the self-healing services restart the service(s), the client can continue the process with the mirrored interim results. </paragraph>
<paragraph id="P-0205" lvl="0"><number>&lsqb;0205&rsqb;</number> In accordance with one embodiment of the present invention, individual registrars may be responsible for tracking the enterprise leases for all services listed in their respective lookups. In accordance with another embodiment of the present invention, the registrars are responsible for notifying each other through replication and the like (and possibly the enterprise repository) of a lease to a expiring service. Finally, in accordance with still another embodiment, specialized enterprise leasing services track individual leases for services and notify the directories (domain level and possibly enterprise level) whenever an enterprise lease expires. With regard to NW service leases, the main construct is to de-list any service that has failed in any directory that the service is visible to clients (i.e., domain registrars and enterprise repositories). </paragraph>
<paragraph id="P-0206" lvl="0"><number>&lsqb;0206&rsqb;</number> The premise is that all enterprise leases are managed in the local domain that the service is running. Some component(s) in the local domain (i. e., one or all local domain registrars or a leasing service) must recognize that a service&apos;s enterprise lease has expired. The service must then be de-listed from local directories that client can access and then re-listed in non-local directories that clients can access. Enterprise leases are managed at the domain level while the resources that they reserve might concern a service that is available to clients across the enterprise. Such is the case when a service registers itself locally, making itself visible to local clients, and then makes itself visible to non-local clients (i.e., clients in non-local domains). Registering in non-local domains requires that a service list itself with enterprise repository <highlight><bold>926</bold></highlight> to make itself visible to clients in non-local domains. Therefore, whenever an enterprise lease expires in a local registrar, that service must be de-listed from the local registrar(s) and then the lease expiration must be communicated to enterprise level directories in order to make that service invisible to potential clients. Several mechanisms are useful for this task depending on the functionality of registrar <highlight><bold>914</bold></highlight>. </paragraph>
<paragraph id="P-0207" lvl="0"><number>&lsqb;0207&rsqb;</number> The first leasing mechanism involves an individual registrar managing only the enterprise leases for service that it registered. It is expected that self-contained registrar models that operate only at the domain level, such as Jini technology registrars, will utilize this mechanism. In accordance with this mechanism, when a lease expires in a registrar, clean up is automatic and the registrar does not communicate the lease expiration to either other registrars in the local domain or to the enterprise repository. In this case, each registrar is responsible for managing its own leases as eventually the failed service&apos;s enterprise leases will expire in all of the registrars that it registered (i.e., local registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN). However, if the service was listed in enterprise repository(ies) <highlight><bold>926</bold></highlight>, it will remain listed until the repository is notified that of the lease expiration. Notifying enterprise repository(ies) <highlight><bold>926</bold></highlight> of lease expirations is the job of the enterprise repository scavenger services. Recall that trawler services originally found all services listed in local domain registrars that intended to be visible non-locally and returned the service&apos;s attributes and the URL address(es) of the registrar(s) in which the services were listed. Scavengers are the antithesis of the trawler services as these scavenger services de-list services that leases expired in a domain registrar from the enterprise repository(ies). Recall also that a service might be listed in an enterprise repository with one or several URL address(es) for the registrars with which the service is registered. A scavenger daemon is a background service that compares the contents of registrar&apos;s lookup table between scheduled checks. Registrar entries for services that have been cleaned up between checks, for whatever reason (i.e., enterprise lease expiration, explicit shutdown, etc.), will be communicated to enterprise repository <highlight><bold>926</bold></highlight>. Enterprise repository <highlight><bold>926</bold></highlight> can then de-list the service from the registrar&apos;s address from its directory. If the service has only one associated URL, then the service is completely de-listed from the enterprise repository&apos;s lookup and the service will be rendered invisible to potential consumers. </paragraph>
<paragraph id="P-0208" lvl="0"><number>&lsqb;0208&rsqb;</number> In accordance with another mechanism, each of registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN communicate lease expirations from their respective directories directly to enterprise repository <highlight><bold>926</bold></highlight>. Direct communications between registrar <highlight><bold>914</bold></highlight> and enterprise repository <highlight><bold>926</bold></highlight> is possible only if registrar <highlight><bold>914</bold></highlight> maintains a reference or address for enterprise repository <highlight><bold>926</bold></highlight> itself (or possibly for enterprise repository lookup <highlight><bold>916</bold></highlight>, which can then be accessed by the registrar). In that case, when a service&apos;s lease expires, registrar <highlight><bold>914</bold></highlight> communicates the lease expiration to enterprise repository <highlight><bold>916</bold></highlight>. Enterprise repository <highlight><bold>916</bold></highlight> can then de-list the reference to the registrar from its lookup or, if only one URL address/reference is listed, enterprise repository <highlight><bold>916</bold></highlight> can then de-list the service completely as described immediately above. </paragraph>
<paragraph id="P-0209" lvl="0"><number>&lsqb;0209&rsqb;</number> 3. Enterprise Level Listing/Lookup </paragraph>
<paragraph id="P-0210" lvl="0"><number>&lsqb;0210&rsqb;</number> Clients seeking services outside their local domain and services wishing to be visible outside their local domain must have a mechanism to utilize a non-local directory. The present invention uses an enterprise repository for global service listing thereby making services visible from outside their local domain. As alluded to above, registrar <highlight><bold>914</bold></highlight> may or may not provide clients and consumers with a reference or location information (URL) for enterprise repository <highlight><bold>926</bold></highlight>. Certain domain level registrars, notably Jini technology registrars, do not themselves provide multi-tiered domain structures (i.e., a local level and non-local or enterprise level). Those domain level registrars cannot be easily modified themselves, but can be integrated with enterprise-scoped directory services to expand service visibility to enterprise range. Therefore, in accordance with one embodiment of the present invention, a reference to a &ldquo;find&rdquo; service such as enterprise repository lookup service <highlight><bold>916</bold></highlight>A, is held in the registrar&apos;s lookup. Enterprise repository lookup service <highlight><bold>916</bold></highlight>A is then utilized by local clients and service for finding enterprise level directories, and finding or listing service in those directories. In the case of service, enterprise lookup service <highlight><bold>914</bold></highlight>A looks up an enterprise repository and then registers the service by listing the service&apos;s attributes and the service&apos;s registrars&apos; URLs in the enterprise repository. In the case of a global client, enterprise lookup service <highlight><bold>914</bold></highlight>A looks up an enterprise repository and finds a service listed in enterprise repository <highlight><bold>926</bold></highlight> based on the attributes listed for the service. Enterprise lookup service <highlight><bold>914</bold></highlight>A either returns the service&apos;s registrars&apos; URLs to the client and the client accesses the registrar for the service proxy, or alternatively enterprise lookup service <highlight><bold>914</bold></highlight>A accesses one of the service&apos;s registrars directly and causes that registrar to pass the service&apos;s proxy to the client. </paragraph>
<paragraph id="P-0211" lvl="0"><number>&lsqb;0211&rsqb;</number> In accordance with an alternative embodiment of the present invention, enterprise repository <highlight><bold>926</bold></highlight> is treated like any other service and a reference for enterprise repository <highlight><bold>926</bold></highlight> is copied directly into registrars <highlight><bold>914</bold></highlight>. In this case, enterprise repository lookup <highlight><bold>916</bold></highlight> would check for enterprise repositories starting up or shutting down and list or de-list the repositories accordingly. Newly-launched services, as well as local consumers, can then discover enterprise repository <highlight><bold>926</bold></highlight> from the reference in the registrar without having to access a separate lookup service for the address. In addition, once having a reference to the enterprise repository, registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN can replicate service registration information and lease updates directly to enterprise repository <highlight><bold>926</bold></highlight> without the need for trawling and scavenger services. </paragraph>
<paragraph id="P-0212" lvl="0"><number>&lsqb;0212&rsqb;</number> What is novel about this approach to enterprise service lookup is that, by combining multicast-based local service lookup with enterprise-scope directory services, the client can bootstrap its way to finding a service anywhere in the enterprise. This bootstrapping occurs without an a priori knowledge of the IP address, URL, DNS host name or other detailed location information detailing how to connect to the enterprise service directory. Prior approaches to finding enterprise services, such as CORBA naming or RMI Registry, require the client to know, or be able to find, the contact information for the enterprise service directory. Other service location technologies, based upon multicast discovery (notably Jini technology) enable spontaneous discovery of services without such a priori address knowledge, but are limited to local service discovery, unless augmented by additional techniques. The NW multi-stage approach to enterprise service lookup achieves a &ldquo;best of both worlds,&rdquo; allowing spontaneous boot-strapping by the client to find services anywhere in the enterprise. </paragraph>
<paragraph id="P-0213" lvl="0"><number>&lsqb;0213&rsqb;</number> 4. Replication </paragraph>
<paragraph id="P-0214" lvl="0"><number>&lsqb;0214&rsqb;</number> Replication between registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN is unnecessary if services are responsible for discovering all registrars in their respective local domains (e.g., registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN in local domain A), and if the individual registrars are responsible for their own lease management. Otherwise, the separate registrars&apos; lookups must be reconciled with one another by including one another&apos;s updates. The simplest means for rectifying registration and leasing information between registrars is through a replication mechanism. Therefore, in accordance with one embodiment of the present invention, registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN provide a replicating service for replicating listing changes (i.e., registrations, lease expirations, lease renewals, explicit shutdown or reset, etc.) to each of the other registrars in the domain. </paragraph>
<paragraph id="P-0215" lvl="0"><number>&lsqb;0215&rsqb;</number> As mentioned above, registrar <highlight><bold>914</bold></highlight> may have a reference to enterprise repository <highlight><bold>926</bold></highlight>. If so, then the enterprise repository could also be updated from the registrar during replication. In that case, domain services <highlight><bold>910</bold></highlight> would then be relieved from the responsibility of registering with all of registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN in the domain, as well as renewing leases with all registrars in the domain. A service merely discovers one registrar in the domain and registers with it. The registrar replicates the registration information throughout the domain and to enterprise repository <highlight><bold>926</bold></highlight> if necessary. However, if the registrar known to the client fails or becomes unresponsive to the client, the client must discover and register with another registrar prior to the enterprise lease expiring. </paragraph>
<paragraph id="P-0216" lvl="0"><number>&lsqb;0216&rsqb;</number> Alternatively, the individual services are responsible for replicating service related information throughout the local domain. Services discover all running registrar services in their local domain and then register themselves with each registrar. Additionally, services make and renews enterprise leases with the individual domain registrars. In that case, the client also registers with all newly-launched registrar services in its local domain and, through a process that will be described below, registers with enterprise repository <highlight><bold>926</bold></highlight> if the service desires to be visible and usable by non-local clients. In accordance with still another embodiment of the present invention, a series of enterprise repository services are responsible for trawling the registrars <highlight><bold>914</bold></highlight> for registrations and promoting any enterprise-visible service registration up to the enterprise level. Enterprise lease expirations are handled by comparing the content of the registrar&apos;s lookup between trawls. </paragraph>
</section>
<section>
<heading lvl="1">Enterprise Directory Services </heading>
<paragraph id="P-0217" lvl="0"><number>&lsqb;0217&rsqb;</number> NW services may make themselves visible to clients in their local domain or may intend to the visible to all enterprise clients, whether local or non-local. Enterprise repository <highlight><bold>926</bold></highlight> provides a lookup service for clients, but at an enterprise level (non-local) rather than domain level (local) registration provided by domain registrar <highlight><bold>914</bold></highlight>. As described above, registering a service outside its local domain is the responsibility of either the service itself, enterprise repository lookup service <highlight><bold>916</bold></highlight>A or a series of enterprise registrar services that trawl local registrars <highlight><bold>914</bold></highlight> for registrations. Each of these mechanisms promote any service wishing to be visible outside its local domain the means to be enterprise-visible, through registration at the enterprise level. </paragraph>
<paragraph id="P-0218" lvl="0"><number>&lsqb;0218&rsqb;</number> In addition to being a registry, enterprise repository <highlight><bold>926</bold></highlight> is a directory for clients needing a service. Enterprise repository <highlight><bold>926</bold></highlight> provides a means for non-local clients to access services that are not available in their own domains. Therefore, the lookup for enterprise repository <highlight><bold>926</bold></highlight> must include, at a minimum, all attributes for listed services, along with addresses (URL addresses or host names or some other references) for the services&apos; registrars. With that information, a potential consumer can look up a needed service by its attributes and, by using the associated URL, go to one of the service&apos;s registrars for a proxy to the service. </paragraph>
<paragraph id="P-0219" lvl="0"><number>&lsqb;0219&rsqb;</number> The enterprise utilizes multiple enterprise repositories <highlight><bold>926</bold></highlight> that are strategically located around the enterprise&apos;s geographic domain. A potential service consumer might access any of enterprise repositories <highlight><bold>926</bold></highlight> for finding a service. Therefore, each of enterprise repositories <highlight><bold>926</bold></highlight> must list all running services in the enterprise that wish to be visible to clients in non-local domains (i.e., at the enterprise level). Thus, enterprise repository <highlight><bold>926</bold></highlight> must replicate service information received from enterprise registrars with every other enterprise repository in the enterprise. </paragraph>
<paragraph id="P-0220" lvl="0"><number>&lsqb;0220&rsqb;</number> The Lightweight Directory Access Protocol (LDAP) is a protocol used to access directory listings and is supported by web browsers and e-mail programs, and the like, which can query a LDAP-compliant directory. LDAP provides a common method for searching e-mail addresses on the Internet, similar to a global white pages. LDAP is a sibling protocol to HTTP and FTP and uses the ldap://prefix in its URL, thus familiar to use. LDAP provides good replication around the world and therefore provides the necessary level of replication needed for an enterprise repository. However, the LDAP protocol and directory also have shortcomings which make them unsuitable for use as an enterprise repository in the present invention. </paragraph>
<paragraph id="P-0221" lvl="0"><number>&lsqb;0221&rsqb;</number> It is not possible to support the full range of attributes and lookup required by enterprise registrar <highlight><bold>914</bold></highlight> in an LDAP directory as LDAP directories do not support all of the configuration information for a container that is necessary for launching a service in that container. The LDAP directory is not able to store logical domain mappings that are defined along any relevant dimensions (e.g., geography, line-of-business, etc.). This aspect of the present invention will be discussed below with the description of the DataBus service. </paragraph>
<paragraph id="P-0222" lvl="0"><number>&lsqb;0222&rsqb;</number> In an effort to overcome the above shortcomings of the LDAP and its directory, and in accordance with an exemplary embodiment of the present invention, enterprise repository <highlight><bold>926</bold></highlight> supports all service attributes that may be used by a client for finding a service. These attributes are available to local clients in registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN and therefore must be available in enterprise repository <highlight><bold>926</bold></highlight> for a client to find a service in a non-local domain. It should be remembered that a client finds a service that it needs by comparing the type and attributes for the services running in the enterprise and are listed in a lookup to the attributes needed by the client. Service lookup is based on type and attributes and not on unique name, and therefore the enterprise repository must support service type and attribute information. </paragraph>
<paragraph id="P-0223" lvl="0"><number>&lsqb;0223&rsqb;</number> Another shortcoming with LDAP is that it was never intended to store database schema. Services that use a resource which must be local must be able to automatically provision that resource. For instance, if a service uses a database locally, it must be able to start with a completely empty database, adding the tables needed on the fly. To do this, database schema information is stored in enterprise repository <highlight><bold>926</bold></highlight> by any method, including proprietary. XML-based schemas (Extensible or XML Structure Definitions (XSD)) are popular because they can be created with any XML tools. </paragraph>
<paragraph id="P-0224" lvl="0"><number>&lsqb;0224&rsqb;</number> NW service must be mobile from the point of view of machine-specific configuration information. Configuration information cannot be tied to a specific machine because the service might run anywhere, and configurations cannot be redefine at runtime. It must be available from anywhere in the world, and a service must be able to be launched using configuration information that is not local to the service. To do this, all configuration information is stored in enterprise repository <highlight><bold>926</bold></highlight> and replicated throughout the world on other enterprise repositories. Launch scripts access enterprise repository <highlight><bold>926</bold></highlight> to get the configuration information and forward the configuration information to VM container <highlight><bold>910</bold></highlight>A where the service is launched. Therefore, in accordance with another exemplary embodiment of the present invention, enterprise repository <highlight><bold>926</bold></highlight> supports all configuration information needed by a VM container to launch a service and the configuration information needed by the service itself. </paragraph>
<paragraph id="P-0225" lvl="0"><number>&lsqb;0225&rsqb;</number> Recall that a VM container is actually a running NW service that is launched from the operating system and not from within another container. Conceptually, VM container services might be considered as an integral part of the operating environment. Other NW services, such as those that run inside VM containers, must be programmatically launched from a remote location according to the NW conventions. In order to launch a service in a specific container, the administrator must have the configuration information for the VM container that the service will run in, as well as configuration information concerning the service itself. Thus, enterprise repository <highlight><bold>926</bold></highlight> contains all configuration information for every VM container service currently running in the enterprise, so an administrator merely accesses the repository for all container configure information. In actuality, when a service is launched in a container, the container is provided with certain configuration information, including the service&apos;s codebase. The codebase contains the URLs of the code servers which are able to serve up the service&apos;s code. Therefore, when the service is launched, its code is loaded from HTTP servers at a remote location, for instance from HTTP server <highlight><bold>920</bold></highlight>A. </paragraph>
<paragraph id="P-0226" lvl="0"><number>&lsqb;0226&rsqb;</number> Finally, the enterprise repository supports logical domain mapping information in accordance with an exemplary embodiment of the present invention. In accordance with the present invention, enterprise data is no longer owned by an application but instead is owned by the enterprise. Enterprise data is, however, stored at various locations around the enterprise in specialized resource servers called &ldquo;entity&rdquo; servers. Separate entities will generally be housed in separate storage servers. Even a given entity is likely to be physically partitioned across many separate storages. Partitions of a given entity are often collocated at a given operations center, but the same entity might alternatively be physically partitioned across geographically distributed sites, for example, by siting one subset of customer data in the U.S. and another in Europe. Logical domains are used to narrow the context of an operation to a scope that is smaller than the entire enterprise. Logical domains are, in a sense, orthogonal to the dimension of entity type or subject area, and thereby cut across different entity boundaries. These could be along geographic lines or along lines of business, or according to some other classification. With the entities being highly partitioned across distributed data stores, the multi-hop finder is used for finding any particular data object of interest. Entity instances can then be found from anywhere in the enterprise, no matter where it is physically located, by a Primary Key (PK). A multi-stage finder strategy allows the navigation to any entity instance from anywhere in the enterprise given its primary key. This strategy, of course, requires that a primary key is mapped onto the partition number where the entity is stored. Mappings from the PKs onto respective partition numbers that uniquely identifies a relevant container where the entity is stored are then stored on the enterprise repository. </paragraph>
<paragraph id="P-0227" lvl="0"><number>&lsqb;0227&rsqb;</number> Also included in each of domains A-N are enterprise repository lookups <highlight><bold>916</bold></highlight>A-N, respectively. Enterprise repository lookup <highlight><bold>916</bold></highlight> is an alternative embodiment as its functionality may be incorporated directly into each of domain registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>914</bold></highlight>AN and is therefore represented in the Figure as a dashed block. As discussed immediately above, the sole function of enterprise repository lookup <highlight><bold>916</bold></highlight> is to track the location of at least one enterprise repository <highlight><bold>926</bold></highlight> for newly-launched services wishing to be visible outside their local domains, and for clients needing to find a service from outside their local domains. It is the function of the enterprise repositories to track every service running to the enterprise, at least those running services that wish to be visible enterprise-wide, and make that information available, either directly or indirectly, to clients that cannot find a needed service in the client&apos;s own domain. Notice that, in accordance with an exemplary embodiment of the present invention, N enterprise repositories are used which tends to prevent the administrative interactions and discovery/registration and find stages from becoming a bottleneck. </paragraph>
</section>
<section>
<heading lvl="1">HTTP Servers </heading>
<paragraph id="P-0228" lvl="0"><number>&lsqb;0228&rsqb;</number> NewWave services are mobile, in other words, the services can be quickly deployed on any machine, anywhere, without human intervention. As such, NW services can be launched on a server without any code specific to the service being pre-installed on the server and without any configuration information being pre-installed on the server. All resources used by the service can be accessed remotely and are not dependent on the resource being present on the local machine. Databases can be created on the fly by a service which creates the necessary database tables from a schema that is likewise remotely loaded. Additionally, NW services can be launched on a server without an administrator logging onto the server to initiate the launch. Re-homing of services is also performed at runtime from one server to another without human intervention. </paragraph>
<paragraph id="P-0229" lvl="0"><number>&lsqb;0229&rsqb;</number> To create this environment, the NW service platform deploys many HyperText Transport Protocol (HTTP) servers in place to serve up code, that is, Java class files and resources. In addition to the NW components described above, a plurality of web servers <highlight><bold>920</bold></highlight>A to <highlight><bold>920</bold></highlight>D are also located in the enterprise. Each HTTP web server (HTTP Daemon) <highlight><bold>920</bold></highlight>A-<highlight><bold>920</bold></highlight>C holds a plurality of mobile code <highlight><bold>922</bold></highlight>A-<highlight><bold>922</bold></highlight>C including, for example, service code <highlight><bold>922</bold></highlight>A, application classes <highlight><bold>922</bold></highlight>B and vendor code <highlight><bold>922</bold></highlight>C. Through administrative APIs, the service supplier indicates the URL address that identifies where which one of servers <highlight><bold>920</bold></highlight>A-<highlight><bold>920</bold></highlight>C service code <highlight><bold>922</bold></highlight> resides, which can be essentially anywhere on the Internet. The API method allows a requestor to start a service executing in the service container, supplying parameters that identify the URL for the code-base of the service code, the fully-qualified class name of the Java object that is the service&apos;s root object, and initialization payload object. Other methods are provided to allow a service to be abruptly shut down, allow the service to be gracefully quiesced (requested to stop accepting incoming requests, but carry to completion in-flight requests), and allow one to query whether the service is in a quiescent state. A generic service container service, such as VM container <highlight><bold>918</bold></highlight>A loads code <highlight><bold>922</bold></highlight> via one of HTTP web servers <highlight><bold>920</bold></highlight>A-<highlight><bold>920</bold></highlight>C and runs the service in its own thread of control. </paragraph>
</section>
<section>
<heading lvl="1">Transaction Managers </heading>
<paragraph id="P-0230" lvl="0"><number>&lsqb;0230&rsqb;</number> Notice that within each local domain a plurality of transaction managers <highlight><bold>912</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>912</bold></highlight>AN are available for creating transactions which are used for the purpose of transacting with host servers. In accordance with an exemplary embodiment of the present invention, transaction managers <highlight><bold>912</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>912</bold></highlight>AN are NewWave service and as such discover and register with local registrars <highlight><bold>914</bold></highlight>A<highlight><bold>1</bold></highlight> as any other service. In an environment in which a function is the collaboration of many services taking action cooperatively, an important ingredient is the notion of a distributed unit-of-work. A unit-of-work is managed by transaction managers <highlight><bold>912</bold></highlight>A at the domain level. The NW approach to transaction semantics relies on a transaction that is passed around like a football each time a service request is made. There is no central transaction manager managing the transaction, to be a bottleneck, instead a client finds any transaction manager in the domain and creates a transaction. Finally, resource managers must support bi-directional communications between a transaction manager (TP monitor) and resource managers such as eXtended transActions (XA) for providing two-phase commit to persistence. </paragraph>
<paragraph id="P-0231" lvl="0"><number>&lsqb;0231&rsqb;</number> The distributed nature of transaction managers <highlight><bold>912</bold></highlight>A is facilitated by the highly-distributed world of the NW services. Any service, running anywhere, needs only to find a transaction manager running close by. If load is high, up to N transaction managers may be deployed across a domain thereby allowing highly-distributed services to gain access to a transaction manager and for scalability&mdash;as load increases the transaction manager does not become a bottleneck. In accordance with another exemplary embodiment of the present invention, all transactions have a lease associated with them, similar to the NW services described above. A transaction has a predetermined time-to-live. Transaction manager <highlight><bold>912</bold></highlight> issues enterprise leases on newly-created transactions in much the same manner as registrar <highlight><bold>914</bold></highlight> issues enterprise leases on services. However, the participants in the transaction can renew the lease if the activity takes longer than expected, but absent a renewal, an uncommitted transaction will expire and roll back. Any NW service which maintains state about other services or clients should implement a leasing scheme to keep its state clean. </paragraph>
<paragraph id="P-0232" lvl="0"><number>&lsqb;0232&rsqb;</number> Because of the use of Jini transactions, resources used in the GIB that are expected to participate in transactions must be managed by resource managers exposing a two-phase commit interface, such as XA or the Jini transaction participant interface. A typical resource manager is a database management system, for example, Oracle or Versant. However, recall that in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> enterprise network elements might be NW-enabled and thus access NW services on GIB <highlight><bold>802</bold></highlight> by incorporating NW distributive intelligence services <highlight><bold>824</bold></highlight> onboard. In those cases, network elements <highlight><bold>824</bold></highlight> plug directly into GIB <highlight><bold>802</bold></highlight>. In those cases, the network elements implement the relevant XA interfaces XAResource and XAConnection so that it could participate in the transaction as part of a transaction. </paragraph>
</section>
<section>
<heading lvl="1">NewWave Functionality </heading>
<paragraph id="P-0233" lvl="0"><number>&lsqb;0233&rsqb;</number> In the NewWave environment, an application is a collection of services operating in concert with each other. These NW services may or may not know of each other, but their collective action makes up the functional whole that is an application. To work as an application, NW services &ldquo;find,&rdquo; communicate and function with one another. </paragraph>
<paragraph id="P-0234" lvl="0"><number>&lsqb;0234&rsqb;</number> 1. Find </paragraph>
<paragraph id="P-0235" lvl="0"><number>&lsqb;0235&rsqb;</number> NW services can be found, either locally (within a multicast domain), within a non-local domain, or anywhere in the enterprise. Services register in lookups by their respective attributes and interfaces, and thus they are found by whatever attributes with which they service registers. Locally, a service registers with all domain registrars in the service&apos;s local domain. Non-locally, a service that wishes to be visible to clients from outside the local domain registers with an enterprise level registration and lookup service, the enterprise repository. The transition from local level to enterprise level visibility is bridged by an enterprise repository lookup that provides a reference to an enterprise repository for services and clients in a local domain. </paragraph>
<paragraph id="P-0236" lvl="0"><number>&lsqb;0236&rsqb;</number> 2. Communication </paragraph>
<paragraph id="P-0237" lvl="0"><number>&lsqb;0237&rsqb;</number> NewWave services communicate differently, depending on the type of service and the level of coupling between services desired. A distributed intelligent agent for network elements, for instance, is normally highly de-coupled, depending on little and thus able to continue processing regardless of the state of other NW services. It generally relies on highly, de-coupled forms of communication. The following different forms of communication are supported in the GIB: </paragraph>
<paragraph id="P-0238" lvl="2"><number>&lsqb;0238&rsqb;</number> Tightly coupled: The service implements a remote interface with exposed methods. Clients find the service and make specific requests of it by calling methods on the interface. The coupling is reduced by registrar lookup, thus still a code-level dependency between client and service. </paragraph>
<paragraph id="P-0239" lvl="2"><number>&lsqb;0239&rsqb;</number> Two-way tight coupling: The client opens a session of some sort with the service. The service maintains state about the client. There is then a runtime dependency that exceeds a single request. </paragraph>
<paragraph id="P-0240" lvl="2"><number>&lsqb;0240&rsqb;</number> Moderate coupling, event notification: A client registers with a service to be notified when certain events occur. There is a direct runtime dependency, as the service will hold a reference to the client (listener). However, the reference will be generic. The service will not know the actual interface of the client beyond the listening interface. This minimizes compile-time dependency, but still has runtime dependency. This essentially is a session between client and service, the service could be blocked while the notification is sent, and transaction semantics must be handled carefully. This is good is some circumstances to reduce messaging traffic by having notifications directly from the source to the listener with no intermediary. </paragraph>
<paragraph id="P-0241" lvl="2"><number>&lsqb;0241&rsqb;</number> Loosely coupled, peer-to-peer: Messages are sent through an intermediary, but directed to a particular destination by name. In this case, client and service know about each other, but only via a destination name as they can never directly access each other. </paragraph>
<paragraph id="P-0242" lvl="2"><number>&lsqb;0242&rsqb;</number> Loosely coupled, publish-subscribe: Messages are sent to a topic queue and are delivered to destinations that have issued subscriptions for particular kinds of messages. The sender and receiver of the message are never aware of each other at all. The only coupling is on message topic and message attributes. </paragraph>
<paragraph id="P-0243" lvl="2"><number>&lsqb;0243&rsqb;</number> Loosely coupled, XML: Messages are sent via publish-subscribe or peer-to-peer, but contains only XML, no objects. This removes any class-level dependencies. This is good when unrelated components are involved. </paragraph>
<paragraph id="P-0244" lvl="0"><number>&lsqb;0244&rsqb;</number> 3. Interactions </paragraph>
</section>
<section>
<heading lvl="1">Tightly Coupled Interactions </heading>
<paragraph id="P-0245" lvl="0"><number>&lsqb;0245&rsqb;</number> In a tightly-coupled interaction, a client or service acting as a client finds a target service via a registrar lookup or some other means, obtains a proxy to the target service, and calls methods on the proxy. A proxy, in accordance with the present invention, may communicate to the target service by any means. One exemplary method is Java Remote Method Invocation (RMI). The proxy communicates back to its service via direct sockets, IIOP, HTTP, JMS messages or any other middleware. However, the communication method selected for these transactions must be able to be reasonably effected from the client meaning that it cannot rely on the installation of any runtime component on the client. Code is remotely loaded from the codebase, but must be limited in size. It can be reasonably assumed that sockets, IIOP and HTTP would be generally available. RMI provides remote loading of arguments to the method call via the codebase. </paragraph>
</section>
<section>
<heading lvl="1">Moderately Coupled Interactions Using an Event Model </heading>
<paragraph id="P-0246" lvl="0"><number>&lsqb;0246&rsqb;</number> All services must support a standardized event model, the Jini event model or the like. NW services accept requests to receive notifications from listeners and are used for certain administrative events. However, a service can use this model to extend the way in which it interacts with all clients. In this model, NW services maintain event notification registrations, and directly call each listener when an event occurs matching the event registration. Each listener must first find a service and then makes a registration. All event registrations are maintained and the service accepts lease renewals and cleans out registrations when their lease expires. Services have the proxies to the listeners loaded in their respective virtual machines, requiring the remote loading of all required classes and the services will block waiting on a reply from each listener. This mode of interaction is moderately coupled because the interaction is through standard listener interfaces, rather than specific service interfaces, but it is more coupled than the loosely coupled approaches below. However, it is appropriate for some types of interactions as it is faster than the more loosely coupled approaches and useful when the client must find the service anyway. </paragraph>
</section>
<section>
<heading lvl="1">Loosely Coupled Interactions Using Publish-Subscribe or Peer-to-Peer Messaging </heading>
<paragraph id="P-0247" lvl="0"><number>&lsqb;0247&rsqb;</number> Messaging involves the sending of peer-to-peer and publish-subscribe messages through an intermediary. A variety of messaging services are available, including the Java Message Service (JMS) specification as the interface for messaging (available from Sun Microsystem Corporation). A client could publish a message to a topic queue or send a message to a logical destination. Subscribers would receive a publication if their subscription matched the message published. Loosely coupled interactions can be made even looser by using XML as the primary message format. JMS messages can include objects, but this adds a code-level dependency between sender and receiver; however, XML schemas or XML document-type definitions are not code level dependent. </paragraph>
</section>
<section>
<heading lvl="1">Launching and Registering a Service </heading>
<paragraph id="P-0248" lvl="0"><number>&lsqb;0248&rsqb;</number> In enterprise computing, the platform provider, the supplier of services (programs) and the consumers of services are often all the same corporate entity, residing within the same enterprise. The NewWave infrastructure fills the gap left by other paradigms by providing a dynamic service deployment architecture, that is not domain bound. Essentially, a service provider/supplier launches its services onto host servers at their own enterprise facilities, or at a third-party facility, through the exercising of administrative APIs and/or an administrative console application. This model of dynamic service deployment onto awaiting facilities is radically different from more traditional hosting arrangements that might involve extensive business negotiations. Thus, a service provider deploying its services onto live hosts out on the network amounts to API calls&mdash;not phone calls to support personnel. This model of service deployment is termed &ldquo;frictionless&rdquo; because of its ease of interaction. It allows service providers/suppliers to get tomorrow&apos;s services running in the field in Internet time. The concept of frictionless, dynamic deployment of services onto the network is all enabled by the constructs of code-mobility. As discussed above, code-mobility allows NewWave systems (HTTP servers) to move code out to consumers of services. By the same token, this mobility allows developers of services to also dynamically load the code that implements their services onto these third party host servers. This is very much analogous to the way that Java applets are streamed out to a user&apos;s PC web browser and run in a virtual machine process that serves as a sort of software container for applet code. The present invention service deployment platform simply applies this software container concept to backend-hosted services. Every server in a hosting facility runs at least one of generic container processes (VM container) into which service deployers inject the code for their services. The actual implementation code gets served up from any ordinary web server (http daemon) located anywhere in the Internet. </paragraph>
<paragraph id="P-0249" lvl="0"><number>&lsqb;0249&rsqb;</number> Through administrative APIs, the service supplier indicates the URL that identifies where the service code resides out there somewhere on the Internet. The generic service container process loads the code via the HTTP server and runs the service in its own thread of control. <cross-reference target="DRAWINGS">FIGS. 10 and 11</cross-reference> depict launching and registering service in a local domain or the enterprise, as and well as looking up a service that is running either locally or non-locally, and then interacting with the service in accordance with an exemplary embodiment of the present invention. FIGS. <highlight><bold>10</bold></highlight>A-<highlight><bold>10</bold></highlight>C at diagrams that depict the logical flow of the processes depict on corresponding flowcharts in FIGS. <highlight><bold>11</bold></highlight>A-<highlight><bold>11</bold></highlight>C. </paragraph>
<paragraph id="P-0250" lvl="0"><number>&lsqb;0250&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 10A and 11A</cross-reference> are a diagram and flowchart, respectively, depicting a process for launching and registering service in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention. The process begins with an administrator <highlight><bold>1004</bold></highlight> searching enterprise repository <highlight><bold>1026</bold></highlight> for suitable VM container to run a service (step <highlight><bold>1102</bold></highlight>). Recall that a VM container is merely a service and, as such, can be defined by name or as a set of attributes under which it is registered. While some NW services defer enterprise visibility, it is expected that due to the unique nature of VM container processes, as compared to most other NW services, containers will be registered, and thus visible, at the enterprise level for ease of interaction with service providers that need specific VM container attributes. For example, many services, perhaps most, run perfectly well in a generic VM container. Others, however, need a particular resource to be local to the service as it runs (e.g., as database, rules engine, etc.) The administrator can, therefore, analyze all enterprise VM container services for necessary attribute and select only the VM container(s) that have attributes matching the service&apos;s requirements. Once administrator <highlight><bold>1104</bold></highlight> has selected a group of candidate VM containers, the administrator can further differentiate between specific VM containers by logical location based on the URL address of the containers matching the requirements. By making service containers enterprise-class services, one can centralize administration in an enterprise, while nonetheless making service deployment highly distributed. </paragraph>
<paragraph id="P-0251" lvl="0"><number>&lsqb;0251&rsqb;</number> Once an appropriate VM container is selected, administrator <highlight><bold>1004</bold></highlight> launches the service in the selected VM container by passing a reference (URL address or host name) for the HTTP server holding the service code to the VM container (step <highlight><bold>1104</bold></highlight>). With URL, the VM container fetches the service code from the HTTP server at runtime (step <highlight><bold>1106</bold></highlight>) and the service begins running in the container (step <highlight><bold>1108</bold></highlight>). </paragraph>
<paragraph id="P-0252" lvl="0"><number>&lsqb;0252&rsqb;</number> Once running, service <highlight><bold>1010</bold></highlight>A must make itself visible to potential consumers of the service, whether the consumers are located locally or non-locally to the container. In accordance with an exemplary embodiment of the present invention, NewWave uses multicast packets to allow service provider processes and consumer processes to spontaneously discover lookup servers within multicast radius, thus bootstrapping the process of registering and finding services. Local registration involves the service broadcasting of a message to all registrars in the domain and then registering with them. Enterprise registration involves service <highlight><bold>1010</bold></highlight>A using a &ldquo;Find&rdquo; service to find an enterprise level directory and then registering there. Local registration begins with registrar discovery, or service <highlight><bold>1010</bold></highlight>A broadcasts multicast &ldquo;ping&rdquo; into the multicast radius that defines the local domain, domain <highlight><bold>1002</bold></highlight>A (step <highlight><bold>1110</bold></highlight>). All domain registrars that are &ldquo;listening&rdquo; in domain <highlight><bold>1102</bold></highlight>A will return a &ldquo;pong&rdquo; with their address information, usually URL addresses or host names (step <highlight><bold>1112</bold></highlight>). As depicted in the Figure, only domain registrar <highlight><bold>1014</bold></highlight>A is present, but any quantity of registrars could actually be present in accordance with the present invention. </paragraph>
<paragraph id="P-0253" lvl="0"><number>&lsqb;0253&rsqb;</number> With the addresses of local domain registrar <highlight><bold>1014</bold></highlight>A, service <highlight><bold>1010</bold></highlight>A can register locally with registrar <highlight><bold>1014</bold></highlight>A. Service <highlight><bold>1010</bold></highlight>A registers by passing information to registrar <highlight><bold>1014</bold></highlight>A that makes service <highlight><bold>1010</bold></highlight>A visible to clients looking for a service in domain <highlight><bold>1002</bold></highlight>A and information that facilitates clients&apos; interaction with service <highlight><bold>1010</bold></highlight>A step <highlight><bold>1114</bold></highlight>. Service <highlight><bold>1010</bold></highlight>A registers with local domain registrar <highlight><bold>1014</bold></highlight>A by passing registration information to registrar <highlight><bold>1014</bold></highlight>A, including service attributes (name(s), domain-type information and implementation interfaces). The registration information may also include administrative information such as display icons or user interface objects for an administrator to use. Finally, service <highlight><bold>1010</bold></highlight>A must pass a serialized proxy object (Obj. in the Figure) to registrar <highlight><bold>1014</bold></highlight>A which will be passed to clients looking up the service. The proxy includes code and a codebase for fetching service code for implementing the proxy. The service code is remotely located in an HTTP server, server <highlight><bold>1020</bold></highlight> for example, and the codebase contains an address for that server. At this point, service <highlight><bold>1010</bold></highlight>A is registered locally with registrar <highlight><bold>1014</bold></highlight>A making it visible to any clients looking in registrar <highlight><bold>1014</bold></highlight>A. </paragraph>
<paragraph id="P-0254" lvl="0"><number>&lsqb;0254&rsqb;</number> However, service <highlight><bold>1010</bold></highlight>A is not visible clients located in non-local domains. To be visible to more than just local clients, service <highlight><bold>1010</bold></highlight>A must register at the enterprise level in an appropriate enterprise directory&mdash;enterprise repository <highlight><bold>1026</bold></highlight> is such a directory. However, hopping from a local level domain to an enterprise level has been a shortcoming of the prior art that heretofore has been insurmountable. Services can discover only those services that are within their own multicast domain because the multicast message is not transmitted beyond the multicast radius. Therefore, another mechanism is necessary for &ldquo;finding&rdquo; non-local directories in order to make service <highlight><bold>1010</bold></highlight>A visible to clients which look up service in them. In accordance with one embodiment of the present invention, a service wishing to be registered at the enterprise level utilizes a &ldquo;find&rdquo; service to find enterprise level components, such as enterprise repository <highlight><bold>1026</bold></highlight>, that are not in their multicast domain. </paragraph>
<paragraph id="P-0255" lvl="0"><number>&lsqb;0255&rsqb;</number> The &ldquo;find&rdquo; service is represented in the Figure as enterprise repository <highlight><bold>1016</bold></highlight>A and as a service running in domain <highlight><bold>1002</bold></highlight>A and it is listed in domain registrar <highlight><bold>1014</bold></highlight>A. Therefore, a service wishing to be visible to a client located outside its local domain need only look up enterprise repository lookup service <highlight><bold>1016</bold></highlight>A while registering with the registrar (step <highlight><bold>1116</bold></highlight>). As will be described below, service <highlight><bold>1000</bold></highlight>A retrieves a proxy from the registrar for interacting with enterprise repository lookup service <highlight><bold>1016</bold></highlight>A (not shown in the Figure). Service <highlight><bold>1000</bold></highlight>A then requests enterprise repository lookup service <highlight><bold>1016</bold></highlight>A to service &ldquo;finds&rdquo; enterprise repository <highlight><bold>1026</bold></highlight> and register it with the repository (step <highlight><bold>1118</bold></highlight>). Service <highlight><bold>1000</bold></highlight>A passes its registration information, usually limited to its service attributes and also the address of all registrars with which it is registered, registrar <highlight><bold>1014</bold></highlight>A (URLs) to enterprise repository lookup service <highlight><bold>1016</bold></highlight>A. Enterprise repository lookup service <highlight><bold>1016</bold></highlight>A then finds an enterprise repository in the current example enterprise repository <highlight><bold>1026</bold></highlight> and registers a newly-launched service with that enterprise repository. Service <highlight><bold>1000</bold></highlight>A is now running in domain <highlight><bold>1002</bold></highlight>A and registered for clients that may be located in local domain <highlight><bold>1002</bold></highlight>A or any non-local domain. </paragraph>
</section>
<section>
<heading lvl="1">Finding a Local Service </heading>
<paragraph id="P-0256" lvl="0"><number>&lsqb;0256&rsqb;</number> The reciprocal of registering a service in the NewWave environment is finding a running service. <cross-reference target="DRAWINGS">FIGS. 10B and 11B</cross-reference> are a diagram and flowchart, respectively, depicting a process for finding and implementing a local service in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention. Recall that the term &ldquo;client&rdquo; is used herein to represent any consumer or user of a service, notably, many clients or other services, especially another service that builds upon more primitive services. A client may also be any application, software module or tool that utilizes the processes of a service, or alternatively, a client might refer to an end-user in the enterprise. A client perceives a need to invoke a process, but in accordance with an exemplary embodiment of the present invention, the client need not identify the service by its interface, as is common in the prior art. Instead, client <highlight><bold>1008</bold></highlight> might identify the service process by some service attribute that is important to the client. </paragraph>
<paragraph id="P-0257" lvl="0"><number>&lsqb;0257&rsqb;</number> Therefore, in accordance with an exemplary embodiment of the present invention, a client need not know the identity of the service it wishes to invoke or even where the service is running in the enterprise. Client <highlight><bold>1008</bold></highlight> uses the identical multicasting processes described above with respect to <cross-reference target="DRAWINGS">FIGS. 10A and 11A</cross-reference> to find registrar <highlight><bold>1014</bold></highlight>A (not shown). Thus, a NewWave client may come up cold and discover registrars and services in its local domain. The lookup process begins with client <highlight><bold>1008</bold></highlight> perusing one of the local domain registrar, here domain registrar <highlight><bold>1014</bold></highlight>A, for a needed service (step <highlight><bold>1122</bold></highlight>). Client <highlight><bold>1008</bold></highlight> searches local domain registrar <highlight><bold>1014</bold></highlight>A&apos;s lookup for services with service attributes matching those needed. Once a service is identified, client <highlight><bold>1008</bold></highlight> has no information whatsoever about the running service (e.g., its location, its configuration information, implementing code). Therefore, client <highlight><bold>1008</bold></highlight> retrieves, and registrar <highlight><bold>1014</bold></highlight>A returns, a proxy or object (Obj. in the Figure) to use for interacting with the selected service, service <highlight><bold>1010</bold></highlight>A (step <highlight><bold>1124</bold></highlight>). The code for the proxy is loaded remotely in the client space through its codebase. Thus, once implemented in the client, the proxy fetches service code at runtime from HTTP server <highlight><bold>1020</bold></highlight> using URL in the proxy&apos;s codebase (step <highlight><bold>1126</bold></highlight>). This code in invisible to client <highlight><bold>1008</bold></highlight>. Client <highlight><bold>1008</bold></highlight> uses a series of APIs to interact with the proxy, but the client actually intends to interact with a remote service (step <highlight><bold>1128</bold></highlight>). This does not always happen, even though the client <highlight><bold>1008</bold></highlight> &ldquo;thinks&rdquo; it is communicating with the service. In fact, several interactions are possible and each one is hidden from client <highlight><bold>1008</bold></highlight>. Client <highlight><bold>1008</bold></highlight> might actually be communicating client requests to remote service <highlight><bold>1010</bold></highlight>A as its thinks. Alternatively, client <highlight><bold>1008</bold></highlight> may be interacting only with the remotely-loaded service code and the code is locally performing logic to process the client requests in the client&apos;s own space. Finally, client <highlight><bold>1008</bold></highlight> may be communicating client requests to multiple remote services, via the service code, which may or may not be the service selected by client <highlight><bold>1008</bold></highlight>. This feature allows a client&apos;s requests to be processed anywhere and in any manner that is convenient to the enterprise. For example, since the client did not identify the service by a specific interface, the service may have been provided by any vendor that produces service with attributes that matches the client&apos;s needs. Alternatively, while the attributes listed with the registrar&apos;s lookup might remain constant, throughout the lifecycle of the service its functionally or resource requirements might change (i.e., a service that utilized a particular OEM&apos;s resource might switch to another&apos;s resource). Loading and scope parameters can be managed by hooks implemented in the service code that interact with different services based on dynamic parameters, such as the time of day, day of week, frequency of use, bus loading, service loading, history, complexity of the application running the service. </paragraph>
</section>
<section>
<heading lvl="1">Finding a Non-Local Service </heading>
<paragraph id="P-0258" lvl="0"><number>&lsqb;0258&rsqb;</number> One shortcoming of the prior art is that instances of services, other than infrastructure services, must be running in every domain that a consumer for that service is located. If not, the consumer will not be able to provide some aspect of its functionality. The other alternative is to eliminate logical domain demarcations and make all services available to all consumers in the enterprise. However, here bandwidth and directory listing become an impediment to efficiency. The present invention eliminates the need for either unnecessary duplication of service or eliminating logical domains by providing a mechanism for services and service consumers to see each other outside their own local domains. This has been referred to above as the &ldquo;two-hop&rdquo; process, a local hop, and a non-local or enterprise hop. <cross-reference target="DRAWINGS">FIGS. 10B and 11B</cross-reference> illustrate a mechanism for finding and implementing a service that is local (the local hop or first hop) while <cross-reference target="DRAWINGS">FIGS. 10C and 11C</cross-reference> illustrate a mechanism for finding and implementing a service that is not local (referred to alternatively as the non-local, enterprise or second hop) in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention. With respect to <cross-reference target="DRAWINGS">FIGS. 10C and 11C</cross-reference>, service <highlight><bold>1010</bold></highlight>A registers itself with domain registrar <highlight><bold>1014</bold></highlight>A in exactly the same manner as was described with respect to <cross-reference target="DRAWINGS">FIGS. 10A and 11A</cross-reference>, above. However, with respect to <cross-reference target="DRAWINGS">FIG. 10</cross-reference>C, client <highlight><bold>1006</bold></highlight>, located in domain <highlight><bold>1002</bold></highlight>B, must find and implement a service. The process begins with client <highlight><bold>1006</bold></highlight> searching local domain registrar <highlight><bold>1014</bold></highlight>B&apos;s lookup for a service that matches service attributes needed to accomplish some task (step <highlight><bold>1132</bold></highlight>). However, rather than finding a service, local domain registrar <highlight><bold>1014</bold></highlight>B returns a fault. In practice, whenever a service cannot be located in a client&apos;s local domain registrar, either the registrar or the client initiate a &ldquo;find&rdquo; service that will ultimately lead to finding a non-local service. However, client <highlight><bold>1006</bold></highlight> cannot see outside its local domain, so client <highlight><bold>1006</bold></highlight> must implement a local service for finding an enterprise level directory; that service is enterprise repository lookup <highlight><bold>1016</bold></highlight>B. Client <highlight><bold>1006</bold></highlight> looks up enterprise repository lookup service <highlight><bold>1016</bold></highlight>B in domain registrar <highlight><bold>1014</bold></highlight>B&apos;s lookup and returns a proxy for enterprise repository lookup <highlight><bold>1016</bold></highlight>B that is used to interact with the service (step <highlight><bold>1134</bold></highlight>). Client <highlight><bold>1006</bold></highlight> then interacts with enterprise repository lookup <highlight><bold>1016</bold></highlight>B, through its proxy, for finding the service it needs somewhere in the enterprise (step <highlight><bold>1136</bold></highlight>). </paragraph>
<paragraph id="P-0259" lvl="0"><number>&lsqb;0259&rsqb;</number> Here, enterprise repository lookup <highlight><bold>1016</bold></highlight>B searches for an enterprise repository from which to access its lookup and find a service (step <highlight><bold>1138</bold></highlight>). Enterprise repository lookup <highlight><bold>1016</bold></highlight>B finds enterprise repository <highlight><bold>1026</bold></highlight>, and then accesses its lookup for a service that matches the service attributes required by client <highlight><bold>1006</bold></highlight>. Upon finding a matching service, enterprise repository lookup <highlight><bold>1016</bold></highlight>B returns an address (URL address, host name or some other reference) for the non-local domain registrar with which the service is registered, domain registrar <highlight><bold>1014</bold></highlight>A. Next, enterprise repository lookup <highlight><bold>1016</bold></highlight>B attempts to find a service that matches the requirements of client <highlight><bold>1006</bold></highlight> in domain registrar <highlight><bold>1014</bold></highlight>A&apos;s lookup (step <highlight><bold>1140</bold></highlight>). Domain registrar <highlight><bold>1014</bold></highlight>A returns a proxy object (Obj. in the Figure) for matching service <highlight><bold>1010</bold></highlight>A to client <highlight><bold>1006</bold></highlight> (either directly or via enterprise repository lookup <highlight><bold>1016</bold></highlight>B) (step <highlight><bold>1142</bold></highlight>). The code for the proxy is loaded remotely in the client space through the proxy&apos;s codebase. Thus, once implemented in the client, the proxy fetches service code at runtime from HTTP server <highlight><bold>1020</bold></highlight> using URL in the proxy&apos;s codebase (step <highlight><bold>1144</bold></highlight>). Again, this code in invisible to client <highlight><bold>1006</bold></highlight>, and although client <highlight><bold>1006</bold></highlight> intends to interact with remote service <highlight><bold>1010</bold></highlight>A using APIs for the service, the code might redirect or locally process the calls (step <highlight><bold>1146</bold></highlight>). Thus, while client <highlight><bold>1006</bold></highlight> might intend to communicate with service <highlight><bold>1010</bold></highlight>A, the actual computations may be performed by logic in the service code locally, in the client&apos;s own space. Alternatively, client <highlight><bold>1006</bold></highlight>&apos;s request might be processed by remote service <highlight><bold>1010</bold></highlight>A, or by some combination of remote services such as service <highlight><bold>1010</bold></highlight>B (that is actually local to the client). </paragraph>
</section>
<section>
<heading lvl="1">Registrar Functionality </heading>
<paragraph id="P-0260" lvl="0"><number>&lsqb;0260&rsqb;</number> FIGS. <highlight><bold>12</bold></highlight>A-<highlight><bold>12</bold></highlight>C are flowcharts depicting the methodology implemented in registrar <highlight><bold>914</bold></highlight> for providing the four primary NW functions in accordance with exemplary embodiments of the present invention. It should be understood that these services (domain level listing/lookup for services; resource leasing; enterprise level service listing/lookup; and replication) are available or necessary for each embodiment of to the present invention. Because some of theses service are performed simultaneously, the four registrar services are illustrated in three separate flowcharts. <cross-reference target="DRAWINGS">FIG. 12A</cross-reference> is a flowchart depicting the process employed by the registrar for registering services in accordance with an exemplary embodiment of the present invention. <cross-reference target="DRAWINGS">FIG. 12B</cross-reference> is a flowchart depicting the process for enterprise leasing in accordance with an exemplary embodiment of the present invention, while <cross-reference target="DRAWINGS">FIG. 12C</cross-reference> is a flowchart depicting a process employed by the registrar for looking up a service in accordance with an exemplary embodiment of the present invention. </paragraph>
<paragraph id="P-0261" lvl="0"><number>&lsqb;0261&rsqb;</number> The service registration process begins with the registrar in a listening state, waiting for messages to arrive on the network. The signals may be generated by a service (including a container service) or a client (any consumer or user of a service) located in a local or non-local domain or in another registrar in the local domain, thus allowing for many possible permutations for incoming signals. With regard to the exemplary process, a ping( ) is handled first. If, at step <highlight><bold>1202</bold></highlight>, the registrar receives a ping( ), the registrar immediately returns (pong( )) its location to the service initiated the ping( ) (step <highlight><bold>1204</bold></highlight>). The registrar then waits for the service to return its registration information. If, at step <highlight><bold>1202</bold></highlight>, no ping( ) is received, the process flows to step <highlight><bold>1206</bold></highlight> where a check is made to determine if registration information has been received by the registrar. If the information has not been received by the registrar, the process iteratively reverts to step <highlight><bold>1202</bold></highlight> until registration information is received. Here it should be understood that the registrar is merely in a listening state, listening for events and messages that it must process. &lsqb;Checks <highlight><bold>1202</bold></highlight> and <highlight><bold>1206</bold></highlight> merely represent an iterative process used to simultaneously listen for both a ping( ) and registration information from a variety of services in the domain.&rsqb;</paragraph>
<paragraph id="P-0262" lvl="0"><number>&lsqb;0262&rsqb;</number> Returning to step <highlight><bold>1206</bold></highlight>, if the registrar receives registration information, the process continues to step <highlight><bold>1208</bold></highlight> where the registrar receives registration information about the service, which may include attributes for helping clients find services such as one or more name, domain-type information, implementation interfaces (i.e., what the service does for a client or a description of the service&apos;s functions). Additionally, the registration information may contain administrative information for manually administering the service, such as a display icon or a user interface object. Finally, the registration information may contain a serialized proxy object. It is possible for there to be cases where a service registers with only a URL or host name, but as a practical matter, most clients will need a proxy to interact with the service. Clients access the service with the proxy. The proxy could then contain any code which could be executed in a client environment before, after or instead of forwarding the request. The type of proxy, a smart proxy, may invoke services and functionality unknown to the clients. For example, the proxy might call more than one service for concurrently executing the client&apos;s request. In another example, the proxy might call for services executing ancillary functions unrelated to the client&apos;s service request (e.g., a client might intend to execute a network management function (profit center) and proxy calls billing services (cost center) to perform client and billing procedures that are ancillary to the client&apos;s request). The proxy also contains a codebase which is, at least, the URL address of an HTTP server which contains the implementation code for the proxy. That URL is used when the proxy is passed to a client to load the implementation code to the client, unbeknownst to the client. </paragraph>
<paragraph id="P-0263" lvl="0"><number>&lsqb;0263&rsqb;</number> Regardless of the type of proxy, the registrar may check the lookup for an instance of the service (step <highlight><bold>1210</bold></highlight>). In accordance with one embodiment of the present invention, the domain registrar will receive registration information only from services wishing to register themselves in the registrar&apos;s domain. However, in accordance with other embodiments, the domain registrar will receive registration information from another registrar in the local domain through a domain level replication process. The present flowchart envisions either eventuality. Here it should be understood the domain registrar of the present invention is extremely flexible. A domain registrar may communicate changes in its table to any service that is listening, for instance at the local domain to other registrar, re-start services, trawling services, scavenger daemons, enterprise repository lookup services and find services. </paragraph>
<paragraph id="P-0264" lvl="0"><number>&lsqb;0264&rsqb;</number> If the registration information is from another registrar in the local domain, it might be possible for a record of the service to already exist in the lookup table. This record might exist due to a previous replication from another third registrar, or from a re-start and re-registration where the service was not properly communicated to all of the other registrars throughout the local domain. While either of these cases is unlikely, it is good practice to continually monitor the registrar&apos;s lookup table for duplicative registrations. Therefore, if a copy of the service&apos;s registration information exists in the registrar&apos;s lookup table, it should be assumed that the service was re-started and the enterprise lease for the service should then be extended (step <highlight><bold>1224</bold></highlight>). However, with regard to enterprise leasing, it is possible for enterprise leases to be managed independently at each registrar in the local domain (assuming that more than one instance of a registrar exists), or managed at one registrar, typically the registrar that initially registered the service. That registrar would be expected to communicate the lookup information to all registrars throughout the domain. Thus, if the service registration information received by the current registrar is from another registrar in the domain and that registrar manages that service&apos;s enterprise lease, the process would then end without renewing the service&apos;s lease. </paragraph>
<paragraph id="P-0265" lvl="0"><number>&lsqb;0265&rsqb;</number> Returning to step <highlight><bold>1210</bold></highlight>, if the service is not listed in the registrar&apos;s lookup, the registrar makes an entry for the service in the lookup table (step <highlight><bold>1212</bold></highlight>). Typically, attribute information would be listed in the registrar&apos;s lookup table for easy access when looking up services corresponding to clients&apos; requests. Administrative information and the serialized proxy object may be stored separate from the attribute information in another location, but referenced from the attribute information for quick retrieval after a match has been found. Next, the registrar determines whether or not the registration information has been received directly from a newly-launched service or another registrar (step <highlight><bold>1214</bold></highlight>). If the registration information is not directly from the service, the registrar then creates an enterprise lease for the newly-registered service, assuming that each registrar in the domain manages its own leases (step <highlight><bold>1224</bold></highlight>). The process then ends. </paragraph>
<paragraph id="P-0266" lvl="0"><number>&lsqb;0266&rsqb;</number> Returning to step <highlight><bold>1214</bold></highlight>, if the information has been received from the service directly, it is the responsibility of the registrar to replicate the information in each of the registrars in the domain. In that case, the registrar must update the enterprise repository with registration information from each service wishing to be locally visible in only the local domain (step <highlight><bold>1216</bold></highlight>). Next, the registrar determines whether the service intends to be visible in only the local domain (step <highlight><bold>1218</bold></highlight>). If so, the process reverts to step <highlight><bold>1224</bold></highlight> where the registrar creates an enterprise lease for the service and then the process ends. Alternatively, at step <highlight><bold>1218</bold></highlight>, if the service intends to be non-locally visible (i.e., in the enterprise, outside the local domain), the registrar passes the registration information to the enterprise repository. As discussed above, finding the location of the enterprise registrar may be performed internally, inside the registrar, or externally via an enterprise repository lookup. If registering with the enterprise repository is handled internally, the registrar merely looks up the enterprise repository&apos;s location (step <highlight><bold>1220</bold></highlight>) and passes the device&apos;s registration information to the repository step (step <highlight><bold>1222</bold></highlight>). Otherwise, the registrar looks up the location of the enterprise repository lookup and passes the device&apos;s registration information to the enterprise repository lookup (step <highlight><bold>1220</bold></highlight>), which in turn passes the device&apos;s registration information to the repository (step <highlight><bold>1222</bold></highlight>). </paragraph>
<paragraph id="P-0267" lvl="0"><number>&lsqb;0267&rsqb;</number> Two things should be made clear here. First, it is apparent that creating an entirely independent lookup just for finding the enterprise repository is counterproductive. That is normally true except in the present case where technology exists to perform some of the registrar&apos;s functionality that is usable, but not easily adapted, from a local domain-type environment to an enterprise consisting of multiple domains. One such technology is Jini technology that performs certain registrar functions at a domain level, but is not suited to multi-domain functionality. Secondly, enterprise registration might not be synonymous with domain registration. In some situations it might be acceptable to merely pass the location of the registrar to the enterprise repository. Whenever a client cannot find a service in its own domain and hops to the enterprise repository, the client can pick up the host name, or URL, for a registrar in the service&apos;s domain. From there the client can retrieve the serialized proxy in the same manner as if the client had retrieved it from a local registrar. Moreover, it might be that all services have an entry in the enterprise repository, even though some are not visible in non-local domains because it is expected that administrative functions will almost always be performed at the enterprise level. Administrators can then access administrative information, icons, interface and other service tools for services that are not visible in the non-local domains (enterprise) which is especially important for launching a service. Since containers are service, there might be a case where the intent is not to be visible in the enterprise, but be available for administrative use (i.e., launching a new service). </paragraph>
<paragraph id="P-0268" lvl="0"><number>&lsqb;0268&rsqb;</number> Regardless of whether or not an enterprise repository lookup is used, the registrar must create a lease for the newly-started service (step <highlight><bold>1224</bold></highlight>) prior to ending the process. </paragraph>
<paragraph id="P-0269" lvl="0"><number>&lsqb;0269&rsqb;</number> Regarding <cross-reference target="DRAWINGS">FIG. 12B, a</cross-reference> flowchart depicts a process for managing enterprise leases in accordance with a preferred embodiment of the present invention. Every service running in any of the enterprise&apos;s domains must have a lease. When the registrar accepts a service registration, it issues a lease for the registration. The service must periodically renew the lease or the registrar will dispose of the registration, thus allowing the registrar to remain stable. If a service goes away or is inoperative, the lease will not be renewed and the registrar will eventually clean up its tables. The principle of lease management is a fundamental principle of the NW infrastructure and is used throughout the GIB. Any GIB service which maintains state about other services or clients should implement a leasing scheme to keep its state clean. Services typically run a background thread that periodically wakes up to perform the lease-renewal chore. A service remains registered only so long as it keeps expressing interest via lease renewal. The renewal is passed, if necessary, from the registering registrar to other local registrars or to the enterprise repository. However, the task of lease maintenance might be left to the registering registrar and renewals are replicated around the enterprise. </paragraph>
<paragraph id="P-0270" lvl="0"><number>&lsqb;0270&rsqb;</number> Lease maintenance, as depicted in the flowchart, is a continuous process that always reverts to an enterprise lease monitoring state (step <highlight><bold>1230</bold></highlight>). Leases remain valid for a predetermined amount of time. That duration of time may be fixed or specifiable by the service making the enterprise lease. Therefore, the registrar must have a sense of time from which to make expiration determinations, for instance, from outputs from the internal CPU oscillator clock. Whenever a lease is created, a counter may be initialized that, based on the duration time of the lease, counts down to a lease expiration event. The lease expiration event may be circumvented by the service renewing the enterprise lease anytime prior to an expiration event. Therefore, the registrar is cognizant of lease creation or extension events and lease expiration events. If, at step <highlight><bold>1232</bold></highlight>, the registrar detects an enterprise leasing or renewal event, the registrar must first identify the service associated with the event (step <highlight><bold>1234</bold></highlight>). Next, the registrar creates or extends the service&apos;s enterprise lease by postponing the lease expiration event for a period of time equal to the preset lease duration (step <highlight><bold>1238</bold></highlight>). The process may end here or in accordance with another exemplary embodiment of the present invention, the registrar may determine if the container running the service is being fully utilized (i.e., the threshold amount of threads are currently being processed (step <highlight><bold>1240</bold></highlight>)). Recall that generic service containers are multi-threaded processes allowing many separate service instances to be run in their own threads. However, if all of the container&apos;s threads are used by services, the container cannot support another service and a load error will occur. A threshold number of services may be defined for a container and, whenever the number of services being run exceeds that threshold, the container service simply de-lists itself until some services&apos; leases expire. Thus, if the threshold is not exceeded by the addition of the new enterprise lease, the process reverts to step <highlight><bold>1230</bold></highlight> where the registrar continues to monitor the enterprise leases. Conversely, if the threshold number of services are now being run in the container, the container can no longer support new services, so the registrar notifies the enterprise repository to make the container service invisible to potential clients (step <highlight><bold>1242</bold></highlight>). It is expected that, in most instances, container services are discovered at the enterprise level most likely by an administrator; thus, the registration must be hidden at least the enterprise level. However, it is also possible that the container service may be discovered at the local domain level so each registration instance of the container service in the local registrars might also be hidden from view, depending upon the discovery process for containers. Once the fully-loaded container service is hidden, the process reverts to step <highlight><bold>1230</bold></highlight>. </paragraph>
<paragraph id="P-0271" lvl="0"><number>&lsqb;0271&rsqb;</number> The second type event being watched for by the registrar is a lease expiration event (step <highlight><bold>1244</bold></highlight>). If one is detected, the registrar identifies the service whose enterprise lease expired (step <highlight><bold>1246</bold></highlight>). Next, in accordance with an alternative exemplary embodiment of the present invention, the registrar determines if the container service is running at threshold capacity (step <highlight><bold>1248</bold></highlight>). If so, the registrar notifies the enterprise repository to unhide the container service and make the container visible to enterprise clients looking for a service (step <highlight><bold>1250</bold></highlight>). At this point, the registrar&apos;s listing of the container service must also be made visible if the container service was hidden in the registrar&apos;s lookup. However, the listing of a service whose lease expired must be removed from the lookup (step <highlight><bold>1252</bold></highlight>) and that removal be replicated to the other registrars in the local domain (step <highlight><bold>1254</bold></highlight>). Finally, the registrar must notify the enterprise repository that the service&apos;s lease expired and the service&apos;s registration information be removed from the enterprise repository (step <highlight><bold>1256</bold></highlight>). The process then reverts to step <highlight><bold>1230</bold></highlight>. </paragraph>
<paragraph id="P-0272" lvl="0"><number>&lsqb;0272&rsqb;</number> Regarding <cross-reference target="DRAWINGS">FIG. 12C, a</cross-reference> flowchart depicts a process employed by a registrar in response to a &ldquo;find&rdquo; request from a client in accordance with a preferred embodiment of the present invention. The present invention allows a service to register itself with a local registrar by providing service attributes in the registration to make it easier for clients to find and interact with the service. These attributes may include one or more names, domain-type information and/or the interfaces which the service implements. &ldquo;Finding&rdquo; a service is potentially a two-hop process for a client, a local hop; and if a suitable service is not found in the local domain, a non-local hop. Registrars store all attribute information for each service running in their respective local domain for finding a service, and a proxy for each running service is passed to a requesting client to use for interacting with the service. While the registrar performs certain functionality associated with finding a service in its local domain, registrars do not provide attribute information for each service running in all non-local domains (i.e., the enterprise). The enterprise repository provides a requesting client with a mechanism for finding a needed service in a non-local domain by listing all running services in the enterprise. A client needing a service that is not running in its local domain can access the enterprise repository for the location of a registrar having a running copy of the service. In accordance with one embodiment of the present invention, the client can then go to that registrar for the service&apos;s proxy and interact with the service. In accordance with another embodiment of the present invention, the enterprise repository also maintains a proxy for each running service in the enterprise so the client can get the proxy directly from the enterprise repository rather than going to the service&apos;s registrar. </paragraph>
<paragraph id="P-0273" lvl="0"><number>&lsqb;0273&rsqb;</number> Turning now to <cross-reference target="DRAWINGS">FIG. 12</cross-reference>C, the process begins with a registrar receiving a &ldquo;find&rdquo; request for a particular service (step <highlight><bold>1270</bold></highlight>). It should be understood that the client may be in the registrar&apos;s local domain and, in fact, with respect to the first, or local, hop the client is in the registrar&apos;s local domain. However, in accordance with some embodiments of the present invention, the &ldquo;find&rdquo; request may have been referred to the present registrar by an enterprise repository. The registrar then checks its lookup for service using information in the request, such as service name or any other attribute information in the request (step <highlight><bold>1272</bold></highlight>). Next, the registrar decides whether or not the service is running in the local domain (i. e., if there is a match between the attribute information contained in the &ldquo;find&rdquo; request and the service attributes contained in the registrar&apos;s lookup table (step <highlight><bold>1274</bold></highlight>)). On the first hop, the service needed by the client may or may not be found in the local domain, and thus registered with the registrar and listed in the lookup table. It is, however, expected that administrators will attempt to locate services proximate to clients that utilize those services; therefore, in many cases the service needed by the client will be found on the first hop in the client&apos;s local domain. With respect to the present flowchart, the client may not be local to the registrar, but might have been referred to the present registrar by the enterprise repository. In that case, it is highly unlikely that the service will not be found in the registrar lookup table because the present registrar registers the service with the enterprise repository. In any case, if the service is found in the registrar&apos;s lookup, the registrar gets the proxy object for the service from a storage location associated with the lookup table (step <highlight><bold>1276</bold></highlight>) and returns the proxy to the requesting client (step <highlight><bold>1278</bold></highlight>). The process then ends. </paragraph>
<paragraph id="P-0274" lvl="0"><number>&lsqb;0274&rsqb;</number> Returning to step <highlight><bold>1274</bold></highlight>, if the service cannot be found by the registrar in its lookup table, then the registrar must pass the client request on to another registrar, albeit indirectly, in which the service is registered. Here, two alternate embodiments are possible. The first requires that the registrar track the location of at least one enterprise repository, while the second embodiment involves the registrar merely pointing to an enterprise repository lookup containing the location of an enterprise repository. As discussed above, the alternate embodiments are brought about due to technologies for performing some of the registrar&apos;s functionality actually existing, and due to the varying ease in which these technologies may be transformed from a domain-type environment to an enterprise environment consisting of multiple domains. Regardless, if the service information cannot be found in the registrar&apos;s lookup, the registrar must get next hop information for the client (step <highlight><bold>1280</bold></highlight>). The next hop information may be either the location of the enterprise repository itself or might instead be the location of the enterprise repository lookup. In that case, the location of the enterprise repository must be acquired from the enterprise repository lookup. In either case, the location of the enterprise repository is found and passed to the client (step <highlight><bold>1282</bold></highlight>) and the process ends. Alternatively, the registrar passes the client&apos;s request directly to either the enterprise repository lookup or the enterprise repository to checks it records for a service that is compatible with the client&apos;s request. Once found, the client request would then be passed to the service&apos;s registrar and the present process would return to step <highlight><bold>1270</bold></highlight> for the new registrar. </paragraph>
</section>
<section>
<heading lvl="1">Transaction Processing </heading>
<paragraph id="P-0275" lvl="0"><number>&lsqb;0275&rsqb;</number> With regard to FIGS. <highlight><bold>13</bold></highlight>A-<highlight><bold>13</bold></highlight>B, a flowchart depicting the transaction process employed by the transaction manager is illustrated in accordance with a preferred embodiment of the present invention. The process begins with the client sending a transaction request to the transaction manager (step <highlight><bold>1302</bold></highlight>). The transaction manager may be any of transaction managers <highlight><bold>912</bold></highlight>A<highlight><bold>1</bold></highlight>-<highlight><bold>912</bold></highlight>AN depicted in <cross-reference target="DRAWINGS">FIG. 9</cross-reference> and the client may be one of the services being run in containers <highlight><bold>906</bold></highlight>. Upon receiving the request, the transaction manager creates a transaction for the client, issues an enterprise lease for the transaction, and then returns the transaction content to the client as a transaction object (TXN) (step <highlight><bold>1304</bold></highlight>). The transaction manager will manage the transaction only as long as a valid enterprise lease exists for the transaction. Should the enterprise lease expire, the transaction manager will clean up the client&apos;s transaction. By using the enterprise leasing concept, the client need not notify the transaction manager in case of a transaction failure. Should the client not be able to complete a transaction, the transaction manager automatically cleans up after the enterprise lease expires. However, if the transaction is proceeding at a slower than expected pace, the client can always renew the enterprise lease with the transaction manager. The enterprise lease maintenance process will not be further described for the transaction manager as the process has been fully described for the registrar with respect to <cross-reference target="DRAWINGS">FIG. 11B</cross-reference>. </paragraph>
<paragraph id="P-0276" lvl="0"><number>&lsqb;0276&rsqb;</number> Returning to <cross-reference target="DRAWINGS">FIG. 13</cross-reference>A, the client then requests various resources to join the transaction by passing the TXN to a resource in a request to join the transaction (step <highlight><bold>1306</bold></highlight>). Recall that the client may be communicating with resources via traditional resource managers or might instead be communicating with NW-enable devices and network elements that are managing a resource. Next, if the resource manager notifies the client that it intends to join the transaction, the process flows to step <highlight><bold>1308</bold></highlight> where the resource manager also passes a participant interface to the transaction manager (step <highlight><bold>1314</bold></highlight>). The client then determines whether or not another resource is needed in the transaction (step <highlight><bold>1316</bold></highlight>). If another resource is necessary, the process returns to step <highlight><bold>1306</bold></highlight> where the client invites another resource to join the transaction and the process continues as described immediately above. If, on the other hand, another resource is not necessary for the transaction and the client has joined the necessary resources in the transaction, the client makes a &ldquo;commit&rdquo; call to the transaction manager (step <highlight><bold>1318</bold></highlight>). At that point, the transaction manger implements the two-phase commit process which is invoked by the transaction manager on all participants joined in the current transaction (step <highlight><bold>1318</bold></highlight>). </paragraph>
<paragraph id="P-0277" lvl="0"><number>&lsqb;0277&rsqb;</number> Returning to step <highlight><bold>1308</bold></highlight>, should the resource manager not join the transaction, either expressly or by failing to respond to the client&apos;s request, the client may attempt to find another resource (step <highlight><bold>1312</bold></highlight>). The process implemented by the client for finding a resource is similar to that described above with respect to <cross-reference target="DRAWINGS">FIG. 10</cross-reference> for finding a service and will be discussed further with respect to the DataBus. Should the client find another resource that is suitable for the transaction, the process reverts to step <highlight><bold>1306</bold></highlight> and continues as described above. However, if the client cannot find a suitable resource to transact with, the transaction ends. At some point, the transaction&apos;s enterprise lease expires with the transaction manager and the transaction manager cleans up itself. </paragraph>
<paragraph id="P-0278" lvl="0"><number>&lsqb;0278&rsqb;</number> Turning now to <cross-reference target="DRAWINGS">FIG. 13</cross-reference>B, the two-phase commit process implemented by the transaction manager is described. After the client makes a &ldquo;commit&rdquo; call to the transaction manager via the TXN object, the transaction manager makes a &ldquo;prepare&rdquo; call to all participants (resource managers) that have joined the transaction with the client (step <highlight><bold>1330</bold></highlight>). If all participants accept the &ldquo;prepare&rdquo; call, then the transaction manager issues a &ldquo;commit&rdquo; call to all participants (step <highlight><bold>1334</bold></highlight>). Here again, the participant may accept the call or abort the transaction (step <highlight><bold>1336</bold></highlight>). Should every participant acknowledge that it accepts the commit, the participants then perform the requested transaction and the transaction manager notifies the client that the transaction has been accomplished (step <highlight><bold>1338</bold></highlight>), and the process ends. However, at times a participant cannot complete a transaction, thus returning to steps <highlight><bold>1332</bold></highlight> and <highlight><bold>1336</bold></highlight>. At any time during the two-phase commit process a participant aborts the transaction, the client is notified of the failure (step <highlight><bold>1340</bold></highlight>) and the transaction is rolled back at all of the participants due to the failure (step <highlight><bold>1342</bold></highlight>). Roll back is a mechanism for returning participants to the state in which they each were prior to the participant accepting the transaction request. Rolling the transaction back ensures that no participant has partially completed the transaction. </paragraph>
</section>
<section>
<heading lvl="1">Service Failures and Self-Healing Services </heading>
<paragraph id="P-0279" lvl="0"><number>&lsqb;0279&rsqb;</number> It is a fundamental principle of NewWave that it is a normal occurrence for the operating environment to be unstable for a time, but that it must return to stability independently. Maintaining a healthy environment depends first on finding out the health of the environment. As such, two techniques are used. The first involves the reporting requirements of all services. All NW service must answer ping( ) and healthCheck( ) requests. The ping( ) only establishes that the service is alive. The healthCheck( ) establishes that the service is alive and is able to perform all of its required functions. This includes accessing any needed resources, such as a database and a transaction manager. It also includes the ability to perform a task in a predetermined time period, depending on the task. </paragraph>
<paragraph id="P-0280" lvl="0"><number>&lsqb;0280&rsqb;</number> Enterprise leasing provides information to the registrar about the health of the services registered in its tables. If a lease is renewed, the registrar rightly assumes that it is alive, but not its condition. If the lease expires, the registrar assumes that the service is no longer functioning. This information is used to keep the registrar&apos;s tables clean and avoid giving out any stale references. The registrar will also notify any interested parties when a change is made to its tables. Certain NewWave infrastructure services monitor the registrar and use lease expirations as information about the state of the environment. Different types of monitoring services take different actions, such as restarting services or replicating registrations outside of the domain of the registrar. </paragraph>
<paragraph id="P-0281" lvl="0"><number>&lsqb;0281&rsqb;</number> Remote code loading, remote configuration and remote launching of services make easier the task of keeping the NewWave infrastructure and GIB running all of its services. When a service abnormally goes down, it must be restarted without human intervention if at all possible. This is done using an Arch Angel concept&mdash;a number of agents whose job it is to watch other services, know what services should be running, and start them if they are not running. The job of the Arch Angel is made easier because services have limited constraints on where they run&mdash;if one server goes down, the services that were running on it can usually be immediately re-homed on another server. However, some services have special requirements, local resources and the like. </paragraph>
<paragraph id="P-0282" lvl="0"><number>&lsqb;0282&rsqb;</number> As discussed above, some services require special resources and find it necessary to maintain mirrored state information in case of a service failure. Some services cannot be re-homed on a different service because those services have some state that must be restored when restarted. If a restarted service must re-establish the previous state, then that state information must be stored or mirrored in a place that would not go away if the server the service is running fails (i.e., on a non-local resource for instance). One solution is using virtual bulletin boards that allocate space to running application or service. State information is updated to a service&apos;s space until needed to recover from a failure. One approach for maintaining this type of private state managed by a service and another is for maintaining state that is shared by multiple services. </paragraph>
<paragraph id="P-0283" lvl="0"><number>&lsqb;0283&rsqb;</number> When a service goes away, it is not enough to just restart it. This may restore the services to the ecosystem, but not the interconnectedness of the ecosystem. There will still be stale references to the old service. So, even if all of the services are running, the NewWave environment may still be broken because collaborative services can no longer get to each other. A simple and effective way to handle this problem is by means of smart proxies, which have been discussed above. Recall that the proxy used to access a service from a client (which may be another service) is provided by the service itself. A proxy can encapsulate any code that can be executed in the client space. Self-healing services provide proxies which handle connection-related errors and re-find their respective target services, and finally re-execute the previous request. In this way, when a service is restarted, the stale references will eventually heal themselves. </paragraph>
<paragraph id="P-0284" lvl="0"><number>&lsqb;0284&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a diagram depicting a service failure and re-homing the service to a different server and further depicting self-healing a proxy reference using a smart proxy in a global ecosystem of interrelated services in accordance with an exemplary embodiment of the present invention, and further illustrates self-healing a proxy reference using a smart proxy. <cross-reference target="DRAWINGS">FIG. 15A</cross-reference> is a flowchart depicting a service restarting process in a global ecosystem of interrelated services in accordance with the present invention, while <cross-reference target="DRAWINGS">FIG. 15B</cross-reference> is a flowchart depicting a process for self-healing stale references using a smart proxy in accordance with the present invention. With respect to <cross-reference target="DRAWINGS">FIGS. 14 and 15</cross-reference>A, a monitoring service known as an &ldquo;Arch Angel&rdquo; is configured with information about the services for which it has the responsibility of monitoring. At a minimum, Arch Angel <highlight><bold>1412</bold></highlight> must know the identity of the services being monitored, their VM container requirements (what type of local resources, server platform, etc.), and the location of their service code (an address or reference for the remote HTTP server holding the service&apos;s code). Arch Angel <highlight><bold>1412</bold></highlight> is charged with attempting to restart failed services, ones that die an unnatural death for any reason. However, when a service&apos;s natural life is over, it will go away gracefully, executing normal shutdown procedures. In this case, Arch Angel <highlight><bold>1412</bold></highlight> recognizes that the service must not be restarted. One mechanism used to tell abnormal service failures from normal shutdowns is through enterprise leasing. A lease expiration is considered an abnormal event in the life of a service so if one occurs, the service must be re-started to bring the ecosystem back in balance. </paragraph>
<paragraph id="P-0285" lvl="0"><number>&lsqb;0285&rsqb;</number> Turning now to <cross-reference target="DRAWINGS">FIG. 15</cross-reference>A, the process begins with Arch Angel <highlight><bold>1412</bold></highlight> performing an iterative check to determine if a service, service <highlight><bold>1406</bold></highlight> for instance, has failed (step <highlight><bold>1502</bold></highlight>). Recall that this check may be precipitated by a variety of events, or even combinations of events. For example, a lease expiration where registrar <highlight><bold>1410</bold></highlight> notifies, or publishes, a monitor service of lease expiration. Alternatively, service <highlight><bold>1406</bold></highlight> might fail a healthCheck( ) request while still maintaining its lease(s). Regardless, if the service failure metric is exceeded, service <highlight><bold>1406</bold></highlight> must be restarted and its previous registrations cleaned up. In that case, Arch Angel <highlight><bold>1412</bold></highlight> identifies the service that has failed and checks its lookup for any VM container requirements required by the service (step <highlight><bold>1504</bold></highlight>). Next, Arch Angel <highlight><bold>1412</bold></highlight> must find a suitable container for service <highlight><bold>1406</bold></highlight> and so it accesses domain registrar <highlight><bold>1410</bold></highlight>&apos;s lookup for VM service container service attributes (step <highlight><bold>1506</bold></highlight>). Once a VM container is found that matches the service container attribute needs of service <highlight><bold>1406</bold></highlight>, Arch Angel <highlight><bold>1412</bold></highlight> retrieves a reference to that container (URL address, etc.). Next, Arch Angel <highlight><bold>1412</bold></highlight> must lookup the URL for the HTTP server with service <highlight><bold>1404</bold></highlight>&apos;s service code (step <highlight><bold>1508</bold></highlight>). Arch Angel <highlight><bold>1412</bold></highlight> then re-launches service <highlight><bold>1406</bold></highlight> by passing the service code server&apos;s URL out to the container service using the container&apos;s URL (step <highlight><bold>1510</bold></highlight>). This is exactly the process employed for manually launching a service for an administrator&apos;s console described above with respect to <cross-reference target="DRAWINGS">FIG. 11A</cross-reference>. The service can then register itself as shown above with respect to <cross-reference target="DRAWINGS">FIG. 11A</cross-reference> for step <highlight><bold>1106</bold></highlight>. However, in the case of service <highlight><bold>1406</bold></highlight> being restarted prior to a lease expiration, such as might occur when using the healthCheck( ) request, a number of stale references might still reside in registrar <highlight><bold>1410</bold></highlight> as well as the enterprise repositories, assuming that service <highlight><bold>1406</bold></highlight> was registered globally. Therefore, once service <highlight><bold>1406</bold></highlight> has been successfully re-started, Arch Angel <highlight><bold>1412</bold></highlight> can issue a shutdown request that appears to the registrar and enterprise repository that service <highlight><bold>1406</bold></highlight> has executed its normal shutdown procedure. Thus, registrar <highlight><bold>1410</bold></highlight> and the enterprise repositories can clean their respective lookups of stale references to service <highlight><bold>1406</bold></highlight> in its previous VM container. </paragraph>
<paragraph id="P-0286" lvl="0"><number>&lsqb;0286&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15B</cross-reference> is a flowchart depicting a process using smart proxy for the self-healing of stale references in accordance with the present invention. This process is performed entirely by the service&apos;s smart proxy that was passed to a client during lookup, thus the process is actually performed internal to the client (unbeknownst to the client). The process begins with smart proxy <highlight><bold>1420</bold></highlight> performing an iterative check to determine if requests to a service, service <highlight><bold>1406</bold></highlight> for instance, result in a stale exception (step <highlight><bold>1522</bold></highlight>). If not, the check continues to iterate through. If a stale exception is returned, then smart proxy <highlight><bold>1420</bold></highlight> attempts to relocate service <highlight><bold>1460</bold></highlight> in its new container (step <highlight><bold>1524</bold></highlight>). Smart proxy <highlight><bold>1420</bold></highlight> looks up service <highlight><bold>14056</bold></highlight> in registrar <highlight><bold>1410</bold></highlight> for an updated URL to service <highlight><bold>1406</bold></highlight>&apos;s location. However, merely because the service is not responding to requests from client <highlight><bold>1408</bold></highlight> does not necessarily mean that service <highlight><bold>1406</bold></highlight> has been restarted elsewhere in another VM container. If service <highlight><bold>1406</bold></highlight> is not listed in registrar <highlight><bold>1410</bold></highlight>, then smart proxy <highlight><bold>1420</bold></highlight> will periodically recheck registrar <highlight><bold>1410</bold></highlight>&apos;s lookup for service <highlight><bold>1406</bold></highlight>&apos;s new URL, provided the rechecking process does not timeout (step <highlight><bold>1528</bold></highlight>). If the process times out prior to relocating the service, the self-healing process ends and client <highlight><bold>1408</bold></highlight> will be forced to roll back its operation to whatever state is necessary for finding and using a different service. Returning to step <highlight><bold>1526</bold></highlight>, once service <highlight><bold>1406</bold></highlight> has been looked up in registrar <highlight><bold>1410</bold></highlight>&apos;s lookup, smart proxy reissues the request to newly restarted service <highlight><bold>1406</bold></highlight> in its new VM container. Once service <highlight><bold>1406</bold></highlight> responds, the stale reference is healed and the process ends. </paragraph>
</section>
<section>
<heading lvl="1">DataBus </heading>
<paragraph id="P-0287" lvl="0"><number>&lsqb;0287&rsqb;</number> The traditional approach to data management in an enterprise was that the applications own the data. Independent stovepipe applications are based on this approach as depicted above in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. In this approach, data scaled well (divide and conquer), but also led to incoherent data images due to each application having its own, independent view of the data. Additionally, the stovepipe approach limits an enterprise&apos;s ability to integrate business, as it tends to wall the enterprise into the current model. </paragraph>
<paragraph id="P-0288" lvl="0"><number>&lsqb;0288&rsqb;</number> A second approach to data management in an enterprise recognized that new applications invariably need data from older applications, thus data was replicated between applications in a peer-to-peer fashion. The peer-to-peer data transfer approach is depicted above in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>A and is often considered a type of Enterprise Application Integration (EAI). Because each application has an opportunity to access more than its traditionally owned data, this approach facilitates a more &ldquo;enterprise view&rdquo; of the data; however, transferring the data from its current location to where it is needed often makes it problematic. Applications using this approach often have to devote time and resources to wait for necessary data and/or caches for temporarily storing requested data during an execution cycle. Moreover, data replication approaches often require a spaghetti of data feeds between peers to effectively and harmoniously replicate data. </paragraph>
<paragraph id="P-0289" lvl="0"><number>&lsqb;0289&rsqb;</number> A final approach to data management in an enterprise involved another EAI between stovepipe applications and warehousing application data to make enterprise data centrally accessible to all enterprise clients. The EAI approach to data management using a hub and spoke configuration is depicted above in <cross-reference target="DRAWINGS">FIG. 1B</cross-reference>. Application integration, using the hub and spoke configuration of feeds, is a mechanism for providing cleaner data transfer than peer-to-peer (i.e., often less spaghetti), but it still emphasizes shuttling data around the enterprise to finally end up in an enterprise data warehouse. This might be the preferred data management mechanism for integrating disparate legacy systems into an enterprise without wholesale migration to a standard enterprise system. Because the enterprise data is ultimately warehoused, the enterprise controls the data and access to it. The enterprise determines the mode of data access and handles security. While the hub and spoke EAI approach may be the best and most widespread data management approach in use, it still suffers from having duplicative data between stovepipe applications and the enterprise warehouse and bottlenecking at the hub. Improvements in the hub and spoke approach include federated architectures wherein the applications are able to statically connect to a single integration server or hub and to exchange information with each other. While the bottlenecking problem has been somewhat alleviated, data transfer is much less clean because an application can transact only with a single hub due to the constraint that each application&apos;s messages must be processed on its own hub. Thus, there is more spaghetti between hubs to get all application data to a central enterprise warehouse, a &ldquo;spaghetti data warehouse.&rdquo;</paragraph>
<paragraph id="P-0290" lvl="0"><number>&lsqb;0290&rsqb;</number> As briefly discussed above, the DataBus of the present invention provides a mechanism for alleviating the shortcomings in the prior art by decoupling data from the services and applications that historically owned the data. The DataBus makes enterprise data available to all authorized users without consulting with an &ldquo;owner&rdquo; application. The DataBus is a data management architecture for the NewWave service platform that presents an architecture for creating a consistent, enterprise-wide data persistence layer which allows clients to access shared enterprise data. The DataBus achieves this enterprise-wide look by decoupling shared enterprise data from specific applications (breaking down the stovepipes) and opening up the data layer to across-the-enterprise access (given proper authorization). The DataBus architecture is designed from the ground up for global scalability and accommodation of evolving business data models in a highly-distributed physical deployment. Scaling is realized predominantly through the partitioning, while individual partitions are mapped to logical data domains that are defined along more relevant dimensions than entity-type dimensions (e.g., geography, line of business, etc.), thus cutting across traditional entity boundaries. </paragraph>
<paragraph id="P-0291" lvl="0"><number>&lsqb;0291&rsqb;</number> Central to the DataBus data model is the notion that a data layer represents a shared asset of the corporation that is decoupled from the separate production applications requiring access to this data. This view represents a significant departure from currently dominant models where vertical applications have ownership of data described above. In accordance with the DataBus Architecture, a clean separation is made between applications (i.e., the dynamic elements of the system, which carry out use-cases) and the data resources or persistent business objects (i.e., somewhat static, passive elements) that are accessed by those applications. The data tier is an horizontal substrate underlying any and all corporate applications requiring access to that data. Where appropriate, there are, of course, exceptions to allow private data that is truly isolated to specific applications. </paragraph>
<paragraph id="P-0292" lvl="0"><number>&lsqb;0292&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a diagram depicting a conceptual realization of the DataBus two-tier infrastructure concept for mediating data transactions and an enterprise-wide data persistence layer which allows clients to access shared enterprise data in accordance with an exemplary embodiment of the present invention. Briefly, requests for data made by applications or components from the underlying (database) storage technology are mediated in the data mediation layer, the one, pandemic DataBus. The mediation layer further provides uniform, ubiquitous access to corporately-controlled business objects, such as customer, product, service or device, by dissociating data from applications so that no service or product application controls and rations data needed by another application. In the place of application ownership, persistent objects and data are created and a steward entity is given the responsibility for owning and controlling the persistence objects and data. Finally, the DataBus provides shared copies of data and manages updates to data with globally-guaranteed transactions. </paragraph>
<paragraph id="P-0293" lvl="0"><number>&lsqb;0293&rsqb;</number> Transaction management, and the role of the transaction manager, has been described above with respect to <cross-reference target="DRAWINGS">FIGS. 13A and 13B</cross-reference> which describe the two-phase commitment process and roll back contingency if all parties do not successfully implement their part of the required change. However, these functions are implemented under a process model used by applications for changing data and data associations. </paragraph>
<paragraph id="P-0294" lvl="0"><number>&lsqb;0294&rsqb;</number> The DataBus comprises a data layer with an object-oriented interface. All interactions with data are through methods on objects. If relational technology is used for actual backing store, then this implies that the data layer is actually two distinct tiers: 1) a persistent business object layer; and 2) the underlying relational database which stores the state of these business objects. If object-oriented database technology is used, the data layer might be realized as a single tier. In any case, we assume throughout this document that a distributed object-oriented approach is applied to the entire architecture, even if the wording of this document sometimes lapses into database terminology. </paragraph>
<paragraph id="P-0295" lvl="0"><number>&lsqb;0295&rsqb;</number> Any services contemplated for creating or retrieving instances of business objects must observe some fundamental principles. First, there is the notion that entity types (the nodes in an E-R diagram discussed in detail below) are deployed in runtime container processes. All access to persistent business object data is effected through remote calls to the object interface of the entity instances that are managed by the container. The entity instances are simply Java objects which conform to some strict conventions and live in a container environment. The entity instances themselves will interact with the backing data store, typically via Structured Query Language (SQL) calls to a Relational DataBase Management System (RDBMS). However, all application interaction with data is mediated through the instances, thus applications do not directly interact with the data store level of the DataBus. All entity instances must offer both a home interface and an instance interface. The home interface supports class-level functions, such as creation and initialization of new entity instances; finders allow query for existing entity instances matching specified criteria and methods for permanently deleting existing entities from persistent storage. Finally, the containers should have a sophisticated model for caching entity instances in-core, managing the life-cycle of cached instances as they move in and out of cache and are created and destroyed, management of concurrent access by multiple users, and management of security (access control) and transactions. </paragraph>
<paragraph id="P-0296" lvl="0"><number>&lsqb;0296&rsqb;</number> All application interactions with entity instances, as well as interactions between entity instances, transpire via remote method calls. In other words, the data objects are fixed in space, and interaction with them occurs over the wire. However, there are situations where it is more desirable to move data out to clients for a local style of interaction. Thus, the remote access mode of data access is supplemented with a mode of access entailing interaction with a local data copy. </paragraph>
<paragraph id="P-0297" lvl="0"><number>&lsqb;0297&rsqb;</number> The DataBus data architecture combines several main features or facets, such as partitioning, multi-hop finder strategies, externalized associations, object layer mediating access to underlying data storage, support for logical domains and transaction management. These separate facets of the architecture are briefly summarized in the following: </paragraph>
<paragraph id="P-0298" lvl="2"><number>&lsqb;0298&rsqb;</number> The proposed solution is Java-centric, with major systems based upon server-side Java and Application Server implementations. </paragraph>
<paragraph id="P-0299" lvl="2"><number>&lsqb;0299&rsqb;</number> Entity Partition Containers define a model where container processes provide an environment in which business objects live. Access to business objects is obtained via remote method calls to stationary objects that are fixed to a physical container. Each partition container provides a &ldquo;home&rdquo; interface which can be located and used to create or access instances of the class. </paragraph>
<paragraph id="P-0300" lvl="2"><number>&lsqb;0300&rsqb;</number> The Data layer allows for an alternative access style where clones of business objects may be streamed out to satellite cache servers or directly into an application&apos;s process space. Any number of satellite cache servers can be deployed as needed. </paragraph>
<paragraph id="P-0301" lvl="2"><number>&lsqb;0301&rsqb;</number> Loosely-coupled concurrency control idioms are provided, such as optimistic concurrency control, to detect stale data when multiple applications concurrently hold local copies of the same data. This approach allows data replication to many local sites, but operates at the business objects level rather than wholesale replication of database tables. Data is maintained in volatile storage since non-master data does not need the full robustness of a database. </paragraph>
<paragraph id="P-0302" lvl="2"><number>&lsqb;0302&rsqb;</number> Scalability is enhanced by the ability to partition any object class or data type across multiple, independent physical stores. Both business object containers (entity partitions) and corresponding database stores can be partitioned (horizontally) and further distributed across different operations centers if desired. Partitioning is emphasized over replication as the means for scalability. </paragraph>
<paragraph id="P-0303" lvl="2"><number>&lsqb;0303&rsqb;</number> A central steward assigned for each entity type provides coordination and management of unique primary keys across all partitions. Most operations, other than instance creation, involve no access to the steward. Significant effort is made to prevent the steward from becoming a bottleneck. Given its primary key, a multi-stage finder strategy allows navigation to any entity instance from anywhere in the enterprise. The first stage of the finder provides a &ldquo;map&rdquo; from the primary key onto the physical partition where the corresponding entity instance is stored. A second stage operation can then locate the specified object within the partition. </paragraph>
<paragraph id="P-0304" lvl="2"><number>&lsqb;0304&rsqb;</number> The information managed by the steward can be cached within the satellite cache servers so that, in most cases, an object is obtained without consulting the central steward. </paragraph>
<paragraph id="P-0305" lvl="2"><number>&lsqb;0305&rsqb;</number> The data layer architecture allows logical domains, cutting across entity-type boundaries to be defined and used to scope down the context of operations to a relevant size. Domains are conceptually orthogonal to entities, and serve as a logical overlay on top of the physical partitions. For finder operations more complex than find-by-primary-key, the specification of a domain narrows the range of a search to a small number of relevant physical partitions, thereby avoiding a broad search. Create operations can specify the logical domain to link with the object. </paragraph>
<paragraph id="P-0306" lvl="2"><number>&lsqb;0306&rsqb;</number> Externalized associative engines allow the creation of relationships between entity types. These constitute the literal realization of the links in an E-R diagram or object diagram. Foreign keys are not embedded within entities; rather, associations are externalized as first-class persistent objects allowing for a highly de-coupled, adaptive data/object model. </paragraph>
<paragraph id="P-0307" lvl="2"><number>&lsqb;0307&rsqb;</number> Existing entities can be made to participate in new associations without impacting existing links. Evolving business needs can be met by appending supplementary business objects to existing core objects through the agency of associations. Since the data storage for associations can itself be partitioned, association storage size grows independently of entity partition size and is not limited in terms of scale. At the same time, the architecture permits entities to be managed entirely from within. To the applications programmer, relationship traversal from entity to entity is completely transparent and seems centralized. </paragraph>
<paragraph id="P-0308" lvl="2"><number>&lsqb;0308&rsqb;</number> The proposed infrastructure supports a variety of integrity constraints upon associations, such as cardinality, as needed. </paragraph>
<paragraph id="P-0309" lvl="2"><number>&lsqb;0309&rsqb;</number> Subject areas are used to classify entities into broad categories of data areas in the company, such as Customer, Inventory, etc. Within each subject area, there can be many subordinate entities. These subordinate entities can be expected to evolve on a faster time scale as the details of the business evolve; however, the subject area model is expected to be much more stable. </paragraph>
<paragraph id="P-0310" lvl="2"><number>&lsqb;0310&rsqb;</number> Each subject area is defined by a principle entity that serves as an anchor point for the remainder of the information within the grouping. These standardized anchor objects represent major corporate elements. Subordinate data classes can be added as needed whenever required by new products and services. </paragraph>
<paragraph id="P-0311" lvl="2"><number>&lsqb;0311&rsqb;</number> Subordinate object classes within a given subject area may often have the character of local data; local in a logical sense of being relevant only in the context of a particular line of business. As pointed out above, externalized associations lend a great deal of flexibility for evolving the data model as new entities and relationships are added to the model. </paragraph>
<paragraph id="P-0312" lvl="2"><number>&lsqb;0312&rsqb;</number> Alternatively, the data administrators may choose to use more conventional, tightly-coupled intra-database relational mechanisms. However, it is intended that associations across major subject areas are exclusively built using externalized associative constructs. </paragraph>
<paragraph id="P-0313" lvl="0"><number>&lsqb;0313&rsqb;</number> Replication of databases using conventional commercial products can be used for purposes of fault tolerance and disaster recovery. However, in general, traditional wholesale replication of database tables is not viewed as being a sustainable basis for a scalable architecture. For example, if one database of size N served a company&apos;s current needs and the company were to grow ten-fold, the database would need to be of size 10&times;N. It would also need to be replicated to N distributed copies to hold access rates constant. The total amount of data storage using full replication strategies thus scales as the square of the company size. In the Data layer proposal, the extensive partitioning and distribution of business objects to form a loosely-coupled web or mesh of associated objects is considered to be the path to a sustainable, linearly-scaling data architecture. </paragraph>
</section>
<section>
<heading lvl="1">Entity-Relationship Model </heading>
<paragraph id="P-0314" lvl="0"><number>&lsqb;0314&rsqb;</number> With respect to the present invention, the term &ldquo;entity&rdquo; will be understood in the context of a conventional entity-relationship diagram. An entity-relationship (E-R) model is a data modeling technique that creates a graphical representation of entities and the relationships between entities within an information system. The E-R model figures prominently into this data architecture in general. <cross-reference target="DRAWINGS">FIG. 17A</cross-reference> is a traditional representation of an E-R diagram, nodes <highlight><bold>1700</bold></highlight>, <highlight><bold>1702</bold></highlight>, <highlight><bold>1704</bold></highlight>, <highlight><bold>1706</bold></highlight> and <highlight><bold>1708</bold></highlight> represent entity classes for &ldquo;Customers,&rdquo; &ldquo;Accounts,&rdquo; &ldquo;Account Service,&rdquo; &ldquo;Billing Address&rdquo; and &ldquo;Pending Orders,&rdquo; respectively. An &ldquo;entity&rdquo; is any person, object, place or event for which data is collected. For example, in a business&apos;s information system, entities are business customers <highlight><bold>1700</bold></highlight>, the customers&apos; addresses <highlight><bold>1702</bold></highlight>, orders <highlight><bold>1708</bold></highlight>, etc. The entity is represented in a conventional entity-relationship model as a geometric shape, normally a rectangle, but in this case an ellipse labeled with a singular noun that describes the entity. A relationship is defined as the interaction between the entities. For instance, customer <highlight><bold>1700</bold></highlight> of the aforementioned business maintains account <highlight><bold>1702</bold></highlight> and account <highlight><bold>1702</bold></highlight> lists pending order <highlight><bold>1708</bold></highlight>. Thus, the word &ldquo;maintains&rdquo; defines the relationship between a customer and the account or accounts that they maintain, while the word &ldquo;pending&rdquo; defines the relationship between an account and the pending order or orders. A relationship is normally denoted in a conventional entity-relationship diagram by either a diamond shape, or more simply, a line terminated with arrowheads which connects the entities. In either case, verbs may be used to label the relationships. Cardinality defines the association between the entities in terms of numbers. An entity may be optional or mandatory. For example, a sales representative could have no customers, or one or many customers, or there must be at least one product listed in an order. There are several different types of cardinality notation, but with respect to <cross-reference target="DRAWINGS">FIG. 17A, a</cross-reference> single arrowhead represents a unit of one, while a double arrowhead represents a unit of many. The three main cardinal relationships are: 1) one-to-one, expressed as 1:1, representing the relationship between customer <highlight><bold>1700</bold></highlight> and account <highlight><bold>1704</bold></highlight>; 2) one-to-many, expressed as 1:M, representing the relationship between customer <highlight><bold>1700</bold></highlight> and bill address <highlight><bold>1706</bold></highlight>; and <highlight><bold>3</bold></highlight>) many-to-many, expressed as M:N (not shown in the Figure). </paragraph>
<paragraph id="P-0315" lvl="0"><number>&lsqb;0315&rsqb;</number> A central concept of this data architecture is that the nodes and arcs of the E-R diagram are literally mapped onto entity engine processes and association engine processes on the network. <cross-reference target="DRAWINGS">FIG. 17B</cross-reference> is a representation of nodes and arcs of the E-R diagram being mapped onto entity engine processes and association engine processes. Customer entity <highlight><bold>1700</bold></highlight> is mapped to customer entity engine <highlight><bold>1710</bold></highlight>; account entity <highlight><bold>1702</bold></highlight> is mapped to account entity engine <highlight><bold>1712</bold></highlight>; account service entity <highlight><bold>1704</bold></highlight> is mapped to service entity engine <highlight><bold>1714</bold></highlight>; billing address entity <highlight><bold>1706</bold></highlight> is mapped to billing address entity engine <highlight><bold>1716</bold></highlight>; and pending order entity <highlight><bold>1708</bold></highlight> is mapped to pending order entity engine <highlight><bold>1708</bold></highlight>. Associations between entities can also be externalized. Externalized associative engines allow the creation of relationships between entity types. These relationships constitute the literal realization of the links in an E-R diagram or object diagram. With regard to <cross-reference target="DRAWINGS">FIG. 17</cross-reference>B, these external associations between entity types are shown as boxes between each entity engine. Three types of association engines are: 1) one-to-one; 2) one-to-many; or 3) many-to-many, depending upon the cardinal relationship between the specific entity classes. For example, each customer entity in customer entity class <highlight><bold>1700</bold></highlight> is associated with only a single billing address entity within bill address entity class <highlight><bold>1706</bold></highlight>, thus Cust/BillAddr association engine <highlight><bold>1724</bold></highlight> is a &ldquo;1-1&rdquo; association engine, whereas customer entity might be associated with several accounts. Thus, Customer/AccAssociation engine <highlight><bold>1720</bold></highlight> is a &ldquo;1-M&rdquo; association engine serving associations between Acc/AccCustomer entity engine <highlight><bold>1710</bold></highlight> and account entity engine <highlight><bold>1712</bold></highlight>. </paragraph>
<paragraph id="P-0316" lvl="0"><number>&lsqb;0316&rsqb;</number> As the <cross-reference target="DRAWINGS">FIGS. 17A and 17B</cross-reference> illustrate, the E-R diagram of a business object model is directly recognized as a web of processes linked together over the network. This model is similar is some aspects of the so-called &ldquo;network databases,&rdquo; and to the World Wide Web model where any object can have links to any other object. However, there is greater discipline here in that associations are structured, follow a schema defined by the E-R model, and obey integrity constraints such as cardinality. </paragraph>
<paragraph id="P-0317" lvl="0"><number>&lsqb;0317&rsqb;</number> Further, <cross-reference target="DRAWINGS">FIGS. 17A and 17B</cross-reference> underscore the notion that associations and entities receive equal treatment as first class objects supported by deployed processes. Both entity engines and association engines have their own backing store as well. The backing store for entities will typically store records of attributes that represent the state of the various entity instances managed by a given entity engine. The backing store for association engines will contain tables of link records, which are pairs of foreign references to the entities that stand in relation to each other. In database language, the association storage is sometimes called a &ldquo;correlation table.&rdquo;</paragraph>
<paragraph id="P-0318" lvl="0"><number>&lsqb;0318&rsqb;</number> Further, with respect to <cross-reference target="DRAWINGS">FIG. 17</cross-reference>B, the lines connecting the boxes representing the various engines convey two points. First, they connote the foreign references to the entities that the association links together. Second, they correspond to interprocess communication (IPC) channels that are exercised at runtime as applications establish new links between entity instances and traverse existing relationship paths among associated entities. This simplified view of the mapping of E-R diagrams onto process engines has glossed over some details that will be filled in below. In particular, the fact that each given entity class may actually have its instances partitioned horizontally across several distributed stores has been ignored. &ldquo;Horizontal partitioning&rdquo; is database jargon for deploying different &ldquo;rows&rdquo; in a table across different stores, the image being of a horizontal slice through the table, as opposed to vertical partitioning where different attributes of the same record are stored in separate physical areas. </paragraph>
</section>
<section>
<heading lvl="1">Entity Partitions </heading>
<paragraph id="P-0319" lvl="0"><number>&lsqb;0319&rsqb;</number> As discussed throughout the present disclosure, the DataBus architecture relies very heavily upon data partitioning to achieve the scalability. Data is deployed throughout an enterprise network in a highly decentralized, distributed manner, but at the same time, remains logically unified. Thus, an enterprise user (service, client or even end user) can easily navigate to any data item from anywhere in the enterprise. Even though the data deployment is unconventional, conventional databases are relied upon for implementing highly-independent physical data partitions which have essentially no direct knowledge of each other. As described in detail below, external navigational mechanisms, such as finders and associations (described above and below), are the glue that binds these highly independent partitions together. </paragraph>
<paragraph id="P-0320" lvl="0"><number>&lsqb;0320&rsqb;</number> Separate entities will generally be housed in separate storage servers. Even a given entity is likely to be physically partitioned across many separate storages. Practically speaking, an enterprise may strive to co-locate partitions of a given entity at a single physical facility, an operations center, for instance, on separate nodes of an SP&bsol;2 multiprocessor complex. However, the same entity might often be physically partitioned across geographically-distributed sites (e.g., siting one subset of customer data in the United States, and another in Europe). </paragraph>
<paragraph id="P-0321" lvl="0"><number>&lsqb;0321&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a diagram illustrating entity A <highlight><bold>1802</bold></highlight>, entity B <highlight><bold>1804</bold></highlight> and entity C <highlight><bold>1806</bold></highlight> which are partitioned in accordance with an exemplary embodiment of the present invention. Each of entities A-C (<highlight><bold>1802</bold></highlight>-<highlight><bold>1806</bold></highlight>) is partitioned in as few as two and as many as four separate partitions; however, the diagram is merely illustrative. In practice, an entity might be partitioned in literally hundreds, and possibly thousands, of separate partitions. Note that the grouping of partitions within the entity boxes does not imply physical proximity in actual deployment. In fact, the deployment of some entities may be quite widespread across an enterprise. Remember, it is expected that data which is repeatedly accessed by a client will most likely be physically located proximate to that client. Thus, clients that are geographically disparate, while utilizing records or instances of the same entity, will result in the entity instances being geographically divided up by partitioning the entity. </paragraph>
<paragraph id="P-0322" lvl="0"><number>&lsqb;0322&rsqb;</number> Interestingly, entity partitioning is not limited to the records of the underlying database storage media. Partitioning also includes the entity instance containers that house the object representation of the business entities. In other words, both the business objects tier and the data storage tier of the N-tier DataBus architecture are partitioned. In accordance with one embodiment of the present invention, only one object container instance is deployed for each corresponding database partition. <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is a diagram illustrating three container-database partition pair in accordance with an exemplary embodiment of the present invention. Note that VM container 1 (<highlight><bold>1910</bold></highlight>-<highlight><bold>1</bold></highlight>) is deployed for database <highlight><bold>1918</bold></highlight>-<highlight><bold>1</bold></highlight>; VM container 2 (<highlight><bold>1910</bold></highlight>-<highlight><bold>2</bold></highlight>) is deployed for database <highlight><bold>1918</bold></highlight>-<highlight><bold>2</bold></highlight>; and VM container 3 (<highlight><bold>1910</bold></highlight>-<highlight><bold>3</bold></highlight>) is deployed for database <highlight><bold>1918</bold></highlight>-<highlight><bold>3</bold></highlight>. It should be understood that while databases <highlight><bold>1918</bold></highlight>-<highlight><bold>1</bold></highlight>-<highlight><bold>1918</bold></highlight>-<highlight><bold>3</bold></highlight> are physically partitioned, and likely to be deployed to physically distinct server hosts, deployers may often wish to locate the database and corresponding entity partition container onto the same host. For example, to co-locate container <highlight><bold>1910</bold></highlight>-<highlight><bold>1</bold></highlight> and database <highlight><bold>1918</bold></highlight>-<highlight><bold>1</bold></highlight> on the same host, etc. In fact, it is logical to pair the object instance container and its matching database store on the same processor node so as to make container to database communications very fast. </paragraph>
</section>
<section>
<heading lvl="1">DataBus Architecture </heading>
<paragraph id="P-0323" lvl="0"><number>&lsqb;0323&rsqb;</number> With DataBus entities highly partitioned across distributed data stores, a suitable strategy or set of strategies for finding any particular object of interest is needed. These strategies include using a multi-stage finder mechanism to find objects given their primary key and employing a scoping mechanism, for limiting the scope of an arbitrary, criteria-based finding operation to a subset to all partitions in which the entity must be found. The final strategy uses an externalized associative engine mechanism for following association links between entities. The multi-hop finder is especially suited for finding an entity instance by primary key from anywhere in the enterprise, regardless of where it is physically located. </paragraph>
<paragraph id="P-0324" lvl="0"><number>&lsqb;0324&rsqb;</number> However, before discussing the multistage finder, it might be helpful to discuss the DataBus architecture in more detail and the process for creating an entity instance in a partition in accordance with an exemplary embodiment of the present invention. <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is a diagram depicting DataBus components necessary for creating an entity instance in accordance with an exemplary embodiment of the present invention. For each entity in an enterprise, there exists one steward service, depicted as steward <highlight><bold>2010</bold></highlight>. This steward is logically central, but for access, availability and latency considerations, could be physically composed of federated, cooperating components constituting a logically unified steward service. Within every multicast domain, there exists a plurality of satellites, depicted as satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight>. Steward <highlight><bold>2010</bold></highlight> provides a measure of central management to the present invention. With the storage and container servers for each entity being partitioned and distributed across physically separate server hosts, as described directly above, there is a need for a central manger, one for each entity class. The entity manager serves as a central authority for those aspects of the entity needing to be centralized, as represented in <cross-reference target="DRAWINGS">FIG. 20</cross-reference> as steward <highlight><bold>2010</bold></highlight>. In spite of the emphasis of the DataBus architecture on decentralization and distribution, however, is in situations where there is no way of avoiding some central control. This is where the central manager comes into play. While the central manager is necessary, we go to great lengths to avoid this manager becoming a bottleneck to throughput, and avoid excessive accesses to this central steward or manager. </paragraph>
</section>
<section>
<heading lvl="1">Roles of the Entity Manager </heading>
<paragraph id="P-0325" lvl="0"><number>&lsqb;0325&rsqb;</number> One of the main roles of this central manager is to provide coordination and management of unique primary keys (PKs) across all partitions. In the present architecture, all entities follow the convention of defining a candidate primary key consisting of a unique 64-bit integer called the UID (unique identifier). This UID provides a convenient foreign key that is used by externalized association engines to store references to entity instances, as will be further described below. In accordance with one exemplary embodiment of the present invention, one of the primary responsibilities of central entity manager <highlight><bold>2010</bold></highlight> is to maintain a block-up counter for generating new UIDs when a new block of primary keys is called for by any of satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight>. Satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight> actually issue a primary key whenever an entity instance is created and not steward <highlight><bold>2010</bold></highlight>. This approach avoids the necessity of accessing the manager upon every creation of a new entity instance. The satellite need only consult the steward during entity creation in the event that the satellite runs out of keys in its allocated block of keys. It must then go back to the steward to request another block of keys. This approach avoids the necessity of accessing the manager upon every creation of a new entity instance. In accordance with another exemplary embodiment of the present invention, steward <highlight><bold>2010</bold></highlight> validates that a primary key proposed by a user for a new instance is not already in use by an existing instance. This latter sort of PK contrasts with the block-up UID generated by the central manager in that its form is dictated by the type of business object it represents. For example, the PK for a given entity might be a string or an integer, or it might be a composite key having more than one component. These domain-specific PKs would often be proposed by the application, or by custom logic within the entity implementation, and checked for uniqueness by the central entity manager, using for example, a hashing or directory service. </paragraph>
<paragraph id="P-0326" lvl="0"><number>&lsqb;0326&rsqb;</number> In accordance with another exemplary embodiment of the present invention, steward <highlight><bold>2010</bold></highlight> serves as a place to keep the master data for the mapping of primary keys onto partition identifiers that indicate where each given object is stored. This is an alternative embodiment and is discussed more below with respect to multi-stage finders. However, in that case, when a cache miss is suffered out at a satellite server, the finder service faults over to the master data managed by steward <highlight><bold>2010</bold></highlight> to determine which partition contains the entity having a given PK. When a new entity is created, steward <highlight><bold>2010</bold></highlight> places a new entry in its master copy of the PK-to-partition map. This role of steward <highlight><bold>2010</bold></highlight>, as the master record for this mapping, assumes that the multi-hop finder is based on distributed caches. If, as is discussed with respect to another embodiment of the present invention, enterprise repository <highlight><bold>2030</bold></highlight> is used for storing PK-to-partition maps, then burden for this data management shifts entirely to enterprise repository <highlight><bold>2030</bold></highlight>. However, if, and only if, the embodiment requires steward <highlight><bold>2010</bold></highlight> to generate new primary keys when new instances are created, and its responsibility for recording the PK-to-partition association, then the central logic of the home interface&apos;s create operation can also be located within steward <highlight><bold>2010</bold></highlight>. </paragraph>
<paragraph id="P-0327" lvl="0"><number>&lsqb;0327&rsqb;</number> Finally, steward <highlight><bold>2010</bold></highlight> is responsible for finding an instance&apos;s partition container if the guidance stage of the find operation fails. As will be discussed above, a find operation may consist of a guidance stance and a local find stage. Steward <highlight><bold>2010</bold></highlight> issues parallel query to all entity partition containers if a PK-partition map is not listed in the satellite or enterprise repository for the partition holding the instance for the primary key. </paragraph>
</section>
<section>
<heading lvl="1">Avoiding Entity Manager becoming a Bottleneck </heading>
<paragraph id="P-0328" lvl="0"><number>&lsqb;0328&rsqb;</number> Despite the central nature of the entity manager within a federation of entity partitions, one is not to think of the steward as being strictly layered over the physical partitions in a top-down sense. In other words, all operations on an entity instance or on the entity home interface are not channeled through the manager. On the contrary, we seek to avoid, as far as we can, directing traffic through the manager, turning only to the entity manager in those situations, such as instance creation, where consulting it cannot be avoided. This point is key to the scalability of the proposed architecture. We wish to avoid having the central entity manager turn into a constriction point. </paragraph>
<paragraph id="P-0329" lvl="0"><number>&lsqb;0329&rsqb;</number> It should be mentioned that, in contrast with the prior art, when the client application holds a proxy or handle to an entity instance and invokes methods on that instance, steward <highlight><bold>2010</bold></highlight> is completely bypassed, and the remote invocation goes directly to the partition container where the instance is stored. Thus, instance-level operations entirely short circuit both steward <highlight><bold>2010</bold></highlight> and satellite <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight>. </paragraph>
<paragraph id="P-0330" lvl="0"><number>&lsqb;0330&rsqb;</number> The find-by-primary-key methods in the entity&apos;s home interface are handled by the satellite cache servers as discussed above in the section on multi-hop finders. These caches are consulted first to find the partition where a desired entity instance is located; the entity manager is consulted only whenever there is a cache miss. The hope is that most of the find operations will never need to consult the central entity manager. Association traversal and association creation (link) operations likewise never need to touch the central entity manager. </paragraph>
<paragraph id="P-0331" lvl="0"><number>&lsqb;0331&rsqb;</number> Finally, in accordance with another exemplary embodiment of the present invention, steward <highlight><bold>2010</bold></highlight> is responsible for allocating blocks of primary keys to the satellites for its entity class and for locating the partition containing an entity instance, given the instance&apos;s primary key in case of cache faults in enterprise repository <highlight><bold>2030</bold></highlight> and/or at satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight>. In accordance with this embodiment, steward <highlight><bold>2010</bold></highlight> issues parallel query to all entity partition containers only if a PK-partition map does not have a copy of its own or the PK-partition map is not listed in enterprise repository <highlight><bold>2030</bold></highlight> and/or satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight>. In that case, the parallel query is issued and steward <highlight><bold>2010</bold></highlight> retains a copy for itself prior to sending it to satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight>, possibly saving a parallel query in the future. </paragraph>
<paragraph id="P-0332" lvl="0"><number>&lsqb;0332&rsqb;</number> Satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight>, on the other hand, are responsible for two class level tasks. The first is finding a suitable container for a new partition. Satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight> select a specific partition container to place the entity instance based on some algorithm, such as proximity to the creating client, partition container loading, distribution leveling or some combination of the above. Satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight> also cache the PK-partition map and may pass that information on the steward <highlight><bold>2010</bold></highlight> after creating an instance. </paragraph>
<paragraph id="P-0333" lvl="0"><number>&lsqb;0333&rsqb;</number> In addition to client <highlight><bold>2030</bold></highlight>, steward <highlight><bold>2010</bold></highlight> and satellites <highlight><bold>2012</bold></highlight>-<highlight><bold>2018</bold></highlight>, the local multicast domain also contains a plurality of domain registers <highlight><bold>2032</bold></highlight> for registering and looking up local NW services. External to the local multicast domain is enterprise repository <highlight><bold>2030</bold></highlight> which maintains enterprise level service and data registration as described above with respect to the processes described in <cross-reference target="DRAWINGS">FIGS. 10A, 11C</cross-reference>, <highlight><bold>12</bold></highlight>A and <highlight><bold>12</bold></highlight>C. Additionally, enterprise repository may contain PK-partition mapping information as described immediately above. </paragraph>
<paragraph id="P-0334" lvl="0"><number>&lsqb;0334&rsqb;</number> Also shown in <cross-reference target="DRAWINGS">FIG. 20</cross-reference> are servers <highlight><bold>2002</bold></highlight>A-<highlight><bold>2002</bold></highlight>D which may be physically located in the local domain, but are more probably scattered throughout the geography of the enterprise. For instance, server <highlight><bold>2002</bold></highlight>A might be situated in Paris, while server <highlight><bold>2002</bold></highlight>B is situated in Moscow. Also depicted in <cross-reference target="DRAWINGS">FIG. 20</cross-reference> are arrows depicting the interaction between DataBus components. For the reader&apos;s convenience, these lines represent the correspondingly-numbered step in the flowchart depicted in <cross-reference target="DRAWINGS">FIG. 25</cross-reference>, which will be described below. </paragraph>
<paragraph id="P-0335" lvl="0"><number>&lsqb;0335&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> is a flowchart depicting a process for creating an entity instance in accordance with an exemplary embodiment of the present invention. The process begins with client <highlight><bold>1920</bold></highlight> accessing an interface for interacting with a satellite by finding a satellite service for the entity class in domain registrar <highlight><bold>1932</bold></highlight> (step <highlight><bold>2102</bold></highlight>). Client <highlight><bold>1920</bold></highlight> looks up and retrieves the proxy (or a smart proxy) for satellite <highlight><bold>1912</bold></highlight>. It should be understood that because each local domain should have satellite services for each entity class running, it should never be necessary for the client to hop to the enterprise repository for a non-local satellite. Of course, if a satellite service is not found in registrar <highlight><bold>1932</bold></highlight>, client <highlight><bold>1920</bold></highlight> can find enterprise repository <highlight><bold>1930</bold></highlight> and then look up a non-local registrar with a listing for a satellite service as described above with respect to <cross-reference target="DRAWINGS">FIG. 12C</cross-reference>. If client <highlight><bold>1920</bold></highlight> already has the interface to satellites <highlight><bold>1910</bold></highlight>, then steps <highlight><bold>2102</bold></highlight> and <highlight><bold>2104</bold></highlight> can be omitted. </paragraph>
<paragraph id="P-0336" lvl="0"><number>&lsqb;0336&rsqb;</number> Next, client <highlight><bold>1910</bold></highlight> requests an entity instance be created in a partition (step <highlight><bold>2106</bold></highlight>). Once the request is received by satellite <highlight><bold>2112</bold></highlight>, it checks its cache for primary keys (step <highlight><bold>2108</bold></highlight>). If satellite <highlight><bold>1910</bold></highlight> does not have a primary key on hand for creating a new entity instance, it requests a block of key from steward <highlight><bold>1910</bold></highlight>, which is forwarded to satellite <highlight><bold>1912</bold></highlight> (step <highlight><bold>2110</bold></highlight>). Once satellite <highlight><bold>1912</bold></highlight> has a key, it determines the best entity container partition to create an entity instance in step <highlight><bold>2112</bold></highlight>. Satellite <highlight><bold>1912</bold></highlight> might base the decision on proximity to client <highlight><bold>1920</bold></highlight>, container loading or some other quantifiable factor. The partition container may also be specified explicitly by the caller. Or the caller may specify a logical domain where the new entity instance is to be located. In this latter usage, the satellite would query an enterprise mapping of logical domains onto qualifying entity partitions. The steward would select from the set of qualifying partitions belonging to a domain a given partition to house the new entity instance. This selection could be random round-robin or based upon available capacity, determined by policy. Then, satellite <highlight><bold>1912</bold></highlight> caches the PK-partition mapping, passes it to steward <highlight><bold>1910</bold></highlight> and forwards the create(PK) request to the selected partition container (step <highlight><bold>2112</bold></highlight>). From there, the partition container creates the entity instance and passes a proxy for the instance to client <highlight><bold>2014</bold></highlight>. Additionally, the newly-created data object can register itself with the enterprise, like services as described above with respect to <cross-reference target="DRAWINGS">FIG. 12A</cross-reference>. The process then ends. </paragraph>
<paragraph id="P-0337" lvl="0"><number>&lsqb;0337&rsqb;</number> Once the entity instance has been created, there must be a coherent strategy to find it again when needed by a client. A multi-stage finder strategy allows the navigation to any entity instance from anywhere in the enterprise, given its primary key. The basic idea is that a first stage is used to map the primary key (PK), or candidate PK, onto the partition number where the entity is stored. The second stage is to invoke the &ldquo;local&rdquo; finder interface out at the relevant physical partition to produce the actual entity instance of interest. This second stage of the find operation is implemented with a SQL select statement for backing store that uses a RDBMS. However, before discussing the multi-finder strategy, in might be useful to review various protocols employed by the DataBus for accessing and safeguarding data objects. </paragraph>
</section>
<section>
<heading lvl="1">Modes of Data Access </heading>
<paragraph id="P-0338" lvl="0"><number>&lsqb;0338&rsqb;</number> The present invention envisions three distinct types of data access: 1) remote calls to fixed entities; 2) streaming copies of the data to client; and 3) moving a mobile agent into the entity&apos;s space. The core strategy has all client access to business objects effected by remote method calls into stationary data locations, the containers. This mode is similar to that described above with respect to services where a client intending to interact with an entity acquires a proxy to the entity instance and uses the proxy to interact with the instance. </paragraph>
<paragraph id="P-0339" lvl="0"><number>&lsqb;0339&rsqb;</number> With respect to the data-movement approach, copies of data objects are moved out to the locales of the clients, thereby allowing client applications to exercise the business objects locally. By locale, we might mean a process close to the client, say on the same LAN, or even the process address space of the client application, where there is room for variations. At some point, changes to the copies need to be synchronized back to a master copy of the data. This approach generally implies the possibility that multiple copies corresponding to the same underlying objects may exist concurrently in different users&apos; application spaces. Therefore, this approach to data access requires the adoption of well-thought-out concurrency control strategies. </paragraph>
<paragraph id="P-0340" lvl="0"><number>&lsqb;0340&rsqb;</number> The third style of access to data, in addition to remote calls to stationary business objects and moving of object copies out to clients, is to again keep the business objects stationary, but dispatch client code in the form of mobile agents out to the business objects. The agent does work on behalf of the client then reports back to the client when there are results. This is somewhat similar in spirit to the familiar stored procedures from the relational database world where an application can install functionality inside the database engine. </paragraph>
<paragraph id="P-0341" lvl="7"><number>&lsqb;0341&rsqb;</number> Remote Access to Stationary Business Objects </paragraph>
<paragraph id="P-0342" lvl="0"><number>&lsqb;0342&rsqb;</number> As the remote calls to fixed entities mode of data access has been thoroughly discussed above, the notion is that clients obtain (using create, find, or association methods) remote handles to entity instances. These remote handles are similar in some respects to the familiar RMI proxies or CORBA proxies from ORB computing. However, the remote handles to entity instances are implemented with their own code which may be remotely loaded and hidden from the client in accordance with an exemplary embodiment of the present invention. These handles of remotely-loaded code are the smart proxies discussed above with respect to NewWave services. Recall that a smart proxy is a local object streamed to the client&apos;s process space which may contain both local data, logic and behavior, as well as references to remote server-side objects. In accordance with another exemplary embodiment of the present invention, the smart proxy that serves as a remote handle to entity instances encapsulates local state (i.e., the entity primary key), the name of the entity class or the partition number where the entity instance is actually stored. Additionally, the smart proxy will also encapsulate an RMI proxy to the container managing the entity instance. </paragraph>
<paragraph id="P-0343" lvl="7"><number>&lsqb;0343&rsqb;</number> Streaming Data Copies to Client: Two Variations </paragraph>
<paragraph id="P-0344" lvl="0"><number>&lsqb;0344&rsqb;</number> In the second mode of access to entities, a copy or clone of the business object is streamed out to the locale of the client application. Two modes of streaming supported by the present invention are direct streaming of a clone object into the process space of the client application and caching the clone object in a satellite cache server. <cross-reference target="DRAWINGS">FIGS. 22 and 23</cross-reference> are diagrams depicting both modes of streamed data copies in accordance with an exemplary embodiment of the present invention. <cross-reference target="DRAWINGS">FIG. 22</cross-reference> is a diagram showing a read/write copy of the entity instance being streamed directly to the client, while <cross-reference target="DRAWINGS">FIG. 23</cross-reference> shows the cache server approach where a copy of the entity instance is streamed to a cache server rather than the copy being directly steamed to the client. In the latter approach, the client accesses the copy via the cache server. With respect to <cross-reference target="DRAWINGS">FIG. 22, a</cross-reference> copy or clone <highlight><bold>2206</bold></highlight> is shown streaming from container <highlight><bold>2212</bold></highlight> directly to client <highlight><bold>2204</bold></highlight> for the client&apos;s use. Client <highlight><bold>2204</bold></highlight> issues a getClone( ) to container <highlight><bold>2212</bold></highlight> which obliges with clone <highlight><bold>2206</bold></highlight>. Client <highlight><bold>2204</bold></highlight> can then interact with the clone of entity instance <highlight><bold>2202</bold></highlight> including updating the instance using a updateFromClient( ). Here client <highlight><bold>2204</bold></highlight> is implemented in Java and therefore has the space to accommodate clone <highlight><bold>2206</bold></highlight>. </paragraph>
<paragraph id="P-0345" lvl="0"><number>&lsqb;0345&rsqb;</number> By contrast, with respect to the cache server approach depicted in <cross-reference target="DRAWINGS">FIG. 23</cross-reference>, client <highlight><bold>2314</bold></highlight> does not interact directly with clone <highlight><bold>2306</bold></highlight>. Instead, clone <highlight><bold>2306</bold></highlight> is streamed to satellite <highlight><bold>2310</bold></highlight> rather than directly to client <highlight><bold>2314</bold></highlight>. The cache server approach is mandatory if the client application is non-Java client <highlight><bold>2314</bold></highlight>. Some Java &ldquo;proxy&rdquo; space is needed to store the clone object on behalf of client <highlight><bold>2314</bold></highlight>. </paragraph>
<paragraph id="P-0346" lvl="0"><number>&lsqb;0346&rsqb;</number> In order to support this streaming of clones out to the client, the entities must support a convention of supplying a getClone( ) method and an updateFromClone( ) method. For each entity type, there also must also be a serializable clone class defined (sometimes called a state object) which represents the thing that actually gets streamed out to the client. The entity&apos;s getClone( ) method creates a ( )clone object reflecting the entity&apos;s current state, then streams the clone object out to the caller&apos;s address space. The updateFromClone( ) method of the entity takes the clone instance as an argument and updates the state of the master to match the attributes of the clone object. </paragraph>
<paragraph id="P-0347" lvl="0"><number>&lsqb;0347&rsqb;</number> The above approach of having each entity support a getClone( ) method implies that there is one fixed type of clone object for each entity. In an enterprise, different applications may have differing needs for making up the exact internal data in a clone object (e.g., nested entities to varying levels.) The DataBus architecture accommodates these varying needs by offering a factory mechanism whereby clients can stream a factory object into an entity container during the request to create a clone of an entity. The entity container will ask the custom factory to create the clone, passing a reference to itself (i.e., to the entity) in order that the factory may call back the entity to extract entity state information during the construction of the clone. With this methodology, clients can create customized copies suitable for their purposes. By streaming factory code from clients into the entity containers at runtime, the entity container&apos;s abilities for stamping out data copies becomes extensible, much as a computer-controlled machining tool&apos;s behavior is extensible through uploading instructions. Note that the factory can imbed, within the primary copy, any number of copies of associated entities to whatever depth of recursion the application deems desirable. Clients can thereby stream into a custom factory that tailors copies to the clients&apos; specific needs. The DataBus uses the approach of streaming client code into &ldquo;the system&rdquo; in another context, apart from clone factories. The DataBus also allows the client to provide a filter object during association traversal or find-by-criteria method calls. The filter implements custom Java code that can narrow a result set. In so doing, primarily only &ldquo;good&rdquo; objects are returned to the client, rather than all objects that match a &ldquo;find&rdquo; or &ldquo;get&rdquo; request. Recall that the &ldquo;getAccountsForCustomer( )&rdquo; method returns all destination objects that are associated with a given source object and that the solution requires either extra remote calls and data passing, or the client sequencing through the unfiltered array of accounts and performing its own filtering. By contrast, with the factory, the client streams objects into DataBus that act like the SQL &ldquo;where&rdquo; clause to perform custom filtering inside the entity container. Thus, the entity containers (the partition services), as well as the association engines, can apply filter objects to narrow results based on some preset criteria determined by the client. </paragraph>
<paragraph id="P-0348" lvl="7"><number>&lsqb;0348&rsqb;</number> Concurrency Control </paragraph>
<paragraph id="P-0349" lvl="0"><number>&lsqb;0349&rsqb;</number> Clearly, the streaming of clones to the client mode of data access has potential problems under concurrent usage scenarios. For example, in the lost update problem, two users fetch a copy of an entity instance. The first user modifies one copy and submits the changes. Thereafter, the second user modifies another copy and submits the changes, thus eliminating the modifications made to copy by the first user. The present invention solves the concurrent user problems by implementing one of two mechanisms. The first approach is used in scenarios where the client is using the data copies in a read-only fashion. That approach involves notifying the user of a read-only copy that a modification has been made to the original data and notifies the user of the changes in accordance with one embodiment of the present invention. The second approach is used in scenarios where the client is using the data copy in a read/write fashion. The second approach involves tracking version number of clones and rejecting any updates from clones that are not current in accordance with one embodiment of the present invention. </paragraph>
<paragraph id="P-0350" lvl="0"><number>&lsqb;0350&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 24 and 25</cross-reference> are diagrams depicting both approaches for maintaining concurrency control implemented by DataBus in accordance with an exemplary embodiment of the present invention. <cross-reference target="DRAWINGS">FIG. 24</cross-reference> is a diagram showing the event notification approach where the client is using only read-only copies of the entity instance and receiving change notifications whenever an update is received. The optimistic concurrency approach in <cross-reference target="DRAWINGS">FIG. 25</cross-reference>, on the other hand, depicts the client using a read/write copy that must stay in sync with a master copy in order for updates to be accepted. </paragraph>
<paragraph id="P-0351" lvl="0"><number>&lsqb;0351&rsqb;</number> With respect to <cross-reference target="DRAWINGS">FIG. 24</cross-reference>, client <highlight><bold>2404</bold></highlight> is using read-only clone <highlight><bold>2406</bold></highlight>, while client <highlight><bold>2405</bold></highlight> is using a second copy, clone <highlight><bold>2406</bold></highlight>, which is not read only. In the read-only scenario, event services keep the client copy reasonably in sync with the master data <highlight><bold>2402</bold></highlight>. Whenever client <highlight><bold>2404</bold></highlight> obtains a clone copy <highlight><bold>2406</bold></highlight>, the system registers with the event service the interest of client <highlight><bold>2404</bold></highlight> in obtaining refresh events whenever the master data gets updated by anyone else. A flag is also set on entity <highlight><bold>2402</bold></highlight> so that every time an update gets stored to the database, the system publishes a change event to the event bus so that the client is notified of the change. Here, client <highlight><bold>2404</bold></highlight> takes out an enterprise lease on the event service which, as described above, requires that client <highlight><bold>2404</bold></highlight> actively renew the lease if interested. Essentially, the event service publishes event notification to any service or clients wanting to subscribe and stay interested as long to the enterprise lease is current. Should client <highlight><bold>2404</bold></highlight> lose interest and let the lease expire, client <highlight><bold>2404</bold></highlight>&apos;s subscriptions of interest are purged. As discussed previously, if client <highlight><bold>2404</bold></highlight> disappears ungracefully, the lease is expunged from the record; however, should client <highlight><bold>2404</bold></highlight> eloquently shut down or decide not to take a data copy, the lease is removed gracefully. Recall from the description of <cross-reference target="DRAWINGS">FIGS. 13A and 13B</cross-reference> that the transaction process implemented by the transaction manager is a two-step commit process. All invited participants must join in the transaction prior to the transaction manager issuing the &ldquo;prepare&rdquo; and &ldquo;commit&rdquo; commands. Therefore, in accordance with an exemplary embodiment of the present invention, the change notification to client <highlight><bold>2404</bold></highlight> depends on the update transaction actually being committed. Should all participants in a transaction actually commit to the transaction, as opposed to joining it, the change notification is sent to client <highlight><bold>2404</bold></highlight>. Conversely, should the participants only confirm that the update transaction has been received to (tentative) store back to the database, the change notification is withheld, no matter how certain the impending change looks. </paragraph>
<paragraph id="P-0352" lvl="0"><number>&lsqb;0352&rsqb;</number> With respect to <cross-reference target="DRAWINGS">FIG. 24</cross-reference>, client <highlight><bold>2404</bold></highlight> is using read/write clone <highlight><bold>2408</bold></highlight>, as is client <highlight><bold>2405</bold></highlight>. Thus, either of clients <highlight><bold>2404</bold></highlight> and <highlight><bold>2405</bold></highlight> can update master entity instance <highlight><bold>2402</bold></highlight>. The second approach to concurrency control is when there are clone copies in the so-called optimistic concurrency control strategy. This strategy assumes a lack of locking due to the fact that there is optimism that collisions will be infrequent. In the optimistic concurrency-control idiom, a version number (a one-up count will do) is maintained on every entity instance. Each time an update to an instance occurs, the counter is incremented. Whenever a client obtains an entity clone, the clone contains the version number among its attributes. Whenever the client does a copy-back, using the updateFromClone( ) method, the system compares the clone&apos;s version number with the current version in the database. If there is an inconsistency, this means that some other user has performed an update since the first user originally fetched their copy. Under these conditions, the updateFromClone( ) method throws a &ldquo;StaleData&rdquo; exception and the update is aborted. With respect to <cross-reference target="DRAWINGS">FIG. 25</cross-reference>, when client <highlight><bold>2504</bold></highlight> takes clone <highlight><bold>2508</bold></highlight>, the copy comes with a version number. It is assumed that client <highlight><bold>2504</bold></highlight> will be able to make any necessary modifications to clone <highlight><bold>2508</bold></highlight> prior to another client, for instance client <highlight><bold>2505</bold></highlight>, taking a clone of entity instance <highlight><bold>2502</bold></highlight>, and thus another version. If so, client <highlight><bold>2504</bold></highlight> can update instance <highlight><bold>2502</bold></highlight> without incident. If, however, client <highlight><bold>2505</bold></highlight> does take out another copy, now clone copy <highlight><bold>2509</bold></highlight>, then updated clone <highlight><bold>2508</bold></highlight> from client <highlight><bold>2504</bold></highlight> will not be accepted and a StaleData exception is returned because clone <highlight><bold>2508</bold></highlight> is not in sync with instance <highlight><bold>2502</bold></highlight>. In that case, client <highlight><bold>2504</bold></highlight> merely rolls back the entire transaction and runs internal application logic that redoes the use-case on a new version of instance <highlight><bold>2502</bold></highlight>. There is the possibility that the transaction cannot be successfully rolled back and client <highlight><bold>2504</bold></highlight> is then forced to re-key clone <highlight><bold>2508</bold></highlight> (i.e., create another instance with its unique primary key). It should be noted that under the optimistic idiom, one generally fetches the clone under one transaction, works with the clone under no transactional control, and then finally updates the original data store from the clone state under a second transaction. </paragraph>
</section>
<section>
<heading lvl="1">Multi-Hop Finder Process </heading>
<paragraph id="P-0353" lvl="0"><number>&lsqb;0353&rsqb;</number> One aspect of the present invention is that, despite the fact that two stages are involved in the find operation, this fact is hidden from the applications programmer. The find operation appears to the user as a single seamless operation. There is quite a range of possible implementation strategies and technologies that could be used for building the first stage of the finder, sometimes referred to as the guidance stage, for example, relational database tables to correlate keys and partition identifiers. This would really be overkill for a number of reasons. First, there is no real need for the first stage data store to be transactional. Less than 100% clean data is acceptable in the first stage. If the guidance stage occasionally points one to the wrong place, or to nowhere, the find procedure is backed up by a brute force parallel query to all entity class partition containers. Thus, the system can always find out where, if anywhere, the desired object is actually stored. Moreover, directing all find queries to the same database invites bottlenecks. </paragraph>
<paragraph id="P-0354" lvl="0"><number>&lsqb;0354&rsqb;</number> Additionally, in accordance with an exemplary embodiment of the present invention, a non-transactional guidance stage can be self-healing. Strictly speaking, the guidance stage does not even need to be persistent, but instead can take on the form of cache held in volatile memory. This is so because guidance data is, in principle, recoverable using the parallel query approach outlined above. The PK-partition mapping results returned from the parallel query are replicated down to each entity class satellite. The idea is that distribution and replication of the guidance data (which allows availability and scaling to meet access volumes) is more important than transactional integrity or absolute fault tolerance. </paragraph>
<paragraph id="P-0355" lvl="0"><number>&lsqb;0355&rsqb;</number> One approach to building a guidance stage of the multi-hop finder is to use an enterprise level directory service, such as an LDAP-based service or the enterprise repository, to store the mapping from PK onto partition number or whatever information uniquely identifies the relevant container where the entity is stored. This approach has the advantage of being automatic because newly-created entity objects can register themselves similar to services whenever they are started. However, due to the increased traffic to the enterprise repository, more repositories must be utilized and the PK-partition mapping replicated across all the enterprise lookups in order to guard against bottlenecking at the enterprise lookup (or LDAP-based service). </paragraph>
<paragraph id="P-0356" lvl="0"><number>&lsqb;0356&rsqb;</number> An alternative to the enterprise lookup approach is to incorporate a cache architecture in certain entity class components, such as the steward and/or the satellites. In this approach, a cache of PK-to-partitionId entries is maintained in volatile storage out in the various satellite servers that has already been configured for holding streamed object clones. The guidance cache is in the form of a finite size, in-core hash table, following LRU (least recently used) chain semantics typical of caches. One feature is that the satellite caches exist in any number across the enterprise, as appropriate, to prevent the guidance stage from becoming a bottleneck (similar to how the problem of bottlenecking at the domain registrars is handled). The cached guidance stages are largely self-maintaining and present one level of a multi-level faulting approach to handle cache misses. When a find-by-PK operation is invoked by the user, the satellite cache is checked for a match. If found, the find request is sent to the relevant entity partition container. If there is a cache miss at the satellite, the process faults over to a centralized master store of the complete set of guidance data. This store may actually be present in two locations, the enterprise repository and the steward. Thus, the enterprise repository, populated with PK-partition mapping from data object registrations, is free. The other central store of guidance data is maintained by an entity management engine (the steward). It is expected that some embodiments of the present invention will utilize the guidance data in the steward, while others will use the guidance data in both the enterprise lookup and the steward. However, it should be noted that if the enterprise repository is checked, then the steward should also be checked because the process faults over to the steward automatically. </paragraph>
<paragraph id="P-0357" lvl="0"><number>&lsqb;0357&rsqb;</number> However, if for whatever reason a match is not found in either the steward or enterprise lookup, the process then faults over to a brute force parallel query out to all known entity partitions to find who has the data. Note that it is the steward who remains aware of all current partitions and who is responsible for initiating this brute-force query to all known partitions. Also note that this query to all partitions proceeds in parallel in concurrent threads. In accordance with exemplary alternative embodiments of the present invention, the query takes one of two forms. First, query all known partitions for the partition holding the data that is identified by the specific primary key being sought. Alternatively, the query might instead be a request for all partitions to declare their primary key identifier of all entity instances. In that case, the response will repopulate all guidance data held by the steward, along with PK-partition mapping information held in the satellites. </paragraph>
<paragraph id="P-0358" lvl="0"><number>&lsqb;0358&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 27</cross-reference> is a flowchart depicting a multi-hop find process in accordance with an exemplary embodiment of the present invention described above. <cross-reference target="DRAWINGS">FIG. 26</cross-reference> is a diagram depicting DataBus components necessary for performing the multi-hop find process described in the flowchart of <cross-reference target="DRAWINGS">FIG. 27</cross-reference>. Each of the relevant process steps is depicted in <cross-reference target="DRAWINGS">FIG. 26</cross-reference> as an arrow accompanied with the corresponding step number for <cross-reference target="DRAWINGS">FIG. 27</cross-reference>. The process begins with client <highlight><bold>2620</bold></highlight> looking up satellite service <highlight><bold>2612</bold></highlight> in domain registrar <highlight><bold>2632</bold></highlight> (step <highlight><bold>2702</bold></highlight>). As discussed above with respect to <cross-reference target="DRAWINGS">FIG. 12A, a</cross-reference> NW service can be found in the lookup table by its attributes rather than by its interface. Client <highlight><bold>2620</bold></highlight> returns the proxy object for interacting with satellite <highlight><bold>2612</bold></highlight> (step <highlight><bold>2704</bold></highlight>). Should client <highlight><bold>2720</bold></highlight> already have the interface for satellite <highlight><bold>2612</bold></highlight>, then steps <highlight><bold>2702</bold></highlight> and <highlight><bold>2704</bold></highlight> can be omitted. </paragraph>
<paragraph id="P-0359" lvl="0"><number>&lsqb;0359&rsqb;</number> The find operation is a two-step process wherein the first step locates the partition holding the entity instance and the second step is a local find where the partition is requested to return an interface for the entity instance. The process begins with client <highlight><bold>2620</bold></highlight> issuing a findByPk( ) to satellite <highlight><bold>2612</bold></highlight> via the satellite&apos;s proxy (step <highlight><bold>2706</bold></highlight>). If satellite <highlight><bold>2612</bold></highlight> has the PK-partition mapping listed, the satellite identifies the partition holding the entity instance and the process moves on to the second step wherein the satellite performs the local find (step <highlight><bold>2708</bold></highlight>). If, however, the PK-partition map is not in the satellite <highlight><bold>2612</bold></highlight>&apos;s cache, the satellite looks up the primary key in enterprise repository <highlight><bold>2630</bold></highlight> (step <highlight><bold>2710</bold></highlight>). (Note that the satellite will cache the new information.) If, at this point, satellite <highlight><bold>2612</bold></highlight> finds the primary key in enterprise repository <highlight><bold>2630</bold></highlight>, the satellite retrieves partition information and performs a local find in that partition (step <highlight><bold>2712</bold></highlight>). If, however, the primary key is not listed in the enterprise repository, the process faults over to steward <highlight><bold>2610</bold></highlight>. Here Steward <highlight><bold>2610</bold></highlight> can perform various alternative processes. First, if steward <highlight><bold>2610</bold></highlight> has a listing for the primary key in its cache, it merely passes the partition identifier to satellite <highlight><bold>2612</bold></highlight>. Alternatively, steward <highlight><bold>2612</bold></highlight> executes a parallel query for the partition holding the primary key. Once the partition identifies itself to steward <highlight><bold>2610</bold></highlight>, that information is again passed to satellite <highlight><bold>2612</bold></highlight>. Further, in accordance with another embodiment of the present invention, steward <highlight><bold>2610</bold></highlight> executes a parallel query for all entity-class partitions to report the primary keys for their entity instances. In that case, steward <highlight><bold>2610</bold></highlight> can repopulate its own cache with the PK-partition mappings received from the individual partitions. That information is then passed down to the entity-class satellites (<highlight><bold>2612</bold></highlight>-<highlight><bold>2618</bold></highlight>) which repopulate their caches with the PK-partition mappings (step <highlight><bold>2714</bold></highlight>). </paragraph>
<paragraph id="P-0360" lvl="0"><number>&lsqb;0360&rsqb;</number> In any case, at this point satellite <highlight><bold>2612</bold></highlight> will have identified the partition holding the entity instance and performs a local find (step <highlight><bold>2716</bold></highlight>). Satellite <highlight><bold>2612</bold></highlight> makes the findByPk( ) to the home interface of the partition identified as having the entity instance. The partition container returns a proxy for the entity instance to client <highlight><bold>2620</bold></highlight> for interacting with the instance (step <highlight><bold>2718</bold></highlight>). The process then ends. </paragraph>
<paragraph id="P-0361" lvl="0"><number>&lsqb;0361&rsqb;</number> Logical domains are used to narrow the context of an operation to a scope that is smaller than the entire enterprise. <cross-reference target="DRAWINGS">FIG. 28</cross-reference> is a diagram representing a logical domain boundary defined from partitions in each of several entities in accordance with one embodiment of the present invention. Domains are, in a sense, orthogonal to the dimension of entity type or subject area cutting across different entity boundaries. Individual domains may be defined along with any pertinent grouping, for example, along geographic lines or along lines of business, or according to some other classification. Logical domains supplement the methods of finding entity instances, such as by using either multi-stage finder strategy using primary keys described above, or to chase relationship paths from a known entity to related entities using the mechanism of externalized associative engines, the description of which follows. </paragraph>
<paragraph id="P-0362" lvl="0"><number>&lsqb;0362&rsqb;</number> Logical domains are particularly useful with respect to situations in which a user needs to locate one or more entities, starting cold, by criteria that are more complex than a search by primary key. In these situations, the where clause of the SQL select query may be used for the more complex find-by-criteria operations and can be performed in parallel out at the separate partition containers for a given entity, and then the results can be coalesced. However, there is no need to perform these parallel find operations at entity partitions where the entity could not possibly be located by searching a U.K. customer base when trying to find a U.S. customer. In these situations, it is desirable to scope the range of an operation to a logical subset of all partitions. Logical domains provide the means to perform this narrowing of scope. </paragraph>
<paragraph id="P-0363" lvl="0"><number>&lsqb;0363&rsqb;</number> In formal terms, the organization of data into logical domains is represented by a mapping from the pair </paragraph>
<paragraph lvl="0"><in-line-formula>(entity class name, domain common-name) </in-line-formula></paragraph>
<paragraph id="P-0364" lvl="2"><number>&lsqb;0364&rsqb;</number> onto the set of all partitions where entities of that type and logical domain are stored: </paragraph>
<paragraph lvl="0"><in-line-formula>D: (entity type, domain name)&verbar;&rarr;&lcub;partitions&rcub;</in-line-formula></paragraph>
<paragraph id="P-0365" lvl="0"><number>&lsqb;0365&rsqb;</number> Domains are closely related to the notion of data partitions serving as a logical overlay on top of the physical partitions. In the simplest form, a domain could amount to nothing more than an alias for a specific partition of some entity providing a more user-friendly common-name in place of a physical partition identifier. For example, domain &ldquo;UK&rdquo; might map onto partition &num;8 for the Customer entity. However, a given domain for a given entity may span several partitions. More than one domain could coexist and overlap to represent the dissection of the enterprise along different dimensions (e.g., geographic and line of business). </paragraph>
<paragraph id="P-0366" lvl="0"><number>&lsqb;0366&rsqb;</number> Logical domain mapping may be stored in a directory service that would be used during find operations to identify all the physical partitions that are relevant for a given entity within a desired logical domain. When a partition is created after the fact, the partition can be assigned to one or more logical domains. </paragraph>
<paragraph id="P-0367" lvl="0"><number>&lsqb;0367&rsqb;</number> At runtime, the use of the logical domains is particularly relevant in the entity creator methods and the entity finder methods. It can be understood from the description of creating an entity as described with respect to <cross-reference target="DRAWINGS">FIG. 21</cross-reference> above, that there is no explicit notion of where to create it; the &ldquo;where&rdquo; question is answered implicitly by the entity container that the client has an interface to. With respect to the present invention, creator methods are introduced that allow the specification of where to create the instance. Each entity&apos;s create interface (implemented by the satellites) needs to supply a createInPartition( ) method that explicitly indicates the physical partition in which the new instance should be created. Also required is a createInDomain(String domain) method that allows the user to specify in which domain the instance should be created. This method would first use directory services to map the specified domain name onto the set of partitions that belonged to that domain. It would then use some policy (e.g., random selection or greatest available capacity) to select one physical partition from the set of qualifying partitions; the new instance would then be created in that partition. In accordance with a further embodiment of the present invention, a createInDomains(String&lsqb; &rsqb; domains) method searches the directory for all partitions belonging to all specified domains (intersection) to deploy a new entity instance in a partition that concurrently belonged to two or more domains (e.g., placing an entity simultaneously in Europe and Internet LOB domains). </paragraph>
<paragraph id="P-0368" lvl="0"><number>&lsqb;0368&rsqb;</number> In accordance with another embodiment of the present invention, another major area where domains would be visible in the user interfaces is in the complex finders for an entity. These find-by-criteria methods are given an extra argument for naming one or more domains to be intersected. The find operation is then performed in parallel out at all partitions matching the specified domain(s). The results of the parallel queries would then be coalesced and returned to the requester. </paragraph>
</section>
<section>
<heading lvl="1">Externalization of Associations </heading>
<paragraph id="P-0369" lvl="0"><number>&lsqb;0369&rsqb;</number> The above-described data architecture externalizes relationships between entities using association data storage that is completely de-coupled from the participating entities themselves. This model departs from traditional relational practice of using foreign keys within entity tables to represent relationships, or the analogous object-oriented practice of &ldquo;burying&rdquo; object references within other objects. In essence, the entities themselves have no immediate awareness of the associations in which they participate. This knowledge is completely encapsulated within an outside authority, the association engine that manages the association and ensures that integrity constraints are not violated. </paragraph>
<paragraph id="P-0370" lvl="0"><number>&lsqb;0370&rsqb;</number> The externalization of associations is extremely flexible in that new associations may be added to existing entities as business models evolve. Thus, new entities can be introduced and associated with existing entities without any impact upon those existing entity classes or the instances themselves. This externalization is possible because neither the entity class nor the entity instance internally track any information relating to associating, or linking through association, to other entities. Rather, the external association engine is modified with association information (the links) for the additional entities which makes for an extremely loosely-coupled fabric of business objects. As an example of this flexibility, a new association can be easily defined to append supplementary information to an existing entity to support the needs of a new service. This is somewhat like object subclassing (inheritance), but is in some ways, more powerful. The supplementary information can even be applied after the fact to entity instances already in deployment which is not possible with object inheritance. Furthermore, externalized associations allow any objects housed in any store across the enterprise to be linked together with any other object in the enterprise. Externalized associations also have less rigidity in the face of evolving business models than does the conventional approach of realizing a data schema as foreign keys within entity tables. </paragraph>
<paragraph id="P-0371" lvl="0"><number>&lsqb;0371&rsqb;</number> The association engines that manage relationships between entities are built from reusable infrastructure. A number of different specialized association engines are supplied to support the different common association types. For example, specialized association engines will support the common cardinalities of one-to-one, one-to-many and many-to-many relationships. Another possible variation is the addition of an ordering property to one-to-many or many-to-many relationships which is useful in, for example, ordering the circuit legs that comprise the end-to-end path of a complete circuit. Other more specialized associations are possible, such as ternary associations linking triplets of entities. </paragraph>
<paragraph id="P-0372" lvl="0"><number>&lsqb;0372&rsqb;</number> The following pseudo-code gives a sketch of how an application programmer might find a Customer instance by primary key, then traverse a one-to-many association to fetch all the Account instances belonging to that customer:  
<table-cwu id="TABLE-US-00001">
<number>1</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217PT" align="left"/>
<thead>
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="1" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry>//</entry>
</row>
<row>
<entry>// We assume an interface to a lookup service:</entry>
</row>
<row>
<entry>Lookup lookup;</entry>
</row>
<row>
<entry>// The Customer PK:</entry>
</row>
<row>
<entry>long customerId &equals; 1234L;</entry>
</row>
<row>
<entry>// Use the lookup service to get a finder interface for</entry>
</row>
<row>
<entry>// the Customer entity:</entry>
</row>
<row>
<entry>CustomerFinder finder &equals; (CustomerFinder)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="OFFSET" colwidth="14PT" align="left"/>
<colspec colname="1" colwidth="203PT" align="left"/>
<tbody valign="top">
<row>
<entry></entry>
<entry>lookup.getService (&ldquo;entity.finder.Customer&rdquo;);</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217PT" align="left"/>
<tbody valign="top">
<row>
<entry>// Use the lookup service to get the interface to the</entry>
</row>
<row>
<entry>// Customer/Account association engine:</entry>
</row>
<row>
<entry>CustomerAccountAssoc assoc (CustomerAccountAssoc)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="OFFSET" colwidth="14PT" align="left"/>
<colspec colname="1" colwidth="203PT" align="left"/>
<tbody valign="top">
<row>
<entry></entry>
<entry>Lookup.getservice (&ldquo;assoc.1-m.customer.account&rdquo;);</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217PT" align="left"/>
<tbody valign="top">
<row>
<entry>// Use the finder interface to obtain remote reference to</entry>
</row>
<row>
<entry>// relevant Customer entity:</entry>
</row>
<row>
<entry>Customer cust &equals; finder.findByPkrcustomerId);</entry>
</row>
<row>
<entry>// Traverse the association from the Customer source object</entry>
</row>
<row>
<entry>// to obtain an array of all associated Account objects:</entry>
</row>
<row>
<entry>Account &lsqb;&rsqb; accounts &equals; assoc.getAccountsForCustomer(cust);</entry>
</row>
<row>
<entry>// Exercise the functionality of the Customer and Account</entry>
</row>
<row>
<entry>// objects through their remote interfaces:</entry>
</row>
<row>
<entry>cust.dosomething ();</entry>
</row>
<row>
<entry>// etc.</entry>
</row>
<row><entry namest="1" nameend="1" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0373" lvl="0"><number>&lsqb;0373&rsqb;</number> This sample code illustrates the use of class-level entity functionality through an entity&apos;s finder interface, the exercising of association functionality through an association engine interface, and the use of an entity&apos;s instance-level interface (i.e., cust.doSomething( )). The most striking aspect about this sample code is that the program asks the association interface to return the Accounts related to the Customer, rather than the more familiar object-oriented practice of asking the Customer object for its Accounts. Note that the entity and association engines and their storage might be physically located anywhere across the enterprise, while access should, nevertheless, remain this simple and transparent. Finally, the entity and association engines appear to the client as centralized services deployed somewhere &ldquo;out there.&rdquo; This centralization is purely logical . . . an illusion that hides the distributed, de-centralized nature of the implementation. </paragraph>
<paragraph id="P-0374" lvl="0"><number>&lsqb;0374&rsqb;</number> The above-described routine for navigating to all the Account instances belonging to a particular Customer instance based on the Customer&apos;s primary key will now be described in the NewWave environment with respect to <cross-reference target="DRAWINGS">FIGS. 29 and 30</cross-reference>. <cross-reference target="DRAWINGS">FIGS. 29 and 30</cross-reference> are a diagram and a flowchart, respectively, depicting a process for fetching all the Account instances belonging to that Customer instance based on the Customer&apos;s primary key in accordance with an exemplary embodiment of the present invention. </paragraph>
<paragraph id="P-0375" lvl="0"><number>&lsqb;0375&rsqb;</number> With reference to <cross-reference target="DRAWINGS">FIG. 29, a</cross-reference> diagram of NW service platform infrastructure of interrelated services relating to an enterprise is illustrated in accordance with an exemplary embodiment of the present invention. There, entity servers <highlight><bold>2902</bold></highlight>A and <highlight><bold>2902</bold></highlight>B are shown with the respective databases <highlight><bold>2904</bold></highlight>A and <highlight><bold>2906</bold></highlight>A for server <highlight><bold>2902</bold></highlight>A, while databases <highlight><bold>2904</bold></highlight>B and <highlight><bold>2906</bold></highlight>B are hosted by server <highlight><bold>2902</bold></highlight>B. In the depicted Figure, each server has two VM containers <highlight><bold>2908</bold></highlight> and <highlight><bold>2910</bold></highlight> running, and each container has two NW partition services running within. Partitions <highlight><bold>2908</bold></highlight> and <highlight><bold>2910</bold></highlight> are responsible for two main things&mdash;retrieving one or more instances of a business object and creating a new instance of a business object. Typically, client <highlight><bold>2940</bold></highlight> would not directly invoke methods of the partition, but would utilize instead a satellite service. Notice that the Figure depicts four entity classes, A-D, representative of, for example, Customer, Account, Billing Address and Pending Order entity classes. Notice also that each of the entity classes is partitioned. With respect to the present Figure, each entity has two partitions, but in practice, most entities would have many more partitions. Each partition is responsible for a plurality of entity instances which are identifiable by a primary key. Also depicted is registrar <highlight><bold>2930</bold></highlight> which may be a domain registrar as described above with respect to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. It is expected that the business objects normally used by a client are proximate to that client, thus a fair assumption is that all components represented in <cross-reference target="DRAWINGS">FIG. 29</cross-reference> are in a local domain, such as the local domains defined by a multicast radius as further described above with respect to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. However, as has been alluded to above, and which will be described in greater detail below, a client may interact with business objects located anywhere in the enterprise, locally or non-locally. Thus, servers <highlight><bold>2902</bold></highlight>A and <highlight><bold>2902</bold></highlight>B may or may not be local, while registrar <highlight><bold>2930</bold></highlight> and finder <highlight><bold>2932</bold></highlight> are local to client <highlight><bold>2940</bold></highlight>. However, the operations that each of these services perform might lead to hops in other non-local domains. </paragraph>
<paragraph id="P-0376" lvl="0"><number>&lsqb;0376&rsqb;</number> Also shown in <cross-reference target="DRAWINGS">FIG. 29</cross-reference> is 1:M entity A-B association engine <highlight><bold>2934</bold></highlight> which provides the logic and table resources for tracking all instances of class A (Customer class) to instances of class B (Account calls) through 1:M associations between Customer entity instances and Account entity instances. In practice, an association engine service will be available for the enterprise for each association between entities (similar to the association engines depicted in the E-R diagram on <cross-reference target="DRAWINGS">FIG. 16B</cross-reference>). The table resource list links the instance between the Customer entity class A and the Account entity class B. Each time a customer makes a new enterprise account, a new Account entity is created in a partition and a link is added to engine <highlight><bold>2934</bold></highlight> from the customer instance to the newly-created account instance. </paragraph>
<paragraph id="P-0377" lvl="0"><number>&lsqb;0377&rsqb;</number> Finder service <highlight><bold>2932</bold></highlight> may be a satellite service which will be described below. Briefly stated, a satellite is responsible for two main things, finding existing entity instances and creating new entity instances of the business object. Satellites are helper services to a steward service that allocates blocks of primary keys to the satellites and locates a partition based on a specific primary key. It should be understood that in the enterprise there is only one steward for each entity class in the enterprise, but there might be many satellites distributed across the domain for that entity class whose purpose is to help the steward. Finally, <cross-reference target="DRAWINGS">FIG. 29</cross-reference> further depicts the interaction between components with lines that are representative of the correspondingly-numbered step in the flowchart depicted in <cross-reference target="DRAWINGS">FIG. 30</cross-reference>. </paragraph>
<paragraph id="P-0378" lvl="0"><number>&lsqb;0378&rsqb;</number> With respect to the process depicted on the flowchart illustrated in <cross-reference target="DRAWINGS">FIG. 30</cross-reference>, the process begins with client <highlight><bold>2940</bold></highlight> possessing a primary key that identifies a Customer entity instance for a customer. Client <highlight><bold>2940</bold></highlight>, needing account information for the client, looks up the address (URL, URI) of the finder service <highlight><bold>2932</bold></highlight> in registrar <highlight><bold>2930</bold></highlight>&apos;s lookup (step <highlight><bold>3002</bold></highlight>). As discussed in great detail above, the registrar returns a proxy to finder service <highlight><bold>2932</bold></highlight> which allows client <highlight><bold>2940</bold></highlight> to interact with finder service <highlight><bold>2932</bold></highlight> (step <highlight><bold>3004</bold></highlight>). A similar lookup is performed for the Customer/Account Association Engine service <highlight><bold>2934</bold></highlight> (step <highlight><bold>3006</bold></highlight>) where an appropriate proxy is returned for client <highlight><bold>2940</bold></highlight> to interact with engine <highlight><bold>2934</bold></highlight> (step <highlight><bold>3008</bold></highlight>). Client <highlight><bold>2940</bold></highlight> then uses the finder service to obtain a remote reference to the customer entity instance identified by the primary key (step <highlight><bold>3010</bold></highlight>). With a reference to the Customer instance, client <highlight><bold>2940</bold></highlight> can access the data using one of the data access modes to be described below. Next, client <highlight><bold>2940</bold></highlight> conveys the Customer instance primary key to Association Engine <highlight><bold>2934</bold></highlight> which traverses its association table and returns references to all Account entity instances associated with (link to) the Customer primary key (step <highlight><bold>3012</bold></highlight>). Alternatively, Association Engine <highlight><bold>2934</bold></highlight> might pass the primary keys to all associated Account entity instances making client <highlight><bold>2940</bold></highlight> responsible for looking up each key. Finally, client <highlight><bold>2940</bold></highlight> uses the reference to the Customer and client entity instances to exercise the functionality of the entity instances (step <highlight><bold>3014</bold></highlight>). </paragraph>
<paragraph id="P-0379" lvl="0"><number>&lsqb;0379&rsqb;</number> Due to the pattern of relationship traversal implicit in a method like &ldquo;getAccountsForCustomer( ),&rdquo; the method returns all destination objects that are associated with a given source object. The complete set of entity instances may be more than necessary. A lack of filtering during a relationship traversal is a shortcoming of the proposed network-style of distributed data management in comparison to the full expressive power of the SQL &ldquo;where&rdquo; clause to narrow a join operation. One way of compensating for this shortcoming is to adopt the pattern of implementing narrowing or filtering methods at the class level in entity implementations. A narrowing method would take as an input an array of entity instance references, apply filtering criteria (probably using a SQL select), and return the filtered array of the subset of entities matching the criteria. With such a narrowing method available, the more restricted relationship traversal would be effected by calling upon the association engine to perform the initial traversal, then passing the resulting array of destination objects to the entity home interface for the narrowing operation resulting in extraneous remote calls and data passing. This pattern is illustrated in the following pseudo-code:  
<table-cwu id="TABLE-US-00002">
<number>2</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="OFFSET" colwidth="14PT" align="left"/>
<colspec colname="1" colwidth="203PT" align="left"/>
<thead>
<row>
<entry></entry>
<entry></entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="1" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry></entry>
<entry>// Find all accounts for given customer:</entry>
</row>
<row>
<entry></entry>
<entry>Account &lsqb;&rsqb; accounts &equals; assoc.getAccountsForCustomer (cust);</entry>
</row>
<row>
<entry></entry>
<entry>// Look up the Account home interface:</entry>
</row>
<row>
<entry></entry>
<entry>AccountHome acctHome &equals;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="OFFSET" colwidth="28PT" align="left"/>
<colspec colname="1" colwidth="189PT" align="left"/>
<tbody valign="top">
<row>
<entry></entry>
<entry>lookup.getservice (&ldquo;entity.home.account&rdquo;);</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="OFFSET" colwidth="14PT" align="left"/>
<colspec colname="1" colwidth="203PT" align="left"/>
<tbody valign="top">
<row>
<entry></entry>
<entry>// Filter the accounts to those older than 48 months:</entry>
</row>
<row>
<entry></entry>
<entry>acctHome.narrowToOlderThan (accounts, 48);</entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="1" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0380" lvl="0"><number>&lsqb;0380&rsqb;</number> As an alternative, a client could also sequence through the unfiltered array of accounts and perform its own filtering via some criteria; however, this approach is very network intensive. </paragraph>
<paragraph id="P-0381" lvl="0"><number>&lsqb;0381&rsqb;</number> A third alternative, mentioned above, is for the client to pass in a Java filter object to the association engine during association traversal. The filter is a serializable Java object, whole code is fetchable at runtime by the Java language infrastructure from its codebase URL. The association engine can apply the client-supplied, custom filter to an association traversal result set before returning the result set to the client. </paragraph>
<paragraph id="P-0382" lvl="0"><number>&lsqb;0382&rsqb;</number> Merely gathering a suitably-filtered solution set of entity instances is not the only challenge of the process described above. Another challenge to be overcome is that the architecture depicted in <cross-reference target="DRAWINGS">FIG. 29</cross-reference> is not overly scalable. Two factors thwart scalability after a certain point. First, there is an absolute threshold number of entity instances in an entity class that can be supported by association engine <highlight><bold>2934</bold></highlight>. Beyond that number, performance is rapidly reduced. Secondly, the quantity of links between the entity instances is reduced. Obviously, this is not a concern with 1:1 cardinality association engines, but the performance of 1:M and N:M cardinality association engines drops off as the number of links increases. Moreover, 1:M and N:M cardinality association engine performance decreases as a nonlinear rate with increased entity loading because the possible number of links increases by M with the addition of a single entity instance to the data. However, before discussing solutions to the above-described shortcomings, data access and the role partitioning plays in system scalability will be discussed. </paragraph>
</section>
<section>
<heading lvl="1">The Scaling Problem </heading>
<paragraph id="P-0383" lvl="0"><number>&lsqb;0383&rsqb;</number> As described above, extensive entity partitioning and distribution is central to the DataBus scalability strategy. Entities are scaled to nearly unlimited volumes of data by simply adding more and more partitions of relatively constant size in accordance with the present invention. However, as the volume of data grows, the central association engine must also expand to accommodate the new data and associations. However, at some point this growth becomes constrictive. The centralized nature of the external association engine architecture results in an overall reduction in DataBus navigation capacity due to bottlenecking inefficiencies inherent in handling the shear quantity of entity association requests with a correspondingly scaled central association engine for the data size. </paragraph>
<paragraph id="P-0384" lvl="0"><number>&lsqb;0384&rsqb;</number> In accordance with one embodiment of the present invention, the bottlenecking problem is alleviated by applying some of the same concepts in the central association engine that are applied to entities for scaling (i.e., the association engine is partitioned, or more properly, &ldquo;fragmented&rdquo; by partition). Fragmenting the association does two things. It decentralizes the association engine, allowing the association links to be kept proximate to clients that would normally use them, and reduce to a manageable amount the quantity of association links kept in any one location. </paragraph>
<paragraph id="P-0385" lvl="0"><number>&lsqb;0385&rsqb;</number> It should be understood that a link record exists to represent every pair of entities involved in an association describes an association relationship between two instances from the respective entities. Of course, with respect to the present invention, each of these instances must be contained in a separate partition (i.e., from the separate entities). Therefore, in accordance with an exemplary embodiment of the present invention, each of these link records is redundantly stored in two locations. The first link record is stored in an association engine fragment that is physically proximate to the entity partition where the source object is located. In fact, the engine fragment is logically coupled to that entity partition. The duplicate link is stored in a second location that is physically proximate to the entity partition in which the destination object is located. It is also referenced or coupled to the entity partition where the destination object resides. Thus, there is a fragment of the association link records co-located with respect to each entity partition. The association engine is logically central, but physically composed of fragments that may be widely dispersed. To traverse a relationship from a specific source object, the association fragment coupled to that source object&apos;s partition is used. Likewise, the association storage fragment coupled to the destination entity&apos;s partition is used for traversing the relationship in the backward direction. This approach to partitioning the associations allows both the association and entity storage to remain relatively constant in size as one adds more and more partitions. </paragraph>
<paragraph id="P-0386" lvl="0"><number>&lsqb;0386&rsqb;</number> The precise structure of the association engine fragments might be better understood with resect to the description of <cross-reference target="DRAWINGS">FIG. 31</cross-reference> which is a diagram showing external central association engine <highlight><bold>3102</bold></highlight> consisting of a plurality of link records which describe associative relationships between Customer entity instances and Account entity instances. A client merely accesses engine <highlight><bold>3102</bold></highlight> with a unique identifier for a Customer entity and utilizes the association link records to find any association relationships that might exist to any and all Account entity instances. In accordance with an exemplary embodiment of the present invention, external central entity association engine <highlight><bold>3102</bold></highlight> is &ldquo;fragmented&rdquo; into association engine fragments <highlight><bold>3112</bold></highlight>, <highlight><bold>3114</bold></highlight>, <highlight><bold>3116</bold></highlight>, <highlight><bold>3118</bold></highlight>, <highlight><bold>3122</bold></highlight> and <highlight><bold>3124</bold></highlight>, one for each entity partition from the participating entities. Each association engine fragment is proximately coupled to a specific entity partition. In practice, a partition references its association engine fragment, though this record of links should remain physically close to the partition as the partition will call on the engine fragment for association link records. Association links between entity instances recorded in central engine <highlight><bold>3102</bold></highlight> are divided up between the partitions&apos; engine fragments resulting in twice as many link records as in central engine <highlight><bold>3102</bold></highlight>. This occurs because each link that was previously recorded for an association between two instances is now recorded in the partition&apos;s association engine fragment for each instance&apos;s partition. Notice t, although entity instances in central engine <highlight><bold>3102</bold></highlight> are identified only by their unique identifier (primary key), the entity instances in the engine fragments <highlight><bold>3112</bold></highlight>, <highlight><bold>3114</bold></highlight>, <highlight><bold>3116</bold></highlight>, <highlight><bold>3118</bold></highlight>, <highlight><bold>3122</bold></highlight> and <highlight><bold>3124</bold></highlight> are associated with a particular entity partition. It should be understood that this is merely an exemplary embodiment and that destination instances might be identified only by their unique identifiers because the client can always look up the partition container with a find service from the instance&apos;s identity as described elsewhere and above. </paragraph>
<paragraph id="P-0387" lvl="0"><number>&lsqb;0387&rsqb;</number> Storing link records in engine fragments for both the source instance and the destination instance results in doubling the amount of records to be stored. External association engine <highlight><bold>3102</bold></highlight> is depicted as having sixteen links between instances from two entity classes (thirteen instances in the Customer entity class and nine instances in the Account entity class). Thus, resultant association engine fragments <highlight><bold>3112</bold></highlight>, <highlight><bold>3114</bold></highlight>, <highlight><bold>3116</bold></highlight>, <highlight><bold>3118</bold></highlight>, <highlight><bold>3122</bold></highlight> and <highlight><bold>3124</bold></highlight> contain thirty-two association link records, thirteen link records for instances in partition containers for the Customer entity and thirteen link records instances in partition containers for the Account entity. </paragraph>
<paragraph id="P-0388" lvl="0"><number>&lsqb;0388&rsqb;</number> The quantity of association engine fragments corresponds with the total number of partitions between the entities. If, for instance, one of the participating entities (i.e., Customer) is divided into four partitions, and the other, Account, is partitioned two ways, then six association engine fragments would result. It should be understood that it might be possible for the instances in one or more entity partitions to not have associations with the instances in one or more partitions of a second entity. In that case, the total amount of records would still be twice that of the non-fragmented engine, but one or some of the resultant engine fragments would not have association link records. </paragraph>
<paragraph id="P-0389" lvl="0"><number>&lsqb;0389&rsqb;</number> With reference now to <cross-reference target="DRAWINGS">FIG. 32, a</cross-reference> diagram of NW service platform infrastructure of interrelated services relating to an enterprise is illustrated in accordance with an exemplary embodiment of the present invention. <cross-reference target="DRAWINGS">FIG. 32</cross-reference> is identical to <cross-reference target="DRAWINGS">FIG. 29</cross-reference> and therefore will not be described further except to add that arrows depicting the interaction between DataBus components are shown with regard to the process described in <cross-reference target="DRAWINGS">FIG. 33</cross-reference>. </paragraph>
<paragraph id="P-0390" lvl="0"><number>&lsqb;0390&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 33</cross-reference>, on the other hand, is a flowchart depicting a process for getting all accounts instances that are associated with an identified customer instance in accordance with an exemplary embodiment of the present invention. It is assumed that the client has already found an association service and has association proxy <highlight><bold>3230</bold></highlight> to interface with the service. The process begins by identifying the partition container holding the entity instance (step <highlight><bold>3302</bold></highlight>). Although this might be accomplished via finder service <highlight><bold>3232</bold></highlight>, as described above, this extra lookup is not necessary. The smart proxy that serves as a remote handle to an entity actually encapsulates a remote reference (typically an RMI stub) to the entity partition container, as well as other information like PK. In either case, the partition container must be found for the entity instance in order to locate the association engine fragment that is coupled to it (step <highlight><bold>3304</bold></highlight>). Once the container is found, the interface to the coupled association engine fragment is gotten (typically via local registrar service lookup) and the Customer/Account association engine fragment traversed starting from the Customer instance to find all associated Account instances (step <highlight><bold>3306</bold></highlight>). Those instances are then returned to the association engine (step <highlight><bold>3308</bold></highlight>) which passes them on to client <highlight><bold>3240</bold></highlight> (step <highlight><bold>3310</bold></highlight>). At step <highlight><bold>3308</bold></highlight>, it is assumed that the remote interfaces are returned for the Account instances and the client interacts with the Account instances as need be. In one embodiment of the present invention, the link records held in the association fragment engines consist of the triplets (primary key, entity type, partition number) for both source entity and destination entity that are linked. In traversing the association, the association fragment engine must query its link record store for all link records matching a given source entity. Then, given a set of link records, it must resolve the PK, entity type and partition number for destination entities into remote smart proxies for those entities. This could be done via the multi-hop find-by-PK. In practice, we optimize this by caching, in the association fragment engine, a map from (entity-type, partition &num;) onto the remote RMI stub to the corresponding entity partitions. Should this stub lookup suffer a cache &ldquo;miss,&rdquo; the interface to the partition service is fetched via enterprise service lookup described above via a partition naming convention formed from the entity type and partition number. In either case, once remote reference to destination partition or partitions is available, the association fragment engine can request those partitions to return smart proxies corresponding to all the destination entities matching the destination PKs. </paragraph>
<paragraph id="P-0391" lvl="0"><number>&lsqb;0391&rsqb;</number> In accordance with another embodiment of the present invention, the client need only to be able to identify a particular entity instance to efficiently navigate to all data stores associated with that instance using the association engine fragments. Thus, a client merely invokes an assoc.getAccountsForCustomer(cust) method, just as described above with respect to the process depicted in <cross-reference target="DRAWINGS">FIG. 30</cross-reference>. It appears to the user that they are exercising a remote interface to a central association engine, while there is in fact no such central association engine. This slight-of-hand is accomplished by using smart proxies, a concept we have already mentioned in a number of other contexts above. Thus, many of the steps described in the process immediately above are being performed out of view from client <highlight><bold>3230</bold></highlight>. </paragraph>
<paragraph id="P-0392" lvl="0"><number>&lsqb;0392&rsqb;</number> Now, by way of contrast, the process described above from the flowchart in <cross-reference target="DRAWINGS">FIG. 33</cross-reference> will be described below, but using smart proxies. <cross-reference target="DRAWINGS">FIG. 34</cross-reference> is a flowchart depicting a process for getting all accounts instances that are associated with an identified customer instance using smart proxies in accordance with an exemplary embodiment of the present invention. The process begins with the client invoking a traversal method, assoc.getAccountsForCustomer (aCustomer), with the association engine (not shown). This method invokes logic local to the association smart proxy that queries the Customer entity argument (which is itself a smart proxy) for its primary key, partition identifier and its remote interface to the entity container where the actual Customer entity instance is stored (step <highlight><bold>3402</bold></highlight>). The association smart proxy then makes a remote request to the Customer entity&apos;s partition container to traverse the &ldquo;assoc.1-m.customer.account&rdquo; association from the source entity with the given PK (step <highlight><bold>3404</bold></highlight>). The Customer entity container has no built-in knowledge of how to traverse a Customer/Account association. Remember that in loosely coupled DataBus architecture, entities know nothing of associations, and new associations can be added at any time without breaking existing entities in deployment. The entity partition container can look up the interface to the association engine fragment for the association named &ldquo;assoc.1-m.customer.account&rdquo; which is paired with that entity partition (step <highlight><bold>3406</bold></highlight>). The entity partition can also keep a cache of references to these association fragments so it does not have to go out to a lookup service every time. Once the entity partition has found the remote interface to the relevant association engine fragment, it forwards the association traversal request to that association engine fragment, which in turn can accomplish the relationship traversal (step <highlight><bold>3408</bold></highlight>). The association engine fragment queries association database based on Customer PK and requests remote interface (Smart Proxy) for the separate account partition that holds instances associated with the customer. After the Account remote references are passed to the association engine fragment, they get passed back the invocation chain all the way to the requesting client (step <highlight><bold>3410</bold></highlight>), thus ending the process. </paragraph>
<paragraph id="P-0393" lvl="0"><number>&lsqb;0393&rsqb;</number> One aspect of one embodiment of the association approach of the current invention is the novel use of smart proxies in the interfaces to the logical association engine services. In this embodiment, the association engines are accessed through a service interface that is implemented with a smart proxy that, itself, contains no inherent remote references (proxies in stubs) to a remote object. The association engine smart proxies &ldquo;piggyback&rdquo; on the communications channels of the entity smart proxies that are passed to it as parameters in &ldquo;link( )&rdquo; or &ldquo;traverseAssociation( )&quest;&rdquo; requests. For example, when the association interface is told to &ldquo;link&rdquo; entities A and B, the association smart proxy will extract from A and B their remote handles to their respective partition containers. The smart proxy will then proceed to send parallel link requests (in separate threads) to these two entity containers, which in turn forward the requests to the appropriate association fragments. This is a highly novel and a typical example of the use of a smart proxy. It has no communications &ldquo;channels&rdquo; of its own, but rather &ldquo;parasitically&rdquo; employs the communications channels of objects with which it comes into contact. </paragraph>
<paragraph id="P-0394" lvl="0"><number>&lsqb;0394&rsqb;</number> Another feature of one embodiment of the present invention is the manner in which the virtual association engine deals with violations of cardinality integrity. Specifically, when a client requests that a one-to-many association add a new link record, the system must check for cardinality violations. Due to the asymmetric nature of a one-to-many association and the DataBus approach of partitioning entities, only the fragment engine on the &ldquo;many&rdquo; side can reliably detect a cardinality violation. A simple-minded implementation would serialize the link requests to the association fragments on either side of the relation, first to the &ldquo;many&rdquo; side, then only if successful, sending the link request to the &ldquo;one&rdquo; side. In one embodiment of the current invention, these link requests are forwarded in parallel (using two background threads) to the two &ldquo;sides&rdquo; of the association. If the &ldquo;many&rdquo; side detects a cardinality violation, it will throw an exception. The &ldquo;one&rdquo; side will, in any case, proceed to add a link record, all-the-while ignorant of whether doing so violates cardinality constraints. But all such link operations are performed under the oversight of a global transaction. Thus, when the caller of the (illegal) link request catches the cardinality exception, they will (according to the &ldquo;contract&rdquo; they are expected to obey) &ldquo;roll back&rdquo; the global transaction. The &ldquo;one&rdquo; side&apos;s inappropriate adding of an illegal link record will be effectively undone. </paragraph>
</section>
<section>
<heading lvl="1">Management Operations Center Overview </heading>
<paragraph id="P-0395" lvl="0"><number>&lsqb;0395&rsqb;</number> The Management Operations Center (MOC) is an application for providing support for people addressing problems similar to those handled in a Network Operations Center (NOC), but not limited to only network problems. As such, it is intended to support problem management in many forms, including those typically handled by customer support centers and tactical assistance centers. The MOC represents a tool that assumes a fundamental re-engineering of the processes and tools used in these environments. It should not be compared directly against the tools that currently support these environments (trouble tickets, workflows, network management consoles, etc.), but should be analyzed as to how it supports the new re-engineered process. As such, it will not support many things currently expected in these environments because some activities are not needed. </paragraph>
<paragraph id="P-0396" lvl="0"><number>&lsqb;0396&rsqb;</number> The current NOC environment can be described in simple terms as an approach involving monitoring of activity, identification of problems, selection of problems to work on off of a queue, and resolving the problem. By contrast, in accordance with an exemplary embodiment of the present invention, the MOC monitors and identifies problems based on rules set up by experts. Additionally, rather than an ad hoc personnel deployment, the MOC determines the best available personnel for a particular problem based on circumstances and policy rules and then directly invites those persons to work on the problem. Therefore, the work team is composed based on differing roles and skill sets required for the problem, and might involve people from different organizations. Because the MOC is an integration of services, the MOC is able to handle problem cases that are not limited to one area, as is the practice of Network Operations, but to any affected areas. For instance, a problem may bind together a network event, customer tickets, application events, etc. Finally, in accordance with an exemplary embodiment of the present invention, a work event can be worked on and accessed by anyone with connectivity to the NewWave environment, so people involved do not have to be in one center, but could be at home, on the other side of the world, etc. Thus, in stark contrast with prior art attempts, the MOC&apos;s emphasis is on collaboration tools and world-wide access. </paragraph>
<paragraph id="P-0397" lvl="0"><number>&lsqb;0397&rsqb;</number> Operations support systems today tend to be large, closed applications that perform part of the work needed by OSS personnel. OSS personnel usually end up using several systems that overlap and do not talk to each other. As opposed to a closed application that provides merely a partial solution, the MOC of the present invention represents an example of a new way of designing applications: the inside-out design. In this approach to building systems, rather than building monolithic application systems, the &ldquo;application&rdquo; is a collaboration of many smaller units acting on common objects, possibly without knowledge of each other, but with their actions affecting each other. This design also makes heavy use of rules external to code executed by rules engines or policy specific objectives. This allows for changing the behavior of the system without changing the code. Those behaviors which represent organizational policy are removed into rules, and can then be managed by experts in those organizations. </paragraph>
<paragraph id="P-0398" lvl="0"><number>&lsqb;0398&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 35</cross-reference> is a diagram of the MOC and associated NewWave services necessary for collecting events into policy-based work documents, and then directly routing work to the best currently available operations staff that is automatically assembled based on the individual staff members&apos; aptitude for particular tasks in a process flow in accordance with an exemplary embodiment of the present invention. The primary MOC component services are assessor <highlight><bold>3504</bold></highlight>, aggregator <highlight><bold>3506</bold></highlight>, workspace <highlight><bold>3502</bold></highlight>, dispatcher <highlight><bold>3508</bold></highlight>, distributor <highlight><bold>3510</bold></highlight>, avatar <highlight><bold>3512</bold></highlight>, archive <highlight><bold>3514</bold></highlight> and work rendezvous <highlight><bold>3516</bold></highlight>. Before describing the other aspects of the MOC, the functionality of each of the above identified MOC services will be briefly described. Assessor <highlight><bold>3504</bold></highlight> initially receives most events from pub/sub bus <highlight><bold>3528</bold></highlight> and applies operations-specified policy to the treatment of those events using, for example, a rules agent in a commonly shared rule server. Authorized operation staff can change and update policy rules in near-real time using behavior service <highlight><bold>3530</bold></highlight> described below. Highly distributed and individually customizable, typically many (customized) assessors will exist in the MOC system, thus allowing different treatment of events by different operations teams. </paragraph>
<paragraph id="P-0399" lvl="0"><number>&lsqb;0399&rsqb;</number> Aggregator <highlight><bold>3506</bold></highlight> receives event information from pub/sub bus <highlight><bold>3528</bold></highlight> and assessor <highlight><bold>3504</bold></highlight> which it associates and binds together according to an operation&apos;s requested organization of work integration to produce work document <highlight><bold>3630</bold></highlight>. Aggregator <highlight><bold>3506</bold></highlight> also provides real-time binding of associated corporate business objects to the document including binding an event to many different documents. To that end, aggregator <highlight><bold>3506</bold></highlight> contains the templates for documents for, for example, different functional areas/teams. Additionally, many different aggregators will exist and run simultaneously providing different work documents to different teams. Dispatcher <highlight><bold>3508</bold></highlight> applies current policy rules to associate work documents and events with specific operators, customer contacts and other service care staff. Dispatcher <highlight><bold>3508</bold></highlight> assigns work with an understanding of who is free and able to do that work and implements priority rules for understanding relative priority, thus dispatcher <highlight><bold>3508</bold></highlight> can bump work in progress for higher priority tasks. Additionally, dispatcher <highlight><bold>3508</bold></highlight> implement alternates strategies to handle cases where work is refused or overdue. Distributor <highlight><bold>3510</bold></highlight> handles outbound and remote communication notifications for the MOC based on decisions from dispatcher <highlight><bold>3508</bold></highlight>. </paragraph>
<paragraph id="P-0400" lvl="0"><number>&lsqb;0400&rsqb;</number> Each avatar object <highlight><bold>3512</bold></highlight> represents a virtual image of a specific operator&apos;s or customer contact&apos;s skills and responsibilities. Operators, provisions, customer contacts, service support staff and any other management-tasked staff in the customer and network care environment will have an avatar. Avatar <highlight><bold>3512</bold></highlight> provides the MOC with a skills assessment of care staff including reference to a history of past work, interactions and success ratings and a means for contacting and communicating with these individuals. </paragraph>
<paragraph id="P-0401" lvl="0"><number>&lsqb;0401&rsqb;</number> Archive service <highlight><bold>3514</bold></highlight> updates and otherwise modifies work documents for or in storage based on recent experiences. Finally, work rendezvous <highlight><bold>3516</bold></highlight> associates later arriving processed events with events that initially generated a work stream/task. With this service, different people working on the same route or associated task can learn of the complementary work going on. Rendezvous <highlight><bold>3516</bold></highlight> notifies different work documents about all other references to a common event and associates processed events with a work document that contain a reference to the source event. With respect to <cross-reference target="DRAWINGS">FIG. 35</cross-reference>, the GIB services have been discussed thoroughly above and will not be discussed again. </paragraph>
<paragraph id="P-0402" lvl="0"><number>&lsqb;0402&rsqb;</number> The key features of the MOC design are: </paragraph>
<paragraph id="P-0403" lvl="2"><number>&lsqb;0403&rsqb;</number> Rather than a single monolithic application, the MOC employs an inside-out design in which many small components act largely independently of each other, but affecting each other by: </paragraph>
<paragraph id="P-0404" lvl="3"><number>&lsqb;0404&rsqb;</number> directly interacting with shared resources; </paragraph>
<paragraph id="P-0405" lvl="3"><number>&lsqb;0405&rsqb;</number> registering for notification of updates to shared resources; </paragraph>
<paragraph id="P-0406" lvl="3"><number>&lsqb;0406&rsqb;</number> finding each other and communicating via the GIB services of registration and lookup; and </paragraph>
<paragraph id="P-0407" lvl="3"><number>&lsqb;0407&rsqb;</number> publishing messages over the GIB publish/subscribe bus; </paragraph>
<paragraph id="P-0408" lvl="2"><number>&lsqb;0408&rsqb;</number> Providing a mechanism wherein automation and current policy can be applied to managing process; </paragraph>
<paragraph id="P-0409" lvl="2"><number>&lsqb;0409&rsqb;</number> Providing a team to analyze the situation and effect the solution, rather than a succession of individuals, doing a piece and handing off to the next in line; </paragraph>
<paragraph id="P-0410" lvl="2"><number>&lsqb;0410&rsqb;</number> Providing a server side, peer-to-peer interaction environment in which all participants can access the same, real-time information. </paragraph>
<paragraph id="P-0411" lvl="0"><number>&lsqb;0411&rsqb;</number> In general, the overall behavior of the MOC can be changed by adding new components, work templates, or changing policy rules, without directly modifying existing components. All MOC components are NewWave services, using the NewWave registration, lookup and enterprise lookup services. The MOC extends the behavior of its code through the use of external rules engines using the NewWave behavior service. This allows organizations with the expert knowledge of operations support to be in control of the behaviors implementing operations support policy, instead of programming organizations. The MOC must communicate with systems outside of its direct control. It uses XML messages sent over the GIB publish/subscribe buses to do so in a highly decoupled way. In this way, it uses a common approach for receiving events from disparate sources: external sources such as the network, customer service systems and legacy systems; and internal sources such as MOC or NewWave components. Events received are assessed by an assessing component. It is the job of this assessor to apply organizational policy dealing with how a event should be addressed. </paragraph>
<paragraph id="P-0412" lvl="0"><number>&lsqb;0412&rsqb;</number> Work documents are constructed by an aggregating component. It is the job of this aggregating component to put together a document (a software construct) containing what information is needed to resolve the problem, including aggregating related network, customer and application events, setting initial milestones, applying rules which deal with the understanding or categorization of the problem, and binding in related information (such as necessary topology information). Work documents are first class objects accessible through the NewWave DataBus. They are not just data, as they have a controlling feature that allows state changes throughout its life. All components are able to interact with and change it using distributed transaction semantics. </paragraph>
<paragraph id="P-0413" lvl="0"><number>&lsqb;0413&rsqb;</number> People are invited to participate in work groups by a dispatching component running dispatching rules. It is the job of this dispatcher to apply organization policy dealing with who should deal with a problem. </paragraph>
<paragraph id="P-0414" lvl="0"><number>&lsqb;0414&rsqb;</number> People are represented by in-memory &ldquo;avatars&rdquo; which are responsible for knowing the manner in which to communicate with the person, that person&apos;s current workload and information about the person. Technologies for communication are encapsulated within the avatar, allowing other components to not be knowledgeable about or bound to those technologies. An avatar is a first-class object running as a service and can be found and interacted with using standard NewWave techniques. A workspace (<cross-reference target="DRAWINGS">FIG. 39</cross-reference>) is the interaction, peer-to-peer, of those services about a single work item. </paragraph>
<paragraph id="P-0415" lvl="0"><number>&lsqb;0415&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 36</cross-reference> is a functional diagram of the MOC depicting interactions between key MOC components which interact in accordance with an exemplary embodiment of the present invention. Note that <cross-reference target="DRAWINGS">FIG. 36</cross-reference> contains component representations from the MOC, NewWave infrastructure and rule agents <highlight><bold>3632</bold></highlight>. The MOC is responsible for coordinating the response to events which occur within individual components bound into workspace <highlight><bold>3640</bold></highlight> developed for the NewWave environment. Components in workspace <highlight><bold>3640</bold></highlight> might be NewWave-enabled devices, and applications and services developed on NewWave or are detected by NewWave surrogates for external systems, for instance, agents monitoring devices or other resources, and bridges to legacy (non-NewWave) systems. None of these components and surrogates have any special knowledge of the MOC or its functionality and thus are not modified in any special way to interact with the MOC. These components and surrogates are responsible only for knowing when a problem has occurred, and for publishing an XML document describing the problem on the publish/subscribe bus. The only coordination which occurs between the MOC and components <highlight><bold>3630</bold></highlight> is in the definition of the XML document and the topic that it is published with it. </paragraph>
<paragraph id="P-0416" lvl="0"><number>&lsqb;0416&rsqb;</number> To make any component able to be supported by the MOC, it must be able to interact with the MOC components, even though components <highlight><bold>3630</bold></highlight> do not have any specific know-upon format and transmission media. To that end, any component wishing to be supported by the MOC must publish events to the GIB publish/subscribe bus, or to an external publish/subscribe bus with a bridge to the GIB, shown generally as pub/sub service <highlight><bold>3618</bold></highlight>. Each event message must use an agreed-upon XML schema for the format and follow an agreed-upon structure for the topic of the event message. </paragraph>
<paragraph id="P-0417" lvl="0"><number>&lsqb;0417&rsqb;</number> The precise XML document standards are not important for the purposes herein, but some exemplary events are listed below. </paragraph>
<paragraph id="P-0418" lvl="2"><number>&lsqb;0418&rsqb;</number> FMEvent XML (Fault Management Event) XML document, topic ngn.nfp.fm; </paragraph>
<paragraph id="P-0419" lvl="2"><number>&lsqb;0419&rsqb;</number> Application Event XML document, topic ngn.service.admin; </paragraph>
<paragraph id="P-0420" lvl="2"><number>&lsqb;0420&rsqb;</number> Customer Service Event XML document, topic ngn.customerservice; and </paragraph>
<paragraph id="P-0421" lvl="2"><number>&lsqb;0421&rsqb;</number> UUNet Ping Alarm FMEvent XML document, topic ngn.uunet.fm. </paragraph>
</section>
<section>
<heading lvl="1">Building a Work Document Describing an Event </heading>
<paragraph id="P-0422" lvl="7"><number>&lsqb;0422&rsqb;</number> Assessing Events </paragraph>
<paragraph id="P-0423" lvl="0"><number>&lsqb;0423&rsqb;</number> When events are received by the MOC over publish/subscribe bus <highlight><bold>3618</bold></highlight>, they are optionally received by assessor <highlight><bold>3604</bold></highlight>. An assessor is responsible for applying organizational policy dealing with how the organization responds to events of that type. An organization may set policy saying that certain events are ignored; others are problems that must be addressed immediately, etc. </paragraph>
<paragraph id="P-0424" lvl="0"><number>&lsqb;0424&rsqb;</number> Simply put, assessor <highlight><bold>3604</bold></highlight> runs rules agent <highlight><bold>3632</bold></highlight> against an incoming event received from publish/subscribe bus <highlight><bold>3618</bold></highlight>. In accordance with an exemplary embodiment of the present invention, assessor <highlight><bold>3604</bold></highlight> determines, based on the rules, whether the event is a primary event, which must be investigated and then classified by type. The function of assessor <highlight><bold>3604</bold></highlight> is then entirely dependent upon the rules that are set up and executed by the rules engine. These rules would be defined by experts in an organization or set of organizations responsible for handling problem events. An exemplary rules engine for implementing policy based rules is Brokat Advisor and the Brokat Advisor Server (both available form Brokat Aktiengesellschaft Industriestrasse 3, D-70565 Stuttgart, Germany). Because the present invention is supported by the NewWave infrastructure, and relies on remote loading of services which in some forms rely on the Java programming language, a rule engine that is also written in Java would better match the operating environment of the MOC in its use of the mobile rules agents. </paragraph>
<paragraph id="P-0425" lvl="0"><number>&lsqb;0425&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 37</cross-reference>, an assessor is depicted for assessing events based on organizational rules in accordance with an exemplary embodiment of the present invention. Notice that the present invention envisions implementing rules in the normal manner by developers in development <highlight><bold>3710</bold></highlight>. However, the present invention recognizes that the developers are not always the best implementers for rules, nor the timeliest, especially those based on organizational policy, such as from operations <highlight><bold>3712</bold></highlight>. Therefore, the rules may be adjusted, modified, supplemented or even replaced by experts in an organization or set of organizations responsible for handling problem events at, for instance, code server <highlight><bold>3720</bold></highlight>. Code server <highlight><bold>3720</bold></highlight> then serves up the rules to rules agents in behavior service <highlight><bold>3730</bold></highlight>, which are fired whenever an event is received. </paragraph>
</section>
<section>
<heading lvl="1">Work Item Aggregation </heading>
<paragraph id="P-0426" lvl="0"><number>&lsqb;0426&rsqb;</number> The primary process involves building the case, involving the separate activities of: </paragraph>
<paragraph id="P-0427" lvl="2"><number>&lsqb;0427&rsqb;</number> 1. the correlation of the primary event and related events into a single bundle; </paragraph>
<paragraph id="P-0428" lvl="2"><number>&lsqb;0428&rsqb;</number> 2. the building of a work document containing the bundled events and the other related information; </paragraph>
<paragraph id="P-0429" lvl="2"><number>&lsqb;0429&rsqb;</number> 3. the running of rules designed to help determine the cause of the problem; and </paragraph>
<paragraph id="P-0430" lvl="2"><number>&lsqb;0430&rsqb;</number> 4. the control of the life of the work to be done including coordinating the actors involved in the process. </paragraph>
<paragraph id="P-0431" lvl="0"><number>&lsqb;0431&rsqb;</number> A common approach used in both cases to alert the MOC of an anomalous condition is the NewWave publish/subscribe service. As described elsewhere, the publish/subscribe service is part of the NewWave GIB and represents a contract between components for sharing information. </paragraph>
<paragraph id="P-0432" lvl="0"><number>&lsqb;0432&rsqb;</number> Many separate aggregators will be generally deployed within the MOC. It is entirely reasonable for an aggregator to begin work before the assessor, bringing the case up to a certain point to give the assessor adequate information to make its assessment. Then, it could continue its work conditional on the assessment. </paragraph>
<paragraph id="P-0433" lvl="0"><number>&lsqb;0433&rsqb;</number> The basic design of an aggregator is shown in <cross-reference target="DRAWINGS">FIG. 38</cross-reference> in accordance with an exemplary embodiment of the present invention. <cross-reference target="DRAWINGS">FIG. 38</cross-reference> also describes the basic workings of aggregator <highlight><bold>3606</bold></highlight> in accordance with the present invention. Accordingly, events flow into aggregator <highlight><bold>3806</bold></highlight> and pass through a &ldquo;gate,&rdquo; logic gate <highlight><bold>3748</bold></highlight>, which applies some logic to determine whether this event represents a new or existing opportunity for packaging work. Logic gate <highlight><bold>3748</bold></highlight> acts as a logical IF to determine if the event represents new or existing opportunities. </paragraph>
<paragraph id="P-0434" lvl="0"><number>&lsqb;0434&rsqb;</number> If new, aggregator <highlight><bold>3606</bold></highlight> starts a new state machine, and the associated bucket for collecting events and data, depicted as state machine <highlight><bold>3850</bold></highlight>, for controlling the work. It must select a template <highlight><bold>3848</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 38</cross-reference>) for the state machine that is appropriate for the particular event. For instance, a failure of a Sonet Ring would be handled differently than a failure of a modem. In the MOC, the state machine is a micro-workflow and description of the life cycle of a telecommunications process. State machine <highlight><bold>3850</bold></highlight> performs a number for functions regarding the event, including determining other related events needing to be bundled with the primary event and what events would signify closure of the primary event. Additionally, the state machine might need additional information so the state machine must be equipped to determine the additional information that is needed, such as topology or customer service level agreement (SLA). Finally, the state machine <highlight><bold>3850</bold></highlight> must determine what milestones in the life of a particular event are important. The state machine, the events that are to be associated, the milestones, the means of gathering additional information is represented in the template. </paragraph>
<paragraph id="P-0435" lvl="0"><number>&lsqb;0435&rsqb;</number> If, on the other hand, the event represents an existing opportunity, aggregator <highlight><bold>3606</bold></highlight> joins the incoming event to running state machine <highlight><bold>3850</bold></highlight> that has expressed interest in it. At some point, the state machine ultimately produces a work document and makes this document known (publishes it) to other components via distributor <highlight><bold>3810</bold></highlight>. In accordance with another embodiment of the present invention, a behavior engine (rules engine) can be used both to implement logic gate <highlight><bold>3848</bold></highlight> and by the state machine to control its actions or to provide some root cause analysis of the problem. </paragraph>
<paragraph id="P-0436" lvl="0"><number>&lsqb;0436&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 39</cross-reference> is a diagram of a simplified version of a workspace showing a controlling state machine in accordance with an exemplary embodiment of the present invention. Many separate workspaces may exist simultaneously. State machine <highlight><bold>3850</bold></highlight> controls the actual work in the aggregator. </paragraph>
<paragraph id="P-0437" lvl="0"><number>&lsqb;0437&rsqb;</number> As can be seen in <cross-reference target="DRAWINGS">FIG. 39</cross-reference>, state machine <highlight><bold>3950</bold></highlight> is responsible for receiving incoming events, binding them together (the tree of E&apos;s in the figure) and responding to any state change as a result of the new event, or binding information into the work document (the network of circles in the figure). State machine <highlight><bold>3950</bold></highlight> continues operating until closure conditions are reached, which may be based on completeness or time elapsed. Then, state machine <highlight><bold>3950</bold></highlight> publishes the work document in some manner (for instance, persist on DataBus or publish via publish/subscribe) and in some agreed-upon form (for instance, XML document or Java objects). </paragraph>
<paragraph id="P-0438" lvl="0"><number>&lsqb;0438&rsqb;</number> The aggregator may be implemented in a number of different ways, even by the functional workings of the other services (i.e., in accordance with one embodiment of the present invention, there is no physical component called the aggregator). When a work task is always present, a resource manager can create the required number of workspaces and state machines. In that case, state machine <highlight><bold>3950</bold></highlight> subscribes with the publish/subscribe bus for the events in which it is interested. As such, state machine <highlight><bold>3950</bold></highlight> receives the events directly without going through a &ldquo;gate,&rdquo; thus performing the join function implicitly. Additionally, the MOC rendezvous service, discussed below, is used to prevent an event which has gone directly to state machine <highlight><bold>3950</bold></highlight> from also causing the creation of a new state machine, thereby also performing the gate function. Finally, the assessor is allowed to create the state machine if the event is determined to be primary and the rendezvous service says it is not being handled already, thus performing the start function of the aggregator. </paragraph>
<paragraph id="P-0439" lvl="0"><number>&lsqb;0439&rsqb;</number> State machines are a common way of handling a process that goes through many states and responds to events, with the response being dependent upon the current state. Many implementations of state machines exist and many that may be applicable to the present invention could have been used here. The MOC implementation follows along somewhat non-traditional lines because the state transactions are not complex, but the determination of the event coming in is. The implementation, then, does not optimize the state transition (as one would see in, for instance, a source code parser). </paragraph>
<paragraph id="P-0440" lvl="0"><number>&lsqb;0440&rsqb;</number> In the normal course of action, the state machine continues operating for the life of the work. This is necessary because, even after the document is produced, related events will still keep coming in and need to be joined to the existing work document. Rather than create a new component for doing this function after the work document was created, the state machine continues to live on its own for: </paragraph>
<paragraph id="P-0441" lvl="2"><number>&lsqb;0441&rsqb;</number> care staff&mdash;skills assessment; </paragraph>
<paragraph id="P-0442" lvl="2"><number>&lsqb;0442&rsqb;</number> customer and network care staff&mdash;a reference to history of past work; </paragraph>
<paragraph id="P-0443" lvl="2"><number>&lsqb;0443&rsqb;</number> interactions and success ratings (knowledge base); </paragraph>
<paragraph id="P-0444" lvl="2"><number>&lsqb;0444&rsqb;</number> data on domains of responsibility (assignments); </paragraph>
<paragraph id="P-0445" lvl="2"><number>&lsqb;0445&rsqb;</number> physical location; and </paragraph>
<paragraph id="P-0446" lvl="2"><number>&lsqb;0446&rsqb;</number> availability. </paragraph>
<paragraph id="P-0447" lvl="7"><number>&lsqb;0447&rsqb;</number> One exemplary state machine is implemented as an extension of the base class WorkItemActor. The particulars of this exemplary implementation are that the publication of the document is done through publish/subscribe and after publishing the document, the state machine does not go away. </paragraph>
<paragraph id="P-0448" lvl="0"><number>&lsqb;0448&rsqb;</number> With respect to a given enterprise, many state machine templates <highlight><bold>3852</bold></highlight> should be developed to handle different classes of problems for the enterprise that share characteristics. With respect to the WorkItemActor state machine example where the enterprise is a telecommunications company, state machines might be developed to handle, for example, SonetLinearFailure, ModemReset, StandbyRequest, and ApplicationRestartFailure. An XML template can then be used to describe the control differences between state machines. The template document contains the settings for milestones, related events, and information to be bound in. </paragraph>
</section>
<section>
<heading lvl="1">Event and Work Item Rendezvous </heading>
<paragraph id="P-0449" lvl="0"><number>&lsqb;0449&rsqb;</number> As mentioned above, the MOC depends on a rendezvous service to tell if an event is being handled by a work item (or a state machine controlling a work item), represented in <cross-reference target="DRAWINGS">FIG. 36</cross-reference> as rendezvous <highlight><bold>3616</bold></highlight>. A rendezvous service is responsible for determining if a given event is already being handled and if the problem represented by a work item document overlaps with an existing work item document. It then routes that event to the proper work item. The client role of the rendezvous service dynamically registers work-items for subscriptions to related events. It also finds if any specific event is already registered in the service register as being processed by a state machine/workspace. The server side continuously skims the service register for work items which should be informed of each other or joined into one work process unit. </paragraph>
<paragraph id="P-0450" lvl="0"><number>&lsqb;0450&rsqb;</number> As with many other MOC components, many rendezvous services can be deployed simultaneously in a MOC environment. Rendezvous service <highlight><bold>3616</bold></highlight> can use rules to make its determinations, or any appropriate logic. Different rendezvous services may be deployed with different rules for determining overlap by different parameters. For instance, different services could consult different views of topology, for instance, one service could look at layer 2, a second a layer 3, a third looking only at cross domain interactions. By deploying many such rendezvous services, and by allowing work documents already started to be merged together, it is not necessary to apply all rendezvous rules before starting work. Therefore, some rendezvous rules could be quite slow and still result in alerting people to the fact that a problem spans multiple areas. Asynchronous processing allows parallel work to occur in a dynamic environment, at its own pace, and then be merged with other work upon reaching a certain resolution. </paragraph>
<paragraph id="P-0451" lvl="0"><number>&lsqb;0451&rsqb;</number> In accordance with an uncomplicated implementation of rendezvous service <highlight><bold>3616</bold></highlight>, it applies simple rules to determine if an event has been handled and if there is overlap between different work item documents. Rendezvous service <highlight><bold>3616</bold></highlight> dynamically subscribes with publish/subscribe services to be made aware of any new work item document as the item is created (but before it is published for all). Rendezvous service <highlight><bold>3616</bold></highlight> pulls the events off of the document and keeps an index of events based on their type and based on the network element affected. Whenever it is asked about a new event, it can compare the new event against the network element to see if any existing work item document references that element. </paragraph>
</section>
<section>
<heading lvl="1">The Work Document </heading>
<paragraph id="P-0452" lvl="0"><number>&lsqb;0452&rsqb;</number> WorkItem <highlight><bold>3630</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 36</cross-reference> holds all of the objects, or references to the objects, associated with the item of work (i. e., the problem described in the initial event that is being addressed). In accordance with an exemplary embodiment of the present invention, WorkItem <highlight><bold>3630</bold></highlight> will have many types of objects, bound in, including: </paragraph>
<paragraph id="P-0453" lvl="2"><number>&lsqb;0453&rsqb;</number> events&mdash;the primary event and associated/correlated events; </paragraph>
<paragraph id="P-0454" lvl="2"><number>&lsqb;0454&rsqb;</number> status information describing the current state of the problem resolution, for instance, status, probable cause, priority, time to resolve, actual cause; </paragraph>
<paragraph id="P-0455" lvl="2"><number>&lsqb;0455&rsqb;</number> informational objects, such as: </paragraph>
<paragraph id="P-0456" lvl="3"><number>&lsqb;0456&rsqb;</number> customer information and service level agreement information; </paragraph>
<paragraph id="P-0457" lvl="3"><number>&lsqb;0457&rsqb;</number> topology information; </paragraph>
<paragraph id="P-0458" lvl="3"><number>&lsqb;0458&rsqb;</number> basic instructions regarding the problem; </paragraph>
<paragraph id="P-0459" lvl="3"><number>&lsqb;0459&rsqb;</number> progress notes; and </paragraph>
<paragraph id="P-0460" lvl="3"><number>&lsqb;0460&rsqb;</number> sundry information such as configuration information on the elements in question; </paragraph>
<paragraph id="P-0461" lvl="2"><number>&lsqb;0461&rsqb;</number> user avatars for the people participating in the work group; </paragraph>
<paragraph id="P-0462" lvl="2"><number>&lsqb;0462&rsqb;</number> proxies to devices or services related to the problem, for instance, a proxy to the device or agent for the device that is reporting the problem; and </paragraph>
<paragraph id="P-0463" lvl="2"><number>&lsqb;0463&rsqb;</number> tools needed to resolve the problem, including collaboration tools for interacting with the work group, or getting information about the problem elements. </paragraph>
<paragraph id="P-0464" lvl="0"><number>&lsqb;0464&rsqb;</number> It should be understood that some of the information in Workspace <highlight><bold>3940</bold></highlight> and Work Item <highlight><bold>3630</bold></highlight> are required to be persisted permanently, or for some time, while other objects need only be in memory where they can be accessed. In accordance with one embodiment of the present invention, the work document is the DataBus-enabled WorkItem (implemented, according to DataBus standards, as the WorkItemBean class and related classes). There, WorkItem <highlight><bold>3630</bold></highlight> is completely persisted on the DataBus. With respect to an alternative embodiment, a technique similar to the Jini Registrar and the Jini JavaSpace is employed for storing any serializable object and also attaching external &ldquo;attributes&rdquo; to be used when looking for the object (a serializable object, as described above, is an object which Java is able to &ldquo;serialize&rdquo; the object in a form suitable for storing or transporting across processes&mdash;this is a standard Java technique). The external attributes are selected by the storer. </paragraph>
</section>
<section>
<heading lvl="1">The Workspaces </heading>
<paragraph id="P-0465" lvl="0"><number>&lsqb;0465&rsqb;</number> Similar to WorkItem <highlight><bold>3630</bold></highlight>, the MOC design has the concept of the work group space Workspace <highlight><bold>3940</bold></highlight>, a space for the work group collaborating on a problem to share relevant objects. This allows the client&apos;s avatars to interact as if the workspace were a peer-to-peer environment. One implementation is to convert WorkItem <highlight><bold>3630</bold></highlight> into an in-memory work group space with a simple interface for finding objects and retrieving them, and a persistent work item document for persisting data about the work item. This is an in-memory shared space capable of holding objects that the participants may need, including: </paragraph>
<paragraph id="P-0466" lvl="2"><number>&lsqb;0466&rsqb;</number> the work item document itself; </paragraph>
<paragraph id="P-0467" lvl="2"><number>&lsqb;0467&rsqb;</number> proxies to user avatars for communicating with other participants; </paragraph>
<paragraph id="P-0468" lvl="2"><number>&lsqb;0468&rsqb;</number> work flow objects; </paragraph>
<paragraph id="P-0469" lvl="2"><number>&lsqb;0469&rsqb;</number> an active object controlling the lifecycle; </paragraph>
<paragraph id="P-0470" lvl="2"><number>&lsqb;0470&rsqb;</number> proxies to intelligent devices and agents for devices to directly interact with these devices; </paragraph>
<paragraph id="P-0471" lvl="2"><number>&lsqb;0471&rsqb;</number> user interfaces to access the work item information (allowing different user interfaces for different roles&mdash;technical support, customer support, etc.); and </paragraph>
<paragraph id="P-0472" lvl="2"><number>&lsqb;0472&rsqb;</number> collaboration tools. </paragraph>
<paragraph id="P-0473" lvl="0"><number>&lsqb;0473&rsqb;</number> The work group space must support the putting of objects into and the getting of objects from the space, the remote downloading of the classes needed to use the objects, the registration for and notification of events relating to the objects, and the tailoring of the contents of the space to the particular problem using rules. These concepts are features of the NewWave infrastructure and GIB architecture, and are easily implemented. Alternatively, with the exception of the rules, this resembles the responsibilities of a Jini JavaSpace, which could be also used as a component in implementing a workspace. </paragraph>
<paragraph id="P-0474" lvl="0"><number>&lsqb;0474&rsqb;</number> WorkItem <highlight><bold>3630</bold></highlight> is very similar to the work space concept of the present invention and performs most functions of the work this function; however, as a DataBus object, WorkItem <highlight><bold>3630</bold></highlight> is not practical to support those objects that are not really intended to be persistent. In accordance with an exemplary embodiment of the present invention, there are three alternative implementations of the work group space. The first implementation is a NewWave service, described in detail above, registers itself in the domain registrar and the enterprise repository. This implementation allows the work group to be accessed via normal administrative tools for services; however, large numbers of work group spaces could get unwieldy. A second implementation involves creating an in-memory DataBus object. This would scale well to large numbers, but would not be directly accessible via normal service administrative methods. Finally, the work group can be implemented as a JavaSpace. This would require the addition of proxies so that one JavaSpace could service a number of work group spaces. </paragraph>
</section>
<section>
<heading lvl="1">Creating a Work Group to Handle the Event User Avatar Service (User Proxy) </heading>
<paragraph id="P-0475" lvl="0"><number>&lsqb;0475&rsqb;</number> In accordance with an exemplary embodiment of the present invention, contacts (e.g., Operators, Provisions, Customer Contacts, Service Support staff, any other management-tasked staff in the customer and network care environment, Customers, etc.) may participate in the resolution of, or may need notification of, WorkItem <highlight><bold>3630</bold></highlight>. As such, it is necessary to understand what the operations staff is currently working on real-time, what the task priority is, and when is it due to be completed&mdash;workload, and how to route messages and work to a contact. </paragraph>
<paragraph id="P-0476" lvl="0"><number>&lsqb;0476&rsqb;</number> In some cases, additional information is needed in order to support the dispatching function of the MOC: </paragraph>
<paragraph id="P-0477" lvl="2"><number>&lsqb;0477&rsqb;</number> for care staff&mdash;skills assessment; </paragraph>
<paragraph id="P-0478" lvl="2"><number>&lsqb;0478&rsqb;</number> for customer and network care staff&mdash;a reference to history of past work, interactions, and success ratings (knowledge base); </paragraph>
<paragraph id="P-0479" lvl="2"><number>&lsqb;0479&rsqb;</number> data on domains of responsibility (assignments); </paragraph>
<paragraph id="P-0480" lvl="2"><number>&lsqb;0480&rsqb;</number> physical location; and </paragraph>
<paragraph id="P-0481" lvl="2"><number>&lsqb;0481&rsqb;</number> availability. </paragraph>
<paragraph id="P-0482" lvl="0"><number>&lsqb;0482&rsqb;</number> Contact data can then be saved in an appropriate location, for instance, persisted within a Contact DataBus Entity. </paragraph>
<paragraph id="P-0483" lvl="0"><number>&lsqb;0483&rsqb;</number> The user avatar is a representation of a person as a service, invoke-able by other software services; a virtualization of the individual, the current state of the individual and the current interface to the individual. In accordance with an exemplary embodiment of the present invention, a user avatar, depicted as user avatar <highlight><bold>3604</bold></highlight> on <cross-reference target="DRAWINGS">FIG. 36</cross-reference> represents a virtual image of a specific operator&apos;s or customer contact&apos;s skills and responsibilities. A user avatar is depicted as user avatar <highlight><bold>3604</bold></highlight> on <cross-reference target="DRAWINGS">FIG. 36</cross-reference> that serves as a proxy for a contact within the MOC. Optimally, each contact has an associated user avatar. This concept is better understood with respect to <cross-reference target="DRAWINGS">FIG. 40</cross-reference> that depicts a user avatar in accordance with an exemplary embodiment of the present invention. </paragraph>
<paragraph id="P-0484" lvl="7"><number>&lsqb;0484&rsqb;</number> Lookup </paragraph>
<paragraph id="P-0485" lvl="0"><number>&lsqb;0485&rsqb;</number> Each UA <highlight><bold>4012</bold></highlight> registers in registration service <highlight><bold>4022</bold></highlight>, which may be a domain registrar, started with group &ldquo;Users.&rdquo; UA <highlight><bold>4012</bold></highlight> is registered with attributes including primary key (PK), login ID and name. Any service requesting information from, or sending messages or work to, UA <highlight><bold>4012</bold></highlight> locates this proxy using existing NewWave protocols for lookup described above. </paragraph>
<paragraph id="P-0486" lvl="7"><number>&lsqb;0486&rsqb;</number> Contact DataBus Entity </paragraph>
<paragraph id="P-0487" lvl="0"><number>&lsqb;0487&rsqb;</number> UA <highlight><bold>4012</bold></highlight> is initially populated from the Contact DataBus Entity stored in DataBus <highlight><bold>4024</bold></highlight>. Once created, UA <highlight><bold>4012</bold></highlight> has the ability to synchronize its data with the DataBus. Additionally, UA <highlight><bold>4012</bold></highlight> provides &ldquo;helper&rdquo; convenience methods so that data persisted with the Contact DataBus Entity can be accessed through UA <highlight><bold>4012</bold></highlight>. </paragraph>
<paragraph id="P-0488" lvl="7"><number>&lsqb;0488&rsqb;</number> Contact Means </paragraph>
<paragraph id="P-0489" lvl="0"><number>&lsqb;0489&rsqb;</number> As a proxy to the contact, the User Avatar knows all available contact means for a contact and is responsible for forwarding all communications, messages and work to the contact via the appropriate contact mean(s). All logon/logoff requests from the WorkSpace applet (GUI) will be made through UA <highlight><bold>4012</bold></highlight>. A remote proxy to the WorkSpace will be retained as an available contact mean after a &ldquo;logon&rdquo; request from the WorkSpace GUI has been successfully processed. Likewise, all logon/logoff requests from the PDA service will be made through UA <highlight><bold>4012</bold></highlight>. Again, a proxy to the PDA Service will be retained as an available contact mean once a &ldquo;logon&rdquo; request from the PDA service is successfully processed. Other contact means supported by the current implementation include text messages sent to pagers via email, text messages sent to cellular phones via email, and email. </paragraph>
<paragraph id="P-0490" lvl="0"><number>&lsqb;0490&rsqb;</number> UA <highlight><bold>4012</bold></highlight> is also responsible for determining whether a message should be sent via one or more available contact means. This determination is made by evaluating the priority of the message or work. More urgent messages may be distributed via multiple, or even all, available contact means. </paragraph>
<paragraph id="P-0491" lvl="7"><number>&lsqb;0491&rsqb;</number> Workload </paragraph>
<paragraph id="P-0492" lvl="0"><number>&lsqb;0492&rsqb;</number> In addition to providing a communication vehicle for a Contact, UA <highlight><bold>4012</bold></highlight> knows what a Contact is currently working on (workload). Workload is primarily used by dispatching function <highlight><bold>3608</bold></highlight> to determine the &ldquo;most available&rdquo; Contact to participate in the resolution of a WorkItem. Workload is provided by the UserAvatar as XML. Again, workload is defined as what the operations staff is currently working on real-time, the task priority, and when is it due to be completed. Individuals can be participants in more than one workspace at the same time. The UA sees/stores this collection of work of an individual and the workspace client for an individual can reference any work-item for which an invitation is active and/or accepted. </paragraph>
<paragraph id="P-0493" lvl="7"><number>&lsqb;0493&rsqb;</number> Subscriptions </paragraph>
<paragraph id="P-0494" lvl="0"><number>&lsqb;0494&rsqb;</number> UA <highlight><bold>4012</bold></highlight> has the ability to publish and subscribe via the GIB&apos;s pub/sub bus <highlight><bold>3618</bold></highlight>. In the MOC, UA <highlight><bold>4012</bold></highlight> subscribes for WorkItem status changes so that UA <highlight><bold>4012</bold></highlight> can forward status change messages to the Contact via the available contact means. Contacts also subscribe for items of interest within the MOC via their established contact means. These subscriptions are established with UA <highlight><bold>4012</bold></highlight> as profile information. Once UA <highlight><bold>4012</bold></highlight> receives a subscribed item, it is responsible for forwarding the corresponding messages in the proper format to the Contact via the established contact mean(s). </paragraph>
<paragraph id="P-0495" lvl="7"><number>&lsqb;0495&rsqb;</number> Statistics </paragraph>
<paragraph id="P-0496" lvl="0"><number>&lsqb;0496&rsqb;</number> UA <highlight><bold>4012</bold></highlight>, just as every other MOC service, implements the MOC&apos;s Service Admin interface, and provides statistics as XML including health/heartbeat, and additionally, the MOC specific statistics such as workload and profile information (current subscriptions, contact means, etc.). </paragraph>
</section>
<section>
<heading lvl="1">Avatar Service (Generic Service) </heading>
<paragraph id="P-0497" lvl="0"><number>&lsqb;0497&rsqb;</number> In the MOC, avatar service <highlight><bold>4013</bold></highlight> serves as a container for UA(s) <highlight><bold>4012</bold></highlight>. Optimally, one avatar service is deployed for each Contact logical domain. Avatar service <highlight><bold>4013</bold></highlight> has all of the behavior associated with a NewWave service and therefore can initially create and register (with the domain registrar) the user avatar(s), in addition to maintaining user avatar(s) leases with the registrar. Finally, avatar service <highlight><bold>4013</bold></highlight> provides convenience methods to the DataBus for the user avatar synchronization functions. </paragraph>
<paragraph id="P-0498" lvl="7"><number>&lsqb;0498&rsqb;</number> Dispatcher Service </paragraph>
<paragraph id="P-0499" lvl="0"><number>&lsqb;0499&rsqb;</number> As discussed above, the GIB architecture implements &ldquo;policy-based&rdquo; rules that can be modified in &ldquo;near-real-time&rdquo; to handle predicate logic requirements. Various off-the-shelf services might be integrated into the GIB architecture to provide this functionality (i.e., the Brokat product(s), Advisor Builder and Advisor Rule Engine). Below is an exemplary description of the function of the dispatching rules in accordance with an exemplary embodiment of the present invention. It should be understood that the account detailed below is merely exemplary and any specific policy might be applied to any policy based MOC component. Also, policy can be implemented in any rules agent as a relocatable service, including as a java object. </paragraph>
<paragraph id="P-0500" lvl="0"><number>&lsqb;0500&rsqb;</number> It should also be noted that the data, rules, subscriptions, and templates for this described exemplary implementation of the dispatcher service have been limited in scope to a particular telecommunications challenge business scenario to aid in explanation (actual rule sets can be quite large). As such, this explanation is intended to describe this service as a participant in the Management Operations Center (MOC). No attempt has been made to describe all data, rules, subscriptions, and templates needed to support all policy functions necessary for the MOC. </paragraph>
<paragraph id="P-0501" lvl="0"><number>&lsqb;0501&rsqb;</number> The Dispatcher Service (GenericGIBService) provides the MOC the ability to: </paragraph>
<paragraph id="P-0502" lvl="2"><number>&lsqb;0502&rsqb;</number> 1. apply current policy rules to associate work documents and events with specific operators, customer contacts and other service care staff; </paragraph>
<paragraph id="P-0503" lvl="2"><number>&lsqb;0503&rsqb;</number> 2. assign work (WorkItems) with an understanding of who is free and able to do that work; </paragraph>
<paragraph id="P-0504" lvl="2"><number>&lsqb;0504&rsqb;</number> 3. understand relative priority and can bump work in progress for higher priority tasks; and </paragraph>
<paragraph id="P-0505" lvl="2"><number>&lsqb;0505&rsqb;</number> 4. identify Customer Contact(s) that should be notified of WorkItems based on their Service Level Agreement (SLA). </paragraph>
<paragraph id="P-0506" lvl="0"><number>&lsqb;0506&rsqb;</number> The Dispatcher Service accomplishes the above stated objectives by implementing the following functions: </paragraph>
<paragraph id="P-0507" lvl="7"><number>&lsqb;0507&rsqb;</number> 1. Register to Receive WorkItem Change Events via the Publish/Subscribe Bus. </paragraph>
<paragraph id="P-0508" lvl="0"><number>&lsqb;0508&rsqb;</number> As a GenericGIBService, the Dispatcher Service inherits the ability to participate in the publish/subscribe bus. Upon service start-up, the Dispatcher Service registers as a subscriber for WorkItem Events that include, but are not limited to: </paragraph>
<paragraph id="P-0509" lvl="2"><number>&lsqb;0509&rsqb;</number> WorkItems that have had a status change such as &ldquo;opened&rdquo; or &ldquo;escalated&rdquo;; </paragraph>
<paragraph id="P-0510" lvl="2"><number>&lsqb;0510&rsqb;</number> WorkItems whose key information has changed requiring a rerun of the dispatching rules; </paragraph>
<paragraph id="P-0511" lvl="2"><number>&lsqb;0511&rsqb;</number> Invitations to participate in a WorkItem that have been &ldquo;declined&rdquo; by a candidate Contact; and </paragraph>
<paragraph id="P-0512" lvl="2"><number>&lsqb;0512&rsqb;</number> Invitations that have &ldquo;expired&rdquo; (i.e., not accepted or declined by a candidate contact), and need to have an alternate contact assigned to the associated role. </paragraph>
<paragraph id="P-0513" lvl="0"><number>&lsqb;0513&rsqb;</number> Once the Dispatcher Service receives a WorkItem Event, it is ready to run the dispatching rules. As a GenericGIBService, the Dispatcher Service inherits the ability to directly interface with a behavior (rules) engine. The current Dispatcher Service implements the Brokat products to define, via Brokat Advisor, and then process, via Brokat Rules Engine, the dispatching rules. </paragraph>
<paragraph id="P-0514" lvl="7"><number>&lsqb;0514&rsqb;</number> 2. Run Dispatching Rules. </paragraph>
<paragraph id="P-0515" lvl="0"><number>&lsqb;0515&rsqb;</number> The Dispatcher Service passes the WorkItem to the rules engine for processing. Upon receipt of the WorkItem, the dispatching rules must determine which rules, e.g. rules agent, to run based on the type of WorkItem Event. It is important to understand that this function would run at every milestone in the controlling state machine. In most cases, the first task is for the rule engine to determine: </paragraph>
<paragraph id="P-0516" lvl="0"><number>&lsqb;0516&rsqb;</number> 1. Identification of Contacts that need to Participate in the WorkItem. </paragraph>
<paragraph id="P-0517" lvl="0"><number>&lsqb;0517&rsqb;</number> The dispatching rules are responsible for determining which contacts need to be invited to participate in, and ultimately resolve, the WorkItem. In order to define the participation needed to resolve the WorkItem, rules identify roles to be filled by &ldquo;appropriately skilled&rdquo; Contact(s). The roles are determined by rules that evaluate the WorkItem&apos;s data. Although the WorkItem contains comprehensive information, the event data currently evaluated by the dispatching rules for the purpose of determining roles includes: </paragraph>
<paragraph id="P-0518" lvl="2"><number>&lsqb;0518&rsqb;</number> the primary event type; </paragraph>
<paragraph id="P-0519" lvl="2"><number>&lsqb;0519&rsqb;</number> the primary event location; </paragraph>
<paragraph id="P-0520" lvl="2"><number>&lsqb;0520&rsqb;</number> the type of equipment involved; and </paragraph>
<paragraph id="P-0521" lvl="2"><number>&lsqb;0521&rsqb;</number> the severity of the primary event. </paragraph>
<paragraph id="P-0522" lvl="0"><number>&lsqb;0522&rsqb;</number> An example of the roles identified, via rules, for a Sonet Linear Failure network event have been included BELOW: </paragraph>
<paragraph id="P-0523" lvl="2"><number>&lsqb;0523&rsqb;</number> if the currentWorkItem.primaryEventType &ldquo;Sonet Linear Failure&rdquo;</paragraph>
<paragraph id="P-0524" lvl="2"><number>&lsqb;0524&rsqb;</number> assign role&equals;&ldquo;Router Technician&rdquo;</paragraph>
<paragraph id="P-0525" lvl="2"><number>&lsqb;0525&rsqb;</number> assign role&equals;&ldquo;Customer Service Representative&rdquo;</paragraph>
<paragraph id="P-0526" lvl="2"><number>&lsqb;0526&rsqb;</number> assign role&equals;&ldquo;Transport Engineer&rdquo;</paragraph>
<paragraph id="P-0527" lvl="2"><number>&lsqb;0527&rsqb;</number> assign role&equals;&ldquo;Dispatch Truck&rdquo;</paragraph>
<paragraph id="P-0528" lvl="2"><number>&lsqb;0528&rsqb;</number> assign role&equals;&ldquo;Supervisor&rdquo;</paragraph>
<paragraph id="P-0529" lvl="2"><number>&lsqb;0529&rsqb;</number> end if </paragraph>
<paragraph id="P-0530" lvl="0"><number>&lsqb;0530&rsqb;</number> In addition to evaluating the event data on the WorkItem, the dispatching rules evaluate customers who have been impacted by the event(s). Impacted customers and their corresponding Service Level Agreement information have been bound into the WorkItem prior to receipt of the WorkItem by the Dispatcher Service. The dispatching rules determine whether direct customer participation in the WorkItem is required. Additionally, the dispatching rules determine whether it is necessary to assign a Contact specifically to the impacted customer. The customer participation rules evaluate: </paragraph>
<paragraph id="P-0531" lvl="2"><number>&lsqb;0531&rsqb;</number> the customer&apos;s Service Level Agreement (SLA) to determine whether their notification of the WorkItem is required; or </paragraph>
<paragraph id="P-0532" lvl="2"><number>&lsqb;0532&rsqb;</number> whether the customer has been located on the customer service special handling list. </paragraph>
<paragraph id="P-0533" lvl="0"><number>&lsqb;0533&rsqb;</number> A WorkItem status change may identify additional roles through the involvement of additional rules. In the case of the milestone, WorkItem &ldquo;escalated&rdquo; status change, management and more highly-skilled personnel may be invited to participate in the WorkItem via the dispatching rules. </paragraph>
<paragraph id="P-0534" lvl="0"><number>&lsqb;0534&rsqb;</number> Once the roles have been identified by the dispatching rules, a second set of rules are run to determine the &ldquo;most appropriate&rdquo; Contact(s) to fill the roles. Contacts can be defined as interested parties, not limited to people, that have been identified by the dispatching rules as being available for participation in a particular WorkItem. In order to determine the &ldquo;most appropriate&rdquo; Contact(s), the dispatching rules perform pattern matches on Contacts&apos; characteristics. In this exemplary Dispatcher Service implementation, the dispatching rules define Contact characteristics as: </paragraph>
<paragraph id="P-0535" lvl="2"><number>&lsqb;0535&rsqb;</number> skills&mdash;Does the Contact possess the appropriate skill type and level to fulfill the role&quest;</paragraph>
<paragraph id="P-0536" lvl="2"><number>&lsqb;0536&rsqb;</number> experiences&mdash;Has this Contact solved this problem or a problem like this before&mdash;history&quest;</paragraph>
<paragraph id="P-0537" lvl="2"><number>&lsqb;0537&rsqb;</number> assignments&mdash;Is this Contact currently assigned to this Customer, Vendor, System, or piece of equipment&quest;</paragraph>
<paragraph id="P-0538" lvl="2"><number>&lsqb;0538&rsqb;</number> physical location&mdash;Does the fulfillment of this role require physical proximity to the event location&quest;</paragraph>
<paragraph id="P-0539" lvl="2"><number>&lsqb;0539&rsqb;</number> availability&mdash;Does the Contact&apos;s current workload allow participation in the WorkItem&quest;</paragraph>
<paragraph id="P-0540" lvl="0"><number>&lsqb;0540&rsqb;</number> 2. Invitation Creation </paragraph>
<paragraph id="P-0541" lvl="0"><number>&lsqb;0541&rsqb;</number> As each candidate Contact is identified by the rules, a function is invoked to create an Invitation object and bind it to the WorkItem. Each Invitation contains base WorkItem information, such as event type, priority, contact&apos;s proposed role, contact&apos;s ID and WorkItem ID. The initial invitation status is &ldquo;ready for dispatch.&rdquo;</paragraph>
<paragraph id="P-0542" lvl="0"><number>&lsqb;0542&rsqb;</number> 3. Instructions/Scripts Bound into the WorkItem </paragraph>
<paragraph id="P-0543" lvl="0"><number>&lsqb;0543&rsqb;</number> The dispatching rules evaluate the roles, customers&apos; SLAs, and event information to determine whether instructions or scripts need to be bound into the WorkItem for the candidate contacts. Once all contacts have been identified, invitations have been created, and instructions have been bound into the WorkItem, the dispatching rules engine returns to the Dispatcher Service for further processing. </paragraph>
<paragraph id="P-0544" lvl="0"><number>&lsqb;0544&rsqb;</number> 3. Dispatch the Invitation to the Contact&apos;s Proxy. </paragraph>
<paragraph id="P-0545" lvl="0"><number>&lsqb;0545&rsqb;</number> The Dispatcher Service queries the WorkItem for a list of invitations that need to be dispatched and then performs a registrar lookup for the Contact&apos;s proxy (UserAvatar) by Contact ID. Upon return of the contact proxy from lookup, the Dispatcher Service performs a &ldquo;send&rdquo; request passing the invitation. The contact proxy is responsible for determining where the invitation should be sent and how it should be formatted. </paragraph>
<paragraph id="P-0546" lvl="7"><number>&lsqb;0546&rsqb;</number> Distributor Services </paragraph>
<paragraph id="P-0547" lvl="0"><number>&lsqb;0547&rsqb;</number> In accordance with an exemplary embodiment of the present invention, messages in the Management Operations Center (MOC) need to be distributed to contacts. Within the MOC, messages take several formats: XML, HTML, text, and direct communication with a remote proxy. The messages may be disbursed via a variety of communication mechanisms: PDA, email (WorkSpace servlet), pager, mobile phone, and WorkSpace GUI Client (applet). </paragraph>
<paragraph id="P-0548" lvl="0"><number>&lsqb;0548&rsqb;</number> In order to support the MOC requirement of distributing messages to Contacts using such varied communication mechanisms, adapters have been developed by the team. Adapters are Generic Services that register with a domain registrar. As Generic Services, they inherit all associated behavior. Two such adapters are described below. </paragraph>
<paragraph id="P-0549" lvl="7"><number>&lsqb;0549&rsqb;</number> Distributor Message Service </paragraph>
<paragraph id="P-0550" lvl="0"><number>&lsqb;0550&rsqb;</number> The Distributor Message Service of the MOC is responsible for distributing messages via email. This exemplary implementation of the Distributor Service implements the Java Mail classes and distributes messages to mobile phones, pagers, and email. </paragraph>
<paragraph id="P-0551" lvl="0"><number>&lsqb;0551&rsqb;</number> The Distributor Service implements a simple interface with one public method for sending messages. The send method takes two parameters, the first indicating whether the message is to be sent in HTML or text format, and the second parameter is the message to be sent. </paragraph>
<paragraph id="P-0552" lvl="7"><number>&lsqb;0552&rsqb;</number> PDA Adapter Service </paragraph>
<paragraph id="P-0553" lvl="0"><number>&lsqb;0553&rsqb;</number> The PDA Adapter, a service of the MOC, is responsible for distributing messages to a PDA client. This exemplary implementation of the PDA Adapter distributes XML messages to the PDA. </paragraph>
<paragraph id="P-0554" lvl="0"><number>&lsqb;0554&rsqb;</number> The PDA Adapter implements a simple interface with one public method for sending messages. The send method takes a single parameter which is the message to be sent. </paragraph>
<paragraph id="P-0555" lvl="7"><number>&lsqb;0555&rsqb;</number> Archiving Work Documents </paragraph>
<paragraph id="P-0556" lvl="0"><number>&lsqb;0556&rsqb;</number> When a work item is closed, the experience of the people who participated in the work group needs to be updated. An archive service is provided for this and any other cleanup activity that is needed. In fact, multiple archive services could be deployed, each doing different activities such as one concentrating solely on updating experiences; packaging up the work item for long-term storage; calculating statistics for trend analysis, etc. </paragraph>
<paragraph id="P-0557" lvl="0"><number>&lsqb;0557&rsqb;</number> The exemplary archive service implementation for the MOC performs a simple calculation on the experience level of each person in the role played in the work group. Each time a person participates in a successful resolution of the problem, that person&apos;s experience level is modified according to the following formula: current&plus;((max&minus;current)*0.5). This gives the person a lot of credit the first time that person is successful, but less credit each time until the score is close to the maximum. </paragraph>
<paragraph id="P-0558" lvl="0"><number>&lsqb;0558&rsqb;</number> The description of the present invention has been presented for purposes of illustration and description, but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain the principles of the invention, the practical application of the invention and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A data processing system implemented method for realizing an avatar as a shared resource among clients in an enterprise comprising: 
<claim-text>defining an avatar as information related to at least some of communication, skills, responsibilities, experience, physical location, availability, workload and history of work success, wherein the information is based on attributes for a contact; </claim-text>
<claim-text>registering the avatar in the enterprise; and </claim-text>
<claim-text>interacting with a service based on the information defining the avatar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method recited in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein interacting with a service based on one of the information defining the avatar further comprises: 
<claim-text>receiving a request for the contact to participate with a work group from a client; </claim-text>
<claim-text>conveying the request to the contact using the communication information; and </claim-text>
<claim-text>updating the workload information to reflect an affirmative response to the request. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method recited in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein interacting with a service based on one of the information defining the avatar further comprises: 
<claim-text>receiving a request for the contact to participate with a work group from a client; </claim-text>
<claim-text>conveying the request to the contact using the communication information; and declining the request for the contact to participate based on a negative response to the request from the contact. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method recited in <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> further comprises: 
<claim-text>updating the skill and history of work success information for the avatar based on completion of the participation with the work group. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method recited in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the contact is one of an enterprise person and a customer person. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method recited in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein interacting with a service based on the information defining the avatar further comprises: 
<claim-text>receiving a request for the contact to participate with a work group from a client, wherein the request is based on the skill, experience, physical location, availability, workload and history of work success of the contact, wherein the contact is a service person. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method recited in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the enterprise having a plurality of avatars being registered therein, each of the plurality of avatars being defined as information related to at least some of communication, skill, experience, physical location, availability, workload and history of work success based on attributes for a contact. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method recited in <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the client is a service associated with a Management Operations Center (MOC) and conveying the request to the contact using the communication information further comprises: 
<claim-text>binding the request to a WorkItem representing work being addressed by the work group; </claim-text>
<claim-text>binding a proxy avatar for the avatar to the WorkItem; and </claim-text>
<claim-text>communicating the conveying the request and at least some information pertaining to the work being addressed by the work group to the contact using the proxy avatar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method recited in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprises: 
<claim-text>deploying an avatar service in the enterprise, wherein the avatar is contained within the avatar service. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method recited in <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein registering the avatar in the enterprise further comprises: 
<claim-text>registering the avatar with a registrar within the enterprise, wherein registering is performed by the avatar service; and </claim-text>
<claim-text>requesting an enterprise lease for the avatar from the registrar, wherein requesting an enterprise lease is performed by the avatar service. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A data processing system implemented program product embodied on a data processing system readable medium for realizing a method for implementing an avatar as a shared resource among clients in an enterprise, said program product comprising: 
<claim-text>instructions for defining an avatar as information related to at least some of communication, skill, responsibilities, experience, physical location, availability, workload and history of work success, wherein the information is based on attributes for a contact; </claim-text>
<claim-text>instructions for registering the avatar in the enterprise; and </claim-text>
<claim-text>instructions for interacting with a service based on the information defining the avatar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The program product recited in <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the instructions for interacting with a service based on one of the information defining the avatar further comprises: 
<claim-text>instructions for receiving a request for the contact to participate with a work group from a client; </claim-text>
<claim-text>instructions for conveying the request to the contact using the communication information; and </claim-text>
<claim-text>instructions for updating the workload information to reflect an affirmative response to the request. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The program product recited in <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the instructions for interacting with a service based on one of the information defining the avatar further comprises: 
<claim-text>instructions for receiving a request for the contact to participate with a work group from a client; </claim-text>
<claim-text>instructions for conveying the request to the contact using the communication information; and </claim-text>
<claim-text>instructions for declining the request for the contact to participate based on a negative response to the request from the contact. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The program product recited in <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> further comprises: 
<claim-text>instructions for updating the skill and history of work success information of for the avatar based on completion of the participation with the work group. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The program product recited in <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the contact is one of an enterprise person and a customer person. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The program product recited in <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the instructions for interacting with a service based on the information defining the avatar further comprises: 
<claim-text>instructions for receiving a request for the contact to participate with a work group from a client, wherein the request is based on the skill, experience, physical location, availability, workload and history of work success of the contact, wherein the contact is a service person. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The program product recited in <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the enterprise having a plurality avatars being registered therein, each of the plurality of avatars being defined as information related to at least some of communication, skill, experience, physical location, availability, workload and history of work success based on attributes for a contact. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The program product recited in <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein the client is a service associated with a Management Operations Center (MOC) and the instructions for conveying the request to the contact using the communication information further comprises: 
<claim-text>instructions for binding the request to a WorkItem representing work being addressed by the work group; </claim-text>
<claim-text>instructions for binding a proxy avatar for the avatar to the WorkItem; and </claim-text>
<claim-text>instructions for communicating the conveying the request and at least some information pertaining to the work being addressed by the work group to the contact using the proxy avatar. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The program product recited in <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> further comprises: 
<claim-text>instructions for deploying an avatar service in the enterprise, wherein the avatar is contained within the avatar service. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The program product recited in <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, wherein the instructions for registering the avatar in the enterprise further comprises: 
<claim-text>instructions for registering the avatar with a registrar within the enterprise, wherein registering is performed by the avatar service; and </claim-text>
<claim-text>instructions for requesting an enterprise lease for the avatar from the registrar, wherein requesting an enterprise lease is performed by the avatar service.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>5</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004774A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004774A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004774A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004774A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004774A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004774A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004774A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004774A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004774A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004774A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030004774A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030004774A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030004774A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030004774A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030004774A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030004774A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030004774A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030004774A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030004774A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00019">
<image id="EMI-D00019" file="US20030004774A1-20030102-D00019.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00020">
<image id="EMI-D00020" file="US20030004774A1-20030102-D00020.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00021">
<image id="EMI-D00021" file="US20030004774A1-20030102-D00021.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00022">
<image id="EMI-D00022" file="US20030004774A1-20030102-D00022.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00023">
<image id="EMI-D00023" file="US20030004774A1-20030102-D00023.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00024">
<image id="EMI-D00024" file="US20030004774A1-20030102-D00024.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00025">
<image id="EMI-D00025" file="US20030004774A1-20030102-D00025.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00026">
<image id="EMI-D00026" file="US20030004774A1-20030102-D00026.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00027">
<image id="EMI-D00027" file="US20030004774A1-20030102-D00027.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00028">
<image id="EMI-D00028" file="US20030004774A1-20030102-D00028.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00029">
<image id="EMI-D00029" file="US20030004774A1-20030102-D00029.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00030">
<image id="EMI-D00030" file="US20030004774A1-20030102-D00030.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00031">
<image id="EMI-D00031" file="US20030004774A1-20030102-D00031.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00032">
<image id="EMI-D00032" file="US20030004774A1-20030102-D00032.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00033">
<image id="EMI-D00033" file="US20030004774A1-20030102-D00033.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00034">
<image id="EMI-D00034" file="US20030004774A1-20030102-D00034.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00035">
<image id="EMI-D00035" file="US20030004774A1-20030102-D00035.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00036">
<image id="EMI-D00036" file="US20030004774A1-20030102-D00036.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00037">
<image id="EMI-D00037" file="US20030004774A1-20030102-D00037.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00038">
<image id="EMI-D00038" file="US20030004774A1-20030102-D00038.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00039">
<image id="EMI-D00039" file="US20030004774A1-20030102-D00039.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00040">
<image id="EMI-D00040" file="US20030004774A1-20030102-D00040.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00041">
<image id="EMI-D00041" file="US20030004774A1-20030102-D00041.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00042">
<image id="EMI-D00042" file="US20030004774A1-20030102-D00042.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00043">
<image id="EMI-D00043" file="US20030004774A1-20030102-D00043.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00044">
<image id="EMI-D00044" file="US20030004774A1-20030102-D00044.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
