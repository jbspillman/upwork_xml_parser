<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002481A1-20030102-D00000.TIF SYSTEM "US20030002481A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00001.TIF SYSTEM "US20030002481A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00002.TIF SYSTEM "US20030002481A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00003.TIF SYSTEM "US20030002481A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00004.TIF SYSTEM "US20030002481A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00005.TIF SYSTEM "US20030002481A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00006.TIF SYSTEM "US20030002481A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00007.TIF SYSTEM "US20030002481A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00008.TIF SYSTEM "US20030002481A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00009.TIF SYSTEM "US20030002481A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00010.TIF SYSTEM "US20030002481A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00011.TIF SYSTEM "US20030002481A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00012.TIF SYSTEM "US20030002481A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00013.TIF SYSTEM "US20030002481A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00014.TIF SYSTEM "US20030002481A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00015.TIF SYSTEM "US20030002481A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00016.TIF SYSTEM "US20030002481A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00017.TIF SYSTEM "US20030002481A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00018.TIF SYSTEM "US20030002481A1-20030102-D00018.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00019.TIF SYSTEM "US20030002481A1-20030102-D00019.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00020.TIF SYSTEM "US20030002481A1-20030102-D00020.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00021.TIF SYSTEM "US20030002481A1-20030102-D00021.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00022.TIF SYSTEM "US20030002481A1-20030102-D00022.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00023.TIF SYSTEM "US20030002481A1-20030102-D00023.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00024.TIF SYSTEM "US20030002481A1-20030102-D00024.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00025.TIF SYSTEM "US20030002481A1-20030102-D00025.TIF" NDATA TIF>
<!ENTITY US20030002481A1-20030102-D00026.TIF SYSTEM "US20030002481A1-20030102-D00026.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002481</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10122397</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020416</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04L012/66</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>370</class>
<subclass>352000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>370</class>
<subclass>358000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Method and system for providing media services</title-of-invention>
</technical-information>
<continuity-data>
<continuations>
<continuation-of>
<parent-child>
<child>
<document-id>
<doc-number>10122397</doc-number>
<kind-code>A1</kind-code>
<document-date>20020416</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09930500</doc-number>
<document-date>20010816</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>PENDING</parent-status>
</parent-child>
</continuation-of>
</continuations>
<continuations>
<continuation-in-part-of>
<parent-child>
<child>
<document-id>
<doc-number>09930500</doc-number>
<document-date>20010816</document-date>
<country-code>US</country-code>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09893743</doc-number>
<document-date>20010629</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>PENDING</parent-status>
</parent-child>
</continuation-in-part-of>
</continuations>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Arthur</given-name>
<middle-name>I.</middle-name>
<family-name>Laursen</family-name>
</name>
<residence>
<residence-us>
<city>Diablo</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>David</given-name>
<family-name>Israel</family-name>
</name>
<residence>
<residence-us>
<city>Santa Clara</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Thomas</given-name>
<family-name>McKnight</family-name>
</name>
<residence>
<residence-us>
<city>Santa Clara</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>IP Unity</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>STERNE, KESSLER, GOLDSTEIN &amp; FOX PLLC</name-1>
<name-2></name-2>
<address>
<address-1>1100 NEW YORK AVENUE, N.W., SUITE 600</address-1>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20005-3934</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The present invention provides a method and system for providing media services in Voice over IP telephony. A switch is coupled between one or more audio sources and a network interface controller. The switch can be a packet switch or a cell switch. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application is a continuation of and claims the benefit of priority to &ldquo;Method and System for Distributed Conference Bridge Processing,&rdquo; application Ser. No. 09/930,500, by A. Laursen, filed on Aug. 16, 2001 (Atty Dkt. No. 2013.0040001), which in turn claims the benefit of priority to U.S. non-provisional application, &ldquo;Method and System for Switching Among Independent Packetized Audio Streams,&rdquo; application Ser. No. 09/893,743, by D. Israel et al., filed on Jun. 29, 2001 (Atty Dkt. No.2013.0040000), both of the application Ser. Nos. 09/930,500 and 09/893,743 are hereby incorporated herein by reference in their entirety.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The invention relates generally to audio communication over a network. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> 2. Background Art </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Audio has long been carried in telephone calls over networks. Traditional circuit-switched time division multiplexing (TDM) networks including public-switched telephone networks (PSTN) and plain old telephone networks (POTS) were used. These circuit-switched networks establish a circuit across the network for each call. Audio is carried in analog and/or digital form across the circuit in real-time. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The emergence of packet-switched networks, such as the local area networks (LANs), and the Internet, now requires that audio be carried digitally in packets. Audio can include but is not limited to voice, music, or other type of audio data. Voice over Internet Protocol systems (also called Voice over IP or VOIP systems) transport the digital audio data belonging to a telephone call in packets over packet-switched networks instead of traditional circuit-switched networks. In one example, a VOIP system forms two or more connections using Transmission Control Protocol/Internet Protocol (TCP/IP) addresses to accomplish a connected telephone call. Devices that connect to a VOIP network must follow standard TCP/IP packet protocols in order to interoperate with other devices within the VOIP network. Examples of such devices are IP phones, integrated access devices, media gateways, and media servers. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> A media server is often an endpoint in a VOIP telephone call. The media server is responsible for ingress and egress audio streams, that is, audio streams which enter and leave a media server respectively. The type of audio produced by a media server is controlled by the application that corresponds to the telephone call such as voice mail, conference bridge, interactive voice response (IVR), speech recognition, etc. In many applications, the produced audio is not predictable and must vary based on end user responses. Words, sentences, and whole audio segments such as music must be assembled dynamically in real time as they are played out in audio streams. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Packet-switched networks, however, can impart delay and jitter in a stream of audio carried in a telephone call. A real-time transport protocol (RTP) is often used to control delays, packet loss and latency in an audio stream played out of a media server. The audio stream can be played out using RTP over a network link to a real-time device (such as a telephone) or a non-real-time device (such as an email client in unified messaging). RTP operates on top of a protocol such as the User Datagram Protocol (UDP) which is part of the IP family. RTP packets include among other things a sequence number and a timestamp. The sequence number allows a destination application using RTP to detect the occurrence of lost packets and to ensure a correct order of packets are presented to a user. The timestamp corresponds to the time at which the packet was assembled. The timestamp allows a destination application to ensure synchronized play-out to a destination user and to calculate delay and jitter. See, D. Collins, <highlight><italic>Carrier Grade Voice over IP, </italic></highlight>Mc-Graw Hill: United States, Copyright 2001, pp. 52-72, the entire book of which is incorporated in its entirety herein by reference. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> A media server at an endpoint in a VOIP telephone call uses protocols such as RTP to improve communication quality for a single audio stream. Such media servers, however, have been limited to outputting a single audio stream of RTP packets for a given telephone call. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> A conference call links multiple parties over a network in a common call. Conference calls were originally carried out over a circuit-switched network such as a plain old telephone system (POTS) or public switched telephone network (PSTN). Conference calls are now also carried out over packet-switched networks, such as local area networks (LANs) and the Internet. Indeed, the emergence of voice over the Internet systems (also called Voice over IP or VOIP systems) has increased the demand for conference calls over networks. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> Conference bridges connect participants in conference calls. Different types of conference bridges have been used depending in part upon the type of network and how voice is carried over the network to the conference bridge. One type of conference bridge is described in U.S. Pat. No. 5,436,896 (see the entire patent). This conference bridge 10 operates in an environment where voice signals are digitally encoded in a 64 Kbps data stream (FIG. 1, col. 1, lns. 21-26). </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> Conference bridge 10 has a plurality of inputs 12 and outputs 14. Inputs 12 are connected through respective speech detectors 16 and switches 18 to a common summing amplifier 20. Speech detector 16 detects speech by sampling an input data stream and determining the amount of energy present over time. (col. 1, lns. 36-39). Each speech detector 16 controls a switch 18. When no speech is present switch 18 is held open to reduce noise. During a conference call, inputs 12 of all participants who are speaking are coupled through summing amplifier 20 to each of the outputs 14. Subtractors 24 subtract each participant&apos;s own voice data stream. A number of participants 1-n then can speak and hear each other in the connections made through conference bridge 10. See, &apos;896 patent, col. 1, ln. 12-col. 2, ln. 16. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Digitized voice is now also being carried in packets over packet-switched networks. The &apos;896 patent describes one example of asynchronous mode transfer (ATM) packets (also called cells). To support a conference call in this networking environment, conference bridge 10 converts input ATM cells to network packets. Digitized voice is extracted from the packets and processed in conference bridge 12 as described above. The summed output digitized voices is re-converted from network packets back to ATM cells prior to being sent to participants 1-n. See, &apos;896 patent, col. 2, ln. 17-col. 2, ln. 36. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> The &apos;896 patent also describes a conference bridge 238 shown in FIGS. 2 and 3 which processes ATM cells without converting and re-converting the ATM cells to network packets as in conference 10. Conference bridge 238 has inputs 302-306, one from each of the participants, and outputs 308-312, one to each of the participants. Speech detectors 314-318 analyze input data aggregated in sample and hold buffers 322-326. Speech detectors 314-318 report the detected speech an/or volume of detected speech to controller 320. See, &apos;896 patent, col. 4, lns. 16-39. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> Controller 320 is coupled to a selector 328, gain control 329 and replicator 330. Controller 320 determines which of the participants is speaking based on the outputs of speech detectors 314-318. When one speaker (such as participant 1) is talking, controller 320 sets selector 328 to read data from buffer 322. The data moves through automatic gain control 329 to replicator 330. Replicator replicates the data in the ATM cell selected by selector 328 for all participants except the speaker. See, &apos;896 patent, col. 4, ln. 40-col. 5, ln. 5. When two or more speakers are speaking, the loudest speaker is selected in a given selection period. The next loudest speaker is then selected in a subsequent selection period. The appearance of simultaneous speech is kept up by scanning speech detectors 314-318 and reconfiguring selector 328 at appropriate interval such as six milliseconds. See, &apos;896 patent, col. 5, lns. 6-65. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Another type of conference bridge is described in U.S. Pat. No. 5,983,192 (see the entire patent). In one embodiment, a conference bridge 12 receives compressed audio packets through a real-time transport protocol (RTP/RTCP). See, &apos;192 patent, col. 3, ln. 66-col. 4, ln. 40. Conference bridge 12 includes audio processors 14<highlight><italic>a</italic></highlight>-14<highlight><italic>d</italic></highlight>. Exemplary audio processor 14<highlight><italic>c </italic></highlight>associated with a site C (i.e., a participant C) includes a switch 22 and selector 26. Selector 26 includes a speech detector which determines which of other sites A, B, or D has the highest likelihood of speech. See, &apos;192 patent, col. 4, lns. 40-67. Alternatives include selecting more than one site and using an acoustic energy detector. See, &apos;192 patent, col. 5, lns. 1-7. In another embodiment described in the &apos;192 patent, the selector 26/switches 22 output a plurality of loudest speakers in separate streams to local mixing end-point sites. The loudest streams are sent to multiple sites. See, &apos;192 patent, col. 5, lns. 8-67. Configurations of mixer/encoders are also described to handle multiple speakers at the same time, referred to as &ldquo;double-talk&rdquo; and &ldquo;triple-talk.&rdquo; See, &apos;192 patent, col. 7, ln. 20-col. 9, ln. 29. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> Voice-over-the-Internet (VOIP) systems continue to require an improved conference bridge. For example, a Softswitch VOIP architecture may use one or more media servers having a media gateway control protocol such as MGCP (RFC 2705). See, D. Collins, <highlight><italic>Carrier Grade Voice over IP, </italic></highlight>Mc-Graw Hill: United States, Copyright 2001, pp. 234-244, the entire book of which is incorporated in its entirety herein by reference. Such media servers are often used to process audio streams in VOIP calls. These media servers are often endpoints where audio streams are mixed in a conference call. These endpoints are also referred to as &ldquo;conference bridge access points&rdquo; since the media server is an endpoint where media streams from multiple callers are mixed and provided again to some or all of the callers. See, D. Collins, p. 242. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> As the popularity and demand for IP telephony and VOIP calls increases, media servers are expected to handle conference call processing with carrier grade quality. Conference bridges in a media server need to be able to scale to handle different numbers of participants. Audio in packet streams, such as RTP/RTCP packets, needs to be processed in real-time efficiently. </paragraph>
</section>
<section>
<heading lvl="1">BRIEF SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> The present invention provides a method and system for providing media services in Voice over IP telephony. In one embodiment, a switch is coupled between multiple audio sources and a network interface controller. The switch can be a packet switch or a cell switch. Internal and/or external audio sources generate audio streams of packets. Any type of packet can be used. In one embodiment, an internal packet includes a packet header and a payload. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Further embodiments, features, and advantages of the present inventions, as well as the structure and operation of the various embodiments of the present invention, are described in detail below with reference to the accompanying drawings.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The accompanying drawings, which are incorporated herein and form a part of the specification, illustrate the present invention and, together with the description, further serve to explain the principles of the invention and to enable a person skilled in the pertinent art to make and use the invention. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> In the drawings: </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a diagram of a media server in a voice over the Internet example environment according to the present invention. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a diagram of an example media server including media services and resources according to the present invention. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 3A and 3B</cross-reference> are diagrams of an audio processing platform according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a diagram of a audio processing platform as shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> according to an example implementation of the present invention. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5A</cross-reference> is a flow diagram showing the establishment of a call and ingress packet processing according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5B</cross-reference> is a flow diagram showing egress packet processing and call completion according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> FIGS. <highlight><bold>6</bold></highlight>A-<highlight><bold>6</bold></highlight>F are diagrams of noiseless switch over systems according to embodiments of the present invention. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6A</cross-reference> is diagram of a noiseless switch over system that carries out cell switching of independent egress audio streams generated by internal audio sources according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is diagram of audio data flow in a noiseless switch over system that carries out cell switching of independent egress audio streams generated by internal audio sources according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6C</cross-reference> is diagram of a noiseless switch over system that carries out cell switching between independent egress audio streams generated by internal and/or external audio sources according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6D</cross-reference> is diagram of audio data flow in a noiseless switch over system that carries out cell switching between independent egress audio streams generated by internal and/or external audio sources according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6E</cross-reference> is diagram of audio data flow in a noiseless switch over system that carries out packet switching between independent egress audio streams generated by internal and/or external audio sources according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6F</cross-reference> is diagram of a noiseless switch over system that carries out switching between independent egress audio streams generated by external audio sources according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7A</cross-reference> is a schematic illustration of an IP packet with RTP information. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7B</cross-reference> is a schematic illustration of an internal packet according to one embodiment of the present invention. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flow diagram showing the switching functionality according to one embodiment of the present invention. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 9A, 9B</cross-reference>, and <highlight><bold>9</bold></highlight>C are flow diagrams showing the call event processing for audio stream switching according to one embodiment of the present invention. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a block diagram of a distributed conference bridge according to one embodiment of the present invention. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is an example look-up table used in the distributed conference bridge of <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a flowchart diagram of the operation of the distributed conference bridge of <cross-reference target="DRAWINGS">FIG. 10</cross-reference> in establishing a conference call. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 13A, 13B</cross-reference>, and <highlight><bold>13</bold></highlight>C are flowchart diagrams of the operation of the distributed conference bridge of <cross-reference target="DRAWINGS">FIG. 10</cross-reference> in processing a conference call. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14A</cross-reference> is a diagram of an example internal packet generated by an audio source during a conference call according to one embodiment of the present invention. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14B</cross-reference> is a diagram that illustrates example packet content in a fully mixed audio stream and set of partially mixed audio streams according to the present invention. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is a diagram that illustrates example packet content after the packets of <cross-reference target="DRAWINGS">FIG. 14</cross-reference> have been multicasted and after they have been processed into IP packets to be sent to appropriate participants in a 64 participant conference call according to the present invention. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> The present invention will now be described with reference to the accompanying drawings. In the drawings, like reference numbers indicate identical or functionally similar elements. Additionally, the left-most digit(s) of a reference number identifies the drawing in which the reference number first appears. </paragraph>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
</section>
<section>
<heading lvl="1">Table of Contents </heading>
<paragraph id="P-0048" lvl="1"><number>&lsqb;0048&rsqb;</number> I. Overview and Discussion </paragraph>
<paragraph id="P-0049" lvl="1"><number>&lsqb;0049&rsqb;</number> II. Terminology </paragraph>
<paragraph id="P-0050" lvl="1"><number>&lsqb;0050&rsqb;</number> III. Audio Networking Environment </paragraph>
<paragraph id="P-0051" lvl="1"><number>&lsqb;0051&rsqb;</number> IV. Media Server, Services and Resources </paragraph>
<paragraph id="P-0052" lvl="1"><number>&lsqb;0052&rsqb;</number> V. Audio Processing Platform with a Packet/Cell Switch for Noiseless Switching of Independent Audio Streams </paragraph>
<paragraph id="P-0053" lvl="1"><number>&lsqb;0053&rsqb;</number> VI. Example Audio Processing Platform Implementation </paragraph>
<paragraph id="P-0054" lvl="1"><number>&lsqb;0054&rsqb;</number> VII. Call Control and Audio Feature Manager </paragraph>
<paragraph id="P-0055" lvl="1"><number>&lsqb;0055&rsqb;</number> VIII. Audio Processing Platform Operation </paragraph>
<paragraph id="P-0056" lvl="2"><number>&lsqb;0056&rsqb;</number> A. Ingress Audio Streams </paragraph>
<paragraph id="P-0057" lvl="2"><number>&lsqb;0057&rsqb;</number> B. Egress Audio Streams </paragraph>
<paragraph id="P-0058" lvl="1"><number>&lsqb;0058&rsqb;</number> IX. Noiseless Switching of Egress Audio Streams </paragraph>
<paragraph id="P-0059" lvl="2"><number>&lsqb;0059&rsqb;</number> A. Cell Switch&mdash;Internal Audio Sources </paragraph>
<paragraph id="P-0060" lvl="2"><number>&lsqb;0060&rsqb;</number> B. Packets </paragraph>
<paragraph id="P-0061" lvl="3"><number>&lsqb;0061&rsqb;</number> 1. IP Packets with RTP information </paragraph>
<paragraph id="P-0062" lvl="3"><number>&lsqb;0062&rsqb;</number> 2. Internal Egress Packets </paragraph>
<paragraph id="P-0063" lvl="2"><number>&lsqb;0063&rsqb;</number> C. Priority Levels </paragraph>
<paragraph id="P-0064" lvl="2"><number>&lsqb;0064&rsqb;</number> D. Noiseless Fully Meshed Cell Switch </paragraph>
<paragraph id="P-0065" lvl="2"><number>&lsqb;0065&rsqb;</number> E. Two-Stage Egress Switching </paragraph>
<paragraph id="P-0066" lvl="2"><number>&lsqb;0066&rsqb;</number> F. Call Event Triggering Noiseless Switch Over </paragraph>
<paragraph id="P-0067" lvl="2"><number>&lsqb;0067&rsqb;</number> G. Audio Data Flow </paragraph>
<paragraph id="P-0068" lvl="2"><number>&lsqb;0068&rsqb;</number> H. Other Embodiments </paragraph>
<paragraph id="P-0069" lvl="1"><number>&lsqb;0069&rsqb;</number> X. Conference Call Processing </paragraph>
<paragraph id="P-0070" lvl="2"><number>&lsqb;0070&rsqb;</number> A. Distributed Conference Bridge </paragraph>
<paragraph id="P-0071" lvl="2"><number>&lsqb;0071&rsqb;</number> B. Distributed Conference Bridge Operation </paragraph>
<paragraph id="P-0072" lvl="2"><number>&lsqb;0072&rsqb;</number> C. Outbound Packet Flow through Distributed Conference Bridge </paragraph>
<paragraph id="P-0073" lvl="2"><number>&lsqb;0073&rsqb;</number> D. Control Logic and Additional Embodiments </paragraph>
<paragraph id="P-0074" lvl="1"><number>&lsqb;0074&rsqb;</number> XI. Conclusion </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> I. Overview and Discussion </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> The present invention provides a method and system for distributed conference bridge processing in Voice over IP telephony. Work is distributed away from a mixing device such as a DSP. In particular, a distributed conference bridge according to the present invention uses internal multicasting and packet processing at a network interface to reduce work at an audio mixing device. A conference call agent is used to establish and end a conference call. An audio source such as a DSP mixes audio of active conference call participants. Only one fully mixed audio stream and a set of partially mixed audio streams need to be generated. A switch is coupled between the audio source mixing audio content and a network interface controller. The switch includes a multi-caster. The multi-caster replicates packets in the one fully mixed audio stream and a set of partially mixed audio streams and multi-casts the replicated packets to links (such as SVCs) associated with each call participant. A network interface controller processes each packet to determine whether to discard or forward the packet for the fully mixed or partially mixed audio stream to a participant. This determination can be made in real-time based on a look-up table at the NIC and the packet header information in the multicasted audio streams. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> In one embodiment, a conference bridge according to the present invention is implemented in a media server. According to embodiments of the present invention, the media server can include a call control and audio feature manager for managing the operations of the conference bridge. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> The present invention is described in terms of an example voice over the Internet environment. Description in these terms is provided for convenience only. It is not intended that the invention be limited to application in these example environments. In fact, after reading the following description, it will become apparent to a person skilled in the relevant art how to implement the invention in alternative environments known now or developed in the future. </paragraph>
<paragraph id="P-0079" lvl="7"><number>&lsqb;0079&rsqb;</number> II. Terminology </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> To more clearly delineate the present invention, an effort is made throughout the specification to adhere to the following term definitions as consistently as possible. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> The term noiseless according to the present invention refers to switching between independent audio streams where packet sequence information is preserved. The term synchronized header information refers to packets having headers where packet sequence information is preserved. Packet sequence information can include but is not limited to valid RTP information. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> The term digital signal processor (DSP) includes but is not limited to a device used to code or decode digitized voice samples according to a program or application service. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> The term digitized voice or voice includes but is not limited to audio byte samples produced in a pulse code modulation (PCM) architecture by a standard telephone circuit compressor/decompressor (CODEC). </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> The term packet processor refers to any type of packet processor that creates packets for a packet-switched network. In one example, a packet processor is a specialized microprocessor designed to examine and modify Ethernet packets according to a program or application service. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> The term packetized voice refers to digitized voice samples carried within a packet. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> The term real time protocol (RTP) stream of audio refers to the sequence of RTP packets associated with one channel of packetized voice. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The term switched virtual circuit (SVC) refers to a temporary virtual circuit that is set up and used only as long as data is being transmitted. Once the communication between the two hosts is complete, the SVC disappears. In contrast, a permanent virtual circuit (PVC) remains available at all times. </paragraph>
<paragraph id="P-0088" lvl="7"><number>&lsqb;0088&rsqb;</number> III. Audio Networking Environment </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> The present invention can be used in any audio networking environment. Such audio networking environments can include but are not limited to a wide area and/or local area network environment. In example embodiments, the present invention is incorporated within an audio networking environment as a stand-alone unit or as part of a media server, packet router, packet switch or other network component. For brevity, the present invention is described with respect to embodiments incorporated in a media server. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> Media servers deliver audio on network links over one or more circuit-switched and/or packet-switched networks to local or remote clients. A client can be any type of device that handles audio including but not limited to a telephone, cellular phone, personal computer, personal data assistant (PDA), set-top box, console, or audio player. <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a diagram of a media server <highlight><bold>140</bold></highlight> in an voice over the Internet example environment according to the present invention. This example includes a telephone client <highlight><bold>105</bold></highlight>, public-switched telephone network (PSTN) <highlight><bold>110</bold></highlight>, softswitch <highlight><bold>120</bold></highlight>, gateway <highlight><bold>130</bold></highlight>, media server <highlight><bold>140</bold></highlight>, packet-switched network(s) <highlight><bold>150</bold></highlight>, and computer client <highlight><bold>155</bold></highlight>. Telephone client <highlight><bold>105</bold></highlight> is any type of phone (wired or wireless) that can send and receive audio over PSTN <highlight><bold>110</bold></highlight>. PSTN <highlight><bold>110</bold></highlight> is any type of circuit-switched network(s). Computer client <highlight><bold>155</bold></highlight> can be a personal computer. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> Telephone client <highlight><bold>105</bold></highlight> is coupled through a public-switched telephone network (PSTN) <highlight><bold>110</bold></highlight>, gateway <highlight><bold>130</bold></highlight> and network <highlight><bold>150</bold></highlight> to media server <highlight><bold>140</bold></highlight>. In this example, call signaling and control is separated from the media paths or links that carry audio. Softswitch <highlight><bold>120</bold></highlight> is provided between PSTN <highlight><bold>110</bold></highlight> and media server <highlight><bold>140</bold></highlight>. Softswitch <highlight><bold>120</bold></highlight> supports call signaling and control to establish and remove voice calls between telephone client <highlight><bold>105</bold></highlight> and media server <highlight><bold>140</bold></highlight>. In one example, softswitch <highlight><bold>120</bold></highlight> follows the Session Initiation Protocol (SIP). Gateway <highlight><bold>130</bold></highlight> is responsible for converting audio passing to and from PSTN <highlight><bold>110</bold></highlight> and network <highlight><bold>150</bold></highlight>. This can include a variety of well-known functions such as translating a circuit-switched telephone number to an Internet Protocol (IP) address and vice versa. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> Computer client <highlight><bold>155</bold></highlight> is coupled over network <highlight><bold>150</bold></highlight> to media server <highlight><bold>140</bold></highlight>. A media gateway controller (not shown) can also use SIP to support call signaling and control to establish and breakdown links such as voice calls between computer client <highlight><bold>155</bold></highlight> and media server <highlight><bold>140</bold></highlight>. An application server (not shown) can also be coupled to media server <highlight><bold>140</bold></highlight> to support VOIP services and applications. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> The present invention is described in terms of these example environments. Description in these terms is provided for convenience only. It is not intended that the invention be limited to application in these example environments involving a media server, router, switch, network component, or stand-alone unit within a network. In fact, after reading the following description, it will become apparent to a person skilled in the relevant art how to implement the invention in alternative environments known now or developed in the future. </paragraph>
<paragraph id="P-0094" lvl="7"><number>&lsqb;0094&rsqb;</number> IV. Media Server, Services and Resources </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a diagram of an example media platform <highlight><bold>200</bold></highlight> according to one embodiment the present invention. Platform <highlight><bold>200</bold></highlight> provides scalable VOIP telephony. Media platform <highlight><bold>200</bold></highlight> includes a media server <highlight><bold>202</bold></highlight> coupled to resource(s) <highlight><bold>210</bold></highlight>, media service(s) <highlight><bold>212</bold></highlight>, and interface(s) <highlight><bold>208</bold></highlight>. Media server <highlight><bold>202</bold></highlight> includes one or more applications <highlight><bold>210</bold></highlight>, a resource manager <highlight><bold>220</bold></highlight> and audio processing platform <highlight><bold>230</bold></highlight>. Media server <highlight><bold>202</bold></highlight> provides resources <highlight><bold>210</bold></highlight> and services <highlight><bold>212</bold></highlight>. Resources <highlight><bold>210</bold></highlight> include, but are not limited to modules <highlight><bold>211</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>f</italic></highlight>, as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Resource modules <highlight><bold>211</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>f </italic></highlight>include conventional resources such as play announcements/collect digits IVR resources <highlight><bold>211</bold></highlight><highlight><italic>a</italic></highlight>, tone/digit voice scanning resource <highlight><bold>211</bold></highlight><highlight><italic>b</italic></highlight>, transcoding resource <highlight><bold>211</bold></highlight><highlight><italic>c</italic></highlight>, audio record/play resource <highlight><bold>211</bold></highlight><highlight><italic>d</italic></highlight>, text-to-speech resource <highlight><bold>211</bold></highlight><highlight><italic>e</italic></highlight>, and speech recognition resource <highlight><bold>211</bold></highlight><highlight><italic>f. </italic></highlight>Media services <highlight><bold>212</bold></highlight> include, but are not limited to, modules <highlight><bold>213</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>e</italic></highlight>, as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Media services modules <highlight><bold>213</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>e </italic></highlight>include conventional services such as telebrowsing <highlight><bold>213</bold></highlight><highlight><italic>a</italic></highlight>, voice mail service <highlight><bold>213</bold></highlight><highlight><italic>b</italic></highlight>, conference bridge service <highlight><bold>213</bold></highlight><highlight><italic>c</italic></highlight>, video streaming <highlight><bold>213</bold></highlight><highlight><italic>d</italic></highlight>, and a VOIP gateway <highlight><bold>213</bold></highlight><highlight><italic>e. </italic></highlight></paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> Media server <highlight><bold>202</bold></highlight> includes an application central processing unit (CPU) <highlight><bold>210</bold></highlight>, a resource manager CPU <highlight><bold>220</bold></highlight>, and an audio processing platform <highlight><bold>230</bold></highlight>. Application CPU <highlight><bold>210</bold></highlight> is any processor that supports and executes program interfaces for applications and applets. Application CPU <highlight><bold>210</bold></highlight> enables platform <highlight><bold>200</bold></highlight> to provide one or more of the media services <highlight><bold>212</bold></highlight>. Resource manager CPU <highlight><bold>220</bold></highlight> is any processor that controls connectivity between resources <highlight><bold>210</bold></highlight> and the application CPU <highlight><bold>210</bold></highlight> and/or audio processing platform <highlight><bold>230</bold></highlight>. Audio processing platform <highlight><bold>230</bold></highlight> provides communications connectivity with one or more of the network interfaces <highlight><bold>208</bold></highlight>. Media platform <highlight><bold>200</bold></highlight> through audio processing platform <highlight><bold>230</bold></highlight> receives and transmits information via network interface <highlight><bold>208</bold></highlight>. Interface <highlight><bold>208</bold></highlight> can include, but it not limited to, Asynchronous Transfer Mode (ATM) <highlight><bold>209</bold></highlight><highlight><italic>a</italic></highlight>, local area network (LAN) Ethernet <highlight><bold>209</bold></highlight><highlight><italic>b</italic></highlight>, digital subscriber line (DSL) <highlight><bold>209</bold></highlight><highlight><italic>c</italic></highlight>, cable modem <highlight><bold>209</bold></highlight><highlight><italic>d</italic></highlight>, and channelized T1-T3 lines <highlight><bold>209</bold></highlight><highlight><italic>e. </italic></highlight></paragraph>
<paragraph id="P-0097" lvl="7"><number>&lsqb;0097&rsqb;</number> V. Audio Processing Platform with a Packet/Cell Switch for Noiseless Switching of Independent Audio Streams </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> In one embodiment of the present invention, audio processing platform <highlight><bold>230</bold></highlight> includes a dynamic fully-meshed cell switch <highlight><bold>304</bold></highlight> and other components for the reception and processing of packets, such as Internet Protocol (IP) packets. Platform <highlight><bold>230</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 3A</cross-reference> with regard to audio processing including noiseless switching according to the present invention. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> As illustrated, audio processing platform <highlight><bold>230</bold></highlight> includes a call control and audio feature manager <highlight><bold>302</bold></highlight>, cell switch <highlight><bold>304</bold></highlight> (also referred to as a packet/cell switch to indicate cell switch <highlight><bold>304</bold></highlight> can be a cell switch or packet switch), network connections <highlight><bold>305</bold></highlight>, network interface controller <highlight><bold>306</bold></highlight>, and audio channel processors <highlight><bold>308</bold></highlight>. Network interface controller <highlight><bold>306</bold></highlight> further includes packet processors <highlight><bold>307</bold></highlight>. Call control and audio feature manager <highlight><bold>302</bold></highlight> is coupled to cell switch <highlight><bold>304</bold></highlight>, network interface controller <highlight><bold>306</bold></highlight>, and audio channels processors <highlight><bold>308</bold></highlight>. In one configuration, call control and audio feature manager <highlight><bold>302</bold></highlight> is connected directly to the network interface controller <highlight><bold>306</bold></highlight>. Network interface controller <highlight><bold>306</bold></highlight> then controls packet processor <highlight><bold>307</bold></highlight> operation based on the control commands sent by call control and audio feature manager <highlight><bold>302</bold></highlight>. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> In one embodiment, call control and audio feature manager <highlight><bold>302</bold></highlight> controls cell switch <highlight><bold>304</bold></highlight>, network interface controller <highlight><bold>306</bold></highlight> (including packet processors <highlight><bold>307</bold></highlight>), and audio channel processors <highlight><bold>308</bold></highlight> to provide noiseless switching of independent audio streams according to the present invention. This noiseless switching is described further below with respect to FIGS. <highlight><bold>6</bold></highlight>-<highlight><bold>9</bold></highlight>. An embodiment of the call control and audio feature manager <highlight><bold>302</bold></highlight> according to the present invention is described further below with respect to <cross-reference target="DRAWINGS">FIG. 3B</cross-reference>. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> Network connections <highlight><bold>305</bold></highlight> are coupled to packet processors <highlight><bold>307</bold></highlight>. Packet processors <highlight><bold>307</bold></highlight> are also coupled to cell switch <highlight><bold>304</bold></highlight>. Cell switch <highlight><bold>304</bold></highlight> is coupled in turn to audio channel processors <highlight><bold>308</bold></highlight>. In one embodiment, audio channel processors <highlight><bold>308</bold></highlight> include four channels capable of handling four calls, i.e., there are four audio processing sections. In alternative embodiments, there are more or less audio channel processors <highlight><bold>308</bold></highlight>. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> Data packets, such as IP packets, that include payloads having audio data arrive at network connections <highlight><bold>305</bold></highlight>. In one embodiment, packet processors <highlight><bold>307</bold></highlight> comprise one or more or eight 100Base-TX full-duplex Ethernet links capable of high speed network traffic in the realm of 300,000 packets per second per link. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> In another embodiment, packet processors <highlight><bold>307</bold></highlight> are capable of 1,000 G.711 voice ports per link and/or 8,000 G.711 voice channels per system. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> In additional embodiments, packet processors <highlight><bold>307</bold></highlight> recognize the IP headers of packets and handle all RTP routing decisions with a minimum of packet delay or jitter. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> In one embodiment of the present invention, packet/cell switch <highlight><bold>304</bold></highlight> is a non-blocking switch with 2.5 Gbps of total bandwidth. In another embodiment, the packet/cell switch <highlight><bold>204</bold></highlight> has 5 Gbps of total bandwidth. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> In one embodiment, the audio channel processors <highlight><bold>308</bold></highlight> comprise any audio source, such as digital signal processors, as described in further detail with regards to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. The audio channel processors <highlight><bold>308</bold></highlight> can perform audio related services including one or more of the services <highlight><bold>211</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>f. </italic></highlight></paragraph>
<paragraph id="P-0107" lvl="7"><number>&lsqb;0107&rsqb;</number> VI. Example Audio Processing Platform Implementation </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows one example implementation which is illustrative and not intended to limit the present invention. As shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, audio processing platform <highlight><bold>230</bold></highlight> can be a shelf controller card (SCC). System <highlight><bold>400</bold></highlight> embodies one such SCC. System <highlight><bold>400</bold></highlight> includes cell switch <highlight><bold>304</bold></highlight>, call control and audio feature manager <highlight><bold>302</bold></highlight>, a network interface controller <highlight><bold>306</bold></highlight>, interface circuitry <highlight><bold>410</bold></highlight>, and audio channel processors <highlight><bold>308</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>d. </italic></highlight></paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> More specifically, system <highlight><bold>400</bold></highlight> receives packets at network connections <highlight><bold>424</bold></highlight> and <highlight><bold>426</bold></highlight>. Network connections <highlight><bold>424</bold></highlight> and <highlight><bold>426</bold></highlight> are coupled to network interface controller <highlight><bold>306</bold></highlight>. Network interface controller <highlight><bold>306</bold></highlight> includes packet processors <highlight><bold>307</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>b</italic></highlight>. Packet processors <highlight><bold>307</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>b </italic></highlight>comprise controllers <highlight><bold>420</bold></highlight>, <highlight><bold>422</bold></highlight>, forwarding tables <highlight><bold>412</bold></highlight>,<highlight><bold>416</bold></highlight>, and forwarding processor (EPIF) <highlight><bold>414</bold></highlight>,<highlight><bold>418</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, packet processor <highlight><bold>307</bold></highlight><highlight><italic>a </italic></highlight>is coupled to network connection <highlight><bold>424</bold></highlight>. Network connection <highlight><bold>424</bold></highlight> is coupled to controller <highlight><bold>420</bold></highlight>. Controller <highlight><bold>420</bold></highlight> is coupled to both forwarding table <highlight><bold>412</bold></highlight> and EPIF <highlight><bold>414</bold></highlight>. Packet processor <highlight><bold>307</bold></highlight><highlight><italic>b </italic></highlight>is coupled to network connection <highlight><bold>426</bold></highlight>. Network connection <highlight><bold>426</bold></highlight> is coupled to controller <highlight><bold>422</bold></highlight>. Controller <highlight><bold>422</bold></highlight> is coupled to both forwarding table <highlight><bold>416</bold></highlight> and EPIF <highlight><bold>418</bold></highlight>. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> In one embodiment, packet processors <highlight><bold>307</bold></highlight> can be implemented on one or more LAN daughtercard modules. In another embodiment, each network connection <highlight><bold>424</bold></highlight> and <highlight><bold>426</bold></highlight> can be a 100Base-TX or 1000Base-T link. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> The IP packets received by the packet processors <highlight><bold>307</bold></highlight> are processed into internal packets. When a cell layer is used, the internal packets are then converted to cells (such as ATM cells by a conventional segmentation and reassembly (SAR) module). The cells are forwarded by packet processors <highlight><bold>307</bold></highlight> to cell switch <highlight><bold>304</bold></highlight>. The packet processors <highlight><bold>307</bold></highlight> are coupled to the cell switch <highlight><bold>304</bold></highlight> via cell buses <highlight><bold>428</bold></highlight>, <highlight><bold>430</bold></highlight>, <highlight><bold>432</bold></highlight>, <highlight><bold>434</bold></highlight>. Cell switch <highlight><bold>304</bold></highlight> forwards the cells to interface circuitry <highlight><bold>410</bold></highlight> via cell buses <highlight><bold>454</bold></highlight>,<highlight><bold>456</bold></highlight>,<highlight><bold>458</bold></highlight>,<highlight><bold>460</bold></highlight>. Cell switch <highlight><bold>304</bold></highlight> analyzes each of the cells and forwards each of the cells to the proper cell bus of cell buses <highlight><bold>454</bold></highlight>, <highlight><bold>456</bold></highlight>, <highlight><bold>458</bold></highlight>, <highlight><bold>460</bold></highlight> based on an audio channel for which that cell is destined. Cell switch <highlight><bold>304</bold></highlight> is a dynamic, fully-meshed switch. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> In one embodiment, interface circuitry <highlight><bold>410</bold></highlight> is a backplane connector. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> The resources and services available for the processing and switching of the packets and cells in system <highlight><bold>400</bold></highlight> are provided by call control and audio feature manager <highlight><bold>304</bold></highlight>. Call control and audio feature manager <highlight><bold>302</bold></highlight> is coupled to cell switch <highlight><bold>402</bold></highlight> via a processor interface (PIF) <highlight><bold>436</bold></highlight>, a SAR, and a local bus <highlight><bold>437</bold></highlight>. Local bus <highlight><bold>437</bold></highlight> is further coupled to a buffer <highlight><bold>438</bold></highlight>. Buffer <highlight><bold>438</bold></highlight> stores and queues instructions between the call control and audio feature manager <highlight><bold>302</bold></highlight> and the cell switch <highlight><bold>304</bold></highlight>. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> Call control and audio feature manager <highlight><bold>302</bold></highlight> is also coupled to a memory module <highlight><bold>442</bold></highlight> and a configuration module <highlight><bold>440</bold></highlight> via bus connection <highlight><bold>444</bold></highlight>. In one embodiment, configuration module <highlight><bold>440</bold></highlight> provides control logic for the boot-up, initial diagnostic, and operational parameters of call control and audio feature manager <highlight><bold>302</bold></highlight>. In one embodiment, memory module <highlight><bold>442</bold></highlight> comprises dual in-line memory modules (DIMMs) for random access memory (RAM) operations of call control and audio feature manager <highlight><bold>302</bold></highlight>. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> Call control and audio feature manager <highlight><bold>302</bold></highlight> is further coupled to interface circuitry <highlight><bold>410</bold></highlight>. A network conduit <highlight><bold>408</bold></highlight> couples resource manager CPU <highlight><bold>220</bold></highlight> and/or application CPU <highlight><bold>210</bold></highlight> to the interface circuitry <highlight><bold>410</bold></highlight>. In one embodiment, call control and audio feature manager <highlight><bold>302</bold></highlight> monitors the status of the interface circuitry <highlight><bold>410</bold></highlight> and additional components coupled to the interface circuitry <highlight><bold>410</bold></highlight>. In another embodiment, call control and audio feature manager <highlight><bold>302</bold></highlight> controls the operations of the components coupled to the interface circuitry <highlight><bold>410</bold></highlight> in order to provide the resources <highlight><bold>210</bold></highlight> and services <highlight><bold>212</bold></highlight> of platform <highlight><bold>200</bold></highlight>. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> A console port <highlight><bold>470</bold></highlight> is also coupled to call control and audio feature manager <highlight><bold>302</bold></highlight>. Console port <highlight><bold>470</bold></highlight> provides direct access to the operations of call control and audio feature manager <highlight><bold>302</bold></highlight>. For example, one could administer the operations, re-boot the media processor, or otherwise affect the performance of call control and audio feature manager <highlight><bold>302</bold></highlight> and thus the system <highlight><bold>400</bold></highlight> using the console port <highlight><bold>470</bold></highlight>. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> Reference clock <highlight><bold>468</bold></highlight> is coupled to interface circuitry <highlight><bold>410</bold></highlight> and other components of the system <highlight><bold>400</bold></highlight> to provide consistent means of time-stamping the packets, cells and instructions of the system <highlight><bold>400</bold></highlight>. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> Interface circuitry <highlight><bold>410</bold></highlight> is coupled to each of audio channel processors <highlight><bold>308</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>308</bold></highlight><highlight><italic>d</italic></highlight>. Each of the processors <highlight><bold>308</bold></highlight> comprise a PIF <highlight><bold>476</bold></highlight>, a group <highlight><bold>478</bold></highlight> of one or more card processors (also referred to as &ldquo;bank&rdquo; processors), and a group <highlight><bold>480</bold></highlight> of one or more digital signal processors (DSP) and SDRAM buffers. In one embodiment, there are four card processors in group <highlight><bold>478</bold></highlight> and <highlight><bold>32</bold></highlight> DSPs in group <highlight><bold>480</bold></highlight>. In such an embodiment, each card processor of group <highlight><bold>478</bold></highlight> would access and operate with eight DSPs of group <highlight><bold>480</bold></highlight>. </paragraph>
<paragraph id="P-0119" lvl="7"><number>&lsqb;0119&rsqb;</number> VII. Call Control and Audio Feature Manager </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3B</cross-reference> is a block diagram of call control and audio feature manager <highlight><bold>302</bold></highlight> according to one embodiment of the present invention. Call control and audio feature manager <highlight><bold>302</bold></highlight> is illustrated functionally as processor <highlight><bold>302</bold></highlight>. Processor <highlight><bold>302</bold></highlight> comprises a call signaling manager <highlight><bold>352</bold></highlight>, system manager <highlight><bold>354</bold></highlight>, connection manager <highlight><bold>356</bold></highlight>, and feature controller <highlight><bold>358</bold></highlight>. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> Call signaling manager <highlight><bold>352</bold></highlight> manages call signaling operation such as call establishment and removal, interface with a softswitch, and handling signaling protocols like SIP. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> System manager <highlight><bold>354</bold></highlight> performs bootstrap and diagnostic operations on the components of system <highlight><bold>230</bold></highlight>. System manager <highlight><bold>354</bold></highlight> further monitors the system <highlight><bold>230</bold></highlight> and controls various hot-swapping and redundant operation. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> Connection manager <highlight><bold>356</bold></highlight> manages EPIF forwarding tables, such as tables <highlight><bold>412</bold></highlight> and <highlight><bold>416</bold></highlight>, and provides the routing protocols (such as Routing Information Protocol (RIP), Open Shortest Path First (OSPF), and the like). Further, the connection manager <highlight><bold>356</bold></highlight> establishes internal ATM permanent virtual circuits (PVC) and/or SVC. In one embodiment, the connection manager <highlight><bold>356</bold></highlight> establishes bi-directional connections between the network connections, such as network connections <highlight><bold>424</bold></highlight> and <highlight><bold>426</bold></highlight>, and the DSP channels, such as DSPs <highlight><bold>480</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>d</italic></highlight>, so that data flows can be sources or processed by a DSP or other type of channel processor. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> In another embodiment, connection manager <highlight><bold>356</bold></highlight> abstracts the details of the EPIF and ATM hardware. Call signaling manager <highlight><bold>352</bold></highlight> and the resource manager CPU <highlight><bold>220</bold></highlight> can access these details so that their operations are based on the proper service set and performance parameters. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> Feature controller <highlight><bold>358</bold></highlight> provides communication interfaces and protocols such as, H.323, and MGCP (Media Gateway Control Protocol). </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> In one embodiment, card processors <highlight><bold>478</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>d </italic></highlight>function as controllers with local managers for the handling of instructions from the call control and audio feature manager <highlight><bold>302</bold></highlight> and any of its modules: call signaling manager <highlight><bold>352</bold></highlight>, system manager <highlight><bold>354</bold></highlight>, connection manager <highlight><bold>356</bold></highlight>, and feature controller <highlight><bold>358</bold></highlight>. Card processors <highlight><bold>478</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>d </italic></highlight>then manage the DSP banks, network interfaces and media streams, such as audio streams. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> In one embodiment, the DSPs <highlight><bold>480</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>d </italic></highlight>provide the resources <highlight><bold>210</bold></highlight> and services <highlight><bold>212</bold></highlight> of platform <highlight><bold>200</bold></highlight>. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> In one embodiment, call control and audio feature manager <highlight><bold>302</bold></highlight> of the present invention exercises control over the EPIF of the present invention through the use of applets. In such an embodiment, the commands for configuring parameters (such as port MAC address, port IP address, and the like), search table management, statistics uploading, and the like, are indirectly issued through applets. </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> The EPIF provides a search engine to handle the functionality related to creating, deleting and searching entries. Since the platform <highlight><bold>200</bold></highlight> operates on the source and destination of packets, the EPIF provides search functionality of sources and destinations. The sources and destinations of packets are stored in search tables for incoming (ingress) and outgoing (egress) addresses. The EPIF can also manage RTP header information and evaluating relative priorities of egress audio streams to be transmitted as described in further detail below. </paragraph>
<paragraph id="P-0130" lvl="7"><number>&lsqb;0130&rsqb;</number> VII. Audio Processing Platform Operation </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> The operation of audio processing platform <highlight><bold>230</bold></highlight> is illustrated in the flow diagrams of <cross-reference target="DRAWINGS">FIGS. 5A and 5B</cross-reference>. <cross-reference target="DRAWINGS">FIG. 5A</cross-reference> is a flow diagram showing the establishment of a call and ingress packet processing according to an embodiment of the present invention. <cross-reference target="DRAWINGS">FIG. 5B</cross-reference> is a flow diagram showing egress packet processing and call completion according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> A. Ingress Audio Streams </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 5</cross-reference>A, the process for an ingress (also called inbound) audio stream starts at step <highlight><bold>502</bold></highlight> and immediately proceeds to step <highlight><bold>504</bold></highlight>. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> In step <highlight><bold>504</bold></highlight>, call control and audio feature manager <highlight><bold>302</bold></highlight> establishes a call with a client communicating via the network connections <highlight><bold>305</bold></highlight>. In one embodiment, call control and audio feature manager <highlight><bold>302</bold></highlight> negotiates and authorizes access to the client. Once client access is authorized, call control and audio feature manager <highlight><bold>302</bold></highlight> provides IP and UDP address information for the call to the client. Once the call is established, the process immediately proceeds to step <highlight><bold>506</bold></highlight>. </paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> In step <highlight><bold>506</bold></highlight>, packet processors <highlight><bold>307</bold></highlight> receive IP packets carrying audio via the network connections <highlight><bold>305</bold></highlight>. Any type of packet can be used including but not limited to IP packets, such as Appletalk, IPX, or other type of Ethernet packets. Once a packet is received, the process proceeds to step <highlight><bold>508</bold></highlight>. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> In step <highlight><bold>508</bold></highlight>, packet processors <highlight><bold>307</bold></highlight> check IP and UDP header address in search table to find associated SVC, and then convert the VOIP packets into internal packets. Such internal packets for example can be made up of a payload and control header as described further below with respect to <cross-reference target="DRAWINGS">FIG. 7B</cross-reference>. Packet processors <highlight><bold>307</bold></highlight> then construct packets using at least some of the data and routing information and assign a switched virtual circuit (SVC). The SVC is associated with one of the audio channel processors <highlight><bold>308</bold></highlight>, and in particular with one of respective DSP that will process the audio payload. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> When a cell layer is used, internal packets are further converted or merged into cells, such as ATM cells. In this way, audio payloads in the internal packets are converted to audio payloads in a stream of one or more ATM cells. A conventional segmentation and reassembly (SAR) module can be used to convert internal packets to ATM cells. Once the packets are converted into the cells, the process proceeds to step <highlight><bold>510</bold></highlight>. </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> In step <highlight><bold>510</bold></highlight>, cell switch <highlight><bold>304</bold></highlight> switches the cells to the proper audio channel of the audio channel processors <highlight><bold>308</bold></highlight> based on the SVC. The process proceeds to step <highlight><bold>512</bold></highlight>. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> In step <highlight><bold>512</bold></highlight>, audio channel processors <highlight><bold>308</bold></highlight> convert the cells into packets. Audio payloads in the arriving ATM cells for each channel are converted to audio payloads in a stream of one or more packets. A conventional SAR module can be used to convert ATM to packets. Packets can be internal egress packets or IP packets with audio payloads. Once the cells are converted into the internal packets, the process proceeds to step <highlight><bold>514</bold></highlight>. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> In step <highlight><bold>514</bold></highlight>, audio channel processors <highlight><bold>308</bold></highlight> process the audio data of the packets in the respective audio channels. In one embodiment, the audio channels are related to one or more of the media services <highlight><bold>213</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>e</italic></highlight>. For example, these media services can be telebrowsing, voice mail, conference bridging (also called conference calling), video streaming, VOIP gateway services, telephony, or any other media service for audio content. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> B. Egress Audio Streams </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 5</cross-reference>B, the process for an egress (also called outbound) audio stream starts at step <highlight><bold>522</bold></highlight> and immediately proceeds to step <highlight><bold>524</bold></highlight>. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> In step <highlight><bold>524</bold></highlight>, call control and audio feature manager <highlight><bold>302</bold></highlight> identifies an audio source for noiseless switch over. This audio source can be associated with an established call or other media service. Once the audio source is identified, the process immediately proceeds to step <highlight><bold>526</bold></highlight>. </paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> In step <highlight><bold>526</bold></highlight>, an audio source creates packets. In one embodiment, a DSP in audio channel processor <highlight><bold>308</bold></highlight> is an audio source. Audio data can be stored in a SDRAM associated with the DSP. This audio data is then packetized by a DSP into packets. Any type of packet can be used including but not limited to internal packets or IP packets, such as Ethernet packets. In one preferred embodiment, the packets are internal egress packets generated as described with respect to <cross-reference target="DRAWINGS">FIG. 7B</cross-reference>. </paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> In step <highlight><bold>528</bold></highlight>, an audio channel processor <highlight><bold>308</bold></highlight> converts the packets into cells, such as ATM cells. Audio payloads in the packets are converted to audio payloads in a stream of one or more ATM cells. In brief, the packets are parsed and the data and routing information analyzed. Audio channel processor <highlight><bold>308</bold></highlight> then construct cells using at least some of the data and routing information and assigns a switched virtual circuit (SVC). A conventional SAR module can be used to convert packets to ATM cells. The SVC is associated with one of the audio channel processors <highlight><bold>308</bold></highlight>, and in particular with a circuit connecting the respective DSP of the audio source and a destination port <highlight><bold>305</bold></highlight> of NIC <highlight><bold>306</bold></highlight>. Once the packets are converted into the cells, the process proceeds to step <highlight><bold>530</bold></highlight>. </paragraph>
<paragraph id="P-0146" lvl="0"><number>&lsqb;0146&rsqb;</number> In step <highlight><bold>530</bold></highlight>, cell switch <highlight><bold>304</bold></highlight> switches the cells of an audio channel of the audio channel processors <highlight><bold>308</bold></highlight> to a destination network connection <highlight><bold>305</bold></highlight> based on the SVC. The process proceeds to step <highlight><bold>532</bold></highlight>. </paragraph>
<paragraph id="P-0147" lvl="0"><number>&lsqb;0147&rsqb;</number> In step <highlight><bold>532</bold></highlight>, packet processors <highlight><bold>307</bold></highlight> convert the cells into IP packets. Audio payloads in the arriving ATM cells for each channel are converted to audio payloads in a stream of one or more internal packets. A conventional SAR module can be used to convert ATM to internal packets. Any type of packet can be used including but not limited to IP packets, such as Ethernet packets. Once the cells are converted into the packets, the process proceeds to step <highlight><bold>534</bold></highlight>. </paragraph>
<paragraph id="P-0148" lvl="0"><number>&lsqb;0148&rsqb;</number> In step <highlight><bold>534</bold></highlight>, each packet processor <highlight><bold>307</bold></highlight> further adds RTP, IP, and UDP header information. A search table is checked to find IP and UDP header address information associated with the SVC. IP packets are then sent carrying audio via the network connections <highlight><bold>305</bold></highlight> over a network to a destination device (phone, computer, palm device, PDA, etc.). Packet processors <highlight><bold>307</bold></highlight> process the audio data of the packets in the respective audio channels. In one embodiment, the audio channels are related to one or more of the media services <highlight><bold>213</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>e</italic></highlight>. For example, these media services can be telebrowsing, voice mail, conference bridging (also called conference calling), video streaming, VOIP gateway services, telephony, or any other media service for audio content. </paragraph>
<paragraph id="P-0149" lvl="7"><number>&lsqb;0149&rsqb;</number> IX. Noiseless Switching of Egress Audio Streams </paragraph>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> According to the one aspect of the present invention, audio processing platform <highlight><bold>230</bold></highlight> noiselessly switches between independent egress audio streams. Audio processing platform <highlight><bold>230</bold></highlight> is illustrative. The present invention as it relates to noiseless switching of egress audio stream can be used in any media server, router, switch, or audio processor and is not intended to be limited to audio processing platform <highlight><bold>230</bold></highlight>. </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> A. Cell Switch&mdash;Internal Audio Sources </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6A</cross-reference> is diagram of a noiseless switch over system that carries out cell switching of independent egress audio streams generated by internal audio sources according to an embodiment of the present invention. <cross-reference target="DRAWINGS">FIG. 6A</cross-reference> shows an embodiment of a system <highlight><bold>600</bold></highlight>A for egress audio stream switching from internal audio sources. System <highlight><bold>600</bold></highlight>A includes components of audio processing platform <highlight><bold>230</bold></highlight> configured for an egress audio stream switching mode of operation. In particular, as shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>A, system <highlight><bold>600</bold></highlight>A includes call control and audio feature controller <highlight><bold>302</bold></highlight> coupled to a number n of internal audio sources <highlight><bold>604</bold></highlight><highlight><italic>n</italic></highlight>, cell switch <highlight><bold>304</bold></highlight>, and network interface controller <highlight><bold>306</bold></highlight>. Internal audio sources <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>604</bold></highlight><highlight><italic>n </italic></highlight>can be two or more audio sources. Any type of audio source can be used including but not limited to DSPs. In one example, DSPs <highlight><bold>480</bold></highlight> can be audio sources. To generate audio, audio sources <highlight><bold>604</bold></highlight> can either create audio internally and/or convert audio received from external sources. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> Call control and audio feature controller <highlight><bold>302</bold></highlight> further includes an egress audio controller <highlight><bold>610</bold></highlight>. Egress audio controller <highlight><bold>610</bold></highlight> is control logic that issues control signals to audio sources <highlight><bold>604</bold></highlight><highlight><italic>n</italic></highlight>, cell switch <highlight><bold>304</bold></highlight>, and/or network interface controller <highlight><bold>306</bold></highlight> to carry out noiseless switching between independent egress audio streams according to the present invention. The control logic can implemented in software, firmware, microcode, hardware or any combination thereof. </paragraph>
<paragraph id="P-0154" lvl="0"><number>&lsqb;0154&rsqb;</number> A cell layer including SARs <highlight><bold>630</bold></highlight>, <highlight><bold>632</bold></highlight>, <highlight><bold>634</bold></highlight> is also provided. SARs <highlight><bold>630</bold></highlight>, <highlight><bold>632</bold></highlight> are coupled between cell switch <highlight><bold>304</bold></highlight> and each audio source <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>n</italic></highlight>. SAR <highlight><bold>634</bold></highlight> is coupled between cell switch <highlight><bold>304</bold></highlight> and NIC <highlight><bold>306</bold></highlight>. </paragraph>
<paragraph id="P-0155" lvl="0"><number>&lsqb;0155&rsqb;</number> In one embodiment, independent egress audio streams involve streams of IP packets with RTP information and internal egress packets. Accordingly, it is helpful to first describe IP packets and internal egress packets (FIGS. <highlight><bold>7</bold></highlight>A-<highlight><bold>7</bold></highlight>B). Next, system <highlight><bold>600</bold></highlight>A and its operation is described in detail with respect to independent egress audio streams (FIGS. <highlight><bold>8</bold></highlight>-<highlight><bold>9</bold></highlight>). </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> B. Packets </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> In one embodiment, the present invention uses two types of packets: (1) IP packets with RTP information and (2) internal egress packets. Both of these types of packets are shown and described with respect to examples in <cross-reference target="DRAWINGS">FIGS. 7A and 7B</cross-reference>. IP packets <highlight><bold>700</bold></highlight>A are sent and received over a external packet-switched network by packet processors <highlight><bold>307</bold></highlight> in NIC <highlight><bold>306</bold></highlight>. Internal egress packets <highlight><bold>700</bold></highlight>B are generated by audio sources (e.g. DSPs) <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>604</bold></highlight><highlight><italic>n. </italic></highlight></paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> 1. IP Packets with RTP Information </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> A standard Internet Protocol (IP) packet <highlight><bold>700</bold></highlight>A is shown in <cross-reference target="DRAWINGS">FIG. 7A</cross-reference>. IP packet <highlight><bold>700</bold></highlight>A is shown with various components: media access control (MAC) field <highlight><bold>704</bold></highlight>, IP field <highlight><bold>706</bold></highlight>, user datagram protocol (UDP) field <highlight><bold>708</bold></highlight>, RTP field <highlight><bold>710</bold></highlight>, payload <highlight><bold>712</bold></highlight> containing digital data, and cyclic redundancy check (CRC) field <highlight><bold>714</bold></highlight>. Real-Time Transport Protocol (RTP) is a standardized protocol for carrying periodic data, such as digitized audio, from a source device to a destination device. A companion protocol, Real-Time Control Protocol (RTCP), can also be used with RTP to provide information on the quality of a session. </paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> More specifically, the MAC <highlight><bold>704</bold></highlight> and IP <highlight><bold>706</bold></highlight> fields contain addressing information to allow each packet to traverse an IP network interconnecting two devices (origin and destination). UDP field <highlight><bold>708</bold></highlight> contains a 2-byte port number that identifies a RTP/audio stream channel number so that it can be internally routed to the audio processor destination when received from the network interface. In one embodiment of the present invention, the audio processor is a DSP, as described herein. </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> RTP field <highlight><bold>710</bold></highlight> contains a packet sequence number and timestamp. Payload <highlight><bold>712</bold></highlight> contains the digitized audio byte samples and can be decoded by the endpoint audio processors. Any payload type and encoding scheme for audio and/or video types of media compatible with RTP can be used as would be apparent to a person skilled in the art given this description. CRC field <highlight><bold>714</bold></highlight> provides a way to verify the integrity of the entire packet. See, the description of RTP packets and payload types described by D. Collins, <highlight><italic>Carrier Grade Voice over IP, </italic></highlight>pp. 52-72 (the text of the entire book of which is incorporated herein by reference). </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> 2. Internal Egress Packets </paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7B</cross-reference> illustrates an example internal egress packet of the present invention in greater detail. Packet <highlight><bold>700</bold></highlight>B includes a control (CTRL) header <highlight><bold>720</bold></highlight> and a payload <highlight><bold>722</bold></highlight>. The advantage of internal egress packet <highlight><bold>700</bold></highlight>B is it is simpler to create and smaller in size than IP packet <highlight><bold>700</bold></highlight>A. This reduces the burden and work required of audio sources and other components handling the internal egress packets. </paragraph>
<paragraph id="P-0164" lvl="0"><number>&lsqb;0164&rsqb;</number> In one embodiment, audio sources <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>604</bold></highlight><highlight><italic>n </italic></highlight>are DSPs. Each DSP adds a CTRL header <highlight><bold>720</bold></highlight> in front of a payload <highlight><bold>722</bold></highlight> that it creates in for a respective audio stream. CTRL <highlight><bold>720</bold></highlight> is then used to relay control information downstream. This control information for example can be priority information associated with a particular egress audio stream. </paragraph>
<paragraph id="P-0165" lvl="0"><number>&lsqb;0165&rsqb;</number> Packet <highlight><bold>700</bold></highlight>B is converted to one or more cells, such as ATM cells, and sent internally over cell switch <highlight><bold>304</bold></highlight> to a packet processor <highlight><bold>307</bold></highlight> in network interface controller <highlight><bold>306</bold></highlight>. After the cells are converted to internal egress packets, packet processor <highlight><bold>307</bold></highlight> decodes and removes internal header CTRL <highlight><bold>720</bold></highlight>. The rest of the IP packet information is added before the payload <highlight><bold>722</bold></highlight> is transmitted as an IP packet <highlight><bold>700</bold></highlight>A onto an IP network. This achieves an advantage as processing work at the DSPs is reduced. DSPs only have to add a relatively short control header to payloads. The remaining processing work of adding information to create valid IP packets with RTP header information can be distributed to packet processor(s) <highlight><bold>307</bold></highlight>. </paragraph>
<paragraph id="P-0166" lvl="0"><number>&lsqb;0166&rsqb;</number> C. Priority Levels </paragraph>
<paragraph id="P-0167" lvl="0"><number>&lsqb;0167&rsqb;</number> Network interface controller (NIC) <highlight><bold>306</bold></highlight> processes all internal egress packets, as well as all egress IP packets destined for the external network. Thus, NIC <highlight><bold>306</bold></highlight> can make final forwarding decisions about each packet sent to it based on the content of each packet. In some embodiments, NIC <highlight><bold>306</bold></highlight> manages the forwarding of egress IP packets based on priority information. This can include switching over to an audio stream of egress IP packets with a higher priority and buffering or not forwarding another audio stream of egress IP packets with a lower priority. </paragraph>
<paragraph id="P-0168" lvl="0"><number>&lsqb;0168&rsqb;</number> In one embodiment, internal audio sources <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>604</bold></highlight><highlight><italic>n </italic></highlight>determine priority levels. Alternatively, NIC <highlight><bold>306</bold></highlight> can determine a priority for audio received from an external source at NIC <highlight><bold>306</bold></highlight>. Any number of priority levels can be used. The priority levels distinguish the relative priority of audio sources and their respective audio streams. Priority levels can be based on any criteria selected by a user including, but not limited to, time of day, identity or group of the caller or callee, or other similar factors relevant to audio processing and media services. Components of the system <highlight><bold>600</bold></highlight> filter and forward the priority level information within the audio stream. In one embodiment, a resource manager in system <highlight><bold>600</bold></highlight> can interact with external systems to alter the priority levels of audio streams. For example, an external system can be an operator informing the system to queue a billing notice or advertisement on a call. Thus, the resource manager is capable of barging into audio streams. This noiseless switch over can be triggered by user or automatically based on certain predefined events such as signaling conditions like on-hold condition, emergency event, or timed event. </paragraph>
<paragraph id="P-0169" lvl="0"><number>&lsqb;0169&rsqb;</number> D. Noiseless Fully Meshed Cell Switch </paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> System <highlight><bold>600</bold></highlight>A can be thought of as a &ldquo;free pool&rdquo; of multiple input (ingress) and output (egress) audio channels because a fully meshed packet/cell switch <highlight><bold>304</bold></highlight> is used to switch egress audio channels to participate in any given call. Any egress audio channel can be called upon to participate in a telephone call at any time. During both the initial call setup and while the call is in session, any egress audio channel can be switched into and out of the call. The fully meshed switching capability of system <highlight><bold>600</bold></highlight>A of the present invention provides a precise noiseless switching functionality which does not drop or corrupt the IP packets or the cells of the present invention. In addition, a two-stage egress switching technique is used. </paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> E. Two-Stage Egress Switching </paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> System <highlight><bold>600</bold></highlight>A includes at least two stages of switching. In terms of egress switching, the first stage is cell switch <highlight><bold>304</bold></highlight>. The first stage is cell-based and uses switched virtual circuits (SVCs) to switch audio streams from separate physical sources (audio sources <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>604</bold></highlight><highlight><italic>n</italic></highlight>) to a single destination egress network interface controller (NIC <highlight><bold>306</bold></highlight>). Priority information is provided in the CTRL header <highlight><bold>720</bold></highlight> of cells generated by the audio sources. The second stage is contained within the egress NIC <highlight><bold>306</bold></highlight> such that it selects which of the audio streams from multiple audio sources (<highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>604</bold></highlight><highlight><italic>n</italic></highlight>) to process and send over a packet network such as an packet-switched IP network. This selection of which audio streams to forward can be performed by NIC <highlight><bold>306</bold></highlight> is based on the priority information provided in the CTRL headers <highlight><bold>720</bold></highlight>. In this way, a second audio stream with a higher priority can be forwarded by NIC <highlight><bold>306</bold></highlight> on the same channel as a first audio stream. From the perspective of the destination device receiving the audio streams, the insertion of the second audio stream on the channel is received as a noiseless switch between independent audio streams. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> More specifically, in one embodiment, the egress audio switching can occur in a telephone call. A call is first established using audio source <highlight><bold>604</bold></highlight><highlight><italic>a </italic></highlight>by negotiating with the destination device&apos;s MAC, IP, and UDP information, as previously described. First audio source <highlight><bold>604</bold></highlight><highlight><italic>a </italic></highlight>begins generating a first audio stream during the call. The first audio stream is made up of internal egress packets having audio payload and CTRL header <highlight><bold>720</bold></highlight> information as described with respect to packet format <highlight><bold>700</bold></highlight>B. Internal egress packets egress on the channel established for the call. Any type of audio payload including voice, music, tones, or other audio data can be used. SAR <highlight><bold>630</bold></highlight> converts the internal packets to cells for transport through cell switch <highlight><bold>304</bold></highlight> to SAR <highlight><bold>634</bold></highlight>. SAR <highlight><bold>634</bold></highlight> then converts cells back to internal egress packets prior to delivery to NIC <highlight><bold>306</bold></highlight>. </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> During the flow from the audio source <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>, NIC <highlight><bold>306</bold></highlight> is decoding and removing the CTRL header <highlight><bold>720</bold></highlight> and adding the appropriate RTP, UDP, IP, MAC, and CRC fields, as previously described. CTRL header <highlight><bold>720</bold></highlight> includes the priority field used by NIC <highlight><bold>306</bold></highlight> to process the packet and send a corresponding RTP packet. NIC <highlight><bold>306</bold></highlight> evaluates the priority field. Given the relatively high priority field (the first audio source <highlight><bold>604</bold></highlight><highlight><italic>a </italic></highlight>is the only transmitting source), NIC <highlight><bold>306</bold></highlight> forwards IP packets with synchronized RTP header information which carry the first audio stream over the network to the destination device associated with the call. (Note CTRL header <highlight><bold>720</bold></highlight> can also include RTP or other synchronized header information which can be used or ignored by NIC <highlight><bold>306</bold></highlight> if NIC <highlight><bold>306</bold></highlight> generates and adds RTP header information). </paragraph>
<paragraph id="P-0175" lvl="0"><number>&lsqb;0175&rsqb;</number> When the egress audio controller <highlight><bold>610</bold></highlight> determines a call event where a noiseless switch over is to occur, a second audio source <highlight><bold>604</bold></highlight><highlight><italic>n </italic></highlight>begins generating a second audio stream. Audio can be generated by audio source <highlight><bold>604</bold></highlight><highlight><italic>n </italic></highlight>directly or by converting audio originally generated by external devices. The second audio stream is made up of internal egress packets having audio payload and CTRL header <highlight><bold>720</bold></highlight> information as described with respect to packet format <highlight><bold>700</bold></highlight>B. Any type of audio payload including voice, music, or other audio data can be used. Assume the second audio stream is given a higher priority field than the first audio stream. For example, the second audio stream can represent an advertisement, emergency public service message, or other audio data that is desired to have noiselessly inserted into the first channel established with the destination device. </paragraph>
<paragraph id="P-0176" lvl="0"><number>&lsqb;0176&rsqb;</number> The second audio stream&apos;s internal egress packets are then converted to cells by SAR <highlight><bold>632</bold></highlight>. Cell switch <highlight><bold>304</bold></highlight> switches the cells to an SVC destined for the same destination NIC <highlight><bold>306</bold></highlight> as the first audio stream. SAR <highlight><bold>634</bold></highlight> converts the cells back to internal packets. NIC <highlight><bold>306</bold></highlight> now receives the internal packets for the first and second audio streams. NIC <highlight><bold>306</bold></highlight> evaluates the priority field in each stream. </paragraph>
<paragraph id="P-0177" lvl="0"><number>&lsqb;0177&rsqb;</number> The second audio stream having internal packets with the higher priority are converted to IP packets with synchronized RTP header information and forwarded to the destination device. The first audio stream having internal packets with the lower priority are either stored in a buffer or converted to IP packets with synchronized RTP header information and stored in buffer. NIC <highlight><bold>306</bold></highlight> can resume forwarding the first audio stream when the second audio stream is completed, after a predetermined time elapses, or when a manual or automatic control signal is received to resume. </paragraph>
<paragraph id="P-0178" lvl="0"><number>&lsqb;0178&rsqb;</number> F. Call Event Triggering Noiseless Switch Over </paragraph>
<paragraph id="P-0179" lvl="0"><number>&lsqb;0179&rsqb;</number> The functionality of the priority field in an embodiment of noiseless switching according to the present invention is now described with regard to <cross-reference target="DRAWINGS">FIGS. 8, 9A</cross-reference> and <highlight><bold>9</bold></highlight>B. </paragraph>
<paragraph id="P-0180" lvl="0"><number>&lsqb;0180&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 8, a</cross-reference> flow diagram of a noiseless switching routine <highlight><bold>800</bold></highlight> according to one embodiment of the present invention is shown. For brevity, the noiseless switching routine <highlight><bold>800</bold></highlight> is described with respect system <highlight><bold>600</bold></highlight>. </paragraph>
<paragraph id="P-0181" lvl="0"><number>&lsqb;0181&rsqb;</number> Flow <highlight><bold>800</bold></highlight> begins at step <highlight><bold>802</bold></highlight> and proceeds immediately to step <highlight><bold>804</bold></highlight>. </paragraph>
<paragraph id="P-0182" lvl="0"><number>&lsqb;0182&rsqb;</number> In step <highlight><bold>804</bold></highlight>, call control and audio feature manager <highlight><bold>302</bold></highlight> establishes a call from a first audio source <highlight><bold>604</bold></highlight><highlight><italic>a </italic></highlight>to a destination device. Call control and audio feature manager <highlight><bold>302</bold></highlight> negotiates with the destination device to determine the MAC, IP and UDP port to use in a first audio stream of IP packets sent over a network. </paragraph>
<paragraph id="P-0183" lvl="0"><number>&lsqb;0183&rsqb;</number> Audio source <highlight><bold>604</bold></highlight><highlight><italic>a </italic></highlight>delivers a first audio stream on one channel for the established call. In one embodiment, a DSP delivers the first audio stream of internal egress packets on one channel to cell switch <highlight><bold>304</bold></highlight> and then to NIC <highlight><bold>306</bold></highlight>. The process proceeds to step <highlight><bold>806</bold></highlight>. </paragraph>
<paragraph id="P-0184" lvl="0"><number>&lsqb;0184&rsqb;</number> In step <highlight><bold>806</bold></highlight>, egress audio controller <highlight><bold>610</bold></highlight> sets a priority field for the first audio source. In one embodiment, egress audio controller <highlight><bold>610</bold></highlight> sets the priority field to a value of one. In another embodiment, the priority field is stored in the CTRL header of the internally routed internal egress packets. The process immediately proceeds to step <highlight><bold>808</bold></highlight>. </paragraph>
<paragraph id="P-0185" lvl="0"><number>&lsqb;0185&rsqb;</number> In step <highlight><bold>808</bold></highlight>, egress audio controller <highlight><bold>610</bold></highlight> determines the call&apos;s status. In one embodiment, egress audio controller <highlight><bold>610</bold></highlight> determines whether or not the call allows or has been configured to allow call events to interact with it. In one embodiment of the present invention, a call can be configured so that only emergency call events will interrupt it. In another embodiment, a call can be configured to receive certain call events based on either the caller(s) or callee(s) (i.e., the one or more of the parties on the call). The process immediately proceeds to step <highlight><bold>810</bold></highlight>. </paragraph>
<paragraph id="P-0186" lvl="0"><number>&lsqb;0186&rsqb;</number> In step <highlight><bold>810</bold></highlight>, egress audio controller <highlight><bold>610</bold></highlight> monitors for call events. In one embodiment, a call event can be generated within the system <highlight><bold>600</bold></highlight>, such as notifications of time, weather, advertisements, billing (&ldquo;please insert another coin&rdquo; or &ldquo;you have 5 minutes remaining&rdquo;). In another embodiment, call events can be sent to the system <highlight><bold>600</bold></highlight>, such as requests for news, sporting information, etc. Egress audio controller <highlight><bold>610</bold></highlight> can monitor both internally and externally for call events. The process proceeds immediately to step <highlight><bold>812</bold></highlight>. </paragraph>
<paragraph id="P-0187" lvl="0"><number>&lsqb;0187&rsqb;</number> In step <highlight><bold>812</bold></highlight>, egress audio controller <highlight><bold>610</bold></highlight> receives a call event. If not, then egress audio controller <highlight><bold>610</bold></highlight> continues to monitor as stated in step <highlight><bold>810</bold></highlight>. If so, then the process proceeds immediately to step <highlight><bold>814</bold></highlight>. </paragraph>
<paragraph id="P-0188" lvl="0"><number>&lsqb;0188&rsqb;</number> In step <highlight><bold>814</bold></highlight>, egress audio controller <highlight><bold>610</bold></highlight> determines the call event and performs the operations necessitated by the call event. The process then proceeds to step <highlight><bold>816</bold></highlight> where it either ends or returns to step <highlight><bold>802</bold></highlight>. In one embodiment, the process <highlight><bold>800</bold></highlight> repeats for as long as the call continues. </paragraph>
<paragraph id="P-0189" lvl="0"><number>&lsqb;0189&rsqb;</number> In FIGS. <highlight><bold>9</bold></highlight>A-<highlight><bold>9</bold></highlight>C, flow diagram <highlight><bold>900</bold></highlight> of the call event processing for audio stream switching based on priority according to one embodiment of the present invention are shown. In one embodiment, flow <highlight><bold>900</bold></highlight> shows in more detail the operations performed in step <highlight><bold>814</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. </paragraph>
<paragraph id="P-0190" lvl="0"><number>&lsqb;0190&rsqb;</number> Process <highlight><bold>900</bold></highlight> starts at step <highlight><bold>902</bold></highlight> and proceeds immediately to step <highlight><bold>904</bold></highlight>. </paragraph>
<paragraph id="P-0191" lvl="0"><number>&lsqb;0191&rsqb;</number> In step <highlight><bold>904</bold></highlight>, egress audio controller <highlight><bold>610</bold></highlight> reads a call event for an established call. In this operation, a first audio stream from source <highlight><bold>604</bold></highlight><highlight><italic>a </italic></highlight>is already being sent from NIC <highlight><bold>306</bold></highlight> to a destination device as part of the established call. The process proceeds to step <highlight><bold>906</bold></highlight>. </paragraph>
<paragraph id="P-0192" lvl="0"><number>&lsqb;0192&rsqb;</number> In step <highlight><bold>906</bold></highlight>, egress audio controller <highlight><bold>610</bold></highlight> determines whether the call event includes a second audio source. If so, then the process proceeds to step <highlight><bold>908</bold></highlight>. If not, then the process proceeds to step <highlight><bold>930</bold></highlight>. </paragraph>
<paragraph id="P-0193" lvl="0"><number>&lsqb;0193&rsqb;</number> In step <highlight><bold>908</bold></highlight>, egress audio controller <highlight><bold>610</bold></highlight> determines the priority of the second audio source. In one embodiment, egress audio controller <highlight><bold>610</bold></highlight> issues a command to second audio source <highlight><bold>604</bold></highlight><highlight><italic>n </italic></highlight>that instructs the second audio source to generate a second audio stream of internal egress packets. Priority information for the second audio stream can be automatically generated by the second audio source <highlight><bold>604</bold></highlight><highlight><italic>n </italic></highlight>or generated based on a command from the egress audio controller <highlight><bold>610</bold></highlight>. The process then proceeds to step <highlight><bold>910</bold></highlight>. </paragraph>
<paragraph id="P-0194" lvl="0"><number>&lsqb;0194&rsqb;</number> In step <highlight><bold>910</bold></highlight>, a second audio source <highlight><bold>604</bold></highlight><highlight><italic>n </italic></highlight>begins generating a second audio stream. The second audio stream is made up of internal egress packets having audio payload and CTRL header <highlight><bold>720</bold></highlight> information as described with respect to packet format <highlight><bold>700</bold></highlight>B. Any type of audio payload including voice, music, or other audio data can be used. Audio payload is meant broadly to also include audio data included as part of video data. The process then proceeds to step <highlight><bold>912</bold></highlight>. </paragraph>
<paragraph id="P-0195" lvl="0"><number>&lsqb;0195&rsqb;</number> In step <highlight><bold>912</bold></highlight>, the second audio stream&apos;s egress packets are then converted to cells. In one example, the cells are ATM cells. The process then proceeds to step <highlight><bold>914</bold></highlight>. </paragraph>
<paragraph id="P-0196" lvl="0"><number>&lsqb;0196&rsqb;</number> In step <highlight><bold>914</bold></highlight>, cell switch <highlight><bold>304</bold></highlight> switches the cells to an SVC destined for the same destination NIC <highlight><bold>306</bold></highlight> on the same egress channel as the first audio stream. The process then proceeds to step <highlight><bold>915</bold></highlight>. </paragraph>
<paragraph id="P-0197" lvl="0"><number>&lsqb;0197&rsqb;</number> As shown in step <highlight><bold>915</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 9</cross-reference>B, SAR <highlight><bold>634</bold></highlight> now receives cells for the first and second audio streams. The cells are converted back to streams of internal egress packets and have control headers that include the respective priority information for the two audio streams. </paragraph>
<paragraph id="P-0198" lvl="0"><number>&lsqb;0198&rsqb;</number> In step <highlight><bold>916</bold></highlight>, NIC <highlight><bold>306</bold></highlight> compares the priorities of the two audio streams. If the second audio stream has a higher priority then the process proceeds to step <highlight><bold>918</bold></highlight>. If not, then the process proceeds to step <highlight><bold>930</bold></highlight>. </paragraph>
<paragraph id="P-0199" lvl="0"><number>&lsqb;0199&rsqb;</number> In step <highlight><bold>918</bold></highlight>, the transmission of the first audio stream is held. For example, NIC <highlight><bold>306</bold></highlight> buffers the first audio stream or even issues a control command to audio source <highlight><bold>604</bold></highlight><highlight><italic>a </italic></highlight>to hold the transmission of the first audio source. The process proceeds immediately to step <highlight><bold>920</bold></highlight>. </paragraph>
<paragraph id="P-0200" lvl="0"><number>&lsqb;0200&rsqb;</number> In step <highlight><bold>920</bold></highlight>, the transmission of the second audio stream starts. NIC <highlight><bold>306</bold></highlight> instructs packet processor(s) <highlight><bold>307</bold></highlight> to create IP packets having the audio payload of the internal egress packets of the second audio stream. Packet processor(s) <highlight><bold>307</bold></highlight> add additional synchronized RTP header information (RTP packet information) and other header information (MAC, IP, UDP fields) to the audio payload of the internal egress packets of the second audio stream. </paragraph>
<paragraph id="P-0201" lvl="0"><number>&lsqb;0201&rsqb;</number> NIC <highlight><bold>306</bold></highlight> then sends the IP packets with synchronized RTP header information on the same egress channel of the first audio stream. In this way, a destination device receives the second audio stream noise instead of the first audio stream. Moreover, from the perspective of the destination device this second audio stream is received in real-time noiselessly without delay or interruption. Steps <highlight><bold>918</bold></highlight> and <highlight><bold>920</bold></highlight> of course can be performed at the same time or in any order. The process proceeds immediately to step <highlight><bold>922</bold></highlight>. </paragraph>
<paragraph id="P-0202" lvl="0"><number>&lsqb;0202&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>C, NIC <highlight><bold>306</bold></highlight> monitors for the end of the second audio stream (step <highlight><bold>922</bold></highlight>). The process proceeds immediately to step <highlight><bold>924</bold></highlight>. </paragraph>
<paragraph id="P-0203" lvl="0"><number>&lsqb;0203&rsqb;</number> In step <highlight><bold>924</bold></highlight>, NIC <highlight><bold>306</bold></highlight> determines whether the second audio stream has ended. In one example, NIC <highlight><bold>306</bold></highlight> reads a last packet of the second audio stream which has a priority level lower than preceding packets. If so, then the process proceeds immediately to step <highlight><bold>930</bold></highlight>. If not, then the process proceeds to step <highlight><bold>922</bold></highlight>. </paragraph>
<paragraph id="P-0204" lvl="0"><number>&lsqb;0204&rsqb;</number> In step <highlight><bold>930</bold></highlight>, NIC <highlight><bold>306</bold></highlight> either continues to forward the first audio stream (after step <highlight><bold>906</bold></highlight>) or returns to forwarding the first audio stream (after steps <highlight><bold>916</bold></highlight> or <highlight><bold>924</bold></highlight>). The process proceeds to step <highlight><bold>932</bold></highlight>. </paragraph>
<paragraph id="P-0205" lvl="0"><number>&lsqb;0205&rsqb;</number> In one embodiment, NIC <highlight><bold>306</bold></highlight> maintains a priority level threshold value. NIC <highlight><bold>306</bold></highlight> then increments and sets the threshold based on priority information in the audio streams. When faced with multiple audio streams, NIC <highlight><bold>306</bold></highlight> forwards the audio stream having priority information equal to or greater than the priority level threshold value. For example, if the first audio stream had a priority value of 1 then the priority level threshold value is set to 1 and the first audio stream is transmitted (prior to step <highlight><bold>904</bold></highlight>). When a second audio stream with a higher priority is received at NIC <highlight><bold>306</bold></highlight>, then NIC <highlight><bold>306</bold></highlight> increments the priority threshold value to 2. The second audio stream is then transmitted as described above in step <highlight><bold>920</bold></highlight>. When the last packet of the second audio stream having a priority field value set to 0 (or null or other special value) is read, then the priority level threshold value is decremented back to 1 as part of step <highlight><bold>924</bold></highlight>. In this case, the first audio stream with priority information 1 is then be sent by NIC <highlight><bold>306</bold></highlight> as described above with respect to step <highlight><bold>930</bold></highlight>. </paragraph>
<paragraph id="P-0206" lvl="0"><number>&lsqb;0206&rsqb;</number> In step <highlight><bold>932</bold></highlight>, egress audio controller <highlight><bold>610</bold></highlight> processes any remaining call events. The process then proceeds to step <highlight><bold>934</bold></highlight> where it terminates until re-instantiated. In one embodiment, the steps of the above-described process occur substantially at the same time, such that the process can be run in parallel or in an overlapping manner on one or more processors in the system <highlight><bold>600</bold></highlight>. </paragraph>
<paragraph id="P-0207" lvl="0"><number>&lsqb;0207&rsqb;</number> G. Audio Data Flow </paragraph>
<paragraph id="P-0208" lvl="0"><number>&lsqb;0208&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is a diagram of audio data flow <highlight><bold>615</bold></highlight> in the noiseless switch over system of <cross-reference target="DRAWINGS">FIG. 6A</cross-reference> in one embodiment. In particular, <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> shows the flow of internal packets from audio sources <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>n </italic></highlight>to SARs <highlight><bold>630</bold></highlight>, <highlight><bold>632</bold></highlight>, the flow of cells through cell switch <highlight><bold>304</bold></highlight> to SAR <highlight><bold>634</bold></highlight>, the flow of internal packets between SAR <highlight><bold>634</bold></highlight> and packet processors <highlight><bold>307</bold></highlight>, and the flow of IP packets from NIC <highlight><bold>306</bold></highlight> over the network. </paragraph>
<paragraph id="P-0209" lvl="0"><number>&lsqb;0209&rsqb;</number> H. Other Embodiments </paragraph>
<paragraph id="P-0210" lvl="0"><number>&lsqb;0210&rsqb;</number> The present invention is not limited to internal audio sources or a cell layer. Noiseless switch over can also be carried out in different embodiments using internal audio sources only, internal and external audio sources, external audio sources only, a cell switch or a packet switch. For example, <cross-reference target="DRAWINGS">FIG. 6C</cross-reference> is diagram of a noiseless switch over system <highlight><bold>600</bold></highlight>C that carries out cell switching between independent egress audio streams generated by internal audio source <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>n </italic></highlight>and/or external audio sources (not shown) according to an embodiment of the present invention. Noiseless switch over system <highlight><bold>600</bold></highlight>C operates similar to system <highlight><bold>600</bold></highlight>A described in detail above except that noiseless switch over is made to audio received from an external audio source. The audio is received in IP packets and buffered at NIC <highlight><bold>306</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 6C</cross-reference>. NIC <highlight><bold>306</bold></highlight> strips IP information (stores it in forward table entry associated with external audio source and destination device) and generates internal packets assigned to a SVC. SAR <highlight><bold>634</bold></highlight> converts the internal packets to cells and routes cells on the SVC on link <highlight><bold>662</bold></highlight> through switch <highlight><bold>304</bold></highlight> back through link <highlight><bold>664</bold></highlight> to SAR <highlight><bold>634</bold></highlight> for conversion to internal packets. As described above, the internal packets are then processed by packet processor <highlight><bold>307</bold></highlight> to create IP packets with synchronized header information. NIC <highlight><bold>306</bold></highlight> then sends the IP packets to destination device. In this way, a user at the destination device is noiselessly switched over to receive audio from an external audio source. <cross-reference target="DRAWINGS">FIG. 6D</cross-reference> is diagram of audio data flow <highlight><bold>625</bold></highlight> for an egress audio stream received from the external audio source in the noiseless switch over system of <cross-reference target="DRAWINGS">FIG. 6C</cross-reference>. In particular, <cross-reference target="DRAWINGS">FIG. 6D</cross-reference> shows the flow of IP packets from an external audio source (not shown) to NIC <highlight><bold>306</bold></highlight>, the flow of internal packets from NIC <highlight><bold>306</bold></highlight> to SAR <highlight><bold>634</bold></highlight>, the flow of cells through cell switch <highlight><bold>304</bold></highlight> back to SAR <highlight><bold>634</bold></highlight>, the flow of internal packets between SAR <highlight><bold>634</bold></highlight> and packet processors <highlight><bold>307</bold></highlight>, and the flow of IP packets from NIC <highlight><bold>306</bold></highlight> over the network to a destination device (not shown). </paragraph>
<paragraph id="P-0211" lvl="0"><number>&lsqb;0211&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6E</cross-reference> is diagram of audio data flows <highlight><bold>635</bold></highlight>, <highlight><bold>645</bold></highlight> in a noiseless switch over system <highlight><bold>600</bold></highlight>E that carries out packet switching between independent egress audio streams generated by internal and/or external audio sources according to an embodiment of the present invention. Noiseless switch over system <highlight><bold>600</bold></highlight>E operates similar to systems <highlight><bold>600</bold></highlight>A and <highlight><bold>600</bold></highlight>C described in detail above except that a packet switch <highlight><bold>694</bold></highlight> is used instead of a cell switch <highlight><bold>304</bold></highlight>. In this embodiment, a cell layer including SARs <highlight><bold>630</bold></highlight>, <highlight><bold>632</bold></highlight>, <highlight><bold>634</bold></highlight> is omitted. In audio data flow <highlight><bold>635</bold></highlight>, internal packets flow through the packet switch <highlight><bold>694</bold></highlight> from internal audio sources <highlight><bold>604</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><italic>n </italic></highlight>to packet processors <highlight><bold>307</bold></highlight>. IP packets flow out to the network. In audio data flow <highlight><bold>645</bold></highlight>, IP packets from an external audio source (not shown) are received at NIC <highlight><bold>306</bold></highlight>. The audio is received in packets and buffered at NIC <highlight><bold>306</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 6E</cross-reference>. NIC <highlight><bold>306</bold></highlight> strips IP information (stores it in forward table entry associated with external audio source and destination device) and generates internal packets assigned to a SVC (or other type of path) associated with the destination device. The internal packets are routed on the SVC through packet switch <highlight><bold>694</bold></highlight> to NIC <highlight><bold>306</bold></highlight>. As described above, the internal packets are then processed by packet processor <highlight><bold>307</bold></highlight> to create IP packets with synchronized header information. NIC <highlight><bold>306</bold></highlight> then sends the IP packets to destination device. In this way, a user at the destination device is noiselessly switched over to receive audio from an external audio source. </paragraph>
<paragraph id="P-0212" lvl="0"><number>&lsqb;0212&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6F</cross-reference> is diagram of a noiseless switch over system <highlight><bold>600</bold></highlight>F that carries out switching between independent egress audio streams generated by only external audio sources according to an embodiment of the present invention. No switch or internal audio sources are required. NIC <highlight><bold>306</bold></highlight> strips IP information (stores it in forward table entry associated with external audio source and destination device) and generates internal packets assigned to a SVC (or other type of path) associated with the destination device. The internal packets are routed on the SVC to NIC <highlight><bold>306</bold></highlight>. (NIC <highlight><bold>306</bold></highlight> can be a common source and destination point). As described above, the internal packets are then processed by packet processor <highlight><bold>307</bold></highlight> to create IP packets with synchronized header information. NIC <highlight><bold>306</bold></highlight> then sends the IP packets to destination device. In this way, a user at the destination device is noiselessly switched over to receive audio from an external audio source. </paragraph>
<paragraph id="P-0213" lvl="0"><number>&lsqb;0213&rsqb;</number> Functionality described above with respect to the operation of egress audio switching system <highlight><bold>600</bold></highlight> can be implemented in control logic. Such control logic can be implemented in software, firmware, hardware or any combination thereof. </paragraph>
<paragraph id="P-0214" lvl="7"><number>&lsqb;0214&rsqb;</number> X. Conference Call Processing </paragraph>
<paragraph id="P-0215" lvl="0"><number>&lsqb;0215&rsqb;</number> A. Distributed Conference Bridge </paragraph>
<paragraph id="P-0216" lvl="0"><number>&lsqb;0216&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a diagram of a distributed conference bridge <highlight><bold>1000</bold></highlight> according to one embodiment of the present invention. Distributed conference bridge <highlight><bold>1000</bold></highlight> is coupled to a network <highlight><bold>1005</bold></highlight>. Network <highlight><bold>1005</bold></highlight> can be any type of network or combination of networks, such as, the Internet. For example, network <highlight><bold>1005</bold></highlight> can include a packet-switched network or a packeted-switched network in combination with a circuit-switched network. A number of conference call participants C<highlight><bold>1</bold></highlight>-CN can connect through network <highlight><bold>1005</bold></highlight> to distributed conference bridge <highlight><bold>1000</bold></highlight>. For example, conference call participants C<highlight><bold>1</bold></highlight>-CN can place a VOIP call through network <highlight><bold>1005</bold></highlight> to contact distributed conference bridge <highlight><bold>1000</bold></highlight>. Distributed conference bridge <highlight><bold>1000</bold></highlight> is scalable and can handle any number of conference call participants. For example, distributed conference bridge <highlight><bold>1000</bold></highlight> can handle conference calls between two conference call participants up to 1000 or more conference call participants. </paragraph>
<paragraph id="P-0217" lvl="0"><number>&lsqb;0217&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, distributed conference bridge <highlight><bold>1000</bold></highlight> includes a conference call agent <highlight><bold>1010</bold></highlight>, network interface controller (NIC) <highlight><bold>1020</bold></highlight>, switch <highlight><bold>1030</bold></highlight>, and audio source <highlight><bold>1040</bold></highlight>. Conference call agent <highlight><bold>1010</bold></highlight> is coupled to NIC <highlight><bold>1020</bold></highlight>, switch <highlight><bold>1030</bold></highlight> and audio source <highlight><bold>1040</bold></highlight>. NIC <highlight><bold>1020</bold></highlight> is coupled between network <highlight><bold>1005</bold></highlight> and switch <highlight><bold>1030</bold></highlight>. Switch <highlight><bold>1030</bold></highlight> is coupled between NIC <highlight><bold>1020</bold></highlight> and audio source <highlight><bold>1040</bold></highlight>. A look-up table <highlight><bold>1025</bold></highlight> is coupled to NIC <highlight><bold>1020</bold></highlight>. Look-up table <highlight><bold>1025</bold></highlight> (or a separate look-up table not shown) can also be coupled to audio source <highlight><bold>1040</bold></highlight>. Switch <highlight><bold>1030</bold></highlight> includes a multicaster <highlight><bold>1050</bold></highlight>. NIC <highlight><bold>1020</bold></highlight> includes a packet processor <highlight><bold>1070</bold></highlight>. </paragraph>
<paragraph id="P-0218" lvl="0"><number>&lsqb;0218&rsqb;</number> Conference call agent <highlight><bold>1010</bold></highlight> establishes a conference call for a number of participants. During a conference call, packets carrying audio, such as digitized voice, flow from the conference call participants C<highlight><bold>1</bold></highlight>-CN to the conference bridge <highlight><bold>1000</bold></highlight>. These packets can be IP packets including, but not limited to, RTP/RTCP packets. NIC <highlight><bold>1020</bold></highlight> receives the packets and forwards the packets along links <highlight><bold>1028</bold></highlight> to switch <highlight><bold>1030</bold></highlight>. Links <highlight><bold>1028</bold></highlight> can be any type of logical and/or physical links such as PVCs or SVCs. In one embodiment, NIC <highlight><bold>1020</bold></highlight> converts IP packets (as described above with respect to <cross-reference target="DRAWINGS">FIG. 7A</cross-reference>) to internal packets which only have a header and payload (as described with respect to <cross-reference target="DRAWINGS">FIG. 7B</cross-reference>). The use of the internal packets further reduces processing work at audio source <highlight><bold>1040</bold></highlight>. Incoming packets processed by NIC <highlight><bold>1020</bold></highlight> can also be combined by a SAR into cells, such as ATM cells, and sent over link(s) <highlight><bold>1028</bold></highlight> to switch <highlight><bold>1030</bold></highlight>. Switch <highlight><bold>1030</bold></highlight> passes the incoming packets from NIC <highlight><bold>1020</bold></highlight> (or cells) to audio source <highlight><bold>1040</bold></highlight> on link(s) <highlight><bold>1035</bold></highlight>. Link(s) <highlight><bold>1035</bold></highlight> can also be any type of logical and/or physical link including, but not limited to, a PVC or SVC. </paragraph>
<paragraph id="P-0219" lvl="0"><number>&lsqb;0219&rsqb;</number> Audio provided over links <highlight><bold>1035</bold></highlight> is referred to in this conference bridge processing context as &ldquo;external audio&rdquo; since it originates from conference call participants over network <highlight><bold>1005</bold></highlight>. Audio can also be provided internally through one or more links <highlight><bold>1036</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. Such &ldquo;internal audio&rdquo; can be speech, music, advertisements, news, or other audio content to be mixed in the conference call. The internal audio can be provided by any audio source or accessed from a storage device coupled to conference bridge <highlight><bold>1000</bold></highlight>. </paragraph>
<paragraph id="P-0220" lvl="0"><number>&lsqb;0220&rsqb;</number> Audio source <highlight><bold>1040</bold></highlight> mixes audio for the conference call. Audio source <highlight><bold>1040</bold></highlight> generates outbound packets containing the mixed audio and sends the packets over link(s) <highlight><bold>1045</bold></highlight> to switch <highlight><bold>1030</bold></highlight>. In particular, audio source <highlight><bold>1040</bold></highlight> generates a fully mixed audio stream of packets and a set of partially mixed audio streams. In one embodiment, audio source <highlight><bold>1040</bold></highlight> (or &ldquo;mixer&rdquo; since it is mixing audio) dynamically generates the appropriate fully mixed and partially mixed audio streams of packets having conference identifier information (CID) and mixed audio during the conference call. The audio source retrieves the appropriate CID information of conference call participants from a relatively static look-up table (such as table <highlight><bold>1025</bold></highlight> or a separate table closer to audio source <highlight><bold>1040</bold></highlight>) generated and stored at the initiation of the conference call. </paragraph>
<paragraph id="P-0221" lvl="0"><number>&lsqb;0221&rsqb;</number> Multicaster <highlight><bold>1050</bold></highlight> multicasts the packets in the fully mixed audio stream and a set of partially mixed audio streams. In one embodiment, multicaster <highlight><bold>1050</bold></highlight> replicates the packets in each of the fully mixed audio stream and set of partially mixed audio streams N times which corresponds to the N number of conference call participants. The N replicated packets are then sent to endpoints in NIC <highlight><bold>1020</bold></highlight> over the N switched virtual circuits (SVC<highlight><bold>1</bold></highlight>-SVCN), respectively. One advantage of distributed conference bridge <highlight><bold>1000</bold></highlight> is that audio source <highlight><bold>1040</bold></highlight> (i.e., the mixing device) is relieved of the work of replication. This replication work is distributed to multicaster <highlight><bold>1050</bold></highlight> and switch <highlight><bold>1030</bold></highlight>. </paragraph>
<paragraph id="P-0222" lvl="0"><number>&lsqb;0222&rsqb;</number> NIC <highlight><bold>1020</bold></highlight> then processes outbound packets arriving on each SVC<highlight><bold>1</bold></highlight>-SVCN to determine whether to discard or forward the packets of the fully mixed and partially mixed audio streams to a conference call participant C<highlight><bold>1</bold></highlight>-CN. This determination is made based on packet header information in real-time during a conference call. For each packet arriving on a SVC, NIC <highlight><bold>1020</bold></highlight> determines based on packet header information, such as TAS and IAS fields, whether the packet is appropriate for sending to a participant associated with the SVC. If yes, then the packet is forwarded for further packet processing. The packet is processed into a network packet and forwarded to the participant. Otherwise, the packet is discarded. In one embodiment, the network packet is an IP packet which includes the destination call participant&apos;s network address information (IP/UDP address) obtained from a look-up table <highlight><bold>1025</bold></highlight>, RTP/RTCP packet header information (time stamp/sequence information), and audio data. The audio data is the mixed audio data appropriate for the particular conference call participant. The operation of distributed conference bridge <highlight><bold>1000</bold></highlight> is described further below with respect to an example look-up table <highlight><bold>1025</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, flowchart diagrams shown in <cross-reference target="DRAWINGS">FIGS. 12 and 13</cross-reference>A-<highlight><bold>13</bold></highlight>C, and example packet diagrams shown in <cross-reference target="DRAWINGS">FIGS. 14A, 14B</cross-reference> and <highlight><bold>15</bold></highlight>. </paragraph>
<paragraph id="P-0223" lvl="0"><number>&lsqb;0223&rsqb;</number> B. Distributed Conference Bridge Operation </paragraph>
<paragraph id="P-0224" lvl="0"><number>&lsqb;0224&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> shows a routine <highlight><bold>1200</bold></highlight> for establishing conference bridge processing according to the present invention. (Steps <highlight><bold>1200</bold></highlight>-<highlight><bold>1280</bold></highlight>). In step <highlight><bold>1220</bold></highlight>, a conference call is initiated. A number of conference call participants C<highlight><bold>1</bold></highlight>-CN dial distributed conference bridge <highlight><bold>1000</bold></highlight>. Each participant can use any VOIP terminal including, but not limited to, a telephone, computer, PDA, set-top box, network appliance, etc. Conference call agent <highlight><bold>1010</bold></highlight> performs conventional IVR processing to acknowledge that a conference call participant wishes to participate in a conference call and obtains the network address of each conference call participant. For example, the network address information can include, but is not limited to, IP and/or UDP address information. </paragraph>
<paragraph id="P-0225" lvl="0"><number>&lsqb;0225&rsqb;</number> In step <highlight><bold>1240</bold></highlight>, look-up table <highlight><bold>1025</bold></highlight> is generated. Conference call agent <highlight><bold>1010</bold></highlight> can generate the look-up table or instruct NIC <highlight><bold>1020</bold></highlight> to generate the look-up table. As shown in the example on <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, look-up table <highlight><bold>1025</bold></highlight> includes N entries corresponding to the N conference call participants in the conference call initiated in step <highlight><bold>1220</bold></highlight>. Each entry in look-up table <highlight><bold>1025</bold></highlight> includes an SVC identifier, conference ID (CID), and network address information. The SVC identifier is any number or tag that identifies a particular SVC. In one example, the SVC identifier is a Virtual Path Identifier and Virtual Channel Identifier (VPI/VCI). Alternatively, the SVC identifier or tag information can be omitted from look-up table <highlight><bold>1025</bold></highlight> and instead be inherently associated with the location of the entry in the table. For example, a first SVC can be associated with the first entry in the table, a second SVC can be associated with a second entry in the table, and so forth. The CID is any number or tag assigned by conference call agent <highlight><bold>1010</bold></highlight> to a conference call participant C<highlight><bold>1</bold></highlight>-CN. The network address information is the network address information collected by conference call agent <highlight><bold>1010</bold></highlight> for each of the N conference call participants. </paragraph>
<paragraph id="P-0226" lvl="0"><number>&lsqb;0226&rsqb;</number> In step <highlight><bold>1260</bold></highlight>, NIC <highlight><bold>1020</bold></highlight> assigns respective SVCs to each of the participants. For N conference call participants then N SVCs are assigned. Conference call agent <highlight><bold>1010</bold></highlight> instructs NIC <highlight><bold>1020</bold></highlight> to assign N SVCs. NIC <highlight><bold>1020</bold></highlight> then establishes N SVC connections between NIC <highlight><bold>1020</bold></highlight> and switch <highlight><bold>1030</bold></highlight>. In step <highlight><bold>1280</bold></highlight>, the conference call then begins. Conference call agent <highlight><bold>1010</bold></highlight> sends a signal to NIC <highlight><bold>1020</bold></highlight> and switch <highlight><bold>1030</bold></highlight> and audio source <highlight><bold>1040</bold></highlight> to begin conference call processing. Although <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is described with respect to SVCs and SVC identifiers, the present invention is not so limited and any type of link (physical and/or logical) and link identifier can be used. Also, in embodiments where an internal audio source is included, conference call agent <highlight><bold>1010</bold></highlight> adds the internal audio source as one of the potential N audio participants whose input is to be mixed at audio source <highlight><bold>1040</bold></highlight>. </paragraph>
<paragraph id="P-0227" lvl="0"><number>&lsqb;0227&rsqb;</number> The operation of distributed conference bridge <highlight><bold>1000</bold></highlight> during conference call processing is shown in FIGS. <highlight><bold>13</bold></highlight>A-<highlight><bold>13</bold></highlight>C (steps <highlight><bold>1300</bold></highlight>-<highlight><bold>1398</bold></highlight>). Control begins at step <highlight><bold>1300</bold></highlight> and proceeds to step <highlight><bold>1310</bold></highlight>. In step <highlight><bold>1310</bold></highlight>, audio source <highlight><bold>1040</bold></highlight> monitors energy in the incoming audio streams of the conference call participant C<highlight><bold>1</bold></highlight>-CN. Audio source <highlight><bold>1040</bold></highlight> can be any type of audio source including, but not limited to, a digital signal processor (DSP). Any conventional technique for monitoring the energy of a digitized audio sample can be used. In step <highlight><bold>1320</bold></highlight>, audio source <highlight><bold>1040</bold></highlight> determines a number of active speakers based on the energy monitored in step <highlight><bold>1310</bold></highlight>. Any number of active speakers can be selected. In one embodiment, a conference call is limited to three active speakers at a given time. In this case, up to three active speakers are determined which correspond to the up to three audio streams having the most energy during the monitoring in step <highlight><bold>1320</bold></highlight>. </paragraph>
<paragraph id="P-0228" lvl="0"><number>&lsqb;0228&rsqb;</number> Next, audio source <highlight><bold>1040</bold></highlight> generates and sends fully mixed and partially mixed audio streams (steps <highlight><bold>1330</bold></highlight>-<highlight><bold>1360</bold></highlight>). In step <highlight><bold>1330</bold></highlight>, one fully mixed audio stream is generated. The fully mixed audio stream includes the audio content of the active speakers determined in step <highlight><bold>1320</bold></highlight>. In one embodiment, the fully mixed audio stream is an audio stream of packets with packet headers and payloads. Packet header information identifies the active speakers whose audio content is included in the fully mixed audio stream. In one example, as shown in <cross-reference target="DRAWINGS">FIG. 14A</cross-reference> audio source <highlight><bold>1040</bold></highlight> generates an outbound internal packet <highlight><bold>1400</bold></highlight> having a packet header <highlight><bold>1401</bold></highlight> with TAS, IAS, and Sequence fields and a payload <highlight><bold>1403</bold></highlight>. The TAS field lists CIDs of all of the current active speaker calls in the conference call. The IAS field lists CIDs of the active speakers whose audio content is in the mixed stream. The sequence information can be a timestamp, numeric sequence value, or other type of sequence information. Other fields (not shown) can include checksum or other packet information depending upon a particular application. In the case of a fully mixed audio stream, the TAS and IAS fields are identical. Payload <highlight><bold>1403</bold></highlight> contains a portion of the digitized mixed audio in the fully mixed audio stream. </paragraph>
<paragraph id="P-0229" lvl="0"><number>&lsqb;0229&rsqb;</number> In step <highlight><bold>1340</bold></highlight>, audio source <highlight><bold>1040</bold></highlight> sends the fully mixed audio stream generated in step <highlight><bold>1330</bold></highlight> to switch <highlight><bold>1030</bold></highlight>. Eventually, passive participants in the conference call (that is those determined not to be in the number of active speakers determined in step <highlight><bold>1320</bold></highlight>), will hear mixed audio from the fully mixed audio stream. </paragraph>
<paragraph id="P-0230" lvl="0"><number>&lsqb;0230&rsqb;</number> In step <highlight><bold>1350</bold></highlight>, audio source <highlight><bold>1040</bold></highlight> generates a set of partially mixed audio streams. The set of partially mixed audio streams is then sent to switch <highlight><bold>1030</bold></highlight> (step <highlight><bold>1360</bold></highlight>). Each of the partially mixed audio streams generated in step <highlight><bold>1350</bold></highlight> and sent in step <highlight><bold>1360</bold></highlight> includes the mixed audio content of the group of identified active speakers determined in step <highlight><bold>1320</bold></highlight> minus the audio content of a respective recipient active speaker. The recipient active speaker is the active speaker within the group of active speakers determined in step <highlight><bold>1320</bold></highlight> towards which a partially mixed audio stream is directed. </paragraph>
<paragraph id="P-0231" lvl="0"><number>&lsqb;0231&rsqb;</number> In one embodiment, audio source <highlight><bold>1040</bold></highlight> inserts in packet payloads the digital audio from the group of identified active speakers minus the audio content of the recipient active speaker. In this way, the recipient active speaker will not receive audio corresponding to their own speech or audio input. However, the recipient active speaker will hear the speech or audio input of the other active speakers. In one embodiment, packet header information is included in each partially mixed audio stream to identify active speakers whose audio content is included in the respective partially mixed audio stream. In one example, audio source <highlight><bold>1040</bold></highlight> uses the packet format of <cross-reference target="DRAWINGS">FIG. 14</cross-reference>A and inserts one or more conference identification numbers (CIDs) into TAS and IAS header fields of packets. The TAS field lists CIDs of all of the current active speakers in the conference call. The IAS field lists CIDs of the active speakers whose audio content is in the respective partially mixed stream. In the case of a partially mixed audio stream, the TAS and IAS fields are not identical since the IAS field has one less CID. In one example, to build packets in steps <highlight><bold>1330</bold></highlight> and <highlight><bold>1350</bold></highlight>, audio source <highlight><bold>1040</bold></highlight> retrieves the appropriate CID information of conference call participants from a relatively static look-up table (such as table <highlight><bold>1025</bold></highlight> or a separate table) generated and stored at the initiation of the conference call. </paragraph>
<paragraph id="P-0232" lvl="0"><number>&lsqb;0232&rsqb;</number> For example, in a conference call where there are 64 participants (N&equals;64) of which three are identified as active speakers (<highlight><bold>1</bold></highlight>-<highlight><bold>3</bold></highlight>), then one fully mixed audio stream will contain audio from all three active speakers. This fully mixed stream is eventually sent to each of the 61 passive participants. Three partially mixed audio streams are then generated in step <highlight><bold>1350</bold></highlight>. A first partially mixed stream <highlight><bold>1</bold></highlight> contains audio from speakers <highlight><bold>2</bold></highlight>-<highlight><bold>3</bold></highlight> but not speaker <highlight><bold>1</bold></highlight>. A second partially mixed stream <highlight><bold>2</bold></highlight> contains audio from speakers <highlight><bold>1</bold></highlight>-<highlight><bold>3</bold></highlight> but not speaker <highlight><bold>2</bold></highlight>. A third partially mixed stream <highlight><bold>3</bold></highlight> contains audio from speakers <highlight><bold>1</bold></highlight> and <highlight><bold>2</bold></highlight> but not speaker <highlight><bold>3</bold></highlight>. The first through third partially mixed audio streams are eventually sent to speakers <highlight><bold>1</bold></highlight>-<highlight><bold>3</bold></highlight> respectively. In this way only four mixed audio streams (one fully mixed and three partially mixed) need be generated by audio source <highlight><bold>1040</bold></highlight>. This reduces the work on audio source <highlight><bold>1040</bold></highlight>. </paragraph>
<paragraph id="P-0233" lvl="0"><number>&lsqb;0233&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>B, in step <highlight><bold>1370</bold></highlight>, multicaster <highlight><bold>1050</bold></highlight> replicates packets in the fully mixed audio stream and set of partially mixed audio streams and multicasts the replicated packet copies on all of the SVCs (SVC<highlight><bold>1</bold></highlight>-SVCN) assigned to the conference call. NIC <highlight><bold>1020</bold></highlight> then processes each packet received on the SVC (step <highlight><bold>1380</bold></highlight>). For clarity, each packet processed internally in distributed conference bridge <highlight><bold>1000</bold></highlight> (including packets received at SVCs by NIC <highlight><bold>1020</bold></highlight>) are referred to as internal packets. Internal packets can be any type of packet format including, but not limited to, IP packets and/or internal egress packets described above in <cross-reference target="DRAWINGS">FIGS. 7A and 7B</cross-reference>, and the example internal egress or outbound packet described with respect to <cross-reference target="DRAWINGS">FIG. 14A</cross-reference>. </paragraph>
<paragraph id="P-0234" lvl="0"><number>&lsqb;0234&rsqb;</number> For each SVC, NIC <highlight><bold>1020</bold></highlight> determines whether to discard or forward a received internal packet for further packet processing and eventual transmission to a corresponding conference call participant (step <highlight><bold>1381</bold></highlight>). The received internal packet can be from a fully mixed or partially mixed audio stream. If yes, the packet is to be forwarded, then control proceeds to step <highlight><bold>1390</bold></highlight>. If no, the packet is not to be forwarded, then control proceeds to step <highlight><bold>1380</bold></highlight> to process the next packet. In step <highlight><bold>1390</bold></highlight>, the packet is processed into a network IP packet. In one embodiment, packet processor <highlight><bold>1070</bold></highlight> generates a packet header with at least the participant&apos;s network address information (IP and/or UDP address) obtained from the look-up table <highlight><bold>1025</bold></highlight>. Packet processor <highlight><bold>1070</bold></highlight> further adds sequence information such as RTP/RTCP packet header information (e.g., a timestamp and/or other type of sequence information). Packet processor <highlight><bold>1070</bold></highlight> can generate such sequence information based on the order of received packets and/or based on sequence information (e.g. the Sequence field) provided in packets generated by the audio source <highlight><bold>1040</bold></highlight> (or by multicaster <highlight><bold>1050</bold></highlight>). Packet processor <highlight><bold>1070</bold></highlight> further adds a payload in each network packet that includes audio from the received internal packet being forwarded to a participant. NIC <highlight><bold>1020</bold></highlight> (or packet processor <highlight><bold>1070</bold></highlight>) then sends the generated IP packet to the participant (step <highlight><bold>1395</bold></highlight>). </paragraph>
<paragraph id="P-0235" lvl="0"><number>&lsqb;0235&rsqb;</number> One feature of the present invention is that the packet processing determination in step <highlight><bold>1381</bold></highlight> can be performed quickly and in real-time during a conference call. <cross-reference target="DRAWINGS">FIG. 13C</cross-reference> shows one example routine for carrying out the packet processing determination step <highlight><bold>1381</bold></highlight> according to the present invention (steps <highlight><bold>1382</bold></highlight>-<highlight><bold>1389</bold></highlight>). This routine is carried out for each outbound packet that arrives on each SVC. NIC <highlight><bold>1020</bold></highlight> acts as a filter or selector in determining which packets are discarded and which are converted to IP packets and sent to a call participant. </paragraph>
<paragraph id="P-0236" lvl="0"><number>&lsqb;0236&rsqb;</number> When an internal packet arrives on a SVC, NIC <highlight><bold>1020</bold></highlight> looks up an entry in look up table <highlight><bold>1025</bold></highlight> that corresponds to the particular SVC and obtains a CID value (step <highlight><bold>1382</bold></highlight>). NIC <highlight><bold>1020</bold></highlight> then determines whether the obtained CID value matches any CID value in the Total Active Speakers (TAS) field of the internal packet (step <highlight><bold>1383</bold></highlight>). If yes, control proceeds to step <highlight><bold>1384</bold></highlight>. If no, control proceeds to step <highlight><bold>1386</bold></highlight>. In step <highlight><bold>1384</bold></highlight>, NIC <highlight><bold>1020</bold></highlight> determines whether the obtained CID value matches any CID value in the Included Active Speakers (IAS) field of the internal packet. If yes, control proceeds to step <highlight><bold>1385</bold></highlight>. If no, control proceeds to step <highlight><bold>1387</bold></highlight>. In step <highlight><bold>1385</bold></highlight>, the packet is discarded. Control then proceeds to step <highlight><bold>1389</bold></highlight> which returns control to step <highlight><bold>1380</bold></highlight> to process a next packet. In step <highlight><bold>1387</bold></highlight>, control jumps to step <highlight><bold>1390</bold></highlight> for generating an IP packet from the internal packet. </paragraph>
<paragraph id="P-0237" lvl="0"><number>&lsqb;0237&rsqb;</number> In step <highlight><bold>1386</bold></highlight>, a comparison of the TAS and IAS fields is made. If the fields are identical (as in the case of a fully mixed audio stream packet), then control proceeds to step <highlight><bold>1387</bold></highlight>. In step <highlight><bold>1387</bold></highlight>, control jumps to step <highlight><bold>1390</bold></highlight>. If the TAS and IAS fields are not identical, then control proceeds to step <highlight><bold>1385</bold></highlight> and the packet is discarded. </paragraph>
<paragraph id="P-0238" lvl="0"><number>&lsqb;0238&rsqb;</number> C. Outbound Packet Flow through Distributed Conference Bridge </paragraph>
<paragraph id="P-0239" lvl="0"><number>&lsqb;0239&rsqb;</number> Outbound packet flow in distributed conference bridge <highlight><bold>1000</bold></highlight> is described further with respect to example packets in a 64-person conference call shown in <cross-reference target="DRAWINGS">FIGS. 14 and 15</cross-reference>. In <cross-reference target="DRAWINGS">FIGS. 14 and 15</cross-reference>, mixed audio content in a packet payload is denoted by a bracket surrounding the respective participants whose audio is mixed (e.g., &lcub;C<highlight><bold>1</bold></highlight>,C<highlight><bold>2</bold></highlight>,C<highlight><bold>3</bold></highlight>&rcub;). CID information in packet headers is denoted by underlining the respective active speaker participants (e.g., C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, C<highlight><bold>3</bold></highlight>, etc.). Sequence information is simply shown by a sequence number 0, 1 etc. </paragraph>
<paragraph id="P-0240" lvl="0"><number>&lsqb;0240&rsqb;</number> In this example, there are 64 participants C<highlight><bold>1</bold></highlight>-C<highlight><bold>64</bold></highlight> in a conference call of which three are identified as active speakers at a given time (C<highlight><bold>1</bold></highlight>-C<highlight><bold>3</bold></highlight>). Audio participants C<highlight><bold>4</bold></highlight>-C<highlight><bold>64</bold></highlight> are considered passive and their audio is not mixed. Audio source <highlight><bold>1040</bold></highlight> generates one fully mixed audio stream FM having audio from all 3 active speakers (C<highlight><bold>1</bold></highlight>-C<highlight><bold>3</bold></highlight>). <cross-reference target="DRAWINGS">FIG. 14B</cross-reference> shows two example internal packets <highlight><bold>1402</bold></highlight>, <highlight><bold>1404</bold></highlight> generated by audio source <highlight><bold>1040</bold></highlight> during this conference call. Packets <highlight><bold>1402</bold></highlight>, <highlight><bold>1404</bold></highlight> in stream FM have a packet header and payload. The payloads in packets <highlight><bold>1402</bold></highlight>, <highlight><bold>1404</bold></highlight> each include mixed audio from each of the three active speakers C<highlight><bold>1</bold></highlight>-C<highlight><bold>3</bold></highlight>. Packets <highlight><bold>1402</bold></highlight>, <highlight><bold>1404</bold></highlight> each include packet headers having TAS and IAS fields. The TAS field contains CIDs for the total three active speakers C<highlight><bold>1</bold></highlight>-C<highlight><bold>3</bold></highlight>. The IAS field contains CIDs for the active speakers C<highlight><bold>1</bold></highlight>-C<highlight><bold>3</bold></highlight> whose content is actually mixed in the payload of the packet. Packet <highlight><bold>1402</bold></highlight>, <highlight><bold>1404</bold></highlight> further include sequence information 0 and 1 respectively to indicate packet <highlight><bold>1402</bold></highlight> precedes packet <highlight><bold>1404</bold></highlight>. Mixed audio from fully mixed stream FM is eventually sent to each of the 61 currently passive participants (C<highlight><bold>4</bold></highlight>-C<highlight><bold>64</bold></highlight>). </paragraph>
<paragraph id="P-0241" lvl="0"><number>&lsqb;0241&rsqb;</number> Three partially mixed audio streams PM<highlight><bold>1</bold></highlight>-PM<highlight><bold>3</bold></highlight> are generated by audio source <highlight><bold>1040</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 14B</cross-reference> shows two packets <highlight><bold>1412</bold></highlight>, <highlight><bold>1414</bold></highlight> of first partially mixed stream PM<highlight><bold>1</bold></highlight>. Payloads in packets <highlight><bold>1412</bold></highlight> and <highlight><bold>1414</bold></highlight> contain mixed audio from speakers C<highlight><bold>2</bold></highlight> and C<highlight><bold>3</bold></highlight> but not speaker C<highlight><bold>1</bold></highlight>. Packets <highlight><bold>1412</bold></highlight>, <highlight><bold>1414</bold></highlight> each include packet headers. The TAS field contains CIDs for the total three active speakers C<highlight><bold>1</bold></highlight>-C<highlight><bold>3</bold></highlight>. The TAS field contains CIDs for the two active speakers C<highlight><bold>2</bold></highlight> and C<highlight><bold>3</bold></highlight> whose content is actually mixed in the payload of the packet. Packet <highlight><bold>1412</bold></highlight>, <highlight><bold>1414</bold></highlight> have sequence information 0 and 1 respectively to indicate packet <highlight><bold>1412</bold></highlight> precedes packet <highlight><bold>1414</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 14B</cross-reference> shows two packets <highlight><bold>1422</bold></highlight>, <highlight><bold>1424</bold></highlight> of second partially mixed stream PM<highlight><bold>2</bold></highlight>. Payloads in packets <highlight><bold>1422</bold></highlight> and <highlight><bold>1424</bold></highlight> contain mixed audio from speakers C<highlight><bold>1</bold></highlight> and C<highlight><bold>3</bold></highlight> but not speaker C<highlight><bold>2</bold></highlight>. Packets <highlight><bold>1422</bold></highlight>, <highlight><bold>1424</bold></highlight> each include packet headers. The TAS field contains CIDs for the total three active speakers C<highlight><bold>1</bold></highlight>-C<highlight><bold>3</bold></highlight>. The IAS field contains CIDs for the two active speakers C<highlight><bold>1</bold></highlight> and C<highlight><bold>3</bold></highlight> whose content is actually mixed in the payload of the packet. Packets <highlight><bold>1422</bold></highlight>, <highlight><bold>1424</bold></highlight> have sequence information 0 and 1 respectively to indicate packet <highlight><bold>1422</bold></highlight> precedes packet <highlight><bold>1424</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 14B</cross-reference> further shows two packets <highlight><bold>1432</bold></highlight>, <highlight><bold>1434</bold></highlight> of third partially mixed stream PM<highlight><bold>3</bold></highlight>. Payloads in packets <highlight><bold>1432</bold></highlight> and <highlight><bold>1434</bold></highlight> contain mixed audio from speakers C<highlight><bold>1</bold></highlight> and C<highlight><bold>2</bold></highlight> but not speaker C<highlight><bold>3</bold></highlight>. Packets <highlight><bold>1432</bold></highlight>, <highlight><bold>1434</bold></highlight> each include packet headers. The TAS field contains CIDs for the total three active speakers C<highlight><bold>1</bold></highlight>-C<highlight><bold>3</bold></highlight>. The IAS field contains CIDs for the two active speakers C<highlight><bold>1</bold></highlight> and C<highlight><bold>2</bold></highlight> whose content is actually mixed in the payload of the packet. Packets <highlight><bold>1432</bold></highlight>, <highlight><bold>1434</bold></highlight> have sequence information 0 and 1 respectively to indicate packet <highlight><bold>1432</bold></highlight> precedes packet <highlight><bold>1434</bold></highlight>. </paragraph>
<paragraph id="P-0242" lvl="0"><number>&lsqb;0242&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is a diagram that illustrates example packet content after the packets of <cross-reference target="DRAWINGS">FIG. 14</cross-reference> have been multicasted and after they have been processed into IP packets to be sent to appropriate conference call participants according to the present invention. In particular, packets <highlight><bold>1412</bold></highlight>, <highlight><bold>1422</bold></highlight>, <highlight><bold>1432</bold></highlight>, <highlight><bold>1402</bold></highlight>, <highlight><bold>1414</bold></highlight> are shown as they are multicast across each of SVC<highlight><bold>1</bold></highlight>-SVC<highlight><bold>64</bold></highlight> and arrive at NIC <highlight><bold>1020</bold></highlight>. As described above with respect to step <highlight><bold>1381</bold></highlight>, NIC <highlight><bold>1020</bold></highlight> determines for each SVC<highlight><bold>1</bold></highlight>-SVC<highlight><bold>64</bold></highlight> which packets <highlight><bold>1412</bold></highlight>, <highlight><bold>1422</bold></highlight>, <highlight><bold>1432</bold></highlight>, <highlight><bold>1402</bold></highlight>, <highlight><bold>1414</bold></highlight> are appropriate to forward to a respective conference call participant C<highlight><bold>1</bold></highlight>-C<highlight><bold>64</bold></highlight>. Network packets (e.g. IP packets) are then generated by packet processor <highlight><bold>1070</bold></highlight> and sent to the respective conference call participant C<highlight><bold>1</bold></highlight>-C<highlight><bold>64</bold></highlight>. </paragraph>
<paragraph id="P-0243" lvl="0"><number>&lsqb;0243&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, for SVC<highlight><bold>1</bold></highlight>, packets <highlight><bold>1412</bold></highlight> and <highlight><bold>1414</bold></highlight> are determined to be forwarded to C<highlight><bold>1</bold></highlight> based on their packet headers. Packets <highlight><bold>1412</bold></highlight>, <highlight><bold>1414</bold></highlight> have the CID of C<highlight><bold>1</bold></highlight> in the TAS field but not the IAS field. Packets <highlight><bold>1412</bold></highlight> and <highlight><bold>1414</bold></highlight> are converted to network packets <highlight><bold>1512</bold></highlight> and <highlight><bold>1514</bold></highlight>. Network packets <highlight><bold>1512</bold></highlight>, <highlight><bold>1514</bold></highlight> include the IP address of C<highlight><bold>1</bold></highlight> (C<highlight><bold>1</bold></highlight>ADDR) and the mixed audio from speakers C<highlight><bold>2</bold></highlight> and C<highlight><bold>3</bold></highlight> but not speaker C<highlight><bold>1</bold></highlight>. Packets <highlight><bold>1512</bold></highlight>, <highlight><bold>1514</bold></highlight> have sequence information 0 and 1 respectively to indicate packet <highlight><bold>1512</bold></highlight> precedes packet <highlight><bold>1514</bold></highlight>. For SVC<highlight><bold>2</bold></highlight> (corresponding to conference call participant C<highlight><bold>2</bold></highlight>), packet <highlight><bold>1422</bold></highlight> is determined to be forwarded to C<highlight><bold>2</bold></highlight>. Packet <highlight><bold>1422</bold></highlight> has the CID of C<highlight><bold>2</bold></highlight> in the TAS field but not the IAS field. Packet <highlight><bold>1422</bold></highlight> is converted to network packet <highlight><bold>1522</bold></highlight>. Network packet <highlight><bold>1522</bold></highlight> includes the IP address of C<highlight><bold>2</bold></highlight> (C<highlight><bold>2</bold></highlight>ADDR), sequence information 0, and the mixed audio from speakers C<highlight><bold>1</bold></highlight> and C<highlight><bold>3</bold></highlight> but not speaker C<highlight><bold>2</bold></highlight>. For SVC<highlight><bold>3</bold></highlight> (corresponding to conference call participant C<highlight><bold>3</bold></highlight>), packet <highlight><bold>1432</bold></highlight> is determined to be forwarded to C<highlight><bold>3</bold></highlight>. Packet <highlight><bold>1432</bold></highlight> has the CID of C<highlight><bold>3</bold></highlight> in the TAS field but not the IAS field. Packet <highlight><bold>1432</bold></highlight> is converted to network packet <highlight><bold>1532</bold></highlight>. Network packet <highlight><bold>1532</bold></highlight> includes the IP address of C<highlight><bold>3</bold></highlight> (C<highlight><bold>3</bold></highlight>ADDR), sequence information 0, and the mixed audio from speakers C<highlight><bold>1</bold></highlight> and C<highlight><bold>2</bold></highlight> but not speaker C<highlight><bold>3</bold></highlight>. For SVC<highlight><bold>4</bold></highlight> (corresponding to conference call participant C<highlight><bold>4</bold></highlight>), packet <highlight><bold>1402</bold></highlight> is determined to be forwarded to C<highlight><bold>4</bold></highlight>. Packet <highlight><bold>1402</bold></highlight> does not have the CID of C<highlight><bold>4</bold></highlight> in the TAS field and the TAS and IAS fields are identical indicating a fully-mixed stream. Packet <highlight><bold>1402</bold></highlight> is converted to network packet <highlight><bold>1502</bold></highlight>. Network packet <highlight><bold>1502</bold></highlight> includes the IP address of C<highlight><bold>4</bold></highlight> (C<highlight><bold>4</bold></highlight>ADDR), sequence information 0, and the mixed audio from all of the active speakers C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, and C<highlight><bold>3</bold></highlight>. Each of the other passive participants C<highlight><bold>5</bold></highlight>-C<highlight><bold>64</bold></highlight> receive similar packets. For example, for SVC<highlight><bold>64</bold></highlight> (corresponding to conference call participant C<highlight><bold>64</bold></highlight>), packet <highlight><bold>1402</bold></highlight> is determined to be forwarded to C<highlight><bold>64</bold></highlight>. Packet <highlight><bold>1402</bold></highlight> is converted to network packet <highlight><bold>1503</bold></highlight>. Network packet <highlight><bold>1503</bold></highlight> includes the IP address of C<highlight><bold>64</bold></highlight> (C<highlight><bold>64</bold></highlight>ADDR), sequence information 0, and the mixed audio from all of the active speakers C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, and C<highlight><bold>3</bold></highlight>. </paragraph>
<paragraph id="P-0244" lvl="0"><number>&lsqb;0244&rsqb;</number> D. Control Logic and Additional Embodiments </paragraph>
<paragraph id="P-0245" lvl="0"><number>&lsqb;0245&rsqb;</number> Functionality described above with respect to the operation of conference bridge <highlight><bold>1000</bold></highlight> (including conference call agent <highlight><bold>1010</bold></highlight>, NIC <highlight><bold>1020</bold></highlight>, switch <highlight><bold>1030</bold></highlight>, audio source <highlight><bold>1040</bold></highlight>, and multi-caster <highlight><bold>1050</bold></highlight>) can be implemented in control logic. Such control logic can be implemented in software, firmware, hardware or any combination thereof. </paragraph>
<paragraph id="P-0246" lvl="0"><number>&lsqb;0246&rsqb;</number> In one embodiment, distributed conference bridge <highlight><bold>1000</bold></highlight> is implemented in a media server such as media server <highlight><bold>202</bold></highlight>. In one embodiment, distributed conference bridge <highlight><bold>1000</bold></highlight> is implemented in audio processing platform <highlight><bold>230</bold></highlight>. Conference call agent <highlight><bold>1010</bold></highlight> is part of call control and audio feature manager <highlight><bold>302</bold></highlight>. NIC <highlight><bold>306</bold></highlight> carries out the network interface functions of NIC <highlight><bold>1020</bold></highlight> and packet processors <highlight><bold>307</bold></highlight> carry out the function of packet processor <highlight><bold>1070</bold></highlight>. Switch <highlight><bold>304</bold></highlight> is replaced with switch <highlight><bold>1030</bold></highlight> and multicaster <highlight><bold>1050</bold></highlight>. Any of audio sources <highlight><bold>308</bold></highlight> can carry out the function of audio source <highlight><bold>1040</bold></highlight>. </paragraph>
<paragraph id="P-0247" lvl="7"><number>&lsqb;0247&rsqb;</number> XI. Conclusion </paragraph>
<paragraph id="P-0248" lvl="0"><number>&lsqb;0248&rsqb;</number> While specific embodiments of the present invention have been described above, it should be understood that they have been presented by way of example only, and not limitation. It will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the spirit and scope of the invention as defined in the appended claims. Thus, the breadth and scope of the present invention should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A media platform for providing media services over a network, comprising: 
<claim-text>a resource manager that manages resources used to support the media services; and </claim-text>
<claim-text>an audio processing platform that manages calls and the media services provided in the calls; said audio processing platform including: 
<claim-text>a network interface having a set of packet processors that process packets of audio data entering and exiting the media platform in the calls being handled; </claim-text>
<claim-text>a set of audio processors that process the audio data according to the media services provided in the calls; and </claim-text>
<claim-text>a switch that switches packets of audio data sent between the audio processors and packet processors. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said audio processing platform further comprises a call control and audio feature manager that controls resources and media services provided in calls processed by said audio processors. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein said call control and audio feature manager includes: 
<claim-text>a call signaling manager; </claim-text>
<claim-text>system manager; </claim-text>
<claim-text>connection manager; and </claim-text>
<claim-text>feature controller. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein said call control and audio feature manager includes: 
<claim-text>a call signaling manager; </claim-text>
<claim-text>system manager; </claim-text>
<claim-text>connection manager; and </claim-text>
<claim-text>feature controller. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004-1">
<claim-text><highlight><bold>4</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein said audio processing platform comprises a shelf controller card. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>a set of ports coupled to the network; and </claim-text>
<claim-text>wherein said network interface further comprises, for each packet processor, a respective controller and forwarding information table. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said switch comprises a packet switch. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising a cell layer that combines the packets of audio data into cells of audio, and wherein said switch comprises a cell switch that switches said cells. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein each audio processor comprises a digital signal processor. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein each audio processor comprises a plurality of card processors coupled to a plurality of digital signal processors. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein for at least one ingress audio stream, each packet processor receives IP packets with RTP information from the network and converts the IP packets to internal packets, each internal packet having a payload and header. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein each audio processor processes internal packets. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The media platform according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein for egress audio streams, each packet processor receives internal packets and generates IP packets with RTP information to be sent over the network. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A media platform for providing media services over a network, comprising: 
<claim-text>means for managing resources used to support the media services; </claim-text>
<claim-text>means for interfacing with a network, said interface means including means for processing packets of audio data entering and exiting the media platform in calls being handled; </claim-text>
<claim-text>means for processing the audio data according to the media services provided in the calls; and </claim-text>
<claim-text>means for switching packets of audio data sent between the audio processors and packet processors. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A scalable audio processing platform that manages voice over the Internet calls and media services provided in the calls, the platform including: 
<claim-text>a network interface having a set of packet processors that process packets of audio data entering and exiting the platform in the calls being handled; </claim-text>
<claim-text>a set of audio processors that process the audio data according to the media services provided in the calls; and </claim-text>
<claim-text>a switch coupled between said network interface and said set of audio processors that switches packets of audio data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A method for providing media services over a network, comprising: 
<claim-text>managing resources used to support at least one media service provided to voice over the Internet calls; </claim-text>
<claim-text>processing IP packets of audio data in ingress audio streams and egress audio streams in the calls being handled including converting IP packets to internal packets in ingress audio streams and converting internal packets to IP packets in egress audio streams; </claim-text>
<claim-text>switching the internal packets of audio data in ingress audio streams and egress audio streams in the calls being handled; and </claim-text>
<claim-text>processing the internal packets of audio data in ingress audio streams and egress audio streams to provide at least one media service in the calls.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002481A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002481A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002481A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002481A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002481A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002481A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002481A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002481A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002481A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030002481A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030002481A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030002481A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030002481A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030002481A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030002481A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030002481A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030002481A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030002481A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030002481A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00019">
<image id="EMI-D00019" file="US20030002481A1-20030102-D00019.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00020">
<image id="EMI-D00020" file="US20030002481A1-20030102-D00020.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00021">
<image id="EMI-D00021" file="US20030002481A1-20030102-D00021.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00022">
<image id="EMI-D00022" file="US20030002481A1-20030102-D00022.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00023">
<image id="EMI-D00023" file="US20030002481A1-20030102-D00023.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00024">
<image id="EMI-D00024" file="US20030002481A1-20030102-D00024.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00025">
<image id="EMI-D00025" file="US20030002481A1-20030102-D00025.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00026">
<image id="EMI-D00026" file="US20030002481A1-20030102-D00026.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
