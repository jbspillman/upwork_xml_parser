<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002405A1-20030102-D00000.TIF SYSTEM "US20030002405A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002405A1-20030102-D00001.TIF SYSTEM "US20030002405A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002405A1-20030102-D00002.TIF SYSTEM "US20030002405A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002405A1-20030102-D00003.TIF SYSTEM "US20030002405A1-20030102-D00003.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002405</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10130273</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020718</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>199 57 552.5</doc-number>
</priority-application-number>
<filing-date>19991130</filing-date>
<country-code>DE</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G11B020/10</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G11B019/02</ipc>
</classification-ipc-secondary>
<classification-ipc-secondary>
<ipc>G11B015/52</ipc>
</classification-ipc-secondary>
<classification-ipc-secondary>
<ipc>G11B005/09</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>369</class>
<subclass>047100</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Backup and archiving system by means of tape volume cassettes for data processing units</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Hansjorg</given-name>
<family-name>Linder</family-name>
</name>
<residence>
<residence-non-us>
<city>Munchen</city>
<country-code>DE</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>NEIFELD IP LAW, PC</name-1>
<name-2></name-2>
<address>
<address-1>CRYSTAL PLAZA 1, SUITE 1001</address-1>
<address-2>2001 JEFFERSON DAVIS HIGHWAY</address-2>
<city>ARLINGTON</city>
<state>VA</state>
<postalcode>22202</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
<international-conventions>
<pct-application>
<document-id>
<doc-number>PCT/DE00/04261</doc-number>
<document-date>20001130</document-date>
<country-code>WO</country-code>
</document-id>
</pct-application>
</international-conventions>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A backup and archiving system by means of tape cassettes is proposed which avoids bottlenecks at a higher performance level &lsqb;that may be&rsqb; caused by a central working storage especially during backup and archiving procedures. Such a backup and archiving system provides a distributed hardware architecture in which several Component Computers (<highlight><bold>6</bold></highlight>) work without reciprocal obstruction. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The invention pertains to a backup and archiving system by means of tape cassettes for data processing systems in keeping with the preamble to claim <highlight><bold>1</bold></highlight>. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> At present, tape cassettes are the lowest-priced archiving medium for realizing backup and archiving systems. It is noteworthy that, on the one hand, the current significant growth in data volume entails an increasing number of tape cassettes (hereinafter also referred to as volumes) addressing one host unit individually. On the other hand, the growth in data volume entails only a limited increase in data volume per volume. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> In addition, the principal use of backup and archiving systems currently takes place in an ever narrowing archiving window, since it must not impede any application operation. Thus, any backup and archiving system has to meet high requirements of parallelization in order to be able to transfer a volume of data. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> It is noteworthy that the actually usable transfer rates for backup and archiving processes are, at present, markedly lower than those which tape technology can currently support. On the one hand, this is due to the fact that only limited data rates can be transferred by individual applications. Another reason is the fact that, whenever the data streams of several applications are clustered, access to the disk systems is constrained by the data structures of the systems platforms. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Moreover, tape systems have short innovation cycles for increasing capacity and a rate of transfer increasing by factors. One of the reasons is that more tracks are used to record on one tape. Another reason is that the degree of data compression is increasing. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Furthermore, manual operation of peripheral tape devices is more and more being automated by robot systems called stackers and ATLs (Automatic Tape Libraries). </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Finally, a greater tendency to centralize archiving in computer centers is discernible, in an effort to do so in clusters of several platforms. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The above-described development trends bring about the problems detailed below. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> For example, the average recording quantity (filling ratio) of the tapes decreases. Studies have revealed that, on average, less than 20% of the tapes are filled. Compounded with respect to the new technologies, this filling ratio threatens to drop to as little as 1%. The volumes are therefore filled only partially, and therefore again uneconomically. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The transfer rates of the cassette drives are not fully used and respresent an unused potential. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The number of tapes/cassettes rises disproportionally, requiring appropriate shelf space, and leads to high cost. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> Increased cost for shelf space in a robot, compared with a conventional shelf, exacerbates the cost problem. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The cassette drives are only fully used in phases; in other words, their use is uneconomical. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Since a high degree of parallelization is required for short-term peak loads, the number of cassette drives must, in addition, be increased even though the drives are rarely in use. In other words, the cost of investment is additionally increased by technical exigencies. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In today&apos;s tape technology, obstructions continue to occur during operation, brought about by extended mount and positioning times. For example, such obstructions may occur during a Reclaim, so called, of archived data for the purpose of reading or update. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> As a rule, it is not possible to make adjustments to the host systems for optimal use of the tape and drive technology because functional adjustments within the applications are too costly. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> Due to the incompatibility between various manufacturers and between generations of drives, problems arise to the user when expansion becomes necessary and when new technologies are used. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> Previous approaches to solving these problems may be divided into two categories. One category pertains to individual solutions, while the other category pertains to integrated solutions. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> A first individual solution may be referred to as &ldquo;ATL&rdquo; (Automatic Tape Libraries). ATL systems enable manual operation of the tape devices to be automated. Besides reducing the need for manual labor, the operation becomes more dependable and safer, and mount times are shortened because they proceed mechanically. Due to centralization for reasons of cost, an ATL is typically used jointly by several hosts. Thus, tape cassettes may frequently be used jointly by several systems regardless of the systems platform. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Another individual solution may be described as &ldquo;virtual volumes&rdquo;. In this solution, several volumes, viewed by the host as independently named volumes or cassettes, are embodied on one single physical volume. This increases the storage capability of the physical volumes (tape cassettes), so that fewer tape cassettes need to stand by. The specific properties of a new drive and the volumes run on it are no longer visible to the host. Therefore, adjustments no longer are necessary for operating the host, since the adjustments are captured by virtualization whenever transition is made to a new generation. In other words, the adjustments are accomplished in a software-driven virtualization stratum. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Yet another individual solution is temporary storage of data. The data are temporarily stored in a volume cache. In other words, entire virtual volumes are saved in a disk memory, in order to allow immediate writing (without prior mount time) and faster reading (without mount and positioning times). Retrieval and storage from a virtual volume to the volume cache may then take advantage of the physical tape transfer rate. In other words, the performance requirements of archiving may be met with fewer drives than in instances in which the host accesses the tape cassette drives directly. At the host interface, the number of available virtual cassette drives may be greater than available physically installed cassette drives. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> Variable mechanisms are used for optimized management of the temporary disk memory, so that advance reservations etc. are possible. They control the exact time of secondary data transfer, i.e. the point at which a virtual volume is transferred between volume cache and physical cassettes. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> In order to prevent data losses when errors occur in temporary memory, steps are taken to make the disks failsafe. The use of RAID disks, so called, is an example of such steps. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Volume caching is typically superimposed on a standard file system. A UNIX file system is an example of such a standard file system. This file system also contains data such as label contents from the virtual volumes being managed, as well as meta information. Meta information may, for example, be information indicating which virtual volume resides in which physical tape cassette, etc. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> An appropriately dimensioned volume cache may, given a short archivation time window such as a 2-hour time window, achieve a nearly continuous optimal load for the cassette drives over 24 hours with high data traffic between host and disk. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> In an integrated solution, virtualization, caching and operation are simultaneously achieved in any system via an ATL. Appropriate processing capacities are autonomously accomplished by a system of architecture visually presented in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> in detail and hereinafter referred to as Architecture Model M<highlight><bold>1</bold></highlight>. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The integrated solution in accordance with Architecture Model M<highlight><bold>1</bold></highlight> arises as a natural approach to solve the problems described above. On the other hand, Architecture Model M<highlight><bold>1</bold></highlight> leads to new problems. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The system in accordance with Architecture Model M<highlight><bold>1</bold></highlight> may itself become a bottleneck in the case of certain configurations. The scaleability of any system is, therefore, already too narrow for current installations. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> It is furthermore problematic that guarantees versus the host regarding transfer rates are by now possible only up to a point, due to the system&apos;s complex internal processes with reciprocal obstruction. Particularly, operational obstructions may arise due to internal systems reorganization processes when, for example, a tape containing few data is to be fully used again because of a cassette recycling. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> The scant use of the tapes is due, on the one hand, to additional data being regularly added to the end of the tape while, on the other hand, invalid data can be so marked but cannot be deleted from the tape. The obstructed space on the tapes can only be recaptured by a reorganization, i.e. by selecting, temporarily storing and then writing the desired data to a reformatted tape. This entails an enormous additional burden on the CPU, especially, and on the bus system of the archiving systems, with the effect that overall performance of the systems declines even further. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> It is also problematic that the system additionally represents a new danger. Additional efforts are required to avoid systems failure when individual components fail. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> To avoid the bottleneck in the data transfer, multiprocessors and multibus systems are used. However, all of the data transferred between host and disks, and all of the data transferred between disks and tape cassettes have to be moved via the CPUs&apos; working storage, as the data formats, such as the blocking of data, header information etc., differ between host, caching disk and tape cassettes. Therefore, it turns out that the rate of transfer to the CPUs&apos; working storage is the limiting factor for the data transfer of the entire system. This is true in equal measure for multiprocessor systems. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> This potential bottleneck limits the scaleability of systems following Architecture Model M<highlight><bold>1</bold></highlight> and may force the user to operate several systems with consequently separate data quantities. This results in organizational problems for the user, such as the need for reorganizing his internal work processes. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> It is a particular problem that it is not possible to guarantee transfer rates versus the hosts. Indirectly launched transfers between the volume cache and physical tape cassettes obstruct the data traffic between host and volume cache, since they both have to be reformatted via the working storage. Resulting fluctuations of the transfer rates available to the host may require for their avoidance a reserve capacity in the system which cannot otherwise be provided. Attempts to copy from one cassette drive directly onto another without going through the volume cache, while reducing load on the working storage, require an additional physical drive. This renders the external control of the internal optimization even more difficult. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Failsafe dual systems in accordance with Architecture Model M<highlight><bold>1</bold></highlight> have not appeared on the market so far. Since they involve additional coordination efforts, they may also entail additional bottlenecks and control problems. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> It is the task of the invention at hand to specify a backup and archiving system of the type described above, in which a bottleneck due to a central working storage is avoided, especially in backup and archiving procedures in higher performance contexts. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> This task has been solved by a backup and archiving system having the characteristics of claim <highlight><bold>1</bold></highlight>, thus achieving a distributed hardware architecture in which several component computers work without reciprocal interference. This avoids resorting to a bottleneck-causing central hardware element for data conversion, such as the central working storage in an Architecture Model M<highlight><bold>1</bold></highlight> as described above. In accordance with the distributed hardware architecture, several autonomous working memories, i.e. one per component computer, are available to handle data conversion. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Moreover, this distributed hardware architecture has the advantage of enabling an increased number of component computers to raise the overall performance of the backup and archiving system beyond the performance spectrum required today. The addition of further data entries and/or cassette drives can be handled by simply adding more component computers. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> It is also of advantage that software components required for realizing the backup and archiving system are scaleable. The hardware basis is of no importance; i.e., it does not matter whether the system is based on a single processor or on multiple processors. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The device in this invention permits fundamentally higher overall rates of transfer than prior architectures. Should additional performance increases become necessary, they can be realized because the capacity all available interface media is expandable beyond currently foreseeable neeeds, by means of multiplication. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> Moreover, it is of advantage&mdash;whenever guarantees for transfer rates versus the hosts are required&mdash;that needless reserve capacities are unnecessary. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> Furthermore, complex special solutions are avoided for relieving the bottleneck of data conversion in main storage for recycling cassettes. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Finally, it is of advantage that the use of standard hardware components for the first, second and third functional unit is also feasible for peak performance levels, which leads to lower overall cost. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> Advantageous configurations of the invention are described in subordinate claims. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> In accordance therewith, LAN, SCSI and FC connection structures may be used for fast data transfer. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> If several component computers and cassette drives or hosts are interconnected via appropriate multiple connectors, the component computers may be reciprocally used as substitute computers at no extra cost, making the system highly failsafe. This does not impinge on the coordination of normal operation. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> An additional increase in the system&apos;s performance is achieved through multiple layout of hardware components needed for access to the volume cache, for communication regarding access to the volume cache, and for communication regarding management tasks between the component computers, because bottlenecks which might otherwise arise at these points are avoided.</paragraph>
</summary-of-invention>
<brief-description-of-drawings>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> Below, one sample implementation of the invention is explained in greater detail, using a drawing. It comprises: </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1 a</cross-reference> schematic of a backup and archiving system with one state-of-the-art integrated volume cache. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2 a</cross-reference> schematic of a backup and archiving system with a distributed hardware architecture in accordance with the invention. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3 a</cross-reference> schematic of the software architecture of a backup and archiving system in accordance with <cross-reference target="DRAWINGS">FIG. 2</cross-reference>; and </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4 a</cross-reference> schematic summary of the hardware and software architecture in accordance with <cross-reference target="DRAWINGS">FIGS. 2 and 3</cross-reference> regarding a general Virtual Tape Library System in accordance with the invention as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>.</paragraph>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> The backup and archiving system by means of tape cassettes for data processing systems shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is connected to a Host Unit <highlight><bold>1</bold></highlight>. Optionally, a second host unit, or additional Host Units <highlight><bold>1</bold></highlight> may be included. The backup and archiving system according to <cross-reference target="DRAWINGS">FIG. 1</cross-reference> has at least one Cassette Drive <highlight><bold>2</bold></highlight> for tape cassettes. Moreover, a Disk Memory Subsystem <highlight><bold>3</bold></highlight> is included which comprises at least one Disk Memory Unit <highlight><bold>4</bold></highlight>. For mutual data-technical interface of existing Hosts <highlight><bold>1</bold></highlight>, Cassette Drive <highlight><bold>2</bold></highlight>, and Disk Memory Subsystem <highlight><bold>3</bold></highlight>, a data-technical Interface Unit <highlight><bold>5</bold></highlight> has been inserted. As also shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, data-technical Interface Unit <highlight><bold>5</bold></highlight> consists of a single computer with Bus System <highlight><bold>17</bold></highlight>. The single computer consists of one or several CPUs (Central Processing Units), i.e., of one or several central processors which, together with a Central Working Storage <highlight><bold>16</bold></highlight>, process the data transfers between the Hosts <highlight><bold>1</bold></highlight>, the Cassette Drives <highlight><bold>2</bold></highlight> and the Disk Memory Subsystem <highlight><bold>3</bold></highlight>. For this purpose, the CPUs and the Central Working storage <highlight><bold>15</bold></highlight> are connected to Bus System <highlight><bold>17</bold></highlight>, to which Hosts <highlight><bold>1</bold></highlight>, the Cassette Drive <highlight><bold>2</bold></highlight>, and the Disk Memory Subsystem <highlight><bold>3</bold></highlight> are likewise connected. Data conversions necessitated by the backup and archiving processes take place via the central working storage. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a backup and archiving system in accordance with the invention which is based on a virtually distributed hardware and software architecture. Analogously to the architecture of the backup and archiving system shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, which has also been called Architecture Model M<highlight><bold>1</bold></highlight>, the architecture of the backup and archiving system shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> may be regarded as Architecture Model M<highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Just like the backup and archiving system shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the backup and archiving system shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is connected to one or several Hosts <highlight><bold>1</bold></highlight> and one or several Cassette Drives <highlight><bold>2</bold></highlight>. The data from Hosts <highlight><bold>1</bold></highlight> are presented at Data Ports <highlight><bold>15</bold></highlight>. Furthermore, a Disk Memory Subsystem <highlight><bold>3</bold></highlight> with at least one Disk Memory Unit <highlight><bold>4</bold></highlight> is present as part of a data-technical Interface Unit <highlight><bold>5</bold></highlight>. As in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the data-technical Interface Unit <highlight><bold>5</bold></highlight> is connected to the Hosts <highlight><bold>1</bold></highlight> and the Cassette Drives <highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> In contrast with <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, discrete Function Units <highlight><bold>11</bold></highlight> and <highlight><bold>12</bold></highlight> are provided within the data-technical Interface Unit of <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, each having several Component Computers <highlight><bold>6</bold></highlight> with respective CPUs and working memories, for handling the data-technical processes required for backup and archiving procedures. A second Function Unit <highlight><bold>11</bold></highlight> transfers the data received from at least one Data Port <highlight><bold>15</bold></highlight> to Disk Memory Subsystem <highlight><bold>3</bold></highlight>, while a third Function Component is provided for transfer of the data temporarily stored on Disk Memory Subsystem <highlight><bold>3</bold></highlight> to at least one Cassette Drive <highlight><bold>2</bold></highlight>. A first Function Component <highlight><bold>10</bold></highlight> coordinates and controls the data flow between Data Ports <highlight><bold>15</bold></highlight>, the Cassette Drives <highlight><bold>2</bold></highlight>, and Disk Memory Subsystem <highlight><bold>3</bold></highlight>. In the sample implementation shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, Function Units <highlight><bold>11</bold></highlight> and <highlight><bold>12</bold></highlight> are realized by two Component Computers <highlight><bold>6</bold></highlight> each, which are each connected to Disk Memory Subsystem <highlight><bold>3</bold></highlight>. Moreover, a few of the Component Computers <highlight><bold>6</bold></highlight> are each connected to at least one Host <highlight><bold>1</bold></highlight>, for the purpose of handling the data transfer to the host side. Moreover, a few other Component Computers <highlight><bold>6</bold></highlight> are connected, in the direction of the cassette drive side, to one Cassette Drive <highlight><bold>2</bold></highlight> each. The number of Component Computers <highlight><bold>6</bold></highlight> may be variably chosen. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Disk Memory Subsystem <highlight><bold>3</bold></highlight> is sometimes referred to as volume cache in the description. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows the facts of <cross-reference target="DRAWINGS">FIG. 2</cross-reference> in greater detail. In <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, Component Computers <highlight><bold>6</bold></highlight> are interconnected by an appropriate first Interface Element <highlight><bold>7</bold></highlight> for the purpose of data-technical exchange of information. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> In the sample implementation, this first Interface Element <highlight><bold>7</bold></highlight> is realized by a LAN (Local Area Network), i.e. by a local network. A local network is a hardware- and software- related conjunction of computers into a functional system. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> As <cross-reference target="DRAWINGS">FIG. 4</cross-reference> also shows, appropriate Component Computers <highlight><bold>6</bold></highlight> are connected, for a data transfer between the appropriate Component Computers <highlight><bold>6</bold></highlight> and the Disk Memory Subsystem <highlight><bold>3</bold></highlight> or the cassette drives, to Disk Memory Subsystem <highlight><bold>3</bold></highlight> or the Cassette Drives <highlight><bold>2</bold></highlight> by an appropriate and fast second Interface Element (<highlight><bold>8</bold></highlight>; <highlight><bold>9</bold></highlight>). In particular, Interface Element <highlight><bold>8</bold></highlight> is realized between the appropriate Component Computers <highlight><bold>6</bold></highlight> and Disk Memory Subsystem <highlight><bold>3</bold></highlight> by means of an FC technology (Fibre Channel), and Interface Element <highlight><bold>9</bold></highlight> is realized between the appropriate Component Computers <highlight><bold>6</bold></highlight> and the Cassette Drives <highlight><bold>2</bold></highlight> by means of an SCSI technology (Small Computer System Interface). Interface Element <highlight><bold>8</bold></highlight> between the appropriate Component Computers <highlight><bold>6</bold></highlight> and Disk Memory Subsystem <highlight><bold>3</bold></highlight> might, in a different sample implementation, also be realized by means of an FC-AL technology (Fibre Channel-Arbitrated Loops). The FC technology permits bridging great distances up to 10 km. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> In the backup and archiving system shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> or <highlight><bold>4</bold></highlight>, a distributed file system has been realized with a coordinating function for access to files in this file system by internal processes running distributed or not distributed processes on Component Computers <highlight><bold>6</bold></highlight>. Communication of these processes takes place via the first Interface Element <highlight><bold>7</bold></highlight> located between Component Computers <highlight><bold>6</bold></highlight>. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Among the processes there are processes which are accomplished by first Function Components <highlight><bold>10</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 4</cross-reference>) and which realizee a strategy function by which decisions regarding data placement and regarding the time of their retrieval and storage in the disk memory subsystem are triggered. These processes will be abbreviated as VLP (Virtual Library Process) below. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> Among the above-mentioned processes, there are furthermore processes which are accomplished by second Function Components <highlight><bold>11</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 4</cross-reference>) and which realize access from the host units to Disk Memory Subsystem <highlight><bold>3</bold></highlight>. These processes will be abbreviated as ICP (Internal Channel Process) below. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Finally, among the above-mentioned processes, there are processes which are accomplished by third Function Components <highlight><bold>12</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 4</cross-reference>) and which control the data transfer between Disk Memory Subsystem <highlight><bold>3</bold></highlight> and Cassette Drives <highlight><bold>2</bold></highlight>. These processes will be abbreviated as IDP (Internal Device Process) below. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Disk Memory Subsystem <highlight><bold>3</bold></highlight> in <cross-reference target="DRAWINGS">FIGS. 2 and 4</cross-reference> has been realized on the basis of a RAID system (Redundant Array of Independent Disks) such as RAID<highlight><bold>1</bold></highlight> and/or RAID<highlight><bold>3</bold></highlight>. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows an overview of the software architecture realized on the Virtual Tape Library System (VTLS) shown in <cross-reference target="DRAWINGS">FIGS. 2 and 4</cross-reference>. It is based on a systems basis with communication mechanisms and operator interfaces. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> In accordance with the sample implementation, especially as in <cross-reference target="DRAWINGS">FIG. 4, a</cross-reference> UNIX system serves as a systems basis. For joining the Component Computers <highlight><bold>6</bold></highlight> to the rest of the system, Standard Peripheral Channel Connectors (SPCC) were used. The SPCCs are a Siemens product (e.g., Channel Adapter 3970). They are special high-performance adapters which bring about the physical connection with the appropriate individual system components. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> On this systems basis, UNIX downward-compatibly establishes the distributed file system with a file block structure suitable for tape operation. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> At the next higher stratum, the various processes ICP, IDP and VLP have been realized parallel of one another. VLP manages the cache catalog and coordinates file access. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> At the top stratum, the host connections, magnetic tape connections (connections to the cassette drives) and robot connections (connections to the tape storage units) have been realized. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a typical hardware-software configuration of a VTLS containing five Component Computers <highlight><bold>6</bold></highlight>. Each Component Computer <highlight><bold>6</bold></highlight> contains an SPCC system as a basis for the software strata imposed over it (<cross-reference target="DRAWINGS">FIG. 3</cross-reference>). For greater protection against failure, the External Connections <highlight><bold>14</bold></highlight> have been doubled. This permits ICP<highlight><bold>1</bold></highlight> and ICP<highlight><bold>2</bold></highlight> to take on each other&apos;s tasks. The VLP runs on an autonomous Component Computer <highlight><bold>6</bold></highlight>. If this Component Computer <highlight><bold>6</bold></highlight> fails, the VLP is restarted on another Component Computer <highlight><bold>6</bold></highlight>, such as IDP<highlight><bold>1</bold></highlight>. Since all of the data regarding the processing status of the Virtual Volumes and the physical cassettes are stored in the failsafe Disk Memory Subsystem <highlight><bold>3</bold></highlight>, the restarted process is able to continue the interrupted process after a brief delay. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> The channel connections to Hosts <highlight><bold>1</bold></highlight> may be realized by failsafe networked ESCON channel connections (Enterprise Systems CONnection). ESCON technology is an IBM product. </paragraph>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">Patent claims </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. Backup and archiving system by means of tape cassettes for data processing systems with 
<claim-text>at least one Data Port (<highlight><bold>15</bold></highlight>) for receiving data to be stored in memory, </claim-text>
<claim-text>at least one Cassette Drive (<highlight><bold>2</bold></highlight>) for tape cassettes, </claim-text>
<claim-text>one Interface Unit (<highlight><bold>5</bold></highlight>) for connecting at least one data port with at least one Cassette Drive (<highlight><bold>2</bold></highlight>), comprising a Disk Memory Subsystem (<highlight><bold>3</bold></highlight>) with at least one Disk Memory Unit (<highlight><bold>4</bold></highlight>) for temporary storage of data to be secured on the tape cassettes, characterized by </claim-text>
<claim-text>a second Function Unit (<highlight><bold>11</bold></highlight>) designed to transfer the data received by at least one Data Port (<highlight><bold>15</bold></highlight>) to the Disk Memory Subsystem (<highlight><bold>3</bold></highlight>), </claim-text>
<claim-text>a third Function Unit (<highlight><bold>12</bold></highlight>) designed to transfer the data temporarily stored on the Disk Memory Subsystem (<highlight><bold>3</bold></highlight>) to at least one Cassette Drive (<highlight><bold>2</bold></highlight>), and </claim-text>
<claim-text>a first Function Unit (<highlight><bold>10</bold></highlight>) designed to monitor the second and third Function Unit (<highlight><bold>11</bold></highlight>, <highlight><bold>12</bold></highlight>) in order to check the processing and the access to the Disk Memory Subsystem (<highlight><bold>3</bold></highlight>), </claim-text>
<claim-text>wherein at least one Component Computer (<highlight><bold>6</bold></highlight>) each is being provided for the first, second and third Function Unit (<highlight><bold>10</bold></highlight>, <highlight><bold>11</bold></highlight>, <highlight><bold>12</bold></highlight>). </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. Backup and archiving system in accordance with <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, characterized by the fact that for each Data Port (<highlight><bold>15</bold></highlight>) and/or each Cassette Drive (<highlight><bold>2</bold></highlight>) one Component Computer (<highlight><bold>6</bold></highlight>) is provided which may be separately accessed by the first Function Unit (<highlight><bold>10</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. Backup and archiving system in accordance with <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, characterized by the fact that the third Function Unit (<highlight><bold>12</bold></highlight>) comprises several Component Computers (<highlight><bold>6</bold></highlight>), each of the Component Computers (<highlight><bold>6</bold></highlight>) being connected to a Cassette Drive (<highlight><bold>2</bold></highlight>) for tape cassettes, and each Component Computer (<highlight><bold>6</bold></highlight>) separately accessible by the first Function Unit (<highlight><bold>10</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. Backup and archiving system in accordance with <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> or <highlight><bold>3</bold></highlight>, characterized by the fact that each Component Computer (<highlight><bold>6</bold></highlight>) comprises a microprocessor and a working storage as well as a bus system. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. Backup and archiving system in accordance with <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> or <highlight><bold>2</bold></highlight>, characterized by the fact that the connection between the second and third Function Unit (<highlight><bold>11</bold></highlight>, <highlight><bold>12</bold></highlight>) and the Disk Memory Subsystem (<highlight><bold>3</bold></highlight>) is realized via a Bus System (<highlight><bold>8</bold></highlight>) in an FC and/or an SCSI connection structure. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. Backup and archiving system in accordance with any of the foregoing claims, characterized by the fact that, for mutual substitute computer service, multiple connectors are provided between several Component Computers (<highlight><bold>6</bold></highlight>) and the CassetteDrives (<highlight><bold>2</bold></highlight>) and/or the Hosts (<highlight><bold>1</bold></highlight>) submitting data at the Data Ports (<highlight><bold>15</bold></highlight>). </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. Backup and archiving system in accordance with any of the foregoing claims, characterized by the fact that a multiple layout is provided of at least one of the hardware components required for access to Disk Memory Subsystem (<highlight><bold>3</bold></highlight>), for communication regarding access to Disk Memory Subsystem (<highlight><bold>3</bold></highlight>), and for communication regarding management tasks between the Component Computers (<highlight><bold>6</bold></highlight>).</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>3</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002405A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002405A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002405A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002405A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
