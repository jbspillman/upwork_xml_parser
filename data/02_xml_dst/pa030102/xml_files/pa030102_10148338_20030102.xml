<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002746A1-20030102-D00000.TIF SYSTEM "US20030002746A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00001.TIF SYSTEM "US20030002746A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00002.TIF SYSTEM "US20030002746A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00003.TIF SYSTEM "US20030002746A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00004.TIF SYSTEM "US20030002746A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00005.TIF SYSTEM "US20030002746A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00006.TIF SYSTEM "US20030002746A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00007.TIF SYSTEM "US20030002746A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00008.TIF SYSTEM "US20030002746A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00009.TIF SYSTEM "US20030002746A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00010.TIF SYSTEM "US20030002746A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00011.TIF SYSTEM "US20030002746A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030002746A1-20030102-D00012.TIF SYSTEM "US20030002746A1-20030102-D00012.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002746</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10148338</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020529</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2000-295767</doc-number>
</priority-application-number>
<filing-date>20000928</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06T005/00</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>H04N005/217</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>382</class>
<subclass>255000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>382</class>
<subclass>106000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>348</class>
<subclass>208400</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Image creating device and image creating method</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Yosuke</given-name>
<family-name>Kusaka</family-name>
</name>
<residence>
<residence-non-us>
<city>Yokohama-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>Oliff &amp; Berridge</name-1>
<name-2></name-2>
<address>
<address-1>P O Box 19928</address-1>
<city>Alexandria</city>
<state>VA</state>
<postalcode>22320</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
<international-conventions>
<pct-application>
<document-id>
<doc-number>PCT/JP01/08423</doc-number>
<document-date>20010927</document-date>
<country-code>WO</country-code>
</document-id>
</pct-application>
</international-conventions>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">An image-capturing unit generates an image signal corresponding to an image of a subject formed by a photographing optical system. A point spread function generating unit generates varying point spread functions corresponding to various distances based upon two-dimensional distance distribution information indicating the two-dimensional distance distribution of the subject detected by a distance detection unit and an image blur signal indicating an image blur occurring during the exposure period which is detected by a blur detection unit. An image repair unit divides the image signal into partial images based upon the distance distribution information, executes image processing to repair the blur in the individual partial images by using the point spread functions corresponding to the various distances and creates a whole image by synthesizing the partial images in which the blur has been repaired. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The disclosure of the following priority application is herein incorporated by reference: </paragraph>
<paragraph id="P-0002" lvl="2"><number>&lsqb;0002&rsqb;</number> Japanese Patent Application No. 2000-295767 filed Sep. 28, 2000 </paragraph>
<section>
<heading lvl="1">TECHNICAL FIELD </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The present invention relates to an image generating apparatus and an image generating method to be adopted to repair an image, the quality of which has become poorer due to unsteady hand movement or the like, to a blur-free state, through image processing implemented on the image. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND ART </heading>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> There is a technology known in the related art for repairing an image, the quality of which has deteriorated due to an unsteady hand movement (hereafter referred to as a blurred image) and correcting the original image to a blur-free state. For instance, the image generating apparatus disclosed in Japanese Laid-Open Patent Publication No. S62-127976 expresses the extent of image quality deterioration caused by an unsteady hand movement during the photographing operation through a point spread function and repairs the blurred image based upon the point spread function. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> However, the desired results are not always achieved by repairing an image obtained through an actual image-capturing operation with the image generating apparatus described above. For instance, blurs in an image having a plurality of objects present over varying distances within a single image plane and in a close-up image cannot be repaired to a satisfactory degree. </paragraph>
</section>
<section>
<heading lvl="1">DISCLOSURE OF THE INVENTION </heading>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> An object of the present invention is to provide an image generating apparatus and an image generating method that enable a successful repair on a blurred image even when the image contains a plurality of subjects present over varying ranges within the image plane or the image is a close-up image. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> In order to achieve the object described above, an image generating apparatus according to the present invention comprises an image-capturing unit that captures an image of a subject formed on an image plane by a photographing optical system and generates an image signal, a distance detection unit that detects distance of the subject on the image plane and generates distance information, a blur detection unit that detects a blur occurring during the image-capturing operation at the photographing optical system and generates a blur signal, a point spread function generating unit that generates a point spread function corresponding to the distance based upon the distance information and the blur signal and an image repair unit that forms a repaired image by repairing the image signal using the point spread function. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> It is desirable that the distance detection unit detects two-dimensional distance distribution of the subject, divides the subject distance into a plurality of distance zones based upon distance distribution information and calculates a plurality of sets of distance data each representing one of the distance zones. The point spread function generating unit then generates a plurality of point spread functions in correspondence to the plurality of sets of distance data. The image repair unit, in turn, should divide the image signal into a plurality of partial images each corresponding to one of the distance zones, form a plurality of repaired partial images by repairing each partial image with the point spread function corresponding to the specific distance data and form a repaired image by synthesizing the plurality of repaired partial images. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> The object described above may instead be achieved through an image generating apparatus according to the present invention which comprises an information readout unit that reads out image information obtained by photographing a subject, distance information indicating the distance of the subject during the photographing operation and blur information indicating a blur occurring during the photographing operation from a recording medium having recorded therein the image information, the distance information and the blur information, a point spread function generating unit that generates a point spread function in correspondence to the distance based upon the distance information and the blur information and an image repair unit that forms a repaired image by repairing the image information with the point spread function. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> In order to achieve the object described above, in the image generating method according to the present invention, an image of a subject is formed on a specific image plane, an image signal is generated by capturing the image of the subject formed on the image plane, distance information is generated by detecting the distance of the subject on the image plane, a blur signal is generated by detecting a blur occurring during the image-capturing operation, a point spread function is generated in correspondence to the distance based upon the distance information and the blur signal and a repaired image is formed by repairing the image signal with the point spread function. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The blur detection unit may detect an angular movement of the photographing optical system through which the photographing optical system becomes displaced around the two axes each extending perpendicular to the optical axis. Alternatively, the blur detection unit may detect a parallel movement through which the photographing optical system becomes shifted parallel to the optical axis. Furthermore, the blur detection unit may detect both an angular movement of the photographing optical system through which it becomes displaced around the two axes perpendicular to the optical axis and a parallel movement through which the photographing optical system becomes shifted parallel to the optical axis to generate a blur signal based upon the angular movement and the parallel movement, instead. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> It is desirable that the information readout unit be capable of electronically reading out the image information, the distance information and the blur information recorded in the recording medium. As an alternative, the information readout unit may read out the image information, the distance information and the blur information recorded on silver halide film with a scanner. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> As described above, in the image generating apparatus and the image generating method according to the present invention, the distance or the distance distribution of the subject on the image plane is detected and a point spread function (point spread functions) corresponding to the distance or the distance distribution is generated. Since a blurred image is repaired by utilizing the optimal point spread function corresponding to the distance or the distance distribution, the blurred image can be repaired successfully. In particular, the present invention is highly effective in repairing a blur in an image obtained through a close-up photographing operation which tends to be greatly affected by an unsteady hand movement.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram of the structure assumed in an embodiment of the image generating apparatus according to the present invention; </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram of the structure assumed in a digital camera adopting the present invention; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates the principle of the distance detection; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates the principle of the distance detection; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a block diagram showing the structure of the CPU and its periphery; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows the waveform of an angular speed signal; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> shows the waveform of a relative angle signal; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates the two-dimensional state of the relative angle signal; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows coordinates taken on the photographic image plane; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> shows the frequencies with which various distance values are detected on the photographic image plane; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> illustrates the relationship between the angular movement and the image blur manifesting in correspondence to the distance; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> shows an example of the point spread function; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> illustrates the blurred image repair processing implemented in correspondence to distance; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> presents a flowchart of the CPU operation processing; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> presents a flowchart of the CPU operation processing; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> presents a flowchart of the CPU operation processing; and </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> illustrates the relationship between the parallel movement and the image blur manifesting in correspondence to the distance.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">BEST MODE FOR CARRYING OUT THE INVENTION </heading>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> The extent to which an image becomes blurred due to an unsteady hand movement or the like varies depending upon the subject distance, and the blur becomes drastically pronounced as the distance of the subject becomes shorter. In the blurred image repair technology achieved in the related art, a uniform hypothetical point spread function (blurring extent) is used to repair a blurred image without taking into consideration the subject distance. For this reason, a blur in an image having a plurality of objects present over varying distances within a single image plane or in a close-up image cannot be fully repaired. Accordingly, in the image generating apparatus according to the present invention, a blurred image is repaired based upon a point spread function set in conformance to the distance. The term &ldquo;point spread function&rdquo; used in this context refers to a function that indicates the intensity distribution of point images blurred by a movement. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> presents a block diagram illustrating the concept of the image generating apparatus achieved in an embodiment of the present invention. An image generating apparatus <highlight><bold>1</bold></highlight> according to the present invention comprises a photographing optical system <highlight><bold>3</bold></highlight>, an image-capturing unit <highlight><bold>4</bold></highlight>, a distance detector <highlight><bold>5</bold></highlight>, a blur detector <highlight><bold>6</bold></highlight>, a point spread function generating unit <highlight><bold>7</bold></highlight> and an image repair unit <highlight><bold>8</bold></highlight>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The photographing optical system <highlight><bold>3</bold></highlight> forms an image of a subject <highlight><bold>2</bold></highlight> on a specific image plane. The image-capturing unit <highlight><bold>4</bold></highlight> is constituted of a solid image-capturing element such as a CCD or a CMOS that captures the image of subject <highlight><bold>2</bold></highlight> formed on the specific image plane and a control circuit for the solid image-capturing element. The control circuit controls the length of exposure time (the length of time over which electrical charges are stored) to elapse at the solid image-capturing element in correspondence to the brightness level of the subject image and generates an image signal corresponding to the image of the subject <highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> The distance detector <highlight><bold>5</bold></highlight> is constituted of a distance detection device of the known art. The distance detector <highlight><bold>5</bold></highlight> detects a two-dimensional distance distribution of the subject <highlight><bold>2</bold></highlight> formed on the specific image plane and thus generates distance distribution information. The blur detector <highlight><bold>6</bold></highlight> detects the movement of the photographing optical system <highlight><bold>3</bold></highlight> occurring during an image-capturing operation at the image-capturing unit <highlight><bold>4</bold></highlight> and generates a blur signal which changes over time. The blur detector <highlight><bold>6</bold></highlight> may be constituted of, for instance, an angular speed sensor. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> The point spread function generating unit <highlight><bold>7</bold></highlight> generates a point spread function which changes in correspondence to the distance, based upon the distance distribution information with regard to the subject <highlight><bold>2</bold></highlight> and the blur signal input from the distance detector <highlight><bold>5</bold></highlight> and the blur detector <highlight><bold>6</bold></highlight> respectively. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The image repair unit <highlight><bold>8</bold></highlight> executes image processing on the image signal (the blurred image signal) generated by the image-capturing unit <highlight><bold>4</bold></highlight>, the quality of which has been lowered by an unsteady hand movement, in conformance to the distance distribution information by using the point spread function generated by the point spread function generating unit <highlight><bold>7</bold></highlight> and thus generates an image signal with its image quality, which has been compromised by the unsteady hand movement, restored. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram of the structure assumed in a digital still camera <highlight><bold>10</bold></highlight> adopting the image generating apparatus according to the present invention. The following is a detailed explanation of the image generating apparatus and the image generating method according to the present invention, given in reference to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> A subject image formed by a photographic lens <highlight><bold>11</bold></highlight> undergoes a photoelectric conversion at a charge-storage type solid image-capturing element <highlight><bold>12</bold></highlight> such as a CCD and, as a result, an image signal is output. The image signal is converted to a digital image signal at an A/D conversion circuit <highlight><bold>18</bold></highlight> and is stored in a volatile memory <highlight><bold>19</bold></highlight> which may be a RAM. The image constituted of the image signal stored in the memory <highlight><bold>19</bold></highlight> is displayed at a liquid crystal display device <highlight><bold>20</bold></highlight> and the image signal is also recorded into a nonvolatile recording medium <highlight><bold>21</bold></highlight> such as a compact flash memory. A CPU (central processing control unit) <highlight><bold>17</bold></highlight> controls the image-capturing operation, the storage operation, the display operation and the recording operation described above. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> An angular speed sensor V<highlight><bold>13</bold></highlight> and an angular speed sensor H<highlight><bold>14</bold></highlight> are blur detection sensors provided to detect movement (vibration) of the digital still camera <highlight><bold>10</bold></highlight>. The angular speed sensor V<highlight><bold>13</bold></highlight> and the angular speed sensor H<highlight><bold>14</bold></highlight> perform real-time detection of the angular speeds around two axes both extending perpendicular to the optical axis of the photographic lens <highlight><bold>11</bold></highlight> and also extending perpendicular to each other. Their detection outputs are provided to the CPU <highlight><bold>17</bold></highlight> as angular speed signals. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> A distance sensor <highlight><bold>15</bold></highlight> is a sensor provided to detect the two-dimensional distance distribution of the subject. The distance sensor <highlight><bold>15</bold></highlight> is to be described in detail later. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> A shutter release button <highlight><bold>16</bold></highlight>, which is a member operated by the photographer to take a photograph, generates a shutter release signal in response to the photographer operation. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> It is to be noted that an optical viewfinder (not shown) is provided at the digital still camera <highlight><bold>10</bold></highlight>. The photographer is able to observe the subject through the optical viewfinder (not shown). </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The CPU <highlight><bold>17</bold></highlight> calculates the extent to which the photographic lens <highlight><bold>11</bold></highlight> is displaced during the image-capturing operation based upon the angular speed signals provided from the angular speed sensor V<highlight><bold>13</bold></highlight> and the angular speed sensor H<highlight><bold>14</bold></highlight>. The CPU <highlight><bold>17</bold></highlight> also obtains the subject distance distribution information detected by the distance sensor <highlight><bold>15</bold></highlight>. Based upon the blur signal and the distance distribution information, the CPU <highlight><bold>17</bold></highlight> generates point spread functions in correspondence to various distances. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> In addition, it implements the image repair processing to be detailed later on the blurred image signal stored in the memory <highlight><bold>19</bold></highlight> by using these point spread functions. The repaired image signal is then stored back into the memory <highlight><bold>19</bold></highlight>. The repaired image signal is displayed at the liquid crystal display device <highlight><bold>20</bold></highlight> in response to the command signal from the CPU <highlight><bold>17</bold></highlight> and is also recorded into the recording medium <highlight><bold>21</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Now, the distance sensor <highlight><bold>15</bold></highlight> is explained in detail. <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows the structure of the distance sensor <highlight><bold>15</bold></highlight>. The distance sensor <highlight><bold>15</bold></highlight> detects the subject distance distribution information indicating the distance distribution of the subject when the shutter release signal is input from the shutter release button <highlight><bold>16</bold></highlight> to the CPU <highlight><bold>17</bold></highlight>. In this embodiment, the distance sensor <highlight><bold>15</bold></highlight> receives the subject light flux through an optical system provided separately from the photographing optical system <highlight><bold>3</bold></highlight>. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> An image of the subject formed by a range finding lens <highlight><bold>42</bold></highlight> is captured by a two-dimensional image sensor <highlight><bold>44</bold></highlight> provided rearward relative to the range finding lens <highlight><bold>42</bold></highlight> over a distance E from the range finding lens <highlight><bold>42</bold></highlight>. The two-dimensional image sensor <highlight><bold>44</bold></highlight> generates image data of the subject image. In addition, an image of the subject formed by a range finding lens <highlight><bold>43</bold></highlight> achieving optical characteristics identical to those of the range finding lens <highlight><bold>42</bold></highlight> is captured by a two-dimensional image sensor <highlight><bold>45</bold></highlight> provided rearward relative to the range finding lens <highlight><bold>43</bold></highlight> over the distance E from the range finding lens <highlight><bold>43</bold></highlight> and image data of the subject image are generated by the two-dimensional image sensor <highlight><bold>45</bold></highlight>. It is to be noted that the range finding lens <highlight><bold>42</bold></highlight> and the range finding lens <highlight><bold>43</bold></highlight> are set apart over a baseline length B from each other. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows the relationship between a point <highlight><bold>46</bold></highlight> set over an unknown distance d from the range finding lenses <highlight><bold>42</bold></highlight> and <highlight><bold>43</bold></highlight> and image forming points <highlight><bold>47</bold></highlight> and <highlight><bold>48</bold></highlight> on the two-dimensional image sensors <highlight><bold>44</bold></highlight> and <highlight><bold>45</bold></highlight> corresponding to the point <highlight><bold>46</bold></highlight>. The distance L between the images formed at the image forming points <highlight><bold>47</bold></highlight> and <highlight><bold>48</bold></highlight> is measured based upon the image data generated by the two-dimensional image sensors <highlight><bold>44</bold></highlight> and <highlight><bold>45</bold></highlight>. The distance d to the point <highlight><bold>46</bold></highlight> can be determined through the formula in (expression 1) based upon the principle of trigonometric range measurement.</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>d&equals;B&times;E/</italic></highlight>(<highlight><italic>L&minus;B</italic></highlight>)&emsp;&emsp;(expression 1)</in-line-formula></paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> The image plane is divided into a plurality of areas, e.g., 5&times;10 areas, and the distances to these areas are measured by scanning the range finding points present in the individual areas. As a result, the two-dimensional distance distribution of the subject can be detected. The distance distribution of the subject in the photographic image plane is detected by correlating the image signal from the solid image-capturing element <highlight><bold>12</bold></highlight> with the image data generated by the two-dimensional image sensors <highlight><bold>44</bold></highlight> and <highlight><bold>45</bold></highlight>. It is to be noted that if the size of the solid image-capturing element <highlight><bold>12</bold></highlight> which generates the image signal is different from the size of the two-dimensional image sensors <highlight><bold>44</bold></highlight> and <highlight><bold>45</bold></highlight> provided for range finding, the image signal and the image data should be made to correspond to each other through reduction/enlargement, shifting or the like. The subject distance distribution information thus detected is transmitted to the CPU <highlight><bold>17</bold></highlight>. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> presents a block diagram showing the structure assumed in the CPU <highlight><bold>17</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> and its periphery in further detail. Now, in reference to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the processing executed by the CPU <highlight><bold>17</bold></highlight> to repair an image signal that has become degraded due to a movement (vibration) is explained in detail. It is to be noted that the CPU <highlight><bold>17</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> comprises an integrating calculation unit <highlight><bold>31</bold></highlight>, a blur distribution storage unit <highlight><bold>32</bold></highlight>, a photographing control unit <highlight><bold>33</bold></highlight>, a distance distribution calculation unit <highlight><bold>34</bold></highlight>, a point spread function calculation unit <highlight><bold>35</bold></highlight> and an image repair unit <highlight><bold>38</bold></highlight>. In addition, the memory <highlight><bold>19</bold></highlight> is constituted of a raw image memory <highlight><bold>36</bold></highlight> and a repaired image memory <highlight><bold>37</bold></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> Angular speed signals are generated at the angular speed sensor V<highlight><bold>13</bold></highlight> and the angular speed sensor H<highlight><bold>14</bold></highlight> in response to an unsteady hand movement or the like to which the digital still camera <highlight><bold>10</bold></highlight> is subjected. <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows a one-dimensional angular speed signal generated when the digital still camera <highlight><bold>10</bold></highlight> is subjected to an unsteady hand movement represented by a sine wave. This angular speed signal undergoes A/D conversion over predetermined sampling intervals and it thus is converted to digital data. The angular speed signal converted to digital data is then converted to a relative angle signal through an integration operation executed at the integrating calculation unit <highlight><bold>31</bold></highlight>. The relative angle signal indicates a relative angular displacement obtained by excluding the integration constant. The relative angle signal thus calculated is transmitted to the blur distribution storage unit <highlight><bold>32</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 7</cross-reference> shows the relative angle signal obtained by integrating the relative angular speed signal shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> A shutter release signal is provided to the photographing control unit <highlight><bold>33</bold></highlight> and the distance sensor <highlight><bold>15</bold></highlight> through the shutter release button <highlight><bold>16</bold></highlight> in response to an operation of the shutter release button <highlight><bold>16</bold></highlight> by the photographer. Upon receiving the shutter release signal, the photographing control unit <highlight><bold>33</bold></highlight> implements control so as to execute an exposure operation at the solid image-capturing element <highlight><bold>12</bold></highlight> over the exposure period set in conformance to the subject brightness, the sensitivity of the solid image-capturing element <highlight><bold>12</bold></highlight> and the aperture value at the photographic lens <highlight><bold>11</bold></highlight>. In addition, the photographing control unit <highlight><bold>33</bold></highlight> transmits an exposure timing signal to the blur distribution storage unit <highlight><bold>32</bold></highlight>. In response to the exposure timing signal, the blur distribution storage unit <highlight><bold>32</bold></highlight> stores in memory the relative angle signals generated during the exposure period. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates the two-dimensional state of the data constituted of the relative angle signal stored in the blur distribution storage unit <highlight><bold>32</bold></highlight> as described above. The data values representing the relative angle sampled at the predetermined time intervals during the exposure period are indicated by the filled circles. In <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, &thgr;x represents the angle around the X axis and &thgr;y represents the angle around the Y axis. It is to be noted that the X axis and the Y axis are defined so as to intersect each other perpendicularly in a photographic image plane <highlight><bold>41</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. In addition, both the X axis and the Y axis extend perpendicular to the optical axis. The total number of times the relative angle is sampled during the exposure period is N and data obtained from the nth sampling are indicated as (&thgr;xn, &thgr;yn) . The conversion is executed by ensuring that the average of the N sets of relative angle data sampled during the exposure period is (0, 0). </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> In response to the shutter release signal, the distance sensor <highlight><bold>15</bold></highlight> measures the distance distribution of the subject to be photographed and provides it to the distance distribution calculation unit <highlight><bold>34</bold></highlight>. Based upon the two-dimensional distance distribution that has been received, the distance distribution calculation unit <highlight><bold>34</bold></highlight> prepares a histogram such as that shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> indicating the frequencies with which various distance values appear in the photographic image plane. By using this histogram, the subject distances ranging from a small distance to an infinite distance are divided into a plurality of distance zones in correspondence to the frequencies with which those distances manifest. Then, distance data indicating values each representing one of the divided distance zones are selected. In <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, the subject distances are divided into distance zones Z<highlight><bold>1</bold></highlight>, Z<highlight><bold>2</bold></highlight>, Z<highlight><bold>3</bold></highlight> and Z<highlight><bold>4</bold></highlight> respectively represented by distance data d<highlight><bold>1</bold></highlight>, d<highlight><bold>2</bold></highlight>, d<highlight><bold>3</bold></highlight> and d<highlight><bold>4</bold></highlight>. In addition, the distance distribution calculation unit <highlight><bold>34</bold></highlight> divides the image signal into a plurality of partial images in correspondence to the divided distance zones and obtains position information indicating the positions of the partial images. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> At the point spread function calculation unit <highlight><bold>35</bold></highlight>, the relative angle signal (&thgr;xn, &thgr;yn) stored in the blur distribution storage unit <highlight><bold>32</bold></highlight> is converted to a signal (Xn, Yn) indicating the extent of image blur manifesting in the image plane based upon the distance data obtained by the distance distribution calculation unit <highlight><bold>34</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 11</cross-reference> illustrates the principle of the conversion from the relative angle signal to the image blur signal, which is implemented in correspondence to the distance. For purposes of simplification, the photographing optical system is shown as a single lens <highlight><bold>51</bold></highlight>. The focal length of the lens <highlight><bold>51</bold></highlight> is f. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Let us consider a situation in which the lens <highlight><bold>51</bold></highlight> has tilted by an angle &thgr;y around the y axis relative to the center <highlight><bold>55</bold></highlight> of an image plane <highlight><bold>54</bold></highlight>. It is assumed that points <highlight><bold>52</bold></highlight> and <highlight><bold>53</bold></highlight> are set on the optical axis over distances d<highlight><bold>1</bold></highlight> and d<highlight><bold>2</bold></highlight> respectively from the image plane <highlight><bold>54</bold></highlight>. Reference numbers <highlight><bold>56</bold></highlight> and <highlight><bold>57</bold></highlight> respectively indicate the image points on the image plane corresponding to the points <highlight><bold>52</bold></highlight> and <highlight><bold>53</bold></highlight>. The extents of image blur occurring with regard to the points <highlight><bold>52</bold></highlight> and <highlight><bold>53</bold></highlight> along the x axis on the image plane are equal to distances X<highlight><bold>1</bold></highlight> and X<highlight><bold>2</bold></highlight> of the image points <highlight><bold>56</bold></highlight> and <highlight><bold>57</bold></highlight> from the image plane center <highlight><bold>55</bold></highlight> respectively. The extents X<highlight><bold>1</bold></highlight> and X<highlight><bold>2</bold></highlight> to which the images at the points <highlight><bold>52</bold></highlight> and <highlight><bold>53</bold></highlight> become blurred along the x axis on the image plane are respectively calculated through the following formulae in (expression 2).</paragraph>
<paragraph lvl="0"><in-line-formula>X<highlight><bold>1</bold></highlight>&equals;d<highlight><bold>1</bold></highlight>&times;<highlight><italic>f&times;</italic></highlight>tan &thgr;y/(d<highlight><bold>1</bold></highlight>&minus;<highlight><italic>f</italic></highlight>)</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>X<highlight><bold>2</bold></highlight>&equals;d<highlight><bold>2</bold></highlight>&times;<highlight><italic>f&times;</italic></highlight>tan &thgr;y/(d<highlight><bold>2</bold></highlight>&minus;<highlight><italic>f</italic></highlight>)&emsp;&emsp;(expression 2)</in-line-formula></paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> It is to be noted that the extents Y<highlight><bold>1</bold></highlight> and Y<highlight><bold>2</bold></highlight> of image blur manifesting along the y axis, too, can be calculated through a similar process. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> As (expression 2) indicates, the factor of d/(d&minus;f) changes more drastically as the value of the distance d becomes smaller, i.e., as the distance becomes shorter. For this reason, the extent of blurring changes more dramatically as the subject is set closer when the digital camera undergoes a given degree of angular displacement (tilt). </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Using the formulae in (expression 2), the point spread function calculation unit <highlight><bold>35</bold></highlight> converts the relative angle signals (&thgr;xn, &thgr;yn) such as those shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> to image blur signals (X<highlight><bold>1</bold></highlight>n, Y<highlight><bold>1</bold></highlight>n), (X<highlight><bold>2</bold></highlight>n, Y<highlight><bold>2</bold></highlight>n) . . . in correspondence to the distance data d<highlight><bold>1</bold></highlight>, d<highlight><bold>2</bold></highlight> . . . respectively. Then, the discrete image blur signals (X<highlight><bold>1</bold></highlight>n, Y<highlight><bold>1</bold></highlight>n), (X<highlight><bold>2</bold></highlight>n, Y<highlight><bold>2</bold></highlight>n) . . . are converted to continuous point spread functions h<highlight><bold>1</bold></highlight> (x, y) , h<highlight><bold>2</bold></highlight> (x, y) . . . shown in <cross-reference target="DRAWINGS">FIG. 12</cross-reference> through smoothing or the like. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> The image repair unit <highlight><bold>38</bold></highlight> reads out the image signal having been degraded by a hand movement from the raw image memory <highlight><bold>36</bold></highlight> where it has been stored. This image information is expressed as functions g<highlight><bold>1</bold></highlight> (x, y), g<highlight><bold>2</bold></highlight> (x, y) . . . The image repair processing is implemented on the functions g<highlight><bold>1</bold></highlight> (x, y), g<highlight><bold>2</bold></highlight> (x, y) . . . of the degraded image signal by using the point spread functions h<highlight><bold>1</bold></highlight> (x, y), h<highlight><bold>2</bold></highlight> (x , y ) . . . Furthermore, a repaired image signal is generated through image synthesis processing executed in correspondence to the individual distance zones (z<highlight><bold>1</bold></highlight>, z<highlight><bold>2</bold></highlight> . . . ) in the image plane and the repaired image signal is then stored into the repaired image memory <highlight><bold>37</bold></highlight>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> illustrates the concept of the image repair processing described above. First, position information <highlight><bold>62</bold></highlight> indicating the positions of the plurality of partial images obtained by dividing an image <highlight><bold>61</bold></highlight> having become degraded due to a blur into a plurality of portions in correspondence to the individual distance zones (Z<highlight><bold>1</bold></highlight>, Z<highlight><bold>2</bold></highlight>, Z<highlight><bold>3</bold></highlight> and Z<highlight><bold>4</bold></highlight>) and then identified is obtained. Next, the image <highlight><bold>61</bold></highlight> having become degraded due to a blur individually undergoes image repair processing implemented by utilizing each of the point spread functions h<highlight><bold>1</bold></highlight> (x , y), h<highlight><bold>2</bold></highlight> (x, y), h<highlight><bold>3</bold></highlight> (x, y) and h<highlight><bold>4</bold></highlight> (x, y) determined in correspondence to the distance data (d<highlight><bold>1</bold></highlight>, d<highlight><bold>2</bold></highlight>, d<highlight><bold>3</bold></highlight> and d<highlight><bold>4</bold></highlight>) representing the distance zones (Z<highlight><bold>1</bold></highlight>, Z<highlight><bold>2</bold></highlight>, Z<highlight><bold>3</bold></highlight> and Z<highlight><bold>4</bold></highlight>) respectively. From the repaired images, partial images <highlight><bold>63</bold></highlight>, <highlight><bold>64</bold></highlight>, <highlight><bold>65</bold></highlight> and <highlight><bold>66</bold></highlight> corresponding to varying distances are extracted based upon the image position information <highlight><bold>62</bold></highlight>. Finally, the partial images <highlight><bold>63</bold></highlight>, <highlight><bold>64</bold></highlight>, <highlight><bold>65</bold></highlight> and <highlight><bold>66</bold></highlight> are synthesized to generate a repaired image <highlight><bold>67</bold></highlight>. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Now, the concept of the image repair processing implemented by using the individual point spread functions h<highlight><bold>1</bold></highlight> (x, y), h<highlight><bold>2</bold></highlight> (x, y) . . . is explained. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> A function f (x, y) represents the image information of a blur-free image, a function g (x, y) represents the image information of an image having become degraded due to a blur and a point distribution function h (x, y) represents the image information of a point image which has become blurred due to a movement (vibration). The following relationship in (expression 3) is achieved by these functions f (x, y), g(x, y) and h(x, y).</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>f</italic></highlight>(<highlight><italic>x, y</italic></highlight>)*<highlight><italic>h</italic></highlight>(<highlight><italic>x, y</italic></highlight>)&equals;<highlight><italic>g</italic></highlight>(<highlight><italic>x, y</italic></highlight>)&emsp;&emsp;(expression 3)</in-line-formula></paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> &ldquo;*&rdquo; in the expression above is a symbol that indicates a convolution operation. When the two sides of (expression 3) are converted through a Fourier transform, the equation in (expression 4) is true in the frequency range:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>F</italic></highlight>(<highlight><italic>u, v</italic></highlight>)&times;<highlight><italic>H</italic></highlight>(<highlight><italic>u, v</italic></highlight>)&equals;<highlight><italic>G</italic></highlight>(<highlight><italic>u, v</italic></highlight>)&emsp;&emsp;(expression 4)</in-line-formula></paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> The functions G, F and H above are obtained by Fourier transforming the functions g, f and h. u and v respectively represent the frequencies along the x direction and the y direction. By dividing the two sides of (expression 4) by H (u, v), the equation in (expression 5) is obtained.</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>F</italic></highlight>(<highlight><italic>u, v</italic></highlight>)&equals;<highlight><italic>G</italic></highlight>(<highlight><italic>u, v</italic></highlight>)/<highlight><italic>H</italic></highlight>(<highlight><italic>u, v</italic></highlight>)&emsp;&emsp;(expression 5)</in-line-formula></paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Then, by inverse Fourier transforming (expression 5), a function f (x, y) of the original information from which the blur has been eliminated is obtained as indicated in (expression 6).</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>f</italic></highlight>(<highlight><italic>x, y</italic></highlight>)&equals;<highlight><italic>S</italic></highlight>(<highlight><italic>F</italic></highlight>(<highlight><italic>u, v</italic></highlight>))&equals;<highlight><italic>S</italic></highlight>(<highlight><italic>G</italic></highlight>(<highlight><italic>u, v</italic></highlight>)/<highlight><italic>H</italic></highlight>(<highlight><italic>u, v</italic></highlight>))&emsp;&emsp;(expression 6)</in-line-formula></paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> In the expression above, S( ) indicates an inverse Fourier transform. By Fourier transforming the image function representing the image having become degraded due to a movement, dividing the resulting function by the function obtained through a Fourier transformation implemented on the blurred point spread function and then by inverse Fourier transforming the results of the division, the function of the original image containing no blur can be obtained. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Next, the processing procedure adopted in the image repair operation program executed by the CPU <highlight><bold>17</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is explained in reference to the flowcharts in FIGS. <highlight><bold>14</bold></highlight>&tilde;<highlight><bold>16</bold></highlight>. It is to be noted that the explanation is given on the assumption that the solid image-capturing element <highlight><bold>12</bold></highlight> is constituted of a CCD. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> presents a flowchart of the main program executed by the CPU <highlight><bold>17</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 15</cross-reference> presents a flowchart of the timer interrupt program executed to convert the analog angular speed signal to digital signal over the predetermined time intervals. <cross-reference target="DRAWINGS">FIG. 16</cross-reference> presents a flowchart of the shutter release interrupt program started up in response to a shutter release signal. It is to be noted that the timer interrupt processing program and the shutter release interrupt processing program in <cross-reference target="DRAWINGS">FIGS. 15 and 16</cross-reference> are executed by interrupting the execution of the main program shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> as necessary. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> The main program executed by the CPU <highlight><bold>17</bold></highlight> which is shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference> starts as the power to the digital still camera <highlight><bold>10</bold></highlight> is turned on. In step S<highlight><bold>101</bold></highlight>, the operation of the CCD <highlight><bold>12</bold></highlight> is reset and also the timer and the like are reset, thereby enabling a subsequent timer interrupt or shutter release interrupt. In step S<highlight><bold>102</bold></highlight>, the length of time over which the electrical charges are to be stored (the length of the exposure time) at the CCD <highlight><bold>12</bold></highlight> is calculated by using information (the subject brightness level, the pixel sensitivity, the aperture value and the like) required when determining the length of the exposure period. Subsequently, the processing in step S<highlight><bold>102</bold></highlight> is executed repeatedly. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The timer interrupt program shown in <cross-reference target="DRAWINGS">FIG. 15</cross-reference> which is executed over predetermined time intervals is explained. In step S<highlight><bold>201</bold></highlight>, the analog angular speed signals are converted to digital signals and the digitized data are stored into a memory (not shown). In step S<highlight><bold>202</bold></highlight>, the angular speed data including the most recent angular speed data stored in the memory are integrated to calculate a relative angle signal. The relative angle signal thus calculated is stored into the memory (not shown) in step S<highlight><bold>203</bold></highlight> before the operation makes a return. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> presents a flowchart of the shutter release interrupt program. This processing is started up as a shutter release signal is input to the CPU <highlight><bold>17</bold></highlight> in response to an operation of the shutter release button <highlight><bold>16</bold></highlight>. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> First, in step S<highlight><bold>301</bold></highlight>, the distance distribution information with regard to the subject on the photographic image plane is taken in by the distance sensor <highlight><bold>15</bold></highlight> and a distance histogram such as that shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is prepared. In addition, representative distance data (d<highlight><bold>1</bold></highlight>, d<highlight><bold>2</bold></highlight> . . . ) are calculated in correspondence to the individual distance zones (Z<highlight><bold>1</bold></highlight>, Z<highlight><bold>2</bold></highlight>, . . . ) and the calculated representative distance data are stored in memory. In step S<highlight><bold>302</bold></highlight>, the subject image formed by the photographic lens <highlight><bold>11</bold></highlight> is captured at the CCD <highlight><bold>12</bold></highlight> over the exposure period the length of which has been calculated in step S<highlight><bold>102</bold></highlight> most recently. In step S<highlight><bold>303</bold></highlight>, the image signal stored at the CCD <highlight><bold>12</bold></highlight> is read out. In step S<highlight><bold>304</bold></highlight>, the image signal that has been read out undergoes an A/D conversion, and the image signal having undergone A/D conversion, i.e., the image signal having become degraded due to blurring, is temporarily stored into the memory <highlight><bold>19</bold></highlight> in step S<highlight><bold>305</bold></highlight>. In step S<highlight><bold>306</bold></highlight>, the image signal stored in the memory <highlight><bold>19</bold></highlight> is recorded into the recording medium <highlight><bold>21</bold></highlight>. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> In step S<highlight><bold>307</bold></highlight>, the image signal is divided into partial images in correspondence to the individual distance zones (Z<highlight><bold>1</bold></highlight>, z<highlight><bold>2</bold></highlight>, . . . ). In step S<highlight><bold>308</bold></highlight>, point spread functions h<highlight><bold>1</bold></highlight> (x, y), h<highlight><bold>2</bold></highlight> (x, y) . . . corresponding to the representative distance data (d<highlight><bold>1</bold></highlight>, d<highlight><bold>2</bold></highlight> . . . ) are calculated based upon the relative angle signal stored in the memory (not shown) in step S<highlight><bold>203</bold></highlight> and the representative distance data (d<highlight><bold>1</bold></highlight>, d<highlight><bold>2</bold></highlight> . . . ) calculated in step S<highlight><bold>301</bold></highlight> as explained earlier. In step S<highlight><bold>309</bold></highlight>, an image repair processing operation is executed by using the point spread functions h<highlight><bold>1</bold></highlight> (x, y), h<highlight><bold>2</bold></highlight> (x, y) . . . corresponding to the representative distance data (d<highlight><bold>1</bold></highlight>, d<highlight><bold>2</bold></highlight> . . . ) and also, repaired partial images over the individual divided areas corresponding to the distance zones (Z<highlight><bold>1</bold></highlight>, Z<highlight><bold>2</bold></highlight>, . . . ) are extracted. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> In step S<highlight><bold>310</bold></highlight>, the individually repaired partial images are synthesized to generate a whole repaired image. In step S<highlight><bold>311</bold></highlight>, the synthesized repaired image is recorded into the recording medium <highlight><bold>21</bold></highlight> before the operation returns to step S<highlight><bold>102</bold></highlight>. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> As explained above, the blurred image repair processing is executed by using the optimal point spread functions in correspondence to the various distances and, as a result, a blurred image can be successfully repaired even when there are a plurality of subjects present over varying distances in the image plane or when the image is obtained through a close-up photographing operation. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> (Variations of the Embodiment) </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> The present invention is not limited to the embodiment explained above and it allows for a number of variations and modifications. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> While the blurred image is repaired in the embodiment by detecting the two-dimensional distance distribution of the subject and preparing a plurality of point spread functions in correspondence to various distances, it is not absolutely necessary to detect the two-dimensional distance distribution. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> For instance, only the distance to the object constituting the main subject may be measured and a point spread function corresponding to the distance may be prepared. In this case, the overall image is repaired by using point spread function thus prepared. Since this structure only requires an inexpensive and simple distance detection device instead of a distance detection device capable of detecting the two-dimensional distance distribution, the image repair apparatus can be more readily included in a digital still camera or the like. In addition, since the image of an object present at a distance different from the distance of the main subject is already blurred due to defocusing, executing an image repair based upon the distance to the main subject alone itself does not pose a serious problem. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> While an explanation has been given above on the assumption that an image blur occurs due to an angular displacement of the photographic optical system, a parallel displacement (a movement through which the photographic optical system shifts parallel to the optical axis) of the photographing optical system also greatly affects the image quality in a close-up photographing operation. In such a case, an acceleration sensor for parallel movement detection may be utilized to detect a parallel blur signal so as to calculate a point spread function corresponding to the distance by using the parallel blur signal and the distance data. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> illustrates the principle of the conversion of parallel blur signal to an image blur signal, which is executed in correspondence to the distance. The same reference numerals are assigned to components identical to those shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>. Let us now consider a situation in which the lens <highlight><bold>51</bold></highlight> has shifted by a distance R parallel to the optical axis along the x axis. As the lens <highlight><bold>51</bold></highlight> shifts by the distance R along the x axis, the image plane center <highlight><bold>55</bold></highlight>, too, shifts. Reference numeral <highlight><bold>55</bold></highlight> &prime; indicates the image plane center after the shift. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> It is assumed that the extent of blurring of the image at the points <highlight><bold>52</bold></highlight> and <highlight><bold>53</bold></highlight> set on the optical axis over the distances d<highlight><bold>1</bold></highlight> and d<highlight><bold>2</bold></highlight>, which manifests along the x axis of the image plane are equal to the distances X<highlight><bold>1</bold></highlight> and X<highlight><bold>2</bold></highlight> of the image points <highlight><bold>56</bold></highlight> and <highlight><bold>57</bold></highlight> corresponding to the points <highlight><bold>52</bold></highlight> and <highlight><bold>53</bold></highlight> from the image plane center <highlight><bold>55</bold></highlight> &prime;. The extents of image blurring X<highlight><bold>1</bold></highlight> and X<highlight><bold>2</bold></highlight> for the points <highlight><bold>52</bold></highlight> and <highlight><bold>53</bold></highlight> respectively, manifesting along the x axis of the image plane are determined as indicated through the formulae in (expression 7)</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>X</italic></highlight><highlight><bold>1</bold></highlight>&equals;<highlight><italic>f&times;R</italic></highlight>/(d<highlight><bold>1</bold></highlight>&minus;<highlight><italic>f</italic></highlight>)</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>X</italic></highlight><highlight><bold>2</bold></highlight>&equals;<highlight><italic>f&times;R</italic></highlight>/(d<highlight><bold>2</bold></highlight>&minus;<highlight><italic>f</italic></highlight>)&emsp;&emsp;(expression 7)</in-line-formula></paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> It is to be noted that the image blurring extents Y<highlight><bold>1</bold></highlight> and Y<highlight><bold>2</bold></highlight> along the y axis, too, can be calculated through a similar process. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> As (expression 7) indicates, the extent of blurring attributable to a parallel movement increases drastically in a close-up photographing operation as the distance d becomes closer to the focal length f. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> Through a conversion performed in conformance to the conversion formulae in (expression 7), the parallel movement is converted to an image blur corresponding to the distance and thus, a point spread function can be calculated in correspondence to the image blur. Then, the blurred image is repaired by using the point spread function thus obtained. As a result, it becomes possible to repair an image having become degraded due to an image blur caused by a parallel movement in correspondence to the distance. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> In the variation of the embodiment described above, an image having become blurred during a close-up photographing operation can be successfully repaired. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> In addition, an even more effective image repair can be achieved by combining the image repair of a blur caused by a parallel movement and the image repair of a blur caused by an angular movement described above. In this case, the angular speed sensors for detecting an angular movement and an acceleration sensor for detecting a parallel movement should be utilized. Then, the extent of image blurring attributable to the angular movement, which are calculated through the formulae in (expression 2) and the extent of image blurring attributable to the parallel movement, which are calculated through the formulae in (expression 7) are individually synthesized. A synthesized image blurring extent Xt along the x axis is expressed as in (expression 8) below.</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>Xt&equals;K&times;Xa&plus;L&times;Xp</italic></highlight>(0<highlight><italic>&lt;K</italic></highlight>&lt;1, 0&lt;<highlight><italic>L</italic></highlight>&lt;1)&emsp;&emsp;(expression 8)</in-line-formula></paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> In the above expression, Xa represents the extent of image blurring attributable to the angular movement manifesting along the x axis and Xp represents the extent of image blurring attributable to the parallel movement manifesting along the x axis. K and L represent coefficients by which Xa and Xp are respectively multiplied. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> By comparing the image blurring extent Xa attributable to the angular movement and the image blurring extent Xp attributable to the parallel movement, K is set larger than L if Xa&gt;Xp. If Xa&lt;Xp, on the other hand, K is set smaller than L. In other words, if the image blurring extent Xa attributable to the angular movement is larger than the image blurring the extent Xp attributable to the parallel movement, the ratio of Xa is increased. If, on the other hand, the image blurring extent Xp attributable to the parallel movement is larger than the image blurring extent Xa attributable to the angular movement, the ratio of Xp is increased. As a result, the image can be repaired by taking into consideration both the angular movement and the parallel movement. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> (expression 2) and (expression 7) used to convert an angular movement and a parallel movement to image blurring extents on the image plane may be corrected in correspondence to the distance by which the lens has been driven or the photographing magnification factor if the photographic lens is driven out over a large distance during close-up photographing causing the focal length f to change greatly in correspondence to the distance over which the photographic lens has been driven. In addition, while angular speed sensors are utilized as blur detection sensors in the embodiment described earlier, the present invention is not limited to this example and an acceleration sensor or image sensors, which detects an image blur by detecting the movement of the image over time, may be utilized instead. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> While a passive trigonometric distance detection (trigonometric range measurement) device is used as the distance sensor in the embodiment described earlier, the present invention is not limited to this example. The distance distribution may instead be measured by scanning the subject with a so-called active trigonometric range finding device. Such an active trigonometric range finding device may emit a light beam toward the subject along a specific optical axis and may detect the distance by measuring the image forming position at which the reflected light beam is formed with an optical system distanced from the light beam by a baseline length. Alternatively, the distance distribution of the subject may be detected by emitting an electromagnetic wave or a sonic wave and measuring the length of time elapsing before the wave reflected by the subject returns. In this case, highly accurate distance measurement is achieved even when the subject is relatively dark. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> In addition, the blurred image repair processing is automatically executed in the digital still camera in response to a shutter release signal in the embodiment. However, the distance information or the distance distribution information, the blur information and the image signal may be temporarily stored into a recording medium so as to allow the digital camera to repair the blurred image later by reading out the distance information or the distance distribution information, the blur information and the image signal from the recording medium. This alternative, which allows the blurred image repair processing to be executed when the onus on the digital still camera is relatively small, is particularly advantageous when the camera is used in a continuous shooting operation. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> The distance information or the distance distribution information, the blur information and the image signal may be temporarily stored into a recording medium so that the blurred image can be repaired later on a personal computer or the like by reading out the distance information or the distance distribution information, the blur information and the image signal from the recording medium of the personal computer. This lessens the onus placed on the digital still camera and, at the same time, image processing which involves larger-scale arithmetic operations is enabled. Moreover, the quality of the repaired image improves. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> Silver halide film may be used as the recording medium instead of a memory card. For instance, an image may be optically recorded onto silver halide film having a magnetic layer where distance information or distance distribution information and blur information are magnetically recorded. Then, the image signal should be extracted into a personal computer by reading the silver halide film with a scanner or the like. Alternatively, the distance information or the distance distribution information recorded in the magnetic layer may be read by using a magnetic head. The image repair according to the present invention can be adopted in a photographing system that uses silver halide film in this manner, as well as in a digital still camera. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> In addition, while the processing for repairing a blurred image is automatically executed in the embodiment explained earlier, the processing for dividing the image plane into a plurality of portions in correspondence to the various distance zones, for instance, may be executed interactively in response to an operating input by the photographer while the image is displayed on a display unit or the like. In such a case, the blurred image can be repaired by reflecting the intent of the photographer. In addition, the blurred image repair can be executed in a reliable manner even when the automatic processing cannot be performed easily. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> In the embodiment described above, the blurred image repair processing is executed on the image over all the distance zones. However, since the image of a subject in a distance zone that does not match the distance setting at photographing optical system is already blurred due to defocusing, the blurred image repair processing on the image in this distance zone may be omitted. For instance, the defocusing extent calculated based upon the distance setting information indicating the distance setting at the photographing optical system and the aperture value information should be compared with the image blurring extent in a specific distance zone. If the defocusing extent is predominant, the blurred image repair processing is not executed on the image in this distance zone. As a result, a high-response image repair apparatus can be realized by reducing the length of time required for the image processing. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> In addition, while the blurred image repair processing is executed each time a shutter release signal is input through the shutter release button in the embodiment, the blurred image repair processing may instead be executed when a specific operating mode (e.g., a close-up photographing mode for performing a camera operation suitable for close-up shooting or a high definition recording mode in which a low compression rate is set for image recording) is set in the digital still camera, or when the distance setting at the photographing optical system is smaller than a predetermined distance. Since this allows the blurred image repair processing to be automatically executed only when it is essential to repair the blurred image, a high response photographing operation is enabled under normal circumstances. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> As explained above, in the image generating apparatus and the image generating method according to the present invention, the distances or the distance distribution of the subject on the image plane is detected and blurred image repair processing is executed by using the optimal point spread functions corresponding to the distance or the distance distribution. As a result, the blurred image can be repaired more successfully compared to blurred image repair processing executed by using a uniform point spread function regardless of variations in the subject distance. The present invention and is particularly effective in application for repairing a blur in a close-up image, the quality of which is greatly affected by an unsteady hand movement. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> Moreover, blurs are repaired in an image that contains a plurality of subjects present over varying distances within the image plane by first repairing the blurred partial images corresponding to the various distances and then synthesizing them to create a whole repaired image, an effective blur repair can be achieved. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. An image generating apparatus comprising: 
<claim-text>an image-capturing unit that captures an image of a subject formed on an image plane by a photographing optical system and generates an image signal; </claim-text>
<claim-text>a distance detection unit that detects a distance of the subject on the image plane and generates distance information; </claim-text>
<claim-text>a blur detection unit that detects a blur occurring during the image-capturing operation at the photographing optical system and generates a blur signal; </claim-text>
<claim-text>a point spread function generating unit that generates a point spread function corresponding to the distance based upon the distance information and the blur signal; and </claim-text>
<claim-text>an image repair unit that forms a repaired image by repairing the image signal using the point spread function. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. An image generating apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein: 
<claim-text>said distance detection unit detects two-dimensional distance distribution of the subject, divides the subject distance into a plurality of distance zones based upon distance distribution information and calculates a plurality of sets of distance data each representing one of the distance zones; </claim-text>
<claim-text>said point spread function generating unit generates a plurality of point spread functions each corresponding to one of said plurality of sets of distance data; and </claim-text>
<claim-text>said image repair unit divides the image signal into a plurality of partial images each corresponding to one of the distance zones, forms a plurality of repaired partial images by repairing the partial images with the point spread functions each corresponding to one set of distance data and forms a repaired image by synthesizing said plurality of repaired partial images. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. An image generating apparatus comprising: 
<claim-text>an information readout unit that reads out image information obtained by photographing a subject, distance information indicating a distance of the subject during the photographing operation and blur information indicating a blur occurring during the photographing operation from a recording medium having recorded therein the image information, the distance information and the blur information; </claim-text>
<claim-text>a point spread function generating unit that generates a point spread function in correspondence to the distance based upon the distance information and the blur information; and </claim-text>
<claim-text>an image repair unit that forms a repaired image by repairing the image information with the point spread function. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. An image generating method for forming a repaired image, comprising: 
<claim-text>forming an image of a subject on a specific image plane; </claim-text>
<claim-text>capturing the image of the subject formed on the image plane and generating an image signal; </claim-text>
<claim-text>detecting a distance of the subject on the image plane and generating distance information; </claim-text>
<claim-text>detecting a blur occurring during the image-capturing operation and generating a blur signal; </claim-text>
<claim-text>generating a point spread function corresponding to the distance based upon the distance information and the blur signal; and </claim-text>
<claim-text>repairing the image signal with the point spread function. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. An image generating apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein: 
<claim-text>said blur detection unit detects an angular movement through which the photographing optical system becomes displaced around two axes each extending perpendicular to an optical axis thereof. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. An image generating apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein: 
<claim-text>said blur detection unit detects a parallel movement through which the photographing optical system becomes shifted parallel to an optical axis thereof. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. An image generating apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein: 
<claim-text>said blur detection unit detects an angular movement through which the photographic optical system becomes displaced around two axes each extending perpendicular to an optical axis thereof and a parallel movement through which the photographing optical system becomes shifted parallel to the optical axis to generate a blur signal based upon the angular movement and the parallel movement. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. An image generating apparatus according to <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein: 
<claim-text>said information readout unit electronically reads out the image information, the distance information and the blur information recorded in the recording medium. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. An image generating apparatus according to <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein: 
<claim-text>said information readout unit reads out the image information, the distance information and the blur information recorded on silver halide film by using a scanner. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. An image generating apparatus comprising: 
<claim-text>an image-capturing unit that captures an image of a subject formed on an image plane by a photographing optical system and generates an image signal; </claim-text>
<claim-text>a distance detection unit detects two-dimensional distance distribution of the subject, divides the subject distance into a plurality of distance zones based upon distance distribution information and calculates a plurality of sets of distance data each representing one of the distance zones; </claim-text>
<claim-text>a blur detection unit that detects a blur occurring during the image-capturing operation at the photographing optical system and generates a blur signal; </claim-text>
<claim-text>a point spread function generating unit that generates a plurality of point spread functions each corresponding to one of said plurality of sets of distance data based upon the distance distribution information and the blur signal; and </claim-text>
<claim-text>an image repair unit that divides the image signal into a plurality of partial images each corresponding to one of the distance zones, forms a plurality of repaired partial images by repairing the partial images with the point spread functions each corresponding to one set of distance data and forms a repaired image by synthesizing said plurality of repaired partial images.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002746A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002746A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002746A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002746A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002746A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002746A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002746A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002746A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002746A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030002746A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030002746A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030002746A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030002746A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
