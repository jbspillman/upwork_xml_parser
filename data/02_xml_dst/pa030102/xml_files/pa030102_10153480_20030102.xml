<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005156A1-20030102-D00000.TIF SYSTEM "US20030005156A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005156A1-20030102-D00001.TIF SYSTEM "US20030005156A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005156A1-20030102-D00002.TIF SYSTEM "US20030005156A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005156A1-20030102-D00003.TIF SYSTEM "US20030005156A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005156A1-20030102-D00004.TIF SYSTEM "US20030005156A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005156A1-20030102-D00005.TIF SYSTEM "US20030005156A1-20030102-D00005.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005156</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10153480</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020521</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F015/16</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>709</class>
<subclass>245000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Scalable and flexible method for address space decoding in a multiple node computer system</title-of-invention>
</technical-information>
<continuity-data>
<non-provisional-of-provisional>
<document-id>
<doc-number>60301775</doc-number>
<document-date>20010629</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Sudheer</given-name>
<family-name>Miryala</family-name>
</name>
<residence>
<residence-us>
<city>San Jose</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Jeremy</given-name>
<middle-name>J.</middle-name>
<family-name>Farrell</family-name>
</name>
<residence>
<residence-us>
<city>Campbell</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Kazunori</given-name>
<family-name>Masuyama</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanazawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Patrick</given-name>
<middle-name>N.</middle-name>
<family-name>Conway</family-name>
</name>
<residence>
<residence-us>
<city>Los Altos</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>FENWICK &amp; WEST LLP</name-1>
<name-2></name-2>
<address>
<address-1>TWO PALO ALTO SQUARE</address-1>
<city>PALO ALTO</city>
<state>CA</state>
<postalcode>94306</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A multi-node computer system includes a plurality of I/O nodes, CPU nodes, memory nodes, and hybrid nodes connected via an interconnect. A CPU node or an I/O node issues a request. An address decoder residing in the interconnect decodes the request to determine whether the request is a coherent memory request. The address decoder also determines a physical destination node address of the request based on a logical node address stored in the request. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">RELATED APPLICATION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application claims priority under 35 U.S.C. &sect;119(e) from U.S. provisional application No. 60/301,775 entitled &ldquo;SCALABLE AND FLEXIBLE METHOD FOR ADDRESS SPACE DECODING IN A MULTIPLE NODE COMPUTER SYSTEM&rdquo;, filed on Jun. 29, 2001 by Jeremy J. Farrell, Kazunori Masuyama, Sudheer Miryala, and Patrick N. Conway, which provisional application is incorporated herein by this reference in its entirety.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates generally to multi-node computer systems, and more specifically to a mechanism for decoding a destination node address of a memory request in a multi-node computer system. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> Multi-node computer networks may include central processor unit (CPU) nodes, memory nodes, input/output (I/O) nodes, and hybrid nodes (with any combination of memory, I/O, and CPU). These nodes are connected via a system interconnect, which is responsible for address decoding, i.e., for determining to which node a request should be routed. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> In multi-node computer systems, memory has high latency compared to present day CPU speeds. This means that the time for a memory node to respond to a read or write request is large. Another frequent bottleneck is the maximal throughput, i.e., the amount of data a memory system can provide per unit time. Memory interleaving is a well-known technique that allows a multi-node computer system to increase throughput by splitting the memory system across a group of nodes at an interleave size. For example, in a system with four memory nodes with an interleave size of x, a base address B can be mapped to Node <highlight><bold>0</bold></highlight>. Address B&plus;x is mapped to Node <highlight><bold>1</bold></highlight>, B&plus;2x to Node <highlight><bold>2</bold></highlight>, B&plus;3x to Node <highlight><bold>3</bold></highlight>, and B&plus;4x to Node <highlight><bold>0</bold></highlight>. This allows the system to avoid any hot memory spots as well as to increase the system performance. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> As multi-node computer systems are becoming larger, it becomes important to be able to address many nodes. Existing methods require base and size (limit) declaration for each node in the system. Thus, if there are n nodes in the system, they require n base registers and n size registers. As the number of nodes increases, the memory registers holding the &lcub;base, size&rcub; pairs increase linearly, thereby requiring very large amount of chip real estate. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Another disadvantage of existing methods is that in order to determine quickly the destination node address of the request, existing solutions require multiple magnitude comparators. There is typically one magnitude comparator for each node. As the number of nodes is added, more &lcub;base, size&rcub; pairs must be added and more magnitude comparators are needed. The cost of implementation of these magnitude comparators is usually very high. Thus, existing decode schemes are not scalable enough to support many address nodes. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Yet another disadvantage of conventional implementations having multiple nodes and using interleaving, is that conventional systems use a fixed interleave size and a limited number of combination of nodes for each interleave group. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> To summarize, existing decode schemes are not scalable enough to support many address nodes. In addition, existing address decoding schemes are not flexible enough to allow different sizes for interleaving and to allow a variety of interleave sets. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> What is needed, therefore, is an improved mechanism for address space decoding in a multi-node computer system. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The present invention includes a system for address space decoding in a multi-node compute system. In accordance with an embodiment of the present invention, a multi-node computer system includes a plurality of I/O nodes, CPU nodes, memory nodes, and hybrid nodes connected by an interconnect (as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>). In one embodiment of the present invention, a request issued by a CPU node or an I/O node includes an address comprising a base field that stores a base address of a destination node; an index field that stores a logical address of a destination node; and a granularity field that stores a size of an addressable space of a memory node. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The system further includes an address decoder adapted to extract a base address of a destination node, using a width of the base field. The address decoder is also configured to extract a logical address of a destination node, using a width of the index field and the granularity field. The address decoder further comprises a base register for storing a number of bits indicating the width of the base field; an index register for storing a number of bits indicating the width of the index register; and a granularity register for storing a number of bits indicating a width of the granularity field. The width of the granularity field is used to determine where the index field starts in the address. The address decoder further comprises a base offset register for storing a programmed base offset indicating where a memory node is mapped in a system address space; a logical comparator for performing a comparison between the base address and the base offset to determine whether the request for data is made to a memory node; and a mapping table for mapping the extracted logical address of a destination node to a physical node address where the request is routed. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> The present invention also includes a method for address space decoding in the multi-node computer system. Initially, a messaging driver causes a CPU node or an I/O node to issue a request to a memory node. The request includes an address. The address decoder extracts a base field of the address using the width of the base field. A logical comparison is performed between the base address and the programmed base offset. If the two match, it indicates that the request is a coherent memory request, i.e., it is made to a memory node. If the request is a coherent memory request, the address decoder extracts a logical node address of the destination node using the width of the index field and the granularity field. A physical destination node address is determined based on the logical node address by indexing into the mapping table. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The present invention advantageously performs a logical comparison instead of performing arithmetic comparisons to decode a destination of the request. This obviates the need of having multiple magnitude comparators. Furthermore, as the number of nodes in a multi-node computer system increases, the memory registers do not increase linearly. As a result, the implementation cost does not scale linearly, but remains small.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram of an overall architecture of a distributed multi-node computer system in accordance with an embodiment of the present invention; </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a pictorial illustration of a preferred format of an address of a memory request; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a pictorial illustration of a coherent address space in a system address map; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a block diagram of a logical node address to a physical node address mapping table in accordance with an embodiment of the present invention; and </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a flow chart of a method performed by the system of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, there is shown a block diagram of an overall architecture of a distributed multi-node computer system <highlight><bold>100</bold></highlight>. System <highlight><bold>100</bold></highlight> includes a plurality of nodes: CPU nodes <highlight><bold>110</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>110</bold></highlight><highlight><italic>n </italic></highlight>(generally <highlight><bold>110</bold></highlight>); memory nodes <highlight><bold>115</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>115</bold></highlight>n (generally <highlight><bold>115</bold></highlight>); I/O nodes <highlight><bold>120</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>120</bold></highlight><highlight><italic>n </italic></highlight>(generally <highlight><bold>120</bold></highlight>), and hybrid nodes <highlight><bold>105</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>105</bold></highlight><highlight><italic>n </italic></highlight>(generally <highlight><bold>105</bold></highlight>). Hybrid nodes <highlight><bold>105</bold></highlight> may combine CPU node <highlight><bold>110</bold></highlight> and memory node <highlight><bold>115</bold></highlight>. Each CPU node <highlight><bold>110</bold></highlight> is a conventional processing unit, for example, an Intel or Intel-compatible Pentium&trade; class or higher processor, a Sun SPARC&trade; class or higher processor, or an IBM/Motorola PowerPC&trade; class or higher processor. Each I/O node <highlight><bold>120</bold></highlight> is a conventional I/O system, for example, a storage device, an input device, a peripheral device, or the like. Each memory node <highlight><bold>115</bold></highlight> is a conventional memory system, for example, a dynamic random access memory (DRAM) system, a static random access memory (SRAM) system, or the like. Any of the CPU node <highlight><bold>110</bold></highlight>, I/O node <highlight><bold>120</bold></highlight>, hybrid node <highlight><bold>105</bold></highlight> can issue a coherent memory request to memory node <highlight><bold>115</bold></highlight>. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, nodes <highlight><bold>105</bold></highlight>, <highlight><bold>110</bold></highlight>, <highlight><bold>115</bold></highlight>, and <highlight><bold>120</bold></highlight> in system <highlight><bold>100</bold></highlight> are connected via an Interconnect <highlight><bold>125</bold></highlight>. Interconnect <highlight><bold>125</bold></highlight> may be, for example, a mesh, a ring or a hypercube implemented using routers or switches. Interconnect <highlight><bold>125</bold></highlight> provides a path between any pair of nodes and routes a message from one node to another in system <highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> System <highlight><bold>100</bold></highlight> has an address space. The address space is divided among any number nodes. The address space provides a set of memory addresses for accessing memory nodes <highlight><bold>115</bold></highlight>. This area is referred to as a coherent address space. The coherent address space is divided into a plurality of memory windows. The coherent address space of system <highlight><bold>100</bold></highlight> is discussed in more detail below in connection with <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, it shows a preferred address <highlight><bold>50</bold></highlight> format for a request issued by CPU node <highlight><bold>110</bold></highlight> or I/O node <highlight><bold>120</bold></highlight> to memory node <highlight><bold>115</bold></highlight>. The address <highlight><bold>50</bold></highlight> includes the following fields: a base field <highlight><bold>10</bold></highlight>; an index field <highlight><bold>20</bold></highlight>; and a granularity field <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> The granularity field <highlight><bold>30</bold></highlight> preferably indicates the number of cache lines stored in each memory window <highlight><bold>40</bold></highlight> in the coherent address space <highlight><bold>210</bold></highlight> of system <highlight><bold>100</bold></highlight>. The granularity field is G bits wide. There could be 2<highlight><superscript>G </superscript></highlight>cache lines stored in each memory window <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The index field <highlight><bold>20</bold></highlight> preferably stores the logical address of each node (logical node ID) of system <highlight><bold>100</bold></highlight>. The index field <highlight><bold>20</bold></highlight> can be adjusted based on the number of addressable memory nodes. Index field <highlight><bold>20</bold></highlight> can be 0 bits wide when there is only one node in the system <highlight><bold>100</bold></highlight>. Index field <highlight><bold>20</bold></highlight> can be 1 bits wide when there are 2 nodes in the system <highlight><bold>100</bold></highlight>. Likewise, index field <highlight><bold>20</bold></highlight> can be 2 bits wide for 3 or 4 nodes, 3 bits wide for 5 to 8 nodes and so on. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> The base field <highlight><bold>10</bold></highlight> stores a base address. The width of base field <highlight><bold>10</bold></highlight> is equal to (total address bits&minus;(index bits&plus;granularity bits)). The total number of bits of the base field <highlight><bold>10</bold></highlight> and granularity field <highlight><bold>30</bold></highlight> determines the size of the addressable space per node. The base address stored in base field <highlight><bold>10</bold></highlight> indicates the base address of a node to which the request for data is made. As will be described in more detail below, the base address is used to determine whether the request is a coherent memory request. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, it pictorially illustrates address space <highlight><bold>200</bold></highlight> of system <highlight><bold>100</bold></highlight>. Address space <highlight><bold>200</bold></highlight> starts at 0 and has a size of 2<highlight><superscript>B&plus;I&plus;G </superscript></highlight>bytes. As used herein, B is the width of the base field <highlight><bold>10</bold></highlight>, I is the width of the index field <highlight><bold>20</bold></highlight>, and G is the width of the granularity field <highlight><bold>30</bold></highlight> (all shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>). As previously discussed, system address space <highlight><bold>200</bold></highlight> provides a set of memory addresses for accessing memory <highlight><bold>115</bold></highlight>. This area is referred to as coherent address space <highlight><bold>210</bold></highlight>. Coherent address space <highlight><bold>210</bold></highlight> has a size of 2<highlight><superscript>I&plus;G </superscript></highlight>bytes. An arrow pointing to the bottom of window <highlight><bold>0</bold></highlight> of the coherent address space <highlight><bold>210</bold></highlight> indicates the address where coherent address space <highlight><bold>210</bold></highlight> starts in the address space <highlight><bold>200</bold></highlight>. This address is called a base offset and is stored in a base offset register <highlight><bold>142</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> Coherent address space <highlight><bold>210</bold></highlight> is divided into 2<highlight><superscript>I </superscript></highlight>memory windows <highlight><bold>40</bold></highlight>. The size of each memory window <highlight><bold>40</bold></highlight> in the coherent address space <highlight><bold>210</bold></highlight> is the addressable space per memory node <highlight><bold>115</bold></highlight> in system <highlight><bold>100</bold></highlight>. There could be 2<highlight><superscript>G </superscript></highlight>cache lines stored in each window <highlight><bold>40</bold></highlight>. As an illustrative example, if G&equals;20, I&equals;4, B&equals;8 and the cache line size is 1B, there could be 16 (2<highlight><superscript>4</superscript></highlight>) number of windows <highlight><bold>40</bold></highlight> in the coherent address space <highlight><bold>210</bold></highlight> in the system address space <highlight><bold>200</bold></highlight>. Each memory window <highlight><bold>40</bold></highlight> will then have a size of 1MB (2<highlight><superscript>20</superscript></highlight>). </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> Referring again to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, system <highlight><bold>100</bold></highlight> further comprises an address decoder <highlight><bold>128</bold></highlight> configured to receive a request issued by CPU node <highlight><bold>110</bold></highlight> or I/O node <highlight><bold>120</bold></highlight> and to extract the base address from the base field <highlight><bold>10</bold></highlight> of the address <highlight><bold>50</bold></highlight> included in the request. Address decoder <highlight><bold>128</bold></highlight> extracts the base address based on the width, B, of the base field <highlight><bold>10</bold></highlight>. Address decoder <highlight><bold>128</bold></highlight> is further configured to extract a logical node address from index field <highlight><bold>20</bold></highlight> of the address <highlight><bold>50</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Address decoder <highlight><bold>128</bold></highlight> may be implemented as software, hardware, or any combination thereof. Address decoder <highlight><bold>128</bold></highlight> preferably comprises a base register <highlight><bold>130</bold></highlight>, index register <highlight><bold>135</bold></highlight>, granularity register <highlight><bold>140</bold></highlight>, base offset register <highlight><bold>142</bold></highlight>, logical comparator <highlight><bold>144</bold></highlight>, and mapping table <highlight><bold>145</bold></highlight>. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Base register <highlight><bold>130</bold></highlight> preferably defines the number of bits (width) programmed to store the base address of the base field <highlight><bold>10</bold></highlight> of the address <highlight><bold>50</bold></highlight> of the memory request shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Index register <highlight><bold>135</bold></highlight> defines the number of bits used by the index field <highlight><bold>20</bold></highlight> of the address <highlight><bold>50</bold></highlight>. Granularity register <highlight><bold>140</bold></highlight> defines the number of bits used by the granularity field <highlight><bold>30</bold></highlight> of the address <highlight><bold>50</bold></highlight>. The width of the granularity field <highlight><bold>30</bold></highlight> is used to determine where the index field <highlight><bold>20</bold></highlight> starts. Base register <highlight><bold>130</bold></highlight>, index register <highlight><bold>135</bold></highlight>, and granularity register <highlight><bold>140</bold></highlight> are programmed at the system initialization time. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Base offset register <highlight><bold>142</bold></highlight> stores a base offset indicating where the coherent address space <highlight><bold>210</bold></highlight> starts in the system address space <highlight><bold>200</bold></highlight> (shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>). The base offset is a programmed constant. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Logical comparator <highlight><bold>144</bold></highlight> preferably performs a logical comparison between the base address stored in base field <highlight><bold>10</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> and the base offset. If the base address matches the base offset, it indicates that the request is a coherent memory request, i.e., it is made to memory node <highlight><bold>115</bold></highlight>. Performing logical comparisons instead of arithmetic comparisons is advantageous because it eliminates the requirement of having multiple magnitude comparators. Further, it scales with the additional number of nodes in the system <highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> Mapping table <highlight><bold>145</bold></highlight> preferably stores mappings of logical node addresses to physical destination-node addresses for each node in system <highlight><bold>100</bold></highlight>. Mapping table <highlight><bold>145</bold></highlight> can be implemented as a DRAM, SRAM, or any equivalent thereof. An example of mapping table <highlight><bold>145</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, it illustrates a logical node ID to a physical node ID mapping table <highlight><bold>145</bold></highlight>. The mapping table <highlight><bold>145</bold></highlight> stores one entry for each node supported by the system <highlight><bold>100</bold></highlight>. It should be understood that there are at least as many entries in the mapping table <highlight><bold>145</bold></highlight> as there are nodes supported by the system <highlight><bold>100</bold></highlight>. Mapping table <highlight><bold>145</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> stores 2<highlight><superscript>I </superscript></highlight>entries, wherein I indicates the width of index field <highlight><bold>20</bold></highlight> of address <highlight><bold>50</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> The present invention preferably supports interleaving by having many memory windows mapped to a single memory node <highlight><bold>115</bold></highlight> in system <highlight><bold>100</bold></highlight> and by having many-to-one mappings in the mapping table <highlight><bold>145</bold></highlight>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, there is shown a flow chart of a method for decoding the destination node address of the request performed by the system <highlight><bold>100</bold></highlight>. The process starts <highlight><bold>510</bold></highlight> and a messaging driver (not shown) causes CPU <highlight><bold>110</bold></highlight> to issue a request to memory node <highlight><bold>115</bold></highlight>. It should be understood that I/O node <highlight><bold>120</bold></highlight> can also issue a request to memory node <highlight><bold>115</bold></highlight>. Address decoder <highlight><bold>128</bold></highlight> (shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>) receives the width of the base field <highlight><bold>10</bold></highlight>, the index field <highlight><bold>20</bold></highlight>, and the granularity <highlight><bold>30</bold></highlight>. Address decoder <highlight><bold>128</bold></highlight> extracts <highlight><bold>530</bold></highlight> the base address from the base field <highlight><bold>10</bold></highlight> of the address, based on the width of the base field <highlight><bold>10</bold></highlight>, B. Address decoder <highlight><bold>128</bold></highlight> then compares <highlight><bold>540</bold></highlight> the base address with the base offset stored in base offset register <highlight><bold>142</bold></highlight> (shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>). If the two match, it indicates that the request is a coherent memory request, i.e., it is made to a memory node. Once it is determined that the request is a coherent memory request, address decoder <highlight><bold>128</bold></highlight> extracts <highlight><bold>550</bold></highlight> a logical node address of the destination node (logical node ID) from the index field <highlight><bold>20</bold></highlight> of the address, based on the width of the index field <highlight><bold>20</bold></highlight>. To determine where the index field starts, address decoder <highlight><bold>128</bold></highlight> uses the width of the granularity field <highlight><bold>30</bold></highlight>, G. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Address decoder <highlight><bold>128</bold></highlight> then indexes into the mapping table <highlight><bold>145</bold></highlight> based on the logical node ID to determine <highlight><bold>555</bold></highlight> a physical node address for the destination node, and the process ends in <highlight><bold>570</bold></highlight>. As an illustrative example, if I&equals;4, address decoder <highlight><bold>128</bold></highlight> extracts a four-bit logical node ID stored in the index field <highlight><bold>20</bold></highlight>. If the logical node ID, for example, is &lsquo;0011&rsquo;, which is a logical representation of a digital number &lsquo;3&rsquo;, indexing into the mapping table <highlight><bold>145</bold></highlight> based on the logical node ID &lsquo;3&rsquo; allows address decoder <highlight><bold>128</bold></highlight> to determine a physical node ID to which the request is routed. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> In the alternative, if the base address and the base offset register <highlight><bold>142</bold></highlight> do not match, the request is not a coherent memory request <highlight><bold>580</bold></highlight>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> An embodiment of the present invention utilizes a decoding mechanism to derive the destination node address for a given logical address using a mapping table. Performing a logical comparison instead of arithmetic comparisons to determine the physical destination node address obviates the need of having multiple magnitude comparisons. As the number of nodes in a multi-node computer system increases, the memory registers do not increase linearly. As a result, the implementation cost does not scale linearly, but remains small. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed this: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. In a multi-node computer system including an I/O node, a CPU node, and a memory node connected by an interconnect, a method for determining a destination node address of a request for data, the method comprising: 
<claim-text>receiving the request for data, the request including an address; </claim-text>
<claim-text>extracting a base address of a destination node from the address; </claim-text>
<claim-text>comparing the base address with a base offset, the base offset indicating where the memory node is mapped in the system address space; and </claim-text>
<claim-text>responsive to the base address matching the base offset: 
<claim-text>extracting a logical node address from the address; and </claim-text>
<claim-text>determining a physical destination node address of the request, based on the logical node address. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the base address is extracted using a width of the base field. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the logical node address is extracted using a width of the index field. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A multi-node computer system comprising: 
<claim-text>an address decoder for receiving a request for data, the request including an address, and for extracting from the address a base address of a destination node and a logical node address; </claim-text>
<claim-text>a comparator residing in the address decoder, the comparator for performing a logical comparison between the extracted base address and a base offset indicating where the memory node is mapped in a system address space; and </claim-text>
<claim-text>a mapping table residing in the address decoder, the mapping table for mapping the logical node address to a physical destination node address of the request for data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein the address decoder further comprises a base offset register for storing the base offset. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein the base offset is a programmed constant. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein the base address is stored in a base field of the address, and wherein the address decoder further comprises a base register for indicating a width of the base field. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the address decoder extracts the base address based on the width of the base field. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein the logical node address is stored in an index field of the address, and wherein the address decoder further comprises an index register for indicating a width of the index field. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein the address decoder extracts the logical node address based on the width of the index field. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein the address further comprises a granularity field indicating a size of an addressable space of the memory node.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005156A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005156A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005156A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005156A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005156A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005156A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
