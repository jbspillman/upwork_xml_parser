<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004583A1-20030102-M00001.NB SYSTEM "US20030004583A1-20030102-M00001.NB" NDATA NB>
<!ENTITY US20030004583A1-20030102-M00001.TIF SYSTEM "US20030004583A1-20030102-M00001.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-M00002.NB SYSTEM "US20030004583A1-20030102-M00002.NB" NDATA NB>
<!ENTITY US20030004583A1-20030102-M00002.TIF SYSTEM "US20030004583A1-20030102-M00002.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00000.TIF SYSTEM "US20030004583A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00001.TIF SYSTEM "US20030004583A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00002.TIF SYSTEM "US20030004583A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00003.TIF SYSTEM "US20030004583A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00004.TIF SYSTEM "US20030004583A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00005.TIF SYSTEM "US20030004583A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00006.TIF SYSTEM "US20030004583A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00007.TIF SYSTEM "US20030004583A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00008.TIF SYSTEM "US20030004583A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00009.TIF SYSTEM "US20030004583A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00010.TIF SYSTEM "US20030004583A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00011.TIF SYSTEM "US20030004583A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00012.TIF SYSTEM "US20030004583A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00013.TIF SYSTEM "US20030004583A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00014.TIF SYSTEM "US20030004583A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00015.TIF SYSTEM "US20030004583A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030004583A1-20030102-D00016.TIF SYSTEM "US20030004583A1-20030102-D00016.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004583</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10153693</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020524</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>164511/2001(PAT.)</doc-number>
</priority-application-number>
<filing-date>20010531</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>164284/2001(PAT.)</doc-number>
</priority-application-number>
<filing-date>20010531</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G05B019/18</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>700</class>
<subclass>004000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>700</class>
<subclass>002000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>700</class>
<subclass>005000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Signal processing circuit involving local synchronous behavior</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Masakazu</given-name>
<family-name>Matsugu</family-name>
</name>
<residence>
<residence-non-us>
<city>Chiba</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Katsuhiko</given-name>
<family-name>Mori</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Osamu</given-name>
<family-name>Nomura</family-name>
</name>
<residence>
<residence-non-us>
<city>Hiroshima</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>FITZPATRICK CELLA HARPER &amp; SCINTO</name-1>
<name-2></name-2>
<address>
<address-1>30 ROCKEFELLER PLAZA</address-1>
<city>NEW YORK</city>
<state>NY</state>
<postalcode>10112</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A local synchronization type parallel pulse signal processing circuit has a plurality of neurons connected to each other based on a predetermined rule and disposed in parallel, executing a predetermined arithmetic process with respect to input signals and outputting, a phase synchronization signal generation circuit outputting phase synchronization signals to the predetermined vicinal neurons, and a synchronization detection portion detecting synchronization within an allowable phase difference between the outputs of the predetermined vicinal neurons. The phase synchronization signal generation circuit functions also as a neuron executing the predetermined arithmetic process and outputting in accordance with a result of the synchronization detection by the synchronization detection portion. With this architecture, the synchronization circuit operating stably without any contradiction in a way that brings neither an increase in circuit scale nor an increase in consumption of electric power, is actualized. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to a signal processing circuit such as a neural network etc for implementing a parallel pulse signal process involving a local synchronous behavior. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Related Background Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Image and voice recognition implementation systems have hitherto been roughly classified into such a type that a recognition processing algorithm specialized for a specified recognition object is sequentially operated and executed as computer software, and a type in which the same algorithm is executed by a dedicated parallel image processor (such as an SIMD (Single Instruction Multiple Data) processor, an MIMD (Multiple Instruction stream/Multiple Data stream) processor and so on). </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Typical examples are given below as exemplifying the image recognition algorithm. At first, the following is methods involving calculating a feature amount relative to a similarity to a recognition object model. One method is a method for representing recognition object model data as a template model, calculating a similarity by template matching etc with an input image (or a feature vector thereof) and calculating a high-order correlation coefficient. Another method is a method (Sirovich, et al., 1987, Low-dimensional procedure for the characterization of human faces, J. Opt. Soc. Am. (A), vol. 3, pp. 519-524) for mapping an input pattern to an intrinsic image function space obtained by analyzing primary components of an object model image, and calculating an intra-feature-space distance from the model. A further method is a method (Lades et al., 1993, Distortion Invariant Object Recognition in the Dynamic Link Architecture, IEE Trans. on Computers, vol. 42, pp. 300-311) for representing a plurality of feature extraction results (feature vectors) and a spatial arrangement relationship as graphs, and calculating a similarity based on elastic graph matching. A still further method is a method (Seibert, et al., 1992, Learning and recognizing 3D objects from multiple views in a neural system, in Neural Networks for Perception, vol. 1 Human and Machine Perception (H. Wechsler Ed.) Academic Press, pp. 427-444) for obtaining position-, rotation- and scale-invariable representations by executing predetermined conversions with respect to input images and thereafter collating with a model. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The following is exemplifications of a pattern recognition method based on a neural network model of which a hint is acquired from a biological information processing system. One exemplification is a method (Japanese Patent Post-Exam. No. 60-712, Fukushima &amp; Miyake, 1982, Neocognitron: A new algorithm for pattern recognition tolerant of deformation and shifts in position, Pattern Recognition, vol. 15, pp-455-469) for implementing hierarchical template matching. Another exemplification is a method (Anderson, et al., 1995, Routing Networks in Visual Cortex, in Handbook of Brain Theory and Neural Networks (M. Arbib, Ed.), MIT Press, pp. 823-826) for obtaining object-based scale- and position-invariable representations by dynamic routing neural networks. Other exemplifications are methods using multi-layer perceptrons, a radial basis function network and so on. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> On the other hand, what is proposed as a scheme for taking an information processing system based on biological neural networks with a higher fidelity, is a neural network model circuit (Murray et al., 1991, Pulse-Stream VLSI Neural Networks Mixing analog and digital Techniques, IEEE Trans. on Neural Networks, vol. 1.2, pp. 193-204,; Japanese Patent Application Laid-Open Nos. 7-262157, 7-334478 and 8-153148, and Japanese Patent Publication No. 2,879,670) for transmitting and representing information through on a pulse train corresponding to an action potential. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Methods for recognizing and detecting a specified object by a neural network constructed of pulse train generation neurons, are systems (U.S. Pat. No. 5,664,065, and Broussard, et al., 1999, Physiologically Motivated Image Fusion for Object Detection using a Pulse Coupled Neural Network, IEEE Trans. on Neural Networks, vol. 10, pp. 554-563, and so forth) using a pulse coupled neural network (which will hereinafter be abbreviated to PCNN), to be specific, a high-order (second-order or higher) model by Echhorn (Eckhorn, et al., 1990, Feature linking via synchronization among distributed assembles: simulation of results from cat cortex, Neural Computation, vol. 2, pp. 293-307) which is based on the premise of linking inputs and feeding inputs. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Further, a method for relieving a wiring problem in the neural network is an event-driven oriented method (Address Event Representation: this will hereinafter be abbreviated to AER) (Lazzaro, et al., 1993, silicon Auditory Processors as Computer Peripherals, In Touretzky, D (ed), Advances in Neural Information Processing Systems 5. San Mateo, Calif.: Morgan Kaufmann Publishers) for coding addresses of so-called pulse output neurons. In this case, IDs of pulse train output-sided neurons are coded as binary addresses, whereby even when output signals from the different neurons are arranged in time sequence on a common bus, the input-sided neurons are able to automatically decode the addresses of the source neurons. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> On the other hand, the neural network processor related to No. 2,741,793 schemes to reduce the number of neurons and to downsize a circuit by configuring multi-layered feedforward oriented networks in a systolic array architecture. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> According to the parallel processing multiprocessors system etc related to Japanese Patent Publication No. 2,500,038, an existence or non-existence of error is detected based on a decision-by-majority process of signatures generated simultaneously with a process of an instruction set in a distributed parallel type computing system. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> Moreover, the operation frequency of the microprocessors have shown sharp increases over the recent years. Under this condition, there is developed an architecture (Schuster, S. et al., &ldquo;Asynchronous Interlocked Pipelined CMOS Circuits operating at 3.3-4.5 GHz&rdquo;, 2000, IEEE International solid-state circuits conference (ISSCC2000), WA17.3, vol. 43, pp. 292-293, 2000) in which the whole chip is not operated in synchronization with the single clock signal, and the chip is divided into a plurality of blocks and these blocks are operated asynchronously. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The prior arts described above are required to use global clock signals as control clock signals for taking synchronism of arithmetic elements, and to use local clock signals as control clock signals for forming a synchronization cluster for performing a local behavior. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> This architecture brings about increases both in circuit scale and in consumption of electric power, and is difficult to actualize a synchronization circuit operating stably without any contradiction. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> It is therefore a primary object of the present invention to stably implement a local synchronous behavior in parallel pulse signal processing without any contradiction owing to a function of outputting a phase synchronization signal having such a signal level that a phase difference between output signals of arithmetic elements falls within an allowable phase difference, to the arithmetic elements from a phase synchronization signal generation circuit, in accordance with outputs of the arithmetic elements of which the outputs are a target for phase synchronization, and also to actualize a low consumption of electric power. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> It is another object of the present invention that the same element actualizes a function of the phase synchronization signal generation circuit and a function of an arithmetic element performing a predetermined arithmetic process and outputting by switching over a topology of the circuit in accordance with a result of synchronization detection by a synchronization detection portion, and that a circuit scale is reduced. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> According to one aspect, the present invention which achieves these objectives relates to a signal processing circuit comprising a plurality of arithmetic elements connected to each other based on a predetermined rule and disposed in parallel, executing a predetermined arithmetic process with respect to input signals and outputting, a phase synchronization signal generation circuit outputting phase synchronization signals to the predetermined vicinal arithmetic elements, and a synchronization detection portion detecting synchronization within an allowable phase difference between the outputs of the predetermined vicinal arithmetic elements, wherein the phase synchronization signal generation circuit functions also as an arithmetic element executing the predetermined arithmetic process and outputting in accordance with a result of the synchronization detection by the synchronization detection portion. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> According to another aspect, the present invention which achieves these objectives relates to a signal processing circuit comprising a plurality of arithmetic elements connected to each other based on a predetermined rule and disposed in parallel, executing a predetermined arithmetic process with respect to input signals and outputting, a phase synchronization signal generation circuit outputting phase synchronization signals to the predetermined vicinal arithmetic elements, and a synchronization detection portion detecting synchronization within an allowable phase difference between the outputs of the predetermined vicinal arithmetic elements, wherein the output of each of the phase synchronization signals outputted to the predetermined vicinal arithmetic elements from the phase synchronization signal generation circuit, is so controlled as to fall within the allowable phase difference between the output signals from the predetermined vicinal arithmetic elements. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Other objectives and advantages besides those discussed above shall be apparent to those skilled in the art from the description of a preferred embodiment of the invention which follows. In the description, reference is made to accompanying drawings, which form a part thereof, and which illustrates an example of the invention. such example, however, is not exhaustive of the various embodiments of the invention, and therefore reference is made to the claims which follow the description for determining the scope of the invention.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a diagram showing a whole architecture of a network according to the present invention; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 2A, 2B</cross-reference> and <highlight><bold>2</bold></highlight>C are diagrams showing configurations of a synaptic portion and a neuron element portion, and a circuit architecture of neuron elements; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 3A and 3B</cross-reference> are diagrams showing how a plurality of pulses are propagated to feature detection layer neurons from a feature integration layer (or an input layer); </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 4A, 4B</cross-reference> and <highlight><bold>4</bold></highlight>C are diagrams showing an architecture of a synaptic circuit; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 5A, 5B</cross-reference> and <highlight><bold>5</bold></highlight>C are diagrams showing an architecture of a synaptic connection small circuit, and an architecture of a pulse phase delay circuit used in an embodiment 1; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a schematic diagram showing an example of a topology in a phase synchronization circuit in a second embodiment; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 7A, 7B</cross-reference>, <highlight><bold>7</bold></highlight>C, <highlight><bold>7</bold></highlight>D and <highlight><bold>7</bold></highlight>E are graphs showing a structure of a time window, an example of a weighting function distribution and an example of feature elements in the case of processing a plurality of pulses corresponding to the different feature elements, which are inputted to feature detection neurons; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a schematic diagram showing a topology in a case where a phase synchronization circuit according to a third embodiment is centered; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a graph showing pulse firing timings of the respective neurons; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 10A and 10B</cross-reference> are schematic diagrams each showing a topology in a case where a phase synchronization circuit according to a fourth embodiment is centered; </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a schematic diagram showing a topology in the case where the phase synchronization circuit according to the fourth embodiment is centered; </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a diagram showing an example of an architecture of a photographic system incorporating a pattern recognition system; </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a schematic diagram showing an example of a topology in a phase synchronization process in the first embodiment; </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 14A, 14B</cross-reference> and <highlight><bold>14</bold></highlight>C are diagrams showing configurations of blocks of the phase synchronization circuit; </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 15A and 15B</cross-reference> are diagrams showing a topology wherein inputs and outputs of phase synchronization signals are based, and a firing process with the phase synchronization signal; and </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a graph showing pulse firing timings of the respective neurons.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Preferred embodiments of the present invention will hereinafter be described in detail with reference to the accompanying drawings. </paragraph>
<paragraph id="P-0037" lvl="7"><number>&lsqb;0037&rsqb;</number> (First Embodiment) </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The discussion in a first embodiment is focused on a neural network model, of which a hint is acquired from a biological information processing system, as a local synchronous signal processing circuit. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> According to the present invention, however, entire functions and operations of a pulse signal processing circuit are not particularly limited. The present invention may include, if capable of transmitting the information in a way that forms a local synchronous cluster as will be mentioned later on, signal processing circuits having other architectures and functions. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> Accordingly, a pattern recognition system that will hereinafter be discussed is, it should be noted, merely one exemplification for explaining the present invention to the end. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> Outline of Whole Architecture </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a diagram showing a whole architecture of a network for a pattern detection/recognition system in the first embodiment. This pattern detection/recognition system mainly deals with information related to a recognition (detection) of an object or a geometrical feature. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the system has a so-called convolutional network architecture (LeCun, Y. and Bengio, Y., 1995, &ldquo;Convolutional Networks for Images Speed, and Time Series&rdquo; in Handbook of Brain Theory and Neural Networks (M. Arbib, Ed.), MIT Press, pp. 255-258). A final output is defined as a result of the recognition, i.e., a category of the object recognized. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> A data input layer <highlight><bold>1</bold></highlight> is a CMOS (Complementary Metal-Oxide Semiconductor) sensor or a photoelectric converting device such as a CCD (Charge Coupled Device) in the case of detecting and recognizing an image, and a voice input sensor in the case of detecting and recognizing a voice. Further, the data input layer <highlight><bold>1</bold></highlight> may be structured to input high-order data obtained from a result of analysis (for example, a primary component analysis, vector quantization and so on) by a predetermined data analyzing portion. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Given hereinafter is an explanation of the case of inputting the image. A feature detection layer (<highlight><bold>1</bold></highlight>, <highlight><bold>0</bold></highlight>) detects, based on a multiple resolution process such as Gabor wavelet conversion and others, a local low-order feature (that may contain a color component feature in addition to the geometrical feature) of an image patter by the number of a plurality of feature categories at a plurality of scale levels or with a plurality of resolutions at the same area in each of positions over the entire image surface (or at each of predetermined sampling points over the entire image surface). The feature detection layer (<highlight><bold>1</bold></highlight>, <highlight><bold>0</bold></highlight>) is constructed of neuron elements, each having a receptive field structure corresponding to a category of feature amount (which is, e.g., gradients of line segments defined as a geometrical structure in the case of extracting the line segments in a predetermined direction as a geometrical feature), and generating a pulse train corresponding to a degree thereof. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> A feature detection layer (<highlight><bold>1</bold></highlight>, k) configures processing channels with the plurality of resolutions (or at the plurality of scale levels) on the whole (wherein k&gE;0). Namely, when exemplifying a case where the Gabor wavelet conversion is executed on the feature detection layer (<highlight><bold>1</bold></highlight>, <highlight><bold>0</bold></highlight>), a set of feature detection cells with Gabor filter kernels having the same scale level but different directional selectivities as a receptive field structure, configure the same processing channel on the feature detection layer (<highlight><bold>1</bold></highlight>, <highlight><bold>0</bold></highlight>), and, on a subsequent layer (<highlight><bold>1</bold></highlight>, <highlight><bold>1</bold></highlight>) also, the feature detection cells (for detecting a higher-order feature) receiving outputs from the former feature detection cells, belong to the same channel as the above processing channel. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> On a still subsequent layer (<highlight><bold>1</bold></highlight>, k) (wherein k&gt;1) also, the feature detection cells receiving the outputs from the plurality of feature integration cells configuring the same channel similarly on a (<highlight><bold>2</bold></highlight>, k&minus;1) layer, are structured to belong to this channel. The processing at the same scale level (or with the same resolution level) proceeds through each processing channel, wherein the low-order through high-order features are detected and recognized by hierarchical parallel processing. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> A feature integration layer (<highlight><bold>2</bold></highlight>, <highlight><bold>0</bold></highlight>) has a predetermined receptive field structure (the receptive field hereinafter implies a connecting range with an output element of an immediate anterior layer, and the receptive field structure implies a connecting load distribution), and is constructed of neuron elements each generating the pulse train. The feature integration layer (<highlight><bold>2</bold></highlight>, <highlight><bold>0</bold></highlight>) integrates a plurality of neuron element outputs within the same receptive field from the feature detection layer (<highlight><bold>1</bold></highlight>, <highlight><bold>0</bold></highlight>) (the integration involving an operation such as sub-sampling based on local averaging and so on). Further, each receptive field of the neuron within the feature integration layer has a structure common to the neurons within the same layer. Each of the feature detection layers (<highlight><bold>1</bold></highlight>, <highlight><bold>1</bold></highlight>), (<highlight><bold>1</bold></highlight>, <highlight><bold>2</bold></highlight>), . . . , (<highlight><bold>1</bold></highlight>, N) and the feature integration layers ((<highlight><bold>2</bold></highlight>, <highlight><bold>1</bold></highlight>), (<highlight><bold>2</bold></highlight>, <highlight><bold>2</bold></highlight>), . . . , (<highlight><bold>2</bold></highlight>, N)) has a predetermined receptive field structure acquired by learning. The former group of feature detection layers ((<highlight><bold>1</bold></highlight>, <highlight><bold>1</bold></highlight>), . . . ) detect, as by the respective layers described above, a plurality of different features in respective feature detection modules. The latter group of feature integration layers ((<highlight><bold>2</bold></highlight>, <highlight><bold>1</bold></highlight>), . . . ) integrate results of detecting the plurality of features from the anterior feature detection layers. The former group of feature detection layers are, however, connected (wired) to receive cell element outputs of the anterior feature integration layers belong to the same channel. The sub-sampling defined as a process executed by the feature integration layer involves averaging the outputs from local areas (local receptive fields of the concerned feature integration layer neurons) from a feature detection cell group coming under the same feature category. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 2A</cross-reference> to <highlight><bold>2</bold></highlight>C are diagrams showing a configuration of a synaptic circuit and a configuration of the neuron element. A structure for connecting inter-layer neuron elements <highlight><bold>201</bold></highlight> is, as depicted in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>A, built by a signal transmission portion <highlight><bold>203</bold></highlight> (a wire or a delay line) corresponding to an axon of a neural cell and by synaptic circuits S<highlight><bold>202</bold></highlight> corresponding to dendrites thereof. <cross-reference target="DRAWINGS">FIG. 2A</cross-reference> shows the connecting architecture related to the outputs (that are inputs if viewed from a certain feature detection (integration) cell (N)) from a neuron group (ni) of a feature integration (detection) cell that configures the receptive field with respect to the feature detection (integration) cell (N). The signal transmission portion <highlight><bold>203</bold></highlight> drawn by a bold line serves as a common bus line, and pulse signals from the plurality of neurons, which a re arranged in time-series, are transmitted through on this signal transmission line. The same architecture is also adopted in the case of receiving the inputs from the cell (N) as an output destination. In this case, the input signals and the output signals may be processed in separation on the time-base absolutely in the same architecture, or the processing may be executed in a way that gives the same architecture as <cross-reference target="DRAWINGS">FIG. 2A</cross-reference> shows in two systems for inputting (the dendrite-side) and for outputting (the axon-side). </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> The synaptic circuits S<highlight><bold>202</bold></highlight> are categorized into those related to the inter-layer connections (which are the connection between the neurons on the feature detection layer <highlight><bold>102</bold></highlight> and the connection between the neurons on the feature integration layer <highlight><bold>103</bold></highlight>, and there might exist the on-layer neuron connections to a posterior layer and to an anterior layer), and those related to the connections between the neurons within on the same layer. The latter type of synaptic circuits are used, as the necessity may rise, mainly for connections with pacemaker neurons that will be explained later on and with the feature detection or integration neurons. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> In the synaptic circuit S<highlight><bold>202</bold></highlight>, a so-called excitatory connection involves amplifying the pulse signals, while an inhibitory connection involves attenuating the signals. In the case of transmitting the information through on the pulse signals, the amplification and the attenuation can be actualized by any one of an amplitude modulation, a pulse width modulation, a phase modulation and a frequency modulation of the pulse signal. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> According to the first embodiment, the synaptic circuit S<highlight><bold>202</bold></highlight> is used chiefly for a pulse phase modulation element, wherein the signal amplification is converted into a substantial advance as a quantity intrinsic to a feature of a pulse arrival time, whereas the attenuation is converted into a substantial delay. Namely, the synaptic connection, as will be mentioned later on, gives an arrival position (phase) on the time-base that is intrinsic to the feature in the neurons at the output destination, wherein the excitatory connection gives a phase advance of the arrival pulse with respect to a certain reference phase in terms of a qualitative aspect, and the inhibitory connection gives a delay likewise. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>A, each of neuron elements nj outputs the pulse signals (a spiked signal train), and involves the use of a so-called integrate-and-fire type neuron element as will be explained below. Note that the synaptic circuit and the neuron elements may, as illustrated in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>C, be combined to configure a circuit block. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Neuron Element </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Next, the neurons that form each layer will be described. Each of the neuron elements is extension-modeled based on the so-called integrate-and-fire type neuron, and is the same as this integrate-and-fire type neuron in terms of such a point that the neuron element fires when a result of linearly adding the input signals (a pulse train corresponding to an action potential) spatiotemporally exceeds a threshold value, and outputs the pulse signals. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2B</cross-reference> shows one example of a basic architecture representing a behavior principle of the pulse generation circuit (CMOS circuit) defined as the neuron element, and illustrates what a known circuit (IEEE Trans. On Neural Networks Vol. 10, p. 540) is extended. Herein, the pulse generation circuit is constructed as what receives the excitatory input and the inhibitory input. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> The behavior principle of this pulse generation circuit will hereinafter be explained. A time constant of a capacitor C<highlight><subscript>1</subscript></highlight>/resistor R<highlight><subscript>1 </subscript></highlight>circuit on the side of the excitatory input, is smaller than a time constant of a capacitor C<highlight><subscript>2</subscript></highlight>/resistor R<highlight><subscript>2 </subscript></highlight>circuit on the side of the inhibitory input. In a steady state, transistors T<highlight><subscript>1</subscript></highlight>, T<highlight><subscript>2</subscript></highlight>, T<highlight><subscript>3 </subscript></highlight>are cut off. Note that the resistor is actually constructed of a transistor connected in a diode mode. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> When an electric potential of the capacitor C<highlight><subscript>1 </subscript></highlight>increases and gets higher by a threshold value of the transistor T<highlight><subscript>1 </subscript></highlight>than that of the capacitor C<highlight><subscript>2</subscript></highlight>, the transistor T<highlight><subscript>1 </subscript></highlight>becomes active, and further the transistors T<highlight><subscript>2</subscript></highlight>, T<highlight><subscript>3 </subscript></highlight>get active. The transistors T<highlight><subscript>2</subscript></highlight>, T<highlight><subscript>3 </subscript></highlight>form a current mirror circuit, and an output of the circuit shown in <cross-reference target="DRAWINGS">FIG. 2B</cross-reference> is given forth from the side of the capacitor C<highlight><subscript>1 </subscript></highlight>by an unillustrated output circuit. The circuit is structured so that when an electric charge accumulation amount of the capacitor C<highlight><subscript>2 </subscript></highlight>is maximized, the transistors T<highlight><subscript>1 </subscript></highlight>falls into a shutdown, then the transistors T<highlight><subscript>2</subscript></highlight>, T<highlight><subscript>3 </subscript></highlight>are cut off as a result of the above shutdown, and a positive feedback comes to 0. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> During a so-called refractory period, the capacitor C<highlight><subscript>2 </subscript></highlight>discharges, and, if a potential of the capacitor C<highlight><subscript>1 </subscript></highlight>is larger than a potential of the capacitor C<highlight><subscript>2 </subscript></highlight>and unless a difference therebetween is over the threshold value of the transistor T<highlight><subscript>1</subscript></highlight>, the neuron does not respond. The periodic pulses are outputted with a repetition of alternate charging/discharging of the capacitors C<highlight><subscript>1</subscript></highlight>, C<highlight><subscript>2</subscript></highlight>, and a frequency thereof is generally determined corresponding to a level of the excitatory input. Owing to an existence of the refractory period, the frequency can be, however, restricted to the maximum value, and a fixed frequency can also be outputted. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> The potential, i.e., the charge accumulation amount of the capacitor is controlled in terms of the time by a reference voltage control circuit (time window weighting function generation circuit) <highlight><bold>204</bold></highlight>. What reflects this control characteristic is a weighted addition within a time window with respect to the input pulse, which will be mentioned later on (see <cross-reference target="DRAWINGS">FIGS. 7A</cross-reference> to <highlight><bold>7</bold></highlight>E). This reference voltage control circuit <highlight><bold>204</bold></highlight> generates a reference voltage signal (corresponding to a weighting function in <cross-reference target="DRAWINGS">FIG. 7B</cross-reference>) on the basis of an input timing (or an interconnection input to the neuron of the subsequent layer) from a pacemaker neuron that will hereinafter be described. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Generally, a relationship between the summation of the input signals and the output level (the pulse phase, the pulse frequency, the pulse width and so forth) changes depending on a sensitivity characteristic of the neuron. This sensitivity characteristic can be changed depending on a top-down input from a higher-order layer. In the following discussion, it is assumed for an explanatory convenience that circuit parameters be set so that a pulse output frequency corresponding to the summation value of the input signals rises steeply (therefore, the values are substantially binary in a frequency domain) and that the output level (such as a timing with a phase modulation added) and so on) fluctuates depending on the pulse phase modulation. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Moreover, a pulse phase modulation portion may have an addition of the circuits as shown in <cross-reference target="DRAWINGS">FIGS. 5A</cross-reference> to <highlight><bold>5</bold></highlight>C, which will hereinafter be described. With this scheme, the weighting function in the time window is controlled based on the reference voltage with the result that the phase-of the pulse output from this neuron changes, and this phase can be used as an output level of the neuron. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> A time &tgr;<highlight><subscript>w1</subscript></highlight>, as shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>B, corresponding to a maximum value of the weighting function that gives a time integrating characteristic (receiving sensitivity characteristic) with respect to the pulse having undergone the pulse phase modulation at the synaptic connection, is generally set earlier in time than an arrival predicted time &tgr;<highlight><subscript>s1 </subscript></highlight>of the pulse intrinsic to the feature given by the synaptic connection. As a result, the pulse arriving earlier than the arrival predicted time within a fixed range (the pulse arriving too early is attenuated in the example in <cross-reference target="DRAWINGS">FIG. 7B</cross-reference>) is, in the neuron receiving this pulse, integrated in time as a pulse signal having a high output level. A profile of the weighting function is not limited to a symmetry as seen on Gaussian function etc and may assume an asymmetry. It should be noted based on the gist elucidated above that the center of each weighting function in <cross-reference target="DRAWINGS">FIG. 7B</cross-reference> does not correspond to the pulse arrival predicted time. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Further, an output phase of a (presynaptic) neuron has such an output characteristic that a delay (phase from a fiducial time corresponding to the beginning of the time window as will be explained later on, is determined by the charge accumulation amount after detecting phase synchronization when receiving the reference pulse (based on the pacemaker output and others). A detailed architecture of the circuit giving this output characteristic is not essential to the present invention and is therefore omitted herein. A pulse phase of a postsynaptic neuron is what the pulse phase of the presynaptic neuron is added to an intrinsic phase modulation amount given at the synapse concerned. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Further, there may also be utilized such a known circuit architecture as to give forth an oscillatory output delayed by a predetermined timing when the input summation value obtained by use of the window function and so on exceeds the threshold value. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> The architecture of the neuron elements using the neurons belonging to the feature detection layer <highlight><bold>102</bold></highlight> or the feature integration layer <highlight><bold>103</bold></highlight>, may take such a circuit architecture as to output the pulse with a phase delay corresponding to the input level (the simple or weighted summation value of the inputs described above) at which the concerned neuron receives from the receptive field of the anterior layer after attaining the phase synchronization of the output receiving the pulse outputted from the pacemaker neuron in a case where a firing pattern is controlled based on an output timing phase synchronization circuit of the pacemaker neuron that will be mentioned later on. In this case, before the output to which the pulse signal from the pacemaker neuron is inputted is phase-synchronized, there exists a transient state where the respective neurons output the pulses in random phases with respect to each other in accordance with the input levels. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> The neuron of the feature detection layer has, as explained above, the receptive field structure corresponding to the feature category, and outputs the pulse with an output (given herein in the form of the phase change; it may also be structured to show a change based on the frequency, the amplitude and the pulse width) taking a so-called squashing function value, i.e., such a non-reductive and nonlinear function as to gradually saturate with a fixed level, as in the case of, e.g., a sigmoidal function etc. in accordance with a load summation value (that will be explained below) when this load summation value depending on the time window function of the input pulse signal from the neuron of the anterior layer (the input layer or the feature integration layer) is equal to or larger than the threshold value. </paragraph>
<paragraph id="P-0068" lvl="7"><number>&lsqb;0068&rsqb;</number> Synaptic Circuit and Others </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 4A</cross-reference> to <highlight><bold>4</bold></highlight>C show a matrix layout of synaptic connection small circuits each giving a synaptic connection strength (that implies a magnitude of the modulation in regard to the phase delay etc) to each of neurons n&prime;<highlight><subscript>j </subscript></highlight>to which the neurons ni are connected in the synaptic circuit <highlight><bold>202</bold></highlight> (Si). </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> If the network takes such an architecture as to have a shared connection mode (for representing the synaptic connection with one single weighting coefficient in the same way) of the connection loads, delay quantities (indicated by P<highlight><subscript>ij </subscript></highlight>below) at the respective synapses can be uniformed within the same receptive field unlike the case shown in <cross-reference target="DRAWINGS">FIGS. 3A and 3B</cross-reference>. Particularly, the connection to the feature integration layer from the feature detection payer may take this architecture without depending on the detection object (i.e., without depending on a category of the target) in a case where the feature integration layer performs the sub-sampling based on the local averaging (the uniform weighting is, however, to be adopted)of the outputs from the feature detection layer existing anterior to this feature integration layer. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> In this case, as illustrated in <cross-reference target="DRAWINGS">FIG. 4C, a</cross-reference> single circuit S<highlight><subscript>k,i </subscript></highlight>suffices for forming each of the synaptic connection small circuits <highlight><bold>401</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>A, and this circuit architecture is particularly economical. On the other hand, if the connection to the feature detection layer from the feature integration layer (or a sensor input layer) takes this circuit architecture, what the feature detection neuron detects is such an event that the pulses representing a plurality of different feature elements arrive simultaneously (or arrive substantially at the same time). </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> As depicted in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>B, each of the synaptic connection small circuits <highlight><bold>401</bold></highlight> is constructed of a learning circuit <highlight><bold>402</bold></highlight> and a phase delay circuit <highlight><bold>403</bold></highlight>. The learning circuit <highlight><bold>402</bold></highlight> adjusts the above delay quantity by changing a characteristic of the phase delay circuit <highlight><bold>403</bold></highlight>. Further, the learning circuit <highlight><bold>402</bold></highlight> stores a characteristic value thereof (or a control value thereof) on a floating gate element or on a capacitor connected to the floating gate element. The phase delay circuit <highlight><bold>403</bold></highlight> is classified as a pulse phase modulation circuit and is, as shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>A, configured by using, for instance, monostable multivibrators <highlight><bold>506</bold></highlight>, <highlight><bold>507</bold></highlight>, resistors <highlight><bold>501</bold></highlight>, <highlight><bold>504</bold></highlight>, capacitors <highlight><bold>503</bold></highlight>, <highlight><bold>505</bold></highlight> and a transistor <highlight><bold>502</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 5B</cross-reference> shows respective timings of a rectangular wave P<highlight><bold>1</bold></highlight> ((<highlight><bold>1</bold></highlight>) in <cross-reference target="DRAWINGS">FIG. 5B</cross-reference>) inputted to the monostable multivibrator <highlight><bold>506</bold></highlight>, a rectangular wave P<highlight><bold>2</bold></highlight> ((<highlight><bold>2</bold></highlight>) in <cross-reference target="DRAWINGS">FIG. 5B</cross-reference>) outputted from the monostable multivibrator <highlight><bold>506</bold></highlight>, and a rectangular wave P<highlight><bold>3</bold></highlight> ((<highlight><bold>3</bold></highlight>) in <cross-reference target="DRAWINGS">FIG. 5B</cross-reference>) outputted from the monostable multivibrator <highlight><bold>507</bold></highlight>. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> Though a detailed explanation of an operational mechanism of the phase delay circuit <highlight><bold>403</bold></highlight> is omitted, a pulse width of the rectangular wave P<highlight><bold>1</bold></highlight> is determined by a time till a voltage of the capacitor <highlight><bold>503</bold></highlight> based on a charging current reaches a predetermined threshold value, while a pulse width of the rectangular wave P<highlight><bold>2</bold></highlight> is determined by a time constant of the resistor <highlight><bold>504</bold></highlight> and the capacitor <highlight><bold>505</bold></highlight>. If the pulse width of P<highlight><bold>2</bold></highlight> expands (as indicated by a dotted-line rectangular wave in <cross-reference target="DRAWINGS">FIG. 5B</cross-reference>) and if a fall timing thereof is shifted back, a rise timing of P<highlight><bold>3</bold></highlight> is shifted by the same quantity, however, the pulse width of P<highlight><bold>3</bold></highlight> remains unchanged, and it therefore follows that the rectangular wave is outputted in a way of being modulated by a phase of the input pulse. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> A control voltage Ec is changed by the learning circuit <highlight><bold>402</bold></highlight> for controlling the charge accumulation amount to a refresh circuit <highlight><bold>509</bold></highlight> having the reference voltage and to the capacitor <highlight><bold>508</bold></highlight> for giving the connection load, whereby the pulse phase (delay quantity) can be controlled. A long-term retainment of this connection load may involve storing the connection load as charge of the floating gate element (not shown) provided outside the circuit shown in <cross-reference target="DRAWINGS">FIG. 5A</cross-reference> after the learning behavior or by writing it to a digital memory and so on. There may be utilized other known circuit architectures such as the architectures (refer to e.g., Japanese Patent Application Laid-Open Nos. 5-37317 and 10-327054) each schemed to downsize the circuit. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> What is exemplified as the learning circuit at the synapse that actualizes the simultaneous arrival of the pulses or the predetermined phase modulation amount, includes the circuit elements as shown in FIG. <highlight><bold>5</bold></highlight>C. To be specific, the learning circuit <highlight><bold>402</bold></highlight> can be constructed of a pulse propagation time measuring circuit <highlight><bold>510</bold></highlight> (a propagation time herein indicates a time difference between a time of the pulse output of a presynaptic neuron on a certain layer and an arrival time of this pulse at an output destination neuron existing on a next layer), a time window generation circuit <highlight><bold>511</bold></highlight>, and a pulse phase modulation amount adjusting circuit <highlight><bold>512</bold></highlight> for adjusting a pulse phase modulation amount in the synaptic portion so that the propagation time takes a fixed value. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> The propagation time measuring circuit <highlight><bold>510</bold></highlight> involves the use of an architecture for inputting clock pulses from the pacemaker neurons configuring the same local receptive field as will be explained later on and obtaining the propagation time based on an output from a counter circuit for these clock pulses in duration of a predetermined time width (time window: see <cross-reference target="DRAWINGS">FIG. 3B</cross-reference>). Note that the time window is set based on a point of firing time of the output destination neuron, whereby Hebb&apos;s learning algorithm (rule) extended as shown below is applied. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> Process (Extraction of Low-Order Feature) on Feature Detection Layer (<highlight><bold>1</bold></highlight>,<highlight><bold>0</bold></highlight>) Supposing that the feature detection layer (<highlight><bold>1</bold></highlight>,<highlight><bold>0</bold></highlight>) contains the neurons detecting a structure (low-order feature) of a pattern having a predetermined spatial frequency in a local area having a certain size and a directional component of being vertical and if there exists a structure corresponding to an interior of the receptive field of N<highlight><bold>1</bold></highlight> on the data input layer <highlight><bold>1</bold></highlight>, the neuron outputs the pulse in phase corresponding to a contrast thereof. This type of function can be actualized by a Gabor filter. A feature detection filter function performed by each of the neurons of the feature detection layer (<highlight><bold>1</bold></highlight>,<highlight><bold>0</bold></highlight>) will hereinafter be discussed. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> It is assumed that the Gabor wavelet conversion expressed by a filter set having multi-scales and multi-directional components on the feature detection layer (<highlight><bold>1</bold></highlight>,<highlight><bold>0</bold></highlight>) and each of the intra-layer neurons (or each group consisting of a plurality of neurons) has a predetermined Gabor filtering function. On the feature detection layer, one single channel is configured by clustering a plurality of neurons groups each consisting of neurons having the receptive field structures corresponding to a convolutional operation kernels of a plurality of Gabor functions that have a fixed scale level (resolution) and different directional selectivities. The neuron group forming the same channel has a different directional selectivity, and the neuron groups exhibiting the same size selectivity may be disposed in positions adjacent to each other, or the neuron groups belonging to different processing channels may also be disposed adjacent to each other. This scheme is based on an idea that the actualization is easier in terms of the circuit architecture by adopting the layouts shown in the respective Figures for the convenience&apos;s sake of a connecting process that will be mentioned below in the group-oriented coding. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> Incidentally, for details of the method of executing the Gabor wavelet conversion in the neural network, refer to a document (IEEE Trans. On Acoustics, Speed, and Signal Processing, vol. 36, pp. 1169-1179) by Daugman (1988). </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> Each of the neurons of the feature detection layer (<highlight><bold>1</bold></highlight>,<highlight><bold>0</bold></highlight>) has the receptive field structure corresponding to a kernel g<highlight><subscript>mn</subscript></highlight>. The kernel g<highlight><subscript>mn </subscript></highlight>having the same scale index m has a receptive field of the same size, and a corresponding kernel gmn size is set corresponding to the scale index in terms of the operation. Herein, the sizes such as 30&times;30, 15&times;15 and 7&times;7 are set on the input image in sequence from the roughest scale. Each neuron outputs the pulse at such an output level (which is herein on a phase basis; an architecture on a frequency basis or an amplitude basis or a pulse basis may also, however, be used) as to become a nonlinear squashing function of a wavelet conversion coefficient value obtained by inputting a sum of products of distribution weighting coefficients and image data. As a result, it follows that the Gabor wavelet conversion is executed as an output of this whole layer (<highlight><bold>1</bold></highlight>,<highlight><bold>0</bold></highlight>). </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> Processes (Extractions of Intermediate- and High-Order Features) on Feature Detection Layer Unlike the feature detection layer (<highlight><bold>1</bold></highlight>,<highlight><bold>0</bold></highlight>), each of the neurons of the subsequent feature detection layers ((<highlight><bold>1</bold></highlight>,<highlight><bold>1</bold></highlight>), (<highlight><bold>1</bold></highlight>,<highlight><bold>2</bold></highlight>), . . . ) forms, based on the so-called Hebb&apos;s learning algorithm etc, the receptive field structure for detecting a feature intrinsic to a pattern of a recognition object. On a more posterior layer, a size of the local area in which to detect the feature becomes stepwise more approximate to a size of the whole recognition object, and geometrically an intermediate- or high-order feature is detected. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> For instance, when detecting and recognizing a face, the intermediate- (or high-order) feature represents a feature at pattern-element-oriented levels such as eyes, a nose, a mouth etc shaping the face. Between different channels, if at the same hierarchical level (the same level in terms of a complexity of the feature to be detected), a difference of the feature detected comes under the same category but is what is detected by the scales different from each other. For example, the &lsqb;eye&rsqb; defined as the intermediate-order feature is detected as an &lsqb;eye&rsqb; having a different size at a different processing channel. Namely, the scheme is that the in-image &lsqb;eye&rsqb; having a given size is detected at the plurality of processing channels exhibiting different scale level selectivities. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> Note that each of the neurons of the feature detection layer may generally have such a mechanism as to receive, based on the output of the anterior layer, an inhibitory (shunting inhibition) connection in order to stabilize the output (without depending on the extractions of the low- and high-order features). </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Process on Feature Integration Layer </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> The neurons of the feature integration layers ((<highlight><bold>2</bold></highlight>,<highlight><bold>0</bold></highlight>), (<highlight><bold>2</bold></highlight>,<highlight><bold>1</bold></highlight>), . . . ) will be explained- As illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the connection to the feature integration layer (e.g., (<highlight><bold>2</bold></highlight>,<highlight><bold>0</bold></highlight>)) from the feature detection layer (e.g., (<highlight><bold>1</bold></highlight>,<highlight><bold>0</bold></highlight>)) is configured to receive, on the excitatory input side, both of outputs of phase synchronization circuits that will be described below and inputs of the excitatory connections from the neurons of the same category (type of feature elements of the anterior feature detection layer within the receptive fields of the concerned feature integration neurons. The function of the neuron of the integration layer is, as explained above, the local averaging or sub-sampling for every feature category. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> According to the former mode, the plurality of pulses of the same category of feature are inputted, and then integrated and averaged in the local area (receptive field) (alternatively, a representative value such as a maximum value is calculated within the receptive field), thereby making it possible to surely detect a positional fluctuation and a deformation of the feature. Therefore, the receptive field structure of the neuron of the feature integration layer may be formed so as to become uniform (such as being in a rectangular area having a predetermined size in any cases and exhibiting a uniform distribution of the sensitivity or the weighting coefficient therein) without depending on the feature category. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> Pulse Signal Processing on Feature Integration Layer </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> As discussed above, according to the first embodiment, the feature integration cell is not structured to receive the synchronization detection signal from the phase synchronization circuit on the feature detection layer with a layer number (<highlight><bold>1</bold></highlight>,k) anterior thereto. The reason is that in the feature integration cell, the neurons output the pulses in phase (any one of the frequency, the pulse width and the amplitude may be dependent, however, the phase is adopted in the first embodiment) determined not by the arrival time pattern of the input pulse but by, if anything, an input level (such as a temporal summation value of the input pulses) within a fixed time range, and hence a time window occurrence timing is not so important. Note that this does not intend to exclude an architecture in which the feature integration cell receives the synchronization signal from the phase synchronization circuit of the anterior feature detection layer, and this architecture is, as a matter of course, feasible. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> Behavior Principles of Pattern Detection and Phase Synchronization </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> Next, pulse encoding of a two-dimensional graphic pattern and a detection method thereof will be explained. <cross-reference target="DRAWINGS">FIGS. 3A and 3B</cross-reference> schematically shows how the pulse signals are propagated to the feature detection layer from the feature integration layer (e.g., from the layer (<highlight><bold>2</bold></highlight>,<highlight><bold>0</bold></highlight>) to the layer (<highlight><bold>1</bold></highlight>,<highlight><bold>1</bold></highlight>) in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>). The neurons ni on the side of the feature integration layer correspond to feature amounts (or feature elements) different from each other, while the neurons n&prime;<highlight><subscript>j </subscript></highlight>on the side of the feature detection layer get involved in detecting a higher-order feature (pattern elements) obtained by combining the respective features within the same receptive field. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> An intrinsic delay (intrinsic to the feature) due to a pulse propagation time and a time delay etc in the synaptic connection (S<highlight><subscript>j,i</subscript></highlight>) to the neuron n&prime;<highlight><subscript>j </subscript></highlight>from the neuron ni, occurs in each inter-neuron connection. As a result, so far as the pulses are outputted from the neurons of the feature integration layer, pulses of a pulse train Pi are set to arrive at the neuron n&prime;<highlight><subscript>j </subscript></highlight>in a predetermined sequence (such as P<highlight><bold>4</bold></highlight>, P<highlight><bold>3</bold></highlight>, P<highlight><bold>2</bold></highlight>, P<highlight><bold>1</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 3A</cross-reference>), depending on a delay quantity at the synaptic connection that is determined by learning. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3B</cross-reference> shows a pulse propagation timing to a certain feature detection cells (n&prime;<highlight><subscript>j</subscript></highlight>) (detecting a higher-order feature) in a layer having a layer number (<highlight><bold>1</bold></highlight>,k&plus;1) from feature integration cells n<highlight><bold>1</bold></highlight>, n<highlight><bold>2</bold></highlight>, n<highlight><bold>3</bold></highlight> (individually representing different categories of features) in a layer having a layer number (<highlight><bold>2</bold></highlight>,k) after taking the phase synchronization between the neurons of the feature integration layer in the case of executing the synchronization control of the time window by using the synchronization detection signal transmitted from the phase synchronization circuit that will be explained later on. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 13</cross-reference>, the phase synchronization circuit is connected to the feature detection neuron forming the same receptive field and detecting a different category of feature, forms the same receptive field as that of the feature detection neuron and receives the excitatory connection from the feature integration layer (or the input layer). Further, an output from the phase synchronization circuit is outputted to the excitatory input of the neuron of the feature integration layer, and hence there exists an (loop-shaped) interconnection between the feature integration layer group and the phase synchronization circuit. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> Subsequently, the circuit architecture in the first embodiment, as depicted in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>, includes a synchronization detection portion for detecting the phase synchronization of the output signals upon receiving an input of this output signal from the feature integration layer neuron, controlling switches <highlight><bold>1</bold></highlight>, <highlight><bold>2</bold></highlight> and outputting the synchronization detection signal, and a module having an interconnection with the feature integration layer neuron and performing two types of functions as the feature detection layer neuron and as a phase synchronization signal generation circuit. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> Note that these two types of functions are switched over by operating the switches <highlight><bold>1</bold></highlight>, <highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> Subsequently, a processing flow in the architecture described above will be described in sequence. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> At first, each of the feature detection layer neuron and the phase synchronization signal generation circuit functions as the phase synchronization signal generation circuit till the phase synchronization of the output from the feature integration layer neuron is established (hereinafter this is called the phase synchronization signal generation circuit till the phase synchronization is established). </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> Note that the switch <highlight><bold>1</bold></highlight> is connected downward, while the switch <highlight><bold>2</bold></highlight> is connected upward at the present time. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> When the feature integration layer neuron fires upon receiving the output from the anterior layer and gives forth an output, the output signal thereof is amplified by the amplifier and thereafter inputted to the phase synchronization signal generation circuit. The phase synchronization signal generation circuit, when receiving even a single input, outputs the phase synchronization signal defined as the pulse signal to the feature integration neuron. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> Assuming herein that a threshold value characteristic of the phase synchronization signal generation circuit be set to have a predetermined value, the output from the feature integration layer neuron is temporarily transmitted through the amplifier and amplified therein so that the phase synchronization signal generation circuit can fire with one single pulse. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> Subsequently, the phase synchronization signal outputted by firing of the phase synchronization signal generation circuit is inputted to the feature integration layer neuron, however, a level of the phase synchronization signal received finally by the feature integration layer neuron is herein set so that the output pulse of the phase synchronization signal generation circuit is inputted to the amplifier to amplify the signal level, and an internal potential of the feature integration layer neuron can reach a threshold value within an allowable phase difference. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> Herein, the allowable phase difference corresponds to a phase synchronization detection window width in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, and, as will be mentioned below, the phase synchronization detection portion detects the phase synchronization with the aid of an integrated value of the output signal from the feature integration layer, which has been inputted inside the phase synchronization detection window. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> The feature integration layer neuron, upon receiving a phase synchronization pulse signal, except for a certain instance just during a refractory period, exceeds a firing threshold level due to the phase synchronization pulse signal in whatever internal condition. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> Herein, as shown in <cross-reference target="DRAWINGS">FIG. 15B, a</cross-reference> minute difference between firing phases of the feature integration layer neurons, occurs depending on a difference between the internal conditions of the respective feature integration layer neurons just when the phase synchronization pulse signal is inputted. As explained above, however, since the phase synchronization signal level is set so that the phase difference is under the allowable phase difference, the outputs of the respective feature integration layer neurons to which the phase synchronization signals are inputted for a time excluding the refractory period, with the phase difference falling within the allowable phase difference, come to a synchronizing state. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> Then, further the feature integration neuron staying in the refractory period in the behavior described above repeats the behavior described above till the same neuron receives the phase synchronization signal at a timing other than the refractory period and fires, whereby the synchronization of the outputs of all the feature integration layer neurons can be eventually taken. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> The subsequent discussion will be focused on the phase synchronization detection portion for detecting the phase synchronization state explained above. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>, the phase synchronization detection portion receives, as an input signal, the output of the feature integration layer neuron. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> Herein, as shown in <cross-reference target="DRAWINGS">FIGS. 14A and 14B</cross-reference>, the phase synchronization detection portion has the same architecture as that of the feature integration layer neuron that has been touched in the discussion on the neuron elements, and fires and outputs if an integrated value of input values within the phase synchronization detection windows each having a predetermined time determined by the phase synchronization detection window generation circuit, exceeds a threshold value. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> Accordingly, the time width of this phase synchronization detection window is set to the allowable phase difference in the case where the feature integration layer neuron phase-synchronizes, and further a firing threshold value is set to an integrated value of the outputs of all the feature integration layer neurons to be connected, whereby the phase synchronization of the feature integration layer neuron can be detected. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> Namely, as depicted in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, the allowable phase difference is set as the phase synchronization detection window, and, when the outputs of all the feature integration layer neurons are synchronized, the neuron element circuit in the phase synchronization detection portion fires as the input integrated value in the phase synchronization detection window reaches the threshold value. As a consequence, the synchronous firing of the feature integration layer neuron can be therefore detected. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> Next, a behavior after detecting the phase synchronization will be discussed. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>A, the phase synchronization detection portion includes a switch control signal generation circuit that generates a switch control signal in accordance with the output of the neuron element circuit, and a synchronization detection signal generation circuit generating a synchronization detection signal in accordance with the above output. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> The phase synchronization detection portion, when detecting the phase synchronization of the feature integration layer neuron due to firing of the neuron element circuit as described above, outputs the switch control signal from the switch control signal generation circuit receiving the output of the neuron element circuit, thereby switching over the switch <highlight><bold>1</bold></highlight> upward. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> This behavior implies that the input to the phase synchronization signal generation circuit becomes what the output of the feature integration layer neuron has undergone the processes of the synaptic circuits S<highlight><bold>1</bold></highlight> through S<highlight><bold>4</bold></highlight>, and the function of the phase synchronization signal generation circuit is switched over to the function of the feature detection layer neuron (hereinafter, the phase synchronization signal generation circuit is called the feature detection layer neuron till the feature detection layer neuron completes the operation and output based on the output signals of the feature integration layer neuron which will be mentioned later on). </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> Then, further the phase synchronization detection portion, in order to transmit the output from the feature detection layer neuron to a posterior processing hierarchy, outputs the switch control signal from the switch control signal generation circuit receiving the output of the neuron element circuit and switches over the switch <highlight><bold>2</bold></highlight> downward, thus setting in a conductive state the connection between the feature detection layer neuron and the posterior feature integration layer neuron. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> Herein, the output signal of the feature integration layer neuron that is to be inputted to the feature detection layer neuron becomes, as the input of the phase synchronization signal to the feature integration layer neuron is stopped by the above switching behavior described above, an output signal based on firing that genuinely corresponds to the input from the layer anterior to the feature integration layer neuron. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> Moreover, the phase synchronization detection portion outputs the synchronization detection signal to the feature detection layer neuron from the synchronization detection signal generation circuit receiving the output of the neuron element circuit, and gives a reference time for a generation timing of the time window that will be explained below. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> In this case, a time required till the output from the feature integration layer arrives at the feature detection layer, is calculated beforehand, thereby making it possible to properly establish a relationship between the synchronization detection signal and the generation timing of the time window. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> According to the first embodiment, the synchronization detection signal is set as the pulse-shaped signal, and the point of time when this pulse signal is inputted to the feature detection layer neuron, is set as the beginning of the time window. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> Note that the integration layer neuron corresponding to the duplex receptive field portion, in the process of executing the phase synchronization process explained above, receives the inputs of a plurality of different phase synchronization signals as illustrated in <cross-reference target="DRAWINGS">FIG. 15A</cross-reference> (herein, the input to the feature integration layer neuron from the anterior layer is indicated by a fine line, the input to the feature detection layer neuron from the feature integration layer neuron is drawn by a dotted line, and the phase synchronization signal is shown by a bold line), however, if the integration layer neuron corresponding to the duplex receptive field portion fires even once due to any one of the input from the anterior layer and the input from the phase synchronization signal generation circuit, the output pulse thereof is inputted to the plurality of phase synchronization signal generation circuits, and hence the phases of the plurality of phase synchronization signals are also synchronized at that point of time. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> Accordingly, it follows that the plurality of phase synchronization signals are inputted, in a state of their phases being synchronized, to the feature integration layer neurons corresponding to the subsequent duplex receptive field portions, and the process of establishing the phase synchronization of the feature integration layer neuron takes the same course as in the case based on the single phase synchronization signal described above. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> Thus, even when the feature integration layer neuron corresponding to the duplex receptive field portion receives the inputs of the plurality of phase synchronization signals, the phase synchronization of the outputs can be established with a stability without any contradiction. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> Further, particularly in the phase synchronization signal generation circuit, if a time interval till the phase synchronization signal is outputted since the signal has been inputted, is set equal to or longer than the refractory period of the feature integration layer neuron, the feature integration layer neuron that did not fire because of the phase synchronization signal being inputted during the refractory period, becomes capable of firing and outputting in a way that phase-synchronizes with other feature integration layer neurons when inputting the next phase synchronization signal, whereby the time up to the phase synchronization can be reduced. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> An arithmetic behavior of the feature detection layer neuron after the phase synchronization of the output of the feature integration layer neuron has been detected, will be explained in succession. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> When the synchronization detection signal is inputted to the feature detection layer neuron from the phase synchronization detection portion, as described above, the time window occurs due to the synchronization detection signal. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> Herein, the time window, which is determined for every feature detection layer neuron (n&prime;<highlight><subscript>i</subscript></highlight>), is common to the respective neurons within the feature integration layer forming the same receptive field with respect to the neuron (n&prime;<highlight><subscript>1</subscript></highlight>), and gives a time range for a time window integration. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> The synchronization detection portion existing on the layer having a layer number (<highlight><bold>1</bold></highlight>,k) (where k is a natural number) outputs the pulse output as the synchronization detection signal to the neuron of the feature detection layer (having the layer number (<highlight><bold>1</bold></highlight>,k)), whereby the feature detection layer neuron gives a timing signal for generating the time window when the feature detection layer neuron adds the inputs in time aspect. A start time of this time window serves as a reference time for measuring an arrival time of the pulse outputted from each feature integration cell. Namely, the synchronization detection portion gives the timing for outputting the pulse from the feature integration layer neuron, and a reference pulse for a time window integration in the feature detection cell. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> Each pulse is given a predetermined quantity of phase delay when passing via the synaptic circuit, and arrives at the feature detection cell further via the signal transmission line such as the common bus. A sequence of the pulse train on the time-base at this time is expressed such as pulses (P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, P<highlight><bold>3</bold></highlight>) drawn by the dotted lines on the time-base of the feature detection cell. </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> In the feature detection cell, if larger than the threshold value as a result of the time window integration (normally the integration is effected once; there may also be, however, executed the electric charge accumulation involving the time window integration effected multiple times or the averaging process involving the time window integration effected multiple times) of the respective pulses (P<highlight><bold>1</bold></highlight>, P<highlight><bold>2</bold></highlight>, P<highlight><bold>3</bold></highlight>), a pulse output (Pd) is outputted based on a termination time of the time window. Note that the in-learning time window shown in the same Figure is what is referred to when executing the learning algorithm (or rule) that will hereinafter be discussed. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> Subsequently, when the feature detection layer neuron completes, as described above, the implementation of the arithmetic behavior that will be explained below, the switch <highlight><bold>1</bold></highlight> is switched back again downward, and the output of the feature integration layer neuron is inputted to the feature detection layer neuron via the amplifier. </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> Further, at the same time, the switch <highlight><bold>2</bold></highlight> is switched back again upward, and the output of the feature detection layer neuron is inputted to the feature integration layer neuron. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> Namely, this behavior implies that the function of the feature detection layer neuron is switched over to the phase synchronization signal generation circuit. </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> Note that according to the first embodiment the switching behaviors of the switches <highlight><bold>1</bold></highlight>, <highlight><bold>2</bold></highlight> are herein actualized by setting beforehand so that the switch control signal is outputted from the switch control signal generation circuit after an elapse of a predetermined time since the switching behavior of the last time. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> Moreover, the behaviors of the switches <highlight><bold>1</bold></highlight>, <highlight><bold>2</bold></highlight> herein can be also performed by use of other control portions, however, this is not related to the essential point of the present invention, and therefore its explanation is omitted. </paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> shows pulse output timings of the respective neurons corresponding to those-in <cross-reference target="DRAWINGS">FIG. 15A</cross-reference> with respect to the processes discussed so far. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, when the feature integration layer neurons (N<highlight><subscript>11 </subscript></highlight>through N<highlight><subscript>61</subscript></highlight>) fire due to the outputs of the feature detection layer neurons of the anterior layer and perform outputting, the phase synchronization signals are outputted from the phase synchronization signal generation circuits. The feature integration layer neuron to which the phase synchronization signal has been inputted undergoes the phase synchronization process described above, and the phase synchronization detection portion detects the phase synchronization of the outputs within the phase synchronization detection window. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> When the phase synchronization detection portion detects the phase synchronization of the outputs of the feature integration layer neurons, the synchronization detection signals are outputted to the feature detection layer neurons (N&prime;<highlight><subscript>2D </subscript></highlight>through N&prime;<highlight><subscript>3D</subscript></highlight>) </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> As a result, the feature detection layer neuron executes the arithmetic process based on the time window and outputs corresponding to a result of this arithmetic process. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> As discussed above, the function of the phase synchronization signal generation circuit and the function of the feature detection layer neuron are switched over by the switching behavior, whereby it is feasible to make compatible both the establishment of the phase synchronization of the outputs with the stability without any contradiction and downsizing of the circuit. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> Spatiotemporal Integration of Pulse Outputs and Network Characteristic </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> Next, an arithmetic process of satiotemporal weighting summation (a load summation) of the input pulses will be explained. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>B, each neuron takes a load summation of the input pulses by use of a predetermined weighting function (e.g., Gaussian function) for every sub time window (timeslot), and the summation of loads is compared with a threshold value. The symbol &tgr;<highlight><subscript>j </subscript></highlight>represents a central position of the weighting function of a sub time window j, and is expressed by a start time reference (an elapse time since the start time) of the time window. The weighting function is generally a function of a distance (a deviation on the time-base) from a predetermined central position (representing a pulse arrival time in the case of detecting a detection target feature), and assumes a symmetry. Accordingly, supposing that the central position &tgr;<highlight><subscript>j </subscript></highlight>of the weighting function of each sub time window (timeslot)<highlight><subscript>j </subscript></highlight>of the neuron corresponds to a time delay after learning between the neurons, a neural network for obtaining the spatiotemporal weighting summation (the load summation) of the input pulses can be defined as one category of a radial basis function network (which will hereinafter be abbreviated to RBF) in the time-base domain. A time window FT<highlight><subscript>i </subscript></highlight>of the neuron ni using Gaussian function as a weighting function is given by:  
<math-cwu id="MATH-US-00001">
<number>1</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>F</mi>
          <mi>Ti</mi>
        </msub>
        <mo>=</mo>
        <mrow>
          <munderover>
            <mo>&Sum;</mo>
            <mi>j</mi>
            <mi>N</mi>
          </munderover>
          <mo>&it;</mo>
          <mrow>
            <msub>
              <mi>b</mi>
              <mi>ij</mi>
            </msub>
            <mo>&it;</mo>
            <mrow>
              <mi>&delta;</mi>
              <mo>&af;</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mi>t</mi>
                  <mo>-</mo>
                  <msub>
                    <mi>&tau;</mi>
                    <mi>ij</mi>
                  </msub>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>&it;</mo>
            <mrow>
              <mi>exp</mi>
              <mo>&af;</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mo>-</mo>
                  <mfrac>
                    <msup>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>t</mi>
                          <mo>-</mo>
                          <msub>
                            <mi>&tau;</mi>
                            <mi>ij</mi>
                          </msub>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                      <mn>2</mn>
                    </msup>
                    <msubsup>
                      <mi>&sigma;</mi>
                      <mi>ij</mi>
                      <mn>2</mn>
                    </msubsup>
                  </mfrac>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>1</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00001" file="US20030004583A1-20030102-M00001.NB"/>
<image id="EMI-M00001" wi="216.027" he="31.9221" file="US20030004583A1-20030102-M00001.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0143" lvl="7"><number>&lsqb;0143&rsqb;</number> Where &sgr; is a spread with respect to every sub time window, and b<highlight><subscript>ij </subscript></highlight>is a coefficient factor. </paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> Note that the weighting function may take a negative value. For example, if a certain feature detection layer neuron is to detect eventually a triangle and when detecting a feature (F<highlight><subscript>faulse</subscript></highlight>) that is not apparently an element configuring this graphic pattern, a connection from the feature detection (integration) cell and a weighting function making a negative contribution can be given from pulses corresponding to the concerned feature (F<highlight><subscript>faulse</subscript></highlight>) in the summation value calculation process of the input so that the detection of the triangle is not eventually outputted even if there is a large contribution from other feature elements. </paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> A spatiotemporal summation X<highlight><subscript>i</subscript></highlight>(t) of the input signals to the neurons n<highlight><subscript>i </subscript></highlight>of the feature detection layer is given by:  
<math-cwu id="MATH-US-00002">
<number>2</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <msub>
            <mi>X</mi>
            <mi>i</mi>
          </msub>
          <mo>&af;</mo>
          <mrow>
            <mo>(</mo>
            <mi>t</mi>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <munder>
            <mo>&Sum;</mo>
            <mi>j</mi>
          </munder>
          <mo>&it;</mo>
          <mrow>
            <msub>
              <mi>S</mi>
              <mi>ij</mi>
            </msub>
            <mo>&it;</mo>
            <mrow>
              <msub>
                <mi>F</mi>
                <mi>Ti</mi>
              </msub>
              <mo>&af;</mo>
              <mrow>
                <mo>(</mo>
                <mi>t</mi>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>&it;</mo>
            <mrow>
              <msub>
                <mi>Y</mi>
                <mi>j</mi>
              </msub>
              <mo>&af;</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mi>t</mi>
                  <mo>-</mo>
                  <msub>
                    <mi>&tau;</mi>
                    <mi>ij</mi>
                  </msub>
                  <mo>-</mo>
                  <msub>
                    <mi>&varepsilon;</mi>
                    <mi>j</mi>
                  </msub>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>2</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00002" file="US20030004583A1-20030102-M00002.NB"/>
<image id="EMI-M00002" wi="216.027" he="21.12075" file="US20030004583A1-20030102-M00002.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0146" lvl="7"><number>&lsqb;0146&rsqb;</number> Where &egr;<highlight><subscript>j </subscript></highlight>is an initial phase of the output pulse from the neuron n<highlight><subscript>j</subscript></highlight>. If converged at 0 due to synchronization firing with the neuron n<highlight><subscript>i</subscript></highlight>, &egr;<highlight><subscript>j </subscript></highlight>may be set to 0 at all times. When obtaining the load summation on the basis of the pulse input in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>A and the weighting function shown in <cross-reference target="DRAWINGS">FIG. 7B, a</cross-reference> time-varying transition of the load summation value as shown in <cross-reference target="DRAWINGS">FIG. 7E</cross-reference> is obtained. The feature detection layer neuron outputs the pulse when this load summation value reaches a threshold value (Vt). </paragraph>
<paragraph id="P-0147" lvl="0"><number>&lsqb;0147&rsqb;</number> The output pulse signal from the neuron ni is, as explained above, outputted to the neuron of the high-order layer with a time delay (phase) given by learning at such an output level as to become a squashing nonlinear function of the spatiotemporal summation (a so-called input summation) of the input signals (wherein the pulse output takes a fixed frequency (binary) and is outputted in a way that adds a phase modulation quantity serving as the squashing nonlinear function with respect to the spatiotemporal summation of the input signals to a phase corresponding to a fixed delay quantity determined by learning). </paragraph>
<paragraph id="P-0148" lvl="0"><number>&lsqb;0148&rsqb;</number> Process on Feature Detection Layer </paragraph>
<paragraph id="P-0149" lvl="0"><number>&lsqb;0149&rsqb;</number> Processes (for learning and recognition) executed mainly on the feature detection layer will hereinafter be described. Each feature detection layer inputs the pulse signals with respect to a plurality of different features from the same receptive field within the processing channel set at every scale level as explained above, and calculates the spatiotemporal weighting summation (the load summation) and implements a threshold process. The pulse corresponding to each feature amount arrives at a predetermined time interval, depending on a delay quantity (phase) predetermined by learning. </paragraph>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> Learning control of this pulse arrival time patter is not essential to the first embodiment and is not therefore explained in depth. For instance, however, to be brief, the pulse corresponding to the feature element among the plurality of future elements configuring a certain graphic patter, if most contributory to detecting this pattern, arrives earlier, and, between the feature elements showing, if intact, substantially the same pulse arrival time, there is introduced a competitive learning scheme that the pulses arrive away by a fixed quantity in time from each other. Alternatively, there may be taken such a scheme that the pulses arrive at time intervals different between predetermined feature elements (configuring a recognition object and conceived important in particular such as a feature exhibiting a large mean curvature, a feature exhibiting a high rectilinearity and so forth). </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> According to the first embodiment, each of the neurons corresponding to the respective low-order feature elements within the same receptive field on a certain feature integration layer defined as a anterior layer, synchronously fires (pulse output) in a predetermined phase. Generally, there exist the connections to the feature detection neurons, defined as the neurons of the feature integration layer, for detecting, though different in their positions, the same high-order feature (in this case, there are the connections, configuring, though difference in their receptive fields, the same high-order feature). At this time, as a matter of course, the synchronous firing occurs also among these feature detection neurons. Further, in each of the neurons on the feature detection layer, the spatiotemporal weighting summation (the load summation) of the input pulses is calculated only in the time window having a predetermined width with respect to the pulse train arriving at the neuron. A module for actualizing the weighting addition within the time window is not limited to the neuron element circuit shown in <cross-reference target="DRAWINGS">FIGS. 2A</cross-reference> to <highlight><bold>2</bold></highlight>C and may be, as a matter of course, actualized otherwise. </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> This time window corresponds more or less to a time zone excluding the refractory period of the neuron. Namely, there is no output from the neuron even by receiving whatever input during the refractory period (a time range other than the time window), however, the behavior that the neuron fires corresponding to the input level in the time window excluding the time range, is similar to that of the actual biological neuron. The refractory period shown in <cross-reference target="DRAWINGS">FIG. 3B</cross-reference> is a time zone from immediate after the firing of the feature detection cell to a start time of the next time window. A length of the refractory period and a width of the time window can be, of course, arbitrarily set, and the refractory period may not be set shorter than the time window as shown in <cross-reference target="DRAWINGS">FIG. 3B</cross-reference>. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> According to the first embodiment, the already-explained mechanism is that the start timing described above is made common by means of inputting the synchronization detection signals by the phase detection portion receiving the inputs from the same receptive field with respect to, for example, every feature detection layer neuron. </paragraph>
<paragraph id="P-0154" lvl="0"><number>&lsqb;0154&rsqb;</number> If configured in this fashion, the synchronization control (even if necessary) of the time window does not need effecting throughout the network, and, even when the timing signal fluctuates as described above, the reliability of detecting the feature is not degraded because of receiving uniformly an influence of the output from the same local receptive field (the on-the-time-base positional fluctuation of the window function becomes the same among the neurons forming the same receptive field). A tolerance of scatter in circuit element parameter also increases in order for the local circuit control to enable the synchronization behavior with a reliability to be attained. </paragraph>
<paragraph id="P-0155" lvl="0"><number>&lsqb;0155&rsqb;</number> For simplicity, the feature detection neuron for detecting the triangle as a feature will be described. It is assumed that the feature integration layer anterior thereto reacts to a graphical feature (feature elements) such as L-shaped patterns (f<highlight><subscript>11</subscript></highlight>, f<highlight><subscript>12</subscript></highlight>, . . . ) having multiple directions, combinational patterns (f<highlight><subscript>21</subscript></highlight>, f<highlight><subscript>22</subscript></highlight>, . . . ) of line segments each having a continuity (connectivity) to the L-shaped pattern and combinations (f<highlight><subscript>31</subscript></highlight>, . . . ) of a part of two sides configuring the triangle as depicted in <cross-reference target="DRAWINGS">FIG. 7C</cross-reference>. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> Further, f<highlight><subscript>41</subscript></highlight>, f<highlight><subscript>42</subscript></highlight>, f<highlight><subscript>43 </subscript></highlight>shown in <cross-reference target="DRAWINGS">FIG. 7C</cross-reference> represent features shaping the triangles having different directions and corresponding to f<highlight><subscript>11</subscript></highlight>, f<highlight><subscript>12</subscript></highlight>, f<highlight><subscript>13</subscript></highlight>. The intrinsic delay quantity is set between the neurons forming the inter-layer connection by learning, and, as a result of this, in the triangle feature detection neuron, the pulses corresponding the principal and different features shaping the triangle are set beforehand to arrive at respective sub time windows (timeslots) (w<highlight><subscript>1</subscript></highlight>, w<highlight><subscript>2</subscript></highlight>, . . . ) into which the time window is divided. </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> For instance, the pulses corresponding to combinations of the feature sets each shaping the triangle on the whole as shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>A, arrive first at the sub time windows w<highlight><subscript>1</subscript></highlight>, w<highlight><subscript>2</subscript></highlight>, . . . , w<highlight><subscript>n </subscript></highlight>into which the time window is divided by &ldquo;n&rdquo;. Herein, the delay quantities are set by learning so that the L-shaped patterns (f<highlight><subscript>11</subscript></highlight>, f<highlight><subscript>12</subscript></highlight>, f<highlight><subscript>13</subscript></highlight>) arrive at within w<highlight><subscript>1</subscript></highlight>, w<highlight><subscript>2</subscript></highlight>, w<highlight><subscript>3</subscript></highlight>, respectively, and the pulses corresponding to the feature elements(f<highlight><subscript>21</subscript></highlight>, f<highlight><subscript>22</subscript></highlight>, f<highlight><subscript>23</subscript></highlight>) arrive at within w<highlight><subscript>1</subscript></highlight>, w<highlight><subscript>2</subscript></highlight>, w<highlight><subscript>3</subscript></highlight>, respectively. </paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> The pulses corresponding to the feature elements (f<highlight><subscript>31</subscript></highlight>, f<highlight><subscript>32</subscript></highlight>, f<highlight><subscript>33</subscript></highlight>) arrive in the same sequence. In the case shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>A, the pulse corresponding to one feature element arrive at the single sub time window (timeslot). The division into the sub time windows has such a significance that an integration mode when integrating those features, e.g., a processing mode such as setting a condition that all the feature elements be detected or a condition that a given proportion of features be detected and so on, is to be enhanced in its changeability and adaptability by individually surely detecting the pulses (detection of the feature elements) corresponding to the different feature elements developed and expressed on the time-base in the restive sub time windows. </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> For instance, under conditions where the recognition (detection) object is a face and a search (detection) for an eye defined as one of parts configuring the face is important (a case where the priority of detecting the eye&apos;s pattern is set high in the visual search), a reaction selectivity ((a detection sensitivity to a specified feature) corresponding to a feature element patter selectively configuring the eye can be enhanced by introducing a feedback connection from a high-order feature detection layer. This scheme makes it possible to detect the feature in a way that gives a higher importance to a lower-order feature element shaping a high-order feature element (pattern). </paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> Further, assuming that the pulse corresponding to a more importance feature is set previously to arrive at the earlier sub time window, the feature exhibiting the higher importance is easier to detect by setting a weighting function value in the concerned sub time window larger than values in other sub time windows. This importance (the detection priority among the features) is acquired by learning or may also be predefined. </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> Accordingly, if on condition that there occurs an event such as detecting a given proportion of feature elements, the division into the sub time windows comes to have almost no meaning, and the processing may be implemented in one single time window. </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> Note that the pulses corresponding to the plurality (three) of different feature elements arrive respectively and may also be added (<cross-reference target="DRAWINGS">FIG. 7D</cross-reference>). Namely, it may be based on a premise that the pulses corresponding to the plurality of feature elements (<cross-reference target="DRAWINGS">FIG. 7D</cross-reference>) or an arbitrary number of feature elements, be inputted to one single sub time window (timeslot). In this case, referring to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>D, the pulses corresponding to other feature elements f<highlight><subscript>21</subscript></highlight>, f<highlight><subscript>23 </subscript></highlight>supporting the detection of an apex angle portion f<highlight><subscript>11 </subscript></highlight>of the triangle, arrive at the first sub time window. Similarly, the pulses corresponding to other feature elements f<highlight><subscript>22</subscript></highlight>, f<highlight><subscript>31 </subscript></highlight>supporting the detection of an apex angle portion f<highlight><subscript>12 </subscript></highlight>arrive at the second sub time window. </paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> Note that the number of divisions into the sub time windows (timeslots), the width of each sub time window (timeslot), the feature class, and the allocation of the time intervals of the pulses corresponding to the feature elements, are not limited to those described above and can be, as a matter of course, changed. </paragraph>
<paragraph id="P-0164" lvl="0"><number>&lsqb;0164&rsqb;</number> Applied Example of Installing into Photographic Device and Others </paragraph>
<paragraph id="P-0165" lvl="0"><number>&lsqb;0165&rsqb;</number> The pattern recognition (detection) system having the architecture in the first embodiment is installed into a photographic system, wherein focusing on a specified object, a color correction of the specified object and exposure control are carried out. This case will be explained referring to <cross-reference target="DRAWINGS">FIG. 12</cross-reference>. <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a diagram showing an architecture in an example where the pattern detection (recognition) system according to the first embodiment is utilized for the photographic system. </paragraph>
<paragraph id="P-0166" lvl="0"><number>&lsqb;0166&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 12, a</cross-reference> photographic system <highlight><bold>1101</bold></highlight> includes an imaging optical system <highlight><bold>1102</bold></highlight> containing a photographic lens and a drive control mechanism for zoom photography, a CCD or CMOS image sensor <highlight><bold>1103</bold></highlight>, an imaging parameter measuring portion <highlight><bold>1104</bold></highlight>, an image signal processing circuit <highlight><bold>1105</bold></highlight>, a storage portion <highlight><bold>1106</bold></highlight>, a control signal generation portion <highlight><bold>1107</bold></highlight> for generating control signals for control of imaging conditions, a display <highlight><bold>1108</bold></highlight> serving as a viewfinder such as EVF etc, a stroboscope light emitting portion <highlight><bold>1109</bold></highlight> and a storage medium <highlight><bold>1110</bold></highlight>. Further, the photographic system <highlight><bold>1101</bold></highlight> further includes the pattern detection system described above as an object detection (recognition) system <highlight><bold>111</bold></highlight>. </paragraph>
<paragraph id="P-0167" lvl="0"><number>&lsqb;0167&rsqb;</number> The object detection (recognition) system <highlight><bold>111</bold></highlight> in this photographic system <highlight><bold>1101</bold></highlight> detects (an existing position and a size of), for example, a face image of a pre-registered figure from within a picture photographed. Then, when the position of this figure and a piece of size data are inputted to the control signal generation portion <highlight><bold>1107</bold></highlight> from the object detection (recognition) system <highlight><bold>111</bold></highlight>, the control signal generation portion <highlight><bold>1107</bold></highlight> generates, based on an output from the imaging parameter measuring portion <highlight><bold>1104</bold></highlight>, control signals for optimally controlling a focus on this figure, exposure conditions, a white balance and so on. </paragraph>
<paragraph id="P-0168" lvl="0"><number>&lsqb;0168&rsqb;</number> The pattern detection (recognition) system described above is thus utilized for the photographic system, as a result of which the detection of the figure etc and the optimal photographic control (AF, AE etc) based on this detection can be attained by actualizing the function of surely detecting (recognizing) the object with a low consumption of electricity and at a high speed (in real time). </paragraph>
<paragraph id="P-0169" lvl="7"><number>&lsqb;0169&rsqb;</number> (Second Embodiment) </paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> A second embodiment is different from the first embodiment with respect to only the items of the behavioral principles of the pattern detection and the phase synchronization. </paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> This being the case, the discussion in the second embodiment will be focused on the these items, and other functions and behaviors are all the same as those in the first embodiment, of which the repetitive explanations are omitted. </paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> To start with, the phase synchronization circuit in the second embodiment includes, as depicted in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the synchronization detection portion, to which the output signals from the feature integration layer neurons are inputted, for detecting the phase synchronization of the output signals, controlling the switches <highlight><bold>1</bold></highlight>, <highlight><bold>2</bold></highlight> and outputting the synchronization detection signal, and the phase synchronization signal generation circuit interconnected with the feature integration layer neuron. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> A processing flow in this architecture will be explained in sequence. </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> To begin with, when the feature integration layer neuron fires and performs outputting upon receiving an output from the anterior layer, the output signal thereof is inputted via the amplifier to the phase synchronization signal generation circuit in the phase synchronization circuit. </paragraph>
<paragraph id="P-0175" lvl="0"><number>&lsqb;0175&rsqb;</number> The phase synchronization signal generation circuit is, as shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>C, constructed of the neuron element circuit and, upon receiving even one input, outputs the phase synchronization signal to the feature integration layer neuron (at this point of time, the switch <highlight><bold>2</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 2A</cross-reference> is kept in the conductive state). </paragraph>
<paragraph id="P-0176" lvl="0"><number>&lsqb;0176&rsqb;</number> Herein, it is assumed that the threshold value characteristic of the phase synchronization signal generation circuit takes a predetermined value, and the output from the feature integration layer neuron is temporarily transmitted through the amplifier and amplified therein so that the phase synchronization signal generation circuit can fire with one single pulse. </paragraph>
<paragraph id="P-0177" lvl="0"><number>&lsqb;0177&rsqb;</number> Subsequently, the phase synchronization signal outputted by firing of the phase synchronization signal generation circuit is inputted to the feature integration layer neuron, however, a level of the phase synchronization signal received finally by the feature integration layer neuron is herein set so that the output pulse of the phase synchronization signal generation circuit is inputted to the amplifier to amplify the signal level, and an internal potential of the feature integration layer neuron can reach a threshold value within an allowable phase difference. </paragraph>
<paragraph id="P-0178" lvl="0"><number>&lsqb;0178&rsqb;</number> Herein, the allowable phase difference corresponds to a phase synchronization detection window width in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, and, as will be mentioned below, the phase synchronization detection portion detects the phase synchronization with the aid of an integrated value of the output signal from the feature integration layer, which has been inputted inside the phase synchronization detection window. </paragraph>
<paragraph id="P-0179" lvl="0"><number>&lsqb;0179&rsqb;</number> The feature integration layer neuron, upon receiving a phase synchronization pulse signal, except for a certain instance just during a refractory period, exceeds a firing threshold level due to the phase synchronization pulse signal in whatever internal condition. </paragraph>
<paragraph id="P-0180" lvl="0"><number>&lsqb;0180&rsqb;</number> Herein, as shown in <cross-reference target="DRAWINGS">FIG. 15B, a</cross-reference> minute difference between firing phases of the feature integration layer neurons, occurs depending on a difference between the internal conditions of the respective feature integration layer neurons just when the phase synchronization pulse signal is inputted. As explained above, however, since the phase synchronization signal level is set so that the phase difference is under the allowable phase difference, the outputs of the respective feature integration layer neurons to which the phase synchronization signals are inputted for a time excluding the refractory period, with the phase difference falling within the allowable phase difference, come to a synchronizing state. </paragraph>
<paragraph id="P-0181" lvl="0"><number>&lsqb;0181&rsqb;</number> Then, further the feature integration neuron staying in the refractory period in the behavior described above repeats the behavior described above till the same neuron receives the phase synchronization signal at a timing other than the refractory period and fires, whereby the synchronization of the outputs of all the feature integration layer neurons can be eventually taken. </paragraph>
<paragraph id="P-0182" lvl="0"><number>&lsqb;0182&rsqb;</number> The subsequent discussion will be focused on the phase synchronization detection portion for detecting the phase synchronization state explained above. </paragraph>
<paragraph id="P-0183" lvl="0"><number>&lsqb;0183&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the phase synchronization detection portion receives, as an input signal, the output of the feature integration layer neuron. </paragraph>
<paragraph id="P-0184" lvl="0"><number>&lsqb;0184&rsqb;</number> Herein, as shown in <cross-reference target="DRAWINGS">FIGS. 14A and 14C</cross-reference>, the phase synchronization detection portion has the same architecture as that of the feature integration layer neuron that has been touched in the discussion on the neuron elements, and fires and outputs if an integrated value of input values within the phase synchronization detection windows each having a predetermined time determined by the phase synchronization detection window generation circuit, exceeds a threshold value. </paragraph>
<paragraph id="P-0185" lvl="0"><number>&lsqb;0185&rsqb;</number> Accordingly, the time width of this phase synchronization detection window is set to the allowable phase difference in the case where the feature integration layer neuron phase-synchronizes, and further a firing threshold value is set to an integrated value of the outputs of all the feature integration layer neurons to be connected, whereby the phase synchronization of the feature integration layer neuron can be detected. </paragraph>
<paragraph id="P-0186" lvl="0"><number>&lsqb;0186&rsqb;</number> Namely, as depicted in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, the allowable phase difference is set as the phase synchronization detection window, and, when the outputs of all the feature integration layer neurons are synchronized, the neuron element circuit in the phase synchronization detection portion fires as the input integrated value in the phase synchronization detection window reaches the threshold value. As a consequence, the synchronous firing of the feature integration layer neuron can be therefore detected. </paragraph>
<paragraph id="P-0187" lvl="0"><number>&lsqb;0187&rsqb;</number> Next, a behavior after detecting the phase synchronization will be discussed. </paragraph>
<paragraph id="P-0188" lvl="0"><number>&lsqb;0188&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>A, the phase synchronization detection portion includes a switch control signal generation circuit that generates a switch control signal in accordance with the output of the neuron element circuit, and a synchronization detection signal generation circuit generating a synchronization detection signal in accordance with the above output. </paragraph>
<paragraph id="P-0189" lvl="0"><number>&lsqb;0189&rsqb;</number> The phase synchronization detection portion, when detecting the phase synchronization of the feature integration layer neuron due to firing of the neuron element circuit as described above, outputs the switch control signal from the switch control signal generation circuit receiving the output of the neuron element circuit, thereby switching over the switch <highlight><bold>1</bold></highlight> to a cut-off state (the conductive state continues till the phase synchronization is detected), and stops the output of the phase synchronization signal to the feature integration layer neuron from the phase synchronization signal generation circuit. </paragraph>
<paragraph id="P-0190" lvl="0"><number>&lsqb;0190&rsqb;</number> Then, at the same time the switch <highlight><bold>1</bold></highlight> is switched over to the conductive state (the cut-off state continues till the phase synchronization is detected), whereby the output of the feature integration layer neuron is, after undergoing the processes in the synaptic circuits S<highlight><subscript>1 </subscript></highlight>through S<highlight><subscript>4 </subscript></highlight>in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, inputted to the feature detection layer neuron. </paragraph>
<paragraph id="P-0191" lvl="0"><number>&lsqb;0191&rsqb;</number> Herein, the output signal of the feature integration layer neuron that is to be inputted to the feature detection layer neuron becomes, as the input of the phase synchronization signal to the feature integration layer neuron is stopped by the above switching behavior described above, an output signal based on firing that genuinely corresponds to the input from the layer anterior to the feature integration layer neuron. </paragraph>
<paragraph id="P-0192" lvl="0"><number>&lsqb;0192&rsqb;</number> Moreover, the phase synchronization detection portion outputs the synchronization detection signal to the feature detection layer neuron from the synchronization detection signal generation circuit receiving the output of the neuron element circuit, and gives a reference time for a generation timing of the time window that will be explained below. </paragraph>
<paragraph id="P-0193" lvl="0"><number>&lsqb;0193&rsqb;</number> In this case, a time required till the output from the feature integration layer arrives at the feature detection layer, is calculated beforehand, thereby making it possible to properly establish a relationship between the synchronization detection signal and the generation timing of the time window. </paragraph>
<paragraph id="P-0194" lvl="0"><number>&lsqb;0194&rsqb;</number> According to the second embodiment, the synchronization detection signal is set as the pulse-shaped signal, and the point of time when this pulse signal is inputted to the feature detection layer neuron, is set as the beginning of the time window. </paragraph>
<paragraph id="P-0195" lvl="0"><number>&lsqb;0195&rsqb;</number> Note that the integration layer neuron corresponding to the duplex receptive field portion, in the process of executing the phase synchronization process explained above, receives the inputs of a plurality of different phase synchronization signals however, if the integration layer neuron corresponding to the duplex receptive field portion fires even once due to any one of the input from the anterior layer and the input from the phase synchronization circuit, the output pulse thereof is inputted to the plurality of phase synchronization circuits, and hence the phases of the plurality of phase synchronization signals are also synchronized at that point of time. </paragraph>
<paragraph id="P-0196" lvl="0"><number>&lsqb;0196&rsqb;</number> Accordingly, it follows that the plurality of phase synchronization signals are inputted, in a state of their phases being synchronized, to the feature integration layer neurons corresponding to the subsequent duplex receptive field portions, and the process of establishing the phase synchronization of the feature integration layer neuron takes the same course as in the case based on the single phase synchronization signal described above. </paragraph>
<paragraph id="P-0197" lvl="0"><number>&lsqb;0197&rsqb;</number> Thus, even when the feature integration layer neuron corresponding to the duplex receptive field portion receives the inputs of the plurality of phase synchronization signals, the phase synchronization of the outputs can be established with a stability without any contradiction. </paragraph>
<paragraph id="P-0198" lvl="0"><number>&lsqb;0198&rsqb;</number> Further, particularly in the phase synchronization signal generation circuit, if a time interval till the phase synchronization signal is outputted since the signal has been inputted, is set equal to or longer than the refractory period of the feature integration layer neuron, the feature integration layer neuron that did not fire because of the phase synchronization signal being inputted during the refractory period, becomes capable of firing and outputting in a way that phase-synchronizes with other feature integration layer neurons when inputting the next phase synchronization signal, whereby the time up to the phase synchronization can be reduced. </paragraph>
<paragraph id="P-0199" lvl="0"><number>&lsqb;0199&rsqb;</number> An arithmetic behavior of the feature detection layer neuron after the phase synchronization of the output of the feature integration layer neuron has been detected, will be explained in succession. </paragraph>
<paragraph id="P-0200" lvl="0"><number>&lsqb;0200&rsqb;</number> When the synchronization detection signal is inputted to the feature detection layer neuron from the phase synchronization detection portion, as described above, the time window occurs due to the synchronization detection signal. </paragraph>
<paragraph id="P-0201" lvl="0"><number>&lsqb;0201&rsqb;</number> Herein, the time window, which is determined for every feature detection layer neuron (n&prime;<highlight><subscript>i</subscript></highlight>), is common to the respective neurons within the feature integration layer forming the same receptive field with respect to the neuron (n&prime;<highlight><subscript>i</subscript></highlight>), and gives a time range for a time window integration. </paragraph>
<paragraph id="P-0202" lvl="0"><number>&lsqb;0202&rsqb;</number> The synchronization detection portion existing on the layer having a layer number (<highlight><bold>1</bold></highlight>,k) (where k is a natural number) outputs the pulse output as the synchronization detection signal to the neuron of the feature detection layer (having the layer number (<highlight><bold>1</bold></highlight>,k)), whereby the feature detection layer neuron gives a timing signal for generating the time window when the feature detection layer neuron adds the inputs in time aspect. A start time of this time window serves as a reference time for measuring an arrival time of the pulse outputted from each feature integration cell. Namely, the synchronization detection portion gives the timing for outputting the pulse from the feature integration layer neuron, and a reference pulse for a time window integration in the feature detection cell. </paragraph>
<paragraph id="P-0203" lvl="0"><number>&lsqb;0203&rsqb;</number> Each pulse is given a predetermined quantity of phase delay when passing via the synaptic circuit, and arrives at the feature detection cell further via the signal transmission line such as the common bus. A sequence of the pulse train on the time-base at this time is expressed such as pulses (P<highlight><subscript>1</subscript></highlight>, P<highlight><subscript>2</subscript></highlight>, P<highlight><subscript>3</subscript></highlight>) drawn by the dotted lines on the time-base of the feature detection cell. </paragraph>
<paragraph id="P-0204" lvl="0"><number>&lsqb;0204&rsqb;</number> In the feature detection cell, if larger than the threshold value as a result of the time window integration (normally the integration is effected once; there may also be, however, executed the electric charge accumulation involving the time window integration effected multiple times or the averaging process involving the time window integration effected multiple times) of the respective pulses (P<highlight><subscript>1</subscript></highlight>, P<highlight><subscript>2</subscript></highlight>, P<highlight><subscript>3</subscript></highlight>), a pulse output (P<highlight><subscript>d</subscript></highlight>) is outputted based on a termination time of the time window. Note that the in-learning time window shown in the same Figure is what is referred to when executing the learning algorithm that will hereinafter be discussed. </paragraph>
<paragraph id="P-0205" lvl="0"><number>&lsqb;0205&rsqb;</number> Subsequently, when the feature detection layer neuron completes, as described above, the implementation of the arithmetic behavior that will be explained below, the switch <highlight><bold>2</bold></highlight> reverts again to the conductive state, and the output of the phase synchronization signal generation circuit is inputted to the feature integration layer neuron via the amplifier. </paragraph>
<paragraph id="P-0206" lvl="0"><number>&lsqb;0206&rsqb;</number> Further, the switch <highlight><bold>1</bold></highlight> reverts again to the cut-off state, and the input to the feature detection layer neuron from the feature integration layer neuron is stopped. </paragraph>
<paragraph id="P-0207" lvl="0"><number>&lsqb;0207&rsqb;</number> Note that according to the second embodiment the switching behaviors of the switches <highlight><bold>1</bold></highlight>, <highlight><bold>2</bold></highlight> are herein actualized by setting beforehand so that the switch control signal is outputted from the switch control signal generation circuit after an elapse of a predetermined time since the switching behavior of the last time. </paragraph>
<paragraph id="P-0208" lvl="0"><number>&lsqb;0208&rsqb;</number> Moreover, the behaviors of the switches <highlight><bold>1</bold></highlight>, <highlight><bold>2</bold></highlight> herein can be also performed by use of other control portions, however, this is not related to the essential point of the present invention, and therefore its explanation is omitted. </paragraph>
<paragraph id="P-0209" lvl="0"><number>&lsqb;0209&rsqb;</number> As discussed above, the signal level of the phase synchronization signal outputted from the phase synchronization circuit is set so that the feature integration layer neuron fires within the allowable phase difference, whereby the phase synchronization of the feature integration layer neuron can be established in a shorter time. </paragraph>
<paragraph id="P-0210" lvl="7"><number>&lsqb;0210&rsqb;</number> (Third Embodiment) </paragraph>
<paragraph id="P-0211" lvl="0"><number>&lsqb;0211&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows an example of topology of how other neurons (the neuron groups of the feature and detection layers) are connected to the phase synchronization circuit as well as showing the phase synchronization circuit itself (wherein the input to the feature integration layer neuron from the anterior layer is indicated by a fine line, the input to the feature detection layer neuron from the feature integration layer neuron is drawn by a dotted line, the interconnection between the feature integration layer and the phase synchronization circuit is indicated by a bold line, the switch control signal is indicated by a fine line, and the synaptic circuit and the synchronization detection signal are omitted). </paragraph>
<paragraph id="P-0212" lvl="0"><number>&lsqb;0212&rsqb;</number> An architecture different from the second embodiment is that one phase synchronization circuit exists for every group formed by clustering the feature detection layer neurons detecting the same feature category by a predetermined number, and generates an independent phase synchronization signal. </paragraph>
<paragraph id="P-0213" lvl="0"><number>&lsqb;0213&rsqb;</number> With this architecture adopted, the duplex receptive field structure with respect to the feature integration layer between the adjacent feature detection layer neurons can be eliminated (the feature integration layer neuron receives only the phase synchronization signal from the one single phase synchronization circuit), and it is feasible to decrease the number of the phase synchronization circuits and the number of the phase synchronization detection portions. </paragraph>
<paragraph id="P-0214" lvl="0"><number>&lsqb;0214&rsqb;</number> According to the third embodiment, the synchronization detection signal of the phase synchronization circuit is, when the synchronization detection portion detects the synchronization firing of the feature integration layer neuron, generated independently of other phase synchronization circuits. </paragraph>
<paragraph id="P-0215" lvl="0"><number>&lsqb;0215&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows the processing flow described above. <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows pulse output timings of the respective corresponding neurons. </paragraph>
<paragraph id="P-0216" lvl="0"><number>&lsqb;0216&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, when the feature integration layer neurons (N<highlight><subscript>11 </subscript></highlight>through N<highlight><subscript>61</subscript></highlight>) fire and output upon outputs of the feature detection neurons of the anterior layer, the phase synchronization signal is outputted from the phase synchronization signal generation circuit. The feature integration layer neuron to which the phase synchronization signal has been inputted undergoes the phase synchronization process described above, and the phase synchronization detection portion detects the phase synchronization of the output within the phase synchronization detection window. </paragraph>
<paragraph id="P-0217" lvl="0"><number>&lsqb;0217&rsqb;</number> When the phase synchronization of the output of the feature integration layer neuron is detected by the phase synchronization portion, the phase synchronization signals are outputted to the feature detection layer neurons (N&prime;<highlight><subscript>2D </subscript></highlight>through N&prime;<highlight><subscript>3D</subscript></highlight>). </paragraph>
<paragraph id="P-0218" lvl="0"><number>&lsqb;0218&rsqb;</number> In consequence, the feature detection layer neuron, the time-widow-based arithmetic process being executed, outputs corresponding to a result of this arithmetic process. </paragraph>
<paragraph id="P-0219" lvl="0"><number>&lsqb;0219&rsqb;</number> Herein, the output of the phase synchronization signal generation circuit is given independently of other phase synchronization circuits when the time integrated value of the input pulses within the phase synchronization detection time window (shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>). </paragraph>
<paragraph id="P-0220" lvl="0"><number>&lsqb;0220&rsqb;</number> As explained above, the architecture is that the single phase synchronization circuit exists for every group formed by clustering the feature detection layer neurons detecting the same feature category by the predetermined number, and generates the independent phase synchronization signal, whereby the circuit scale and the consumption of the electric power can be reduced. </paragraph>
<paragraph id="P-0221" lvl="7"><number>&lsqb;0221&rsqb;</number> (Fourth Embodiment) </paragraph>
<paragraph id="P-0222" lvl="0"><number>&lsqb;0222&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 10A and 10B</cross-reference> each show an example of connecting to the phase synchronization circuit as well as showing the phase synchronization circuit itself (wherein the input to the feature detection layer neuron from the feature integration layer neuron is indicated by a dotted line, the phase synchronization signal is drawn by a fine line, the interconnection between the feature integration layer and the phase synchronization circuit is depicted by a bold line, an interconnection between the feature integration layer and a WTA (Winner-Take-All) circuit is shown by a fine line, an interconnection between the phase synchronization circuit and the WTA circuit is indicated by a bold line, the switch control signal is indicated by a fine line, and the input to the feature integration layer neuron from the anterior layer, the synaptic circuit and the synchronization detection signal are omitted). </paragraph>
<paragraph id="P-0223" lvl="0"><number>&lsqb;0223&rsqb;</number> The phase synchronization circuit receives the pulse signals inputted only from the feature integration layer neurons to the neuron (N<highlight><subscript>31</subscript></highlight>) existing in a centroidal position or a position most vicinal thereto as a representative position of the feature detection layer neuron group formed by clustering the neurons in the same way as in third embodiment, and generates the phase synchronization signal under a predetermined condition. </paragraph>
<paragraph id="P-0224" lvl="0"><number>&lsqb;0224&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 10A, a</cross-reference> neuron existing in a centroidal position of the feature detection layer neuron group connected to the phase synchronization circuit, is N&prime;<highlight><subscript>2D</subscript></highlight>. Feature integration layer neurons N<highlight><subscript>11</subscript></highlight>, N<highlight><subscript>21</subscript></highlight>, N<highlight><subscript>31</subscript></highlight>, N<highlight><subscript>41 </subscript></highlight>to which the neuron N&prime;<highlight><subscript>2D </subscript></highlight>is connected are interconnected to the phase synchronization circuit (the connections are indicated by the bold lines). This topology serves to reduce the wiring needed for the interconnections as compared with the third embodiment. Further, an operational problem (such as a deviation in the time window occurrence timing between the phase synchronization circuit and feature detection layer due to asynchronous inputs of the plurality of phase synchronization signals) does not arise because of eliminating the duplex receptive field structure and using the phase synchronization circuit generating the independent phase synchronization signal even when reducing the wiring as described above. </paragraph>
<paragraph id="P-0225" lvl="0"><number>&lsqb;0225&rsqb;</number> Similarly in a topology illustrated in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>B, the neuron interconnected with the phase synchronization circuit is only one neuron (N<highlight><subscript>31</subscript></highlight>), existing in the vicinity of the centroidal position, among the feature integration layer neuron group from which the neuron N&prime;<highlight><subscript>2D </subscript></highlight>receives the inputs. This topology further reduces the wiring for the interconnections. Moreover, the phase synchronization-circuit can be also structured to receive the inputs only from the neurons performing the maximum outputs among the feature integration layer neurons that should receive the inputs in <cross-reference target="DRAWINGS">FIG. 10B</cross-reference>. For instance, according to a topology shown in <cross-reference target="DRAWINGS">FIG. 11, a</cross-reference> so-called Winner-Take-All (which will hereinafter be abbreviated to a WTA circuit) for detecting the maximum output is provided between the feature integration layer neuron group and the phase synchronization circuit, and the phase synchronization circuit receives an output from this WTA circuit. The feature integration layer neuron group is connected to the feature detection layer neuron group in the same way as in <cross-reference target="DRAWINGS">FIGS. 10A and 10B</cross-reference>. Thus, the stable operation of the parallel pulse signal processing at the much smaller circuit scale can be actualized by executing the local timing control based on the outputs from the feature integration layer neurons detecting the most conspicuous feature in the local area within the predetermined range on the input (image) data. </paragraph>
<paragraph id="P-0226" lvl="0"><number>&lsqb;0226&rsqb;</number> As discussed above, the fourth embodiment exhibits such an effect that the synchronizing operation can be actualized stably without any contradiction in a way that brings about neither an increase in the circuit scale nor an increase in the consumption of electric power in the signal processing circuit. </paragraph>
<paragraph id="P-0227" lvl="0"><number>&lsqb;0227&rsqb;</number> Although the present invention has been described in its preferred form with a certain degree of particularity, many apparently widely different embodiments of the invention can be made without departing from the spirit and the scope thereof. It is to be understood that the invention is not limited to the specific embodiments thereof except as defined in the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A signal processing circuit comprising: 
<claim-text>a plurality of arithmetic elements connected to each other based on a predetermined rule and disposed in parallel, executing a predetermined arithmetic process with respect to input signals and outputting; </claim-text>
<claim-text>a phase synchronization signal generation circuit outputting phase synchronization signals to said predetermined vicinal arithmetic elements; and </claim-text>
<claim-text>synchronization detection means detecting synchronization within an allowable phase difference between the outputs of said predetermined vicinal arithmetic elements, </claim-text>
<claim-text>wherein said phase synchronization signal generation circuit functions also as an arithmetic element executing the predetermined arithmetic process and outputting in accordance with a result of the synchronization detection by said synchronization detection means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said phase synchronization signal generation circuit outputs the phase synchronization signals in accordance with time-series signals inputted from said predetermined vicinal arithmetic elements. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the output of said phase synchronization signal generation circuit is a pulse signal. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein said predetermined vicinal arithmetic element has a refractory period, and, in said phase synchronization signal generation circuit, a time interval till the phase synchronization signal is outputted since the signal has been inputted is equal to or larger than the refractory period of said predetermined vicinal arithmetic element. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the output of each of the phase synchronization signals outputted to said predetermined vicinal arithmetic elements from said phase synchronization signal generation circuit, is so controlled as to fall within the allowable phase difference between the output signals from said predetermined vicinal arithmetic elements. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein said predetermined vicinal arithmetic element has a refractory period, and a phase difference between the output signals of said predetermined vicinal arithmetic elements falls within the allowable phase difference when the phase synchronization signal is inputted other than the refractory period of said arithmetic element. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said synchronization detection means has an arithmetic element outputting in accordance with an integrated value of the input signals. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A signal processing circuit comprising: 
<claim-text>a plurality of arithmetic elements connected to each other based on a predetermined rule and disposed in parallel, executing a predetermined arithmetic process with respect to input signals and outputting; </claim-text>
<claim-text>a phase synchronization signal generation circuit outputting phase synchronization signals to said predetermined vicinal arithmetic elements; and </claim-text>
<claim-text>synchronization detection means detecting synchronization within an allowable phase difference between the outputs of said predetermined vicinal arithmetic elements, </claim-text>
<claim-text>wherein the output of each of the phase synchronization signals outputted to said predetermined vicinal arithmetic elements from said phase synchronization signal generation circuit, is so controlled as to fall within the allowable phase difference between the output signals from said predetermined vicinal arithmetic elements. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein said predetermined vicinal arithmetic element has a refractory period, and a phase difference between the output signals of said predetermined vicinal arithmetic elements falls within the allowable phase difference when the phase synchronization signal is inputted other than the refractory period of said arithmetic element. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein said phase synchronization signal generation circuit outputs the phase synchronization signals in accordance with time-series signals inputted from said predetermined vicinal arithmetic elements. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein said synchronization detection means is an arithmetic element outputting in accordance with an integrated value of the input signals. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein the output of said phase synchronization signal generation circuit is a pulse signal. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A signal processing circuit according to <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein said predetermined vicinal arithmetic element has a refractory period, and, in said phase synchronization signal generation circuit, a time interval till the phase synchronization signal is outputted since the signal has been inputted is equal to or larger than the refractory period of said predetermined vicinal arithmetic element.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004583A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004583A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004583A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004583A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004583A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004583A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004583A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004583A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004583A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004583A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030004583A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030004583A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030004583A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030004583A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030004583A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030004583A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030004583A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
