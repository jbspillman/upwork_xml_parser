<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002062A1-20030102-D00000.TIF SYSTEM "US20030002062A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002062A1-20030102-D00001.TIF SYSTEM "US20030002062A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002062A1-20030102-D00002.TIF SYSTEM "US20030002062A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002062A1-20030102-D00003.TIF SYSTEM "US20030002062A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002062A1-20030102-D00004.TIF SYSTEM "US20030002062A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002062A1-20030102-D00005.TIF SYSTEM "US20030002062A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002062A1-20030102-D00006.TIF SYSTEM "US20030002062A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002062A1-20030102-D00007.TIF SYSTEM "US20030002062A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002062A1-20030102-D00008.TIF SYSTEM "US20030002062A1-20030102-D00008.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002062</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10153769</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020524</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2001-200732</doc-number>
</priority-application-number>
<filing-date>20010702</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>B41J001/00</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G06F015/00</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>358</class>
<subclass>001900</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Image processing apparatus, method and program, and storage medium</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Hiroaki</given-name>
<family-name>Ikeda</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<assignee>
<organization-name>Canon Kabushiki Kaisha</organization-name>
<address>
<city>Tokyo</city>
<country>
<country-code>JP</country-code>
</country>
</address>
<assignee-type>03</assignee-type>
</assignee>
<correspondence-address>
<name-1>FITZPATRICK CELLA HARPER &amp; SCINTO</name-1>
<name-2></name-2>
<address>
<address-1>30 ROCKEFELLER PLAZA</address-1>
<city>NEW YORK</city>
<state>NY</state>
<postalcode>10112</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">In an image obtained by reading a document or the like, when a round portion is present at a corner of a frame for describing a character, extraction of a region where a character image is described is performed by removing pixels constituting a part of rules or lines constituting the frame. Such pixels are removed from an extracted image region by identifying whether or not a desired pixel group contacting at least one of row-direction rules and column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to an image processing apparatus, method and program for segmenting a character image described in a frame or a table in a document image, and a storage medium storing such a program. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> When reading characters described in a document, such as an application form or the like, in many cases, a document formed with a dropout color is used, and characters described with a color different from the dropout color are read and recognized. Since dropout-color documents are printed and distributed using a color adapted to conditions of a light source of a reading apparatus, the documents are expensive and inconvenient. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Although non-dropout-color documents are less expensive and convenient, it is impossible to discriminate between characters and closing lines. Accordingly, the following approaches have been considered as methods for recognizing a non-dropout-color document. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> In a conventional method, the positions and the sizes of frames for describing characters within a document are stored in advance as a document definition, and described characters are extracted by reading differences between an input document to be read and the document definition by superposing them after correcting position deviation between the input document and the document definition. In this method, however, since it is necessary to store the document definition in advance, an input document other than the document definition cannot be dealt with. Accordingly, techniques have been considered in which, even if a document definition is not stored in advance, a frame for describing a character and a character within the frame are recognized. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> For example, according to Japanese Patent Application Laid-Open (Kokai) No. 07-282191 (1995), a black run continuous for at least a predetermined length in the vertical and horizontal directions is extracted as a set of rules (i.e., lines). In some cases, a vertical rule and a horizontal rule are disconnected. In such a case, the vertical rule and the horizontal rule are virtually extended, and if the length of an extended portion is equal to or less than a threshold, the vertical line and the horizontal line are assumed to be connected, and the black run is recognized as a rectangular frame. However, since the frame is handled to be a straight rectangle, if a document having a round portion at a corner of a frame is recognized, the round corner portion is segmented as a character when extracting a character within the frame and is used in character recognition processing, and erroneous character recognition will sometimes occur. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> In Japanese Patent Application Laid-Open (Kokai) No. 07-14000 (1995), a plurality of patterns of corners of a frame are stored in advance. Black pixels continuous in vertical and horizontal directions are checked, and black pixels continuous in the vertical and horizontal directions, having a length equal to or more than a predetermined value are determined to provide rules. A corner-portion pattern that is stored in advance is matched with a intersection point of a pair of a vertical rule and a horizontal rule whose end points are close to each other. If similarity is large, the corner portion is determined to correspond to that pattern. In this approach, it is necessary to store a large number of corner-portion patterns in advance, and therefore to provide a large memory capacity. In addition, a corner portion is not recognized if it has a pattern other than stored patterns. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> In Japanese Patent Application Laid-Open (Kokai) No. 2000-235619 (2,000), a round corner portion is determined by identifying a pixel-density distribution in an oblique direction between end points of extracted rules, or by performing a matching operation by generating a pattern connecting end points of rules using an n-degree function. In the former approach, however, when a change in the pixel-density distribution is small, for example, when a thin portion is present in a corner portion, the corner portion is sometimes not recognized. In the latter approach, although a large number of round-corner portions need not be stored in advance, it is necessary to perform processing of generating a pattern using an n-degree function and matching processing, resulting in an increase in the processing time. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> As described above, in the above-described conventional approaches, there are problems such that, for example, a large memory capacity is necessary, processing requiring a long time for matching or the like must be performed, accuracy in recognition is inferior, and a round portion of rules is segmented as a character and is erroneously recognized. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> It is an object of the present invention to solve the above-described problems. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> It is another object of the present invention to correctly extract a character within a frame for describing a character, even if a corner of the frame is round. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> According to one aspect of the present invention, an image processing apparatus includes row-direction-rule extraction means for extracting rules in a row direction from a document image, column-direction-rule extraction means for extracting rules in a column direction from the document image, image-region extraction means for extracting an image region based on a region surrounded by the row-direction rules extracted by the row-direction-rule extraction means and the column-direction rules extracted by the column-direction-rule extraction means, and removal means for removing pixels constituting a part of rules from the image region extracted by the image-region extraction means, by identifying whether or not a desired pixel group contacting at least one of the row-direction rules and the column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> According to another aspect of the present invention, an image processing apparatus includes an image scanner and a processor. The processor is configured to (i) extract rules in a row direction from a document image scanned by said image scanner, (ii) extract rules in a column direction from the document image, (iii) extract an image region based on a region surrounded by the extracted row-direction rules and the extracted column-direction rules, and (iv) remove pixels from the extracted image region that constitute part of rules, by identifying whether a desired pixel group contacting at least one of the row-direction rules and column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> According to still another aspect of the present invention, an image processing method includes a row-direction-rule extraction step of extracting rules in a row direction from a document image, a column-direction-rule extraction step of extracting rules in a column direction from the document image, an image-region extraction step of extracting an image region based on a region surrounded by the row-direction rules extracted in the row-direction-rule extraction step and the column-direction rules extracted in the column-direction-rule extraction step, and a removal step of removing pixels constituting a part of rules from the image region extracted in the image-region extraction step, by identifying whether or not a desired pixel group contacting at least one of the row-direction rules and the column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> According to yet another aspect of the present invention, an image processing program, capable of being executed by a computer, includes program codes for causing a computer to realize steps, the steps including a row-direction-rule extraction step of extracting rules in a row direction from a document image, a column-direction-rule extraction step of extracting rules in a column direction from the document image, an image-region extraction step of extracting an image region based on a region surrounded by the row-direction rules extracted in the row-direction-rule extraction step and the column-direction rules extracted in the column-direction-rule extraction step, and a removal step of removing pixels constituting a part of rules from the image region extracted in the image-region extraction step, by identifying whether or not a desired pixel group contacting at least one of the row-direction rules and the column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> According to yet a further aspect of the present invention, a storage medium stores an image processing program, capable of being executed by a computer, including program codes for causing a computer to realize steps, the steps including a row-direction-rule extraction step of extracting rules in a row direction from a document image, a column-direction-rule extraction step of extracting rules in a column direction from the document image, an image-region extraction step of extracting an image region based on a region surrounded by the row-direction rules extracted in the row-direction-rule extraction step and the column-direction rules extracted in the column-direction-rule extraction step, and a removal step of removing pixels constituting a part of the rules from the image region extracted in the image-region extraction step, by identifying whether or not a desired pixel group contacting at least one of the row-direction rules and the column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> Other features and advantages of the patent invention will be apparent from the following description taken in conjunction with the accompanying drawings, in which like reference characters designate the same or similar parts throughout the figures thereof. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> The accompanying drawings, which are incorporated in and constitute a part of the specification, illustrate embodiments of the invention and, together with the description, serve to explain the principles of the invention. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram illustrating an image processing apparatus according to a first embodiment of the present invention; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flowchart illustrating a procedure for segmenting a character according to the first embodiment; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a flowchart illustrating a procedure for removing a corner rule portion, according to the first embodiment; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a diagram illustrating a frame for describing characters, according to the first embodiment; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a diagram illustrating processing for extracting intra-rule rectangular regions, according to the first embodiment; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 6A and 6B</cross-reference> are diagrams illustrating an example in which a part of rules is included in the region of a circumscribed rectangle of black pixels, according to the first embodiment; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 7A and 7B</cross-reference> are diagrams illustrating a result of labeling an intra-rule region, according to the first embodiment; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flowchart illustrating a procedure for removing a corner rule portion, according to a second embodiment of the present invention; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a diagram illustrating a frame for describing a character and a described character in the second embodiment; and </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a diagram illustrating a memory map of a storage medium storing various processing programs which can be read by a document reading apparatus according to the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0030" lvl="7"><number>&lsqb;0030&rsqb;</number> First Embodiment </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram illustrating the configuration of an image processing apparatus for reading characters from a document image, according to a first embodiment of the present invention. In <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> CPU (central processing unit) <highlight><bold>101</bold></highlight> controls the entirety of the apparatus in accordance with a control program stored in a ROM (read-only memory) <highlight><bold>102</bold></highlight>. The ROM <highlight><bold>102</bold></highlight> stores control programs and the like, which control processes shown in flowcharts to be described later, to be executed by the CPU <highlight><bold>101</bold></highlight>. A RAM (random access memory) <highlight><bold>103</bold></highlight> stores document images and the like, and operates as a working area for the CPU <highlight><bold>101</bold></highlight>. An external storage device <highlight><bold>104</bold></highlight> comprises a magnetic disk or the like. There are also shown a display <highlight><bold>105</bold></highlight>, a keyboard <highlight><bold>106</bold></highlight>, a pointing device <highlight><bold>107</bold></highlight>, such as a mouse or the like, and an image scanner <highlight><bold>108</bold></highlight> for reading an image. A network interface <highlight><bold>109</bold></highlight> communicates with an apparatus present at a remote location (not shown), and reads and writes programs, data and the like. In order to realize the first embodiment, the CPU <highlight><bold>101</bold></highlight> may execute a control program by reading it from the ROM <highlight><bold>102</bold></highlight>, from the external storage device <highlight><bold>104</bold></highlight>, or an external apparatus connected via a network. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> Operation of the first embodiment, as executed by the image processing apparatus shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, will now be described in detail with reference to FIGS. <highlight><bold>1</bold></highlight>-<highlight><bold>7</bold></highlight>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The first embodiment deals with a document in which a frame for describing a character is set for each character as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. In order to simplify description, the first embodiment deals with a document image obtained by binary coding a read image. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flowchart illustrating a procedure for segmenting a described character from a frame region within a document image. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> In step S<highlight><bold>201</bold></highlight>, the positions of rules in the horizontal direction (hereinafter abbreviated as &ldquo;horizontal rules&rdquo;) are detected from an image read from a photoelectric transducer, such as the image scanner <highlight><bold>108</bold></highlight>, and subjected to binary coding (hereinafter termed a &ldquo;binary image&rdquo;), or from a binary image that has been read and stored in the external storage device <highlight><bold>104</bold></highlight> or the like. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> As for the position of a horizontal rule, in order to represent the coordinate values of the space of the horizontal rule in the vertical direction, and the thickness of the rule, the horizontal rule is represented by the coordinate values of the upper and lower ends of the horizontal rule in the vertical direction. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> For example, when detecting the positions of a horizontal rule from a region for describing characters as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, in a simple detection procedure, a horizontal-direction histogram of black pixels with respect to a vertical projection plane is obtained, and the positions of rise and fall of the peak of a portion where the frequency of peaks equals at least a predetermined threshold are made the positions of the horizontal rule. In order to improve accuracy in detection, a region of processing may be determined while removing inclination, complementing a thin portion, and extracting a circumscribed rectangle of a frame for describing a character in advance. In this case, for example, the threshold may be set to &frac12; of the width of the line of the circumscribed rectangle. For detection of the positions of a horizontal rule, for example, a technique described in Japanese Patent Application Laid-Open (Kokai) No. 2000-380612 (2,000) filed by the assignee of the present application may be used. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> In step S<highlight><bold>202</bold></highlight>, it is determined whether or not at least two horizontal rules have been extracted. If the result of the determination in step S<highlight><bold>202</bold></highlight> is negative, the process is terminated assuming that a frame for describing a character is absent. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> If the result of the determination in step S<highlight><bold>202</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>203</bold></highlight>, where the positions of vertical rules present between two horizontal rules, i.e., between the coordinate of the lower portion of the upper horizontal rule and the coordinate of the upper portion of the lower horizontal rule, are detected. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> For detecting the positions of a vertical rule, a vertical-direction histogram of black pixels with respect to a horizontal projection plane is obtained, and a portion where the frequency of peaks equals at least a threshold are identified as the position of the vertical rule. For example, the threshold may be set to at least 80% of the distance between the horizontal rules. For detection of the position of a vertical rule, for example, a technique described in Japanese Patent Application Laid-Open (Kokai) No. 2000-380612 (2,000) may also be used. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In step S<highlight><bold>204</bold></highlight>, it is determined whether or not at least two vertical rules have been extracted. If the result of the determination in step S<highlight><bold>204</bold></highlight> is negative, the process is terminated assuming that a frame for describing a character is absent. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> If the result of the determination in step S<highlight><bold>204</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>205</bold></highlight>, where the inner portion of a rectangular region surrounded by the extracted horizontal rules and vertical rules is extracted as an intra-rule rectangular region. <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates a result of extracting intra-rule rectangular regions from the document shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, using the above-described processing. At that time, since &ldquo;1&rdquo; is recognized as a vertical rule, two divided intra-rule rectangular regions <highlight><bold>504</bold></highlight> and <highlight><bold>505</bold></highlight> are present. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> In step S<highlight><bold>206</bold></highlight>, a standard pitch of a frame for describing a character is obtained from the extracted intra-rule rectangular region. The standard pitch is determined, for example, from the distribution of the pitches of respective intra-rule rectangular regions. That is, based on the assumption that the pitch of each frame for describing a character within a range of processing is uniform, the distribution of the pitch of each intra-rule rectangular region is counted, and a pitch whose number is largest is adopted as the standard pitch. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> When regions having a pitch smaller than the standard pitch are determined to constitute an erroneously divided region, then, in step S<highlight><bold>207</bold></highlight>, these regions are connected in order to have the standard pitch. As a result, the regions <highlight><bold>504</bold></highlight> and <highlight><bold>505</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> are connected, and a region which coincides with the intra-rule rectangular region is obtained. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> In step S<highlight><bold>208</bold></highlight>, black pixels within an intra-rule rectangular region are detected, and an image is extracted using a circumscribed rectangle surrounding the black pixels within the intra-rule rectangular region. An image is to be extracted using one circumscribed rectangle for one intra-rule rectangular region. In order to remove influence of isolated-point noise, noise contacting a rule, and the like, well-known noise removal may be performed. In another approach, when an extracted image is smaller than a predetermined size, the image may be assumed to be not present by determining that the image is noise. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> In step S<highlight><bold>209</bold></highlight>, it is determined whether or not an image is present within the intra-rule rectangular region. If the result of the determination in step S<highlight><bold>209</bold></highlight> is negative, the process proceeds to step S<highlight><bold>213</bold></highlight>, where the corresponding frame for describing a character is made a void. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> If the result of the determination in step S<highlight><bold>209</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>210</bold></highlight>, where it is determined whether or not a part of a rule is included within the extracted image. If the result of negative, the image is set as a character image in step S<highlight><bold>214</bold></highlight>. If the result of the determination in step S<highlight><bold>210</bold></highlight> is affirmative, that portion is removed in step S<highlight><bold>211</bold></highlight>. After the removal, in step S<highlight><bold>212</bold></highlight> it is determined whether an image remains and flow moves to step S<highlight><bold>213</bold></highlight> or step S<highlight><bold>214</bold></highlight> in accordance with the result of the determination. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 6A and 6B</cross-reference> illustrate a case in which a part of one or more rules is contained within a region. The case of an intra-rule rectangular region <highlight><bold>508</bold></highlight> obtained in step S<highlight><bold>207</bold></highlight> will now be described. First, a rectangular image within the intra-rule rectangular region <highlight><bold>508</bold></highlight> is segmented. A circumscribed rectangle of black pixels within the segmented rectangular region is represented by a broken-line portion <highlight><bold>601</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 6A</cross-reference>. As a result, as shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>B, portions <highlight><bold>602</bold></highlight> and <highlight><bold>603</bold></highlight> of rules remain in the image within the circumscribed rectangle <highlight><bold>601</bold></highlight>. If character recognition is performed for the image shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>B, erroneous recognition will be performed. That is, when round corners are present, if it is intended to extract an image within the frame based on the intra-rule rectangular region, the round portions (each of which is a part of a rule) are included. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> Removal when a part of a round rule is included within an extracted image (step S<highlight><bold>211</bold></highlight>) will now be described in detail illustrating a case in which an upper right corner is round, with reference to the flowchart shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. A description will be provided assuming that the coordinates of the intra-rule rectangular region <highlight><bold>508</bold></highlight> obtained in step S<highlight><bold>207</bold></highlight>, and the coordinates of the circumscribed rectangle <highlight><bold>601</bold></highlight> of the black pixels obtained based on the intra-rule rectangular region <highlight><bold>508</bold></highlight> in step S<highlight><bold>208</bold></highlight> are stored. It is assumed that the uppermost position at the left of the document image is made an origin of the coordinates, the x-coordinate value increases from the left to the right, and the y-coordinate value increases from top to bottom. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> In step S<highlight><bold>301</bold></highlight>, for the intra-rule rectangular region <highlight><bold>508</bold></highlight>, the y coordinate of the upper end is represented by T, the x coordinate of the right end is represented by R, the height of the region is represented by H, and the width of the region is represented by W. In step S<highlight><bold>302</bold></highlight>, the y coordinate of the upper end, and the x coordinate of the right end of the circumscribed rectangle <highlight><bold>601</bold></highlight> of the extracted black pixels are represented by t and r, respectively. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> In step S<highlight><bold>303</bold></highlight>, it is determined whether or not the x coordinate R of the right end of the intra-rule rectangular region <highlight><bold>508</bold></highlight> equals the x coordinate r of the right end of the circumscribed rectangle <highlight><bold>601</bold></highlight> of the black pixels. If the result of the determination in step S<highlight><bold>303</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>304</bold></highlight>, where it is determined whether or not the upper end of the circumscribed rectangle <highlight><bold>601</bold></highlight> of the black pixels is at a position higher than a position &frac16; of the height below the upper end of the intra-rule rectangular region <highlight><bold>508</bold></highlight>. If the result of the determination in step S<highlight><bold>304</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>307</bold></highlight>. If the result of the determination in step S<highlight><bold>304</bold></highlight> is negative, the process is terminated. The above-described value of &frac16;, and respective thresholds to be described below, are only examples for explaining the present invention. The present invention is not limited to these values. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> If the result of the determination in step S<highlight><bold>303</bold></highlight> is negative, the process proceeds to step S<highlight><bold>305</bold></highlight>, where it is determined whether or not the y coordinate T of the upper end of the intra-rule rectangular region <highlight><bold>508</bold></highlight> equals the y coordinate t of the upper end of the circumscribed rectangle <highlight><bold>601</bold></highlight> of the black pixels. If the result of the determination in step S<highlight><bold>305</bold></highlight> is negative, the process is terminated. If the result of the determination in step S<highlight><bold>305</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>306</bold></highlight>, where it is determined whether or not the right end of the circumscribed rectangle <highlight><bold>601</bold></highlight> of the black pixels is to the right of a position that is &frac16; of the width to the left of the right end of the intra-rule rectangular region <highlight><bold>508</bold></highlight>. If the result of the determination in step S<highlight><bold>306</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>307</bold></highlight>. If the result of the determination in step S<highlight><bold>306</bold></highlight> is negative, the process is terminated. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> In step S<highlight><bold>307</bold></highlight>, black pixels contacting the upper end of the intra-rule rectangular region <highlight><bold>508</bold></highlight> within a right-half portion thereof are subjected to labeling, and black pixels at the lowermost end of black pixels having the same label within an upper-half portion of the intra-rule rectangular region <highlight><bold>508</bold></highlight> (those at positions above &frac12; of the height) are extracted. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> In step S<highlight><bold>308</bold></highlight>, black pixels contacting the right end of the intra-rule rectangular region <highlight><bold>508</bold></highlight> within an upper-half portion thereof are subjected to labeling, and black pixels at the left end of black pixels having the same label within a right-half portion of the intra-rule rectangular region <highlight><bold>508</bold></highlight> (those to the right of &frac12; of the width) are extracted. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> In step S<highlight><bold>309</bold></highlight>, a circumscribed rectangle of all labeled pixels is obtained. In the case shown in <cross-reference target="DRAWINGS">FIGS. 7A and 7B</cross-reference>, <cross-reference target="DRAWINGS">FIG. 7A</cross-reference> illustrates an original image, and <cross-reference target="DRAWINGS">FIG. 7B</cross-reference> illustrates an image after labeling. According to labeling processing, two blocks having label <highlight><bold>1</bold></highlight> and label <highlight><bold>2</bold></highlight> are extracted. The obtained circumscribed rectangle is a rectangle including the two blocks. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> In step S<highlight><bold>310</bold></highlight>, a straight line passing through the upper left corner and the lower right corner of the obtained circumscribed rectangle is obtained. In step S<highlight><bold>311</bold></highlight>, the numbers of labeled pixels to the right and to the left of the straight line are counted. If the pixels constitute a rule, most of the pixels are to be at the right of the straight line. Hence, it is possible to determine whether the pixels constitute a rule by comparing the numbers of labeled pixels to the right and to the left of the straight line. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> In step S<highlight><bold>312</bold></highlight>, it is determined whether or not the number of pixels at the right is smaller than four times the number of pixels at the left. If the result of the determination in step S<highlight><bold>312</bold></highlight> is affirmative, the process ends. If the result of the determination in step S<highlight><bold>312</bold></highlight> is negative, the process proceeds to step S<highlight><bold>313</bold></highlight>, where labeled images are removed from the circumscribed rectangle <highlight><bold>601</bold></highlight>. In the case shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, since pixels are absent to the left of the straight line for both label <highlight><bold>1</bold></highlight> and label <highlight><bold>2</bold></highlight>, the pixels having these two labels are removed. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> For each of lower right, upper left and lower left corners, by performing the same processing by changing the direction and variables, it is possible to remove only rule portions even if an image is extracted inclusive of a part of rules. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Character recognition processing is performed for an image not including rules that has been obtained in the above-described manner. Since a rule portion is not included, a character described in a document can be correctly recognized. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> As described above, according to the first embodiment, since black pixels contacting a border of an intra-rule region are subjected to labeling, and pixels are removed by applying determination criteria for each group of labeled pixels, a rule portion can be removed even if rules are disconnected at a round portion. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> According to the first embodiment, since the determination criteria are obtained from the coordinates of labeled pixels, a character image can be extracted from a frame for describing a character so as not to include rules, even if the size of a round corner changes, or the roundness changes to an elliptical arc. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Since it is unnecessary to store the pattern of each corner, the capacity of a memory can be economized. Furthermore, it is unnecessary to perform matching processing with a plurality of corner patterns, and therefore the processing time can be reduced. </paragraph>
<paragraph id="P-0063" lvl="7"><number>&lsqb;0063&rsqb;</number> Second Embodiment </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> A description will now be provided of a case in which a corner rule portion is removed in step S<highlight><bold>211</bold></highlight> when a part of a character is superposed on a corner, according to a second embodiment of the present invention executed by the document reading apparatus shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, with reference to the flowchart shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, and the drawing in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates a frame for describing a character that is to be processed in the second embodiment. The upper right corner is rounded, and a part of a character is described there in a state of exceeding the frame boundary. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> A processing procedure when the upper right corner is round will now be described. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, in step S<highlight><bold>801</bold></highlight>, for an intra-rule rectangular region obtained in the same manner as in the first embodiment, the y coordinate of the upper end is represented by T, the x coordinate of the right end is represented by R, the height of the region is represented by H, and the width of the region is represented by W. In step S<highlight><bold>802</bold></highlight>, the y coordinate of the upper end and the x coordinate of the right end of a circumscribed rectangle of extracted black pixels are represented by t and r, respectively. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> In step S<highlight><bold>803</bold></highlight>, it is determined whether or not the x coordinate R of the right end of the intra-rule rectangular region equals the x coordinate r of the right end of the circumscribed rectangle of the black pixels. If the result of the determination in step S<highlight><bold>803</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>804</bold></highlight>, where it is determined whether or not the upper end of the circumscribed rectangle of the black pixels is at a position higher than a position &frac16; of the height below the upper end of the intra-rule rectangular region. If the result of the determination in step S<highlight><bold>804</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>807</bold></highlight>. If the result of the determination in step S<highlight><bold>804</bold></highlight> is negative, the process is terminated. The above-described value of &frac16;, and respective thresholds to be described below, are only examples for explaining the present invention. The present invention is not limited to these values. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> If the result of the determination in step S<highlight><bold>803</bold></highlight> is negative, the process proceeds to step S<highlight><bold>805</bold></highlight>, where it is determined whether or not the y coordinate T of the upper end of the intra-rule rectangular region equals the y coordinate t of the upper end of the circumscribed rectangle of the black pixels. If the result of the determination in step S<highlight><bold>805</bold></highlight> is negative, the process is terminated. If the result of the determination in step S<highlight><bold>805</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>806</bold></highlight>, where it is determined whether or not the right end of the circumscribed rectangle of the black pixels is to the right of a position that is &frac16; of the width to the left of the right end of the intra-rule rectangular region. If the result of the determination in step S<highlight><bold>806</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>807</bold></highlight>. If the result of the determination in step S<highlight><bold>806</bold></highlight> is negative, the process is terminated. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> In step S<highlight><bold>807</bold></highlight>, the upper end of the intra-rule rectangular region within a right-half portion is scanned, and the position of a black pixel at the left end position is obtained (<highlight><bold>901</bold></highlight>). In step S<highlight><bold>808</bold></highlight>, the right end of the intra-rule rectangular region within an upper-half portion is scanned, and the position of a black pixel at the lowermost position is obtained (<highlight><bold>902</bold></highlight>). </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> In step S<highlight><bold>809</bold></highlight>, only pixels at upper right portions of a straight line (indicated by broken line <highlight><bold>904</bold></highlight>) connecting the obtained two positions are subjected to labeling. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> In step S<highlight><bold>810</bold></highlight>, a label including a pixel at the right end that contacts the upper end of the intra-rule rectangular region from among labeled pixels is selected. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> In step S<highlight><bold>811</bold></highlight>, a label including a pixel at the upper end that contacts the right end of the intra-rule rectangular region from among labeled pixels is selected. If a thin portion and the like are absent in rules, the label selected in step S<highlight><bold>810</bold></highlight> is usually the same as the label selected in step S<highlight><bold>811</bold></highlight>. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> When a plurality of labels have been selected in steps S<highlight><bold>810</bold></highlight> and S<highlight><bold>811</bold></highlight>, then, in step S<highlight><bold>812</bold></highlight>, it is determined whether or not the labels are close. If the result of the determination in step S<highlight><bold>812</bold></highlight> is negative, the concerned image is determined to be not the image of a rule at a corner portion, and the process is terminated. Whether or not the labels are close is determined by checking whether or not circumscribed rectangles of labeled black-pixel images are superposed, or whether or not the distance between respective circumscribed rectangles is within a predetermined number of pixels (for example, one pixel). </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> In step S<highlight><bold>813</bold></highlight>, the position of a pixel at the left end that contacts the upper end of the inter-rule region from the selected label is obtained (<highlight><bold>901</bold></highlight>). </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> In step S<highlight><bold>814</bold></highlight>, the position of a pixel at the lower end that contacts the right end of the inter-rule region from the selected labels is obtained (<highlight><bold>903</bold></highlight>). </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> If a described character or the like does not contact a rule at a position other than a round corner, the position of the pixel obtained in step S<highlight><bold>813</bold></highlight> is the same as the position of the pixel obtained in step S<highlight><bold>807</bold></highlight>, and the position of the pixel obtained in step S<highlight><bold>814</bold></highlight> is the same as the position of the pixel obtained in step S<highlight><bold>808</bold></highlight>. At this stage, the starting position of a round corner included in the extracted image is obtained. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> When the position obtained in step S<highlight><bold>813</bold></highlight> is represented by (X,T), and the position obtained in step S<highlight><bold>814</bold></highlight> is represented by (R,Y), then in step S<highlight><bold>815</bold></highlight>, it is determined whether or not the selected labeled image is divided by a straight line (indicated by broken lines <highlight><bold>905</bold></highlight>) connecting the positions (X,T) and (R,Y). If a character crossing a rule is absent, the image is not divided. If the result of the determination in step S<highlight><bold>815</bold></highlight> is affirmative, the process proceeds to step S<highlight><bold>816</bold></highlight>, where the contour of labeled pixels is tracked from the point of division <highlight><bold>906</bold></highlight> in a direction (R,T), and points <highlight><bold>907</bold></highlight> and <highlight><bold>908</bold></highlight> where the direction of the contour greatly changes are searched. If the width of a line crossing a rule corresponds to at least two pixels, two pixels are present on the contour, and the two pixels are tracked. If the width corresponds to one pixel, the contour of the upper portion and the contour of the lower portion of the pixel on the contour are tracked. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> As a result, the two points <highlight><bold>907</bold></highlight> and <highlight><bold>908</bold></highlight> where the direction of the contour changes are obtained. In step S<highlight><bold>817</bold></highlight>, the labeled image is divided by a straight line connecting the two points, and an image present at the upper right side is left as a labeled image. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> The left labeled image is determined to be a part of a rule, and is removed in step S<highlight><bold>818</bold></highlight>. Thus, it is possible to obtain an image in which a round corner of rules is removed, and perform character recognition processing for the obtained image. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> As in the first embodiment, for each of lower right, upper left and lower left corners, by performing the same processing, rule portions are removed. As a result, it is possible to extract a character image in which rule portions are removed. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> As described above, according to the second embodiment, since labeling is performed by limiting the region of an image to be processed, and the position of a round corner of a rule is specified, it is possible to remove only rule portions and leave a character within a frame, even when a part of the character is threaded through the round portion. </paragraph>
<paragraph id="P-0083" lvl="7"><number>&lsqb;0083&rsqb;</number> Other Embodiments </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> The present invention may be applied to a system comprising a plurality of apparatuses (such as a host computer, an interface apparatus, a reader, a printer and the like), or to an apparatus comprising a single unit (such as a copier, a facsimile apparatus or the like). </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> The objects of the present invention may, of course, also be achieved by supplying a system or an apparatus with a storage medium (or a recording medium) storing program codes of software for realizing the functions of the above-described embodiments, and reading and executing the program codes stored in the storage medium by means of a computer (or a CPU or an MPU (microprocessor unit)) of the system or the apparatus. In such a case the program codes themselves read from the storage medium realize the functions of the above-described embodiments, so that the storage medium storing the program codes constitutes the present invention. The present invention may, of course, be applied not only to a case in which the functions of the above-described embodiments are realized by executing program codes read by a computer, but also to a case in which an OS (operating system) or the like operating in a computer executes a part or the entirety of actual processing, and the functions of the above-described embodiments are realized by the processing. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> The present invention may, of course, be applied to a case in which, after writing program codes read from a storage medium into a memory provided in a function expanding card inserted into a computer or in a function expanding unit connected to the computer, a CPU or the like provided in the function expanding card or the function expanding unit performs a part or the entirety of actual processing, and the functions of the above-described embodiments are realized by the processing. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> Furthermore, program codes constituting the present invention may be read from an external apparatus connected via a network whenever necessary and may be executed by a CPU. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> When applying the present invention to the above-described storage medium, program codes corresponding to the above-described flowcharts are stored in the storage medium. <cross-reference target="DRAWINGS">FIG. 10</cross-reference> illustrates an example of such a storage medium. In <cross-reference target="DRAWINGS">FIG. 10, a</cross-reference> memory map of a storage medium storing various data processing programs capable of being read by a document reading apparatus according to the present invention is shown. Although not illustrated, sets of data to be used for various programs are also managed in a directory of the storage medium. In some cases, for example, a program for installing various programs is stored. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> As described above, according to the present invention, even in a frame for describing a character including rules having round corners, a part of rules is not extracted as a character, and a character within the frame can be correctly extracted. Since a described character can be correctly extracted, the rate of character recognition is improved. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> According to the present invention, it is automatically determined whether or not a part of rules is included, and if the result of the determination is affirmative, that part is removed. Accordingly, it is unnecessary to assign the shape of each frame in advance. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> The individual components shown in outline or designated by blocks in the drawings are all well known in the image processing apparatus, method and program arts and their specific construction or operation are not critical to the operation or the best mode for carrying out the invention. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> While the present invention has been described with respect to what are presently considered to be the preferred embodiments, it is to be understood that the invention is not limited to the disclosed embodiments. To the contrary, the present invention is intended to cover various modifications and equivalent arrangements included within the spirit and scope of the appended claims. The scope of the following claims is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures and functions. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. An image processing apparatus comprising: 
<claim-text>row-direction-rule extraction means for extracting rules in a row direction from a document image; </claim-text>
<claim-text>column-direction-rule extraction means for extracting rules in a column direction from the document image; </claim-text>
<claim-text>image-region extraction means for extracting an image region based on a region surrounded by the row-direction rules extracted by said row-direction-rule extraction means and the column-direction rules extracted by said column-direction-rule extraction means; and </claim-text>
<claim-text>removal means for removing pixels constituting a part of rules from the image region extracted by said image-region extraction means, by identifying whether or not a desired pixel group contacting at least one of the row-direction rules and the column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said removal means removes the pixels constituting part of the rules from the image region by setting a border based on the labeled pixel group, measuring respective numbers of pixels on opposite sides of the border in the labeled pixel group, and identifying whether or not the labeled pixel group constitutes part of the rules based on a result of the measurement. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said removal means removes the pixels constituting part of the rules from the image region by setting a border based on the labeled pixel group, identifying a position where the border and the labeled pixel group intersect, tracking a contour line from the position of intersection, and identifying pixels constituting part of the rules from the labeled pixel group based on a result of tracking the contour line. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the labeling is performed only for pixels within a predetermined region of the image region. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising character recognition means for performing character recognition of an image within the image region from which the pixels constituting part of the rules have been removed by said removal means. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. An image processing method comprising: 
<claim-text>a row-direction-rule extraction step of extracting rules in a row direction from a document image; </claim-text>
<claim-text>a column-direction-rule extraction step of extracting rules in a column direction from the document image; </claim-text>
<claim-text>an image-region extraction step of extracting an image region based on a region surrounded by the row-direction rules extracted in said row-direction-rule extraction step and the column-direction rules extracted in said column-direction-rule extraction step; and </claim-text>
<claim-text>a removal step of removing pixels constituting a part of rules from the image region extracted in said image-region extraction step, by identifying whether or not a desired pixel group contacting at least one of the row-direction rules and the column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. An image processing method according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein in said removal step, the pixels constituting part of the rules are removed from the image region by setting a border based on the labeled pixel group, measuring respective numbers of pixels on opposite sides of the border in the labeled pixel group, and identifying whether or not the labeled pixel group constitutes part of the rules based on a result of the measurement. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. An image processing method according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein in said removal step, the pixels constituting part of the rules are removed from the image region by setting a border based on the labeled pixel group, identifying a position where the border and the labeled pixel group intersect, tracking a contour line from the position of intersection, and identifying pixels constituting part of the rules from the labeled pixel group based on a result of tracking the contour line. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. An image processing method according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein the labeling is performed only for pixels within a predetermined region of the image region. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. An image processing method according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, further comprising a character recognition step of performing character recognition of an image within the image region from which the pixels constituting part of the rules have been removed in said removal step. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. An image processing program, capable of being executed by a computer, including program codes for causing a computer to realize steps, said steps comprising: 
<claim-text>a row-direction-rule extraction step of extracting rules in a row direction from a document image; </claim-text>
<claim-text>a column-direction-rule extraction step of extracting rules in a column direction from the document image; </claim-text>
<claim-text>an image-region extraction step of extracting an image region based on a region surrounded by the row-direction rules extracted in said row-direction-rule extraction step and the column-direction rules extracted in said column-direction-rule extraction step; and </claim-text>
<claim-text>a removal step of removing pixels constituting a part of rules from the image region extracted in said image-region extraction step, by identifying whether or not a desired pixel group contacting at least one of the row-direction rules and the column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. An image processing program according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein in said removal step, the pixels constituting part of the rules are removed from the image region by setting a border based on the labeled pixel group, measuring respective numbers of pixels on opposite sides of the border in the labeled pixel group, and identifying whether or not the labeled pixel group constitutes part of the rules based on a result of the measurement. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. An image processing program according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein in said removal step, the pixels constituting part of the rules are removed from the image region by setting a border based on the labeled image group, identifying a position where the border and the labeled pixel group intersect, tracking a contour line from the position of intersection, and identifying pixels constituting part of the rules from the labeled pixel group based on a result of tracking the contour line. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. An image processing program according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the labeling is performed only for pixels within a predetermined region of the image region. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. An image processing program according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, further comprising a character recognition step of performing character recognition of an image within the image region from which the pixels constituting part of the rules have been removed in said removal step. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A storage medium storing an image processing program, capable of being executed by a computer, including program codes for causing a computer to realize steps, said steps comprising: 
<claim-text>a row-direction-rule extraction step of extracting rules in a row direction from a document image; </claim-text>
<claim-text>a column-direction-rule extraction step of extracting rules in a column direction from the document image; </claim-text>
<claim-text>an image-region extraction step of extracting an image region based on a region surrounded by the row-direction rules extracted in said row-direction-rule extraction step and the column-direction rules extracted in said column-direction-rule extraction step; and </claim-text>
<claim-text>a removal step of removing pixels constituting a part of rules from the image region extracted in said image-region extraction step, by identifying whether or not a desired pixel group contacting at least one of the row-direction rules and the column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A storage medium according to <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein in said removal step, the pixels constituting part of the rules are removed from the image region by setting a border based on the labeled pixel group, measuring respective numbers of pixels on opposite sides of the border in the labeled pixel group, and identifying whether or not the labeled pixel group constitutes part of the rules based on a result of the measurement. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A storage medium according to <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein in said removal step, the pixels constituting part of the rules are removed from the image region by setting a border based on the labeled pixel group, identifying a position where the border and the labeled image group intersect, tracking a contour line from the position of intersection, and identifying pixels constituting part of the rules from the labeled pixel group based on a result of tracking the contour line. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A storage medium according to <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein the labeling is performed only for pixels within a predetermined region of the image region. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A storage medium according to <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, further comprising a character recognition step of performing character recognition of an image within the image region from which the pixels constituting part of the rules have been removed in said removal step. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. An image processing apparatus comprising: 
<claim-text>an image scanner; and </claim-text>
<claim-text>a processor, said processor being configured to (i) extract rules in a row direction from a document image scanned by said image scanner, (ii) extract rules in a column direction from the document image, (iii) extract an image region based on a region surrounded by the extracted row-direction rules and the extracted column-direction rules, and (iv) remove pixels from the extracted image region that constitute part of rules, by identifying whether a desired pixel group contacting at least one of the row-direction rules and column-direction rules constitutes part of the rules, by performing labeling for the pixel group. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein said processor is configured to remove the pixels constituting part of the rules by setting a border based on the labeled pixel group, measuring respective numbers of pixels on opposite sides of the border in the labeled pixel group, and identifying whether the labeled pixel group constitutes part of the rules based on a result of the measurement. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein said processor is configured to remove the pixels constituting part of the rules by setting a border based on the labeled pixel group, identifying a position where the border and the labeled pixel group intersect, tracking a contour line from the position of intersection, and identifying pixels constituting part of the rules from the labeled pixel group based on a result of tracking the contour line. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein the processor is configured to perform labeling only for pixels within a predetermined region of the image region. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein said processor is further configured to perform character recognition of an image within the image region from which the pixels constituting part of the rules have been removed.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>2</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002062A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002062A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002062A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002062A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002062A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002062A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002062A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002062A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002062A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
