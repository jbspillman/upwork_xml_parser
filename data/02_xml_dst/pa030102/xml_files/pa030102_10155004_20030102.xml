<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002718A1-20030102-D00000.TIF SYSTEM "US20030002718A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00001.TIF SYSTEM "US20030002718A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00002.TIF SYSTEM "US20030002718A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00003.TIF SYSTEM "US20030002718A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00004.TIF SYSTEM "US20030002718A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00005.TIF SYSTEM "US20030002718A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00006.TIF SYSTEM "US20030002718A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00007.TIF SYSTEM "US20030002718A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00008.TIF SYSTEM "US20030002718A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00009.TIF SYSTEM "US20030002718A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00010.TIF SYSTEM "US20030002718A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00011.TIF SYSTEM "US20030002718A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00012.TIF SYSTEM "US20030002718A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00013.TIF SYSTEM "US20030002718A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00014.TIF SYSTEM "US20030002718A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00015.TIF SYSTEM "US20030002718A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030002718A1-20030102-D00016.TIF SYSTEM "US20030002718A1-20030102-D00016.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002718</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10155004</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020528</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06K009/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>382</class>
<subclass>124000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method and system for extracting an area of interest from within a swipe image of a biological surface</title-of-invention>
</technical-information>
<continuity-data>
<non-provisional-of-provisional>
<document-id>
<doc-number>60300832</doc-number>
<document-date>20010627</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Laurence</given-name>
<family-name>Hamid</family-name>
</name>
<residence>
<residence-non-us>
<city>Ottawa</city>
<country-code>CA</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>FREEDMAN &amp; ASSOCIATES</name-1>
<name-2></name-2>
<address>
<address-1>117 CENTREPOINTE DRIVE</address-1>
<address-2>SUITE 350</address-2>
<city>NEPEAN, ONTARIO</city>
<postalcode>K2G 5X3</postalcode>
<country>
<country-code>CA</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Disclosed is a biometric imaging device a method of processing images of biometric surfaces that are captured using said imaging device. According to the instant invention, an image of a biometric surface presented by an individual is captured by a sensor of the imaging device, either as a single image or as a plurality of overlapping image portions that are combinable to form a single composite image. The imaging device also includes a memory buffer for retrievably storing image data relating to the image of the biometric surface. A processor of the imaging device is provided for analyzing the stored image data to determine a location of a feature of interest and for providing an output image of a known size and shape for use by a host system that is in communication with the imaging device for identifying the individual. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application claims the benefit from U.S. Provisional Application No. 60/300,832 filed on Jun. 27, 2001.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> This invention relates generally to biometric imaging devices and more particularly to a method of processing images captured using said imaging devices. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> Biometric techniques for determining the identity of individuals are being used increasingly in authentication, recognition, and/or access systems. These techniques use biometric identifiers or human characteristics to verify or identify an individual. The fact that most human characteristics are unique to each individual, are difficult to reproduce by others, and are easily converted to electronic data, is particularly advantageous in biometric identification applications. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Historically, fingerprints have been the most widely used biometric identifiers, as is evident from law enforcement&apos;s extensive use of fingerprinting. The recent trends in biometric identification have been toward automating the above-mentioned authentication, recognition, and/or access systems. Most current techniques rely upon correlation methods that use automated detection systems connected to a computer database, for comparing detected biometric data to biometric data stored in the database, to confirm or determine the identity of an individual. Such automated systems have been used to identify individuals before granting access to cars, computers, home or business offices, hotel rooms, and in general, any sensitive or restricted area. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Various optical devices are known which employ prisms upon which a finger whose print is to be identified is placed. For example, the prism has a first surface upon which a finger is placed, a second surface disposed at an acute angle to the first surface through which the fingerprint is viewed and a third illumination surface through which light is directed into the prism. In some cases, the illumination surface is at an acute angle to the first surface, as seen for example, in U.S. Pat. Nos. 5,187,482 and 5,187,748. In other cases, the illumination surface is parallel to the first surface, as seen for example, in U.S. Pat. Nos. 5,109,427 and 5,233,404. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> An alternative type of contact imaging device is disclosed in U.S. Pat. No. 4,353,056 in the name of Tsikos issued Oct. 5, 1982, herein incorporated by reference. The imaging device that is described by Tsikos uses a capacitive sensing approach. To this end, the imaging device comprises a two dimensional, row and column, array of capacitors, each comprising a pair of spaced apart electrodes, carried in a sensing member and covered by an insulating film. The sensors rely upon deformation to the sensing member caused by a finger being placed thereon so as to vary locally the spacing between capacitor electrodes, according to the ridge/trough pattern of the fingerprint, and hence, the capacitance of the capacitors. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> A further contact imaging device is described in U.S. Pat. No. 5,325,442 in the name of Knapp, issued Jun. 28, 1994, herein incorporated by reference. Knapp discloses a capacitance measuring contact imaging device in the form of a single large active matrix array, formed by the deposition and definition by photolithographic processes of a number of layers on a single large insulating substrate. Electrodes and sets of address conductors formed of metal and field effect transistors are formed as amorphous silicon or polycrystalline silicon thin film transistors (TFTs) using an appropriate substrate of, for example, glass or quartz. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Additionally, a fingerprint sensing device and recognition system that includes an array of closely spaced apart sensing elements, each comprising a sensing electrode and an amplifier circuit, is described in U.S. Pat. No. 5,778,089 in the name of Borza, issued Jul. 7, 1998, herein incorporated by reference. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> &ldquo;Swipe imagers&rdquo; are also known, wherein an individual places a fingertip into contact with a surface of a contact imaging device and then draws, or &ldquo;swipes&rdquo;, the fingertip across a sensing portion of the surface. Images from adjacent portions of the fingertip are captured and combined in order to construct a composite image of the fingertip having an area that is greater than the area of a single captured image. In this way, an area of the fingertip that is substantially larger than the sensing portion is imaged. Such an arrangement allows a smaller capacitive fingerprint scanner to be used, which is advantageous due to lower manufacturing costs, improved robustness, and so forth. Also, the small area required is highly advantageous for embedded applications such as with a cell phone, a telephone, a computer (laptop) and so forth. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Methods for processing fingerprint images, for instance to extract data that is useful in correlating an image with previously stored templates, are well known in the art. However, the prior art methods often rely upon the fingerprint image being of a known size and having a known area of interest, and are best suited for use with contact imaging devices that require the individual to hold their fingertip stationary during image acquisition. A particular problem with the swipe imagers described above is that it is unlikely that the individual will &ldquo;swipe&rdquo; their fingertip along a perfectly straight line. Accordingly, swipe imagers often produce a fingerprint image of arbitrary shape and size. This results in a breakdown of the assumptions that are inherent in the prior art processing methods and therefore must be addressed. Typical systems address this issue by increasing the processing to process the entire image in case features are located anywhere therein. Unfortunately, this approach requires changing every biometric identification system for use with each imager. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> It would be advantageous to provide an imager that is functional with a plurality of identification processes. It would be further advantageous to provide a method for identifying and/or recognizing individuals based upon a feature extracted from an image of a fingerprint, the image being of arbitrary shape and size. </paragraph>
</section>
<section>
<heading lvl="1">OBJECT OF THE INVENTION </heading>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> Thus, in an attempt to overcome these and other limitations of the prior art, it is an object of this invention to provide a contact imaging device that provides an image area about a feature of interest as an output image therefrom. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> In accordance with the invention there is provided a method of imaging a biometric information source comprising the steps of: sensing a biometric information source to provide biometric image data; analyzing the biometric image data to determine a location of at least a repeatably identifiable feature of the sensed biometric information within the biometric image data; and providing an image of a known size less than the size of the biometric image data, the provided image sensed at contiguous locations of the biometric information source near the determined location of the at least a repeatably identifiable feature. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> In accordance with another aspect of the invention there is provided a method of imaging a biological surface comprising the steps of: sensing a plurality of images of a same biological surface; aligning the sensed images one relative to another to form a composite image of the biological surface; analyzing at least one of the composite image and the plurality of images to determine a location of a repeatably identifiable feature; and, providing a known amount of image data at locations relative to the location of the repeatably identifiable feature as the composite image data. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In accordance with yet another aspect of the invention there is provided a swipe fingerprint scanner comprising: a sensor for sensing a plurality of images of a same biological surface; a memory in communication with the sensor, for retrievably storing each image of the plurality of images; a processor in communication with the sensor and with the memory, the processor programmed for aligning the sensed images one relative to another to form a composite image of the biological surface, for analyzing the composite image to determine at least a location of a repeatably identifiable feature and, for providing a known amount of image data at locations relative to the determined location of the repeatably identifiable feature as output image data; and a data input/output port in communication with the processor, for receiving the output image data therefrom, and for providing the output image data to a processor external to the swipe fingerprint scanner.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Exemplary embodiments of the invention will now be described in conjunction with the following drawings, in which similar reference numbers designate similar items: </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a simplified block diagram of a swipe scanner according to the instant invention; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a </italic></highlight>is a simplified block diagram of a first swipe sensor contemplated for use with the swipe scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b </italic></highlight>is a simplified block diagram of a second swipe sensor contemplated use with the swipe scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>c </italic></highlight>is a simplified block diagram of a third swipe sensor contemplated for use with the swipe scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a simplified flow diagram of a method for processing fingerprint information received from one of the swipe sensors shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a </italic></highlight>to <highlight><bold>1</bold></highlight><highlight><italic>c </italic></highlight>to construct a composite image of the fingerprint; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a schematic diagram showing a composite fingerprint image obtained using the swipe scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, including a selected area proximate the fingerprint core; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a schematic diagram showing misalignment of individual images of a composite fingerprint image proximate the fingerprint core; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a simplified flow diagram of a method according to a first embodiment of the instant invention, for imaging a fingerprint using the swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of an image derived therefrom and about a feature or features of interest; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>a </italic></highlight>is a simplified flow diagram of another method according to the first embodiment of the instant invention, for imaging a fingerprint using the swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of an image derived therefrom and about a feature or features of interest; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>b </italic></highlight>is a simplified flow diagram of still another method according to the first embodiment of the instant invention, for imaging a fingerprint using the swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of an image derived therefrom and about a feature or features of interest; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>c </italic></highlight>is a simplified flow diagram of yet another method according to the first embodiment of the instant invention, for imaging a fingerprint using the swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of an image derived therefrom and about a feature or features of interest; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a simplified flow diagram of a method according to the instant invention for imaging a fingerprint using the swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of a scaled image derived therefrom and about a feature or features of interest; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a simplified flow diagram of a method for locating the core region of an acquired fingerprint image; </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a simplified diagram showing ridge-trough alternation near the periphery of a fingerprint image; </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a simplified diagram showing a first crease feature of a fingerprint image; </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> shows a method according to a second embodiment of the instant invention for imaging a fingerprint using a swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of an image derived therefrom and about a feature or features of interest; </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a simplified flow diagram of a method according to a third embodiment of the instant invention for imaging a fingerprint using a contact imaging device and for provision of an image derived therefrom and about a feature or features of interest; </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a simplified flow diagram of a method according to a fourth embodiment of the instant invention for imaging a fingerprint using a contact imaging device and for provision of an image derived therefrom and about a feature or features of interest; and, </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a simplified flow diagram of a method according to the instant invention for imaging a fingerprint using a contact imaging device and for provision of an image derived therefrom and about a feature or features of interest. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The following description is presented to enable a person skilled in the art to make and use the invention, and is provided in the context of a particular application and its requirements. Various modifications to the disclosed embodiments will be readily apparent to those skilled in the art, and the general principles defined herein may be applied to other embodiments and applications without departing from the spirit and the scope of the invention. Thus, the present invention is not intended to be limited to the embodiments disclosed, but is to be accorded the widest scope consistent with the principles and features disclosed herein. It is to be completely understood that the term &ldquo;cropping&rdquo;, as it is used in the specification and in the claims that follow, is intended to encompass both actually deleting image data at image locations outside of a selected image area, and virtually &ldquo;deleting&rdquo; image data at image locations outside of a selected image area by merely eliminating such data from a frame of consideration&mdash;by ignoring such data or other than transferring said data from an imaging device. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, shown is a simplified block diagram of a swipe scanner according to the instant invention. The swipe scanner <highlight><bold>1</bold></highlight> comprises a swipe sensor <highlight><bold>2</bold></highlight> in communication with a memory buffer <highlight><bold>3</bold></highlight> and a processor <highlight><bold>4</bold></highlight>. The processor <highlight><bold>4</bold></highlight> is in communication with the memory buffer <highlight><bold>3</bold></highlight> and with a data input/output port for providing data to and for receiving data from a fingerprint correlation system (not illustrated). The swipe scanner <highlight><bold>1</bold></highlight> is of the swipe contact imager type, and is preferably a capacitive contact imaging sensor. Three examples of capacitive contact imaging sensors that are contemplated for use with the swipe scanner <highlight><bold>1</bold></highlight> are described below with reference to <cross-reference target="DRAWINGS">FIGS. 1</cross-reference><highlight><italic>a </italic></highlight>to <highlight><bold>1</bold></highlight><highlight><italic>c. </italic></highlight>In use, the swipe sensor <highlight><bold>2</bold></highlight> captures a plurality of overlapping image portions from a biometric information source, for example a fingerprint of a fingertip that has been placed into contact therewith. The image portions are provided to and retrievably stored within the memory buffer. Preferably, the memory buffer is sufficiently large to store image data representative of an area larger than a typical fingerprint. The processor <highlight><bold>4</bold></highlight> is for retrieving the image portions from the memory buffer, one or more image portions at a time, and for constructing a single composite fingerprint image therefrom. To this end, the processor <highlight><bold>4</bold></highlight> is for executing program code thereon for processing, aligning and mosaicing the image portions. The processor <highlight><bold>4</bold></highlight> is also for locating a feature or features within the processed image portions, and for cropping image data outside of a selected area about the located feature or features, to produce an output image of known size and shape. Optionally, the processor <highlight><bold>4</bold></highlight> is for locating a feature or features within the composite fingerprint image, and for cropping image data outside of a selected area about the located feature or features, to produce an output image of known size and shape. In use, the processor <highlight><bold>4</bold></highlight> provides the output image of known size and shape to a fingerprint correlation system via the data input/output port <highlight><bold>5</bold></highlight>. Optionally, the data input/output port <highlight><bold>5</bold></highlight> is also for receiving preferences from the fingerprint correlation system, such as for instance a desired size of the output image. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a, </italic></highlight>shown is a first swipe sensor contemplated for use with the swipe scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. The first swipe sensor includes a single active matrix addressed first sensing pad <highlight><bold>100</bold></highlight> having an X-Y array of sense elements including r rows (1 to r) with c sensing elements <highlight><bold>17</bold></highlight> in each row. In practice there are about 10 rows and 300 columns of regularly-spaced elements occupying an area of approximately 0.1 cm&times;2 cm. Sensing elements <highlight><bold>17</bold></highlight> are sized and disposed in such a fashion that they are capable of distinguishing the smallest desired feature of a fingerprint. The placement and spacing of the sensor elements preferably is such that an image of a fingerprint, once scanned, contains sufficient features for analysis. Most preferably, in order to generate an image for analysis, a sensing element <highlight><bold>17</bold></highlight> is smaller than half the smallest feature size to be sensed. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Adjacent the first sensing pad <highlight><bold>100</bold></highlight> is a second sensing pad <highlight><bold>101</bold></highlight> for use in determining motion of a sensed fingertip. Because of the random nature of fingerprint data, a scan line across a fingertip is unlikely to match a second other scan line across the same fingertip unless both scan lines are of a same portion of the fingertip. Therefore, when the sensed fingerprint data sensed by the second sensing pad <highlight><bold>101</bold></highlight> is substantially the same as data previously sensed by the first sensing pad <highlight><bold>100</bold></highlight>, the fingertip is known to have moved a predetermined distance &Dgr;d. Thus, currently sensed fingerprint data, sensed by the first array has a known relative position to the previously sensed data. The second sensing pad <highlight><bold>101</bold></highlight> does not need to be as topographically sensitive as the first sensing pad <highlight><bold>100</bold></highlight>. In this regard, the second sensing pad <highlight><bold>101</bold></highlight> may have a lower resolution than the first sensing pad <highlight><bold>100</bold></highlight>, thereby reducing component costs. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The combined sensing and measuring array of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a </italic></highlight>is disposed within a platen <highlight><bold>102</bold></highlight> for accepting a fingertip. Preferably, the platen <highlight><bold>102</bold></highlight> has an area of approximately 2 cm&times;4 cm for accepting a fingertip drawn across the sensing elements <highlight><bold>17</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b, </italic></highlight>shown is a second swipe sensor contemplated for use with the swipe scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. The second swipe sensor includes a single, or unified, active matrix addressed sensing pad <highlight><bold>103</bold></highlight> having an X-Y array of sense elements including r rows (1 to t) with d sensing elements <highlight><bold>17</bold></highlight> in each row. In practice there may be about 10 rows and 300 columns of regularly spaced elements occupying an area of approximately 0.15 cm&times;2 cm. Sensing elements <highlight><bold>17</bold></highlight> are sized and disposed in such a fashion that they are capable of distinguishing the smallest desired feature of a fingerprint. The placement and spacing of the sensor elements allow an image of a fingerprint, once scanned, to contain sufficient features for analysis. Preferably, in order to generate an image for analysis, a sensing element <highlight><bold>17</bold></highlight> is smaller than half the smallest feature size to be sensed. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> In contrast to <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a, </italic></highlight>in the swipe sensor of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b </italic></highlight>the array for determining motion of a sensed fingertip and the sensing array are a same array. The single active matrix addressed sensing pad <highlight><bold>103</bold></highlight> permits, by virtue of having a series of arrays, both concurrent receipt of fingerprint data and comparison with previously stored data of the fingertip as a fingertip is passed over the sensing pad <highlight><bold>103</bold></highlight>. The swipe sensor illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b </italic></highlight>functions in a similar manner to the swipe sensor illustrated in <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a. </italic></highlight></paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The unitary swipe sensor of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b </italic></highlight>is disposed within a platen <highlight><bold>104</bold></highlight> for accepting a fingertip. Preferably, the platen has an area of approximately 2 cm&times;4 cm for accepting a fingertip that is drawn across the sensing elements <highlight><bold>17</bold></highlight>. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>c, </italic></highlight>shown is a third swipe sensor contemplated for use with the swipe scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. The third swipe sensor is a multi-directional swipe sensor including a horizontal active matrix addressed sensing pad <highlight><bold>105</bold></highlight> having an X-Y array of sense elements including r rows (1 to u) with e sensing elements <highlight><bold>17</bold></highlight> in each row, and a vertical active matrix addressed sensing pad <highlight><bold>106</bold></highlight> having an X-Y array of sense elements including t rows (1 to v) with f sensing elements <highlight><bold>17</bold></highlight> in each row. In practice, either sensing pad <highlight><bold>105</bold></highlight>,<highlight><bold>106</bold></highlight> includes approximately 10 rows and 300 columns of regularly spaced elements occupying an area of approximately 0.15 cm&times;2 cm. Sensing elements <highlight><bold>17</bold></highlight> are sized and disposed in such a fashion that they are capable of distinguishing the smallest desired feature of a fingerprint. The placement and spacing of the sensor elements allow an image of a fingerprint, once scanned, to contain sufficient features for analysis. Preferably, in order to generate an image for analysis, a sensing element <highlight><bold>17</bold></highlight> is smaller than half the smallest feature size to be sensed. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> The multi-directional swipe sensor of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>c </italic></highlight>is disposed within a platen <highlight><bold>107</bold></highlight> for accepting a fingertip. Preferably, the platen <highlight><bold>107</bold></highlight> has an area of approximately 4 cm&times;4 cm for accepting a fingertip that is drawn across the sensing elements <highlight><bold>17</bold></highlight>. Advantageously, the multi-directional swipe sensor supports fingerprint image construction when the individual draws their fingertip across the sensing elements <highlight><bold>17</bold></highlight> in any direction. Unfortunately, the constructed image is of arbitrary shape and size if the individual fails to draw their fingertip along a perfectly straight line. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, shown is a simplified flow diagram of a method for processing fingerprint information received from a swipe fingerprint scanner to construct a composite image of the fingerprint. In a first step an image space <highlight><bold>50</bold></highlight> is provided followed by an image scale <highlight><bold>52</bold></highlight>. An initial image portion of the fingertip is provided <highlight><bold>54</bold></highlight> and stored <highlight><bold>56</bold></highlight> within the image space <highlight><bold>50</bold></highlight>. Another portion of a fingertip is then imaged <highlight><bold>58</bold></highlight>. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> In a next step a search for a correlation between the initial image and a second other image is initiated, that is, it is determined <highlight><bold>60</bold></highlight> if there is a known spatial relationship between stored images. There are two possible results to the search: YES or NO. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> In the case of a YES response an image is stored <highlight><bold>62</bold></highlight> in the image space at a known location relative to a previously imaged portion and another portion of a fingertip is then imaged <highlight><bold>58</bold></highlight>. Again it is determined if there is a known spatial relationship between stored images <highlight><bold>60</bold></highlight>. In the case of a NO response the image portion is stored <highlight><bold>64</bold></highlight> for later reference and another portion of the fingertip is then imaged <highlight><bold>58</bold></highlight> and it is determined <highlight><bold>60</bold></highlight> if there is a known spatial relationship between stored images. By the use of a suitably programmed processor, thresholds for rejection or acceptance of data in determinations of correlation are selectable. After sufficient correlations are found, the data is then assembled using known relations between different image portions and a composite fingerprint image so formed is compared to a stored template of fingerprint data. For example, the fingerprint assembly is performed using a simultaneous solution to place all image portions having unknown fixed locations but limited possible locations relative to some other image portions. Alternatively, the composite image is assembled through iterative steps of image portion placement and image analysis to determine placement errors. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> As described above, the composite image produced according to the method of <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is of arbitrary size and shape. Significantly, features that are of interest for use with correlation methods may be located anywhere within the image. Unfortunately, processing such an arbitrarily large image in its entirety to extract features for comparison to template data increases unnecessarily the amount of processing that is required to identify/recognize an individual. Further, it complicates image processing algorithms that usually require images of known size and resolution. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, shown is a simplified diagram of a composite fingerprint image that was obtained using a swipe fingerprint scanner, including a selected area proximate a feature or features of interest, for example the fingerprint core. In <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the selected area is delineated by a square boarder, which has been superimposed upon the composite fingerprint image. Preferably, the size of the selected area is defined in terms of a number of columns of pixels to either side of the feature of interest and a number of rows of pixels above and below the feature of interest. For example, a user specifies the size of the selected area by providing a desired number of columns and a desired number of rows of pixels to display within the selected area. Optionally, the size of the selected area is a same predetermined value for every correlation application and every swipe scanner system. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> also shows an enlarged view of the selected area in which extraneous fingerprint data has been cropped, for example any data that lies outside of the square region. According to a first embodiment of the instant invention, the swipe scanner provides an output image comprising image data for image portions falling within the selected area, for use by a correlation processor for comparison to template data. Advantageously, the portion of the fingerprint image that lies within the selected area is of known size and shape and contains the features that are required for correlation, such that the output image has universal utility. Optionally, the selected area is defined relative to a feature other than the core, such as for instance a crease or a minutia. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, shown is a simplified flow diagram of a method according to a first embodiment of the instant invention, for imaging a fingerprint using a swipe fingerprint scanner and for provision of an image derived therefrom, the image about a feature or features of interest. A fingertip is passed over the swipe fingerprint imager <highlight><bold>70</bold></highlight> and is imaged in separate overlapping portions <highlight><bold>72</bold></highlight>. A memory buffer within the scanner maintains the imaged portions and a processor acts to construct <highlight><bold>74</bold></highlight> a composite image of the fingertip from numerous scanned portions. The composite image is not limited to a fixed area of the fingertip and as such, the buffer is sufficient in size to maintain a larger than normal fingerprint image. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Once the composite image is constructed <highlight><bold>74</bold></highlight>, the processor analyses the constructed image to locate <highlight><bold>76</bold></highlight> a feature or features of interest. Typically, for fingerprint images, the feature of interest is the fingerprint core. Methods for identifying the core are known, such as for instance the method described below with reference to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. A selected area is then defined about the feature of interest to define a fingerprint image having a resolution according to design requirements, and the selected area is provided <highlight><bold>78</bold></highlight> as the output image from the swipe fingerprint scanner. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>a, </italic></highlight>shown is a simplified flow diagram of another method according to the first embodiment of the instant invention, for imaging a fingerprint using the swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of an image derived therefrom about a feature or features of interest. A fingertip is passed over the swipe fingerprint imager <highlight><bold>70</bold></highlight> and is imaged in separate overlapping portions <highlight><bold>72</bold></highlight>. A memory buffer within the scanner maintains the imaged portions and a processor acts to construct <highlight><bold>74</bold></highlight> a composite image of the fingertip from numerous scanned portions. According to the method of <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>a, </italic></highlight>the processor begins analyzing fingerprint image data immediately in order to locate <highlight><bold>86</bold></highlight> a feature or features of interest, this reduces the overall buffer size requirements and reduces the processing overhead for image construction in many situations. Typically, for fingerprint images, the feature of interest is the fingerprint core. Methods for identifying the core are known, such as for instance the method described below with reference to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. That said, core identification is a difficult task and it is preferred that core identification commence only after sufficient image construction has occurred, in order to make accurate core identification reasonably possible. According to the method of <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>a, </italic></highlight>the steps of image construction <highlight><bold>74</bold></highlight> and of image analysis to locate <highlight><bold>86</bold></highlight> the feature of interest are performed substantially in parallel. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Once the composite image is constructed and the feature of interest is located, a selected area of the composite image having a known spatial relation to the feature of interest is defined, the image within the buffer is cropped&mdash;extraneous data is ignored or deleted&mdash;and the selected area of the composite image is provided <highlight><bold>88</bold></highlight> as the output image. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>b, </italic></highlight>shown is a simplified flow diagram of still another method according to the first embodiment of the instant invention, for imaging a fingerprint using the swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of an image derived therefrom and about a feature or features of interest. A fingertip is passed over the swipe fingerprint imager <highlight><bold>70</bold></highlight> and is imaged in separate overlapping portions <highlight><bold>72</bold></highlight>. A memory buffer within the scanner maintains the imaged portions and a processor acts to construct <highlight><bold>74</bold></highlight> an image of the fingertip from numerous scanned portions. According to the method of <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>a, </italic></highlight>the processor begins analyzing fingerprint image data immediately in order to locate <highlight><bold>86</bold></highlight> a feature or features of interest, this reduces the overall buffer size requirements and reduces the processing overhead for image construction in many situations. Typically, for fingerprint images, the feature of interest is the fingerprint core. Methods for identifying the core are known, such as for instance the method described below with reference to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. That said, core identification is a difficult task and it is preferred that core identification commence only after sufficient image construction has occurred to make accurate core identification reasonably possible. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> According to the method of <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>b, </italic></highlight>the steps of image construction <highlight><bold>74</bold></highlight> and of image analysis to locate <highlight><bold>86</bold></highlight> the feature of interest are performed substantially in parallel until it is determined at <highlight><bold>90</bold></highlight> that the feature of interest has been located. A selected area of the partially constructed composite image having a known spatial relation to the feature of interest is defined <highlight><bold>92</bold></highlight>. The image within the buffer is cropped&mdash;extraneous data is ignored or deleted&mdash;and the image construction continues <highlight><bold>96</bold></highlight> only within the selected area. The selected area of the composite image is provided <highlight><bold>98</bold></highlight> as the output image. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 6</cross-reference><highlight><italic>c, </italic></highlight>shown is a simplified flow diagram of yet another method according to the first embodiment of the instant invention, for imaging a fingerprint using the swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of an image derived therefrom and about a feature or features of interest. A fingertip is passed over the swipe fingerprint imager <highlight><bold>70</bold></highlight> and is imaged in separate overlapping portions <highlight><bold>72</bold></highlight>. A memory buffer within the scanner maintains the imaged portions and a processor acts to locate <highlight><bold>110</bold></highlight> a feature or features of interest within the imaged portions. Preferably, the feature or features of interest are common to all or nearly all imaged portions. Typically, for fingerprint images, the feature of interest is the fingerprint core. Methods for identifying the core are known, such as for instance the method described below with reference to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. Once the feature of interest has been located, a selected area having a known spatial relation to the feature of interest is defined <highlight><bold>112</bold></highlight>. The image within the buffer is cropped <highlight><bold>114</bold></highlight>&mdash;extraneous data is ignored or deleted&mdash;and image construction is performed <highlight><bold>116</bold></highlight> only for the selected area. The selected area of the composite image is provided <highlight><bold>118</bold></highlight> as the output image. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, shown is a simplified flow diagram of a method according to the instant invention for imaging a fingerprint using the swipe fingerprint scanner of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and for provision of a scaled image derived therefrom and about a feature or features of interest. An individual swipes their fingertip and the swipe fingerprint scanner captures <highlight><bold>130</bold></highlight> a plurality of successive images of portions of the fingerprint. The images are then constructed <highlight><bold>131</bold></highlight> into a composite fingerprint image. The composite fingerprint image is then analysed to determine <highlight><bold>132</bold></highlight> a location of a known feature. Once the feature of interest has been located, a selected area having a known spatial relation to the feature of interest is defined <highlight><bold>133</bold></highlight>. The image within the buffer is cropped <highlight><bold>134</bold></highlight>&mdash;extraneous data outside the area of interest is ignored or deleted. Further, the image is analyzed <highlight><bold>135</bold></highlight> to determine scale related information. The scale related information is then used to determine whether the area of interest is to be larger or smaller or in most applications whether the area of interest should be scaled through application of an image transform to decrease ridge spacing or to increase ridge spacing. If it is determined at step <highlight><bold>136</bold></highlight> that image scaling is required, then the image is scaled <highlight><bold>137</bold></highlight>, and the scaled determined area of interest is provided as the output image <highlight><bold>138</bold></highlight>. If it is determined at step <highlight><bold>136</bold></highlight> that image scaling is not required, then the selected area of interest is provided directly as the output image at step <highlight><bold>139</bold></highlight>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 8, a</cross-reference> method of core identification for fingerprint analysis is shown. At step <highlight><bold>120</bold></highlight> an image of a fingerprint is acquired, optionally the fingerprint image is obtained as one of a single image and a composite image constructed from a plurality of image portions. The acquired image is processed at step <highlight><bold>122</bold></highlight> to clean up the image in order to enhance contrast between ridges and valleys. For instance, ridges are cleaned up to remove artifacts that may relate to imaging errors caused by, for example, moisture, dryness, or scars. The cleaned up image is then addressed as an array of data at step <highlight><bold>124</bold></highlight>. The array of data is analyzed to determine <highlight><bold>126</bold></highlight> a center line of the fingertip, for instance along a vertical path ridges are followed to determine a vertical center line of the fingertip. As will be noted with reference to <cross-reference target="DRAWINGS">FIG. 9, a</cross-reference> ridge value alternation exists near the periphery of the fingerprint, shown schematically as a series of dot located along vertical line A. As the center is approached, a vertical line remains on one of a ridge or a valley for a longer time, as denoted by the widened portion of line B. When a ridge can no longer be followed along a vertical path, for instance a valley is encountered, then the above step is repeated for a ridge along a horizontal path. The procedure is repeated along vertical and horizontal paths <highlight><bold>128</bold></highlight> in an iterative fashion, until the core is identified <highlight><bold>130</bold></highlight>. When desired, the process can be repeated at angles such as 45 degree angles within the array. The method described with reference to <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is suitable for identifying a core of a fingerprint that is classified as a whorl; additionally, methods are known in the art for identifying the core regions of fingerprints belonging to other groups. Optionally, the core is positioned <highlight><bold>132</bold></highlight> centrally within the image data before the output image is provided. Further optionally, the core is positioned at a user specified location within the image data. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> The composite image provided as the output image is optionally the cleaned up image. Further optionally, it is the raw image merely cropped to identify a region of interest. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> According to the first embodiment of the instant invention, the feature of interest, for instance the core, is centered within the selected area of image data for provision from the sensor. The image data is of a size and resolution relating to the sensor itself. Typical sensors provide 300&times;200 pixels having 50 &mgr;m spacing. Thus, the core is centered at location (<highlight><bold>150</bold></highlight>, <highlight><bold>100</bold></highlight>) within the provided image. Of course, the position of the feature of interest will vary depending upon the selected feature and upon the sensor. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> According to a second embodiment of the instant invention there is provided a method wherein the quality of the image of the selected area is evaluated prior to the image being output from the sensor. Referring to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, shown is a schematic diagram illustrating misalignment of image portions of a composite image proximate the core of the fingerprint. The misalignment is caused by, for example, the individual drawing their fingertip across the sweep imager along an erratic swipe trajectory such as the one illustrated to the left of the composite image, such that successive image portions do not line up straight with every other image portion. As shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, portions of the image in an area of interest, for instance an area about the core, may be unpopulated with image data. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, shown is a method according to the second embodiment of the instant invention for imaging a fingerprint using a swipe fingerprint scanner and for provision of an image derived therefrom and about a feature or features of interest. An image of a selected area of a fingerprint is acquired <highlight><bold>140</bold></highlight>, for instance according to a method described with reference to one of <cross-reference target="DRAWINGS">FIGS. 5, 6</cross-reference><highlight><italic>a, </italic></highlight><highlight><bold>6</bold></highlight><highlight><italic>b, </italic></highlight><highlight><bold>6</bold></highlight><highlight><italic>c </italic></highlight>and <highlight><bold>7</bold></highlight>. The population of pixels within the selected area is determined at step <highlight><bold>142</bold></highlight>, for instance pixels representative of image data are counted as populated, while pixels that are not representative of image data are counted as being unpopulated. Optionally, the population is defined in absolute terms or as a fraction of the total number of pixels. The population so defined is compared at step <highlight><bold>144</bold></highlight> to a threshold value for accepting the image as a quality image. For instance, the comparison requires that the determined pixel population exceeds a threshold value of 99%. Of course, the actual threshold value depends upon the level of security that is desired, etc. If it is determined that the population is within the threshold value, then the image is provided as the output image at step <highlight><bold>146</bold></highlight>. If it is determined that the population is outside the threshold value, then the image is considered to be of poor quality, a new image is acquired and the method of <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is repeated. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Of course, features of interest selected from other feature types are also suitable for use with any of the above-described methods. For instance, the selected area is optionally defined as an area about and including a minimum number of minutia points per unit area of image. Further optionally, a crease as is shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is used as the feature of interest, more particularly it is the crease nearest the tip in a finger. The crease is identified within a fingerprint image and data above the crease&mdash;toward the fingertip&mdash;is provided from the sensor. Alternatively, data from the centre of the region above the crease is provided from the sensor. Still further optionally, a delta is used as the feature of interest. A delta is a divergence point where the fingerprint ridges tend to wrap around the center of the finger. A whorl-type fingerprint usually has two deltas, a right loop fingerprint has a delta on the left of the observer, and a left loop fingerprint has a delta on the right of the observer. Of course, any other identifiable feature type is also envisaged for use with the described with reference to <cross-reference target="DRAWINGS">FIGS. 5, 6</cross-reference><highlight><italic>a, </italic></highlight><highlight><bold>6</bold></highlight><highlight><italic>b, </italic></highlight><highlight><bold>6</bold></highlight><highlight><italic>c, </italic></highlight>and <highlight><bold>7</bold></highlight>. The above-mentioned feature types are provided merely for illustrative purposes, and should be interpreted only as non-limiting examples. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 12</cross-reference>, shown is a method for selecting a feature type of the feature of interest for use in identifying/recognizing an individual. At step <highlight><bold>200</bold></highlight>, the individual being identified/recognized provides identification information to a host system that is in communication with the swipe fingerprint scanner. At step <highlight><bold>201</bold></highlight><highlight><italic>a </italic></highlight>processor of the host system retrieves, from a memory storage area, template data relating to the identification information and including data indicative of a preferred feature for use in identifying the individual. For example, if the individual does not have a repeatably identifiable fingerprint core, then the preferred feature may be a densely packed group of minutiae points. At step <highlight><bold>202</bold></highlight> the host processor provides the data indicative of the preferred feature to the processor of the swipe fingerprint scanner, and at step <highlight><bold>204</bold></highlight> the processor of the swipe fingerprint scanner registers the preferred feature as the feature of interest. The steps of <cross-reference target="DRAWINGS">FIG. 12</cross-reference> are optionally performed prior to the first step of any of the methods described above with reference to <cross-reference target="DRAWINGS">FIGS. 5, 6</cross-reference><highlight><italic>a, </italic></highlight><highlight><bold>6</bold></highlight><highlight><italic>b, </italic></highlight><highlight><bold>6</bold></highlight><highlight><italic>c </italic></highlight>and <highlight><bold>7</bold></highlight>. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Further optionally, if first and second portions of an individual&apos;s preferred feature can be imaged within first and second image portions, respectively, for instance using 10 rows and 300 columns of sensing elements, then it is possible to significantly reduce the amount of processing that is required to perform composite image construction. Referring now to <cross-reference target="DRAWINGS">FIG. 13</cross-reference>, at step <highlight><bold>210</bold></highlight> the individual being identified/recognized provides identification information to a host system that is in communication with the swipe fingerprint scanner. A processor of the host system retrieves at step <highlight><bold>211</bold></highlight>, from a memory storage area, template data relating to the identification information and including first data indicative of the first portion of the preferred feature and second data indicative of the second portion of the preferred feature. At step <highlight><bold>212</bold></highlight> the host system provides the first data and the second data to the processor of the swipe fingerprint scanner. The individual passes a fingertip over the swipe fingerprint imager <highlight><bold>213</bold></highlight> and the fingertip is imaged in separate overlapping portions <highlight><bold>214</bold></highlight>. A memory buffer within the scanner maintains the image portions and a processor acts to locate <highlight><bold>215</bold></highlight> the first portion of the preferred feature within a single image portion. Once the first portion of the feature of interest has been located, construction of the composite image occurs at step <highlight><bold>216</bold></highlight>. For instance, the twenty image portions immediately preceding the image portion containing the first portion of the preferred feature are included in the composite image and all data prior to that is ignored. At step <highlight><bold>217</bold></highlight> the second portion of the preferred feature is located within an image portion, and composite image construction continues for an additional twenty image portions. Accordingly, the composite image includes the feature of interest and approximately 200 rows of pixels above and below the feature. The image within the buffer is cropped <highlight><bold>218</bold></highlight>&mdash;extraneous data is ignored or deleted&mdash;the composite image is provided <highlight><bold>219</bold></highlight> as the output image. Advantageously, the spatial relationship between the first portion of the preferred feature and the second portion of the preferred feature is known, which further facilitates composite image construction. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> The above exemplary embodiments refer to image resolution and providing data relating to an area of interest. It is preferable, however, that the swipe fingerprint scanner according to the invention be flexible and be able to output any of a number of image formats and sizes at locations relative to a known extracted feature. Alternatively, the extracted feature is also selectable from a number of features. Further alternatively, the fingerprint imager first provides data indicative of identified features and image size and resolution. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> The host system then provides to the imager a set of parameters relating to the data received&mdash;for example, 200 pixels above the core, 200 pixels below, 200 pixels to the right, and 200 pixels to the left&mdash;which allows the imager to determine the area of interest. This provides significant flexibility for the host system recognition process and for the imager&apos;s potential applications. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> According to another aspect of the instant invention, an authorized user, such as for instance a system administrator, configures the system (scanner/software) according to preferred priorities. In this way, the user specifies the desired identifiers. For example, the user selects the feature type of the feature of interest. Some non-limiting examples of feature types include: the fingerprint core; the top crease; six closest minutia, etc. Further, the user selects the location and/or orientation for displaying the feature of interest within the output image. In this way, the system provides a fingerprint composite that meets all of the requirements specified by the user. Optionally, the user provides the image evaluation criteria. For example, the user specifies that the first 30 pixel columns and rows immediately adjacent the feature of interest must be 100% populated, the next 30 rows and columns must be at least 80% populated, the next 30 rows and columns must be at least 50% populated, etc. If it is determined that the image evaluation criteria is not satisfied, then the image is rejected and a new image is acquired. Preferably, the user specified parameters are provided to the system via the data input/output port <highlight><bold>5</bold></highlight> and are retrievably stored within the memory buffer <highlight><bold>3</bold></highlight>. Optionally, the preferences are retrievably stored within a not illustrated non-volatile memory of the swipe scanner <highlight><bold>1</bold></highlight>. The non-volatile memory also optionally stores imager software for execution by the processor <highlight><bold>4</bold></highlight>. Further optionally, the preferences are stored in a not illustrated volatile memory in communication with the processor <highlight><bold>4</bold></highlight>. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> Preferably, the above-described processing is performed within the imager, or using imager software, such that the processing required by the correlation software is reduced. Advantageously, the output image provided by the system is universal in nature, for example, each application can specify the size and/or other attributes of the output image. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> The above examples refer to fingerprint imaging but are equally applicable to other contact based biometric imaging including palm scanning and skin imaging in general. In particular, adoption of the instant invention for use with different biometric imaging devices facilitates processing of biometric information captured. Referring now to <cross-reference target="DRAWINGS">FIG. 14</cross-reference>, shown is a method of imaging a biological information source according to the instant invention, using a contact imaging device of the type disclosed by Borza in U.S. Pat. No. 5,778,089. At step <highlight><bold>220</bold></highlight> a user places a fingertip on a platen of the contact imaging device, and at step <highlight><bold>221</bold></highlight> an image of the entire fingertip is acquired while the fingertip is held approximately stationary. At step <highlight><bold>222</bold></highlight> the feature of interest is located and at step <highlight><bold>223</bold></highlight> a selected area is defined about the feature of interest to define a fingerprint image having a resolution according to design requirements. The selected area is provided as the output image from the contact imaging device. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> Numerous other embodiments may be envisaged without departing from the spirit and scope of the invention. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of imaging a biometric information source comprising the steps of: 
<claim-text>sensing a biometric information source to provide biometric image data; </claim-text>
<claim-text>analyzing the biometric image data to determine a location of at least a repeatably identifiable feature of the sensed biometric information within the biometric image data; and </claim-text>
<claim-text>providing an image of a known size less than the size of the biometric image data, the provided image sensed at contiguous locations of the biometric information source near the determined location of the at least a repeatably identifiable feature. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the biometric information source is a fingerprint and the at least a repeatably identifiable feature is a core of the fingerprint. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the imager is a swipe contact imager. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, including a step of constructing a composite image from a plurality of overlapping image portions sensed by the swipe contact imager, wherein the composite image comprises the biometric image data including the at least a repeatably identifiable feature. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein the step of constructing a composite image and the step of analyzing the biometric image data to determine the location of the at least a repeatably identifiable feature are performed in parallel during a same overlapping period of time. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the biometric information source is a fingerprint and the biometric image data relates to a ridge-and-trough pattern of the fingerprint defining the at least a repeatably identifiable feature. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein the at least a repeatably identifiable feature is a type of feature selected from a group including: a core; a crease; a delta; and, an area of high minutia point density. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, including a step prior to the step of analyzing the biometric image data of receiving data indicative of the type of feature from a host processor. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein the host processor receives identification information relating to a known individual and wherein the data indicative of the type of feature is associated with template data relating to the known individual. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the step of providing an image of a known size less than the size of the biometric image data comprises a step of cropping the image data, wherein cropping means one of i) deleting image data at image locations outside of a selected regular shaped area, and ii) virtually &ldquo;deleting&rdquo; image data at image locations outside of the selected regular shaped area by merely eliminating such data from a frame of consideration. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the step of providing an image of a known size less than the size of the biometric image data including the step of cropping comprises the steps of: 
<claim-text>selecting a regular shaped area having a known spatial relation to the location of the at least a repeatably identifiable feature; </claim-text>
<claim-text>cropping image data other than the image data within the regular shaped area; and, </claim-text>
<claim-text>providing the cropped image data within the regular shaped area as the image of a known size less than the size of the biometric image data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the selected regular shaped area includes a predetermined image area along a predetermined direction relative to the location of the at least a repeatably identifiable feature. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the selected regular shaped area includes a predetermined image area about a predetermined direction relative to the location of the at least a repeatably identifiable feature. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the step of providing an image of a known size less than the size of the biometric image data including the step of cropping comprises the steps of: 
<claim-text>selecting a regular shaped area having a known spatial relation to the location of the at least a repeatably identifiable feature; </claim-text>
<claim-text>cropping image data other than the image data within the regular shaped area; </claim-text>
<claim-text>analyzing the image data within the regular shaped area to determine portions of the regular shaped area for which image data was other than captured; </claim-text>
<claim-text>determining a value relating to the determined portions; </claim-text>
<claim-text>comparing the determined value to a threshold value; and </claim-text>
<claim-text>when the determined value is i) within the threshold value, providing the image data within the regular shaped area as the image of a known size less than the size of the biometric image data and ii) outside the threshold value, requesting additional data relating to sensed biometric information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the step of providing an image of a known size less than the size of the biometric image data including the step of cropping comprises the steps of: 
<claim-text>selecting a regular shaped area having a known spatial relation to the location of the at least a repeatably identifiable feature; </claim-text>
<claim-text>cropping image data other than the image data within the regular shaped area; </claim-text>
<claim-text>scaling the image data within the regular shaped area; and </claim-text>
<claim-text>providing the scaled image data within the regular shaped area as the image of a known size less than the size of the biometric image data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A method of imaging a biological surface comprising the steps of: 
<claim-text>sensing a plurality of images of a same biological surface; </claim-text>
<claim-text>aligning the sensed images one relative to another to form a composite image of the biological surface; </claim-text>
<claim-text>analyzing at least one of the composite image and the plurality of images to determine a location of a repeatably identifiable feature; and, </claim-text>
<claim-text>providing a known amount of image data less than all of the composite image data at locations relative to the location of the repeatably identifiable feature as the composite image data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein the biological surface is a fingertip having a fingerprint and wherein a swipe contact imager is used to sense the plurality of images. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, wherein image data relates to a ridge-and-trough pattern of the fingerprint and having the repeatably identifiable feature therein. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the repeatably identifiable feature is selected from a group comprising: a core; a crease; a delta; and, an area of high minutia point density. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, wherein the step of providing a known amount of image data comprises the step of: 
<claim-text>selecting an image area about the location of the repeatably identifiable feature, the selected area including the known amount of image data at locations relative to the location of the repeatably identifiable feature; </claim-text>
<claim-text>cropping image data other than the known amount of image data within the selected area; and </claim-text>
<claim-text>providing the known amount of image data within the selected area as the as the composite image data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, wherein the step of aligning the sensed images one relative to another to form a composite image of the biological surface and the step of analyzing the at least one of the composite image and the plurality of images to determine the location of the repeatably identifiable feature are performed substantially in parallel during a same overlapping period of time. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, comprising the steps of: 
<claim-text>in dependence upon determining the location of the repeatably identifiable feature during the same overlapping period of time, selecting an image area about the repeatably identifiable feature, the selected area including the known amount of image data at locations relative to the location of the repeatably identifiable feature; </claim-text>
<claim-text>cropping image data other than the image data within the selected area; and </claim-text>
<claim-text>continuing to align the sensed images one relative to another to form a composite image of the selected area of the biological surface. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, wherein the step of analyzing the at least one of the composite image and the plurality of images to determine the location of the repeatably identifiable feature is performed prior to the step of aligning, the method further comprising the step of cropping the image prior to aligning. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A swipe fingerprint scanner comprising: 
<claim-text>a sensor for sensing a plurality of images of a same biological surface; </claim-text>
<claim-text>a memory in communication with the sensor, for retrievably storing each image of the plurality of images; </claim-text>
<claim-text>a processor in communication with the sensor and with the memory, the processor programmed for aligning the sensed images one relative to another to form a composite image of the biological surface, for analyzing the composite image to determine at least a location of a repeatably identifiable feature and, for providing a known amount of image data at locations relative to the determined location of the repeatably identifiable feature as output image data; and </claim-text>
<claim-text>a data input/output port in communication with the processor, for receiving the output image data therefrom, and for providing the output image data to a processor external to the swipe fingerprint scanner. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A swipe fingerprint scanner according to <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference>, wherein the sensor comprises: 
<claim-text>a first sensing pad, having a specific capacitive detective area, for sensing variation in a biological surface; and </claim-text>
<claim-text>a second sensing pad for detecting motion of the sensed variation. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. A swipe fingerprint scanner according to <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein the first sensing pad is disposed adjacent to the second sensing pad in a spaced apart and substantially parallel alignment. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. A swipe fingerprint scanner according to <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein the first sensing pad and the second sensing pad comprise a multi-directional swipe fingerprint scanner. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. A swipe fingerprint scanner according to <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein the first sensing pad and the second sensing pad is a unified sensing pad.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002718A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002718A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002718A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002718A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002718A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002718A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002718A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002718A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002718A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030002718A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030002718A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030002718A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030002718A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030002718A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030002718A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030002718A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030002718A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
