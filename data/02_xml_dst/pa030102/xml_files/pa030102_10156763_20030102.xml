<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004645A1-20030102-M00001.NB SYSTEM "US20030004645A1-20030102-M00001.NB" NDATA NB>
<!ENTITY US20030004645A1-20030102-M00001.TIF SYSTEM "US20030004645A1-20030102-M00001.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-M00002.NB SYSTEM "US20030004645A1-20030102-M00002.NB" NDATA NB>
<!ENTITY US20030004645A1-20030102-M00002.TIF SYSTEM "US20030004645A1-20030102-M00002.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00000.TIF SYSTEM "US20030004645A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00001.TIF SYSTEM "US20030004645A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00002.TIF SYSTEM "US20030004645A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00003.TIF SYSTEM "US20030004645A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00004.TIF SYSTEM "US20030004645A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00005.TIF SYSTEM "US20030004645A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00006.TIF SYSTEM "US20030004645A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00007.TIF SYSTEM "US20030004645A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00008.TIF SYSTEM "US20030004645A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00009.TIF SYSTEM "US20030004645A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00010.TIF SYSTEM "US20030004645A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00011.TIF SYSTEM "US20030004645A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00012.TIF SYSTEM "US20030004645A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00013.TIF SYSTEM "US20030004645A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00014.TIF SYSTEM "US20030004645A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00015.TIF SYSTEM "US20030004645A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00016.TIF SYSTEM "US20030004645A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030004645A1-20030102-D00017.TIF SYSTEM "US20030004645A1-20030102-D00017.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004645</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10156763</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020529</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2001-161286</doc-number>
</priority-application-number>
<filing-date>20010529</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F019/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>702</class>
<subclass>001000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Image measurement and display device, image measurement and display system, construction management method, and construction status monitor system</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Nobuo</given-name>
<family-name>Kochi</family-name>
</name>
<residence>
<residence-non-us>
<city>Tokyo</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<assignee>
<organization-name>TOPCON CORPORATION</organization-name>
<assignee-type>03</assignee-type>
</assignee>
<correspondence-address>
<name-1>FOLEY AND LARDNER</name-1>
<name-2>SUITE 500</name-2>
<address>
<address-1>3000 K STREET NW</address-1>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20007</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A device comprises: a shape measuring section <highlight><bold>350 </bold></highlight>for measuring shape data from a pair of stereovision images of an object taken with an image taking section <highlight><bold>220</bold></highlight>; a memory section <highlight><bold>340 </bold></highlight>for storing target data related to the images of the object; an image display section <highlight><bold>330 </bold></highlight>for superposing the paired stereovision images of the object and the stereovision target data image based on the target data and for displaying the images; and a comparison display processing section <highlight><bold>360 </bold></highlight>for comparing the shape data of the object measured by the shape measuring section <highlight><bold>350</bold></highlight>, with the target data and reflecting the results of the comparison on the superposed display on the image display section <highlight><bold>330. </bold></highlight></paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The invention relates to an image measurement and display device, an image measurement and display system, and a construction management method suitable when used in constructing large scale structures such as dams and power stations and in development of residential sites, and particularly to those that enables a person in charge of carrying out the construction or manufacturing to easily find out if the construction or manufacturing is carried exactly as shown on design drawings. The invention also relates to an image measurement and display device, an image measurement and display system, and a construction management method that enable to find out at a construction management office the status of the construction or manufacturing of objects being constructed or manufactured and, particularly to those that enables detailed measurement of objects being constructed or manufactured and enables accurate comparison with design drawings. The invention further relates to a construction status monitor system helpful for accurately finding out the daily progress status of objects being constructed or manufactured and for re-planning the construction or manufacturing so that the construction or manufacturing goes on exactly as planned. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Conventionally, in the civil engineering, ropes and landmarks, so called finishing stake, for indicating designed shapes such as positions and directions, to construct truly to design drawings are placed by an operator and the operator executes construction work according to such finishing stakes. In recent years, an advanced method is developed in which work machines such as power shovels and bulldozers are equipped with a sensor and the operator operates the machine while monitoring or automatically controlling the horizontal position with laser (Refer to, for example JP-A-11-236716 proposed by the applicant). In another proposal, it is intended to take images of the construction status with a remote control monitor camera and to carry out the construction while superposing the taken image on design drawings. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> However, with the above methods of controlling the construction status, the construction is difficult for the operator to carry out actually exactly as indicated on the design drawings. And the construction takes much time, and requires many corrections, as follows: </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> (1) The method with finishing stakes can make only rough comparison with the design drawings. Moreover, the ground is steep in some places and it is difficult to place the finishing stakes. Because the finishing stakes must be placed by the operator, the placement work often takes much time in particular on a natural ground. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> (2) Since the method using laser is intended to control horizontal positions, the work on a sloping ground or face of slope requires auxiliary equipment. The problem of difficulty in placing the auxiliary equipment on the steep natural ground remains the same with the method using finishing stakes. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> (3) The method of taking the image of the construction status with a remote control camera and comparing the taken image with the design drawings has a problem that the superposition of the design drawing, namely CG (computer graphics) image, on the real image is difficult, and that the design drawing is absorbed in the real image and is not easy to seen. Still another problem for the operator is that the visual point of the image taken with the camera is different from the visual point of the operator who is actually operating the work machine, requiring much skill to operate the work machine while holding down the difference between the taken image and the design drawing. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> On the other hand, the person who manages the construction has problems of difficulty in finding out daily status of progress of the construction and difficulty in quickly planning future man-hours and construction based on current status. Since construction and earth moving work of a large scale involves a large amount of investment in plant-and-equipment, strict observation of delivery deadline and construction period is necessary for the customer and it is very important to manage the construction to meet the conditions of contracts of the large scale structures. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The first object of the invention is to provide an image measurement and display device capable of measuring in detail objects to be constructed or manufactured and comparing accurately the measurements with design drawings. The second object is to provide such an image measurement and display device that enables a person in charge of construction or manufacturing to find out easily whether or not the construction or manufacturing is carried out in compliance with design drawings and enables the person to carry out the construction or manufacturing exactly as specified on the design drawings in a simple manner. The third object is to provide a construction status monitor system useful for finding out accurately the daily status of progress in construction or manufacturing and for organizing the construction or manufacturing flexibly to meet construction plans. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The first invention related to the image measurement and display device for accomplishing the first object, comprises, as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> or <highlight><bold>21</bold></highlight>: a shape measuring section <highlight><bold>350</bold></highlight> for measuring shape data of an object from a pair of stereovision images of the object taken with an image taking section <highlight><bold>220</bold></highlight>; a memory section <highlight><bold>340</bold></highlight> for storing target data related to the image of the object; an image display section <highlight><bold>330</bold></highlight>, <highlight><bold>110</bold></highlight><highlight><italic>a </italic></highlight>for displaying in superposition the paired stereovision images of the object and the stereovision target data images of the object based on the target data; and a comparison display processing section <highlight><bold>360</bold></highlight>, <highlight><bold>120</bold></highlight><highlight><italic>a </italic></highlight>for comparing the shape data of the object with the target data and for reflecting the results of the comparison on the superposed display on the image display section <highlight><bold>330</bold></highlight>, <highlight><bold>110</bold></highlight><highlight><italic>a. </italic></highlight></paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In such an arrangement, the status of the construction on the construction site is remotely measured by measuring in the shape measuring section <highlight><bold>350</bold></highlight> the shape data of the object from the paired stereovision images of the object taken with the image taking section <highlight><bold>220</bold></highlight>. In the memory section <highlight><bold>340</bold></highlight> are stored target data related to the object image, which target data are to be the completion target of the construction site. The image display section <highlight><bold>330</bold></highlight>, <highlight><bold>110</bold></highlight><highlight><italic>a </italic></highlight>is placed, for example, in the vicinity of the construction management person distant from the work machine or in the operation cabin of the work machine to display the paired stereovision images of the object superposed over the stereovision target data images of the object based on the target data. The comparison display processing section <highlight><bold>360</bold></highlight>, <highlight><bold>120</bold></highlight><highlight><italic>a </italic></highlight>compares the shape data of the object with the target data, and reflects the comparison results on the superposed display on the image display section <highlight><bold>330</bold></highlight>, <highlight><bold>110</bold></highlight><highlight><italic>a</italic></highlight>, so that the construction operator or the construction management person can easily find out the relationship between the current status on the construction site and the target data by means of the superposed display of the comparison results. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The second invention related to the image measurement and display device for accomplishing the first object, comprises, as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> or <highlight><bold>21</bold></highlight>: a shape measuring section <highlight><bold>350</bold></highlight> for measuring shape data of an object from a pair of stereovision images of an object taken with an image taking section <highlight><bold>220</bold></highlight>; an imaging position measuring section, corresponding to an automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight> and a camera position taking section <highlight><bold>250</bold></highlight>, for measuring the position where the image taking section <highlight><bold>220</bold></highlight> takes images of the object; a memory section <highlight><bold>340</bold></highlight> for storing target data related to the image of the object; image display sections <highlight><bold>330</bold></highlight>, <highlight><bold>110</bold></highlight><highlight><italic>a </italic></highlight>for displaying in superposition, on the basis of the imaging position measured with the imaging position measuring section (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>), the images of the object and the target data images based on the target data; and a comparison display processing section <highlight><bold>360</bold></highlight>, <highlight><bold>120</bold></highlight><highlight><italic>a </italic></highlight>for comparing, on the basis of the imaging position measured with the imaging position measuring sections (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>), the shape of the object with the shape corresponding to the target data, and for reflecting the comparison results on the superposed display on the image display section <highlight><bold>330</bold></highlight>, <highlight><bold>110</bold></highlight><highlight><italic>a. </italic></highlight></paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> In such an arrangement, the imaging position of the image taking section <highlight><bold>220</bold></highlight> is measured with the imaging position measuring sections (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>). Therefore, the information on the imaging position measured with the imaging position measuring sections (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>) may be used in mutual comparison and superposition of the object shape and the shape corresponding to the target data in the image display sections <highlight><bold>330</bold></highlight> and <highlight><bold>110</bold></highlight><highlight><italic>a </italic></highlight>and the comparison display processing section <highlight><bold>360</bold></highlight>, <highlight><bold>120</bold></highlight><highlight><italic>a</italic></highlight>, so that the image conversion processing required for the superposition is carried out smoothly. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In the first and second inventions, it is preferable that the comparison results obtained with the comparison display processing section <highlight><bold>360</bold></highlight>, <highlight><bold>120</bold></highlight><highlight><italic>a </italic></highlight>are reflected by the display on the image display section <highlight><bold>330</bold></highlight>, <highlight><bold>110</bold></highlight><highlight><italic>a </italic></highlight>so that the part where the shape of the object approximately agrees with the shape corresponding to the target data is displayed distinguishably, so that the status of the construction based on whether or not the target data are reached is easily found out. The first and second inventions are preferably constituted that, as the results of the comparison with the comparison display processing section <highlight><bold>360</bold></highlight>, <highlight><bold>120</bold></highlight><highlight><italic>a</italic></highlight>, the distance or interval to the object is associated with that to the target data, and then their comparative sized of the object and the target data are displayed distinguishably on the image display section <highlight><bold>330</bold></highlight>, <highlight><bold>110</bold></highlight><highlight><italic>a</italic></highlight>, so that whether or not the construction status has reached the target data is easily found out by using the comparative sizes of the object and the target data. In the first and second inventions, it is preferable to provide an intermediate target data setting means <highlight><bold>370</bold></highlight> for setting intermediate target data as the target data for the comparison display processing sections <highlight><bold>360</bold></highlight>, <highlight><bold>120</bold></highlight><highlight><italic>a </italic></highlight>and the image display sections <highlight><bold>330</bold></highlight>, <highlight><bold>110</bold></highlight><highlight><italic>a</italic></highlight>, in every stage of construction on the object and also preferable to constitute the comparison display processing section <highlight><bold>360</bold></highlight>, <highlight><bold>120</bold></highlight><highlight><italic>a </italic></highlight>so as to compare the object shape with the shape corresponding to the intermediate target data, so that intermediate target data exactly matching the daily status of construction are displayed in such a manner that can be understood by the person in charge of the construction and the person who manages the construction. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> The third invention related to the image measurement and display device for accomplishing the second object, comprises, as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>: a shape measuring section <highlight><bold>350</bold></highlight> for measuring the shape data of an object from a pair of stereovision images of the object taken with an image taking section <highlight><bold>220</bold></highlight>; a memory section <highlight><bold>340</bold></highlight> for storing target data related to the image of the object; an image observing section <highlight><bold>110</bold></highlight> for superposing the object related to the target data and the stereovision target data image of the object based on the target data and for displaying with the object remaining to be visible; and a comparative observation display processing section <highlight><bold>120</bold></highlight> for comparing the object shape measured by the shape measuring section <highlight><bold>350</bold></highlight>, with the shape corresponding to the target data and for reflecting the comparison results to be on the stereovision target data image display of the image observing section <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> With the above device, the construction status of the construction site is observed remotely by measuring with the shape measuring section <highlight><bold>350</bold></highlight> the shape data of the object from a pair of stereovision images of the object that are imaged with the image taking section <highlight><bold>220</bold></highlight>. In the memory section <highlight><bold>340</bold></highlight> are memorized target data related to the object image, and the target data that are to be the completion target of the construction site are stored. The image observing section <highlight><bold>110</bold></highlight> displays in superposition the stereovision target data images of the object based on the target data in the state of the object related to the target data being visible by the eye. The comparative observation display processing section <highlight><bold>120</bold></highlight> compares the object shape measured with the shape measuring section <highlight><bold>350</bold></highlight>, with the shape corresponding to the target data, so that the comparison results are reflected on the stereovision target data image displayed on the image observing section <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The fourth invention related to the image measurement and display device for accomplishing the second object, comprises, as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>: a shape measuring section <highlight><bold>350</bold></highlight> for measuring shape data of an object from a pair of stereovision images of the object taken with an image taking section <highlight><bold>220</bold></highlight>; an imaging position measuring section (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>) for measuring the imaging position of the image taking section; a memory section <highlight><bold>340</bold></highlight> for storing target data related to the images of the object; an image observing section <highlight><bold>110</bold></highlight> for superposing the object related to the target data, on the basis of the imaging position measured with the imaging position measuring sections (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>), the stereovision target data image of the object based on the target data and for displaying with the object remaining to be visible; and the comparative observation display processing section <highlight><bold>120</bold></highlight> for comparing, on the basis of the imaging position measured with the imaging position measuring position, the object shape measured by the shape measuring section <highlight><bold>350</bold></highlight>, with the shape corresponding to the target data, and for reflecting the result of the comparison on the stereovision target data image display of the image observing section <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In the above device, the imaging position of the image taking section <highlight><bold>220</bold></highlight> is measured with the imaging position measuring sections (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>). Therefore, the information on the imaging position measured with the imaging position measuring sections (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>) may be used in comparing and superposing the object shape with the shape corresponding to the target data by means of the image observing section <highlight><bold>110</bold></highlight> and the comparative observation display processing section <highlight><bold>120</bold></highlight>, so that image conversion processing required for superposing the stereovision target data image display over the real image of the object is carried out smoothly. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> In the third and fourth inventions, it is preferable that the image observing section <highlight><bold>110</bold></highlight> includes at least one of a head-up display and a head-mount display, so that the person in charge of the work can see the stereovision target data image while seeing the object by the naked eye without moving the line of sight. In the third and fourth inventions, it is preferable that the results of the comparison carried out with the image processing section <highlight><bold>120</bold></highlight> for forming the image to carry out comparative observation and display are reflected on the display of the image observing section <highlight><bold>110</bold></highlight>, so that positions may be discriminated where the object shape is found to match approximately the shape corresponding to the target data, and that the status of the construction is easily found out on the basis of whether or not the target data are reached. In the third and fourth inventions, it is preferable that the comparative result in the image processing section <highlight><bold>120</bold></highlight> forming images for performing comparative observation display is the distance or interval to the object and the target data and that the comparative sizes of the object and the target data are displayed on the image observing section <highlight><bold>110</bold></highlight> so that whether or not the construction status has reached the target data is easily found out by using the relative sizes of the object and the target data. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The fifth invention related to an image measurement and display system for accomplishing the first and second objects, comprises, as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> comprises: an image taking section <highlight><bold>220</bold></highlight> for taking a pair of stereovision images of an object; an image observing sections <highlight><bold>110</bold></highlight> for displaying the images taken with the image taking section <highlight><bold>220</bold></highlight>; a memory section <highlight><bold>340</bold></highlight> for storing target data related to the images of the object; and a construction status measuring device <highlight><bold>300</bold></highlight> including an image calculation processing section <highlight><bold>320</bold></highlight> for processing images of the object taken with the image taking section, to exchange data among the image taking section <highlight><bold>220</bold></highlight>, the image observing sections <highlight><bold>110</bold></highlight>, and the construction status measuring device <highlight><bold>300</bold></highlight>. The construction status measuring device <highlight><bold>300</bold></highlight> further comprises a shape measuring section <highlight><bold>350</bold></highlight> for measuring the shape of the object using the paired stereovision images taken with the image taking section <highlight><bold>220</bold></highlight> and a comparison display processing section <highlight><bold>360</bold></highlight> for comparing the object shape measured by the shape measuring section <highlight><bold>350</bold></highlight>, with the shape corresponding to the target data. The image observing sections <highlight><bold>110</bold></highlight> is constituted to display the object image obtained with the image taking section <highlight><bold>220</bold></highlight> superposed over the object data image formed with the target data coming as sent from the construction status measuring device <highlight><bold>300</bold></highlight>. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> To exchange data among the monitoring unit <highlight><bold>200</bold></highlight> including the image taking section <highlight><bold>220</bold></highlight>, a construction display device <highlight><bold>100</bold></highlight> including the image observing section <highlight><bold>110</bold></highlight>, and the construction status measuring device <highlight><bold>300</bold></highlight>, it is preferable to use one of the existing communication infrastructures: wireless, optical, the Internet, and cable communications. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> The sixth invention related to the construction management method for accomplishing the second object, comprises, as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the steps of: determining the three-dimensional position of a construction display device <highlight><bold>100</bold></highlight> with an image taking position measuring sections (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>) (R<highlight><bold>10</bold></highlight>); acquiring distance images in real time from multiple stereovision images in two dimensions (R<highlight><bold>10</bold></highlight>); superposition, on the basis of the three-dimensional positions, the target data and the stereovision images of the object being processed and displaying the superposed image on the construction display device <highlight><bold>100</bold></highlight>(S<highlight><bold>40</bold></highlight>, S<highlight><bold>60</bold></highlight>); and causing a work machine to execute work according to the information on deviation of the stereovision images, related to the object being processed, from the target data (R<highlight><bold>40</bold></highlight>, R<highlight><bold>50</bold></highlight>). </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The seventh invention related to the construction management method for accomplishing the first object, comprises, as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the steps of: determining the three-dimensional position of a construction display device <highlight><bold>100</bold></highlight> with an imaging position measuring sections (<highlight><bold>250</bold></highlight>, <highlight><bold>252</bold></highlight>) (R<highlight><bold>10</bold></highlight>); acquiring distance images from multiple stereovision images in real time in two dimensions (R<highlight><bold>10</bold></highlight>); measuring the multiple stereovision images (S<highlight><bold>50</bold></highlight>); analyzing construction progress status from the current status of an object being processed and target data (S<highlight><bold>70</bold></highlight>); and updating from time to time the construction plan for realizing the target data according to the results of analyzing the construction progress status (S<highlight><bold>85</bold></highlight>). </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> The eighth invention related to the work monitoring system for accomplishing the third object, comprises, as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>: the image measurement and display device (the construction display device <highlight><bold>100</bold></highlight>, the monitoring unit <highlight><bold>200</bold></highlight>, and the construction status measuring device <highlight><bold>300</bold></highlight>) as set forth in any one of claims 1 to 5; and a construction plan drafting and correcting means <highlight><bold>380</bold></highlight> for calculating from the comparison results obtained with the comparison display processing section, the work-related data for processing or treating an object to meet the target data. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> This application is based on Japanese patent applications, No. 2001-161286 filed in Japan on May 29, 2001, which are entirely incorporated herein by reference. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The present invention will become more fully understood from the detailed description given hereinbelow. However, the detailed description and the specific embodiment are illustrated of desired embodiments of the present invention and are described only for the purpose of explanation. Various changes and modifications will be apparent to those ordinary skilled in the art on the basis of the detailed description. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The applicant has no intention to give to public any disclosed embodiment. Among the disclosed changes and modifications, those which may not literally fall within the scope of the patent claims constitute, therefore, a part of the present invention in the sense of doctrine of equivalents.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is an overall block diagram of a construction monitoring system provided with a construction display device and a construction status measuring device according to the invention. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a bird&apos;s-eye view of the construction display devices used on the construction site. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram, showing the first embodiment of use of the construction display device on a construction site. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a process flow chart of an embodiment of the invention. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a flow chart for explaining the details of stereovision image measurement. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is an explanatory drawing of a normalizing correlation process. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a drawing for explaining the principle of stereovision image measurement. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a drawing for explaining the real time construction flow on the construction site. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows an example of synthesized image before construction. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> shows the state in which a face of slope to be target data has appeared on a sloped surface of a natural ground after starting the construction. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> shows the state in which most of a pyramid shape to be target data has appeared on a raised piece of ground, an object of a construction work, as the construction has progressed to some extent. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is for explaining a measurement comparison process flow. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is for explaining a judgment display process flow. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is for explaining comparison of target data of a changed area from a distance image of a construction area. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is a process flow chart when the invention is applied to excavation for investigating an archaeological site. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a process flow chart when the invention is applied to disaster prevention. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is for explaining a head-up display (HUD) or head-mount display (HMD) for use in real image/virtual image display section and video/virtual image display section. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a block diagram, showing the second embodiment of use of the construction display device on a construction site. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> shows an example of relationship between positions of a monitoring unit and a work machine in the second embodiment of use. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is a block diagram, showing the third embodiment of use of the construction display device on a construction site. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> is a block diagram of a modified embodiment of the construction monitoring system having the construction display device and the construction status measurement device shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, showing the fourth embodiment of use of the construction display device on the construction site. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> Embodiments of the invention will be hereinafter described in reference to the appended drawings. The same or counterpart components in the drawings are provided with the same or similar reference numerals or symbols to avoid redundancy in explanation. <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is an overall block diagram of a construction monitoring system according to the invention which is provided with a construction display device and a construction status measuring device. The construction display device <highlight><bold>100</bold></highlight> is installed in the cockpit of the work machine used on the construction site, or attached to the helmet of the construction site supervisor or the operator, for easy comparison of the construction site situation with the construction target based on the design drawings. The monitoring unit <highlight><bold>200</bold></highlight> is for taking images of the construction site in the current state and is placed in a position where the work machine operator can monitor the state of construction executed by the operator or with the work machine using the construction display device <highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> The construction status measuring device <highlight><bold>300</bold></highlight> is installed, for example, in a construction management office and has three-dimensional data (hereinafter referred to as target data), stored in advance, of the design drawings or of the final expected results. And the device reads the stereovision images of the site status taken from the monitoring unit <highlight><bold>200</bold></highlight> placed on the construction site, performs detailed calculation process, and compares the results with the target data to plan and estimate the work. The construction management office is located in a building standing either distant from or near the construction site. The construction site refers to any object on which earth-moving work, such as work on a face of slope, lot reclamation-construction, excavation for investigating archaeological sites, disaster preventive construction, etc. is executed. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The construction display device <highlight><bold>100</bold></highlight> comprises a real image/virtual image observing section <highlight><bold>110</bold></highlight> as an image observing section, an image processing section <highlight><bold>120</bold></highlight> as a comparative observation display processing section for performing image visual point conversion calculation, an attitude sensor <highlight><bold>130</bold></highlight>, a data exchanging section <highlight><bold>140</bold></highlight>, and a construction position taking section <highlight><bold>150</bold></highlight>. The real image/virtual image observing section <highlight><bold>110</bold></highlight> preferably consists of an HUD (head-up display) or HMD (head-mount display) of the optical see-through image type. With the optical see-through image type, since a CG image as a target data image is synthesized in the field of vision of the construction operator who is viewing the actual construction site, namely since the image is not virtual, the type is suitable for the operator to carry out the construction in real time without feeling inconsistency. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> The image processing section <highlight><bold>120</bold></highlight> uses the attitude data of the construction display device <highlight><bold>100</bold></highlight> measured with the attitude sensor <highlight><bold>130</bold></highlight> and the three-dimensional position data found with the construction position taking section <highlight><bold>150</bold></highlight> to convert the CG image as the target data image sent from the construction status measuring device <highlight><bold>300</bold></highlight> into the image as viewed from the visual point of the operator. The image processing section <highlight><bold>120</bold></highlight> aligns the position of the CG image as the target data image, as seen from the visual point of the operator who is processing the object with the work machine and sends the image to the real image/virtual image observing section <highlight><bold>110</bold></highlight>. As a result, the real image/virtual image observing section <highlight><bold>110</bold></highlight> displays the CG image, the target data image, as superposed over the real image of the object within the field of vision of the operator. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> The attitude sensor <highlight><bold>130</bold></highlight> measures the attitude of the construction display device <highlight><bold>100</bold></highlight>, for example angles of three axes, in vertical, lateral, and depth directions. The data exchanging section <highlight><bold>140</bold></highlight> receives images from the monitoring unit <highlight><bold>200</bold></highlight>, design images and data from the construction status measuring device <highlight><bold>300</bold></highlight>, and three-dimensional coordinates from an automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight> or GPS. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The construction position taking section <highlight><bold>150</bold></highlight> is an arrangement for picking up three-dimensional position data of the construction display device <highlight><bold>100</bold></highlight>, such as the GPS (global positioning system), mobile terminal position search service in mobile communication, and a combination of an automatic tracing type of surveying instrument and tracing targets. The automatic tracing type of surveying instrument is proposed and disclosed by the applicant, for example in JP-A-6-307853. The tracing targets may be prisms and reflection sheets. Furthermore, the attitude sensor <highlight><bold>130</bold></highlight> may be combined with an accelerometer and a gyro to detect direction and distance of movement, to detect movement distance relative to a reference position, and to find three-dimensional position as a supplement. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> The monitoring unit <highlight><bold>200</bold></highlight> includes a construction stereo camera <highlight><bold>210</bold></highlight> for constantly monitoring the construction status, a measurement stereo camera <highlight><bold>220</bold></highlight> serving as an image taking section, a motion image processing section <highlight><bold>230</bold></highlight>, a data exchanging section <highlight><bold>240</bold></highlight>, and a camera position taking section <highlight><bold>250</bold></highlight> serving as an image taking position measuring section. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> In the case the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight> is used, a reflection prism or a reflection sheet serving as a camera position taking section <highlight><bold>250</bold></highlight> is attached to the monitoring unit <highlight><bold>200</bold></highlight>. The position data of the monitoring unit <highlight><bold>200</bold></highlight> found with the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight> are received with the data exchanging section <highlight><bold>240</bold></highlight>. The position data received are synchronized with the images taken with the stereo camera and sent from the data exchanging section <highlight><bold>240</bold></highlight> to the data exchanging section <highlight><bold>310</bold></highlight> of the construction status measuring device <highlight><bold>300</bold></highlight>. In this way, the relationship of positions of the monitoring unit <highlight><bold>200</bold></highlight> and the construction display device <highlight><bold>100</bold></highlight> is known and the positions of the target data image and the construction image can be aligned easily. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> The construction stereo camera <highlight><bold>210</bold></highlight> is used to measure the distance in two dimensions to the object while the object is being processed in real time and to compare the result with the target data during the construction. The measurement-purpose stereo camera <highlight><bold>220</bold></highlight> measures in detail the results of construction and the state of the object before and after the construction, and uses the results for various purposes such as estimation and planning. In view of measurement accuracy, the stereo camera <highlight><bold>220</bold></highlight> for measurement is higher in accuracy than the construction stereo camera <highlight><bold>210</bold></highlight>. Also in view of accuracy, the baseline of the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight> (the distance between cameras) must be long, and the construction stereo camera <highlight><bold>210</bold></highlight> may be of such an accuracy that suffices for the purpose of monitoring the construction in real time, executing construction, and finding the distance to the object. Therefore, the baseline of the construction stereo cameras <highlight><bold>210</bold></highlight> need not be longer than that of the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight>. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Depending on the object requiring no high accuracy, the construction stereo camera <highlight><bold>210</bold></highlight> and the measurement stereo camera <highlight><bold>220</bold></highlight> may of the same type. However, since the same cameras are used differently for the construction and measurement, the stereovision image processing is carried out also differently. The measurement stereo cameras <highlight><bold>220</bold></highlight> and the construction stereo cameras <highlight><bold>210</bold></highlight> may be prepared respectively in plural numbers, two or more, to realize multiple image stereovision. Use of two or more cameras can eliminate the problem of occlusion (sight blockage) and enhance reliability. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> The construction status measuring device <highlight><bold>300</bold></highlight> includes: a data exchanging section <highlight><bold>310</bold></highlight>, an image calculation processing section <highlight><bold>320</bold></highlight> serving as an image processing section, a video/virtual image display section <highlight><bold>330</bold></highlight> serving as an image display section, a three-dimensional target data memory section <highlight><bold>340</bold></highlight> serving as a memory section, a stereovision image shape measuring section <highlight><bold>350</bold></highlight> serving as a shape measuring section, a target data image comparison display processing section <highlight><bold>360</bold></highlight> serving as a comparison display processing section, an intermediate target data setting means <highlight><bold>370</bold></highlight>, and a construction plan drafting and correcting means <highlight><bold>380</bold></highlight>. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> The data exchanging section <highlight><bold>310</bold></highlight> may be any device, such as a PHS (personal handy-phone system), mobile communication terminal, fixed communication terminal, etc. that can be connected to the Internet and exchange image data interactively with the construction display device <highlight><bold>100</bold></highlight>. The image data may include those of motion images in addition to those of static images. The image calculation processing section <highlight><bold>320</bold></highlight> is constituted with a computer such as a personal computer to cause the stereovision image shape measuring section <highlight><bold>350</bold></highlight> to measure in detail in three dimensions the stereovision images sent from the monitoring unit <highlight><bold>200</bold></highlight> on the construction site. The image calculation processing section <highlight><bold>320</bold></highlight> further processes and converts stereovision images coming as sent from the monitoring unit <highlight><bold>200</bold></highlight> on the construction site and the target data images manufactured at the three-dimensional target data storage section <highlight><bold>340</bold></highlight>, so that those images may be compared with each other on the same scale in the same coordinate system. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> The video/virtual image display section <highlight><bold>330</bold></highlight> is of the video see-though type which synthesizes in three dimensions, superposes together, and displays the stereovision images measured on the actual construction site and the CG images as the target data images. The video see-though type is a type that superposes together the actual image taken with the measurement-purpose stereo camera <highlight><bold>220</bold></highlight> and the CG image representing the computer-prepared target data and shows the resultant image to an observing person. The video/virtual image display section <highlight><bold>330</bold></highlight> may be any display that can provide 3D images, such as a 3D monitor, 3D projector, HUD, HMD, hologram, etc. The stereovision image shape measuring section <highlight><bold>350</bold></highlight> measures in three dimensions the stereovision images coming as sent from the data exchanging section <highlight><bold>310</bold></highlight>. Details of the three-dimensional measurement are described for example in reference to <cross-reference target="DRAWINGS">FIG. 7</cross-reference> concerning the stereovision image measurement. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> The target data comparison display processing section <highlight><bold>360</bold></highlight> compares the object shape data with the target data through comparative calculation of the stereovision image taken with the measurement-purpose stereo camera <highlight><bold>220</bold></highlight> on the construction site and the CG image as the target data image prepared at the three-dimensional target data storage section <highlight><bold>340</bold></highlight>, and causes the result to be reflected on the superposed display on the video/virtual image display section <highlight><bold>330</bold></highlight>. To reflect the comparison result, a measurement comparison process flow shown for example in <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is used. The intermediate target data setting means <highlight><bold>370</bold></highlight> sets an intermediate target data in every construction step of the object. The intermediate target data may be set for example either to values conforming to the daily work target or to the value of every intermediate target for construction process management. With reference to the three-dimensional target data stored in the three-dimensional target data memory the construction plan drafting and correcting means <highlight><bold>380</bold></highlight> calculates data related to the processing or treatment on the object to the target data according to the comparison result of the target data image comparison display processing section <highlight><bold>360</bold></highlight>. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram, showing the first embodiment of use of the construction display device on the construction site. <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a bird&apos;s-eye view of the construction display device used on a construction site. The construction display device <highlight><bold>100</bold></highlight> is attached either to a work machine such as a power shovel executing construction or to a work machine operator. The position of the construction display device <highlight><bold>100</bold></highlight> is constantly measured in three dimensions with the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight> to align the positions of the image of the construction executing visual point, the design image, and the image of the monitoring unit <highlight><bold>200</bold></highlight>. In areas where video waves can be received from orbiting satellites, the GPS may be used in place of the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight> as the construction position taking section <highlight><bold>150</bold></highlight>. Unless the construction area is vast, using the automatic tracing type of surveying instrument results in higher accuracy and reliability of the position data obtained. Choice of the automatic tracing type of surveying instrument or the GPS may be decided appropriately depending on the conditions of construction. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Next, the process flow of an embodiment of the invention will be described in reference to the flow chart. <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a process flow chart of an embodiment of the invention. Here, the construction site is assumed to be laid out as shown in <cross-reference target="DRAWINGS">FIGS. 2 and 3</cross-reference>. As an example, it is assumed that automatic tracing type of surveying instruments are used as the construction position taking section <highlight><bold>150</bold></highlight> and the camera position taking section <highlight><bold>250</bold></highlight>. By the way, in the case the GPS is used as the construction position taking section <highlight><bold>150</bold></highlight> and the camera position taking section <highlight><bold>250</bold></highlight>, positions of the construction display device <highlight><bold>100</bold></highlight> and the monitoring unit <highlight><bold>200</bold></highlight> are synchronized with an image and GPS data are sent. Here, the GPS data are the data representing the latitude, longitude, and elevation of the place where electric waves are received from orbiting GPS satellites. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> First, in the construction management office, three-dimensional target data prepared in advance for the object on which construction is complete are stored in the three-dimensional target data storage section <highlight><bold>340</bold></highlight> of the construction status measuring device <highlight><bold>300</bold></highlight> (S<highlight><bold>10</bold></highlight>). On the other hand, on the construction site, the monitoring unit <highlight><bold>200</bold></highlight>, the construction display device <highlight><bold>100</bold></highlight>, and a reference point placed on the object are measured with the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight> (R<highlight><bold>10</bold></highlight>). And the construction operator takes image of the status of the object before construction with the measurement-purpose stereo camera <highlight><bold>220</bold></highlight>. And the construction display device <highlight><bold>100</bold></highlight> sends out the position information measured with the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight> through the data exchanging section <highlight><bold>140</bold></highlight> (R<highlight><bold>20</bold></highlight>). The monitoring unit <highlight><bold>200</bold></highlight> sends out the image data before the work is applied to the object through the data exchanging section <highlight><bold>240</bold></highlight> (R<highlight><bold>20</bold></highlight>). </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Then the construction status measuring device <highlight><bold>300</bold></highlight> side receives at the data exchanging section <highlight><bold>310</bold></highlight> the data sent from the construction display device <highlight><bold>100</bold></highlight> (S<highlight><bold>20</bold></highlight>). And the construction status measuring device <highlight><bold>300</bold></highlight> creates stereovision images of the construction site before the construction is executed (S<highlight><bold>30</bold></highlight>), where since a baseline is known in advance, the measurement-purpose stereo camera <highlight><bold>220</bold></highlight> can create, from the positional relationship with the baseline, stereovision images that can be viewed in three dimensions. Alternatively, even if the baseline is unknown, the stereovision images that can be viewed in three dimensions may be created by carrying out orientation process using reference position data. Here, the orientation process refers to a preparatory process for carrying out stereo-viewing in aerial photogrammetry, in which the position and tilt of the camera are determined. The reference points, six or more in number, suffices for the purpose. The stereovision images that can be viewed in three dimensions refer to the images, with vertical parallax removed, parallel to the object, and called rectified images in the aerial photogrammetry. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> Next, the construction status measuring device <highlight><bold>300</bold></highlight> aligns positions of and synthesizes the target data image and the site image (S<highlight><bold>40</bold></highlight>). Here, since the absolute coordinate system of the stereovision images becomes known from the reference point data taken with the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight>, superposition becomes possible by converting the coordinate system. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Next, the construction status measuring device <highlight><bold>300</bold></highlight> carries out stereovision image measurement and analysis (S<highlight><bold>50</bold></highlight>). Details of the stereovision measurements will be described later in reference to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. Next, the construction status measuring device <highlight><bold>300</bold></highlight> carries out three-dimensional display on the video/virtual image display section <highlight><bold>330</bold></highlight> (S<highlight><bold>60</bold></highlight>). At this time, the stereovision images of the target data and the stereovision images of the measurement-purpose stereo camera <highlight><bold>220</bold></highlight> are converted to the case of: the baseline length B on the intended visual point side (distance between the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight>), the imaging distance H, and the focal length f of the lens. Incidentally, visual points of the construction stereo cameras <highlight><bold>210</bold></highlight> or the visual points of the construction display device <highlight><bold>100</bold></highlight> may be used in place of the visual points of the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight>. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The image conversion process in the image calculation processing section <highlight><bold>320</bold></highlight> is described below. In the image calculation processing section <highlight><bold>320</bold></highlight>, it is assumed that an x-y-z coordinate system as shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is used. When the resolution in the front-and-rear and right-and-left directions is assumed to be &Dgr; xy and the resolution in the depth direction z is assumed to be &Dgr; z, the following equations are derived:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>&Dgr; xy&equals;H&middot;&dgr; p/f</italic></highlight>&emsp;&emsp;(1)</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>&Dgr; z&equals;H</italic></highlight><highlight><superscript>2</superscript></highlight><highlight><italic>&middot;&dgr; p</italic></highlight>/(<highlight><italic>B&middot;f</italic></highlight>)&emsp;&emsp;(2)</in-line-formula></paragraph>
<paragraph id="P-0071" lvl="7"><number>&lsqb;0071&rsqb;</number> where &dgr; p is the pixel resolution. In this way, the stereovision images of the target data and the stereovision images of the measurement-purpose stereo camera <highlight><bold>220</bold></highlight> may be compared with each other at the visual point of the construction operator. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> Next, the construction status measuring device <highlight><bold>300</bold></highlight> carries out comparative examination of the target data and the current status data of the object (S<highlight><bold>70</bold></highlight>). The images obtained by converting the stereovision images of the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight> that represent the current status data of the object using the image calculation processing section <highlight><bold>320</bold></highlight> are referred to as restructured images. Since the volume, exact shape and dimensions are known from the restructured images, the object may be compared with the target data. As for the amount of earth to be handled, it can be known quantitatively by taking the differential between the object and the target data. Comparison of shapes enables examination of how to proceed with the construction and the choice of the method of construction. Amount of construction may be estimated and examined from the amount of earth handled and the time taken. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> Next, if the work proves to be complete as a result of the comparison with the target data, the process of the construction status measuring device <highlight><bold>300</bold></highlight> goes to S<highlight><bold>100</bold></highlight>. If the work is not complete, it goes to S<highlight><bold>85</bold></highlight> (S<highlight><bold>80</bold></highlight>). In S<highlight><bold>85</bold></highlight>, next construction data are set with the construction plan drafting and correcting means <highlight><bold>380</bold></highlight>. That is, next intended construction position data are set. The position data in three dimensions may be set directly to the target data obtained from the design drawing of the final stage, or for example the next construction amount is determined from the result of examination in S<highlight><bold>70</bold></highlight> and, with its position assumed to be the final target (drawing) of the next construction, the final target data may be set. In that way, daily construction amount becomes clear, so that the construction can be executed exactly as planned. And the construction status measuring device <highlight><bold>300</bold></highlight> transmits those analysis data to the construction site (S<highlight><bold>90</bold></highlight>). </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> Next at the construction site, the analysis data transmitted from the construction status measuring device <highlight><bold>300</bold></highlight> are received with the construction display device <highlight><bold>100</bold></highlight> (R<highlight><bold>30</bold></highlight>). And the construction is prepared using the analysis data (R<highlight><bold>40</bold></highlight>). The work machine or the construction operator moves to the construction site planned and executes the construction (R<highlight><bold>50</bold></highlight>). Details at R<highlight><bold>50</bold></highlight> will be described concerning &lsquo;real-time construction flow&rsquo; shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. When the construction is complete, the process goes back to R<highlight><bold>10</bold></highlight> where the construction results are measured and compared with the design drawings as the target data, and examined. If the construction proves not to be complete, the construction is continued and the routines of S<highlight><bold>20</bold></highlight> to S<highlight><bold>90</bold></highlight> and R<highlight><bold>10</bold></highlight> to R<highlight><bold>50</bold></highlight> are repeated until the construction is complete. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> When the entire construction is over, the construction management office prepares the summary description of the entire construction from the measurement data (S<highlight><bold>100</bold></highlight>). For example, the number of days, the amount of construction, man-hours, machines and materials used, and others are enumerated and calculated using the construction status measuring device <highlight><bold>300</bold></highlight>. And a construction report is prepared at the construction management office (S<highlight><bold>110</bold></highlight>). In this way, since the daily status and the final status of construction can be managed systematically, visually, and quantitatively with the construction status measuring device <highlight><bold>300</bold></highlight>, construction progress relative to the plan can be estimated easily. It is possible for example to take appropriate measures when the construction is delayed relative to the plan. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a flow chart for explaining the details of stereovision image measurement. The stereovision image measurement is shown in S<highlight><bold>50</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. First, using the rectified images produced at S<highlight><bold>30</bold></highlight>, stereovision matching is carried out (S<highlight><bold>52</bold></highlight>). The stereovision matching may be carried out using an algorithm such as the image correlation processing. Since special accuracy is required here, the normalizing correlation processing among others is used. </paragraph>
<paragraph id="P-0077" lvl="7"><number>&lsqb;0077&rsqb;</number> Explanation of Normalization Correlation Processing </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is an explanatory view of the normalizing correlation processing. As shown, for example when the position of N1&times;N1 pixel area on the right side image is to be searched on the left side image, a corresponding area on the left side image is detected using the image of N1&times;N1 pixel as a template image. In the case orientation and rectification processing are already applied, the corresponding point can be detected only by searching on the same line on the left side image. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> In the search area (left side image), when the position of the template image is determined so that C(a, b) in the equation below becomes a maximum, the search is assumed to be made to the template image:  
<math-cwu id="MATH-US-00001">
<number>1</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mrow>
            <mi>C</mi>
            <mo>&af;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>a</mi>
                <mo>,</mo>
                <mi>b</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>=</mo>
          <mrow>
            <munderover>
              <mo>&Sum;</mo>
              <mrow>
                <mi>m1</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>N1</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>&it;</mo>
            <mrow>
              <munderover>
                <mo>&Sum;</mo>
                <mrow>
                  <mi>n1</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mrow>
                <mrow>
                  <mi>N1</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
              </munderover>
              <mo>&it;</mo>
              <mfrac>
                <mrow>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mrow>
                        <mrow>
                          <mi>I</mi>
                          <mo>&af;</mo>
                          <mrow>
                            <mo>(</mo>
                            <mrow>
                              <mi>a</mi>
                              <mo>,</mo>
                              <mi>b</mi>
                            </mrow>
                            <mo>)</mo>
                          </mrow>
                        </mrow>
                        <mo>&it;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>m</mi>
                              <mn>1</mn>
                            </msub>
                            <mo>,</mo>
                            <msub>
                              <mi>n</mi>
                              <mn>1</mn>
                            </msub>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>-</mo>
                      <mi>I</mi>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                  <mo>&it;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mrow>
                        <mi>T</mi>
                        <mo>&af;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>m</mi>
                              <mn>1</mn>
                            </msub>
                            <mo>,</mo>
                            <msub>
                              <mi>n</mi>
                              <mn>1</mn>
                            </msub>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>-</mo>
                      <mi>T</mi>
                    </mrow>
                  </mrow>
                </mrow>
                <msqrt>
                  <mrow>
                    <mi>I</mi>
                    <mo>&it;</mo>
                    <mstyle>
                      <mtext>&emsp;</mtext>
                    </mstyle>
                    <mo>&it;</mo>
                    <mi>&sigma;</mi>
                    <mo>&it;</mo>
                    <mstyle>
                      <mtext>&emsp;</mtext>
                    </mstyle>
                    <mo>&it;</mo>
                    <mi>a</mi>
                    <mo>&it;</mo>
                    <mstyle>
                      <mtext>&emsp;</mtext>
                    </mstyle>
                    <mo>&it;</mo>
                    <mi>b</mi>
                    <mo>&it;</mo>
                    <mstyle>
                      <mtext>&emsp;</mtext>
                    </mstyle>
                    <mo>&it;</mo>
                    <mi>Tc</mi>
                  </mrow>
                </msqrt>
              </mfrac>
            </mrow>
          </mrow>
        </mrow>
        <mo>&it;</mo>
        <mstyle>
          <mtext>&NewLine;</mtext>
        </mstyle>
        <mo>&it;</mo>
        <mstyle>
          <mtext>where,</mtext>
        </mstyle>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>3</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>I</mi>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <msubsup>
              <mi>N</mi>
              <mn>1</mn>
              <mn>2</mn>
            </msubsup>
          </mfrac>
          <mo>&it;</mo>
          <mrow>
            <munderover>
              <mo>&Sum;</mo>
              <mrow>
                <mi>m1</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>N1</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>&it;</mo>
            <mrow>
              <munderover>
                <mo>&Sum;</mo>
                <mrow>
                  <mi>n1</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mrow>
                <mrow>
                  <mi>N1</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
              </munderover>
              <mo>&it;</mo>
              <mrow>
                <mrow>
                  <mi>I</mi>
                  <mo>&af;</mo>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mi>a</mi>
                      <mo>,</mo>
                      <mi>b</mi>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>&it;</mo>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <msub>
                      <mi>m</mi>
                      <mn>1</mn>
                    </msub>
                    <mo>,</mo>
                    <msub>
                      <mi>n</mi>
                      <mn>1</mn>
                    </msub>
                  </mrow>
                  <mo>)</mo>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>4</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>T</mi>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <msubsup>
              <mi>N</mi>
              <mn>1</mn>
              <mn>2</mn>
            </msubsup>
          </mfrac>
          <mo>&it;</mo>
          <mrow>
            <munderover>
              <mo>&Sum;</mo>
              <mrow>
                <mi>m1</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>N1</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>&it;</mo>
            <mrow>
              <munderover>
                <mo>&Sum;</mo>
                <mrow>
                  <mi>n1</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mrow>
                <mrow>
                  <mi>N1</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
              </munderover>
              <mo>&it;</mo>
              <mrow>
                <mi>T</mi>
                <mo>&af;</mo>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <msub>
                      <mi>m</mi>
                      <mn>1</mn>
                    </msub>
                    <mo>,</mo>
                    <msub>
                      <mi>n</mi>
                      <mn>1</mn>
                    </msub>
                  </mrow>
                  <mo>)</mo>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>5</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>I</mi>
          <mrow>
            <mi>&sigma;</mi>
            <mo>&it;</mo>
            <mstyle>
              <mtext>&emsp;</mtext>
            </mstyle>
            <mo>&it;</mo>
            <mi>ab</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <msubsup>
              <mi>N</mi>
              <mn>1</mn>
              <mn>2</mn>
            </msubsup>
          </mfrac>
          <mo>&it;</mo>
          <mrow>
            <munderover>
              <mo>&Sum;</mo>
              <mrow>
                <mi>m1</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>N1</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>&it;</mo>
            <mrow>
              <munderover>
                <mo>&Sum;</mo>
                <mrow>
                  <mi>n1</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mrow>
                <mrow>
                  <mi>N1</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
              </munderover>
              <mo>&it;</mo>
              <msup>
                <mrow>
                  <mo>{</mo>
                  <mrow>
                    <mrow>
                      <msub>
                        <mi>I</mi>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>a</mi>
                            <mo>,</mo>
                            <mi>b</mi>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </msub>
                      <mo>&af;</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <msub>
                            <mi>m</mi>
                            <mn>1</mn>
                          </msub>
                          <mo>,</mo>
                          <msub>
                            <mi>n</mi>
                            <mn>1</mn>
                          </msub>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                    <mo>-</mo>
                    <mi>I</mi>
                  </mrow>
                  <mo>}</mo>
                </mrow>
                <mn>2</mn>
              </msup>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>6</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>T</mi>
          <mi>&sigma;</mi>
        </msub>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <msubsup>
              <mi>N</mi>
              <mn>1</mn>
              <mn>2</mn>
            </msubsup>
          </mfrac>
          <mo>&it;</mo>
          <mrow>
            <munderover>
              <mo>&Sum;</mo>
              <mrow>
                <mi>m1</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>N1</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>&it;</mo>
            <mrow>
              <munderover>
                <mo>&Sum;</mo>
                <mrow>
                  <mi>n1</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mrow>
                <mrow>
                  <mi>N1</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
              </munderover>
              <mo>&it;</mo>
              <msup>
                <mrow>
                  <mo>{</mo>
                  <mrow>
                    <mrow>
                      <mi>T</mi>
                      <mo>&af;</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <msub>
                            <mi>m</mi>
                            <mn>1</mn>
                          </msub>
                          <mo>,</mo>
                          <msub>
                            <mi>n</mi>
                            <mn>1</mn>
                          </msub>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                    <mo>-</mo>
                    <mi>T</mi>
                  </mrow>
                  <mo>}</mo>
                </mrow>
                <mn>2</mn>
              </msup>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>7</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00001" file="US20030004645A1-20030102-M00001.NB"/>
<image id="EMI-M00001" wi="216.027" he="162.02025" file="US20030004645A1-20030102-M00001.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0080" lvl="2"><number>&lsqb;0080&rsqb;</number> I<highlight><subscript>(a,b)</subscript></highlight>(m<highlight><subscript>1</subscript></highlight>, n<highlight><subscript>1</subscript></highlight>): part of input image </paragraph>
<paragraph id="P-0081" lvl="2"><number>&lsqb;0081&rsqb;</number> T(m<highlight><subscript>1</subscript></highlight>,n<highlight><subscript>1</subscript></highlight>): template image </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> Incidentally, the templates and the search areas of the left side image and the right side image may be interchanged. In the case of multiple stereovision images, the above process is applied to every pair of stereovisions to determine the corresponding areas. From the results of stereovision matching, three-dimensional coordinates on respective images are calculated (S<highlight><bold>54</bold></highlight>). </paragraph>
<paragraph id="P-0083" lvl="7"><number>&lsqb;0083&rsqb;</number> Principle of Stereovision Image Measurement </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is an explanatory view of the principle of the stereovision image measurement. Any point p(x, y) on the object is projected through a camera lens <highlight><bold>1</bold></highlight> as a point P<highlight><bold>1</bold></highlight>(x1, y1) on an image <highlight><bold>1</bold></highlight>, and through a camera lens <highlight><bold>2</bold></highlight> as a point P<highlight><bold>2</bold></highlight>(x2, y2) on an image P<highlight><bold>2</bold></highlight>. The images <highlight><bold>1</bold></highlight> and <highlight><bold>2</bold></highlight> are already corrected for orientation and rectification. The optical axes z<highlight><bold>1</bold></highlight> and z<highlight><bold>2</bold></highlight> are parallel to each other, with the distances from the two principal points to the CCD (charge-coupled devices) surfaces being identical &lsquo;a&rsquo;, and with the CCDs being converted to be placed perpendicular to the optical axis. Assuming the distance between the two optical axes (baseline length) to be B, the following relationship between the points P<highlight><bold>1</bold></highlight>(x1, y1) and P<highlight><bold>2</bold></highlight>(x1, y1) is holds true:</paragraph>
<paragraph lvl="0"><in-line-formula>x1<highlight><italic>&equals;ax/z</italic></highlight>&emsp;&emsp;(8)</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>y1&equals;y2<highlight><italic>&equals;ay/z</italic></highlight>&emsp;&emsp;(9)</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>x2&minus;x1<highlight><italic>&equals;aB/z</italic></highlight>&emsp;&emsp;(10)</in-line-formula></paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> It is assumed, however, that the origin of the entire coordinate system is positioned at the principal point of the lens of the camera <highlight><bold>1</bold></highlight>. Using the value of z determined from the equation (10), values of x and y are determined with the a equations (8) and (9). That is, since the corresponding points (x<highlight><bold>1</bold></highlight> and x<highlight><bold>2</bold></highlight>) of the right and left images are known by the process of S<highlight><bold>52</bold></highlight>, the distance z from the lens principal point of the camera <highlight><bold>1</bold></highlight> to any point p on the object can be determined. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> Referring again to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the measurement object is restructured using the three-dimensional coordinate system obtained (S<highlight><bold>56</bold></highlight>). That is, combining the three-dimensional coordinates obtained by the normalizing correlation processing and the stereovision method according to the current status of the construction site, expression such as the wire frame becomes possible, and the volume such as the amount of processed earth can be obtained. Next, superposition of the target data image and the restructured image is carried out. This means conversion of position coordinates provided on the construction site to actual size required for the work by the known reference point data (S<highlight><bold>58</bold></highlight>). Thus, the stereovision image measurement is performed. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a drawing for explaining the real time construction flow performed on the construction site. The real time construction flow is shown at R<highlight><bold>50</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. In the construction display device <highlight><bold>100</bold></highlight>, images are converted with the image processing section <highlight><bold>120</bold></highlight> using the analysis data received at R<highlight><bold>30</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> and the data of the attitude sensor <highlight><bold>130</bold></highlight> and the three-dimensional position of the construction display device <highlight><bold>100</bold></highlight> to the visual point position of the construction display device <highlight><bold>100</bold></highlight> (R<highlight><bold>52</bold></highlight>). In this case, if the transmitted data are already converted to the visual point of the construction display device <highlight><bold>100</bold></highlight>, further conversion is not required. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> Next, three-dimensional display is carried out with the real image/virtual image observing section <highlight><bold>110</bold></highlight> (R<highlight><bold>54</bold></highlight>). <cross-reference target="DRAWINGS">FIG. 9</cross-reference> shows an example of synthesized image before construction. Since no construction is executed yet on the object shown with the three-dimensional display image in the real image/virtual image observing section <highlight><bold>110</bold></highlight>, the initial ground shape data represent the solid lines while the target data represent the broken lines in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. Here, the target data represent a truncated pyramid, with the initial ground shape data representing a raised piece of ground greater than the shape represented with the target data. As the construction goes on, the shape of the ground changes as shown in <cross-reference target="DRAWINGS">FIGS. 10 and 11</cross-reference>. <cross-reference target="DRAWINGS">FIG. 10</cross-reference> shows the status at the beginning of the construction when a side corresponding to the target data has appeared as a sloped side of the object, the raised piece of ground. <cross-reference target="DRAWINGS">FIG. 11</cross-reference> shows the status in the course of the construction when most part of the truncated pyramid, the target shape, has appeared. Thus, the construction may be executed to the natural ground while being compared with the target data-based shape. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> And the construction operator executes the construction using the work machine (R<highlight><bold>56</bold></highlight>). And the construction operator carries out measurement and comparison process using the monitoring unit <highlight><bold>200</bold></highlight> (R<highlight><bold>58</bold></highlight>). Details of the measurement and comparison process will be described later in reference to FIG. <highlight><bold>12</bold></highlight>. And judgment display is carried out (R<highlight><bold>60</bold></highlight>). Details of the judgment display process will be described later in reference to <cross-reference target="DRAWINGS">FIG. 13</cross-reference>. The construction operator repeats the construction while watching the video/virtual image display section <highlight><bold>330</bold></highlight> until the above process is over exactly as represented with the target data (R<highlight><bold>62</bold></highlight>). </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> An advantage of executing construction by using the real image/virtual image observing section <highlight><bold>110</bold></highlight> is that the construction operator can recognize the processed ground reaching the target data status while watching both the real image/virtual image observing section <highlight><bold>110</bold></highlight> and the construction site during the construction, without carrying out the construction in excess. Another advantage is that, as the processed ground surface approaches the target data status, a virtual wall appears and so the remaining amount of construction can be visually recognized. The virtual wall display, unlike mere numerals, provides visual recognition, facilitates operation of the work machine, and results in speedy and accurate construction. Not only when digging the ground but also filling or constructing something, the construction may be carried out while watching and confirming 3D display of the target data position and the remaining amount of construction on the real image/virtual image observing section <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is for explaining the measurement comparison process flow. The measurement comparison process flow is shown at the step R<highlight><bold>58</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. First, the image <highlight><bold>1</bold></highlight> is taken with the construction stereo camera <highlight><bold>210</bold></highlight> (R<highlight><bold>70</bold></highlight>). Next, the image <highlight><bold>2</bold></highlight> is taken with the construction stereo camera <highlight><bold>210</bold></highlight> (R<highlight><bold>72</bold></highlight>). Then, a changed area is extracted with the motion image processing section <highlight><bold>230</bold></highlight> by subtracting the image <highlight><bold>1</bold></highlight> from the image <highlight><bold>2</bold></highlight> (R<highlight><bold>74</bold></highlight>). Then, matching of right and left images is carried out only for the changed area (R<highlight><bold>76</bold></highlight>). Since this matching process must be in real time, image correlation processing is carried out by the sequential residue analysis (SSDA) method. </paragraph>
<paragraph id="P-0092" lvl="7"><number>&lsqb;0092&rsqb;</number> SSDA Method </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> Since processing motion images in real time is required here, the SSDA method is used to increase the processing speed. The image correlation processing is carried out according to the same principle as that of the normalizing correlation processing shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> to determine a point in the left image corresponding to the right image or vice versa. Equations of the SSDA method are as follows:  
<math-cwu id="MATH-US-00002">
<number>2</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>R</mi>
          <mo>&af;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mi>a</mi>
              <mo>,</mo>
              <mi>b</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <msubsup>
              <mi>N</mi>
              <mn>1</mn>
              <mn>2</mn>
            </msubsup>
          </mfrac>
          <mo>&it;</mo>
          <mrow>
            <munderover>
              <mo>&Sum;</mo>
              <mrow>
                <mi>m1</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>N1</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>&it;</mo>
            <mrow>
              <munderover>
                <mo>&Sum;</mo>
                <mrow>
                  <mi>n1</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mrow>
                <mrow>
                  <mi>N1</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
              </munderover>
              <mo>&it;</mo>
              <mrow>
                <mo>&LeftBracketingBar;</mo>
                <mrow>
                  <mrow>
                    <msub>
                      <mi>I</mi>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>a</mi>
                          <mo>,</mo>
                          <mi>b</mi>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </msub>
                    <mo>&af;</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <msub>
                          <mi>m</mi>
                          <mn>1</mn>
                        </msub>
                        <mo>,</mo>
                        <msub>
                          <mi>n</mi>
                          <mn>1</mn>
                        </msub>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>-</mo>
                  <mrow>
                    <mi>T</mi>
                    <mo>&af;</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <msub>
                          <mi>m</mi>
                          <mn>1</mn>
                        </msub>
                        <mo>,</mo>
                        <msub>
                          <mi>n</mi>
                          <mn>1</mn>
                        </msub>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                </mrow>
                <mo>&RightBracketingBar;</mo>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>11</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00002" file="US20030004645A1-20030102-M00002.NB"/>
<image id="EMI-M00002" wi="216.027" he="24.97635" file="US20030004645A1-20030102-M00002.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0094" lvl="7"><number>&lsqb;0094&rsqb;</number> where </paragraph>
<paragraph id="P-0095" lvl="2"><number>&lsqb;0095&rsqb;</number> T(m<highlight><subscript>1</subscript></highlight>,n<highlight><subscript>1</subscript></highlight>): template image, I<highlight><subscript>(a,b)</subscript></highlight>(m<highlight><subscript>1</subscript></highlight>,n<highlight><subscript>1</subscript></highlight>): part of the object image, </paragraph>
<paragraph id="P-0096" lvl="2"><number>&lsqb;0096&rsqb;</number> (a, b): left upper coordinates of the template image and R(a, b): residue. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> Here, the position sought is the one where the residue R(a, b) becomes a minimum. To increase the processing speed, it is carried out such that the addition with the equation (11) is stopped when the value of R(a, b) exceeds the minimum of the past residue, and moves on to the left upper coordinates (a, b) of the next template. Thus, motion images can be coped with. In the case plural cameras are used, real time process can be carried out by applying the SSDA method to respective pairs of stereovision images. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> Next, using the corresponding points of the right and left images obtained, three-dimensional coordinates of an area are calculated (R<highlight><bold>78</bold></highlight>). This determines the distance to the changed part of the object being processed (distance image). Judgment display is made back to R<highlight><bold>60</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. The judgment display process becomes as shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>. <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is for explaining the judgment display process flow. The judgment display process flow is shown at the step R<highlight><bold>60</bold></highlight> of <cross-reference target="DRAWINGS">FIGS. 8 and 12</cross-reference>. First, the target data of the changed area (processed area) are compared (to determine difference) using the distance images of the changed area (R<highlight><bold>80</bold></highlight>). </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is for explaining comparison of the target data of the changed area using the distance image of the construction area, with (A) showing the state before executing construction and (B) during the construction. Assuming the distance to the position on the object being processed to be &lsquo;a&rsquo; and the target data to be &lsquo;b,&rsquo; (a&minus;b) is calculated at each point in the changed (processed) area on the image. Using the results, the following three process displays are carried out. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> Case 1: a&minus;b&equals;0 (R<highlight><bold>82</bold></highlight>). This condition means that the target data are reached, and a virtual wall is displayed at the reached point in the changed area (R<highlight><bold>84</bold></highlight>). That is, the display of the virtual wall shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> means that the designed position is reached. In the case the reached point is part of the target data, it is preferable to indicate only that part in a different color, indicating that the part need not be processed any more. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> Case 2: a&gt;b (R<highlight><bold>86</bold></highlight>). This condition means that the target data are exceeded and a warning display is shown (R<highlight><bold>88</bold></highlight>). In this case, the area in which the target data are exceeded may be indicated in a different color in two dimensions together with a message display. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> Case 3: a&lt;b (R<highlight><bold>90</bold></highlight>). This condition means that the target data are not reached yet (R<highlight><bold>92</bold></highlight>). The construction may be facilitated by indicating on the construction display device <highlight><bold>100</bold></highlight> the amount of construction yet to be executed when the status of the object approaches the target data. Such an indication can remarkably improve the construction efficiency, by making the indication not only in figures but also in different colors in two dimensions by the classified distances to the target data position of the object surface. Judgment criteria may be set for example by colors of green, yellow, and red according to threshold values of (a&minus;b) at respective points. These virtual walls may be displayed in front of or behind the object or in see-through color depending on the distance judgment. For example the part not yet reached may be indicated in transparent red. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> Next as the second embodiment of the invention, work of excavating an archaeological site will be described. To carry out excavation and examination of the site, a three-dimensional drawing of the site is made from the data taken with measurement-purpose stereo cameras, positions of buildings or the like that must be under the ground are estimated, and their positions are excavated. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is a process flow chart when the invention is applied to excavation for investigating an archaeological site. First, estimated three-dimensional data of the archaeological site are stored in the three-dimensional target data storage section <highlight><bold>340</bold></highlight>. On the other hand, the site to be excavated is photographed with the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight>. Reference points, positions of the construction display device <highlight><bold>100</bold></highlight> and the monitoring unit <highlight><bold>200</bold></highlight> are measured with the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight> (R<highlight><bold>500</bold></highlight>). The data of the measured positions are sent to the construction status measuring device <highlight><bold>300</bold></highlight> (R<highlight><bold>510</bold></highlight>). </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> The construction status measuring device <highlight><bold>300</bold></highlight> receives the sent position measurement data at the data exchanging section <highlight><bold>310</bold></highlight> (S<highlight><bold>500</bold></highlight>). The construction status measuring device <highlight><bold>300</bold></highlight> carries out measurement and analysis on the basis of the received position measurement data (S<highlight><bold>510</bold></highlight>). In this case, at the image calculation processing section <highlight><bold>320</bold></highlight>, stereovision images are produced from the stereovision images and reference point data of the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight>, and three-dimensional coordinates are calculated by carrying out stereovision matching. These processes are similar to those of S<highlight><bold>30</bold></highlight> to S<highlight><bold>50</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. The three-dimensional data produced are displayed on the video/virtual image display section <highlight><bold>330</bold></highlight> (S<highlight><bold>520</bold></highlight>). </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> Here, the stereovision images of the target data and the stereovision images of the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight> are converted to those under the conditions of: the baseline length (distance between cameras) B on the side of intended visual point, imaging distance H, and the focal length f of the lens, and displayed. Here, the estimated three-dimensional data or the drawing of the archaeological site stored in advance in the three-dimensional target data storage section <highlight><bold>340</bold></highlight> and the measured data of the object, the excavated site, are superposed and displayed in three dimensions on the video/virtual image display section <highlight><bold>330</bold></highlight> and examined (S<highlight><bold>530</bold></highlight>). If no estimated three-dimensional data are present in advance, estimation is made at S<highlight><bold>530</bold></highlight>. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> If the excavation proves to be unnecessary as a result of the examination, the process goes to S<highlight><bold>570</bold></highlight>; if necessary to S<highlight><bold>550</bold></highlight> (S<highlight><bold>540</bold></highlight>). Then, next excavation position data are set while viewing the 3D display on the video/virtual image display section <highlight><bold>330</bold></highlight> (S<highlight><bold>550</bold></highlight>). If the excavation position data are different from those estimated, they are corrected and set. The data are converted so that stereovision images may be displayed at the visual point on the side of real image/virtual image observing section <highlight><bold>110</bold></highlight>. When the excavation position is set, its estimated position and the position data on the drawing are sent to the side of the construction display device <highlight><bold>100</bold></highlight> (S<highlight><bold>560</bold></highlight>). </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> The construction display device <highlight><bold>100</bold></highlight> receives the data at the data exchanging section <highlight><bold>140</bold></highlight> (R<highlight><bold>520</bold></highlight>). Matching of the excavation position is carried out at the image processing section <highlight><bold>120</bold></highlight> using the position data of the construction display device <highlight><bold>100</bold></highlight> and synthesized display is shown on the real image/virtual image observing section <highlight><bold>110</bold></highlight> (R<highlight><bold>530</bold></highlight>). The work operator moves to the excavation site while watching the display on the real image/virtual image observing section <highlight><bold>110</bold></highlight> (R<highlight><bold>540</bold></highlight>). Then the work operator carries out excavation (R<highlight><bold>550</bold></highlight>). The sequence of the excavation work here is similar to that of the real time execution flow chart of <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. The excavation work by the work operator is carried out according to the estimated three-dimensional data. When the work is over, the work operator carries out again stereovision imaging (R<highlight><bold>500</bold></highlight>). The process after R<highlight><bold>510</bold></highlight> is similar to that from S<highlight><bold>500</bold></highlight> on described before. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> When the work is over, the total number of work days, the amount of work, the number of unearthed articles, and others are collectively analyzed (S<highlight><bold>570</bold></highlight>). And the person in charge of controlling the excavation and investigation of the archaeological site makes a report (S<highlight><bold>580</bold></highlight>). In this way, since the actual work may be carried out while visually comparing with the estimated three-dimensional images using the real image/virtual image observing section <highlight><bold>110</bold></highlight>, work efficiency is very much improved. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a process flow chart when the invention is applied to disaster prevention. First, stereovision images of a site are taken with the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight> (R<highlight><bold>700</bold></highlight>). Positions to be reference points on the site are taken in three dimensions with the automatic tracing type of surveying instrument <highlight><bold>252</bold></highlight>, or with an automatic tracing type of surveying instrument without prisms when the site is too dangerous for human access. The construction display device <highlight><bold>100</bold></highlight> in this case is preferably one that can be remotely controlled. Position measurement data are transmitted at the data exchanging section <highlight><bold>140</bold></highlight> (R<highlight><bold>710</bold></highlight>). </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> Then, the construction status measuring device <highlight><bold>300</bold></highlight> receives the transmitted position measurement data at the data exchanging section <highlight><bold>310</bold></highlight> (S<highlight><bold>700</bold></highlight>). Three-dimensional measurement and analysis are carried out in the image calculation processing section <highlight><bold>320</bold></highlight> using the position measurement data (S<highlight><bold>710</bold></highlight>). These processes are similar to those of S<highlight><bold>30</bold></highlight> to S<highlight><bold>50</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. In the case previously measured data are available in S<highlight><bold>710</bold></highlight>, their region of change and the amount of change are extracted and determined from differences obtained from the images. And three-dimensional images are shown on the video/virtual image display section <highlight><bold>330</bold></highlight> (S<highlight><bold>720</bold></highlight>). </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> Here, the stereovision images of the target data and the stereovision images of the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight> are converted to those under the conditions of: the baseline length (distance between cameras) B on the side of intended visual point, imaging distance H, and the focal length f of the lens, and displayed. The person in charge of disaster prevention examines the locations to be reinforced in consideration of various information on weather, ground, etc. while watching the display on the video/virtual image display section <highlight><bold>330</bold></highlight>, synthesizes those positions and construction information with the three-dimensional data, and displays them (S<highlight><bold>730</bold></highlight>). In the case previous measurement data are available, measurement change regions and past situations are superposed over the video/virtual image display section <highlight><bold>330</bold></highlight> and displayed in three-dimensions for examination. In the case measures against disaster are not required, the process goes to S<highlight><bold>750</bold></highlight>. If not required, it goes to S<highlight><bold>760</bold></highlight> (S<highlight><bold>740</bold></highlight>). </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> In the case measures against disaster are required, a construction drawing is prepared and its three-dimensional data are set (S<highlight><bold>760</bold></highlight>). And the data are converted so that stereovision images may be displayed at the visual point on the side of the real image/virtual image observing section <highlight><bold>110</bold></highlight>. And the three-dimensional data set are transmitted through the data exchanging section <highlight><bold>310</bold></highlight> (S<highlight><bold>770</bold></highlight>). Then, the construction display device <highlight><bold>100</bold></highlight> receives the transmitted three-dimensional data at the data exchanging section <highlight><bold>140</bold></highlight> (R<highlight><bold>720</bold></highlight>). The person in charge of disaster prevention puts together the position information of the construction display device <highlight><bold>100</bold></highlight> and the analysis data, displays them on the real image/virtual image observing section <highlight><bold>110</bold></highlight> to confirm the estimated location of disaster prevention construction (R<highlight><bold>730</bold></highlight>). And the person in charge of disaster prevention moves to the site of disaster prevention. Notification and display of information on dangerous areas, etc., if required on the site, are made (R<highlight><bold>740</bold></highlight>). And the person in charge of disaster prevention carries out the disaster prevention construction (R<highlight><bold>750</bold></highlight>). The disaster prevention construction here is similar to that of the flow chart of the real time construction shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> When the disaster prevention construction is over, stereovision images are taken to measure and examine the current status of the site, and data are transmitted (R<highlight><bold>700</bold></highlight>). Procedure thereafter is the repetition of S<highlight><bold>700</bold></highlight>. Since the disaster prevention construction is complete, whether or not observation of the disaster prevention area is to be continued in preparing for future disaster is determined (S<highlight><bold>750</bold></highlight>). If the observation is to be continued, the process goes back to R<highlight><bold>700</bold></highlight> to repeat the steps from R<highlight><bold>700</bold></highlight> to S<highlight><bold>740</bold></highlight> of monitoring and measuring the amount of change. In the case the possibility of a disaster is found to become large during the observation, the process goes to R<highlight><bold>760</bold></highlight> to intensify prevention measures. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> When the disaster prevention construction is complete and the observation becomes unnecessary, the entire construction is summarized (S<highlight><bold>780</bold></highlight>). Here, the construction amount, the number of days taken, and the man-hours are calculated from the data up to the time. A report is written to finish the process (S<highlight><bold>790</bold></highlight>). </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is for explaining a head-up display (HUD) or head-mount display (HMD) for use in real image/virtual image display section and image/virtual image display section. As described before, the HUD or the HMD comes in the optical see-through type and the video see-through type. The HUD or HMD of the optical see-through type is constituted to project CG images such that real images can be seen through and that the construction operator can observe the real images in contrast to the CG images. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a block diagram, showing the second embodiment of use of the construction display device on a construction site. The drawing shows an arrangement in which the construction display device <highlight><bold>100</bold></highlight> and the monitoring unit <highlight><bold>200</bold></highlight> are combined into a single unit to measure positions with an automatic tracing type of surveying instrument. With the above arrangement, since the construction stereo camera <highlight><bold>210</bold></highlight> is located in the construction executing position of the work machine, distance images from the actual visual point of construction are obtained. An example of such arrangement including the monitoring unit <highlight><bold>200</bold></highlight> and a work machine is shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>. The construction position taking section <highlight><bold>150</bold></highlight> and the monitoring unit <highlight><bold>200</bold></highlight> are provided on the ceiling portion of the operator&apos;s compartment of the work machine. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is a block diagram, showing the third embodiment of use of the construction display device on a construction site. In this state of use, the monitoring unit <highlight><bold>200</bold></highlight> is placed on the construction site and the construction display device <highlight><bold>100</bold></highlight> is placed in a distant place to measure positions with the automatic tracing type of surveying machine. That is, the construction display device <highlight><bold>100</bold></highlight> may be placed in a construction management office. Such an arrangement is suitable for situations in which unmanned operation of the work machine is required because of dangerous or severe labor conditions as in a desert or mine. In the case of such unmanned operation of the work machine, a virtual, computer-formed CG image is, as shown in <cross-reference target="DRAWINGS">FIG. 17</cross-reference>, superposed on the real image as seen by the observer, and displayed before the operator of the work machine. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> In the first embodiment of use of the construction display device on the construction site, as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> the construction display device <highlight><bold>100</bold></highlight> and the monitoring unit <highlight><bold>200</bold></highlight> are fixed in position to obtain stabilized vision of the construction site motion image. However, the construction display device <highlight><bold>100</bold></highlight> and the monitoring unit <highlight><bold>200</bold></highlight> may be arranged to be movable. In the first embodiment of use, the construction stereo camera <highlight><bold>210</bold></highlight> and the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight> are placed as a whole in the monitoring unit <highlight><bold>200</bold></highlight>. However, they can be placed in separate positions, with the construction stereo camera <highlight><bold>210</bold></highlight> placed in the construction display device <highlight><bold>100</bold></highlight> and with the measurement-purpose stereo cameras <highlight><bold>220</bold></highlight> placed in the monitoring unit <highlight><bold>200</bold></highlight>. Placing the construction stereo camera <highlight><bold>210</bold></highlight> in the construction display device <highlight><bold>100</bold></highlight> is helpful as for unmanned operation of the work machine and for training operators. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> is a block diagram of a modified embodiment of the construction monitoring system comprising the construction display device and the construction status measurement device shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, and shows the fourth embodiment of use of the construction display device on the construction site. While the construction display device <highlight><bold>100</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is arranged to display the real image and the virtual image in superposition, the construction display device <highlight><bold>100</bold></highlight><highlight><italic>a </italic></highlight>for use in the fourth embodiment is arranged to show the object image and the virtual image in superposition. In <cross-reference target="DRAWINGS">FIG. 21</cross-reference>, the same components as those in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> are provided with the same reference numerals without explanation, and explanation is made only for different points. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> In reference to <cross-reference target="DRAWINGS">FIG. 21</cross-reference>, stereovision images of an object are sent from either the construction stereo camera <highlight><bold>210</bold></highlight> or the measurement-purpose stereo camera <highlight><bold>220</bold></highlight> in a monitoring unit <highlight><bold>200</bold></highlight><highlight><italic>a</italic></highlight>, through a data exchanging section <highlight><bold>240</bold></highlight><highlight><italic>a </italic></highlight>to a data exchanging section <highlight><bold>140</bold></highlight><highlight><italic>a </italic></highlight>of the construction display device <highlight><bold>100</bold></highlight><highlight><italic>a. </italic></highlight></paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> The comparison display processing section <highlight><bold>120</bold></highlight><highlight><italic>a </italic></highlight>of the construction display device <highlight><bold>100</bold></highlight><highlight><italic>a</italic></highlight>, using the attitude data of the construction display device <highlight><bold>100</bold></highlight><highlight><italic>a </italic></highlight>measured with the attitude sensor <highlight><bold>130</bold></highlight> and the three-dimensional position of the construction display device <highlight><bold>100</bold></highlight><highlight><italic>a </italic></highlight>obtained with the construction position taking section <highlight><bold>150</bold></highlight>, converts the target data images sent from the construction status measuring device <highlight><bold>300</bold></highlight> and the stereovision images of the object sent from the monitoring unit <highlight><bold>200</bold></highlight><highlight><italic>a </italic></highlight>to the construction display device <highlight><bold>100</bold></highlight><highlight><italic>a </italic></highlight>to those as seen from the visual point of the construction operator. Then the comparison display processing section <highlight><bold>120</bold></highlight><highlight><italic>a </italic></highlight>matches the positions of the target data images and the stereovision images of the object, and sends them to the real video/virtual image observing section <highlight><bold>110</bold></highlight><highlight><italic>a</italic></highlight>. Thus, the construction operator can observe the construction status at the real video/virtual image observing section <highlight><bold>110</bold></highlight><highlight><italic>a </italic></highlight>on which the target data images and the stereovision images of the object are combined into a CG image. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> In this case, it may be constituted to choose one of two functions, the function of displaying in superposition the real image and the virtual image of the construction display device <highlight><bold>100</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, and the function of displaying the CG images by combining together the stereovision images of the object and the target data images of the construction display device <highlight><bold>100</bold></highlight><highlight><italic>a </italic></highlight>shown in <cross-reference target="DRAWINGS">FIG. 21</cross-reference>, so that the construction operator can switch the function at the operator&apos;s convenience. </paragraph>
<paragraph id="P-0124" lvl="7"><number>&lsqb;0124&rsqb;</number> Industrial Applicability </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> As described above, the image measurement and display device of the invention comprises: a shape measuring section for measuring shape data from a pair of stereovision images of an object taken with an image taking section, a memory section for storing target data related to the images of the object, an image display section for displaying in superposition the paired stereovision images of the object and the stereovision target data image based on the target data, and a comparison display processing section for comparing the shape data of the object with the target data and reflecting the results of the comparison on the superposed display on the image display section. Therefore, the object of processing or construction can be measured and compared with design drawings accurately. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> The image measurement and display device of the invention comprises: a shape measuring section for measuring shape data from a pair of stereovision images of an object taken with an image taking section, a memory section for storing target data related to the image of the object, an image observing section for displaying in superposition, in the state of the object related to the target data being visible, the stereovision target data images of the object based on the target data, and a comparative observation display processing section for comparing the object shape measured by the shape measuring section with the shape corresponding to the target data and for reflecting the comparison results on the stereovision target data image display on the image observing section. Therefore, it is easy for the person in charge of processing or construction to find out whether the processing or construction is carried out exactly as described on design drawings, and to carry out it as designed. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> The construction status monitoring system according to the invention comprises: an image measurement and display device, and a construction plan drafting and correcting means for calculating work-related data up to the time of processing the object to meet the target data. Therefore, it is useful for finding out accurately the daily status of progress in the work of construction or the like and organizing the work flexibly to meet construction plans. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. An image measurement and display device comprising: 
<claim-text>a shape measuring section for measuring shape data of an object from a pair of stereovision images of the object taken with an image taking section; </claim-text>
<claim-text>a memory section for storing target data related to the images of the object; </claim-text>
<claim-text>an image display section for displaying in superposition the paired stereovision images of the object and stereovision target data images of the object based on the target data; and </claim-text>
<claim-text>a comparison display processing section for comparing the shape data of the object with the target data and for reflecting the comparison results on the superposed display on the image display section. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein, the comparison results obtained with the comparison display processing section are reflected so that the part where the shape of the object approximately agrees with the shape corresponding to the target data is displayed distinguishably on the image display section. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein, as the results of the comparison with the comparison display processing section, the distance or interval to the object is associated with that to the target data and then the comparative sizes of the object and the target data are displayed distinguishably on the image display section. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, further comprising an intermediate target data setting means for setting intermediate target data as the target data for the comparison display processing section and the image display section, in every stage of construction on the object, the comparison display processing section comparing the shape of the object with the shape corresponding to the intermediate target data. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein, as the results of the comparison with the comparison display processing section, the distance or interval to the object is associated with that to the target data and then the comparative sizes of the object and the target data are displayed distinguishably on the image display section. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further comprising an intermediate target data setting means for setting intermediate target data as the target data for the comparison display processing section and the image display section, in every stage of construction on the object, the comparison display processing section comparing the shape of the object with the shape corresponding to the intermediate target data. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising an intermediate target data setting means for setting intermediate target data as the target data for the comparison display processing section and the image display section, in every stage of construction on the object, the comparison display processing section comparing the shape of the object with the shape corresponding to the intermediate target data. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. An image measurement and display device comprising: 
<claim-text>a shape measuring section for measuring shape data of an object from a pair of stereovision images of an object taken with an image taking section; </claim-text>
<claim-text>an imaging position measuring section for measuring the position where the image taking section takes images of the object; </claim-text>
<claim-text>a memory section for storing target data related to the images of the object; </claim-text>
<claim-text>an image display section for displaying in superposition the image of the object and the target data image based on the target data, on the basis of the imaging position measured with the imaging position measuring section; and </claim-text>
<claim-text>a comparison display processing section for comparing, on the basis of the imaging position measured with the imaging position measuring sections, the shape of the object with the shape corresponding to the target data, and for reflecting the comparison results on the superposed display on the image display section. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. An image measurement and display device comprising: 
<claim-text>a shape measuring section for measuring the shape data of an object from a pair of stereovision images of the object taken with an image taking section; </claim-text>
<claim-text>a memory section for storing target data related to the images of the object; </claim-text>
<claim-text>an image observing section for superposing the object related to the target data and the stereovision target data image of the object based on the target data and for displaying with the object remaining to be visible; and </claim-text>
<claim-text>a comparative observation display processing section for comparing the shape of the object measured by the shape measuring section, with the shape corresponding to the target data and for reflecting the result of the comparison on the stereovision target data image display of the image observing section. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein the image observing section includes at least one of a head-up display and a head-mount display. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the comparison results obtained with the comparative observation display processing section are reflected so that the part where the shape of the object approximately agrees with the shape corresponding to the target data is displayed distinguishably on the image observation section. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein, as the results of the comparison with the comparative display processing section, the distance or interval to the object is associated with that to the target data and the comparative sizes of the object and the target data are then displayed distinguishably on the image observation section. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein the comparison results obtained with the comparative observation display processing section are reflected so that the part where the shape of the object approximately agrees with the shape corresponding to the target data is displayed distinguishably on the image observation section. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein, as the results of the comparison with the comparative display processing section, the distance or interval to the object is associated with that to the target data and the comparative sizes of the object and the target data are then displayed distinguishably on the image observation section. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. An image measurement and display device according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein, as the results of the comparison with the comparative display processing section, the distance or interval to the object is associated with that to the target data and the comparative sizes of the object and the target data are then displayed distinguishably on the image observation section. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. An image measurement and display device comprising: 
<claim-text>a shape measuring section for measuring the shape data of an object from a pair of stereovision images of the object taken with an image taking section; </claim-text>
<claim-text>an imaging position measuring section for measuring the imaging position of the image taking section; </claim-text>
<claim-text>a memory section for storing target data related to the images of the object; </claim-text>
<claim-text>an image observing section for superposing the object related to the target data, on the basis of the imaging position measured with the imaging position measuring section the stereovision target data image of the object based on the target data, and for displaying with the object remaining to be visible; and </claim-text>
<claim-text>a comparative observation display processing section for comparing, on the basis of the imaging position measured with the imaging position measuring section, the shape of the object measured by the shape measuring section, with the shape corresponding to the target data and for reflecting the result of the comparison on the stereovision target data image display of the image observing section. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. An image measurement and display system comprising: 
<claim-text>an image taking section for taking a pair of stereovision images of an object; </claim-text>
<claim-text>an image display section for displaying the images taken with the image taking section; and </claim-text>
<claim-text>a construction status measuring device including a memory section for storing target data related to the images of the object and an image calculation processing section for processing the images of the object taken with the image taking section; </claim-text>
<claim-text>wherein the image measurement and display system is allowed to exchange data among the image taking section, the image display section, and the construction status measuring device; </claim-text>
<claim-text>the construction status measuring device further comprise a shape measuring section for measuring the shape of the object from the paired stereovision images taken with the image taking section and a comparison display processing section for comparing the shape of the object measured by the shape measuring section, with the shape corresponding to the target data; and </claim-text>
<claim-text>the image display section displays in superposition the image of the object taken with the image taking section and the target data image based on the target data coming sent from the construction status measuring device. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. An image measurement and display system according to <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, wherein the data exchange among the image taking section, the image display section, and the construction status measuring device is performed by one of wireless, optical, Internet, and cable communications. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A method of managing construction, comprising the steps of: 
<claim-text>determining the three-dimensional position of a construction display device with an image taking position measuring section; </claim-text>
<claim-text>acquiring distance images from multiple stereovision images in real time in two dimensions; </claim-text>
<claim-text>superposing, on the basis of the three-dimensional positions, the target data and the stereovision images of an object being processed and displaying the superposed image on the construction display device; and </claim-text>
<claim-text>causing a work machine to execute work according to the information on deviation of the stereovision images, related to the object being processed, from the target data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A method of managing construction, comprising the steps of: 
<claim-text>determining the three-dimensional position of a construction display device with a imaging position measuring section; </claim-text>
<claim-text>acquiring distance images from multiple stereovision images in real time in two dimensions; </claim-text>
<claim-text>measuring the multiple stereovision images; </claim-text>
<claim-text>analyzing construction progress status from the current status of an object being processed and target data; and </claim-text>
<claim-text>updating from time to time construction plan for realizing the target data according to the results of analyzing the construction progress status. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. A system for monitoring the status of construction, comprising: 
<claim-text>an image measurement and display device as set forth in claims <highlight><bold>1</bold></highlight>; and </claim-text>
<claim-text>a construction plan drafting and correcting means for calculating from the comparison results obtained with the comparison display processing section, the work related data for processing or treating an object to meet the target data.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>3</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004645A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004645A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004645A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004645A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004645A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004645A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004645A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004645A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004645A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004645A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030004645A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030004645A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030004645A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030004645A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030004645A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030004645A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030004645A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030004645A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
