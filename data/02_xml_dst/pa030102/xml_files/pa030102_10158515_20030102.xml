<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002720A1-20030102-D00000.TIF SYSTEM "US20030002720A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002720A1-20030102-D00001.TIF SYSTEM "US20030002720A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002720A1-20030102-D00002.TIF SYSTEM "US20030002720A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002720A1-20030102-D00003.TIF SYSTEM "US20030002720A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002720A1-20030102-D00004.TIF SYSTEM "US20030002720A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002720A1-20030102-D00005.TIF SYSTEM "US20030002720A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002720A1-20030102-D00006.TIF SYSTEM "US20030002720A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002720A1-20030102-D00007.TIF SYSTEM "US20030002720A1-20030102-D00007.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002720</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10158515</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020530</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2001-164409</doc-number>
</priority-application-number>
<filing-date>20010531</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06K009/00</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G06K009/62</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>382</class>
<subclass>124000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>382</class>
<subclass>209000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Fingerprint identification apparatus and fingerprint identification method</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Takuya</given-name>
<family-name>Wada</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>FROMMER LAWRENCE &amp; HAUG LLP</name-1>
<name-2></name-2>
<address>
<address-1>745 FIFTH AVENUE</address-1>
<city>NEW YORK</city>
<state>NY</state>
<postalcode>10151</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">By employing template matching using a collation image which is obtained by using a proper technique to binarize an input digital image for fingerprint identification, and a plurality of templates which are recorded beforehand, a fingerprint identification apparatus and method determine whether identity is established between the collation image and each of the recorded images from which recorded templates are extracted. Instead of checking positional relationships among all addresses having high degrees of matching detected for each template, positional relationship checking is performed between addresses detected about adjacent templates. This can greatly reduce the number of combinations for matching, and enables rapid processing. The fingerprint identification apparatus and method are resistant to a change in finger shape since they perform processing for physically close templates, compared with the case of performing processing for separate templates. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to a fingerprint identification apparatus and method that use templates to identify a read fingerprint image. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Conventionally, a technique is known as a fingerprint-image identification method. The technique extracts, from recorded fingerprint images, a plurality of partial images (templates) sufficiently representing the fingerprints, performs matching of the templates with an image read for checking, and determines, based on positional relationships of highly matched points detected in each of the templates, whether or not the read image matches each of the recorded fingerprint images. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In the above technique of the related art, when a large number of templates are used, and a large number of highly matched points are detected, the number of combinations of the templates and the points greatly increases, thus causing a problem in that the processing requires a lot of time. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> For example, when ten templates are used, and thirty highly matched points are detected for each of the templates, the total number of combinations is thirty to the tenth power, that is, approximately six million million. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> In addition, when templates are broadly distributed in an image, and a change in finger shape is large, a problem occurs in that fingerprint identification performance greatly deteriorates. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Accordingly, it is an object of the present invention to provide a fingerprint identification apparatus and method which greatly reduce the time required for fingerprint identification using templates and which maintains identification performance against a change in finger shape. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> To this end, according to an aspect of the present invention, a fingerprint identification apparatus is provided which includes a collation unit for collating a piece of template information extracted from fingerprint information which is recorded beforehand with a part of collation fingerprint information which is input for collation, an extraction unit for extracting, in accordance with the degree of matching detected by the collation unit, collation positions in the collation fingerprint information in which the piece of template information is collated with the part of collation fingerprint information, and a determination unit for determining whether or not identity is established between the recorded fingerprint information and the collation fingerprint information based on the collation positions extracted by the extraction unit and on template extraction positions in the recorded fingerprint information in which the piece of template information is extracted from the recorded fingerprint information. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Preferably, the determination unit determines whether or not the identity is established between the recorded fingerprint information and the collation fingerprint information by comparing only the relationship of the collation positions with the relationship of the template extraction positions. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The determination unit may determine whether or not the identity is established between the recorded fingerprint information and the collation fingerprint information by comparing only the relationship of the collation positions collated by the collation unit with the template extraction positions which are mutually near. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> The determination unit may determine whether or not the identity is established between the recorded fingerprint information and the collation fingerprint information by comparing only the relationship of the collation positions collated by the collation unit with the relationship of the template extraction positions which are mutually adjacent. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The extraction unit may extract a predetermined number of collation positions which have high degrees of matching detected by the collation unit. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> The extraction unit may extract, based on a predetermined threshold value, the collation positions which have the highest degree of matching detected by the collation unit. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The template information may be image information. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> The template information may be one-dimensional image information. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> The piece of template information may be of one of clusters of image information which are obtained by dividing image information represented by the recorded fingerprint information. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> According to another aspect of the present invention, a fingerprint identification method is provided which includes the steps of collating a piece of template information extracted from fingerprint information which is recorded beforehand with a part of collation fingerprint information which is input for collation, extracting, in accordance with the degree of matching detected in the collating step, collation positions in the collation fingerprint information in which the piece of template information is collated with the part of collation fingerprint information, and determining whether or not identity is established between the recorded fingerprint information and the collation fingerprint information based on the collation positions extracted in the extracting step and on template extraction positions in the recorded fingerprint information in which the piece of template information is extracted from the recorded fingerprint information. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> According to another aspect of the present invention, a computer-readable recording medium containing a program is provided. The program controls a computer to execute the steps of collating a piece of template information extracted from fingerprint information which is recorded beforehand with a part of collation fingerprint information which is input for collation, extracting, in accordance with the degree of matching detected in the collating step, collation positions in the collation fingerprint information in which the piece of template information is collated with the part of collation fingerprint information, and determining whether or not identity is established between the recorded fingerprint information and the collation fingerprint information based on the collation positions extracted in the extracting step and on template extraction positions in the recorded fingerprint information in which the piece of template information is extracted from the recorded fingerprint information. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> According to another aspect of the present invention, a program for controlling a computer is provided. The program controls the computer to execute the steps of collating a piece of template information extracted from fingerprint information which is recorded beforehand with a part of collation fingerprint information which is input for collation, extracting, in accordance with the degree of matching detected in the collating step, collation positions in the collation fingerprint information in which the piece of template information is collated with the part of collation fingerprint information, and determining whether or not identity is established between the recorded fingerprint information and the collation fingerprint information based on the collation positions extracted in the extracting step and on template extraction positions in the recorded fingerprint information in which the piece of template information is extracted from the recorded fingerprint information. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> According to the present invention, the time required for checking positional relationships of templates can be greatly reduced compared with the case of determining fingerprint identity by checking positional relationships of positions having high degrees of matching among all the templates. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> In addition, by determining fingerprint identity based on the results of particularly checking positional relationships of points having high degrees of matching between physically close templates, fingerprint identification can be prevented from being affected by a change in fingerprint image, so that fingerprint identification that is resistant to a change in finger shape is realized.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram showing an example of the recording unit <highlight><bold>2</bold></highlight>; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is an illustration of a system configuration including the recording unit <highlight><bold>2</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a sectional view showing the fingerprint sensor unit <highlight><bold>104</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is an illustration of a specific example of a fingerprint image read by the fingerprint sensor unit <highlight><bold>104</bold></highlight> shown in <cross-reference target="DRAWINGS">FIGS. 2 and 3</cross-reference>; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is an illustration of an example of a template structure for use in fingerprint identification; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is an illustration of processing that determines the degree of matching of a collation image (collation image) with the template shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flowchart showing an address comparing operation of a fingerprint registering/verifying circuit according to the present invention; and </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a block diagram showing the address processor of the fingerprint registering/verifying circuit shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> An embodiment of the present invention is described below with reference to the accompanying drawings. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The following embodiment is a preferred embodiment of the present invention and has various types of technically preferable limitations. However, the scope of the present invention is not limited to the embodiment unless limitation on the present invention is particularly not described in the following description. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> A recording unit <highlight><bold>2</bold></highlight> is described below with reference to <cross-reference target="DRAWINGS">FIGS. 1 and 2</cross-reference>. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram showing an example of the recording unit <highlight><bold>2</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a system configuration including the recording unit <highlight><bold>2</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> As <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows, the recording unit <highlight><bold>2</bold></highlight> has a fingerprint sensor unit <highlight><bold>104</bold></highlight> on a surface of a housing <highlight><bold>6</bold></highlight>. The fingerprint sensor unit <highlight><bold>104</bold></highlight> includes capacitive sensors that output electric signals representing a gray scale image by detecting a difference of capacitance caused by ridges and valleys on the fingerprint of a finger <highlight><bold>8</bold></highlight> when it touches a fingerprint reading part <highlight><bold>108</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> When, for example, optical sensors are used, the fingerprint sensor unit <highlight><bold>104</bold></highlight> includes parts shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, that is, a triangular prism <highlight><bold>120</bold></highlight> having a touch surface for a finger <highlight><bold>100</bold></highlight>, a light source <highlight><bold>140</bold></highlight> for emitting a lighting ray to the triangular prism <highlight><bold>120</bold></highlight>, and a charge-coupled device (CCD) camera <highlight><bold>160</bold></highlight>. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> An example the structure shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> has been commonly used. The fingerprint sensor unit <highlight><bold>104</bold></highlight> for use in the present invention may have a structure based on any method if it can capture ridges on fingerprint at a resolution that is not less than a predetermined value, and is particularly not limited to the structure in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> As <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows, for recording, the recording unit <highlight><bold>2</bold></highlight> includes an analog-to-digital (A/D) converter <highlight><bold>12</bold></highlight>, a fingerprint registering/verifying circuit <highlight><bold>14</bold></highlight>, an image memory <highlight><bold>16</bold></highlight>, a central processing unit (CPU) <highlight><bold>18</bold></highlight>, and a program memory <highlight><bold>20</bold></highlight>. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> The A/D converter <highlight><bold>12</bold></highlight> outputs image data representing a fingerprint-gray-scale image by digitizing a fingerprint image signal output by the fingerprint sensor unit <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The fingerprint registering/verifying circuit <highlight><bold>14</bold></highlight> is formed by, for example, a large-scale integrated circuit (LSI). Based on the image data from the A/D converter <highlight><bold>12</bold></highlight>, it generates binarized image data representing a binarized image of fingerprint, and stores the binarized image data in the image memory <highlight><bold>16</bold></highlight> as a rewritable nonvolatile memory. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The program memory <highlight><bold>20</bold></highlight> includes a random access memory (RAM) and a read-only memory (ROM). The CPU <highlight><bold>18</bold></highlight> uses a bus line <highlight><bold>22</bold></highlight> to acquire program data stored in the ROM, and operates based on the program data while using the RAM, whereby the entirety of the recording unit <highlight><bold>2</bold></highlight> is controlled. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> A Universal Serial Bus (USB) controller <highlight><bold>26</bold></highlight> functions as an interface for connecting the recording unit <highlight><bold>2</bold></highlight> by a USB cable <highlight><bold>28</bold></highlight> to an electronic unit (such as the computer <highlight><bold>24</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>) that requires authentication based on fingerprint identification. The electronic unit is arbitrary one of an information appliance, a portable information terminal, and a security system terminal such as an entering/leaving controller. An interface therefor may be based on RS-232C. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The CPU <highlight><bold>18</bold></highlight> outputs image data of fingerprints stored in the image memory <highlight><bold>16</bold></highlight> to the computer <highlight><bold>24</bold></highlight> via the bus line <highlight><bold>22</bold></highlight>, the USB controller <highlight><bold>26</bold></highlight>, and the USB cable <highlight><bold>28</bold></highlight>. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> The operation of the fingerprint sensor unit <highlight><bold>104</bold></highlight> and a fingerprint image read thereby are described below. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> When the fingerprint sensor unit <highlight><bold>104</bold></highlight> employs a capacitance method, by applying voltages to elements constituting the sensors while they are being touched by the finger <highlight><bold>100</bold></highlight>, and measuring stored electric charges so that a capacitance representing ridges on the finger <highlight><bold>100</bold></highlight> can be found, a fingerprint image is read and an electric signal representing the shading of the fingerprint is output. When the fingerprint sensor unit <highlight><bold>104</bold></highlight> employs an optical method, light from the light source <highlight><bold>140</bold></highlight> is diffusely reflected by the protrusions of the fingerprint of the finger <highlight><bold>100</bold></highlight> and is totally reflected by the troughs of the fingerprint of the finger <highlight><bold>100</bold></highlight>. Accordingly, by focusing the reflected light on the CCD camera <highlight><bold>160</bold></highlight>, a fingerprint image in which the protrusions look dark and the troughs look bright can be obtained. The fingerprint image is sampled at appropriate predetermined temporal intervals, for example, it is converted into a digital image having a size of 256 by 218 pixels. By appropriately digitizing the digital image, conversion into a binary pixel image in which each pixel has zero or one can be obtained. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Methods for the digitization include level comparison of the average of the pixel levels of the entire image with each level, and comparison of the average of pixel levels in an appropriate range around a pixel of interest with each pixel level. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates a specific example of the obtained binary pixel image. The black portions of the image indicate the protrusions of the fingerprint, and the white portions of the image indicate the troughs of the fingerprint. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> In the fingerprint identification system shown in FIG. <highlight><bold>2</bold></highlight>, a plurality of patterns composed of two-dimensional image information extracted from appropriate portions of the binary image are recorded as recorded templates beforehand in a nonvolatile memory such as an electrically erasable, programmable read-only memory (EEPROM) or a flash ROM. Normally, patterns that are extracted from portions representing the characteristics of the fingerprint, such as whorls of whorl fingerprints, are recorded as recorded templates. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> In the following, as <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows, a case in which 64-bit two-dimensional templates composed of four 16-bit-length line segments at intervals of four pixels are used as recorded templates is described below. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> Sixteen templates are arranged so that one template is horizontally and vertically sixteen pixels away from an adjacent template. Thus, the storage capacity of the sixteen templates is 128 bytes. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> When fingerprint identification is performed, the fingerprint registering/verifying circuit <highlight><bold>14</bold></highlight> generates binary image data representing a binary image of a fingerprint, based on the image data from the A/D converter <highlight><bold>12</bold></highlight>. By using pattern matching to compare the generated binary image with the binary image data of a fingerprint which is stored in the image memory <highlight><bold>16</bold></highlight> beforehand, the fingerprint registering/verifying circuit <highlight><bold>14</bold></highlight> determines whether the generated image data matches the stored image data. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The CPU <highlight><bold>18</bold></highlight> combines with the USB controller <highlight><bold>26</bold></highlight> to constitute a data input means, and controls the image memory <highlight><bold>16</bold></highlight> to retain binary image data input from the USB cable <highlight><bold>28</bold></highlight>. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> For details, when the fingerprint identification is performed, a change in the average of all the pixel levels is used to detect a touch of the finger <highlight><bold>100</bold></highlight> on the prism <highlight><bold>120</bold></highlight>. An image obtained at the moment is binarized similarly to the method of obtaining the recorded templates, and is written in the binary image area of a work RAM or the like. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Next, in order to detect the coordinates of points having high similarities (degrees of matching) based on pattern matching between each recorded template and a collation image, the degrees of matching at all the points of the collation image are calculated. The degrees of matching are calculated, while the template is being shifted every one pixel. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> After the coordinates of points having high degrees of matching are detected for each template, in order that calculation for checking the positional relationship of the coordinates may be simplified, a distance (address difference) between each template of interest and a template used as a reference for address normalization must be written in an offset address register before the calculation of the degrees of matching is initiated. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> In other words, when sixteen templates 0 to 15 are arranged as shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, and template 10 is used as a reference template, the address difference of template 0 is 32 both in the horizontal and vertical directions. Thus, the offset address register (horizontal value, vertical value)&equals;(32, 32). </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Similarly, for template 1, the offset address register&equals;(16, 32). </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Next, processing for template 0 is performed. This is that, after setting (32, 32) in the offset address register, the degrees of matching at all the pixel positions of the collation image are calculated. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> By way of example, when the template 0 is disposed so that its center is positioned at the origin of the collation image as shown in the frame A in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the number of zeroes is counted in the 64-bit pattern which is generated by performing the exclusive logical sum of the 64-bit pattern of the registered template 0 and the corresponding 64-bit pattern of the collation image in order to calculate how many bits of the two patterns match (the degree of matching). </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> At this time, each portion in which the template does not overlap with the collation image is excluded in the calculation of the degree of matching. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Next, the template is shifted by one bit in the horizontal right, and similar calculation is performed. This operation is repeatedly performed until the center of the template reaches the bottom right end of the collation image (the frame B shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>). </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> When the calculated degree of matching is greater than a predetermined value (threshold value), the values of the offset address register are added to the coordinates of the center of the template in each of the horizontal and vertical directions. The obtained values are written in an area in the address area of a work RAM or the like. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> After calculating the degrees of matching of the entire image, without fixing the threshold value beforehand, an appropriate number of pairs of coordinates having higher degrees of matching may be selected. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Also, as the threshold value is greater, stricter matching is required. Thus, even for a slight change in image, it is not determined that the template matches the collation image. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Accordingly, when an image irregularity due to a change in the finger shape is expected as in a fingerprint image, a value that is approximately 70% to 80% of the degree of matching is appropriate for the threshold value. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> After the above processing for template 0 ends, processing for each of the other templates is performed which performs setting of appropriate values in the offset address register, detection of points having high degrees of matching, correction of the coordinates, and the corrected values in an area for each of the other templates in the work RAM. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Next, between groups of coordinates detected for adjacent templates, it is determined whether relative positional relationships similar to the templates exist. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> This embodiment assumes a case in which each set of thirty pairs of coordinates having higher degrees of matching are selected for each template. In general, just thirty points are not always selected, but it is assumed, for brevity of description, that just thirty points are selected. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> In this case, pairs of coordinates of template number N (N&equals;0 to 15) are represented by A(N, 0) to A(N, 29). For example, pairs of coordinates of template 5 are represented by A(5, 0) to A(5, 29). </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> As is clear from <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, templates that are horizontally and vertically adjacent to template 0 are templates 1 and 4, respectively. Accordingly, coordinate comparison is performed for all the combinations of the pairs of coordinates of both templates. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> First, between each of pairs A of coordinates A(0, k) (k&equals;0 to 29) of template 0, and each of pairs A of coordinates A(1, m) (m&equals;0 to 29), address comparison is performed. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flowchart showing an operation for performing the address comparison. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> After A(0, 0) is loaded into register 1, while each of A(1, 0) to A(1, 29) is being sequentially loaded into register 2, address comparison therebetween is performed. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> In the address comparison, it is determined whether the absolute values of the address differences in the horizontal and vertical directions of A(0, 0) and A(1, m) (m&equals;0 to 29) are less than a predetermined allowable positional shift. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> When the results of determinations for all the values of &ldquo;m&rdquo; are negative (the condition is not satisfied), similar address comparison between A(0, 1) and each of A(1, m) (m&equals;0 to 29) is performed (in steps S<highlight><bold>1</bold></highlight> to S<highlight><bold>10</bold></highlight>). </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> Until address comparison for all the combinations of (k, m) ends, if the condition is satisfied in any of the combinations (in step S<highlight><bold>10</bold></highlight>), a matching score having reset to an initial value of zero is set to 1 (in step S<highlight><bold>11</bold></highlight>), and the operation proceeds to processing for templates 1 and 4 (in step S<highlight><bold>12</bold></highlight>). </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> If the results of determinations for all the combinations of (k, m) are negative, the matching score is unchanged as zero. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> In the processing for templates 0 and 4, it is determined whether the address comparison condition between each of A(0, k) and each of A(4, m) in any one of the combinations of (k, m) is satisfied. At the time it is affirmatively determined, the matching score is incremented by one, and the operation proceeds to processing for template 1 (in step S<highlight><bold>13</bold></highlight>). </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> Since templates that are adjacent to template 1 are templates 0, 2, and 6, processing similar to that for template 0 is performed between templates 1 and 2, and between templates 1 and 6. This is because processing for templates 1 and 0 has already ended. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> When the matching score at the time processing for up to template 15 ends is greater than a predetermined threshold value, it is determined that matching is OK, while when it is less than the threshold value, it is determined that matching is not OK (in steps S<highlight><bold>14</bold></highlight> and S<highlight><bold>15</bold></highlight>). </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> The full matching score in the case of the template arrangement shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is 24. Although, in the above embodiment, positional relationship checking is performed between horizontally and vertically adjacent templates, additional processing for obliquely adjacent templates can be performed. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> As described above, instead of checking positional relationships among all addresses detected for each template, by checking positional relationship between addresses detected for adjacent templates, the number of combinations is greatly reduced. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> Also, since the processing is performed only for physically close templates, it is possible to strongly cope with a change in finger shape, compared with processing between distant templates. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Next, a circuit configuration for effectively performing the above address comparison processing is described below. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a block diagram showing the address processor of the fingerprint registering/verifying circuit <highlight><bold>14</bold></highlight>. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> The address processor includes a group <highlight><bold>10</bold></highlight> of registers, an effectiveness register <highlight><bold>3</bold></highlight> for managing the number of adjacent templates, an address controller <highlight><bold>4</bold></highlight> for controlling addresses, a RAM <highlight><bold>5</bold></highlight> for storing the addresses, four address comparators 1 to 4 (<highlight><bold>11</bold></highlight> to <highlight><bold>14</bold></highlight>), and a score totalizer <highlight><bold>30</bold></highlight> for incrementing the matching score. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The group <highlight><bold>10</bold></highlight> of registers includes the following ones. In register <highlight><bold>1</bold></highlight>, the template number of a template of interest is written. In registers <highlight><bold>2</bold></highlight>A to <highlight><bold>2</bold></highlight>D, the template numbers of the templates that are adjacent to the template whose template number is written in the register <highlight><bold>1</bold></highlight>. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> Pieces of data in the address area that correspond to the templates designated by the registers <highlight><bold>1</bold></highlight> and <highlight><bold>2</bold></highlight>A to <highlight><bold>2</bold></highlight>D are sequentially read during the processing. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> The effectiveness register <highlight><bold>3</bold></highlight> is a 4-bit register that indicates which of the registers <highlight><bold>2</bold></highlight>A to <highlight><bold>2</bold></highlight>D is effective (&ldquo;effective&rdquo; indicated by &ldquo;1&rdquo;, &ldquo;not effective&rdquo; indicated by &ldquo;0&rdquo;) in order to cope with a case in which the number of adjacent templates is less than four. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> In general, when an appropriate number of addresses having higher degrees of matching are selected, the number of addresses is not just &ldquo;N&rdquo;. Accordingly, in a number-of-addresses register <highlight><bold>1</bold></highlight>N, the number of addresses detected for a template of interest is written, and in registers <highlight><bold>2</bold></highlight>AN, <highlight><bold>2</bold></highlight>BN, and <highlight><bold>2</bold></highlight>DN, the number of addresses detected for templates adjacent to the template of interest is written. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> Although the group <highlight><bold>10</bold></highlight> of registers includes registers for storing various types of data for arithmetic processing, they are not shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> The address comparators 1 to 4 (<highlight><bold>11</bold></highlight> to <highlight><bold>14</bold></highlight>) are identical in structure and each include a computing unit <highlight><bold>20</bold></highlight> that computes the difference between the data of the template of interest and the data of a template adjacent thereto, an absolute value circuit <highlight><bold>21</bold></highlight> that finds the absolute value of the computed difference, and a comparator <highlight><bold>23</bold></highlight> that compares the absolute value and an allowable positional shift. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> The outputs of the address comparators 1 to 4 (<highlight><bold>11</bold></highlight> to <highlight><bold>14</bold></highlight>) and the register values of the effectiveness register <highlight><bold>3</bold></highlight> are logically multiplied by AND gates, and the AND values are supplied to the score totalizer <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> In this construction, when processing for template 0 is initially performed, &ldquo;0&rdquo; is set in register <highlight><bold>1</bold></highlight>, and the template numbers 1 and 4 of the templates adjacent to template 0 are set in registers <highlight><bold>2</bold></highlight>A and <highlight><bold>2</bold></highlight>B, respectively. Since the number of templates adjacent to template 0 is only two, only the lower two bits of the effectiveness register <highlight><bold>3</bold></highlight> are set to 1&apos;s. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> When the processing is started after setting the above values, the first data of the templates 0 is set in register A (not shown), and the first data of template 1 and the first data of template 4 are subsequently loaded into registers B and C (not shown), respectively. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> Each of registers A and B performs checking about whether the absolute value of a difference in each of the horizontal and vertical addresses is less than an allowable positional shift. Simultaneously, each of registers A and C performs similar checking. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> If the result of the checking is negative, subsequent data is set in each of registers B and C, and a similar process is performed. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> When the above processing is performed, at the time the number of pieces of data read from address areas for templates 1 and 4 is equal to the value of register <highlight><bold>2</bold></highlight>AN or <highlight><bold>2</bold></highlight>BN, the second data of template 0 is set in register A, and the above processing is repeatedly performed. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> When the result of the checking is affirmative in any point of the processing for templates 0 and 1, or templates 0 and 4, the processing for two templates at the time the checking is affirmative is terminated, and the matching score <highlight><bold>31</bold></highlight> at the above time in the score totalizer <highlight><bold>30</bold></highlight> is incremented by one. For example, when the checking is affirmative between templates 0 and 1, and the checking is affirmative between templates 0 and 4, the matching score <highlight><bold>31</bold></highlight> is 2. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> By performing the above processing while sequentially changing the template number of the template of interest from 0 to 15, the final value of the matching score <highlight><bold>31</bold></highlight> is found. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> In the above processing, the address controller <highlight><bold>4</bold></highlight> controls accessing of the address areas, based on the contents of registers <highlight><bold>1</bold></highlight>, <highlight><bold>2</bold></highlight>A to <highlight><bold>2</bold></highlight>D, <highlight><bold>1</bold></highlight>N, and <highlight><bold>2</bold></highlight>AN to <highlight><bold>2</bold></highlight>AD and the results of address comparison. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> In addition to vertical and horizontal directions, when the processing is performed between obliquely adjacent templates, the number of related registers and address comparators is set at eight. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> By employing the above circuit configuration, an address comparing circuit which has reduced gate size and can operate at very high speed is realized. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> In the above embodiment, the positional relationships of positions having high degrees of matching about a plurality of templates in image identification using template matching are checked. However, the positional relationships and combination of not only adjacent templates but also of templates with one template provided therebetween or arbitrary templates may be checked. When determining whether or not images match each other, not by checking all templates but by checking only the positional relationships of positions having high degrees of matching between adjacent templates, the time required for positional checking can be greatly reduced, and fingerprint identification that is resistant to a change in fingerprint image is realized. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> In the above embodiment, a matching score is influenced by whether or not an address difference between templates having high degrees of matching is less than a predetermined allowable value. In addition, the matching score may be controlled to reflect an address difference between templates and the degree of matching of each template. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> In the above embodiment, each template is divided into rectangles, but the shape is not limited thereto. The template may be divided into arbitrarily closed curve shapes such as polygons, circles, ellipses, and sector forms. The template may have overlapping portions and a plurality of divided areas. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> Also, in the above embodiment, each template composed of two-dimensional image information is used. However, each template composed of one-dimensional information may be used. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> Although the above embodiment performs processing in dedicated collating units, a general-purpose computer may be used to perform recording, collation, authentication, etc. In this case, by using a means such as an apparatus which is connected by an interface such as the USB or RS232C and which includes a fingerprint reading-sensor unit, a server or another apparatus on a network, various recording media, or an input means, fingerprint information is input. A program concerning recording, collation, authentication, etc., may be provided in the form of various recording media such as a compact-disk read-only memory, a digital versatile disk, and a floppy disk, and may be provided by a network. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A fingerprint identification apparatus comprising: 
<claim-text>collation means for collating a piece of template information extracted from fingerprint information which is recorded beforehand with a part of collation fingerprint information which is input for collation; </claim-text>
<claim-text>extraction means for extracting, in accordance with the degree of matching detected by said collation means, collation positions in the collation fingerprint information in which the piece of template information is collated with the part of collation fingerprint information; and </claim-text>
<claim-text>determination means for determining whether or not identity is established between the recorded fingerprint information and the collation fingerprint information based on the collation positions extracted by said extraction means and on template extraction positions in the recorded fingerprint information in which the piece of template information is extracted from the recorded fingerprint information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A fingerprint identification apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said determination means determines whether or not the identity is established between the recorded fingerprint information and the collation fingerprint information by comparing only the relationship of the collation positions with the relationship of the template extraction positions. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A fingerprint identification apparatus according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein said determination means determines whether or not the identity is established between the recorded fingerprint information and the collation fingerprint information by comparing only the relationship of the collation positions collated by said collation means with the template extraction positions which are mutually near. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A fingerprint identification apparatus according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein said determination means determines whether or not the identity is established between the recorded fingerprint information and the collation fingerprint information by comparing only the relationship of the collation positions collated by the collation means with the relationship of the template extraction positions which are mutually adjacent. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A fingerprint identification apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said extraction means extracts a predetermined number of collation positions which have high degrees of matching detected by said collation means. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A fingerprint identification apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said extraction means extracts, based on a predetermined threshold value, the collation positions which have the highest degree of matching detected by said collation means. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A fingerprint identification apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the template information is image information. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A fingerprint identification apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the template information is one-dimensional image information. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A fingerprint identification apparatus according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, wherein the piece of template information is one of clusters of image information which are obtained by dividing image information represented by the recorded fingerprint information. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A fingerprint identification method comprising the steps of: 
<claim-text>collating a piece of template information extracted from fingerprint information which is recorded beforehand with a part of collation fingerprint information which is input for collation; </claim-text>
<claim-text>extracting, in accordance with the degree of matching detected in the collating step, collation positions in the collation fingerprint information in which the piece of template information is collated with the part of collation fingerprint information; and </claim-text>
<claim-text>determining whether or not identity is established between the recorded fingerprint information and the collation fingerprint information based on the collation positions extracted in the extracting step and on template extraction positions in the recorded fingerprint information in which the piece of template information is extracted from the recorded fingerprint information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A fingerprint identification method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein, in the determining step, the method determines whether or not the identity is established between the recorded fingerprint information and the collation fingerprint information by comparing only the relationship of the collation positions with the relationship of the template extraction positions. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A fingerprint identification method according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein, in the determining step, the method determines whether or not the identity is established between the recorded fingerprint information and the collation fingerprint information by comparing only the relationship of the collation positions collated in the collating step with the template extraction positions which are mutually near. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A fingerprint identification method according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein, in the determining step, the method determines whether or not the identity is established between the recorded fingerprint information and the collation fingerprint information by comparing only the relationship of the collation positions collated in the collating step with the relationship of the template extraction positions which are mutually adjacent. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A fingerprint identification method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein, the extracting step, the method extracts a predetermined number of collation positions which have high degrees of matching detected in the collating step. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A fingerprint identification method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein, in the extracting step, the method extracts, based on a predetermined threshold value, the collation positions which have the highest degree of matching detected in the collating step. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A fingerprint identification method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the template information is image information. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A fingerprint identification method according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the template information is one-dimensional image information. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A fingerprint identification method according to <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, wherein the piece of template information is one of clusters of image information which are obtained by dividing image information represented by the recorded fingerprint information. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A computer-readable recording medium containing a program for controlling a computer to execute the steps of: 
<claim-text>collating a piece of template information extracted from fingerprint information which is recorded beforehand with a part of collation fingerprint information which is input for collation; </claim-text>
<claim-text>extracting, in accordance with the degree of matching detected in the collating step, collation positions in the collation fingerprint information in which the piece of template information is collated with the part of collation fingerprint information; and </claim-text>
<claim-text>determining whether or not identity is established between the recorded fingerprint information and the collation fingerprint information based on the collation positions extracted in the extracting step and on template extraction positions in the recorded fingerprint information in which the piece of template information is extracted from the recorded fingerprint information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A program for controlling a computer to execute the steps of: 
<claim-text>collating a piece of template information extracted from fingerprint information which is recorded beforehand with a part of collation fingerprint information which is input for collation; </claim-text>
<claim-text>extracting, in accordance with the degree of matching detected in the collating step, collation positions in the collation fingerprint information in which the piece of template information is collated with the part of collation fingerprint information; and </claim-text>
<claim-text>determining whether or not identity is established between the recorded fingerprint information and the collation fingerprint information based on the collation positions extracted in the extracting step and on template extraction positions in the recorded fingerprint information in which the piece of template information is extracted from the recorded fingerprint information.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002720A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002720A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002720A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002720A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002720A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002720A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002720A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002720A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
