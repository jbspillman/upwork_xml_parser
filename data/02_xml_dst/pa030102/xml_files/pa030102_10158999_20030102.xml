<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005356A1-20030102-D00000.TIF SYSTEM "US20030005356A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005356A1-20030102-D00001.TIF SYSTEM "US20030005356A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005356A1-20030102-D00002.TIF SYSTEM "US20030005356A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005356A1-20030102-D00003.TIF SYSTEM "US20030005356A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005356A1-20030102-D00004.TIF SYSTEM "US20030005356A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005356A1-20030102-D00005.TIF SYSTEM "US20030005356A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030005356A1-20030102-D00006.TIF SYSTEM "US20030005356A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030005356A1-20030102-D00007.TIF SYSTEM "US20030005356A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030005356A1-20030102-D00008.TIF SYSTEM "US20030005356A1-20030102-D00008.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005356</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10158999</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020531</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F011/16</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>714</class>
<subclass>011000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>System and method of general purpose data replication between mated processors</title-of-invention>
</technical-information>
<continuity-data>
<non-provisional-of-provisional>
<document-id>
<doc-number>60295758</doc-number>
<document-date>20010604</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Edward</given-name>
<middle-name>J.</middle-name>
<family-name>Franckowiak</family-name>
</name>
<residence>
<residence-us>
<city>West Chicago</city>
<state>IL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Kenneth</given-name>
<middle-name>R.</middle-name>
<family-name>MacFarlane</family-name>
</name>
<residence>
<residence-us>
<city>Ijamsville</city>
<state>MD</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Kurt</given-name>
<middle-name>A.</middle-name>
<family-name>Vangsness</family-name>
</name>
<residence>
<residence-us>
<city>Geneva</city>
<state>IL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>FAY, SHARPE, FAGAN, MINNICH &amp; McKEE, LLP</name-1>
<name-2></name-2>
<address>
<address-1>Seventh Floor</address-1>
<address-2>1100 Superior Avenue</address-2>
<city>Cleveland</city>
<state>OH</state>
<postalcode>44114-2518</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A system and method of replicating changed data between an active process and a standby process is provided. The active and standby processes each include an application and a processor having memory. The method includes organizing active and standby processor memories into regions, with each region including one or more tuples, datamarking the tuples having changed data in the active processor corresponding to the active application, and transferring copies of the changed data from the active process to the standby process to replicate data between the active and standby processors. The system includes means for datamarking changed data and transferring copies of the changed data between active and standby processes having active and standby processors configured as mated pairs. The system can include a wireless cellular communication network having an active process including an active radio control software application running on an active processor and a standby process including a standby radio control software application running on a standby processor. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">CROSS REFERENCE TO RELATED APPLICATIONS </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application claims the benefit under 35 U.S.C. 119(e) of the provisional application Ser. No. 60/295,758 filed Jun. 4, 2001, which is hereby incorporated by reference herein.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to a system and method of data replication. More particularly, it relates to a system and method of replicating data between an active and standby mated processor pair for achieving high availability. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The present invention will be described in the context of a cellular wireless communication network, although it should be appreciated that the invention is applicable to a variety of mated processor systems and methods providing high availability. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> A typical cellular wireless communication networks is made up of a plurality of cells each occupying a separate geographical area. Each cell usually includes a cell site having known hardware necessary for providing wireless communication coverage to a plurality of wireless terminals within the cell. Examples of such hardware can include, but is not limited to, radio frequency transmitters and receivers, antenna systems, interface equipment and power sources. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> The cell site typically communicates with one or more application processors which handle access network resources such as radios, channels and the like within the cell. Software applications, known as Radio Control Software (RCS), running on these application processors manage the associated call and maintenance traffic to, from, and within the cell. Several cell sites typically communicate with a Mobile Switching Center (MSC) which switches cellular calls to wired central offices to enable mobile terminals to communicate with phones over the Public Switched Telephone Network (PSTN). </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The PSTN offers users the benefit of high availability of service which means call service interruptions are rare. As the use of wireless networks grows and the capacity of wireless networks increases, end users and service providers are becoming more concerned about increasing the availability of the processors and software applications which handle calls thereby reducing service interruptions for callers. Interruptions in wireless communication service can be created when hardware and/or software fails or is taken off line for repairs, maintenance, updates, etc. High availability of wireless communication services is sought to make cellular communications a viable alternative to PSTN. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> In an effort to achieve high availability, RCS application processors are paired to form mated processor pairs in an active/standby arrangement. When a fault occurs on the active processor, the standby process is elevated to the active role to continue providing service. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> In conventional data replication methods involving mated processor arrangements, the process taking over the active role typically performs a data diffing technique in which regions of memory are compared and areas that have changed are identified and sent to the standby process. Alternatively, the active process sends a bulk transfer of all current data to the standby process. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> However, these methods are not suitable for unplanned faults where the current active process fails. And for non-failure cases, these approaches introduce an interval during the switchover where all new activity must be suspended until the standby process is prepared to take over. These methods can also be CPU intensive, requiring significant processing resources, reducing the amount of normal application tasks the processors can handle while also replicating data. It is desirable to provide an improved system and method of data replication. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Not only should the system and method of data replication system assist in replicating data between the active and standby sides of an application as quickly and efficiently as possible, but it is also desirable to know at all times whether the standby side&apos;s data is consistent with that of the active side. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> Further, conventional hardware and software data replication solutions typically specify a transport protocol that the application must use. Also, existing implementations typically require strong typing of data and high application involvement in the replication process, for example requiring explicit copying of data in and out of replication buffers. Thus, these solutions are generally application specific which increases costs and prevents portability. It is desirable to provide a data replication solution which is not application specific and which enables the application to specify the transport protocol. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> According to the present invention, a new and improved system and method of replicating changed data between an active process and a standby process is provided. The active and standby processes each include an application and a processor having memory. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> In accordance with a first aspect of the invention, the method includes organizing active and standby processor memories into regions, with each region including one or more tuples, datamarking the tuples having changed data in the active processor corresponding to the active application, and transferring copies of the changed data from the active process to the standby process to replicate data between the active and standby processors. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> In accordance with a second aspect of the invention, the method also includes encoding the changed data into transport payloads for updates to the standby processor memory. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In accordance with another aspect of the invention, the organizing step also includes organizing the regions into priority groups and the encoding step includes encoding changed data according to the priority groups. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> In accordance with another aspect of the invention, the datamarking step includes mapping the range of addresses of the changed data and marking the mapped regions containing the changed tuples. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> In accordance with another aspect of the invention, a system is provided for replicating data. The system includes a mated pair of application processors including an active processor for running an active application and a standby processor for running a standby application. The active and standby processors each have corresponding memories divided into corresponding regions and tuples. The system includes datamarking means for mapping and marking tuples of data changed in the active processor memory, encoding means for encoding the changed data into transport payloads, and transferring means for transferring the changed data to the standby processor. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> In accordance with another aspect of the invention, the system can include a wireless cellular communication network having an active process including an active radio control software application running on an active processor and a standby process including a standby radio control software application running on a standby processor. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> The invention may take form in certain components and structures, preferred embodiments of which will be illustrated in the accompanying drawings wherein: </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram of a general purpose system for data replication between mated processor pairs in accordance with the invention; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram illustrating the invention; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram illustrating the encoding step shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is diagram illustrating a dataMark, logicalPush and physicalPush in accordance with the invention; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is diagram illustrating a fragmented physicalPush in accordance with the invention; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a block diagram illustrating the initialization step shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a block diagram illustrating resynchronization step shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>; and </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a block diagram illustrating datamarking step shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> It is to be understood that the specific devices and processes illustrated in the attached drawings, and described in the following specification are simply exemplary embodiments of the inventive concepts defined in the appended claims. As used herein, unless stated otherwise, the term process refers to one or more software applications and one or more associated application processors for running the software applications. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> The invention includes a Data Marking Library (DML), also known as a Data Replication Service (DRS), which is a general purpose system and method supporting replication of global application data between an active and standby process in a reliable processor pair and/or cluster. The invention provides a way for an arbitrary application to identify regions of data within the application that are to be replicated to the mate process so that the mate process becomes a &ldquo;hot&rdquo; standby process, ready to take over processing from the active process. By keeping a record of changes to data as the changes are made, the invention quickly and efficiently replicates the pertinent subset of data within the active process. This enables the standby process to take over the active role with a reduced level of initialization and reduces downtime resulting from the recovery of failures that impact the active application. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> The invention treats the application data as blocks of data within regions of memory, thereby providing the ability to replicate the data without having to know the structure of the data. The invention provides this functionality without specifying a transport. These features increase the portability of the invention across various applications and platforms. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> block diagram illustrating the relationship of an active DML instance <highlight><bold>10</bold></highlight> to an active process <highlight><bold>12</bold></highlight> and standby DML instance <highlight><bold>20</bold></highlight> a standby process <highlight><bold>22</bold></highlight> is shown. The active process <highlight><bold>12</bold></highlight> includes an active application <highlight><bold>14</bold></highlight> running on an active application processor <highlight><bold>16</bold></highlight>. The standby process <highlight><bold>22</bold></highlight> includes a standby application <highlight><bold>24</bold></highlight> running on a standby application processor <highlight><bold>26</bold></highlight>. More than one application <highlight><bold>14</bold></highlight>, <highlight><bold>24</bold></highlight> may run on an application processor. The DML instances <highlight><bold>10</bold></highlight>, <highlight><bold>20</bold></highlight> are shared libraries, part of application process space, which can be updated without rebuilding the applications <highlight><bold>14</bold></highlight> and <highlight><bold>24</bold></highlight> respectively. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> Each DML instance <highlight><bold>10</bold></highlight>, <highlight><bold>20</bold></highlight> has an identified role, active or standby, that changes its behavior. Usually, the roles are set to active or standby to match the roles of the corresponding application <highlight><bold>14</bold></highlight>, <highlight><bold>24</bold></highlight>. A special initRole is provided that is used by the application <highlight><bold>14</bold></highlight>, <highlight><bold>24</bold></highlight> to indicate that it is going through some level of initialization that invalidates the data that has been replicated as descried in further detail below. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The applications <highlight><bold>14</bold></highlight>, <highlight><bold>24</bold></highlight> can be any known applications for use in a high availability computing system having active and standby processors <highlight><bold>16</bold></highlight>, and <highlight><bold>26</bold></highlight>, though for the purposes of example which should not be considered as limiting, the preferred embodiment is described as a cellular wireless communication network. The preferred embodiment of the invention includes an active application processor <highlight><bold>16</bold></highlight> mated with a standby processor <highlight><bold>26</bold></highlight>, running RCS applications in active <highlight><bold>14</bold></highlight> and standby <highlight><bold>24</bold></highlight> modes respectively, within a CDMA/TDMA cellular wireless communications system. The mated processors <highlight><bold>16</bold></highlight>, <highlight><bold>26</bold></highlight> can be tightly paired in a specific pairing arrangement, or can be loosely paired as part of a processor cluster. The processors <highlight><bold>16</bold></highlight>, <highlight><bold>26</bold></highlight> can be located at the same location, such as for example a cell site, or different locations. Examples of such systems include, but are not limited to, an Autoplex Flexent system, Flexent RCS, and Flexent Mobility Server (FMS) manufactured by Lucent Technologies. The cellular system can include a variety of cellular configurations including, but not limited to, modular and/or microcell cellular systems. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> The active and standby processors <highlight><bold>16</bold></highlight>, <highlight><bold>26</bold></highlight> each include memories <highlight><bold>18</bold></highlight> and <highlight><bold>28</bold></highlight> respectively. In accordance with the invention, the active and standby memories <highlight><bold>18</bold></highlight>, <highlight><bold>28</bold></highlight> are divided into contiguous blocks called regions <highlight><bold>18</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>18</bold></highlight><highlight><italic>n</italic></highlight>, <highlight><bold>28</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>28</bold></highlight><highlight><italic>n </italic></highlight>that will be replicated. Each region <highlight><bold>18</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>18</bold></highlight><highlight><italic>n</italic></highlight>, <highlight><bold>28</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>28</bold></highlight><highlight><italic>n </italic></highlight>is further divided into one or more tuples, preferably of fixed length. For example, regions <highlight><bold>18</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>28</bold></highlight><highlight><italic>a </italic></highlight>include tuples <highlight><bold>18</bold></highlight><highlight><italic>a</italic></highlight><highlight><subscript>1</subscript></highlight>-<highlight><bold>18</bold></highlight><highlight><italic>a</italic></highlight><highlight><subscript>n</subscript></highlight>, and <highlight><bold>28</bold></highlight><highlight><italic>a</italic></highlight><highlight><subscript>1</subscript></highlight>-<highlight><bold>28</bold></highlight><highlight><italic>a</italic></highlight><highlight><subscript>n </subscript></highlight>respectively. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> A region <highlight><bold>18</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>18</bold></highlight><highlight><italic>n </italic></highlight>and <highlight><bold>28</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>28</bold></highlight><highlight><italic>n </italic></highlight>can be composed any suitable data structures, for example an array of structures, in which case the tuple is a single structure within the array. Each region <highlight><bold>18</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>18</bold></highlight><highlight><italic>n</italic></highlight>, <highlight><bold>28</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>28</bold></highlight><highlight><italic>n </italic></highlight>is identified by a unique region identifier which is defined by the application <highlight><bold>14</bold></highlight>, <highlight><bold>24</bold></highlight>, a starting address, a tuple size and a count of the number of tuples in the region. Regions may not overlap. Usually, a region is a single global data area within the application. For example, an array of structures with call status information would be a region. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Further, each active memory region <highlight><bold>18</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>18</bold></highlight><highlight><italic>n </italic></highlight>can be associated with one of <highlight><bold>32</bold></highlight> or more unique priority groups. The priority groups can be configured to prioritize the transmission of replicated data between the active and standby processes <highlight><bold>12</bold></highlight>, <highlight><bold>22</bold></highlight>, for example priority groups having a lower number will receive a higher priority with regards to the order of data transmission as described below. The active application <highlight><bold>14</bold></highlight> can also use this grouping to associate regions that have logical dependencies and need to be pushed to the standby process <highlight><bold>22</bold></highlight> at the same time. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> By dividing application memory into a set of regions identified by address, size and number of blocks as described below, the invention allows for application memory management without needing further details about the layout of the memory within each block and thus is not application specific. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The invention further includes an application specific transport <highlight><bold>40</bold></highlight> connecting the active process <highlight><bold>12</bold></highlight> with the standby process <highlight><bold>22</bold></highlight>. The invention does not specify how the replicated data is transmitted between the active and standby processes. Rather, the active application <highlight><bold>14</bold></highlight>, or alternatively a plug-in module <highlight><bold>42</bold></highlight>, specifies the transport as described below. The data can be transmitted using any suitable known data transmission protocol and/or hardware, including but not limited to TCP/IP, UDP, or Frame relay. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 2, a</cross-reference> method of replicating data between an active process <highlight><bold>12</bold></highlight> and a standby process <highlight><bold>22</bold></highlight> is shown generally at <highlight><bold>50</bold></highlight>. The method includes initializing the active and standby DML instances <highlight><bold>10</bold></highlight>, <highlight><bold>20</bold></highlight> at step <highlight><bold>52</bold></highlight>. Initialization <highlight><bold>52</bold></highlight>, which shall be described in further detail below, includes specifying each region of memory that may be replicated by identifying the region starting address, tuple length and total number of tuples. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The DML <highlight><bold>10</bold></highlight>, <highlight><bold>20</bold></highlight> also performs a series of initialization steps to validate DML and application versions and to establish an initial pump of the application data to the standby process <highlight><bold>22</bold></highlight>. During initialization <highlight><bold>52</bold></highlight>, the active application <highlight><bold>14</bold></highlight> can operate normally, providing service and changing its data. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> When the active application <highlight><bold>14</bold></highlight> changes data within the regions of the active processor memory <highlight><bold>18</bold></highlight>, as shown at step <highlight><bold>54</bold></highlight>, the changes to the tuple(s) are noted by a dataMark interface at <highlight><bold>56</bold></highlight> as described in further detail below. With the dataMark interface <highlight><bold>56</bold></highlight>, the active DML instance <highlight><bold>10</bold></highlight> quickly makes a note of this change. For example, on a GNP-Application Processor in a cellular network, the implementation of dataMark can takes less than 50 uSec to execute. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> At regular intervals, as determined by the active application <highlight><bold>14</bold></highlight>, when the changes to the application data are complete and consistent as shown at <highlight><bold>58</bold></highlight>, the application invokes a logicalPush as shown at <highlight><bold>60</bold></highlight>. Data consistency <highlight><bold>58</bold></highlight> is determined by the application <highlight><bold>14</bold></highlight> in any suitable known manner. The logicalPush <highlight><bold>60</bold></highlight> encodes the changed data for a group of regions into transport payloads and requests that the active DML instance <highlight><bold>10</bold></highlight> transfer the accumulated changes to the standby process <highlight><bold>22</bold></highlight>. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The frequency of invocations of the logicalPush interface <highlight><bold>60</bold></highlight> determines how current the standby process <highlight><bold>22</bold></highlight> is with respect to the active process <highlight><bold>12</bold></highlight>. The frequency of invocations also determines the volume of data that must be pushed, with more frequent invocations resulting in smaller amounts of data transferred per invocation. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the logicalPush <highlight><bold>60</bold></highlight> is described in further detail. The logicalPush examines the set of marked data associated with each priority group, starting with the lowest group number, and encodes copies of the changed data at <highlight><bold>62</bold></highlight>. The encoding assumes that both processors <highlight><bold>16</bold></highlight>, <highlight><bold>26</bold></highlight> are the same including the same byte ordering, and same alignment rules. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> The data is encoded as a series of updates at <highlight><bold>64</bold></highlight> with a header identifying the region, the starting offset and the length of the update (multiple tuple updates are possible when consecutive tuples have been data marked). As regions are encoded, the associated data marks, which indicate which tuples have changes, are copied to a physical bit vector. The physical bit vector tracks the changed tuples that have been encoded. Once a changed tuple has been encoded, the logical bit vector datamark is cleared at <highlight><bold>66</bold></highlight>, since that tuple is now encoded for transport. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Next, the application specific transport is invoked at <highlight><bold>68</bold></highlight> to handle the transfer one or more payloads of replicated data to the standby process <highlight><bold>22</bold></highlight>. The active application registers a callback function that provides the association between the DML code and the actual transport. The function provides an interface that allows a buffer of data of a specified length to be sent. The function returns an indication of success or failure using a set of return codes. The active application <highlight><bold>14</bold></highlight> handles all aspects of setting up any connection between the active <highlight><bold>12</bold></highlight> and standby <highlight><bold>22</bold></highlight> processes and/or routing the data to the standby process <highlight><bold>22</bold></highlight>. Any connection setup is done by the active application <highlight><bold>14</bold></highlight> prior to DML initialization. Once the application specified transport send function is called, DML assumes that the data has been sent to the standby process <highlight><bold>22</bold></highlight> and will await an acknowledgment. Failure to transmit will result in recovery actions to reinitialize affected regions or resynchronization of the active and standby. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Next, a physical push occurs at <highlight><bold>70</bold></highlight> in which the copies of the changed data is transferred to the standby process <highlight><bold>22</bold></highlight> where the changes are applied directly to the standby processor&apos;s memory <highlight><bold>28</bold></highlight> via updates. A physical push <highlight><bold>70</bold></highlight> occurs when a logical push <highlight><bold>60</bold></highlight> is requested and necessary performance constraints have been met. Such constraints can include a metric of minimum data to be sent. Thus, a logical push <highlight><bold>60</bold></highlight> may not result in a physical push <highlight><bold>70</bold></highlight> if only a small amount of data has been marked prior to the logical push call. Instead, the physical transfer may be postponed to bundle up the changes until predetermined number of changes have accumulated, or some predetermined time interval has elapsed. A diagram illustrating the commands passed for the datamark <highlight><bold>56</bold></highlight>, logical push <highlight><bold>60</bold></highlight> and physical push <highlight><bold>70</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> The standby application receives the changed data and may de-multiplex the received data from other received messages if necessary in any known manner. A multi-threaded application might dedicate a socket to DML traffic, or if a single socket is used, an application header would be used to identify DML specific messages. The standby processor memory then receives the changed data via updates at <highlight><bold>72</bold></highlight>. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> After completion of the physical push at <highlight><bold>70</bold></highlight>, the standby DML instance <highlight><bold>20</bold></highlight> returns an acknowledgement message to the active DML instance <highlight><bold>10</bold></highlight> indicating completion. Alternatively, the acknowledgement behavior may be specified so that only 1 of every N physical pushes are acknowledged. The acknowledgement is noted by invoking the DML receive method to pass the payload down to DML where the acknowledgement is noted thereby preventing a subsequent timeout that will occur when an ACK is not received within an application specified interval. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 5, a</cross-reference> diagram is shown illustrated a fragmented physical push. If the encoded data for the physical push is larger than a single frame in the application transport buffer, the data can be fragmented across several payload frames as shown at <highlight><bold>70</bold></highlight>&prime;. The size of each fragment, as defined by a maxBufSize command, can vary according to the specific application transport employed. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> The individual fragments contain sequence numbers and the last fragment contains an indication that it is the final fragment. If the physical push spans multiple frames, the fragments are stored until the final frame is received. At that point, if all fragments have been received, the data is decoded and the standby processor memory is updated. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the initialization step <highlight><bold>52</bold></highlight> is described in further detail. Initialization of the active DML instance <highlight><bold>10</bold></highlight> includes a series of one time only steps to initialize the DML. Initialization is also performed between the active DML instance <highlight><bold>10</bold></highlight> and the standby DMK instance <highlight><bold>20</bold></highlight>. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> The DML instance initialization consists of a series of calls to the active DML instance <highlight><bold>10</bold></highlight> to set parameters, register application callbacks and register application regions. The DML instance contains a static reference to the DML object, so no construction of the object by the application is necessary. The active application <highlight><bold>14</bold></highlight> first specifies required and optional parameters at <highlight><bold>80</bold></highlight> to control the operation of the DML instance <highlight><bold>10</bold></highlight>, <highlight><bold>20</bold></highlight>. Next, a series of callback functions are registered from the active application <highlight><bold>14</bold></highlight> to the active DML instance <highlight><bold>10</bold></highlight> using the registercallbacks method at <highlight><bold>82</bold></highlight>. The only required callback is the application transport send function. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> The active application <highlight><bold>14</bold></highlight> next registers all regions of memory that it wishes to participate in replication at <highlight><bold>84</bold></highlight>. The application specifies the type of method used to perform the data replication, such as DataMark described herein. Alternatively RawCopy provides for data replication where an entire region or subset of a region is unconditionally copied to the standby process <highlight><bold>22</bold></highlight>. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The active application also assigns a regionid such as an integer number to uniquely identify the region. The active application <highlight><bold>14</bold></highlight> also assigns an priorityGroup ID, such as an integer to identify which priority group the region belongs to. The starting address of each region, tuple length and number of tuples in the region are also identified. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> At this time, all one-time startup initialization of the DML is complete and the active DML instance enters a quiescent state and no communication occurs between the active and standby DML instances <highlight><bold>10</bold></highlight>, <highlight><bold>20</bold></highlight>. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> When the active application <highlight><bold>14</bold></highlight> determines which of the mated pair of processors <highlight><bold>16</bold></highlight>, <highlight><bold>26</bold></highlight> is active, it informs the active DML <highlight><bold>10</bold></highlight> of this role change at <highlight><bold>86</bold></highlight>. This step triggers a sequence of events that perform the remaining steps necessary for the DML to complete initialization and enter a state where normal data replication can be performed. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> In the first step, the PushValidate exchange, the active DML instance <highlight><bold>10</bold></highlight> sends the internal DML version, the application version and a sequence of entries describing each registered region to the standby DML instance <highlight><bold>20</bold></highlight> at <highlight><bold>88</bold></highlight>. The active DML instance <highlight><bold>10</bold></highlight> will attempt to send this message to the standby DML instance <highlight><bold>20</bold></highlight> once during each predetermined interval which is set using a initInteval command. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> When the standby DML instance <highlight><bold>20</bold></highlight> is able to receive this message, the DML examines the internal DML version information and checks it for compatibility with the version running on the standby DML instance <highlight><bold>20</bold></highlight> at <highlight><bold>90</bold></highlight>. If the versions are compatible, the application-supplied version is compared. If the application version check returns true, the version check is completed and a successful return is sent back to the active DML instance <highlight><bold>10</bold></highlight>. If the versions were not compatible, a version mismatch is indicated and both the active and standby DML instances notify the active application <highlight><bold>14</bold></highlight> with a status of DrsVersionMismatch. After the successful version check, the active DML begins the resynchronization portion of initialization at <highlight><bold>92</bold></highlight> described below. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Occasionally the DML needs to resynchronize the standby process memory <highlight><bold>28</bold></highlight> with the active process memory <highlight><bold>18</bold></highlight>. During resynchronization <highlight><bold>92</bold></highlight>, shown in further detail in <cross-reference target="DRAWINGS">FIG. 7, a</cross-reference> copy of the contents of the registered regions of the active processor memory <highlight><bold>18</bold></highlight> is sent to the standby processor memory <highlight><bold>28</bold></highlight>, using the Data Pump method described below, to establish a starting point for subsequent changes. The active DML walks through the active application memory <highlight><bold>18</bold></highlight> in round-robin fashion and sends contiguous blocks of memory to the standby processor memory <highlight><bold>28</bold></highlight>, also clearing any data marks for the sent regions as it goes. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> There are a number of scenarios that can lead to a resynchronization <highlight><bold>92</bold></highlight>, including initial startup of either the active or standby process <highlight><bold>12</bold></highlight>, <highlight><bold>22</bold></highlight>, as described above, or a restart of the standby application process <highlight><bold>22</bold></highlight> during which the standby process will lose all replicated data upon restart. As a recovery from certain error conditions, a partial resynchronization can be performed for only a subset of all registered priority groups. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> A complete copy of the active processor memory <highlight><bold>28</bold></highlight> registered by the application is sent to the standby process <highlight><bold>22</bold></highlight> during resynchronization <highlight><bold>92</bold></highlight>. During this interval, the standby application cannot take over the active role without performing an application reinitialization. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> During a resynchronization <highlight><bold>92</bold></highlight>, the standby process <highlight><bold>22</bold></highlight> regards its copy of the data as inconsistent, and continues to do so until resynchronization is complete. During the resynchronization interval, the active application <highlight><bold>14</bold></highlight> will be providing service and will likely be changing the replicated memory and, therefore, calling the dataMark method to note the changes. While the resynchronization is in progress, data marked changes will be pushed to the standby process <highlight><bold>22</bold></highlight> via logicalPush. These pushes can serve to delay the completion of resynchronization, but they do not impact the consistency of the data between the active and standby processes, and therefore, upon completion of resynchronization, the data is consistent between the active and standby processes. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> The Data Pump phase sends the blocks of application memory during resynchronization. Data Pump can be constrained at <highlight><bold>94</bold></highlight> by maxResynchSize which sets the maximum size of data and resynchFrequency parameters which sets the frequency of replication. The active application <highlight><bold>14</bold></highlight> can tune these parameters to find the appropriate tradeoff between the resynchronization interval, and CPU and network traffic overhead. For example, a resynchFrequency of 10 milliseconds and a maxResynchSize of 20K will mean that the application will transfer 2 Mbytes/sec. The application will also utilize more CPU and will contribute a large amount of traffic to the application transport <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> As the Data Pump phase is progressing, the active DML instance <highlight><bold>20</bold></highlight> clears any marked data as it sends the tuples at <highlight><bold>96</bold></highlight>. If the tuple isn&apos;t marked again during the Data Pump phase, it is not resent, thereby avoiding sending the same tuple(s) more than once. Each segment of the Data Pump is transmitted without any acknowledgment expected from the standby application. Each segment contains a sequence number at 98 that is tracked by the standby DML at 100 to determine that all data segments have arrived. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> As each frame of data arrives at the standby DML instance <highlight><bold>20</bold></highlight>, it is applied to the standby processor memory <highlight><bold>28</bold></highlight>. When all of the application data has been sent, and DML has completed one pass through all of the active application memory <highlight><bold>18</bold></highlight>, a final indication is sent and, upon receipt of the final indication, the standby DML instance <highlight><bold>20</bold></highlight> verifies that all segments of the Data Pump phase arrived and were successfully applied to standby processor memory <highlight><bold>28</bold></highlight>. At this point, the standby instance returns a PushSynchAck message at <highlight><bold>102</bold></highlight> to inform the active side of completion of the Data Pump phase. If the PushSynchAck message is lost, or if it indicates a failure, the active side will initiate a re-initialization. If all went well, the active DML instance <highlight><bold>10</bold></highlight> will notify the active application by invoking the statusCallback with a status value of DrsStatNormal. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, the datamarking interface <highlight><bold>56</bold></highlight> and method of datamarking is described in further detail. When the active application <highlight><bold>14</bold></highlight> makes a change to memory <highlight><bold>18</bold></highlight> that has been registered as described above, it calls dataMark <highlight><bold>56</bold></highlight> to track the changes. A record(s) of the changes to the data is made to indicate that the associated data changes will need to be pushed to the standby process <highlight><bold>22</bold></highlight> at some later time. Any suitable record can be made, one example which should not be considered limiting includes using a dirty bit. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> The changes are tracked on a tuple basis. The application <highlight><bold>14</bold></highlight> passes an address to dataMark at <highlight><bold>106</bold></highlight>, which could be the address of the changed tuple or a field within the changed tuple. The active DML instance <highlight><bold>10</bold></highlight> maps the range of addresses to a region or regions of memory registered by the active application <highlight><bold>14</bold></highlight> at <highlight><bold>107</bold></highlight> and marks the region(s) at <highlight><bold>108</bold></highlight>. Any suitable mapping method can be used. For example, the preferred embodiment uses a utilizes a known balanced binary tree, which insures that the depth of all branches of the tree differs by no more than 2 levels. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> On a successful dataMark, when the region associated with the address has been found, the change is tracked. In the preferred embodiment, a variable length bit vector is used, where each bit represents a tuple in the region. This approach works well for regions with smaller numbers of tuples. Another approach includes using a known linked list. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> As the region is marked, also referred to as datamarked, a count of the amount of marked data is tracked based on the priority group to which it belongs at <highlight><bold>110</bold></highlight>. When the amount marked in a priority group exceeds a threshold, as determined at <highlight><bold>112</bold></highlight>, the active application <highlight><bold>14</bold></highlight> is signaled at <highlight><bold>114</bold></highlight> that a logicalPush should be performed for that priority group soon to avoid the risk exceeding the amount of marked data in a priority group that can be encoded and transmitted. The maximum amount can be defined by the maxTransmitSize parameter. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> As indicated at <highlight><bold>116</bold></highlight>, if the marked data accumulated for a priority group would encode to a size greater than the maximum size defined by maxTransmitSize, an overflow condition occurs at <highlight><bold>118</bold></highlight> and dataMark throws a DrsExceptionTxOverflow exception. When the overflow condition is reached, a subsequent call to logicalPush will trigger resynchronization of the application memory from the active processor <highlight><bold>16</bold></highlight> to the standby processor <highlight><bold>26</bold></highlight> as described above at <highlight><bold>92</bold></highlight>. A partial resynchronization involving only the affected priority group(s) can be performed. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> The system and method of data replication of the invention not only assists in replicating data between the active and standby processes as quickly and efficiently as possible, but enables the active application <highlight><bold>14</bold></highlight> to know at all times whether the standby process&apos;s data is consistent with that of the active process. When events occur that are a clear indication that consistency no longer exists, actions are taken to restore consistency as quickly as possible using resynchronization <highlight><bold>92</bold></highlight> as described above. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> A further step taken to ensure data consistency is a data audit. A data audit is an optional capability to send portions of the active memory to the standby side for comparison at the standby side. The application can choose if the audit will be disabled, or if the audit will perform comparisons and report errors with no changes to the standby memory or if the standby memory is to be overwritten. The portions of active memory to send are controlled by application specified parameters. Only tuples that have not been data marked are sent to the standby process in the data audit. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> DML also performs a periodic heartbeat, sending information from the active application to the standby side so that the standby side can detect when it has missed a physical push or has lost communication with the active side. This information is used to provide parameters to the active application <highlight><bold>14</bold></highlight> used in deciding how &ldquo;stale&rdquo; the replicated data is within the standby process. The heartbeat message is sent every predetermined interval, as determined by heartbeatInterval. The interval is typically a few tens of milliseconds, although any suitable interval may be used. By default, the heartbeat only contains the current physical push sequence number, so that missed pushes can be detected, and status change requests from the active to the standby. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> The application can optionally specify that the heartbeat message also carries audit information described above. The data audit could be useful for in lab testing to verify that data marking is being performed correctly by the application and that DML is replicating data correctly. The audit cycles through the registered regions in the active application and encodes data that corresponds to unmarked data. The audit data is sent with the heartbeat with a special flag set in the heartbeat header to indicate that audit data follows the heartbeat message. On the standby side, upon receipt of this heartbeat message, the application memory is compared to the raw memory in the audit and if there is a mismatch, a diagnostic message is generated. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> When the standby application is promoted to active, it must determine if the data that it has is safe to use or if a reinitialization is necessary. The standby application can use two DML capabilities in making this determination. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> The replicated data is considered invalid if the resynchronization that accompanies a reinitialization has not yet completed, or did not complete successfully, or if at some point the active application <highlight><bold>14</bold></highlight> declared this data to be invalid. In these cases, the standby application <highlight><bold>24</bold></highlight> should not use the replicated data. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> The standby application <highlight><bold>24</bold></highlight> also needs to be able to determine if its copy of the data from the active application <highlight><bold>14</bold></highlight> is up to date. The invention provides two metrics that can be used by the application to determine how recently the data was updated and if some number of updates were lost. The stale( ) interface returns true if the last update to the standby application was longer than a predetermined interval defined by a staleTimeout value as specified by the active application <highlight><bold>14</bold></highlight>. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> The stale( ) interface also returns the number of physical pushes that were missed and the number of milliseconds that have elapsed since the last update to the standby processor memory <highlight><bold>28</bold></highlight> in the arguments to the function. The missed physical push and last update parameters are reset to 0, after completion of a resynchronization or after the standby application is transitioned to Active. This information is used to decide if the replicated data is recent enough to use or if some level of audit or resynchronization should be performed before the standby application transitions to the active application using the replicated data. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> It is desirable that new versions of DML can be installed by updating a shared library on a field installation. This goal can be served by separating the DML interface from it&apos;s implementation, since such a separation can help make it less likely that an implementation change leads to an interface change. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> The invention has been described with reference to preferred embodiments. Obviously, modifications and alterations will occur to others upon reading and understanding the preceding specification. It is intended that the invention be construed as including all such modifications and alterations insofar as they come within the scope of the appended claims or the equivalents thereof. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of replicating changed data between an active process including an application and processor having memory and a standby process including an application and processor having memory comprising: 
<claim-text>organizing active and standby processor memories into regions, each region including one or more tuples; </claim-text>
<claim-text>datamarking tuples having changed data in the active processor corresponding to the active application; </claim-text>
<claim-text>transferring copies of the changed data from the active process to the standby process to replicate data between the active and standby processors. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising the step of encoding the changed data into transport payloads, and the transferring step further comprises transferring the payloads. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference> wherein the encoding step further comprises encoding the changed data as updates, and the transferring step includes updating the standby processor memory with the changed data. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein the organizing step further comprises organizing the regions into priority groups and the encoding step includes encoding changed data according to the priority groups. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> wherein the encoding step further comprises encoding data with an update header identifying region, starting offset and length of the update. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the datamarking step further comprises mapping the range of addresses of the changed data. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> further including marking the mapped regions containing the changed tuples. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference> wherein the mapping step includes utilizing a balanced binary tree. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference> wherein the datamarking step further includes counting the amount of marked data and tracking the counts for each priority group. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference> further including signaling for the encoding step when the amount of marked data exceeds a threshold. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein the datamarking step further comprises copying the datamarks to physical bit vectors and clearing logical bit vector datamarks after the data is encoded in the encoding step. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising resynchronizing the standby process memory with the active process memory by copying and transferring contiguous blocks of memory from the active processor memory to the standby processor memory. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference> wherein the resynchronizing step further comprises clearing data marks for the sent regions. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising the step of performing a data audit comprising sending portions of the active processor memory which have not been datamarked to the standby process and comparing the sent portions with the corresponding portions of the standby processor memory. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference> further comprising reporting errors to the active application without changing the standby memory. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference> further comprising overwriting the corresponding portions of the standby processor memory. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising sending a periodic heartbeat message from the active process to the standby process, wherein the heartbeat message includes the current physical push sequence number for detecting missed pushes of replicated data. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> wherein the heartbeat message further includes audit information including data not having been datamarked for comparison with the standby processor memory. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A method of replicating changed data in a cellular wireless communication network between an active process including an active radio control software application and an active application processor having memory and a standby process including a standby radio control software application and a standby application processor having memory comprising: 
<claim-text>organizing the active and standby application processor memories into regions, each region including one or more tuples; </claim-text>
<claim-text>datamarking the tuples having changed data in the active application processor corresponding to the active radio control software application; </claim-text>
<claim-text>transferring copies of the changed data from the active process to the standby process to replicate data between the active and standby application processors. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> wherein the cellular wireless communication network is a CDMA network. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The method of replicating changed data defined in <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference> wherein the cellular wireless communication network is a TDMA network. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. A system for replicating data comprising: 
<claim-text>a mated pair of application processor including an active processor for running an active application and a standby processor for running a standby application, the active and standby processors each having corresponding memories divided into corresponding regions and tuples; </claim-text>
<claim-text>datamarking means for mapping and marking tuples of data changed in the active processor memory; </claim-text>
<claim-text>encoding means for encoding the changed data into transport payloads; and </claim-text>
<claim-text>transferring means for transferring copies of the changed data to the standby processor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The system for replicating data defined in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference> wherein the transferring means is specified by the active application. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The system for replicating data defined in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference> wherein the encoding means encodes the changed data as updates, and further comprising updating means for updating the standby processor memory with the changed data. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The system for replicating data defined in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference> wherein the datamarking means maps the range of addresses of the changed data. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The system for replicating data defined in <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference> wherein the datamarking means marks the mapped regions containing the changed tuples. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The system for replicating data defined in <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference> wherein the datamarking means utilizes a balanced binary tree. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The system for replicating data defined in <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference> wherein the datamarking means counts the amount of marked data and tracks the counts by priority groups. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The system for replicating data defined in <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference> wherein the datamarking means signals the encoding means when the amount of marked data exceeds a threshold. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The system for replicating data defined in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference> wherein the system is a cellular wireless communication system. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. A cellular wireless communication system for replicating data comprising: 
<claim-text>a mated pair of application processors including an active processor for running an active application and a standby processor for running a standby application, the active and standby processors each having corresponding memories divided into corresponding regions and tuples; </claim-text>
<claim-text>datamarking means for mapping and marking tuples of data changed in the active processor memory; </claim-text>
<claim-text>encoding means for encoding the changed data into transport payloads; and </claim-text>
<claim-text>transferring means for transferring the changed data to the standby processor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. The cellular wireless communication system defined in <dependent-claim-reference depends_on="CLM-00033">claim 31</dependent-claim-reference> wherein the cellular system is a CDMA cellular system. </claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. The cellular wireless communication system defined in <dependent-claim-reference depends_on="CLM-00033">claim 31</dependent-claim-reference> wherein the cellular system is a TDMA cellular system. </claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. The cellular wireless communication system defined in <dependent-claim-reference depends_on="CLM-00033">claim 31</dependent-claim-reference> wherein the active and standby applications are Radio Control Software instances.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005356A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005356A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005356A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005356A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005356A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005356A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030005356A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030005356A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030005356A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
