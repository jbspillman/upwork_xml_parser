<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001825A1-20030102-M00001.NB SYSTEM "US20030001825A1-20030102-M00001.NB" NDATA NB>
<!ENTITY US20030001825A1-20030102-M00001.TIF SYSTEM "US20030001825A1-20030102-M00001.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00000.TIF SYSTEM "US20030001825A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00001.TIF SYSTEM "US20030001825A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00002.TIF SYSTEM "US20030001825A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00003.TIF SYSTEM "US20030001825A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00004.TIF SYSTEM "US20030001825A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00005.TIF SYSTEM "US20030001825A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00006.TIF SYSTEM "US20030001825A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00007.TIF SYSTEM "US20030001825A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00008.TIF SYSTEM "US20030001825A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00009.TIF SYSTEM "US20030001825A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00010.TIF SYSTEM "US20030001825A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00011.TIF SYSTEM "US20030001825A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00012.TIF SYSTEM "US20030001825A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00013.TIF SYSTEM "US20030001825A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00014.TIF SYSTEM "US20030001825A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00015.TIF SYSTEM "US20030001825A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00016.TIF SYSTEM "US20030001825A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00017.TIF SYSTEM "US20030001825A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00018.TIF SYSTEM "US20030001825A1-20030102-D00018.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00019.TIF SYSTEM "US20030001825A1-20030102-D00019.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00020.TIF SYSTEM "US20030001825A1-20030102-D00020.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00021.TIF SYSTEM "US20030001825A1-20030102-D00021.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00022.TIF SYSTEM "US20030001825A1-20030102-D00022.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00023.TIF SYSTEM "US20030001825A1-20030102-D00023.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00024.TIF SYSTEM "US20030001825A1-20030102-D00024.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00025.TIF SYSTEM "US20030001825A1-20030102-D00025.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00026.TIF SYSTEM "US20030001825A1-20030102-D00026.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00027.TIF SYSTEM "US20030001825A1-20030102-D00027.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00028.TIF SYSTEM "US20030001825A1-20030102-D00028.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00029.TIF SYSTEM "US20030001825A1-20030102-D00029.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00030.TIF SYSTEM "US20030001825A1-20030102-D00030.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00031.TIF SYSTEM "US20030001825A1-20030102-D00031.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00032.TIF SYSTEM "US20030001825A1-20030102-D00032.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00033.TIF SYSTEM "US20030001825A1-20030102-D00033.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00034.TIF SYSTEM "US20030001825A1-20030102-D00034.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00035.TIF SYSTEM "US20030001825A1-20030102-D00035.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00036.TIF SYSTEM "US20030001825A1-20030102-D00036.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00037.TIF SYSTEM "US20030001825A1-20030102-D00037.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00038.TIF SYSTEM "US20030001825A1-20030102-D00038.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00039.TIF SYSTEM "US20030001825A1-20030102-D00039.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00040.TIF SYSTEM "US20030001825A1-20030102-D00040.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00041.TIF SYSTEM "US20030001825A1-20030102-D00041.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00042.TIF SYSTEM "US20030001825A1-20030102-D00042.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00043.TIF SYSTEM "US20030001825A1-20030102-D00043.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00044.TIF SYSTEM "US20030001825A1-20030102-D00044.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00045.TIF SYSTEM "US20030001825A1-20030102-D00045.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00046.TIF SYSTEM "US20030001825A1-20030102-D00046.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00047.TIF SYSTEM "US20030001825A1-20030102-D00047.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00048.TIF SYSTEM "US20030001825A1-20030102-D00048.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00049.TIF SYSTEM "US20030001825A1-20030102-D00049.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00050.TIF SYSTEM "US20030001825A1-20030102-D00050.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00051.TIF SYSTEM "US20030001825A1-20030102-D00051.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00052.TIF SYSTEM "US20030001825A1-20030102-D00052.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00053.TIF SYSTEM "US20030001825A1-20030102-D00053.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00054.TIF SYSTEM "US20030001825A1-20030102-D00054.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00055.TIF SYSTEM "US20030001825A1-20030102-D00055.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00056.TIF SYSTEM "US20030001825A1-20030102-D00056.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00057.TIF SYSTEM "US20030001825A1-20030102-D00057.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00058.TIF SYSTEM "US20030001825A1-20030102-D00058.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00059.TIF SYSTEM "US20030001825A1-20030102-D00059.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00060.TIF SYSTEM "US20030001825A1-20030102-D00060.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00061.TIF SYSTEM "US20030001825A1-20030102-D00061.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00062.TIF SYSTEM "US20030001825A1-20030102-D00062.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00063.TIF SYSTEM "US20030001825A1-20030102-D00063.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00064.TIF SYSTEM "US20030001825A1-20030102-D00064.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00065.TIF SYSTEM "US20030001825A1-20030102-D00065.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00066.TIF SYSTEM "US20030001825A1-20030102-D00066.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00067.TIF SYSTEM "US20030001825A1-20030102-D00067.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00068.TIF SYSTEM "US20030001825A1-20030102-D00068.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00069.TIF SYSTEM "US20030001825A1-20030102-D00069.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00070.TIF SYSTEM "US20030001825A1-20030102-D00070.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00071.TIF SYSTEM "US20030001825A1-20030102-D00071.TIF" NDATA TIF>
<!ENTITY US20030001825A1-20030102-D00072.TIF SYSTEM "US20030001825A1-20030102-D00072.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001825</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10164648</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020610</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>10-160302</doc-number>
</priority-application-number>
<filing-date>19980609</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>10-215321</doc-number>
</priority-application-number>
<filing-date>19980730</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>10-230960</doc-number>
</priority-application-number>
<filing-date>19980817</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>11-133795</doc-number>
</priority-application-number>
<filing-date>19990514</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G09G005/00</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G09G005/08</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>345</class>
<subclass>173000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Coordinate position inputting/detecting device, a method for inputting/detecting the coordinate position, and a display board system</title-of-invention>
</technical-information>
<continuity-data>
<continuations>
<continuation-of>
<parent-child>
<child>
<document-id>
<doc-number>10164648</doc-number>
<kind-code>A1</kind-code>
<document-date>20020610</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09328402</doc-number>
<document-date>19990609</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>GRANTED</parent-status>
<parent-patent>
<document-id>
<doc-number>6421042</doc-number>
<country-code>US</country-code>
</document-id>
</parent-patent>
</parent-child>
</continuation-of>
</continuations>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Katsuyuki</given-name>
<family-name>Omura</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Takao</given-name>
<family-name>Inoue</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>OBLON SPIVAK MCCLELLAND MAIER &amp; NEUSTADT PC</name-1>
<name-2>FOURTH FLOOR</name-2>
<address>
<address-1>1755 JEFFERSON DAVIS HIGHWAY</address-1>
<city>ARLINGTON</city>
<state>VA</state>
<postalcode>22202</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The coordinate-position inputting/detecting device comprises a lighting device for emitting light into an entry area into which an arbitrary pointing body is inserted to perform an entry operation. At least two image pickup devices are provided with a prespecified space therebetween on a peripheral section of the entry area for picking up images of the pointing body illuminated by the light from the lighting device. Position on the CCD of the image pickup devices where an image of the pointing body is formed is obtained according to output from each of the image pickup devices. Coordinates of the position of the pointing body in the entry area are calculated from these positions. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present invention relates to a method and device for inputting/detecting the coordinate position and a display board system and more particularly, to a method and device for enabling input and/or detection of coordinates of not only a two-dimensional position but also a three-dimensional position with improved operability as well as a display board system which uses the coordinate-position inputting/detecting device. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Conventionally there has been known a display board which can read freehand information written on a whiteboard or on a writing surface of a writing sheet with some writing tool using a dedicated scanner and output the read information onto a recording paper with a dedicated printer. While, in recent years, there has also been suggested a display board system in which a coordinate-position inputting/detecting device is provided in a writing surface of a display board for enabling inputting of freehand information written in the writing surface in real time. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> For instance, the Soft Board manufactured and provided by the Microfield Graphics, Inc. is a device having a coordinate-position inputting/detecting device provided on a whiteboard. This Soft Board can acquire visual data such as characters and pictures drawn on the whiteboard into a computer in real time. With the display board system using this Soft Board, it is possible to input visual data captured with the Soft Board into a computer for displaying the data on a CRT thereof. The data may be displayed on a large-sized screen using a liquid crystal projector, or the data may be printed on a recording paper using a printer. It is also possible to project an image on a screen of a computer with the Soft Board connected thereto onto the Soft Board with a liquid crystal projector and operate the computer on the screen of the Soft Board. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> There has also been disclosed a display board system having a display unit for displaying characters and images thereon, a coordinate-position inputting/detecting device with a coordinate-position input surface (a touch screen) provided on a front surface of the display unit, and a control unit for providing controls over display by the display unit according to input from the coordinate-position inputting/detecting device. This system forms a display surface and a writing surface of the display board by making use of the display unit and the coordinate-position inputting/detecting device. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> For instance, in case of the Smart 2000 manufactured and supplied by the SMART Technologies Inc., when an image of a character, a picture, or a graphics is projected with a liquid crystal projector connected to a computer onto a panel, freehand information is captured into the computer using a coordinate-position inputting/detecting device (writing surface) provided on a front surface of the projection surface (display surface) of the panel. Then, the freehand information is synthesized with the image information in the computer, and the synthesized information can be displayed again with the liquid crystal projector in real time. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The display board system can display an image inputted by the coordinate-position inputting/detecting device that is superimposed on an image on the screen displayed by the display unit as an overwritten. Because of this characteristics, this display board system has been used in conferences, presentations, or for educational purposes and its effect in actual use has been highly evaluated. When a communicating function for transferring audio or video data is integrated with the display board system as described above, the display board system can also be used as an electronic conference system by connecting remote sites with a communication line. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> By the way, as a coordinate-position inputting/detecting device used in the display board system as described above, devices described below are known according to a difference between input methods thereof. As a first case, there is an optical coordinate-position inputting/detecting device disclosed in Japanese Patent Laid-Open Publication No. HEI 8-240407. This coordinate-position inputting/detecting device has two infrared CCD cameras and these cameras detect a peak signal of an infrared ray from the infrared LED provided on a pen-type pointing body inserted in a coordinate-position entry area with the infrared CCD camera to compute a coordinate position pointed by the pointing body. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> As a second case, there is an optical coordinate-position inputting/detecting device disclosed in Japanese Patent Laid-Open Publication No. HEI 9-319501. In this coordinate-position inputting/detecting device, the coordinate entry area is scanned with a laser beam. A pen pen-type pointing body with a corner cube reflector as a recursive reflecting member provided thereon is inserted into the coordinate entry area and an arbitrary position is pointed thereby. Light is recursively reflected by the pointing body. The reflected light is received by a plurality of light-receiving elements and a position pointed by the pointing body is computed. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> With the coordinate-position inputting/detecting device in the above mentioned case, however, as a dedicated pointing body is required for pointing to an arbitrary position in the coordinate entry area, an input operation with, for example, a fingertip, is not allowed, which is inconvenient. Furthermore, when the dedicated pointing body is lost or damaged, the input operation using the coordinate-position inputting/detecting device can not be carried out. On the other hand, in the coordinate-position inputting/detecting device in the first case, an infrared LED has to be provided in a pointing body, therefore, power unit or so for the pointing body is required, which is inconvenient from the view point of its maintenance. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Furthermore, in the coordinate-position inputting/detecting device, coordinates of only a two-dimensional (X-Y direction) position can be inputted, therefore, it is difficult to determine movement of a pointing body in the vertical direction (Z direction) and a double click or the like. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> It is an object of the present invention to improve, for the purpose of solving the problems described above, operability and usability of a method and device for inputting/detecting the coordinate position by enabling specification of coordinates of a position in an entry area pointed thereto with an arbitrary pointing body such as a fingertip or an ordinary pen without using a particular pointing device. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> It is another object of the present invention to realize a coordinate-position inputting/detecting device enabling entry of not only a two-dimensional position but also a three-dimensional position. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> It is another object of the present invention to improve workability and adaptability to handling of a display board system by using the coordinate-position inputting/detecting device with excellent operability. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> In the present invention, an image of a pointing body inserted into an entry area is picked up by at least two image pickup elements. Then, the position of the image of the pointing body formed on each of the image pickup elements is obtained according to the output from each of the image pickup elements. Finally, coordinates of the position of the pointing body are identified by using the computed positions of the images. Therefore, entry operation can be carried out using an arbitrary pointing body without using a particular pointing body. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In the present invention, light is emitted from light emitting unit into the entry area. An image of a pointing body illuminated by the light emitted from the light emitting unit is picked up by at least two image pickup elements. Then, the position of the image of the pointing body formed on each of the image pickup elements is obtained according to the output from each of the image pickup elements. Finally, coordinates of the position of the pointing body are identified by using the computed positions of the images. Therefore, an entry operation can be carried out using an arbitrary pointing body without using a particular pointing body. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> In the present invention, the light emitting unit and the image pickup devices are so placed that the direction of the light emitted from the light emitting units is substantially the same as the direction from which the pointing body is viewed from each of the image pickup elements. Therefore, the light emitted from the light emitting unit does not directly enter the image pickup elements, and also shadow is not generated on the pointing body as much as possible. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> In the present invention, there is provided an incident light preventing unit for preventing the light emitted from the light emitting unit from directly entering into each of the image pickup elements. Therefore, the light emitted from the light emitting means does not directly enter into the image pickup elements. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> In the present invention, the light emitting unit comprises at least a light source and a mirror. Therefore, the light emitted by the light source can be reflected by the mirror and diffused along the entry area, so that, a light that covers the entire entry area can be emitted from the light emitting unit. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In the present invention, the angle of the light emitted by the light source can be changed by operating the mirror, so that, direction in which the light is reflected from the mirror can be adjusted. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> In the present invention, light reflected by a mirror is received by a light receiving element, and the angle of the mirror is changed according to intensity of the light received by the light receiving element. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> In the present invention, there is provided a reflection preventing unit which prevents the light emitted by the light emitting unit from its being reflected, so that unnecessary light does not enter the image pickup elements. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> In the present invention, when coordinates of the same position are obtained continuously then it is determined that the coordinates are obtained due to dust or something. In such a case the coordinates of this position are not stored in the memory and also are not outputted to an external device. As a result, it is possible to prevent coordinates of the position obtained due to dust or something from its being outputted to an external device. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> In the present invention, optical distortion of an image of a pointing body picked up by each of image pickup elements is electrically corrected, and higher quality of an image of a pointing body can be obtained. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> In the present invention, when a plurality of pointing bodies each with a different pattern provided thereto are inserted into the entry area, patterns are recognized according to each output from the image pickup elements, which allows an entry operation concurrently using the plurality of pointing bodies to be carried out. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> In the present invention, width of the pointing body is determined according to images of the pointing body picked up by image pickup elements. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> In the present invention, the coordinates of the position of a pointing body identified by coordinate-value identifying unit is corrected by using the width of the pointing body obtained by the width identifying unit so that it is possible to obtain coordinates of an accurate position. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> In the present invention, image of an entry area previously picked up by each of image pickup elements is stored as a reference image, images of the entry area picked up afterward by each of the image pickup elements are extracted. Then, a difference between the corresponding reference images and images of the pointing body inserted into the entry area obtained by the corresponding image pickup elements is extracted. From this difference, a position in the image of each of the image pickup elements where an image of the pointing body is formed is computed and coordinates of the position of the pointing body are obtained using the computed positions of the pointing body. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> In the present invention, image of the entry area is picked up utilizing two-dimensional image pickup elements, which allows coordinates of a three-dimensional position of a pointing body to be computed. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> In the present invention, a reference image consists of an image only of a background plate, so that an image of only a pointing body can easily be extracted from an image with the background plate and the pointing body included therein. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> In the present invention, image of the pointing body can easily be extracted just by removing a reference pattern from an image in which the background plate and the pointing body is present. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> In the present invention, an area photographable by the image pickup element is restricted by an area restricting unit so that the area is adjusted to the entry area. Therefore, the image pickup element may not be affected by noise such as interference light. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> In the present invention, when coordinates of the same position are obtained continuously then it is determined that the coordinates are obtained due to dust or something. In such a case the coordinates of this position are not stored in the memory and also are not outputted to an external device. As a result, it is possible to prevent coordinates of the position obtained due to dust or something from its being outputted to an external device. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> In the present invention, by deciding each image of an entry area used to compute coordinates of a position abandoned by updating means as each new reference image, dust existing on the entry area is taken in as a portion of a reference image. Therefore, it is prevented that coordinates of a position of dust are disadvantageously computed. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> In the present invention, a coordinate-position inputting/detecting device is provided in the front surface of a display unit for displaying characters and images, and a display surface and a writing surface of a display board are formed with the display unit and coordinate-position inputting/detecting device, so that viewability of the display unit and operability of the system can be improved. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> In the present invention, a coordinate-position inputting/detecting device is provided in the front surface of a display unit for displaying thereon characters and images. As a result, a display surface and a writing surface of the display board are formed with the display unit and coordinate-position inputting/detecting device, so that viewability of the display unit and operability of the system can be improved. Furthermore, the display board system comprises a frame unit having a holding section for holding a display surface and a writing surface of the display board at a specified height, a printer accommodating section for accommodating the printer therein, and a control unit accommodating section for accommodating the control unit therein. The control unit accommodating section, printer accommodating section and the holding section are arranged in the vertical direction in this order from the bottom. As a result, transport and installation of the system can easily be carried out. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> In the present invention, by using a plasma display as a display unit, optimization of the display board system can be performed. Namely, use of the plasma display allows the thickness of a display unit to be reduced, and the plasma display also has high brightness as well as a wide viewing angle, and can reproduce moving pictures smoothly, so that the plasma display is preferable as a display unit of the display board system. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> In the present invention, a keyboard placement section for placing a keyboard connected to a personal computer is provided at a position in the upper side of the printer accommodating section and in the lower side of the holding section. Therefore, handling capability of the system is improved. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> In the present invention, an angle adjusting unit for adjusting an angle of a display surface and a writing surface of the display board is provided in a holding section. Therefore, disturbance light coming into the display unit (display surface), especially, light from lighting equipment such as a fluorescent tube on the ceiling can be prevented. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> In the present invention, a plurality of connecting terminals for connecting various types of information equipment and AV equipment such as a digital camera, a DVD player, and video equipment are provided in a display unit and is usable as a large-sized screen monitor. Therefore, the display board system can be used in any occasion. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> Other objects and features of this invention will become understood from the following description with reference to the accompanying drawings.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a front view showing general configuration of a coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows general configuration of a lighting device of the coordinate-position inputting/detecting device shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram of the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows the processing for computing coordinates of a position of a pointing body inserted into the entry area in the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows the processing for computing coordinates of a position of a pointing body inserted into the entry area in the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a graph showing a relation between a position of an image of an object formed on a CCD and light quantity of the image of the object picked up by the CCD in the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> shows a shadow produced on the pointing body in the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a graph showing a comparison between the case where there is a shadow on the pointing body to the case where there is no shadow thereon concerning a relation between a position of an image of an object formed on the CCD and light quantity of the image of the object picked up by the CCD in the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a graph showing a relation between a position of an image of an object formed on a CCD, light quantity of the image of the object picked up by the CCD, and a distance D in the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flow chart showing the processing when coordinates of a computed position are transferred to a computer in the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> shows the processing when an operation of inputting freehand characters and graphics into a computer is performed concurrently using two pens in the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a front view showing general configuration of a modification of the coordinate-position inputting/detecting device according to Embodiment 1 of the present invention; </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a front view showing general configuration of a coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> shows a background plate provided in the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> shows a light shielding plate provided in the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a cross-sectional view of the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a block diagram of the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> shows the processing for computing coordinates of a position of a pointing body inserted into the entry area in the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> shows the processing for computing coordinates of a position of a pointing body inserted into the entry area in the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is an explanatory view showing a flow of the processing for computing coordinates of a position of a pointing body inserted into the entry area in the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> is an explanatory view showing an example of a reference image shown in <cross-reference target="DRAWINGS">FIG. 20</cross-reference>; </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 22</cross-reference> is an explanatory view showing an example of a photographed image shown in <cross-reference target="DRAWINGS">FIG. 20</cross-reference>; </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> is an explanatory view showing an example of a differential image shown in <cross-reference target="DRAWINGS">FIG. 20</cross-reference>; </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 24</cross-reference> is an explanatory view showing how a point in the entry area is pointed with a finger in the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 25</cross-reference> is an explanatory view showing a relation between a central point of an image of a differential image in the Z direction formed in a two-dimensional image sensor and a distance D in the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 26</cross-reference>A and <cross-reference target="DRAWINGS">FIG. 26B</cross-reference> are explanatory views showing a drawing and a gesture command usable in the coordinate-position inputting/detecting device according to Embodiment 2 of the present invention; </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 27</cross-reference> is a block diagram of a display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 28</cross-reference> is a block diagram of a computer (personal computer) of a display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 29</cross-reference> is a perspective front view of a frame unit with the display board system according to Embodiment 3 of the present invention accommodated therein; </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 30</cross-reference> is a perspective rear view of the frame unit with the display board system according to Embodiment 3 of the present invention accommodated therein; </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 31</cross-reference> is a side view of the frame unit according to Embodiment 3 of the present invention viewed from the right side thereof; </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 32</cross-reference> shows the configuration of an angle adjusting mechanism section according to Embodiment 3 of the present invention viewed from the upper side of the frame unit (angle of the board section is five degrees); </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 33</cross-reference> shows the configuration of the angle adjusting mechanism section according to Embodiment 3 of the present invention viewed from the upper side of the frame unit (angle of the board section is zero degree); </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 34</cross-reference> shows the configuration of the angle adjusting mechanism section according to Embodiment 3 of the present invention viewed from the side of the frame unit; </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 35</cross-reference> shows a modification of the angle adjusting mechanism section according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 36</cross-reference> shows another modification of the angle adjusting mechanism section according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 37</cross-reference> shows an example of the screen of the display board and a toolbar displayed on the PDP in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 38</cross-reference> shows an example of an extension toolbar displayed on the PDP in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 39</cross-reference> shows an example of a drawing toolbar together with the extension toolbar displayed on the PDP in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 40</cross-reference> shows an example of how a result of freehand characters and lines on the touch surface is displayed on the screen of the display board on the PDP in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 41</cross-reference> shows an example of how the freehand characters and lines displayed on the screen of the display board are deleted with an eraser in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 42</cross-reference> shows an example of how the freehand characters and lines displayed on the screen of the display board are enclosed with a box and the characters and lines in the box are deleted in one operation in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 43</cross-reference> shows a line drawn on the screen of the display board in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 44</cross-reference> shows a rectangle drawn on the screen of the display board in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 45</cross-reference> shows a grid pattern displayed as a background of the screen of the display board in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 46</cross-reference> shows a table created on the screen of the display board in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 47</cross-reference> shows an ellipse created on the screen of the display board in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 48A</cross-reference> shows selection of a graphics as an object for modification and <cross-reference target="DRAWINGS">FIG. 48B</cross-reference> shows the graphics after its modification in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 49A</cross-reference> shows selection of a graphics as an object to be moved and </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 49B</cross-reference> shows the graphics after its movement in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 50</cross-reference> shows an example of a edit menu displayed when an already created graphics is to be edited in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 51</cross-reference> shows the processing for opening an already generated file in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 52</cross-reference> shows the processing for opening an already generated file using thumbnail images in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 53</cross-reference> shows an example of a screen of the computer and a capture toolbar displayed on the PDP in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 54</cross-reference> shows an example of how a screen of a captured application program is displayed as a background of the screen of the display board in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 55</cross-reference> shows an example of how a screen of a captured application program is displayed as a background of the screen of the display board and how the characters or the like are written on the screen in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 56</cross-reference> shows how a thumbnail display dialog box for displaying the pages in creation in a list form is displayed in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 57</cross-reference> shows how a printing dialog box for printing the pages in creation is displayed in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 58</cross-reference> shows an example of a setting screen for coordinate-position input device in the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 59</cross-reference> shows the network connection of the display board system according to Embodiment 3 of the present invention; </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 60</cross-reference> shows the configuration of a display unit of a display board system according to Embodiment 4 of the present invention; </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 61</cross-reference> is a block diagram showing a main control section of the display board system according to Embodiment 4 of the present invention; </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 62</cross-reference> shows a screen that displays a point-operation area in the display board system according to Embodiment 4 of the present invention; </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 63</cross-reference> is a flow chart of a point operation in the display board system according to Embodiment 4 of the present invention; </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 64A, 64B</cross-reference> and <highlight><bold>64</bold></highlight>C are processing steps showing display and deletion of a point-operation area in the display board system according to Embodiment 4 of the present invention; </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 65</cross-reference> is a flow chart of the processing for display and deletion of a point-operation area in the display board system according to Embodiment 4 of the present invention; </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 66</cross-reference> is an explanatory view that shows display contents on the display screen appearing within the point-operation area in the display board system according to Embodiment 4 of the present invention; </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 67</cross-reference> shows a moving operation of the pointer in association with transformation of coordinates in the display board system according to Embodiment 4 of the present invention; </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 68</cross-reference> is a time chart showing drag operations according to operations within a point-operation area in the display board system according to Embodiment 4 of the present invention; </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 69</cross-reference> is a block diagram showing a first example of the configuration of a display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 70</cross-reference> is an appearance view of the first example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 71</cross-reference> shows an example of a method of detecting a position of a person from an image based on the first example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 72</cross-reference> shows a method of deciding a position where a ten-key is to be displayed in the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 73</cross-reference> is a block diagram showing a second example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 74</cross-reference> is an appearance view showing the second example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 75</cross-reference> is a block diagram showing a third example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 76</cross-reference> is an appearance view showing the third example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 77</cross-reference> is a block diagram showing a fourth example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 78</cross-reference> is an appearance view showing the fourth example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 79</cross-reference> is a block diagram showing a fifth example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 80</cross-reference> is an appearance view showing the fifth example of the configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 81</cross-reference> is a block diagram showing configuration, for displaying an input window (a ten-key display specifying window) to specify a position where a ten-key is displayed on an entry surface, applicable in the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 82</cross-reference> is a block diagram showing hardware configuration of the display board system according to Embodiment 5 of the present invention; </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 83</cross-reference> is a block diagram showing a first example of the configuration of a display board system according to Embodiment 6 of the present invention; </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 84</cross-reference> shows a waveform outputted from a coordinate-position input device in the first example of the configuration of the display board system according to Embodiment 6 of the present invention; </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 85</cross-reference> is a flow chart of operations of the first example of the configuration of the display board system according to Embodiment 6 of the present invention; </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 86</cross-reference> is a block diagram showing a second example of the configuration of the display board system according to Embodiment 6 of the present invention; </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 87</cross-reference> is a flow chart of operations of the second example of the configuration of the display board system according to Embodiment 6 of the present invention; </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 88</cross-reference> is a block diagram showing a third example of the configuration of the display board system according to Embodiment 6 of the present invention; </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 89</cross-reference> is a flow chart of operations of the third example of the configuration of the display board system according to Embodiment 6 of the present invention; </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 90</cross-reference> is a block diagram showing a fourth example of the configuration of the display board system according to Embodiment 6 of the present invention; and </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 91</cross-reference> is a block diagram showing a fifth example of the configuration of the display board system according to Embodiment 6 of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> Detailed description is made hereinafter for embodiments of the a method and device for inputting/detecting the coordinate position according to the present invention and a display board system using the same with reference to the attached drawings. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a front view showing general configuration of a coordinate-position inputting/detecting device according to Embodiment 1 of the present invention. <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a state when the coordinate-position inputting/detecting device according to Embodiment 1 is attached to the front surface of a writing surface E (e.g., a white board) of a display board as an example. This coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> comprises a frame <highlight><bold>1</bold></highlight><highlight><italic>a </italic></highlight>having a rectangular space having substantially the same size as the writing surface E of a display board, namely having an entry area <highlight><bold>2</bold></highlight> where a user performs an entry operation using a pointing body such as a finger or a pen. Provided in this frame <highlight><bold>1</bold></highlight><highlight><italic>a </italic></highlight>are a lighting device <highlight><bold>4</bold></highlight>, image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R, a shade <highlight><bold>8</bold></highlight>, a light absorbing member <highlight><bold>9</bold></highlight>, and a light receiving element <highlight><bold>10</bold></highlight>. The pointing body may be anything such as a user&apos;s finger or hand, or a pen on the condition that an arbitrary position can be pointed therewith. </paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> The lighting device <highlight><bold>4</bold></highlight> is provided at substantially the center of the upper side of the entry area <highlight><bold>2</bold></highlight> and emits light which spreads in parallel with the writing surface E as well as over the entire entry area <highlight><bold>2</bold></highlight> using the light from a light source (Refer to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>). The entry area <highlight><bold>2</bold></highlight> in the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1 is actually formed with the light emitted from the lighting device <highlight><bold>4</bold></highlight> so as to cover the whole surface of the writing surface E. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> The image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R are provided at both edges of the upper side of the entry area <highlight><bold>2</bold></highlight> on the same side as that of the lighting device <highlight><bold>4</bold></highlight> and are separated from each other by a distance L. The image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R pick up an image of a pointing body inserted into the entry area <highlight><bold>2</bold></highlight>. Each of the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R have at least a CCD (Charge Coupled Device) <highlight><bold>5</bold></highlight> as a one-dimensional image sensor (one-dimensional image pickup element) for outputting image information (an image of an object) as an electric signal, and a focusing optical lens <highlight><bold>6</bold></highlight> for forming an image of the pointing body inserted into the entry area <highlight><bold>2</bold></highlight> on the CCD <highlight><bold>5</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. The CCD <highlight><bold>5</bold></highlight> and the focusing optical lens <highlight><bold>6</bold></highlight> are separated from each other by a distance f (Refer to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>). </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> The shade <highlight><bold>8</bold></highlight> is provided on the lighting device <highlight><bold>4</bold></highlight> so that the light from the lighting device <highlight><bold>4</bold></highlight> can uniformly be emitted over the entire entry area <highlight><bold>2</bold></highlight>. Further, the shade <highlight><bold>8</bold></highlight> also prevents the light emitted from the lighting device <highlight><bold>4</bold></highlight> to be directly entering into the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R. The light absorbing member <highlight><bold>9</bold></highlight> is provided in the peripheral section of the entry area <highlight><bold>2</bold></highlight> except in the upper side thereof. This light absorbing member <highlight><bold>9</bold></highlight> suppresses reflection of the light by absorbing the light emitted from the lighting device <highlight><bold>4</bold></highlight>. Namely, the light absorbing member <highlight><bold>9</bold></highlight> is provided in order to prevent the reflected light (scattered light) due to the light emitted from the lighting device <highlight><bold>4</bold></highlight> from its entering the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R. </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> Furthermore, the light receiving elements <highlight><bold>10</bold></highlight> (e.g., PIN photodiodes) are located on the light absorbing member <highlight><bold>9</bold></highlight> at both edges of the lower side of the entry area <highlight><bold>2</bold></highlight>. These light receiving elements <highlight><bold>10</bold></highlight> receive the light emitted from the lighting device <highlight><bold>4</bold></highlight> and outputs a signal according to intensity of the received light. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> In the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1 as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the lighting device <highlight><bold>4</bold></highlight> as well as the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R are located along one line in the upper side of the entry area <highlight><bold>2</bold></highlight>. Thus, the direction in which the light is emitted from the lighting device <highlight><bold>4</bold></highlight> is the same as that to which an object (pen A) is viewed from the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R. As a result, the light emitted from the lighting device <highlight><bold>4</bold></highlight> can be prevented from directly entering into the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R, and also production of a shadow on the pointing device viewed from the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R can be prevented as much as possible. However, the lighting device <highlight><bold>4</bold></highlight> as well as the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R may be located not in the upper side of the entry area <highlight><bold>2</bold></highlight> but, for instance, in the lower side thereof, therefore, <cross-reference target="DRAWINGS">FIG. 1</cross-reference> does not limit the location of the attachment of the lighting device <highlight><bold>4</bold></highlight> as well as of the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> When a pointing device such as a finger or a pen is inserted into the entry area <highlight><bold>2</bold></highlight>, although detailed description will be made later, the light emitted from the lighting device <highlight><bold>4</bold></highlight> is irregularly reflected by the pointing device, and a portion of the irregularly reflected light is detected by each CCD <highlight><bold>5</bold></highlight> in the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R respectively. In other words, the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R in Embodiment 1 have sensitivity only when the pointing device is inserted into the entry area <highlight><bold>2</bold></highlight>, and capture an image (pick up an image) of the pointing device inserted into the entry area <highlight><bold>2</bold></highlight> through the irregularly reflected light. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> By the way, in the description below, a state where a portion of the pointing device such as a finger and a pen contacts the writing surface E and moves along the writing surface E with the device contacted thereto will be called as a pen-down state. Comparing this pen-down state to a writing state with a fountain pen or a ball-point pen, the former state corresponds to a state where a tip of the pen contacts and ink oozes out from the pen tip. Then, a state where the pointing device moves in the vertical direction with respect to the writing surface E and there is no contact between the device and the writing surface E will be called as a pen-up state. Comparing the pen-up state to a writing state with a fountain pen or a ball-point pen, the former state corresponds to a state where a tip of the pen is moved away from a paper at intervals between strokes of characters or during movement between characters and the ink does not ooze out from the pen tip. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> Therefore, by enabling determination as to whether the pointing device is in a pen-up state or a pen-down state in the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight>, it is possible to electronically imitate a writing operation such that characters and graphics are drawn on paper with a fountain pen or a ball-point pen. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> In the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1, when the writing surface E is viewed along the same direction as that of the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R, it can clearly be understood that a layer of light having a certain thickness along the vertical direction of the writing surface E is formed because of the light emitted from the lighting device <highlight><bold>4</bold></highlight>. Herein, the pen-up/pen-down state will be described assuming that light is emitted from the lighting device <highlight><bold>4</bold></highlight> very close to the writing surface E. When a pointing device is gradually being inserted into the entry area <highlight><bold>2</bold></highlight> the quantity of light reflected by the pointing device gradually increases. A pen-down state is a state where the pointing device penetrates through the entire layer of the light and contacts the writing surface E. In this pen-down state, the quantity of light reflected by the pointing device is the maximum. On the other hand, a pen-up state is a state where the pointing device is floating over the writing surface E, therefore, the quantity of light reflected by the pointing device is less as compared to that in the pen-down state. In other words, the area on the pointing device that is lighted because of the light emitted from the lighting device <highlight><bold>4</bold></highlight>, namely, the area from where the light is reflected in the pen-up state is different from that in the pen-down state. In coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1, it is possible to determine whether a pointing device is in the pen-up state or in the pen-down state according to the light quantity of the images of the pointing device picked up by the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R. </paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> However, when the layer of the light is formed at a position which is separated from the writing surface E, change in the light quantity of the image of the pointing device in the pen-up state and pen-down state is difficult to occur in proportion to the distance from the writing surface E to the layer of the light. In other words, when there is a gap (a region of no light) between the writing surface E and the layer of the light an object can not be sensed. More specifically, even if the pointing device is in the state where the device does not contact the writing surface E (pen-up state), the same light quantity as that in the pen-down state may sometimes be obtained when the light layer is formed at the location away from the writing surface E, which may possibly be determined as the pen-down state. When a character string is written on the writing surface E in this state then all the movements of the pointing device are determined as the movements for the entry of characters. Due to this, a drawback in the input device that characters and words get linked to each other may occur. </paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> The above mentioned pen-up/pen-down state has to accurately be determined at any position on the writing surface E. Therefore, the height and parallelism of the light emitted from the lighting device <highlight><bold>4</bold></highlight> with respect to the writing surface E are required to precisely be adjusted. </paragraph>
<paragraph id="P-0146" lvl="0"><number>&lsqb;0146&rsqb;</number> The configuration of the lighting device <highlight><bold>4</bold></highlight> will then be described more specifically. <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a general configuration of the lighting device <highlight><bold>4</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the light emitted from the light source <highlight><bold>3</bold></highlight> towards the writing surface E is transformed into parallel light by the optical lens <highlight><bold>11</bold></highlight>. This parallel light is then passed through an arc-shaped slit <highlight><bold>12</bold></highlight> and is reflected by an inclined surface <highlight><bold>13</bold></highlight><highlight><italic>a </italic></highlight>of a conical mirror <highlight><bold>13</bold></highlight>. When the light is reflected by the conical mirror <highlight><bold>13</bold></highlight>, a light which is parallel to the writing surface E as well as which spreads over entire area of the entry area <highlight><bold>2</bold></highlight> is obtained. </paragraph>
<paragraph id="P-0147" lvl="0"><number>&lsqb;0147&rsqb;</number> Herein, the conical mirror <highlight><bold>13</bold></highlight> will be described in more detail. <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a cross section of the conical mirror <highlight><bold>13</bold></highlight>. A shaft <highlight><bold>14</bold></highlight> is provided at the center of the conical mirror <highlight><bold>13</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. This shaft <highlight><bold>14</bold></highlight> is used not only for attachment of the conical mirror <highlight><bold>13</bold></highlight> to the frame <highlight><bold>1</bold></highlight><highlight><italic>a </italic></highlight>by being inserted into a hole (not shown) provided in the frame <highlight><bold>1</bold></highlight><highlight><italic>a </italic></highlight>, but also for adjustment of an angle at which light from the light source <highlight><bold>3</bold></highlight> is to be reflected. </paragraph>
<paragraph id="P-0148" lvl="0"><number>&lsqb;0148&rsqb;</number> Provided at the end of the shaft <highlight><bold>14</bold></highlight> is a spherical angle adjusting section <highlight><bold>15</bold></highlight>. By moving the angle adjusting section <highlight><bold>15</bold></highlight> to and fro and both sides, the angle of reflection of the light passing through the arc slit <highlight><bold>12</bold></highlight> can be changed in the X-Y direction, therefore, parallelism of the light with respect to the writing surface E can be adjusted. </paragraph>
<paragraph id="P-0149" lvl="0"><number>&lsqb;0149&rsqb;</number> The angle adjusting section <highlight><bold>15</bold></highlight> is connected to an actuator <highlight><bold>16</bold></highlight> for adjusting the angle of reflection of the light by the conical mirror <highlight><bold>13</bold></highlight> by moving the angle adjusting section <highlight><bold>15</bold></highlight>. The actuator <highlight><bold>16</bold></highlight> is driven under the control by a microcomputer (Refer to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>) described later according to light receiving power of the light receiving element <highlight><bold>10</bold></highlight> having received the light reflected by the conical mirror <highlight><bold>13</bold></highlight>. Namely, the actuator <highlight><bold>16</bold></highlight> makes the angle adjusting section <highlight><bold>15</bold></highlight> operate under the control by the microcomputer to adjust the angle of reflection of the light by the conical mirror <highlight><bold>13</bold></highlight> so that the light receiving power of the light received by the light-receiving element <highlight><bold>10</bold></highlight> is the maximum (namely, so that the light reflected from the conical mirror <highlight><bold>13</bold></highlight> vertically enters the light receiving element <highlight><bold>10</bold></highlight>). </paragraph>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> As described above, by automatically adjusting the reflecting angle of the light by the conical mirror <highlight><bold>13</bold></highlight>, parallel light with respect to the writing surface E can be emitted from the lighting device <highlight><bold>4</bold></highlight>. Therefore, it is possible to enhance detection precision of coordinates where a pointing body is positioned and also to accurately determine a pen-up/pen-down state. </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram of the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1. As shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> has a microcomputer <highlight><bold>17</bold></highlight> which provides controls over all the sections of the device. This microcomputer <highlight><bold>17</bold></highlight> comprises a CPU <highlight><bold>19</bold></highlight> which provides a centralized control over all the sections of the device, a ROM <highlight><bold>20</bold></highlight> which stores therein fixed data such as a control program, and a RAM <highlight><bold>21</bold></highlight> which stores therein variable data. Connected to the microcomputer <highlight><bold>17</bold></highlight> are the above mentioned light source <highlight><bold>3</bold></highlight>, image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R, light receiving element <highlight><bold>10</bold></highlight>, actuator <highlight><bold>16</bold></highlight>, and a timer <highlight><bold>22</bold></highlight> for counting a prespecified time, an xy computing unit <highlight><bold>23</bold></highlight> for computing coordinates of a position of a pointing body using images of the pointing body picked up by the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R, and an interface (I/F) <highlight><bold>18</bold></highlight> for connecting the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> to a computer (e.g., a personal computer) or the like each described later through a bus <highlight><bold>28</bold></highlight>. </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> A shadow correcting section <highlight><bold>27</bold></highlight> is provided to the xy computing unit <highlight><bold>23</bold></highlight> is for executing processing so that a shadow produced on the pointing body inserted into the entry area <highlight><bold>2</bold></highlight> will not cause any influence over the processing for identifying coordinates of a position of the pointing body. The RAM <highlight><bold>21</bold></highlight> has a coordinate memory <highlight><bold>24</bold></highlight> provided therein for temporarily storing the coordinates of a position of the identified pointing body in the manner as described later. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> Furthermore, a distortion correcting section <highlight><bold>25</bold></highlight> and a pattern recognizing section <highlight><bold>26</bold></highlight> are provided in the CCD <highlight><bold>5</bold></highlight>. The distortion correcting section <highlight><bold>25</bold></highlight> electrically corrects difference in measurement due to optical distortion of image information obtained by the CCD <highlight><bold>5</bold></highlight>. With this operation, higher quality of image information can be achieved. The pattern recognizing section <highlight><bold>26</bold></highlight> executes processing for recognizing a plurality of pointing bodies to make an entry operation possible to be performed by concurrently using the plurality of pointing bodies. For example, different specific patterns are given to the pointing bodies respectively, and the pattern recognizing section <highlight><bold>26</bold></highlight> recognizes and determines a pattern given to a pointing body trough the CCD <highlight><bold>5</bold></highlight>. As a result, it is possible to compute coordinates of positions pointed by the plurality of pointing bodies respectively as described later. </paragraph>
<paragraph id="P-0154" lvl="0"><number>&lsqb;0154&rsqb;</number> The processing executed by the microcomputer <highlight><bold>17</bold></highlight> according to the control program stored in the ROM <highlight><bold>20</bold></highlight> will be described. It should be noted that the processing for adjusting a reflecting angle of light by the conical mirror <highlight><bold>13</bold></highlight> is as described above, therefore, description is made herein for the processing executed by the microcomputer <highlight><bold>17</bold></highlight> centering on the processing for computing coordinates of a position of a pointing body such as a user&apos;s finger and a pen inserted into the entry area <highlight><bold>2</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 4</cross-reference> and <cross-reference target="DRAWINGS">FIG. 5</cross-reference> explain the processing for computing coordinates of a position of a pointing body inserted into the entry area <highlight><bold>2</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a state where an arbitrary position within the entry area <highlight><bold>2</bold></highlight> is pointed to by a pen A as a pointing body, while <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows a portion of <cross-reference target="DRAWINGS">FIG. 4</cross-reference> enlarged to make clear a relation between the image pickup device <highlight><bold>7</bold></highlight>L and the pen A. </paragraph>
<paragraph id="P-0155" lvl="0"><number>&lsqb;0155&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, when the pen A (pointing body) is inserted into the entry area <highlight><bold>2</bold></highlight> in order to write a character or a graphic at a certain position (x, y) on the writing surface E, the inserted pen A is illuminated by the light emitted from the lighting device <highlight><bold>4</bold></highlight>. A subject image as an image of the portion of the illuminated pen A is formed on each of the CCD <highlight><bold>5</bold></highlight> through the focusing optical lens <highlight><bold>6</bold></highlight> of the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R. The xy computing unit <highlight><bold>23</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> executes the processing for computing coordinates (x, y) of a position of the pen A according to the subject images formed on the CCDs <highlight><bold>5</bold></highlight> as described above. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> Specific description is made for the processing of computing the coordinates (x, y) of a position of the pen A by the xy computing unit <highlight><bold>23</bold></highlight>. Description is made herein for the processing of computing the coordinates (x, y) of the position of the pen A by taking the subject image picked up by the image pickup device <highlight><bold>7</bold></highlight>L shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> as an example. It should be noted that the processing described later is also executed to the subject image picked up by the image pickup device <highlight><bold>7</bold></highlight>R. </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a graph showing an example of a relation between a position of a subject image formed on the CCD <highlight><bold>5</bold></highlight> of the image pickup device <highlight><bold>7</bold></highlight>L and light quantity of the subject image picked up by the CCD <highlight><bold>5</bold></highlight>. In <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the position of the subject image formed on the CCD <highlight><bold>5</bold></highlight> is represented by a distance h from the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> to an imaging point. The subject image picked up by the CCD <highlight><bold>5</bold></highlight> appears as a waveform shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> according to the position of the image formed on the CCD <highlight><bold>5</bold></highlight> as well as to the light quantity. Herein, assuming that a threshold level concerning the light quantity of the subject image is set to a level indicated by a dotted line in <cross-reference target="DRAWINGS">FIG. 6, a</cross-reference> size &Dgr;h of the subject image can be computed with the following equation. </paragraph>
<paragraph lvl="0"><in-line-formula>&Dgr;<highlight><italic>h&equals;h</italic></highlight>2&minus;<highlight><italic>h</italic></highlight>1&emsp;&emsp;(1) </in-line-formula></paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> Where h1 and h2 are distances from the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> to the position where the light quality at the same level as the threshold level is obtained as shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> Then, the center h of the subject image shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> (the distance h from the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> to a point at which the image is formed) can be computed with the following equation. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>h&equals;h</italic></highlight>1&plus;(&Dgr;<highlight><italic>h/</italic></highlight>2)&emsp;&emsp;(2) </in-line-formula></paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the distance h from the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> to the point at which the image is formed depends on the angle &thgr; between a central line of the CCD <highlight><bold>5</bold></highlight> and a line linking the pen A and the point at which the image is formed. This angle &thgr; can be computed by with the following equation. </paragraph>
<paragraph lvl="0"><in-line-formula>&thgr;&equals;<highlight><italic>arctan</italic></highlight>(<highlight><italic>h/f</italic></highlight>)&emsp;&emsp;(3) </in-line-formula></paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> Where f is a distance between the focusing optical lens <highlight><bold>6</bold></highlight> and the CCD <highlight><bold>5</bold></highlight>, which in turn corresponds to the focal length of the focusing optical lens <highlight><bold>6</bold></highlight>. </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, an angle &bgr; between the image pickup device <highlight><bold>7</bold></highlight>L and the pen A can be computed with the following equation. </paragraph>
<paragraph lvl="0"><in-line-formula>&bgr;&equals;&agr;&minus;&thgr;&emsp;&emsp;(4) </in-line-formula></paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> Where &agr;is an angle between a reference line that links the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R and the central line of the CCD <highlight><bold>5</bold></highlight>, this in turn is the angle at which the image pickup device <highlight><bold>7</bold></highlight>L is attached. </paragraph>
<paragraph id="P-0164" lvl="0"><number>&lsqb;0164&rsqb;</number> By executing the same above processing to the subject image picked up by the image pickup device <highlight><bold>7</bold></highlight>R, an angle &bgr; between the image pickup device <highlight><bold>7</bold></highlight>R and the pen A can also be computed. Herein, the angle between the image pickup device <highlight><bold>7</bold></highlight>L and the pen A will be considered to &bgr;1 while the angle between the image pickup device <highlight><bold>7</bold></highlight>R and the pen A will be considered as &bgr;2 as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
<paragraph id="P-0165" lvl="0"><number>&lsqb;0165&rsqb;</number> Then, the coordinates (x, y) of the position of the pen A can be computed with the following equation based on the principle of triangulation. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>x&equals;L tan &bgr;</italic></highlight>2/(<highlight><italic>tan &bgr;</italic></highlight>1&plus;<highlight><italic>tan &bgr;</italic></highlight>2)&emsp;&emsp;(5) </in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>y&equals;x tan &bgr;</italic></highlight>1&emsp;&emsp;(6) </in-line-formula></paragraph>
<paragraph id="P-0166" lvl="0"><number>&lsqb;0166&rsqb;</number> In addition, by monitoring the changes in the level of the light quantity of the subject image shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, it is also possible to determine whether the state of the pen A is a pen-up/pen-down state or a double-clicked state or not. </paragraph>
<paragraph id="P-0167" lvl="0"><number>&lsqb;0167&rsqb;</number> Although the coordinates (x, y) of the position of the pen A computed by the processing described above may be inputted into a computer through the I/F <highlight><bold>18</bold></highlight> as they are, by executing the processing for correction described below, coordinates (x, y) of a more accurate position of the pen A can be computed. The reason why execution of the correction processing is preferable is because a shadow S as shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is produced on the pen A viewed from the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R (the cross section of the pen A in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a circle). More specifically, as shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, the size &Dgr;h&prime; of the subject image of the pen A formed on the CCD <highlight><bold>5</bold></highlight> in a state when there is no shadow S thereon is larger than the size &Dgr;h (computed according to the Equation (1)) of the subject image of the pen A having the shadow S thereon. Therefore, when a shadow S is produced, an error occurs in the computation (according to Equation (2)) of the distance h from the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> to the point at which the image is formed and the coordinates of the computed position of the pen A are not accurate. Therefore, in order to compute accurate coordinates of a position, it is required to take into consideration existence of a shadow S on the pen A. A method of computing the accurate coordinates (x, y) of the position of the pen A is described by describing hereinafter a method of computing a distance h from the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> to a point at which the image is formed by taking into consideration existence of the shadow. </paragraph>
<paragraph id="P-0168" lvl="0"><number>&lsqb;0168&rsqb;</number> At first, description is made for the processing of computing a width of an illuminated portion of the pen A by the light emitted from the lighting device <highlight><bold>4</bold></highlight>, namely a width &Dgr;H of the subject shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> according to the subject image of the pen A formed on the CCD <highlight><bold>5</bold></highlight> of the image pickup device <highlight><bold>7</bold></highlight>L. In this case, a magnification of a subject image formed on the CCD <highlight><bold>5</bold></highlight> is considered to change according to a distance D (Refer to <cross-reference target="DRAWINGS">FIG. 5</cross-reference> and <cross-reference target="DRAWINGS">FIG. 7</cross-reference>) between the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R and the pen A. <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a graph showing an example of a relation between a position of a subject image formed on the CCD <highlight><bold>5</bold></highlight> of the image pickup device <highlight><bold>7</bold></highlight>L, light quantity of the subject image picked up by the CCD <highlight><bold>5</bold></highlight>, and the distance D. The difference in the magnification of the subject image formed on the CCD <highlight><bold>5</bold></highlight> appears due to the difference in the width of output from the CCD <highlight><bold>5</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. Namely, when the distance D is long the subject image becomes of a size as shown by the sign &Dgr;h, and when the distance D is short the subject image becomes of a size shown by the sign &Dgr;h&prime;. This distance D is computed according to the coordinates (x, y) of the position of the pen A computed with the Equation (5) and Equation (6) as well as according to the angle &thgr; computed with the Equation (3). </paragraph>
<paragraph id="P-0169" lvl="0"><number>&lsqb;0169&rsqb;</number> Then, width of the illuminated portion of the pen A due to the light emitted from the lighting device <highlight><bold>4</bold></highlight>, namely a subject width &Dgr;H of the pen A shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is computed with the following equation. It should be noted that this processing may be executed by either the xy computing unit <highlight><bold>23</bold></highlight> or the shadow correcting section <highlight><bold>27</bold></highlight>. </paragraph>
<paragraph lvl="0"><in-line-formula>&Dgr;<highlight><italic>H</italic></highlight>&equals;(<highlight><italic>D/f</italic></highlight>)&Dgr;<highlight><italic>h</italic></highlight>&emsp;&emsp;(7) </in-line-formula></paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> Then, the shadow correcting section <highlight><bold>27</bold></highlight> executes the processing for correcting the center h of the subject image (a distance h between the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> and the point at which the image is formed) according to, for instance, the subject image width &Dgr;H&prime; of the actual pen A previously stored in the ROM <highlight><bold>20</bold></highlight> together with the control program. As shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, assuming that the center of the corrected subject image is h&prime;, the center h&prime; can be computed with the following equation as an approximate value. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>h&prime;&equals;h&plus;</italic></highlight>(<highlight><italic>f/D</italic></highlight>)(&Dgr;<highlight><italic>H&prime;&minus;&Dgr;H</italic></highlight>)/2&emsp;&emsp;(8) </in-line-formula></paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> The subject image width &Dgr;H of the pen A shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference> can be computed by using the following Equation (7&prime;) in place of the Equation (7). In this case, an angle &ggr; between a straight line which links the light source <highlight><bold>3</bold></highlight> and the subject (pen A) and a straight line which links the center h of the subject image obtained with Equation (2) and the subject (pen A) is computed. Then, by substituting this angle &ggr; and the subject width &Dgr;H&prime; of the actual pen A previously stored in the ROM <highlight><bold>20</bold></highlight> in the Equation (7&prime;), a subject width &Dgr;H of the pen A viewed from the center h of the subject image on the CCD <highlight><bold>5</bold></highlight> can be computed.  
<math-cwu id="MATH-US-00001">
<number>1</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>&Delta;</mi>
          <mo>&it;</mo>
          <mstyle>
            <mtext>&emsp;</mtext>
          </mstyle>
          <mo>&it;</mo>
          <mi>H</mi>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <mn>2</mn>
          </mfrac>
          <mo>&it;</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mn>1</mn>
              <mo>+</mo>
              <mrow>
                <mi>cos</mi>
                <mo>&it;</mo>
                <mstyle>
                  <mtext>&emsp;</mtext>
                </mstyle>
                <mo>&it;</mo>
                <mi>&gamma;</mi>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
          <mo>&it;</mo>
          <mi>&Delta;</mi>
          <mo>&it;</mo>
          <mstyle>
            <mtext>&emsp;</mtext>
          </mstyle>
          <mo>&it;</mo>
          <msup>
            <mi>H</mi>
            <mi>&prime;</mi>
          </msup>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <msup>
          <mn>7</mn>
          <mi>&prime;</mi>
        </msup>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00001" file="US20030001825A1-20030102-M00001.NB"/>
<image id="EMI-M00001" wi="216.027" he="18.00225" file="US20030001825A1-20030102-M00001.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> Then, by substituting the computed value in Equation (8), center h&prime; of the subject image can be obtained. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> In case of the image pickup device <highlight><bold>7</bold></highlight>R also, a width &Dgr;H of a subject can be computed in the same manner as described above, and the processing of computing the center h&prime; of the subject image is executed. </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> Then, the xy computing unit <highlight><bold>23</bold></highlight> executes again the processing of computing the coordinates (x, y) of a position of the pen A using the value of the center h&prime; obtained in the shadow correcting section <highlight><bold>27</bold></highlight>. Namely, the xy computing unit <highlight><bold>23</bold></highlight> executes the sequence of calculation described with respect to Equation (3) to Equation (6) using the value of the center h&prime; obtained in the shadow correcting section <highlight><bold>27</bold></highlight>, and computes the coordinates of the position of the pen A. As a result, it is possible to compute the coordinates of the accurate position. </paragraph>
<paragraph id="P-0175" lvl="0"><number>&lsqb;0175&rsqb;</number> Although data for a subject width &Dgr;H&prime; of the pen A used in the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> is previously stored in the ROM <highlight><bold>20</bold></highlight> herein as one example, rewriting data as required may be possible by storing a subject width &Dgr;H&prime; in a memory such as a non-volatile RAM so that a pen to be used can be changed. </paragraph>
<paragraph id="P-0176" lvl="0"><number>&lsqb;0176&rsqb;</number> The above mentioned Equations (1) to (8) can previously be stored in the ROM <highlight><bold>20</bold></highlight> as a portion of the control program. The coordinates (x, y) of a position of a pen A are computed according to a distance h between the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> and the subject image formed on the CCD <highlight><bold>5</bold></highlight> through those Equations (1) to (8). Namely, by computing a distance h from the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> in the image pickup device <highlight><bold>7</bold></highlight>L as well as a distance h from the center <highlight><bold>5</bold></highlight><highlight><italic>a </italic></highlight>of the CCD <highlight><bold>5</bold></highlight> in the image pickup device <highlight><bold>7</bold></highlight>R, the coordinates (x, y) of a position of the pen A can be obtained. </paragraph>
<paragraph id="P-0177" lvl="0"><number>&lsqb;0177&rsqb;</number> Furthermore, the subject image of a pen A does not always have to perfectly be formed on the CCD <highlight><bold>5</bold></highlight>. Namely, when the image is not perfectly formed thereon, only the size &Dgr;H of the subject image on the CCD <highlight><bold>5</bold></highlight> becomes larger, therefore, the center h&prime; of the subject image is not affected thereby. </paragraph>
<paragraph id="P-0178" lvl="0"><number>&lsqb;0178&rsqb;</number> The coordinates (x, y) of the position of the pen A computed as described above are temporarily stored in the coordinate memory <highlight><bold>24</bold></highlight> and then inputted into a computer through the I/F <highlight><bold>18</bold></highlight>. The coordinates of a position mentioned herein indicate either one of the coordinates having been subjected to correction because of the above mentioned shadow or the coordinates which are not subjected to any correction. <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flow chart showing the processing when coordinates of a computed position are transferred to a computer. The microcomputer <highlight><bold>17</bold></highlight> makes, as shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, when the coordinates (x2, y2) of the position of the pen A are computed by the xy computing unit <highlight><bold>23</bold></highlight>, namely when the pen-down state is detected (Yes in step S<highlight><bold>1</bold></highlight>), the timer <highlight><bold>22</bold></highlight> start counting a prespecified time (step S<highlight><bold>2</bold></highlight>). </paragraph>
<paragraph id="P-0179" lvl="0"><number>&lsqb;0179&rsqb;</number> In the next step, the microcomputer <highlight><bold>17</bold></highlight> determines whether the coordinates (x2, y2) of the computed position are coincident with the coordinates (x1, y1) of the position stored in the coordinate memory <highlight><bold>24</bold></highlight> or not (step S<highlight><bold>3</bold></highlight>). When it is determined that the coordinates of the two positions are not coincident (No in step S<highlight><bold>3</bold></highlight>), the microcomputer <highlight><bold>17</bold></highlight> updates the coordinates of the position stored in the coordinate memory <highlight><bold>24</bold></highlight> to the newly computed coordinates (x2, y2) of the position, and clears the counting by the timer <highlight><bold>22</bold></highlight> (step S<highlight><bold>4</bold></highlight>). Then, the microcomputer <highlight><bold>17</bold></highlight> transfers the coordinates of the position in the coordinate memory <highlight><bold>24</bold></highlight> to a computer (step S<highlight><bold>5</bold></highlight>), the system control is returned to step S<highlight><bold>1</bold></highlight> where the microcomputer waits for a new detection of a pen-down. The computer executes the processing in response to movement of the pen A according to the transferred coordinates of the position. For example, the computer executes the processing for drawing characters and graphics on a display. </paragraph>
<paragraph id="P-0180" lvl="0"><number>&lsqb;0180&rsqb;</number> On the other hand, when it is determined that the coordinates of the two positions are coincident (Yes in step S<highlight><bold>3</bold></highlight>), the microcomputer <highlight><bold>17</bold></highlight> waits for computation of coordinates of a new position which are different from the coordinates of the position stored in the coordinate memory <highlight><bold>24</bold></highlight> by the xy computing unit <highlight><bold>23</bold></highlight> during the period of time until a prespecified time is counted by the timer (step S<highlight><bold>6</bold></highlight>, step S<highlight><bold>7</bold></highlight>, step S<highlight><bold>3</bold></highlight>). More specifically, the microcomputer <highlight><bold>17</bold></highlight> waits for computation of the coordinates of a new position by the xy computing unit <highlight><bold>23</bold></highlight> (detection of the pen-down state), and when the coordinates of the new position are computed (Yes in step S<highlight><bold>7</bold></highlight>), the system control is shifted to step S<highlight><bold>3</bold></highlight>, and the microcomputer <highlight><bold>17</bold></highlight> determines whether the coordinates of the computed position is coincident with the coordinates of the position in the coordinates memory <highlight><bold>24</bold></highlight> or not. Then, when it is determined that the coordinates of the two positions are not coincident (No in step S<highlight><bold>3</bold></highlight>), the microcomputer <highlight><bold>17</bold></highlight> executes the processing in steps S<highlight><bold>4</bold></highlight> and step S<highlight><bold>5</bold></highlight> as described above. On the other hand, when it is determined that the coordinates of the two positions are coincident (Yes in step S<highlight><bold>3</bold></highlight>), the microcomputer <highlight><bold>17</bold></highlight> shifts the system control again to step S<highlight><bold>6</bold></highlight>. </paragraph>
<paragraph id="P-0181" lvl="0"><number>&lsqb;0181&rsqb;</number> Then, the microcomputer <highlight><bold>17</bold></highlight> executes, when it is determined that the prespecified time has passed (Yes in step S<highlight><bold>6</bold></highlight>), the error processing (step S<highlight><bold>8</bold></highlight>), returns the system control to step S<highlight><bold>1</bold></highlight>, and waits for new detection of a pen-down. Namely, when non coincident coordinates can be obtained (step S<highlight><bold>3</bold></highlight>) until the prespecified time passes, it is considered that there is no movement of the pen A. Therefore, the coordinates of the computed position by the xy computing unit <highlight><bold>23</bold></highlight> are regarded as a position of, for instance, dust or something deposited on the writing surface E, and the error processing is executed in step S<highlight><bold>8</bold></highlight>. As this error processing, the microcomputer <highlight><bold>17</bold></highlight> does not update the coordinates (x1, y1) of the position stored in the coordinates memory <highlight><bold>24</bold></highlight>, but discards the coordinates (x2, y2) of the position computed in step S<highlight><bold>1</bold></highlight> so that the coordinates of the position in the coordinates memory <highlight><bold>24</bold></highlight> will not be transferred to the computer. </paragraph>
<paragraph id="P-0182" lvl="0"><number>&lsqb;0182&rsqb;</number> In this case, the microcomputer <highlight><bold>17</bold></highlight> may provide controls for transmitting an error signal to the computer to stop an entry operation of coordinates and then restarting, when the dust or something is removed and an instruction for restoration is inputted by the user, the stopped operation of entering coordinates. The microcomputer <highlight><bold>17</bold></highlight> may transfer the coordinates of the position of the dust-like substance to the computer and give a note on the dust-deposited position to the computer. With this configuration, the coordinates of the position of the dust can be prevented from being entered into the computer. </paragraph>
<paragraph id="P-0183" lvl="0"><number>&lsqb;0183&rsqb;</number> Furthermore, in the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1, a plurality of users can also concurrently enter freehand characters and graphics into a computer. In this case, however, each of the pointing bodies to be used at the same time needs to be discriminated from the others. In the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1, the pattern recognizing section <highlight><bold>26</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> performs the processing of identifying the plurality of pointing bodies, and the xy computing unit <highlight><bold>23</bold></highlight> computes coordinates of a position for each identified pointing body. For example, it is assumed that pointing bodies are pens and each of patterns with differently-pitched stripes is added to the periphery of each pen (the pattern may be anything such as vertical stripes, horizontal stripes or a grid). The pattern recognizing section <highlight><bold>26</bold></highlight> executes the processing for recognizing patterns of the plurality of pens picked up by the CCD <highlight><bold>5</bold></highlight> in each of the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R. </paragraph>
<paragraph id="P-0184" lvl="0"><number>&lsqb;0184&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> explains the processing when an operation of inputting freehand characters and graphics into a computer is performed concurrently using two pens. Herein, it is assumed as an example that &lsquo;a&rsquo; point a and a point &lsquo;b&rsquo; in the entry area <highlight><bold>2</bold></highlight> are concurrently pointed to by using two pens. In this case, subject images of the pens existing in the directions of {circle over (1)} and {circle over (2)} are picked up by the image pickup device <highlight><bold>7</bold></highlight>L, while subject images of the pens existing in the directions of {circle over (3)} and {circle over (4)} are picked up by the image pickup device <highlight><bold>7</bold></highlight>R respectively. Herein, if identification can not be made which subject images are of the same pen among the subject images of the pens picked up by the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R, coordinates of a point &lsquo;c&rsquo; and a point &lsquo;d&rsquo; will be computed in addition to those of the point &lsquo;a&rsquo; and point &lsquo;b&rsquo;. Therefore, it is necessary to identify which subject images are of the same pen by using differently pitched patterns added to the periphery of pens. However, a pitch of each pattern of the subject images picked up by the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R changes according to a distance D between the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R and the pen even if the pitches are the same (Refer to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>). Therefore, the coordinates of all positions of the points &lsquo;a&rsquo; to &lsquo;d&rsquo; will be computed hereinafter. </paragraph>
<paragraph id="P-0185" lvl="0"><number>&lsqb;0185&rsqb;</number> As described above, by computing the coordinates of positions of the points &lsquo;a&rsquo; to &lsquo;d&rsquo;, each distance D between the image pickup device <highlight><bold>7</bold></highlight>L and each point from the points &lsquo;a&rsquo; to &lsquo;d&rsquo; can be computed respectively, and also each distance D between the image pickup device <highlight><bold>7</bold></highlight>R and each point from the points &lsquo;a&rsquo; to &lsquo;d&rsquo; can be computed respectively. Then, the microcomputer <highlight><bold>17</bold></highlight> computes, assuming that an actual pitch of a pattern added to a pen is P and a pitch of each pattern among the subject images changing according to each distance from the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R to a pen is p (which is recognized by the pattern recognizing section <highlight><bold>26</bold></highlight>), each pattern pitch of pens at each point using the equation described below. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>P&equals;</italic></highlight>(<highlight><italic>D/f</italic></highlight>)<highlight><italic>p </italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0186" lvl="0"><number>&lsqb;0186&rsqb;</number> By using the above equation, each pitch P of pens at each point from the points &lsquo;a&rsquo; to &lsquo;d&rsquo; viewed from the image pickup device <highlight><bold>7</bold></highlight>L is computed, and also each pitch P of pens at each point from the points &lsquo;a&rsquo; to &lsquo;d&rsquo; viewed from the image pickup device <highlight><bold>7</bold></highlight>R is computed respectively. Then, the microcomputer <highlight><bold>17</bold></highlight> compares each pitch P of pens at each point from the points &lsquo;a&rsquo; to &lsquo;d&rsquo; viewed from the image pickup device <highlight><bold>7</bold></highlight>L to each pitch P of pens at each point from the points &lsquo;a&rsquo; to &lsquo;d&rsquo; viewed from the image pickup device <highlight><bold>7</bold></highlight>R respectively, and determines that the points whose pitches P are coincident or similar are points that are actually pointed by pens. </paragraph>
<paragraph id="P-0187" lvl="0"><number>&lsqb;0187&rsqb;</number> The method of enabling identification of each pointing body is not limited to the above mentioned patterns, but there are also methods of changing a color for each pointing body (this will require a use of a color CCD as the CCD <highlight><bold>5</bold></highlight>) or of changing a form and a size or the like of each pointing body. </paragraph>
<paragraph id="P-0188" lvl="0"><number>&lsqb;0188&rsqb;</number> As described above, with the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1, the lighting device <highlight><bold>4</bold></highlight> emits light to the entry area <highlight><bold>2</bold></highlight>, a pointing body illuminated by the light emitted from the lighting device <highlight><bold>4</bold></highlight> is picked up by at least two image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R, each position on the CCD <highlight><bold>5</bold></highlight> where an image of the pointing body is formed is computed according to each output from the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R respectively, coordinates of position of the pointing body is computed by using the computed position, so that coordinates of a position in the entry area pointed using an arbitrary pointing body such as a finger tip or an ordinary pen can be identified, which allows operability of the coordinate-position inputting/detecting device to be enhanced. </paragraph>
<paragraph id="P-0189" lvl="0"><number>&lsqb;0189&rsqb;</number> In the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1, although measures are taken so that light does not directly enter the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R by providing the shade <highlight><bold>8</bold></highlight> on the lighting device <highlight><bold>4</bold></highlight>, the same measures may be taken using some technique other than using the shade <highlight><bold>8</bold></highlight>. The area into which the light is to be emitted may be restricted by the lighting device <highlight><bold>4</bold></highlight> itself. </paragraph>
<paragraph id="P-0190" lvl="0"><number>&lsqb;0190&rsqb;</number> In the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1, although the light absorbing member <highlight><bold>9</bold></highlight> for suppressing reflection cf light is provided on the peripheral section of the entry area <highlight><bold>2</bold></highlight> excluding the upper side thereof, creating a perfect non-reflecting condition described above is not an essential condition for the present invention. For example, in place of the light absorbing member <highlight><bold>9</bold></highlight>, a reflecting member having a uniform reflecting condition in a direction to which light is diverted away from the entry area <highlight><bold>2</bold></highlight> may be provided on the peripheral section of the entry area <highlight><bold>2</bold></highlight> excluding the upper side thereof. As a result, the light emitted from the lighting device <highlight><bold>4</bold></highlight> is reflected by the reflecting member toward outside of the entry area <highlight><bold>2</bold></highlight>, therefore, the reflected light (scattered light) can be prevented from entering into the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R. </paragraph>
<paragraph id="P-0191" lvl="0"><number>&lsqb;0191&rsqb;</number> In the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1, although the lighting device <highlight><bold>4</bold></highlight> is used, coordinates of a position of a pointing body can be computed by picking up an image of the pointing body inserted into the entry area <highlight><bold>2</bold></highlight> by the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R even if the lighting device <highlight><bold>4</bold></highlight> is omitted therefrom. That is because the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1 computes coordinates of a position of a pointing body using each position of images of the pointing body formed on the CCDs <highlight><bold>5</bold></highlight> of the image pickup devices <highlight><bold>7</bold></highlight>L and <highlight><bold>7</bold></highlight>R. As an example, <cross-reference target="DRAWINGS">FIG. 12</cross-reference> shows a front view of a general configuration of the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> from which the lighting device <highlight><bold>4</bold></highlight> is omitted. As shown in <cross-reference target="DRAWINGS">FIG. 12</cross-reference>, when the lighting device <highlight><bold>4</bold></highlight> is omitted from the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight>, the shade <highlight><bold>8</bold></highlight>, the light absorbing member <highlight><bold>9</bold></highlight>, and the light receiving element <highlight><bold>10</bold></highlight> can also be omitted therefrom in accordance with the above case. </paragraph>
<paragraph id="P-0192" lvl="0"><number>&lsqb;0192&rsqb;</number> Furthermore, by using a frame of a display board, the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1 can be integrated with the display board. In addition, the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1 can be used by attaching to the front surface of the display of a computer, and the coordinate-position inputting/detecting device <highlight><bold>1</bold></highlight> according to Embodiment 1 can also be integrated with the display by using the frame of the display. </paragraph>
<paragraph id="P-0193" lvl="0"><number>&lsqb;0193&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a front view showing a general configuration of a coordinate-position inputting/detecting device according to Embodiment 2 of the present invention. <cross-reference target="DRAWINGS">FIG. 13</cross-reference> shows a state, as an example, where the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> according to Embodiment 2 is attached to a display surface d of a computer. The coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> has a frame <highlight><bold>32</bold></highlight> having a rectangular space with substantially the same size as that of the display surface d of a computer, namely having an entry area <highlight><bold>33</bold></highlight> for performing an entry operation using a pointing body such as a finger or a pen by a user. Provided on this frame <highlight><bold>32</bold></highlight> are cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R and a background plate <highlight><bold>37</bold></highlight> which will be described in detail below. </paragraph>
<paragraph id="P-0194" lvl="0"><number>&lsqb;0194&rsqb;</number> The cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R are provided on both edges in the upper side of the entry area <highlight><bold>33</bold></highlight> at a distance L therebetween. The cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R pick up an image of the entry area <highlight><bold>33</bold></highlight> and output the image (photographed image) as an electric signal. These cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R are electronic cameras, and each of the cameras has a two-dimensional image sensor (two-dimensional image pickup element) <highlight><bold>35</bold></highlight> and a focusing optical lens <highlight><bold>36</bold></highlight>. This two-dimensional image sensor <highlight><bold>35</bold></highlight> is a two-dimensional CCD image pickup element formed with a large number of CCDs (Charge Coupled Device) arranged in a matrix. The two-dimensional image sensor <highlight><bold>35</bold></highlight> and focusing optical lens <highlight><bold>36</bold></highlight> are spaced at a distance f therebetween. </paragraph>
<paragraph id="P-0195" lvl="0"><number>&lsqb;0195&rsqb;</number> In addition, the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R are located so that each optical axis of the cameras is parallel with the display surface d and at substantially the same level as that of the surface of the display surface d. Because of this configuration, the display surface d can be prevented from its reflection into the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R. </paragraph>
<paragraph id="P-0196" lvl="0"><number>&lsqb;0196&rsqb;</number> The background plate <highlight><bold>37</bold></highlight> is provided at a location as a peripheral section of the entry area <highlight><bold>33</bold></highlight> excluding the upper side thereof where the whole field of view photographed by the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R is covered. The background plate <highlight><bold>37</bold></highlight> is located so as not to interrupt with the angle of view of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R. <cross-reference target="DRAWINGS">FIG. 14</cross-reference> explains the background plate <highlight><bold>37</bold></highlight> and shows a portion of the background plate <highlight><bold>37</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 14, a</cross-reference> reference pattern P for making easier extraction of a differential image described later is added to the background plate <highlight><bold>37</bold></highlight>. The reference pattern P shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a pattern with horizontal stripes in dark and light colors, but color patterns or the like used in chroma key technology can also be used as the reference pattern P. Furthermore, a pattern in uniform black color which absorbs the light may be used as a reference pattern on the background plate <highlight><bold>37</bold></highlight>. </paragraph>
<paragraph id="P-0197" lvl="0"><number>&lsqb;0197&rsqb;</number> In addition, a light shielding plate B for restricting an area to be photographed is attached to each of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R. <cross-reference target="DRAWINGS">FIG. 15</cross-reference> explains the light shielding plate B, and <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a cross-sectional view of the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, the light shielding plate B has a horizontal notch B1. Then, as shown in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, the light shielding plates B are provided in the front surface of the focusing optical lenses <highlight><bold>36</bold></highlight> of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R respectively, the area which can be photographed by each of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R so restricted that the area matches the entry area <highlight><bold>33</bold></highlight>. It is possible to reduce occurrence of noise due to disturbance light or the like by making the field of view of each of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R narrow with this light shielding plate B. </paragraph>
<paragraph id="P-0198" lvl="0"><number>&lsqb;0198&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a block diagram of the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> according to Embodiment 2. As shown in <cross-reference target="DRAWINGS">FIG. 17</cross-reference>, the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> has a microcomputer <highlight><bold>38</bold></highlight> which provides controls over all the sections of the device. This microcomputer <highlight><bold>38</bold></highlight> comprises a CPU <highlight><bold>40</bold></highlight> which provides centralized control over all the sections of the device, a ROM <highlight><bold>41</bold></highlight> which stores therein fixed data such as a control program, and a RAM <highlight><bold>42</bold></highlight> which stores therein variable data. Connected to the microcomputer <highlight><bold>38</bold></highlight> are, in addition to the above mentioned cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R, a timer <highlight><bold>43</bold></highlight> for counting a prespecified time, a differential unit <highlight><bold>44</bold></highlight> for executing the processing of extracting an image of a pointing body as described later, an xyz computing unit <highlight><bold>45</bold></highlight> for computing coordinates of a three-dimensional position of a pointing body, and an interface (I/F) <highlight><bold>39</bold></highlight> for connecting the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> to a computer (e.g., a personal computer) through a bus <highlight><bold>51</bold></highlight>. </paragraph>
<paragraph id="P-0199" lvl="0"><number>&lsqb;0199&rsqb;</number> Further connected to the microcomputer <highlight><bold>38</bold></highlight> through the bus <highlight><bold>51</bold></highlight> is an EEPROM <highlight><bold>46</bold></highlight> as a non-volatile memory. Provided in the EEPROM <highlight><bold>46</bold></highlight> is a reference image memory <highlight><bold>47</bold></highlight> for storing therein images, for instance, of a state of the entry area <highlight><bold>33</bold></highlight> on starting of the device photographed by the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R as reference images (Refer to <cross-reference target="DRAWINGS">FIG. 21</cross-reference>). Provided in the RAM <highlight><bold>42</bold></highlight> is a coordinate memory <highlight><bold>42</bold></highlight><highlight><italic>a </italic></highlight>for temporarily storing therein coordinates computed by the xyz computing unit <highlight><bold>45</bold></highlight>. </paragraph>
<paragraph id="P-0200" lvl="0"><number>&lsqb;0200&rsqb;</number> Then, description is made for the processing executed by the microcomputer <highlight><bold>38</bold></highlight> according to the control program stored in the ROM <highlight><bold>41</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 18</cross-reference> and <cross-reference target="DRAWINGS">FIG. 19</cross-reference> explain the processing for computing coordinates of a position of a pointing body inserted into the entry area <highlight><bold>33</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 18</cross-reference> shows a state where an arbitrary position within the entry area <highlight><bold>33</bold></highlight> is pointed by a finger C as a pointing body, and <cross-reference target="DRAWINGS">FIG. 19</cross-reference> shows a portion of <cross-reference target="DRAWINGS">FIG. 18</cross-reference> enlarged to make clear a relation between the camera <highlight><bold>34</bold></highlight>L and the finger C. </paragraph>
<paragraph id="P-0201" lvl="0"><number>&lsqb;0201&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 18</cross-reference>, it is assumed that the finger C is inserted into the entry area <highlight><bold>33</bold></highlight> of the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> and an arbitrary position (x, y, z) on the display surface d is pointed or touched thereby. Images of the background plate <highlight><bold>37</bold></highlight> and the finger C are formed on each two-dimensional image sensor <highlight><bold>35</bold></highlight> of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R through each focusing optical lens <highlight><bold>36</bold></highlight>. </paragraph>
<paragraph id="P-0202" lvl="0"><number>&lsqb;0202&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 20</cross-reference>, the images of the background plate <highlight><bold>37</bold></highlight> and the finger C formed on the two-dimensional image sensors <highlight><bold>35</bold></highlight> are outputted from the two-dimensional image sensors <highlight><bold>35</bold></highlight> as photographed images <highlight><bold>48</bold></highlight>. The photographed images <highlight><bold>48</bold></highlight> outputted from the two-dimensional image sensors <highlight><bold>35</bold></highlight> of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R and reference images <highlight><bold>49</bold></highlight> stored in the reference image memories <highlight><bold>47</bold></highlight> are inputted into the differential units <highlight><bold>44</bold></highlight>, and differential images <highlight><bold>50</bold></highlight> are extracted respectively. </paragraph>
<paragraph id="P-0203" lvl="0"><number>&lsqb;0203&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> is an explanatory view showing an example of the reference image <highlight><bold>49</bold></highlight>, and <cross-reference target="DRAWINGS">FIG. 22</cross-reference> is an explanatory view showing an example of the photographed image <highlight><bold>48</bold></highlight>. The reference image <highlight><bold>49</bold></highlight> shows the entry area <highlight><bold>33</bold></highlight> photographed by the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R in an initial state such as on starting of the device. Namely, the reference image <highlight><bold>49</bold></highlight> is the one with only the reference pattern P of the background plate <highlight><bold>37</bold></highlight> photographed as shown in <cross-reference target="DRAWINGS">FIG. 21</cross-reference>. While the photographed image <highlight><bold>48</bold></highlight> is the one with the finger C having been inserted into the entry area <highlight><bold>33</bold></highlight> photographed in addition to the image of the reference image <highlight><bold>49</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 22</cross-reference>. </paragraph>
<paragraph id="P-0204" lvl="0"><number>&lsqb;0204&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> is an explanatory view showing an example of a differential image extracted by the differential unit <highlight><bold>44</bold></highlight>. The differential image <highlight><bold>50</bold></highlight> is a silhouette image consisting of black and white pixels obtained through processing of subtracting the reference image <highlight><bold>49</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 21</cross-reference>) from the photographed image <highlight><bold>48</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 22</cross-reference>) and setting a pixel brighter than a prespecified threshold value to white and a pixel darker than the prespecified threshold value to black. In this case, the section of the white pixels corresponds to the silhouette of the finger C. Then, as shown in <cross-reference target="DRAWINGS">FIG. 20</cross-reference>, each of the differential images <highlight><bold>50</bold></highlight> is inputted in the xyz computing unit <highlight><bold>45</bold></highlight>, and the processing of computing finger-position coordinates (x, y, z). Assuming that the reference pattern is decided as a uniform black pattern for absorbing light described above, there is no need to take a difference between the photographed image <highlight><bold>48</bold></highlight> and reference image <highlight><bold>49</bold></highlight>, therefore, the silhouette image can also be obtained by digitizing the photographed image <highlight><bold>48</bold></highlight> with the prespecified threshold value. </paragraph>
<paragraph id="P-0205" lvl="0"><number>&lsqb;0205&rsqb;</number> Then, specific description is made for the processing of computing coordinates of a three-dimensional position of the finger C by the xyz computing unit <highlight><bold>45</bold></highlight>. At first, the processing for computing coordinates (x, y) of a position will be described herein. The xyz computing unit <highlight><bold>45</bold></highlight> executes the processing for computing a central point in imaging of the finger C in each of the differential image <highlight><bold>50</bold></highlight> and also computing a distance h between the computed central point in the imaging and the center <highlight><bold>35</bold></highlight><highlight><italic>a </italic></highlight>of the two-dimensional image sensor <highlight><bold>35</bold></highlight> (Refer to <cross-reference target="DRAWINGS">FIG. 19</cross-reference>). Each central point of the finger C in the differential images <highlight><bold>50</bold></highlight> corresponds to a position of a white pixel (a portion of the silhouette image of the finger C) with a minimum value of the y coordinate. Namely, the minimum point (x, ymin) in the y coordinate of the white pixels is the central point in the image. Then, assuming that the pixel corresponding to the center <highlight><bold>35</bold></highlight><highlight><italic>a </italic></highlight>of the two-dimensional image sensor <highlight><bold>35</bold></highlight> is x0, the difference x&minus;x0 between the coordinate x of the above mentioned point (x, ymin) and the pixel x0 corresponding to the center <highlight><bold>35</bold></highlight><highlight><italic>a </italic></highlight>of the two-dimensional image sensor <highlight><bold>35</bold></highlight> is a distance h between the center <highlight><bold>35</bold></highlight><highlight><italic>a </italic></highlight>of the two-dimensional image sensor <highlight><bold>35</bold></highlight> and the central point of the image. </paragraph>
<paragraph id="P-0206" lvl="0"><number>&lsqb;0206&rsqb;</number> Further, as shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>, the distance h from the center <highlight><bold>35</bold></highlight><highlight><italic>a </italic></highlight>of the two-dimensional image sensor <highlight><bold>35</bold></highlight> to the central point of the differential image (silhouette image of the finger C) <highlight><bold>50</bold></highlight> depends on an angle &thgr; between a central line of the two-dimensional image sensor <highlight><bold>35</bold></highlight> and a line which links the finger C and the central point in the image. This angle &thgr; can be computed with the following equation. </paragraph>
<paragraph lvl="0"><in-line-formula>&thgr;&equals;<highlight><italic>arctan</italic></highlight>(<highlight><italic>h/f</italic></highlight>)&emsp;&emsp;(10) </in-line-formula></paragraph>
<paragraph id="P-0207" lvl="0"><number>&lsqb;0207&rsqb;</number> Where f is a distance between the focusing optical lens <highlight><bold>6</bold></highlight> and the two-dimensional image sensor <highlight><bold>35</bold></highlight>, which in turn corresponds to a focal length of the focusing optical lens <highlight><bold>6</bold></highlight>. </paragraph>
<paragraph id="P-0208" lvl="0"><number>&lsqb;0208&rsqb;</number> An angle &bgr; between the camera <highlight><bold>34</bold></highlight>L and the finger C can be computed with the following equation. </paragraph>
<paragraph lvl="0"><in-line-formula>&bgr;&equals;&agr;&minus;&thgr;(11) </in-line-formula></paragraph>
<paragraph id="P-0209" lvl="0"><number>&lsqb;0209&rsqb;</number> Where &agr; is an angle between a reference line which links the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R and the central line of the two-dimensional image sensor <highlight><bold>35</bold></highlight>, which in corresponds to an angle at which the camera <highlight><bold>34</bold></highlight>L is attached. </paragraph>
<paragraph id="P-0210" lvl="0"><number>&lsqb;0210&rsqb;</number> By executing the above processing using the differential image <highlight><bold>50</bold></highlight> obtained by the camera <highlight><bold>34</bold></highlight>R, an angle &bgr; between the camera <highlight><bold>34</bold></highlight>R and the finger C together with the angle &bgr; between the camera <highlight><bold>34</bold></highlight>L and the finger C can also be computed. Herein, the angle between the camera <highlight><bold>34</bold></highlight>L and the finger C will be considered as &bgr;1 and the angle between the camera <highlight><bold>34</bold></highlight>R and the pen A is considered as &bgr;2. </paragraph>
<paragraph id="P-0211" lvl="0"><number>&lsqb;0211&rsqb;</number> Then, the coordinates (x, y) of the position of the finger C can be computed with the following equation based on the principle of triangulation. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>x&equals;L tan &bgr;</italic></highlight>2/(<highlight><italic>tan &bgr;</italic></highlight>1&plus;<highlight><italic>tan &bgr;</italic></highlight>2)&emsp;&emsp;(12) </in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>y&equals;x tan &bgr;1&emsp;&emsp;(13) </in-line-formula></paragraph>
<paragraph id="P-0212" lvl="0"><number>&lsqb;0212&rsqb;</number> Then, description is made for the processing of computing the z-coordinate of a position. <cross-reference target="DRAWINGS">FIG. 24</cross-reference> is an explanatory view m showing how a point in the entry area <highlight><bold>33</bold></highlight> is pointed with a finger C. As shown in <cross-reference target="DRAWINGS">FIG. 24</cross-reference>, the z-coordinate of a position is a p distance between the tip of the finger C and the display surface d (each optical axis of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R). However, the distance between the central point of a differential image (silhouette image of the finger C) <highlight><bold>50</bold></highlight> in the Z direction formed on the two-dimensional image sensor <highlight><bold>35</bold></highlight> of the camera <highlight><bold>34</bold></highlight>L (and <highlight><bold>34</bold></highlight>R) and the center <highlight><bold>35</bold></highlight><highlight><italic>a </italic></highlight>of the two-dimensional image sensor <highlight><bold>35</bold></highlight> varies according to the distance D between the camera <highlight><bold>34</bold></highlight>L (and <highlight><bold>34</bold></highlight>R) shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference> and the finger C. </paragraph>
<paragraph id="P-0213" lvl="0"><number>&lsqb;0213&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 25</cross-reference> is an explanatory view showing a relation between a central point of a differential image in the Z direction formed in the two-dimensional image sensor <highlight><bold>35</bold></highlight> and a distance D. As shown in <cross-reference target="DRAWINGS">FIG. 25</cross-reference>, when the finger C is inserted into a point having a height Z from the display surface d, assuming that the distance between the camera <highlight><bold>34</bold></highlight>L (<highlight><bold>34</bold></highlight>R) and the finger C (finger C1 herein) is D1 then image of the finger C is formed at a position separated by the distance k1 from the center <highlight><bold>35</bold></highlight><highlight><italic>a </italic></highlight>of the two-dimensional image sensor <highlight><bold>35</bold></highlight>. Assuming that the distance between the camera <highlight><bold>34</bold></highlight>L (<highlight><bold>34</bold></highlight>R) to the finger C (finger C2 herein) is D2 then image of the finger C is formed at a position separated by the distance k2 from the center <highlight><bold>35</bold></highlight><highlight><italic>a </italic></highlight>of the two-dimensional image sensor <highlight><bold>35</bold></highlight>. Namely, it is clear that, even when the finger C is positioned at the same height Z from the display surface d (each optical axis of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R), a position k of the finger in the image is different depending on a distance D between the camera <highlight><bold>34</bold></highlight>L (<highlight><bold>34</bold></highlight>R) and the finger C. Therefore, the z-coordinate of a position of the finger C can be computed with the following equation according to the distance D computed based on the coordinates (x, y) of the position of the finger C and the angle &agr; described above. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>z&equals;D</italic></highlight>(<highlight><italic>k/f</italic></highlight>)&emsp;&emsp;(14) </in-line-formula></paragraph>
<paragraph id="P-0214" lvl="0"><number>&lsqb;0214&rsqb;</number> By detecting the coordinate (z) of the position of the finger C as described above, it is possible to easily identifying any of the pen-up/pen-down states or even a double click. </paragraph>
<paragraph id="P-0215" lvl="0"><number>&lsqb;0215&rsqb;</number> When a gesture command according to an operation of a pointing body such as the finger C is previously stored in the ROM <highlight><bold>41</bold></highlight> or a storage device for a computer, the microcomputer <highlight><bold>38</bold></highlight> or the computer can determine whether movement of the finger C is for a drawing or for the gesture command according to the z-coordinate of a position. <cross-reference target="DRAWINGS">FIG. 26</cross-reference>A and <cross-reference target="DRAWINGS">FIG. 26B</cross-reference> show examples of a drawing and a gesture command respectively. As shown in <cross-reference target="DRAWINGS">FIG. 26</cross-reference>A and <cross-reference target="DRAWINGS">FIG. 26</cross-reference>B, movements of the finger C for drawing and for the gesture command defined herein are the same in the X-Y direction, but there is a difference in the Z direction. As described above, by combining movements in the X-Y direction with each position in the Z direction, gesture commands based on the movements of the finger C can be built up. As a command allocated to the gesture command shown in <cross-reference target="DRAWINGS">FIG. 26</cross-reference>B, there is &ldquo;turn a page&rdquo; as one of examples. </paragraph>
<paragraph id="P-0216" lvl="0"><number>&lsqb;0216&rsqb;</number> The above mentioned Equations (10) to (14) can previously be stored in the ROM <highlight><bold>41</bold></highlight> as a portion of the control program. </paragraph>
<paragraph id="P-0217" lvl="0"><number>&lsqb;0217&rsqb;</number> The coordinates (x, y, z) of the position of the finger C computed by the xyz computing unit <highlight><bold>45</bold></highlight> are temporarily stored in the coordinate memory <highlight><bold>42</bold></highlight><highlight><italic>a </italic></highlight>and then transferred to the computer through the I/F <highlight><bold>39</bold></highlight>. More specific description is made for the processing in this case with reference to <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. The microcomputer <highlight><bold>38</bold></highlight> makes, when the coordinates (x2, y2, z2) of a position of the finger C are computed by the xyz computing unit <highlight><bold>45</bold></highlight>, namely when the pen-down state is detected (Yes in step S<highlight><bold>1</bold></highlight>), the timer <highlight><bold>22</bold></highlight> start counting a prespecified time (step S<highlight><bold>2</bold></highlight>). </paragraph>
<paragraph id="P-0218" lvl="0"><number>&lsqb;0218&rsqb;</number> In the next step, the microcomputer <highlight><bold>38</bold></highlight> determines whether the coordinates (x2, y2, z2) of the computed position are coincident with the coordinates (x1, y1, z1) of the position stored in the coordinates memory <highlight><bold>42</bold></highlight><highlight><italic>a </italic></highlight>or not (step S<highlight><bold>3</bold></highlight>). When it is determined that the coordinates of the two positions are not coincident (No in step S<highlight><bold>3</bold></highlight>), the microcomputer <highlight><bold>23</bold></highlight> updates the coordinates of the position stored in the coordinate memory <highlight><bold>42</bold></highlight><highlight><italic>a </italic></highlight>to the newly computed coordinates (x2, y2, z2) of the position, and clears the counting by the timer <highlight><bold>22</bold></highlight> (step S<highlight><bold>4</bold></highlight>). Then, the microcomputer <highlight><bold>38</bold></highlight> transfers the coordinates of the position in the coordinates memory <highlight><bold>42</bold></highlight><highlight><italic>a </italic></highlight>to a computer (step S<highlight><bold>5</bold></highlight>) and the system control is returned to step S<highlight><bold>1</bold></highlight> where the microcomputer <highlight><bold>38</bold></highlight> waits for new detection of a pen-down. The computer executes the processing in response to movement of the pen A according to the transferred coordinates of the position. For example, the computer executes the processing for drawing characters and graphics on a display. </paragraph>
<paragraph id="P-0219" lvl="0"><number>&lsqb;0219&rsqb;</number> On the other hand, when it is determined that the coordinates of the two positions are coincident (Yes in step S<highlight><bold>3</bold></highlight>), the microcomputer <highlight><bold>38</bold></highlight> waits for computation of coordinates (x3, y3, z3) of a new position which are different from the coordinates of the position stored in the coordinates memory <highlight><bold>42</bold></highlight><highlight><italic>a </italic></highlight>by the xyz computing unit <highlight><bold>45</bold></highlight> during the period of time until the prespecified time is counted by the timer (step S<highlight><bold>6</bold></highlight>, step S<highlight><bold>7</bold></highlight>, step S<highlight><bold>3</bold></highlight>). More specifically, the microcomputer <highlight><bold>38</bold></highlight> waits for computation of the coordinates of a new position by the xyz computing unit <highlight><bold>45</bold></highlight> (detection of the pen-down state), and when the, coordinates of the new position are computed (Yes in step S<highlight><bold>7</bold></highlight>) the system control is shifted to step S<highlight><bold>3</bold></highlight> where the microcomputer <highlight><bold>38</bold></highlight> determines whether the coordinates of the computed position is coincident with the coordinates of the position in the coordinates memory <highlight><bold>42</bold></highlight><highlight><italic>a </italic></highlight>or not. Then, when it is determined that the coordinates of the two positions are not coincident (No in step S<highlight><bold>3</bold></highlight>), the microcomputer <highlight><bold>38</bold></highlight> executes the processing in step S<highlight><bold>4</bold></highlight> and step S<highlight><bold>5</bold></highlight> as described above. On the other hand, when it is determined that the coordinates of the two positions are coincident (Yes in step S<highlight><bold>3</bold></highlight>), the microcomputer <highlight><bold>17</bold></highlight> shifts the system control again to step S<highlight><bold>6</bold></highlight>. </paragraph>
<paragraph id="P-0220" lvl="0"><number>&lsqb;0220&rsqb;</number> Then, the microcomputer <highlight><bold>38</bold></highlight> executes, when it is determined that the prespecified time has passed (Yes in step S<highlight><bold>6</bold></highlight>), the error processing (step S<highlight><bold>8</bold></highlight>) and the system control is returned to step S<highlight><bold>1</bold></highlight> where is waits for new detection of a pen-down. Namely, when non coincident coordinates can be obtained (step S<highlight><bold>3</bold></highlight>) until the prespecified time passes, it is considered that there is no movement of the finger C. Therefore, the coordinates of the computed position by the xyz computing unit <highlight><bold>45</bold></highlight> are regarded as a position of, for instance, dust or something deposited on the display surface d, and the error processing is executed in step S<highlight><bold>8</bold></highlight>. As this error processing, the microcomputer <highlight><bold>38</bold></highlight> does not update the coordinates of the position stored in the coordinates memory <highlight><bold>42</bold></highlight><highlight><italic>a</italic></highlight>, but discards the coordinates of the position computed in step S<highlight><bold>1</bold></highlight> so that the coordinates of the position in the coordinates memory <highlight><bold>42</bold></highlight><highlight><italic>a </italic></highlight>will not be transferred to the computer. </paragraph>
<paragraph id="P-0221" lvl="0"><number>&lsqb;0221&rsqb;</number> In addition, the microcomputer <highlight><bold>38</bold></highlight> stores a photographed image <highlight><bold>48</bold></highlight> as a source of detecting the coordinates of the position to be abandoned in the reference image memory <highlight><bold>47</bold></highlight> of the EEPROM <highlight><bold>46</bold></highlight> as a new reference image <highlight><bold>49</bold></highlight>. With this operation, even when dust or something exists in the entry area <highlight><bold>33</bold></highlight>, the image of the dust is recognized as a portion of the reference image <highlight><bold>49</bold></highlight>, thus, erroneous recognition of dust as a pointing body can be prevented. </paragraph>
<paragraph id="P-0222" lvl="0"><number>&lsqb;0222&rsqb;</number> As described above, with the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> according to Embodiment 2, images of the entry area <highlight><bold>33</bold></highlight> photographed by the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R are stored as reference images respectively, and then, by extracting the images of the entry area <highlight><bold>33</bold></highlight> photographed by the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R and each difference of the corresponding reference images respectively, images of a pointing body inserted into the entry area <highlight><bold>33</bold></highlight> are extracted, each position of the images of the pointing body formed on each of the CCDs <highlight><bold>5</bold></highlight> is computed according to the extracted images of the pointing body, and coordinates of the position of the pointing body are identified by using the computed position of each imaging, which allows coordinates of a position in an entry area pointed with an arbitrary pointing body such as a finger tip or an ordinary pen to be identified without using any particular pointing body, therefore, operability of the coordinate-position inputting/detecting device can be enhanced. </paragraph>
<paragraph id="P-0223" lvl="0"><number>&lsqb;0223&rsqb;</number> In the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> according to Embodiment 2, although the two-dimensional CCD image pickup element is used as the two-dimensional image sensor <highlight><bold>35</bold></highlight> (two-dimensional image pickup element) for each of the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R, the sensor is not limited to the above sensor, but a plurality of one-dimensional CCD image pickup elements may be used. When a color two-dimensional image sensor (two-dimensional image pickup element) is used, not only coordinates (x, y, z) of a position but also data for color added to a pointing body (e.g., a color soft-point pen) can be transferred to a personal computer. </paragraph>
<paragraph id="P-0224" lvl="0"><number>&lsqb;0224&rsqb;</number> Furthermore, in the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> according to Embodiment 2, although two cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R are used, number of cameras is not limited to two. Namely, at least two cameras may be required. Location where the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R are attached are not limited to the upper side of the entry area <highlight><bold>33</bold></highlight>, but the cameras <highlight><bold>34</bold></highlight>L and <highlight><bold>34</bold></highlight>R can be attached to any arbitrary location. </paragraph>
<paragraph id="P-0225" lvl="0"><number>&lsqb;0225&rsqb;</number> In Embodiment 2, although the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> is attached to the front side of the display, the location is not limited to the front side thereof, the device may also be attached to a display board. In addition, the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> according to Embodiment 2 may be integrated with a display by using a frame of the display. Furthermore, by using a frame of the display board, the coordinate-position inputting/detecting device <highlight><bold>31</bold></highlight> according to Embodiment 2 may also be integrated with the display board. </paragraph>
<paragraph id="P-0226" lvl="0"><number>&lsqb;0226&rsqb;</number> As Embodiment 3 of the present invention, a display board system using the coordinate-position inputting/detecting device described in Embodiments 1 and 2 will be described. The display board system according to Embodiment 3 will be described hereinafter in detail in the order of: </paragraph>
<paragraph id="P-0227" lvl="2"><number>&lsqb;0227&rsqb;</number> 1. System configuration, </paragraph>
<paragraph id="P-0228" lvl="2"><number>&lsqb;0228&rsqb;</number> 2. Operation, and </paragraph>
<paragraph id="P-0229" lvl="2"><number>&lsqb;0229&rsqb;</number> 3. Effects. </paragraph>
<paragraph id="P-0230" lvl="7"><number>&lsqb;0230&rsqb;</number> 1. System Configuration </paragraph>
<paragraph id="P-0231" lvl="0"><number>&lsqb;0231&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 27</cross-reference> is a block diagram showing the display board system according to Embodiment 3. The display board system <highlight><bold>100</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 27</cross-reference> principally comprises a plasma display panel (Described &ldquo;PDP&rdquo; hereinafter) <highlight><bold>101</bold></highlight> for displaying the images. A coordinate-position input device <highlight><bold>102</bold></highlight> is provided on the front surface of the PDP <highlight><bold>101</bold></highlight> with an entry area (Refer to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>) used as a touch surface (writing surface) for inputting characters and graphics written with a fingertip or a pen through the touch surface (which corresponds to the coordinate-position inputting/detecting device described in Embodiments 1 to 3). A controller <highlight><bold>103</bold></highlight> is provided for performing an operation of calculation of a position of coordinates on the touch surface when touched with a fingertip or a pen. A computer <highlight><bold>104</bold></highlight> (a personal computer) is provided for receiving positional information for coordinates from the controller <highlight><bold>103</bold></highlight> and providing controls over the system as a whole such as processing for illustrating characters and graphics inputted through the coordinate-position input device <highlight><bold>102</bold></highlight> onto the PDP <highlight><bold>101</bold></highlight>. </paragraph>
<paragraph id="P-0232" lvl="0"><number>&lsqb;0232&rsqb;</number> Various types of peripheral equipment can be connected to the computer <highlight><bold>104</bold></highlight> of the display board system <highlight><bold>100</bold></highlight>. As an example, <cross-reference target="DRAWINGS">FIG. 27</cross-reference> shows a scanner <highlight><bold>105</bold></highlight> for reading images of a document and a printer <highlight><bold>106</bold></highlight> for outputting image data onto a recording paper connected to the computer <highlight><bold>104</bold></highlight>. Furthermore, the display board system <highlight><bold>100</bold></highlight> can be connected to a network <highlight><bold>107</bold></highlight> through the computer <highlight><bold>104</bold></highlight>. This allows data prepared by other computers that are connected on the network <highlight><bold>107</bold></highlight> to be displayed on the PDP <highlight><bold>101</bold></highlight> or data prepared by the display board system <highlight><bold>100</bold></highlight> to be transferred to other computer. </paragraph>
<paragraph id="P-0233" lvl="0"><number>&lsqb;0233&rsqb;</number> Furthermore, a video input terminal and a speaker are provided in the PDP <highlight><bold>101</bold></highlight> although they are omitted from the figure. By connecting various types of information equipment and AV equipment such as a video player <highlight><bold>108</bold></highlight>, a laser disk player, a DVD player, or a video camera, the PDP <highlight><bold>101</bold></highlight> can be used as a large sized screen monitor. </paragraph>
<paragraph id="P-0234" lvl="0"><number>&lsqb;0234&rsqb;</number> Herein, a 40-inch or 50-inch large sized screen usable as a display board is used as the PDP <highlight><bold>101</bold></highlight>. A plasma display is employed as a display in Embodiment 3 because the plasma display has characteristics such that the display can be upsized, has high brightness so that it is not required to darken the room as required when a projector is used, and that a view field angle is wider as compared to that of a liquid crystal display and further moving images can smoothly be reproduced. As described above, as the plasma display is used, the display unit according to Embodiment 3 can be made thinner (downsized). However, although it is assumed that the PDP <highlight><bold>101</bold></highlight> is used herein, it is needless to say that some other display unit such as a CRT or a crystal liquid display can be used instead of the PDP <highlight><bold>101</bold></highlight>. </paragraph>
<paragraph id="P-0235" lvl="0"><number>&lsqb;0235&rsqb;</number> As the coordinate-position input device <highlight><bold>102</bold></highlight>, the coordinate-position inputting/detecting device described in Embodiments 1 and 2 is used as already described above. Therefore, in Embodiment 3, description of the coordinate-position input device <highlight><bold>102</bold></highlight> is omitted. The controller <highlight><bold>103</bold></highlight> inputs an operation performed on the touch surface of the coordinate-position input device <highlight><bold>102</bold></highlight> to a computer as positional information for coordinates. This controller <highlight><bold>103</bold></highlight> corresponds to the microcomputer <highlight><bold>17</bold></highlight>, the xy computing unit <highlight><bold>23</bold></highlight>, and the shadow correcting section <highlight><bold>27</bold></highlight> or the like in Embodiment 1 and also corresponds to the microcomputer <highlight><bold>38</bold></highlight> and xyz computing unit <highlight><bold>45</bold></highlight> or the like in Embodiment 2. It should be noted that the computer <highlight><bold>104</bold></highlight> executes various processing described later such that a mouse cursor is displayed at the position where a user touches the touch surface of the PDP <highlight><bold>101</bold></highlight> according to positional information for coordinates inputted from the controller <highlight><bold>103</bold></highlight>. </paragraph>
<paragraph id="P-0236" lvl="0"><number>&lsqb;0236&rsqb;</number> A general configuration of the computer <highlight><bold>104</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 27</cross-reference> will be described below. <cross-reference target="DRAWINGS">FIG. 28</cross-reference> is a block diagram of the computer <highlight><bold>104</bold></highlight>. The computer <highlight><bold>104</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 28</cross-reference> is a personal computer which comprises a CPU <highlight><bold>500</bold></highlight> which provides controls over the entire system. A ROM <highlight><bold>501</bold></highlight> is provided for storing therein a boot program or the like. A RAM <highlight><bold>502</bold></highlight> is utilized as a work area of the CPU <highlight><bold>500</bold></highlight>. A keyboard <highlight><bold>503</bold></highlight> is utilized for inputting characters, numerical values, and various instructions or some other data. A mouse <highlight><bold>504</bold></highlight> is provided for moving a cursor and selecting an area. A hard disk <highlight><bold>509</bold></highlight> stores therein an operating system (OS) <highlight><bold>505</bold></highlight>, display board software <highlight><bold>506</bold></highlight> for making the display board system <highlight><bold>100</bold></highlight> function as a display board, a device driver <highlight><bold>507</bold></highlight> for making the coordinate-position input device <highlight><bold>102</bold></highlight> and controller <highlight><bold>103</bold></highlight> operate on the computer <highlight><bold>104</bold></highlight>, and various application programs <highlight><bold>508</bold></highlight> such as word processor and spreadsheet software. A graphics board <highlight><bold>510</bold></highlight> connected to the PDP <highlight><bold>101</bold></highlight> provides controls over display of images on to the PDP <highlight><bold>101</bold></highlight>. A network card <highlight><bold>511</bold></highlight> (or may be a modem) is provided for connecting the display board system <highlight><bold>100</bold></highlight> to the network <highlight><bold>107</bold></highlight> through the computer <highlight><bold>104</bold></highlight>. An interface (I/F) <highlight><bold>512</bold></highlight> is provided for connecting thereto the controller <highlight><bold>103</bold></highlight>, scanner <highlight><bold>105</bold></highlight> and printer <highlight><bold>106</bold></highlight>. A bus <highlight><bold>513</bold></highlight> is utilized for connecting the above mentioned component devices to each other. </paragraph>
<paragraph id="P-0237" lvl="0"><number>&lsqb;0237&rsqb;</number> Although the interface for connecting peripheral equipment to the computer <highlight><bold>104</bold></highlight> is shown as one block indicated by the I/F <highlight><bold>512</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 28</cross-reference> for convenience, I/F <highlight><bold>512</bold></highlight> actually comprises a serial interface such as RS-232C for connecting thereto the controller <highlight><bold>103</bold></highlight>, a parallel interface such as Centronics for connecting thereto the printer <highlight><bold>106</bold></highlight>, and a SCSI for connecting thereto the scanner <highlight><bold>105</bold></highlight>. </paragraph>
<paragraph id="P-0238" lvl="0"><number>&lsqb;0238&rsqb;</number> It should be noted that, as shown in <cross-reference target="DRAWINGS">FIG. 27</cross-reference>, the controller <highlight><bold>103</bold></highlight> is configured independently from the computer <highlight><bold>104</bold></highlight>, however, the controller <highlight><bold>103</bold></highlight> may be integrated with the computer <highlight><bold>104</bold></highlight>, and the function of the controller <highlight><bold>103</bold></highlight> may be added to the computer <highlight><bold>104</bold></highlight> itself. Although not shown in <cross-reference target="DRAWINGS">FIG. 28, a</cross-reference> floppy disk drive, a CD-ROM drive, and a MO drive can be incorporated in the computer <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0239" lvl="0"><number>&lsqb;0239&rsqb;</number> The component devices constituting the display board system <highlight><bold>100</bold></highlight> as described above are accommodated in the frame unit in an integrated form, and downsizing of a system as a whole, operability, adaptability for handling and convenience can be improved. The display board system <highlight><bold>100</bold></highlight> is accommodated in the frame unit as described above is because, a wide space for installation thereof is required if the component devices are discretely managed and a long time is required for moving the whole device from one place to another as the display board system <highlight><bold>100</bold></highlight> comprises a plurality of component devices as shown in <cross-reference target="DRAWINGS">FIG. 27</cross-reference>. </paragraph>
<paragraph id="P-0240" lvl="0"><number>&lsqb;0240&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 29</cross-reference> is a perspective view of the frame unit with the display board system <highlight><bold>100</bold></highlight> accommodated therein viewed from the front side thereof, and <cross-reference target="DRAWINGS">FIG. 30</cross-reference> is a perspective view thereof viewed from the rear side thereof. The frame unit <highlight><bold>600</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 29</cross-reference> and <cross-reference target="DRAWINGS">FIG. 30</cross-reference> comprises a panel section <highlight><bold>601</bold></highlight> for accommodating the PDP <highlight><bold>101</bold></highlight> and coordinate-position input device <highlight><bold>102</bold></highlight> therein. A controller accommodating section <highlight><bold>602</bold></highlight> accommodates the controller <highlight><bold>103</bold></highlight> therein. A stand <highlight><bold>603</bold></highlight> supports the panel section <highlight><bold>601</bold></highlight> and the controller accommodating section <highlight><bold>602</bold></highlight> at a specified height. Finally, an equipment accommodating section <highlight><bold>604</bold></highlight> accommodates the computer <highlight><bold>104</bold></highlight>, scanner <highlight><bold>105</bold></highlight>, printer <highlight><bold>106</bold></highlight>, and a video player <highlight><bold>108</bold></highlight> or the like therein. </paragraph>
<paragraph id="P-0241" lvl="0"><number>&lsqb;0241&rsqb;</number> The PDP <highlight><bold>101</bold></highlight> and coordinate-position input device <highlight><bold>102</bold></highlight> are integrated so that the coordinate-position input device <highlight><bold>102</bold></highlight> is positioned in front of the PDP <highlight><bold>101</bold></highlight>, and as shown in <cross-reference target="DRAWINGS">FIG. 29</cross-reference>, the coordinate-position input device <highlight><bold>102</bold></highlight> is accommodated in the panel section <highlight><bold>601</bold></highlight> so that the touch surface <highlight><bold>201</bold></highlight> of the coordinate-position input device <highlight><bold>102</bold></highlight> is positioned in the front section of the panel section <highlight><bold>601</bold></highlight>. As described above, the panel section <highlight><bold>601</bold></highlight> accommodates therein the PDP <highlight><bold>101</bold></highlight> and coordinate-position input device <highlight><bold>102</bold></highlight>, and constitutes a display surface and a writing surface (touch surface <highlight><bold>201</bold></highlight>) of the display board. </paragraph>
<paragraph id="P-0242" lvl="0"><number>&lsqb;0242&rsqb;</number> Furthermore, the controller <highlight><bold>103</bold></highlight> is accommodated, as shown in <cross-reference target="DRAWINGS">FIG. 30</cross-reference>, in the controller accommodating section <highlight><bold>602</bold></highlight> provided on the rear side of the panel section <highlight><bold>601</bold></highlight>. The panel section <highlight><bold>601</bold></highlight> is mounted on the stand <highlight><bold>603</bold></highlight> of the equipment accommodating section <highlight><bold>604</bold></highlight> through a stay <highlight><bold>605</bold></highlight> to be supported so that the image display surface of the PDP <highlight><bold>101</bold></highlight> and the touch surface <highlight><bold>201</bold></highlight> of the coordinate-position input device <highlight><bold>102</bold></highlight> are positioned at a specified height. The controller accommodating section <highlight><bold>602</bold></highlight> is also similarly mounted on the stand <highlight><bold>603</bold></highlight>. </paragraph>
<paragraph id="P-0243" lvl="0"><number>&lsqb;0243&rsqb;</number> It should be noted that, in the front side of the panel section <highlight><bold>601</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 29</cross-reference>, the reference numeral <highlight><bold>606</bold></highlight> indicates a speaker and the reference numeral <highlight><bold>607</bold></highlight> indicates a power lamp of the PDP <highlight><bold>101</bold></highlight>. Furthermore, in the display board system <highlight><bold>100</bold></highlight> according to Embodiment 3, although detailed description is omitted herein, switching of output sources of images from the PDP <highlight><bold>101</bold></highlight> to the computer <highlight><bold>104</bold></highlight> or the video player <highlight><bold>108</bold></highlight> and the like and adjustment of volume can be performed using a remote control unit, and the reference numeral <highlight><bold>608</bold></highlight> corresponds to a remote control light receiving section for receiving light from a remote control unit. </paragraph>
<paragraph id="P-0244" lvl="0"><number>&lsqb;0244&rsqb;</number> Designated at the reference numeral <highlight><bold>609</bold></highlight>, on the rear side of the panel section <highlight><bold>601</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 30</cross-reference>, is a handle for moving the display board system <highlight><bold>100</bold></highlight>. <highlight><bold>610</bold></highlight> is a control panel for setting brightness and contrast or the like of the PDP <highlight><bold>101</bold></highlight>, and <highlight><bold>611</bold></highlight> is an angle adjusting lever for adjusting the angle of the panel section <highlight><bold>601</bold></highlight> described later. Furthermore, a connector panel for connecting the computer <highlight><bold>104</bold></highlight> or video player <highlight><bold>108</bold></highlight> and the like to the PDP <highlight><bold>101</bold></highlight> or the controller <highlight><bold>103</bold></highlight> and the like is provided on the bottom side of the controller accommodating section <highlight><bold>602</bold></highlight> although it is not shown in the figure. </paragraph>
<paragraph id="P-0245" lvl="0"><number>&lsqb;0245&rsqb;</number> Namely, an image output cable and an audio output cable for the computer <highlight><bold>104</bold></highlight> are connected to the PDP <highlight><bold>101</bold></highlight> through this connector panel, and the computer <highlight><bold>104</bold></highlight> and the controller <highlight><bold>103</bold></highlight> are connected to each other through this connector panel. Furthermore, various types of information equipment and AV equipment such as the video player <highlight><bold>108</bold></highlight> and the like are also connected to the PDP <highlight><bold>101</bold></highlight> through this connector panel. </paragraph>
<paragraph id="P-0246" lvl="0"><number>&lsqb;0246&rsqb;</number> The equipment accommodating section <highlight><bold>604</bold></highlight> of the frame unit <highlight><bold>600</bold></highlight> comprises a computer accommodating section <highlight><bold>612</bold></highlight> for accommodating the computer <highlight><bold>104</bold></highlight> therein. There is a video accommodating section <highlight><bold>613</bold></highlight> for accommodating various information equipment and AV equipment such as the video player <highlight><bold>108</bold></highlight>, a laser disk player, or a DVD player. A printer accommodating section <highlight><bold>614</bold></highlight> accommodates the printer <highlight><bold>106</bold></highlight>. The computer accommodating section <highlight><bold>612</bold></highlight>, video accommodating section <highlight><bold>613</bold></highlight> and printer accommodating section <highlight><bold>614</bold></highlight> are provided in this order from bottom to top. As described, by arranging the devices in the order of the heaviest one in the bottom and lighter ones in the top in the vertical direction, stability of the frame unit <highlight><bold>600</bold></highlight> at the time of movement and installation thereof can be insured even if there is the board section <highlight><bold>601</bold></highlight> having the PDP <highlight><bold>101</bold></highlight> and coordinate-position input device <highlight><bold>102</bold></highlight> in the upper side. Although an accommodating section for accommodating the scanner <highlight><bold>105</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 27</cross-reference> is not provided in the equipment accommodating section <highlight><bold>604</bold></highlight>, the accommodating section for the scanner <highlight><bold>105</bold></highlight> may be provided therein on condition that the devices are arranged in the order of the heaviest one at the bottom and the lighter ones at the top of the heavier ones. </paragraph>
<paragraph id="P-0247" lvl="0"><number>&lsqb;0247&rsqb;</number> The computer accommodating section <highlight><bold>612</bold></highlight> has doors on both sides thereof, through which a floppy disk or a CD-ROM can be inserted thereinto. The video accommodating section <highlight><bold>613</bold></highlight> has a door on the front side thereof, through which a video tape or a laser disk or the like can be inserted into. Furthermore, the printer accommodating section <highlight><bold>614</bold></highlight> has a door on the front side thereof, through which a printer can be operated, and there is a place on this door so that a pen (not shown in the figure) used for touching the touch surface <highlight><bold>201</bold></highlight> of the coordinate-position input device <highlight><bold>102</bold></highlight> can be accommodated therein. In addition, the rear surface of the printer accommodating section <highlight><bold>614</bold></highlight> is not covered with the frame, therefore, the printer <highlight><bold>106</bold></highlight> can be accommodated such that the paper feed tray of this printer is positioned in the outside of the frame unit <highlight><bold>600</bold></highlight> (Refer to <cross-reference target="DRAWINGS">FIG. 31</cross-reference>), and operability can be enhanced. </paragraph>
<paragraph id="P-0248" lvl="0"><number>&lsqb;0248&rsqb;</number> It should be noted that, in the front side of the equipment accommodating section <highlight><bold>604</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 29</cross-reference>, the reference numeral <highlight><bold>615</bold></highlight> indicates a keyboard base for placing thereon a keyboard <highlight><bold>503</bold></highlight> for the computer <highlight><bold>104</bold></highlight> so that it can be used at any time. Further, the reference numeral <highlight><bold>616</bold></highlight> indicates casters for moving the display board system <highlight><bold>100</bold></highlight> with the entire frame unit <highlight><bold>600</bold></highlight>. Designated at the reference numeral <highlight><bold>617</bold></highlight>, in the rear surface of the equipment accommodating section <highlight><bold>604</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 30</cross-reference>, is a power tap for supplying power to the PDP <highlight><bold>101</bold></highlight>, the controller <highlight><bold>103</bold></highlight>, and the-computer <highlight><bold>104</bold></highlight>. <highlight><bold>618</bold></highlight> is a cable guide for wiring various cables, and <highlight><bold>619</bold></highlight> is a main power switch for the display board system <highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0249" lvl="0"><number>&lsqb;0249&rsqb;</number> As described above, by accommodating the display board system <highlight><bold>100</bold></highlight> in the frame unit <highlight><bold>600</bold></highlight>, the display board system <highlight><bold>100</bold></highlight> can easily be moved and installed only by moving the frame unit <highlight><bold>600</bold></highlight>. Furthermore, stability of the frame unit <highlight><bold>600</bold></highlight> when it is moved and installed can be insured because the devices are arranged in the order of the heaviest one to a lighter one from the bottom in the direction of gravity (vertical direction) in the equipment accommodating section <highlight><bold>604</bold></highlight> of the frame unit <highlight><bold>600</bold></highlight>. </paragraph>
<paragraph id="P-0250" lvl="0"><number>&lsqb;0250&rsqb;</number> Furthermore, taking into consideration that, for instance, light of a fluorescent tube directly enters the display surface of the PDP <highlight><bold>101</bold></highlight>, which may cause an image appearing on the PDP <highlight><bold>101</bold></highlight> to be difficult to be seen, an angle adjusting mechanism section for adjusting an angle of the board section <highlight><bold>601</bold></highlight> (a display surface and a writing surface of a display board) is provided in the frame unit <highlight><bold>600</bold></highlight> described above. An example of configuration of this angle adjusting mechanism section is described below. </paragraph>
<paragraph id="P-0251" lvl="0"><number>&lsqb;0251&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 31</cross-reference> is a side view of the frame unit <highlight><bold>600</bold></highlight> viewed from the right side thereof. In <cross-reference target="DRAWINGS">FIG. 31</cross-reference>, the reference numeral <highlight><bold>800</bold></highlight> indicates a pivotal supporting point, and the reference numeral <highlight><bold>801</bold></highlight> indicates a pivotal guide. The board section <highlight><bold>601</bold></highlight> is pivotally mounted on the stand <highlight><bold>603</bold></highlight> existing on both sides of the frame unit <highlight><bold>600</bold></highlight> around the pivotal supporting point <highlight><bold>800</bold></highlight> through the stay <highlight><bold>605</bold></highlight>. Namely, the board section <highlight><bold>601</bold></highlight> can be rotated in the direction indicated by the arrow in <cross-reference target="DRAWINGS">FIG. 31</cross-reference> around the pivotal supporting point <highlight><bold>800</bold></highlight> just like nodding so that an angle at which light of a fluorescent tube is not reflected into the PDP <highlight><bold>101</bold></highlight> can be adjusted. Herein the pivot guide <highlight><bold>801</bold></highlight> restricts the angle of the board section <highlight><bold>601</bold></highlight> pivoting around the pivotal supporting point <highlight><bold>800</bold></highlight>, and the angle adjusting lever <highlight><bold>611</bold></highlight> pivots the board section <highlight><bold>601</bold></highlight> through a mechanism described later to adjust an angle thereof. </paragraph>
<paragraph id="P-0252" lvl="0"><number>&lsqb;0252&rsqb;</number> In Embodiment 3, it is assumed that the angle of the board section <highlight><bold>601</bold></highlight> can be adjusted in a range from zero degree (the board section <highlight><bold>601</bold></highlight> in an upright position) to five degrees (the board section <highlight><bold>601</bold></highlight> in a downward-slanting position) by operating the angle adjusting lever <highlight><bold>611</bold></highlight>. It is also assumed that the angle adjusting mechanism section <highlight><bold>802</bold></highlight> comprises the pivotal supporting point <highlight><bold>800</bold></highlight>, pivot guide <highlight><bold>801</bold></highlight>, angle adjusting lever <highlight><bold>611</bold></highlight>, and each component member described below. </paragraph>
<paragraph id="P-0253" lvl="0"><number>&lsqb;0253&rsqb;</number> It should be noted that, in <cross-reference target="DRAWINGS">FIG. 31</cross-reference>, the reference numeral <highlight><bold>803</bold></highlight> indicates a tray of the printer <highlight><bold>106</bold></highlight> that is accommodated in the printer accommodating section <highlight><bold>614</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 31</cross-reference>, the angle adjusting lever <highlight><bold>611</bold></highlight> for adjusting an angle of the board section <highlight><bold>601</bold></highlight> is provided at such a position that it does not hinder the feeding of recording paper to the tray <highlight><bold>803</bold></highlight>. </paragraph>
<paragraph id="P-0254" lvl="0"><number>&lsqb;0254&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 32</cross-reference> and <cross-reference target="DRAWINGS">FIG. 33</cross-reference> show configuration of the angle adjusting mechanism section <highlight><bold>802</bold></highlight> viewed from the upper side thereof. <cross-reference target="DRAWINGS">FIG. 32</cross-reference> shows the board section <highlight><bold>601</bold></highlight> positioned at an angle of five degrees and <cross-reference target="DRAWINGS">FIG. 33</cross-reference> shows the board section <highlight><bold>601</bold></highlight> positioned at an angle of zero degree. Furthermore, <cross-reference target="DRAWINGS">FIG. 34</cross-reference> is a view showing configuration of the angle adjusting mechanism section <highlight><bold>802</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 32</cross-reference> and <cross-reference target="DRAWINGS">FIG. 33</cross-reference> viewed from the side thereof. <cross-reference target="DRAWINGS">FIG. 34</cross-reference> corresponds to the board section <highlight><bold>601</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 33</cross-reference> positioned at an angle of zero degree. </paragraph>
<paragraph id="P-0255" lvl="0"><number>&lsqb;0255&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 32</cross-reference> to <cross-reference target="DRAWINGS">FIG. 34</cross-reference>, the reference numeral <highlight><bold>900</bold></highlight> indicates a PDP angle pivotally mounted between the stays <highlight><bold>605</bold></highlight> with a PDP supporting point <highlight><bold>901</bold></highlight>. The reference numeral <highlight><bold>902</bold></highlight> indicates a stand stay pivotally mounted between the stands <highlight><bold>603</bold></highlight> with a stand supporting point <highlight><bold>903</bold></highlight> and with a lever bearer <highlight><bold>904</bold></highlight> used for angle adjustment of the board section <highlight><bold>601</bold></highlight> together with the angle adjusting lever <highlight><bold>611</bold></highlight> mounted thereon. </paragraph>
<paragraph id="P-0256" lvl="0"><number>&lsqb;0256&rsqb;</number> The angle adjusting lever <highlight><bold>611</bold></highlight> has such a shape that it can sandwichably hold the PDP angle <highlight><bold>900</bold></highlight> and the stand stay <highlight><bold>902</bold></highlight> therebetween and is pivotally mounted on a lever supporting point <highlight><bold>905</bold></highlight> in the side of the PDP angle <highlight><bold>900</bold></highlight>. In addition, provided in the angle adjusting lever <highlight><bold>611</bold></highlight> is a bearing <highlight><bold>908</bold></highlight> contacting a flat section <highlight><bold>906</bold></highlight> as well as a slant section <highlight><bold>907</bold></highlight> of the lever bearer <highlight><bold>904</bold></highlight> mounted on the stand stay <highlight><bold>902</bold></highlight> for rotating in association with pivot of the angle adjusting lever <highlight><bold>611</bold></highlight>. </paragraph>
<paragraph id="P-0257" lvl="0"><number>&lsqb;0257&rsqb;</number> Herein, it is assumed that the angle adjusting mechanism section <highlight><bold>802</bold></highlight> is in a state shown in <cross-reference target="DRAWINGS">FIG. 32</cross-reference> and the board section <highlight><bold>601</bold></highlight> is positioned at an angle of five degrees. When a user operates the angle adjusting lever <highlight><bold>611</bold></highlight> to the left direction (to the direction indicated by the arrow in the <cross-reference target="DRAWINGS">FIG. 32</cross-reference>), the angle adjusting lever <highlight><bold>611</bold></highlight> pivots around the lever supporting point <highlight><bold>905</bold></highlight>, the bearing <highlight><bold>908</bold></highlight> of the angle adjusting lever <highlight><bold>611</bold></highlight> moves along the flat section <highlight><bold>906</bold></highlight> of the lever bearer <highlight><bold>904</bold></highlight> in association with the pivot and also moves upward along the slope of the slant section <highlight><bold>907</bold></highlight>, and as a result, a force that pushes the PDP angle <highlight><bold>900</bold></highlight> forward is generated. Namely, the lever bearer <highlight><bold>904</bold></highlight> is fixed to the stand <highlight><bold>603</bold></highlight> through the stand stay <highlight><bold>902</bold></highlight>, and the PDP angle <highlight><bold>900</bold></highlight> is mounted on the stays <highlight><bold>605</bold></highlight> pivotally supporting the board section <highlight><bold>601</bold></highlight> at the pivotal supporting points <highlight><bold>800</bold></highlight> and the pivot guides <highlight><bold>801</bold></highlight>, therefore, the board section <highlight><bold>601</bold></highlight> can pivot together with the PDP angle <highlight><bold>900</bold></highlight> (the lower edge of the board section <highlight><bold>601</bold></highlight> can be pushed forward) by operating the angle adjusting lever <highlight><bold>611</bold></highlight>. </paragraph>
<paragraph id="P-0258" lvl="0"><number>&lsqb;0258&rsqb;</number> Through this operation of the angle adjusting lever <highlight><bold>611</bold></highlight>, the angle adjusting mechanism section <highlight><bold>802</bold></highlight> is changed from the state shown in <cross-reference target="DRAWINGS">FIG. 32</cross-reference> to that shown in <cross-reference target="DRAWINGS">FIG. 33</cross-reference>, and the angle of the board section <highlight><bold>601</bold></highlight> can be changed from five degrees to zero degree. Namely, as shown in <cross-reference target="DRAWINGS">FIG. 32</cross-reference> and <cross-reference target="DRAWINGS">FIG. 33</cross-reference>, by increasing the distance between the PDP angle <highlight><bold>900</bold></highlight> and the stand stay <highlight><bold>902</bold></highlight> from L1 to L2, the angle of the board section <highlight><bold>601</bold></highlight> can be changed from five degrees to zero degree. </paragraph>
<paragraph id="P-0259" lvl="0"><number>&lsqb;0259&rsqb;</number> Similarly, when a user operates the angle adjusting lever <highlight><bold>611</bold></highlight> from the state shown in <cross-reference target="DRAWINGS">FIG. 33</cross-reference> to the right direction (to the direction indicated by the arrow in the <cross-reference target="DRAWINGS">FIG. 33</cross-reference>), the angle of the board section <highlight><bold>601</bold></highlight> can be changed from zero degree to five degrees. </paragraph>
<paragraph id="P-0260" lvl="0"><number>&lsqb;0260&rsqb;</number> It should be noted that the angle of the angle adjusting lever <highlight><bold>611</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 34</cross-reference> is changed in association with changing of the angle of the board section <highlight><bold>601</bold></highlight> although it is not shown in the figure. However, each of the PDP angle <highlight><bold>900</bold></highlight> and the stand stay <highlight><bold>902</bold></highlight> is pivotally fixed, therefore, both of these sections are not affected even by a change in the angle of the board section <highlight><bold>601</bold></highlight>. </paragraph>
<paragraph id="P-0261" lvl="0"><number>&lsqb;0261&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 35</cross-reference>, by providing one or a plurality of springs <highlight><bold>1200</bold></highlight> between the PDP angle <highlight><bold>900</bold></highlight> and stand stay <highlight><bold>902</bold></highlight>, operability of the angle adjusting lever <highlight><bold>611</bold></highlight> can be enhanced. This configuration is obtained based on the consideration that the operation of the angle adjusting lever <highlight><bold>611</bold></highlight> may be heavy depending on the weight of the board section <highlight><bold>901</bold></highlight> and the length of the angle adjusting lever <highlight><bold>611</bold></highlight>. Therefore, number of springs <highlight><bold>1200</bold></highlight> and their force are adjusted according to the weight of the board section <highlight><bold>601</bold></highlight>, which allows operability to be further enhanced. </paragraph>
<paragraph id="P-0262" lvl="0"><number>&lsqb;0262&rsqb;</number> Also the lever bearer <highlight><bold>904</bold></highlight> is fixed to the stand stay <highlight><bold>902</bold></highlight> with, for instance, a screw, and a hole (not shown) on the stand stay <highlight><bold>902</bold></highlight> into which the screw is put is preferably a rectangular hole. As a result, a fixing position of the lever bearer <highlight><bold>904</bold></highlight> can be changed to meet the user&apos;s need, therefore, the adjustable range of the angle of the board section <highlight><bold>601</bold></highlight> can be changed. </paragraph>
<paragraph id="P-0263" lvl="0"><number>&lsqb;0263&rsqb;</number> Furthermore, even when the lever bearer <highlight><bold>904</bold></highlight> is provided on the PDP stay <highlight><bold>900</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 36</cross-reference> with the lever supporting point <highlight><bold>905</bold></highlight> provided on the stand stay <highlight><bold>902</bold></highlight> and the configuration is reverse to that of the angle adjusting mechanism section <highlight><bold>802</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 32</cross-reference> to <cross-reference target="DRAWINGS">FIG. 35</cross-reference>, the angle of the board section <highlight><bold>601</bold></highlight> can also be adjusted. </paragraph>
<paragraph id="P-0264" lvl="0"><number>&lsqb;0264&rsqb;</number> The configuration of the angle adjusting mechanism section <highlight><bold>802</bold></highlight> described above is only one of the examples, and it is clear that various designs and modifications are possible. For example, a component member of the angle adjusting lever <highlight><bold>611</bold></highlight> may be provided in the upper side of the board section <highlight><bold>601</bold></highlight> and the pivotal supporting point <highlight><bold>800</bold></highlight> and the pivot guide <highlight><bold>801</bold></highlight> may be reversibly positioned. </paragraph>
<paragraph id="P-0265" lvl="0"><number>&lsqb;0265&rsqb;</number> As described above, by providing an angle adjusting mechanism section <highlight><bold>802</bold></highlight> for adjusting an angle of the board section <highlight><bold>601</bold></highlight> in the frame unit <highlight><bold>600</bold></highlight>, incoming interference light into the PDP <highlight><bold>101</bold></highlight>, especially, light from lighting equipment such as a fluorescent tube provided on the ceiling can be avoided. Therefore, an image on the screen can easily be seen and convenience of the display board system <highlight><bold>100</bold></highlight> can be improved. </paragraph>
<paragraph id="P-0266" lvl="7"><number>&lsqb;0266&rsqb;</number> 2. Operation </paragraph>
<paragraph id="P-0267" lvl="0"><number>&lsqb;0267&rsqb;</number> Next, description is made for an operation of the display board system <highlight><bold>100</bold></highlight> having the same configuration as described above in the order of:  
<table-cwu id="TABLE-US-00001">
<number>1</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="49PT" align="center"/>
<colspec colname="2" colwidth="168PT" align="left"/>
<thead>
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry>(1)</entry>
<entry>Outline,</entry>
</row>
<row>
<entry>(2)</entry>
<entry>Case of using the system as a display board,</entry>
</row>
<row>
<entry>(3)</entry>
<entry>Case of using the system as a computer,</entry>
</row>
<row>
<entry>(4)</entry>
<entry>Adjustment of a coordinate-position input device,</entry>
</row>
<row>
<entry>(5)</entry>
<entry>Use of AV equipment, and</entry>
</row>
<row>
<entry>(6)</entry>
<entry>Connection to a network.</entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0268" lvl="7"><number>&lsqb;0268&rsqb;</number> (1) Outline </paragraph>
<paragraph id="P-0269" lvl="0"><number>&lsqb;0269&rsqb;</number> The display board system <highlight><bold>100</bold></highlight> according to Embodiment 3 can be considered as a communication tool applicable to a conference, a meeting or similar occasions by merging the PDP <highlight><bold>101</bold></highlight> having a large-sized screen with the coordinate-position input device <highlight><bold>102</bold></highlight>, and enabling free writing onto a large-sized screen such as a projector with a fingertip or a pen and clear view of computer data thereon. </paragraph>
<paragraph id="P-0270" lvl="0"><number>&lsqb;0270&rsqb;</number> More specifically, when a user writes characters and draws graphics on the touch surface <highlight><bold>201</bold></highlight> of the coordinate-position input device <highlight><bold>102</bold></highlight> with a user&apos;s fingertip or a pen, the characters and graphics can be displayed on the PDP <highlight><bold>101</bold></highlight> as they are. Furthermore, a screen of word processor or spreadsheet program may be captured, and it is possible to write characters and graphics onto the captured screen and underline a part of the written data on the screen with a pen tool. </paragraph>
<paragraph id="P-0271" lvl="0"><number>&lsqb;0271&rsqb;</number> In the system, a screen displayed on the PDP <highlight><bold>101</bold></highlight> is set to one page, and written information is managed as page units, therefore editing processing such as displaying a list of whole pages, sorting the pages, adding pages thereto, and deleting pages therefrom can be performed. Each created page can be saved as a file, and used by calling it any number of times when a conference on the same subject is held several times. The called file can be processed, and the called file can be reused for preparing a new material. </paragraph>
<paragraph id="P-0272" lvl="0"><number>&lsqb;0272&rsqb;</number> A file prepared using a presentation software on other computer may be read in through the network <highlight><bold>107</bold></highlight>, and a presentation can also be performed using the read-in file. As presentation can be performed using data in a file, an OHP film required for presentation using a projector is not needed. As described above, during the presentation, marking can be made onto certain data using the coordinate-position input device <highlight><bold>102</bold></highlight> on the screen on which any file prepared with the presentation software is open, therefore more effective presentation can be carried out. </paragraph>
<paragraph id="P-0273" lvl="0"><number>&lsqb;0273&rsqb;</number> Furthermore, the system is applicable as an ordinary computer, and can also be utilized for an educational activity on a computer operating method or the like using the large-sized PDP <highlight><bold>101</bold></highlight>. </paragraph>
<paragraph id="P-0274" lvl="7"><number>&lsqb;0274&rsqb;</number> (2) Case of Using the System as a Display Board </paragraph>
<paragraph id="P-0275" lvl="0"><number>&lsqb;0275&rsqb;</number> Description is made hereinafter for the case of using the display board system <highlight><bold>100</bold></highlight> as a display board in the order of:  
<table-cwu id="TABLE-US-00002">
<number>2</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="49PT" align="char"/>
<colspec colname="2" colwidth="168PT" align="left"/>
<thead>
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry>1)</entry>
<entry>Display board software,</entry>
</row>
<row>
<entry>2)</entry>
<entry>Write-in of freehand characters and graphics,</entry>
</row>
<row>
<entry>3)</entry>
<entry>Deletion of freehand characters and graphics,</entry>
</row>
<row>
<entry>4)</entry>
<entry>Drawing of graphics,</entry>
</row>
<row>
<entry>5)</entry>
<entry>Creation of a new page,</entry>
</row>
<row>
<entry>6)</entry>
<entry>Operation for opening a previously prepared file,</entry>
</row>
<row>
<entry>7)</entry>
<entry>Operation for capturing a screen of word processor,</entry>
</row>
<row>
<entry></entry>
<entry>a spreadsheet program, or presentation software,</entry>
</row>
<row>
<entry>8)</entry>
<entry>Operation for displaying pages in creation in a list</entry>
</row>
<row>
<entry></entry>
<entry>form.</entry>
</row>
<row>
<entry>9)</entry>
<entry>Operation for saving created pages,</entry>
</row>
<row>
<entry>10)</entry>
<entry>Printing, and</entry>
</row>
<row>
<entry>11)</entry>
<entry>Other.</entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0276" lvl="7"><number>&lsqb;0276&rsqb;</number> 1) Display Board Software </paragraph>
<paragraph id="P-0277" lvl="0"><number>&lsqb;0277&rsqb;</number> The display board system <highlight><bold>100</bold></highlight> can be operated as a display board by executing the display board software <highlight><bold>506</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 28</cross-reference> using the CPU <highlight><bold>500</bold></highlight>. This display board software <highlight><bold>506</bold></highlight> is one of the application programs operating under the control by the OS <highlight><bold>505</bold></highlight> in the same manner as the various types of application program <highlight><bold>508</bold></highlight> such as the word processor and the spreadsheet program or the like. In Embodiment 3, it is preferable from the viewpoint of workability to set the sequence of execution of the program such that, in response to turning ON the main power switch <highlight><bold>619</bold></highlight> of the system shown in <cross-reference target="DRAWINGS">FIG. 30</cross-reference>, the OS <highlight><bold>505</bold></highlight> is started and then the display board software <highlight><bold>506</bold></highlight> is immediately started. However, the next sequence may be allowable in which a desktop screen provided by the OS <highlight><bold>505</bold></highlight> is displayed on starting the system, one of the icons appearing on the desktop screen is selected, and the display board software <highlight><bold>506</bold></highlight> is started. </paragraph>
<paragraph id="P-0278" lvl="0"><number>&lsqb;0278&rsqb;</number> When the display board software <highlight><bold>506</bold></highlight> is started, a display board screen <highlight><bold>1400</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 37</cross-reference> appears on the PDP <highlight><bold>101</bold></highlight>. This display board screen <highlight><bold>1400</bold></highlight> corresponds to, for instance, a writing surface of a whiteboard. When a user draws characters and graphics with his or her fingertip or a pen on the touch surface <highlight><bold>201</bold></highlight> of the coordinate-position input device <highlight><bold>102</bold></highlight> positioned in the front side of the PDP <highlight><bold>101</bold></highlight> that displays this display board screen <highlight><bold>1400</bold></highlight>, the characters and graphics created by the user on the touch surface <highlight><bold>201</bold></highlight> appear on the display board screen <highlight><bold>1400</bold></highlight> of the PDP <highlight><bold>101</bold></highlight> through the coordinate-position input device <highlight><bold>102</bold></highlight>, controller <highlight><bold>103</bold></highlight>, and computer <highlight><bold>104</bold></highlight> as they are as if the characters and graphics were created on a whiteboard with a pen. </paragraph>
<paragraph id="P-0279" lvl="0"><number>&lsqb;0279&rsqb;</number> The display board software <highlight><bold>506</bold></highlight> is designed so as to manage information in units of pages, and the display board screen <highlight><bold>1400</bold></highlight> corresponds to an information writing area of one page managed by the display board software <highlight><bold>506</bold></highlight>. A user can create a plurality of pages by operating the display board software <highlight><bold>506</bold></highlight>, and an arbitrary page of the pages can be displayed as the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0280" lvl="0"><number>&lsqb;0280&rsqb;</number> Furthermore, the display board software <highlight><bold>506</bold></highlight> displays a toolbar <highlight><bold>1401</bold></highlight> including a plurality of buttons corresponding to various operations on the display board screen <highlight><bold>1400</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 37</cross-reference>. Description is made herein for an outline of functions assigned to the buttons in the toolbar <highlight><bold>1401</bold></highlight>. It should be noted that, in addition to the toolbar <highlight><bold>1401</bold></highlight>, an extension toolbar (Refer to <cross-reference target="DRAWINGS">FIG. 38</cross-reference>) and a graphics drawing toolbar (Refer to <cross-reference target="DRAWINGS">FIG. 39</cross-reference>) are prepared in the toolbar appearing on the display board screen <highlight><bold>1400</bold></highlight> as described later. </paragraph>
<paragraph id="P-0281" lvl="2"><number>&lsqb;0281&rsqb;</number> With the computer screen button <highlight><bold>1402</bold></highlight> a display on the PDP <highlight><bold>101</bold></highlight> can be switched to a screen for a computer (a desktop screen or a screen for other application program). </paragraph>
<paragraph id="P-0282" lvl="2"><number>&lsqb;0282&rsqb;</number> With the pen button <highlight><bold>1403</bold></highlight> characters and lines can be drawn freehand on the PDP <highlight><bold>101</bold></highlight> (use of a pen tool is specified). </paragraph>
<paragraph id="P-0283" lvl="2"><number>&lsqb;0283&rsqb;</number> With the eraser button <highlight><bold>1404</bold></highlight> characters and lines drawn freehand can be deleted. </paragraph>
<paragraph id="P-0284" lvl="2"><number>&lsqb;0284&rsqb;</number> With the previous page button <highlight><bold>1405</bold></highlight> a previous page can be displayed. </paragraph>
<paragraph id="P-0285" lvl="2"><number>&lsqb;0285&rsqb;</number> In the page number window <highlight><bold>1406</bold></highlight> a page number of a page currently displayed as a display board screen <highlight><bold>1400</bold></highlight> is displayed. </paragraph>
<paragraph id="P-0286" lvl="2"><number>&lsqb;0286&rsqb;</number> With the next page button <highlight><bold>1407</bold></highlight> a next page can be displayed. </paragraph>
<paragraph id="P-0287" lvl="2"><number>&lsqb;0287&rsqb;</number> With the print button <highlight><bold>1408</bold></highlight> a page or pages in creation can be printed. </paragraph>
<paragraph id="P-0288" lvl="2"><number>&lsqb;0288&rsqb;</number> With the thumbnail button <highlight><bold>1409</bold></highlight> pages constituting a file in preparation can be displayed in a list form. </paragraph>
<paragraph id="P-0289" lvl="2"><number>&lsqb;0289&rsqb;</number> With the end button <highlight><bold>1410</bold></highlight> the display board software <highlight><bold>506</bold></highlight> can be terminated. </paragraph>
<paragraph id="P-0290" lvl="2"><number>&lsqb;0290&rsqb;</number> With the extension button <highlight><bold>1411</bold></highlight> the extension toolbar <highlight><bold>1500</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 38</cross-reference> can be displayed. When the extension button <highlight><bold>1411</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight> is touched, the extension toolbar is returned to the toolbar <highlight><bold>1401</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 37</cross-reference>. </paragraph>
<paragraph id="P-0291" lvl="0"><number>&lsqb;0291&rsqb;</number> The functions assigned to the buttons in the extension toolbar <highlight><bold>1500</bold></highlight> that is displayed when the extension button <highlight><bold>1411</bold></highlight> is touched will be described with reference to <cross-reference target="DRAWINGS">FIG. 38</cross-reference>. It should be noted that, the same reference numerals are assigned to the buttons corresponding to those in the toolbar <highlight><bold>1401</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 37</cross-reference> and description thereof is omitted herein. </paragraph>
<paragraph id="P-0292" lvl="2"><number>&lsqb;0292&rsqb;</number> With the file button <highlight><bold>1501</bold></highlight> a new page or a previously prepared file can be opened. </paragraph>
<paragraph id="P-0293" lvl="2"><number>&lsqb;0293&rsqb;</number> With the save button <highlight><bold>1502</bold></highlight> a file under preparation can be saved. </paragraph>
<paragraph id="P-0294" lvl="2"><number>&lsqb;0294&rsqb;</number> With the display button <highlight><bold>1503</bold></highlight> switching to any of thumbnail display, full display, or to window display, and zoom (enlarged) display can be set. </paragraph>
<paragraph id="P-0295" lvl="2"><number>&lsqb;0295&rsqb;</number> With the graphics drawing button <highlight><bold>1504</bold></highlight> the graphics drawing toolbar <highlight><bold>1600</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 39</cross-reference> is displayed, and lines, rectangles, ellipses can be created (Use of Graphics drawing tool is specified). Each button in the graphics drawing toolbar <highlight><bold>1600</bold></highlight> is described later. </paragraph>
<paragraph id="P-0296" lvl="2"><number>&lsqb;0296&rsqb;</number> With the background setting button <highlight><bold>1505</bold></highlight> a background color of the display board screen <highlight><bold>1400</bold></highlight> displayed on the PDP <highlight><bold>101</bold></highlight> can be set. </paragraph>
<paragraph id="P-0297" lvl="2"><number>&lsqb;0297&rsqb;</number> With the option button <highlight><bold>1506</bold></highlight> display of the display board software <highlight><bold>506</bold></highlight> when power is ON and processing is ended and insertion of a page when other screen is captured can be set, which is described later. Furthermore, change of work folders can be set. </paragraph>
<paragraph id="P-0298" lvl="2"><number>&lsqb;0298&rsqb;</number> With-the help button <highlight><bold>1507</bold></highlight> a help screen with operations and instruction of functions described thereon can be displayed. </paragraph>
<paragraph id="P-0299" lvl="0"><number>&lsqb;0299&rsqb;</number> Furthermore, functions assigned to buttons in the graphics drawing toolbar <highlight><bold>1600</bold></highlight> displayed when the graphics drawing Button <highlight><bold>1504</bold></highlight> is touched will be described with reference to <cross-reference target="DRAWINGS">FIG. 39</cross-reference>. </paragraph>
<paragraph id="P-0300" lvl="2"><number>&lsqb;0300&rsqb;</number> With the select button <highlight><bold>1601</bold></highlight> when created graphics is to be edited, that graphics to be edited can be selected. </paragraph>
<paragraph id="P-0301" lvl="2"><number>&lsqb;0301&rsqb;</number> With the line button <highlight><bold>1602</bold></highlight> a line can be drawn. </paragraph>
<paragraph id="P-0302" lvl="2"><number>&lsqb;0302&rsqb;</number> With the rectangle button <highlight><bold>1603</bold></highlight> a rectangle can be drawn. </paragraph>
<paragraph id="P-0303" lvl="2"><number>&lsqb;0303&rsqb;</number> With the ellipse button <highlight><bold>1604</bold></highlight> an ellipse can be drawn. </paragraph>
<paragraph id="P-0304" lvl="2"><number>&lsqb;0304&rsqb;</number> With the edit button <highlight><bold>1605</bold></highlight> created graphics can be edited. </paragraph>
<paragraph id="P-0305" lvl="0"><number>&lsqb;0305&rsqb;</number> It should be noted that, in the display board software <highlight><bold>506</bold></highlight>, it can be found which of the buttons a user has touched according to positional information for coordinates inputted from the controller <highlight><bold>103</bold></highlight>. </paragraph>
<paragraph id="P-0306" lvl="0"><number>&lsqb;0306&rsqb;</number> Also the user may touch a specified position of each of the toolbars shown in <cross-reference target="DRAWINGS">FIG. 37</cross-reference> to <cross-reference target="DRAWINGS">FIG. 39</cross-reference> with his fingertip and move the fingertip as it is, in order to move the toolbar to a desired place. </paragraph>
<paragraph id="P-0307" lvl="0"><number>&lsqb;0307&rsqb;</number> Furthermore, the display board screen <highlight><bold>1400</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 37</cross-reference> is displayed on the whole display area of the PDP <highlight><bold>101</bold></highlight> in a display format so-called full screen display. The user touches the display button <highlight><bold>1503</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight> and carries out a specified operation, and the display board screen <highlight><bold>1400</bold></highlight> can be switched to window display. Furthermore, as the display board software <highlight><bold>506</bold></highlight> is one of the application programs operating on the OS <highlight><bold>505</bold></highlight>, by touching the computer screen button <highlight><bold>1402</bold></highlight> in the toolbar <highlight><bold>1401</bold></highlight> (or extension toolbar <highlight><bold>1500</bold></highlight>) as described later, the display of the PDP <highlight><bold>101</bold></highlight> can easily be switched from the display board screen <highlight><bold>1400</bold></highlight> to a desktop screen or a display screen of the word processor or the like. </paragraph>
<paragraph id="P-0308" lvl="0"><number>&lsqb;0308&rsqb;</number> Furthermore, an operation of the coordinate-position input device <highlight><bold>102</bold></highlight> (a touch to the touch surface <highlight><bold>201</bold></highlight>) may be performed with any tool, in addition to a fingertip and a pen, on condition that it can block a light beam. Therefore, even if expression of, for instance, &ldquo;touch with a fingertip&rdquo; is found in the description below, the same operation can be carried out by touching the touch surface with a pen or some other object. </paragraph>
<paragraph id="P-0309" lvl="7"><number>&lsqb;0309&rsqb;</number> 2) Writing of Freehand Characters and Graphics </paragraph>
<paragraph id="P-0310" lvl="0"><number>&lsqb;0310&rsqb;</number> Description is made for various operations using the display board software <highlight><bold>506</bold></highlight> one after another. Herein, description is made for a method of writing in characters and drawing a freehand graphics. </paragraph>
<paragraph id="P-0311" lvl="0"><number>&lsqb;0311&rsqb;</number> Prepared in the display board software <highlight><bold>506</bold></highlight> is a pen tool for writing characters and drawing freehand graphics on the display board screen <highlight><bold>1400</bold></highlight> using a user&apos;s fingertip just like a real pen. This pen tool is made available when a user touches the pen button <highlight><bold>1403</bold></highlight> in the toolbar <highlight><bold>1401</bold></highlight> (or extension toolbar <highlight><bold>1500</bold></highlight>). The user writes a character or a line with his fingertip on the touch surface <highlight><bold>201</bold></highlight> as when a character is written freehand on a blackboard or a whiteboard, which makes it possible to display the corresponding character and line on the display board screen <highlight><bold>1400</bold></highlight>. In a case of this pen tool, the user&apos;s fingertip works like a real pen, and it is also possible to set characters which can be written with the fingertip, a color of graphics and a thickness of a line. <cross-reference target="DRAWINGS">FIG. 40</cross-reference> is an explanatory view showing one example of how a result of writing characters and lines freehand is displayed on the display board screen <highlight><bold>1400</bold></highlight> on the PDP <highlight><bold>101</bold></highlight>. </paragraph>
<paragraph id="P-0312" lvl="0"><number>&lsqb;0312&rsqb;</number> Herein, simple description is made for processing of displaying a character on the display board screen <highlight><bold>1400</bold></highlight> with reference with <cross-reference target="DRAWINGS">FIG. 27</cross-reference> and <cross-reference target="DRAWINGS">FIG. 28</cross-reference>. When the user writes a character with his fingertip on the touch surface <highlight><bold>201</bold></highlight>, the controller <highlight><bold>103</bold></highlight> obtains positional information for coordinates corresponding to a trail of the fingertip through the coordinate-position input device <highlight><bold>102</bold></highlight>, and the obtained positional information for coordinates is successively inputted into the computer <highlight><bold>104</bold></highlight>. In the computer <highlight><bold>104</bold></highlight>, the display board software <highlight><bold>506</bold></highlight> and the OS <highlight><bold>505</bold></highlight> generate drawing information for drawing a line with the preset color and thickness of the line when receiving the positional information for coordinates from the controller <highlight><bold>103</bold></highlight>, and write the generated information in a video memory (not shown) of the graphics board <highlight><bold>510</bold></highlight> matching a position of corresponding coordinates. The graphics board <highlight><bold>510</bold></highlight> transmits an image signal to the PDP <highlight><bold>101</bold></highlight> according to the contents of the video memory, and provides controls for the processing of displaying the same character as that written on the touch surface <highlight><bold>201</bold></highlight> by the user on the PDP <highlight><bold>101</bold></highlight>. </paragraph>
<paragraph id="P-0313" lvl="0"><number>&lsqb;0313&rsqb;</number> In simple words, the computer <highlight><bold>104</bold></highlight> recognizes the coordinate-position input device <highlight><bold>102</bold></highlight> and the controller <highlight><bold>103</bold></highlight> as a pointing device such as a mouse, therefore, the same processing as that when a character is written with a mouse on the drawing software is executed in the computer <highlight><bold>104</bold></highlight>. It should be noted that, the processing is executed in the steps described above also in the processing for deleting a character and creating graphics described below. </paragraph>
<paragraph id="P-0314" lvl="7"><number>&lsqb;0314&rsqb;</number> 3) Deletion of Freehand Drawn Characters and Graphics </paragraph>
<paragraph id="P-0315" lvl="0"><number>&lsqb;0315&rsqb;</number> A user can delete freehand characters written and graphics drawn on the display board screen <highlight><bold>1400</bold></highlight> by touching the eraser button <highlight><bold>1404</bold></highlight> like deleting them with an eraser. When the eraser button <highlight><bold>1404</bold></highlight> is touched, the user&apos;s fingertip or a pen can be used like a real eraser, and a size of the eraser, namely an area in which characters and graphics are to be deleted in one operation can freely be set. <cross-reference target="DRAWINGS">FIG. 41</cross-reference> is an explanatory view showing how the freehand characters and lines shown in <cross-reference target="DRAWINGS">FIG. 40</cross-reference> are deleted with an eraser <highlight><bold>1800</bold></highlight>. </paragraph>
<paragraph id="P-0316" lvl="0"><number>&lsqb;0316&rsqb;</number> In this mode of deleting freehand characters, as shown in <cross-reference target="DRAWINGS">FIG. 42</cross-reference>, freehand characters and lines to be deleted may be enclosed within a box <highlight><bold>1900</bold></highlight> and the characters and lines in the box <highlight><bold>1900</bold></highlight> may be deleted in one operation (data enclosed and deleted). </paragraph>
<paragraph id="P-0317" lvl="7"><number>&lsqb;0317&rsqb;</number> 4) Drawing of Graphics </paragraph>
<paragraph id="P-0318" lvl="0"><number>&lsqb;0318&rsqb;</number> In the display board software <highlight><bold>506</bold></highlight> graphics drawing tools for drawing graphics such as lines, rectangles and ellipses are made available. The graphics drawing tools can be used through the drawing toolbar <highlight><bold>1600</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 39</cross-reference>. The user touches the extension button <highlight><bold>1411</bold></highlight> in the toolbar <highlight><bold>1400</bold></highlight> (Refer to <cross-reference target="DRAWINGS">FIG. 37</cross-reference>) and gets the extension toolbar <highlight><bold>1500</bold></highlight> displayed (Refer to <cross-reference target="DRAWINGS">FIG. 38</cross-reference>), and then touches the graphics drawing button <highlight><bold>1504</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight>, so that the drawing toolbar <highlight><bold>1600</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 39</cross-reference> can be displayed on the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0319" lvl="7"><number>&lsqb;0319&rsqb;</number> {circle over (1)} Drawing of a Line </paragraph>
<paragraph id="P-0320" lvl="0"><number>&lsqb;0320&rsqb;</number> When a line is to be drawn, the user may perform operations of touching the line button <highlight><bold>1602</bold></highlight> in the drawing toolbar <highlight><bold>1600</bold></highlight> with his or her fingertip, touching an arbitrary place on the touch surface <highlight><bold>201</bold></highlight> as a starting point of the line with the fingertip, moving the fingertip kept in its state as far as a place which is the end point, and moving the fingertip off the touch surface <highlight><bold>201</bold></highlight>. As a result, as shown in <cross-reference target="DRAWINGS">FIG. 43, a</cross-reference> line is created on the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0321" lvl="7"><number>&lsqb;0321&rsqb;</number> {circle over (2)} Drawing of a Rectangle </paragraph>
<paragraph id="P-0322" lvl="0"><number>&lsqb;0322&rsqb;</number> When a rectangle is to be created, the user may perform operations of touching the rectangle button <highlight><bold>1603</bold></highlight> in the drawing toolbar <highlight><bold>1600</bold></highlight> with his fingertip, touching an arbitrary place on the touch surface <highlight><bold>201</bold></highlight> with the fingertip, moving the fingertip kept in its state in an arbitrary direction, and moving the fingertip off the touch surface <highlight><bold>201</bold></highlight>. As a result, as shown in <cross-reference target="DRAWINGS">FIG. 44, a</cross-reference> rectangle is created on the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0323" lvl="0"><number>&lsqb;0323&rsqb;</number> Furthermore, in the display board software <highlight><bold>506</bold></highlight>, a function enabling easy creation of a table using the rectangle created as described above is made available. At first, there is performed setting of touching the background setting button <highlight><bold>1505</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight> to display a setting screen (not shown), and displaying a grid on the background of the display board screen <highlight><bold>1400</bold></highlight>. In that case, longitudinal and lateral distance of a grid, and a left-start position and a upper-start position can be specified. In addition, for convenience of use when a table is created with a grid, there is prepared a setting that a created rectangle is displayed so as to match the grid. </paragraph>
<paragraph id="P-0324" lvl="0"><number>&lsqb;0324&rsqb;</number> When setting for the grid is ended, the grid appears on the display board screen <highlight><bold>1400</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 45</cross-reference>. By repeatedly drawing a rectangle as described above the table as shown in <cross-reference target="DRAWINGS">FIG. 46</cross-reference> can be created. It should be noted that, if a setting that a created rectangle is displayed so as to match the grid is executed when a grid is to be set, the display board software <highlight><bold>506</bold></highlight> executes the processing of drawing rectangles along the grid. </paragraph>
<paragraph id="P-0325" lvl="7"><number>&lsqb;0325&rsqb;</number> {circle over (3)} Drawing of an Ellipse </paragraph>
<paragraph id="P-0326" lvl="0"><number>&lsqb;0326&rsqb;</number> When an ellipse is to be created, the user may perform operations of touching the ellipse button <highlight><bold>1604</bold></highlight> in the drawing toolbar <highlight><bold>1600</bold></highlight> with his or her fingertip, touching an arbitrary place on the touch surface <highlight><bold>201</bold></highlight> with the fingertip, moving the fingertip kept in its state in an arbitrary direction, and moving the fingertip off the touch surface <highlight><bold>201</bold></highlight>. As a result, as shown in <cross-reference target="DRAWINGS">FIG. 47</cross-reference>, an ellipse is created on the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0327" lvl="7"><number>&lsqb;0327&rsqb;</number> {circle over (4)} Modification of a Created Graphics </paragraph>
<paragraph id="P-0328" lvl="0"><number>&lsqb;0328&rsqb;</number> When a created graphics is to be modified, the user touches the select button <highlight><bold>1601</bold></highlight> in the drawing toolbar <highlight><bold>1600</bold></highlight> with his fingertip, touches any part of a line of the graphics to be modified, and selects the graphics. As a result, as shown in <cross-reference target="DRAWINGS">FIG. 48A, a</cross-reference> rectangular mark (handle) <highlight><bold>2500</bold></highlight> surrounding the selected graphics is displayed. </paragraph>
<paragraph id="P-0329" lvl="0"><number>&lsqb;0329&rsqb;</number> Then, the user touches any part of the handle <highlight><bold>2500</bold></highlight> with his or her fingertip, and moves the fingertip kept in its state, so that a size and a shape of the graphics can be changed in association with its movement. <cross-reference target="DRAWINGS">FIG. 48B</cross-reference> shows how the graphics is enlarged by moving the part of the handle <highlight><bold>2500</bold></highlight> in the right lower side of the handle <highlight><bold>2500</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 48A</cross-reference>. </paragraph>
<paragraph id="P-0330" lvl="7"><number>&lsqb;0330&rsqb;</number> {circle over (5)} Movement of a Created Graphics </paragraph>
<paragraph id="P-0331" lvl="0"><number>&lsqb;0331&rsqb;</number> When an already created graphics is to be moved, the user touches the select button <highlight><bold>1601</bold></highlight> in the drawing toolbar <highlight><bold>1600</bold></highlight> with his or her fingertip, touches any part of a line of the graphics to be moved, and selects the graphics. As a result, as shown in <cross-reference target="DRAWINGS">FIG. 49A, a</cross-reference> handle <highlight><bold>2500</bold></highlight> surrounding the selected graphics is displayed. </paragraph>
<paragraph id="P-0332" lvl="0"><number>&lsqb;0332&rsqb;</number> Then, the user touches any part of a line of the graphics with his fingertip, and moves the fingertip kept in its state, so that the graphics can be moved in association with its movement. <cross-reference target="DRAWINGS">FIG. 49B</cross-reference> shows how the graphics shown in <cross-reference target="DRAWINGS">FIG. 49A</cross-reference> has been moved in the right direction. </paragraph>
<paragraph id="P-0333" lvl="7"><number>&lsqb;0333&rsqb;</number> {circle over (6)} Edition of a Created Graphics </paragraph>
<paragraph id="P-0334" lvl="0"><number>&lsqb;0334&rsqb;</number> Herein, edition of a created graphics indicates cut or copy of the graphics or the like. At first, when a created graphics is to be cut out and pasted at an arbitrary position, the user touches the select button <highlight><bold>1601</bold></highlight> in the drawing toolbar <highlight><bold>1600</bold></highlight> with his or her fingertip, and touches any part of a line of the graphics to be cut out to select the graphics. Then, when the edit button <highlight><bold>1605</bold></highlight> in the drawing toolbar <highlight><bold>1600</bold></highlight> is touched with the fingertip, an edit menu <highlight><bold>2700</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 50</cross-reference> is displayed on the display board screen <highlight><bold>1400</bold></highlight>. When the user touches &ldquo;cut&rdquo; in the edit menu <highlight><bold>2700</bold></highlight>, the selected graphics is cut-out. </paragraph>
<paragraph id="P-0335" lvl="0"><number>&lsqb;0335&rsqb;</number> In order to paste the cut-out graphics, the edit menu <highlight><bold>2700</bold></highlight> is displayed again and &ldquo;paste&rdquo; is touched, and when an arbitrary place on the display board screen <highlight><bold>1400</bold></highlight> is touched, the cut-out graphics is pasted at the touched place. </paragraph>
<paragraph id="P-0336" lvl="0"><number>&lsqb;0336&rsqb;</number> However, when the cut-out graphics is to be pasted not in a currently displayed page but in another page, the user may perform operations of touching the previous page button <highlight><bold>1405</bold></highlight> or the next page button <highlight><bold>1407</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight>, displaying a desired page, and pasting the graphics as described above. </paragraph>
<paragraph id="P-0337" lvl="0"><number>&lsqb;0337&rsqb;</number> When a created graphics is to be copied and pasted in an arbitrary place, the same operation as those in the case of &ldquo;cut&rdquo; may be performed except touching &ldquo;copy&rdquo; in the edit menu <highlight><bold>2700</bold></highlight>. </paragraph>
<paragraph id="P-0338" lvl="0"><number>&lsqb;0338&rsqb;</number> Next description is made for a case of deleting a created graphics. As described in the operation for cutting a graphics, a graphics to be deleted is selected and the edit menu <highlight><bold>2700</bold></highlight> is displayed. When &ldquo;delete&rdquo; in the edit menu <highlight><bold>2700</bold></highlight> is touched, the selected graphics is deleted. </paragraph>
<paragraph id="P-0339" lvl="0"><number>&lsqb;0339&rsqb;</number> It should be noted that, when a user wants to select all of the created graphics and cut, copy, or delete it, &ldquo;select all&rdquo; in the edit menu <highlight><bold>2700</bold></highlight> is touched, so that all of the created graphics is selected and the operation of cut, copy, or delete can be carried out to all the graphics. It should be noted that, if &ldquo;select all&rdquo; is touched, a handle surrounding all the graphics is displayed, and all the graphics can be moved with the fingertip. </paragraph>
<paragraph id="P-0340" lvl="7"><number>&lsqb;0340&rsqb;</number> 5) Creation of a New Page </paragraph>
<paragraph id="P-0341" lvl="0"><number>&lsqb;0341&rsqb;</number> When a new page other than a page currently displayed as the display board screen <highlight><bold>1400</bold></highlight> is to be created, the user may touch the next page button <highlight><bold>1407</bold></highlight> in the toolbar <highlight><bold>1401</bold></highlight> (or the extension toolbar <highlight><bold>1500</bold></highlight>). When the next page button <highlight><bold>1407</bold></highlight> is touched, the display board software <highlight><bold>506</bold></highlight> generates a new page and display it as display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0342" lvl="0"><number>&lsqb;0342&rsqb;</number> It should be noted that, if a plurality of pages are currently created, the next page button <highlight><bold>1407</bold></highlight> is touched to display the final page, and by touching the next page button <highlight><bold>1407</bold></highlight> again, a new page can be created. </paragraph>
<paragraph id="P-0343" lvl="0"><number>&lsqb;0343&rsqb;</number> Furthermore, when a previous page is to be opened, the user may touch the previous page button <highlight><bold>1405</bold></highlight> in the toolbar <highlight><bold>1401</bold></highlight> (or the extension toolbar <highlight><bold>1500</bold></highlight>). When the previous page button <highlight><bold>1405</bold></highlight> is touched, the display board software <highlight><bold>506</bold></highlight> displays a corresponding page as a display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0344" lvl="7"><number>&lsqb;0344&rsqb;</number> 6) To Open a Previously Prepared File </paragraph>
<paragraph id="P-0345" lvl="0"><number>&lsqb;0345&rsqb;</number> In order to open a previously prepared file, the file button <highlight><bold>1501</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight> is touched to display a file menu (not shown), and &ldquo;open&rdquo; in the file menu is touched to display a dialog box <highlight><bold>2800</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 51</cross-reference>. Then, a desired file name is touched for selection, and an &ldquo;open&rdquo; button <highlight><bold>2801</bold></highlight> is touched, so that a page of a corresponding file is displayed as the display board screen <highlight><bold>1400</bold></highlight>. It should be noted that a file can be opened also by touching a file name twice in a row (described &ldquo;double touch&rdquo; hereinafter) like so-called &ldquo;double click&rdquo;. </paragraph>
<paragraph id="P-0346" lvl="0"><number>&lsqb;0346&rsqb;</number> When the contents of previously prepared file is not clear, operations of displaying a list of the files by using a file thumbnail function, confirming the contents, and opening the target file can be performed. To use the file thumbnail function, a &ldquo;thumbnail&rdquo; button <highlight><bold>2802</bold></highlight> in the dialog box <highlight><bold>2800</bold></highlight> is touched to display the thumbnail dialog box <highlight><bold>2900</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 52</cross-reference>, and a list of the files is displayed in the thumbnail form in the box. Thumbnail images to be displayed here are header pages of the files respectively. Then, a desired thumbnail is touched to be selected, and &ldquo;open&rdquo; button <highlight><bold>2901</bold></highlight> is touched, or the desired thumbnail image is double-touched, so that a page of a corresponding file is displayed as the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0347" lvl="0"><number>&lsqb;0347&rsqb;</number> It should be noted that in order to create a new file, the file button <highlight><bold>1501</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight> is touched to display the file menu (not shown), and when &ldquo;new file&rdquo; in the file menu is touched, a new page is displayed on the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0348" lvl="7"><number>&lsqb;0348&rsqb;</number> 7) Capturing a Screen of a Word Processor, a Spreadsheet Program or a Presentation Software (Capturing Function) </paragraph>
<paragraph id="P-0349" lvl="0"><number>&lsqb;0349&rsqb;</number> The display board software <highlight><bold>506</bold></highlight> has a &ldquo;capture&rdquo; function for capturing the contents of a file created with the word processor, a spreadsheet program, or presentation software as a background of the display board screen <highlight><bold>1400</bold></highlight>. Description is made hereinafter for the processing of capturing the screen of word processor, spreadsheet program, or presentation software by using this capturing function. </paragraph>
<paragraph id="P-0350" lvl="0"><number>&lsqb;0350&rsqb;</number> At first, by touching the computer screen button <highlight><bold>1402</bold></highlight> in the toolbar <highlight><bold>1401</bold></highlight> (or the extension toolbar <highlight><bold>1500</bold></highlight>) by a user, the display of the PDP <highlight><bold>101</bold></highlight> is switched from the display board screen <highlight><bold>1400</bold></highlight> to a computer screen <highlight><bold>3000</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 53</cross-reference>. In <cross-reference target="DRAWINGS">FIG. 53</cross-reference>, the reference numeral <highlight><bold>3001</bold></highlight> indicates a capture toolbar displayed when the display is switched to the computer screen <highlight><bold>3000</bold></highlight>. Functions allocated to the buttons in the capture toolbar <highlight><bold>3001</bold></highlight> are as follows. </paragraph>
<paragraph id="P-0351" lvl="2"><number>&lsqb;0351&rsqb;</number> With the display board screen button <highlight><bold>3002</bold></highlight> display can be switched from the computer screen <highlight><bold>3000</bold></highlight> to the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0352" lvl="2"><number>&lsqb;0352&rsqb;</number> With the capture button <highlight><bold>3003</bold></highlight> a screen displayed on the computer screen <highlight><bold>3000</bold></highlight> can be captured. </paragraph>
<paragraph id="P-0353" lvl="2"><number>&lsqb;0353&rsqb;</number> With the mouse button <highlight><bold>3004</bold></highlight> in an environment where a right button of a two-button type of mouse is usable (e.g., when Windows (trademark) of Microsoft is used as OS), functions assigned to the right button of the mouse become available. </paragraph>
<paragraph id="P-0354" lvl="0"><number>&lsqb;0354&rsqb;</number> Then, in the computer screen <highlight><bold>3000</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 53</cross-reference>, the user touches (double touch) an icon of a desired application program or an icon of a desired file to start a corresponding application program, and also touches the capture button <highlight><bold>3003</bold></highlight> after displaying the target file on the PDP <highlight><bold>101</bold></highlight>. As a result, the display board software <highlight><bold>506</bold></highlight> captures the currently displayed screen and switches the display on the PDP <highlight><bold>101</bold></highlight> to the display board screen <highlight><bold>1400</bold></highlight>, as shown in <cross-reference target="DRAWINGS">FIG. 54</cross-reference>, to display the captured screen as a background of the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0355" lvl="0"><number>&lsqb;0355&rsqb;</number> Then, as shown in <cross-reference target="DRAWINGS">FIG. 55</cross-reference>, the user can write characters and graphics on the display board screen <highlight><bold>1400</bold></highlight> utilizing the method as described above. As the screen of word processor, a spreadsheet program, or presentation software or the like can easily be captured as a background of the display board screen <highlight><bold>1400</bold></highlight> as described above, effective presentation can be carried out by using the display board system <highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0356" lvl="0"><number>&lsqb;0356&rsqb;</number> Namely, while presentation is being carried out by using presentation software on the display board system <highlight><bold>100</bold></highlight>, if a user wants to write something on the screen to describe it, the current screen is captured as soon as the capture button <highlight><bold>3003</bold></highlight> is touched to switch to the display board screen <highlight><bold>1400</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 54</cross-reference>, and the user can write a desired topic on the screen. Then, when the user wants to return to the presentation software, the screen is switched to the screen of the presentation software (computer screen <highlight><bold>3000</bold></highlight>) in response to touching the computer screen button <highlight><bold>1402</bold></highlight> by the user. The captured screen with characters or the like written thereon can be saved as described later. </paragraph>
<paragraph id="P-0357" lvl="0"><number>&lsqb;0357&rsqb;</number> It should be noted that, description has been made here for the method of displaying the computer screen <highlight><bold>3000</bold></highlight> first, starting the application program, and then capturing a desired screen. However, by directly specifying a file of the word processor or spreadsheet program from the display board software <highlight><bold>506</bold></highlight>, a corresponding application program is started directly from the display board screen <highlight><bold>1400</bold></highlight> and a specified file can be opened. When the user wants to capture the screen of the application program, the same operations as those described above may be carried out. Furthermore, when other screen of the application program is captured, touching the next page button <highlight><bold>1407</bold></highlight> allows the screen of the application program to be displayed again on the PDP <highlight><bold>101</bold></highlight>. </paragraph>
<paragraph id="P-0358" lvl="7"><number>&lsqb;0358&rsqb;</number> 8) Operation for Displaying Pages in Creation in a List Form </paragraph>
<paragraph id="P-0359" lvl="0"><number>&lsqb;0359&rsqb;</number> In the display board software <highlight><bold>506</bold></highlight>, all of the pages in creation can be displayed in a thumbnail form. When the pages are to be displayed in a list form with thumbnails, a user touches the thumbnail button <highlight><bold>1409</bold></highlight> in the toolbar <highlight><bold>1401</bold></highlight> (or the extension toolbar <highlight><bold>1500</bold></highlight>). The display board software <highlight><bold>506</bold></highlight> displays, when the thumbnail button <highlight><bold>1409</bold></highlight> is touched, a thumbnail display dialog box <highlight><bold>3300</bold></highlight> for displaying pages in creation in a thumbnail form on the display board screen <highlight><bold>1400</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 56</cross-reference>. </paragraph>
<paragraph id="P-0360" lvl="0"><number>&lsqb;0360&rsqb;</number> In this thumbnail display dialog box <highlight><bold>3300</bold></highlight> the reference numeral <highlight><bold>3301</bold></highlight> indicates an open button, <highlight><bold>3302</bold></highlight> indicates a close button, <highlight><bold>3303</bold></highlight> indicates a backward button, <highlight><bold>3304</bold></highlight> indicates a forward button, <highlight><bold>3305</bold></highlight> indicates an insert before button, <highlight><bold>3306</bold></highlight> indicates an insert after button, <highlight><bold>3307</bold></highlight> indicates a delete button, and <highlight><bold>3308</bold></highlight> indicates a print button respectively. </paragraph>
<paragraph id="P-0361" lvl="0"><number>&lsqb;0361&rsqb;</number> When the thumbnail display dialog box <highlight><bold>3300</bold></highlight> is displayed, the user can perform operations described below. </paragraph>
<paragraph id="P-0362" lvl="7"><number>&lsqb;0362&rsqb;</number> {circle over (1)} Operation for Specifying and Opening a Page </paragraph>
<paragraph id="P-0363" lvl="0"><number>&lsqb;0363&rsqb;</number> A desired thumbnail (page) in the thumbnail display dialog box <highlight><bold>3300</bold></highlight> is touched and selected, and the open button <highlight><bold>3301</bold></highlight> is touched in order to display the selected page as the display board screen <highlight><bold>1400</bold></highlight>. Similarly, a desired page may be double-touched in order to display the page as the display board screen <highlight><bold>1400</bold></highlight>. </paragraph>
<paragraph id="P-0364" lvl="7"><number>&lsqb;0364&rsqb;</number> {circle over (2)} Movement of a Page </paragraph>
<paragraph id="P-0365" lvl="0"><number>&lsqb;0365&rsqb;</number> A page to be moved in the thumbnail display dialog box <highlight><bold>3300</bold></highlight> is touched and selected, and when the page is to be moved backward from the current page, the backward button <highlight><bold>3303</bold></highlight> is touched, and the forward button <highlight><bold>3304</bold></highlight> is touched when the page is to be moved forward from the current page. By moving the page as described above, an operation for replacing pages can be carried out. </paragraph>
<paragraph id="P-0366" lvl="7"><number>&lsqb;0366&rsqb;</number> {circle over (3)} Operation for Inserting a New Page </paragraph>
<paragraph id="P-0367" lvl="0"><number>&lsqb;0367&rsqb;</number> A previous page or a next page of a page to be inserted anew in the thumbnail display dialog box <highlight><bold>3300</bold></highlight> is touched and selected, and when the page is to be inserted before the selected page, the insert before button <highlight><bold>3305</bold></highlight> is touched, and the insert after button <highlight><bold>3306</bold></highlight> is touched when the page is to be inserted after the selected page. By operating as described above, a new page can be inserted in a desired position. </paragraph>
<paragraph id="P-0368" lvl="0"><number>&lsqb;0368&rsqb;</number> It should be noted that, by selecting the final page and touching the insert after button <highlight><bold>3306</bold></highlight>, the same operation as that for creating a new page by touching the above mentioned next page button <highlight><bold>1407</bold></highlight> can be performed. </paragraph>
<paragraph id="P-0369" lvl="7"><number>&lsqb;0369&rsqb;</number> {circle over (4)} Operation for Deleting a Page </paragraph>
<paragraph id="P-0370" lvl="0"><number>&lsqb;0370&rsqb;</number> A page to be deleted in the thumbnail display dialog box <highlight><bold>3300</bold></highlight> is touched and selected, and the delete button <highlight><bold>3307</bold></highlight> is touched, so that the selected page can be deleted. </paragraph>
<paragraph id="P-0371" lvl="7"><number>&lsqb;0371&rsqb;</number> {circle over (5)} Operation for Printing a Page </paragraph>
<paragraph id="P-0372" lvl="0"><number>&lsqb;0372&rsqb;</number> A page to be printed in the thumbnail display dialog box <highlight><bold>3300</bold></highlight> is touched and selected, and the print button <highlight><bold>3308</bold></highlight> is touched, so that the selected page can be printed. It should be noted that, various settings can be performed when printing is executed. Print setting will be described later. </paragraph>
<paragraph id="P-0373" lvl="7"><number>&lsqb;0373&rsqb;</number> 9) Operation for Saving Created Pages </paragraph>
<paragraph id="P-0374" lvl="0"><number>&lsqb;0374&rsqb;</number> As described above, a page created on the display board software <highlight><bold>506</bold></highlight> can be saved as a file. For saving, the save button <highlight><bold>1502</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight> is touched, and either &ldquo;save (overwrite)&rdquo; or &ldquo;save as . . . &rdquo; is selected. When &ldquo;save as . . . &rdquo; is selected, the display board software <highlight><bold>506</bold></highlight> provides current date/month/year and file names having serial numbers on the date as a default. The user inputs a file name and specifies a folder as required, and instructs to save them, and then a created page can be saved as a file. It should be noted that, a file name can be entered through the keyboard <highlight><bold>503</bold></highlight> (Refer to <cross-reference target="DRAWINGS">FIG. 28</cross-reference>). </paragraph>
<paragraph id="P-0375" lvl="0"><number>&lsqb;0375&rsqb;</number> On the other hand, when &ldquo;save (overwrite)&rdquo; is selected, the display board software <highlight><bold>506</bold></highlight> overwrites a corresponding file and saves it. </paragraph>
<paragraph id="P-0376" lvl="0"><number>&lsqb;0376&rsqb;</number> It should be noted that the display board software <highlight><bold>506</bold></highlight> divides the display board screen <highlight><bold>1400</bold></highlight> into a plurality of layers for management. They are, for instance, a background layer for managing a background of the display board screen <highlight><bold>1400</bold></highlight> (which includes a captured screen: bitmap data), a grid layer for managing the grid lines (vector data), a graphics layer for managing the graphics created with graphics drawing tools (vector data), and a freehand layer for managing the freehand characters and graphics (vector data). When the &ldquo;save as . . . &rdquo; is selected, the display board software <highlight><bold>506</bold></highlight> generates a file with these layers maintained as they are. Therefore, when the file is read out again, the contents of each page thereof can easily be processed. In addition, depending on a setting, data for the plurality of layers is integrated as one bitmap data, which can be saved as a bitmap file. </paragraph>
<paragraph id="P-0377" lvl="7"><number>&lsqb;0377&rsqb;</number> 10) Printing </paragraph>
<paragraph id="P-0378" lvl="0"><number>&lsqb;0378&rsqb;</number> When pages in creation are to be printed, a user touches the print button <highlight><bold>1408</bold></highlight> in the toolbar <highlight><bold>1401</bold></highlight> (or the extension toolbar <highlight><bold>1500</bold></highlight>), and touches &ldquo;print&rdquo; in the print menu (not shown). The display board software <highlight><bold>506</bold></highlight> displays a print dialog box <highlight><bold>3400</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 57</cross-reference> according to the operation by the user. The user specifies an area to be printed and a number of copies to be printed in a printer specification column <highlight><bold>3401</bold></highlight>, a print-area setting column <highlight><bold>3402</bold></highlight>, and a number of copies setting column <highlight><bold>3403</bold></highlight> in this print dialog box <highlight><bold>3400</bold></highlight>, and when the OK button <highlight><bold>3404</bold></highlight> is touched, printing is carried out by the preset printer (printer <highlight><bold>106</bold></highlight>). It should be noted that, a cancel button <highlight><bold>3405</bold></highlight> is touched for stopping the printing. </paragraph>
<paragraph id="P-0379" lvl="0"><number>&lsqb;0379&rsqb;</number> Here, a background color of the display board screen <highlight><bold>1400</bold></highlight> can also be set to blank and printed. When such a processing of printing is to be executed, the user may perform operations for touching a check box <highlight><bold>3406</bold></highlight> &ldquo;print background color in white&rdquo; to select it, and touching the OK button <highlight><bold>3404</bold></highlight>. The display board software <highlight><bold>506</bold></highlight> executes, when the check box <highlight><bold>3406</bold></highlight> &ldquo;print background color in white&rdquo; is selected, the processing of printing regarding the background color of the display board screen <highlight><bold>1400</bold></highlight> as blank. The provision of the setting described above allows consumption of ink or toner for the printer to be reduced. </paragraph>
<paragraph id="P-0380" lvl="0"><number>&lsqb;0380&rsqb;</number> A freehand line can also be printed in black. When such a processing of printing is to be executed, the user may perform operations for touching a check box <highlight><bold>3407</bold></highlight> &ldquo;print freehand line in black&rdquo; to select it, and touching the OK button <highlight><bold>3404</bold></highlight>. The display board software <highlight><bold>506</bold></highlight> executes, when the check box <highlight><bold>3406</bold></highlight> &ldquo;print freehand line in black&rdquo; is selected, the processing of printing regarding the freehand line as black. </paragraph>
<paragraph id="P-0381" lvl="0"><number>&lsqb;0381&rsqb;</number> It should be noted that a size or a margin of recording paper for printing can be set and a printed image can be displayed although detailed description thereof is omitted herein. </paragraph>
<paragraph id="P-0382" lvl="7"><number>&lsqb;0382&rsqb;</number> 11) Other Functions </paragraph>
<paragraph id="P-0383" lvl="0"><number>&lsqb;0383&rsqb;</number> It is possible to set a display magnification of characters or the like displayed on the display board screen <highlight><bold>1400</bold></highlight> and a method of displaying the display board screen <highlight><bold>1400</bold></highlight> in a window form by touching the display button <highlight><bold>1503</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight> to open a menu. </paragraph>
<paragraph id="P-0384" lvl="0"><number>&lsqb;0384&rsqb;</number> It is also possible to set a background color of the display board screen <highlight><bold>1400</bold></highlight> using a color pallet by touching the background setting button <highlight><bold>1505</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight> to open a menu. </paragraph>
<paragraph id="P-0385" lvl="0"><number>&lsqb;0385&rsqb;</number> Furthermore, it is also possible to set a work folder in which files to be used for the display board software <highlight><bold>506</bold></highlight> are stored as a unit by touching the option button <highlight><bold>1506</bold></highlight> in the extension toolbar <highlight><bold>1500</bold></highlight> to open a menu. </paragraph>
<paragraph id="P-0386" lvl="7"><number>&lsqb;0386&rsqb;</number> (3) Case of Using the System as a Computer </paragraph>
<paragraph id="P-0387" lvl="0"><number>&lsqb;0387&rsqb;</number> In order to use the display board system <highlight><bold>100</bold></highlight> as a computer, like in a case of using the capture function, the screen is switched to the computer screen <highlight><bold>3000</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 53</cross-reference> by touching the computer screen button <highlight><bold>1401</bold></highlight> on the display board screen <highlight><bold>1400</bold></highlight> or ending the display board software <highlight><bold>506</bold></highlight>. By switching the display on the PDP <highlight><bold>101</bold></highlight> to the computer screen <highlight><bold>3000</bold></highlight> the display board system <highlight><bold>100</bold></highlight> can be used as a computer. As the display board system <highlight><bold>100</bold></highlight> has a large-sized PDP <highlight><bold>101</bold></highlight>, it is possible to make an effective use of the system for educational activities of operating a computer or the like. </paragraph>
<paragraph id="P-0388" lvl="0"><number>&lsqb;0388&rsqb;</number> Furthermore, the coordinate-position input device <highlight><bold>102</bold></highlight> is usable as a pointing device like a mouse, therefore various applications can be operated on the screen. Furthermore, by touching the mouse button <highlight><bold>3004</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 53</cross-reference>, the functions assigned to the right button of the mouse can be used with a fingertip or a pen in an environment where the right button of a two-button type of mouse is usable. </paragraph>
<paragraph id="P-0389" lvl="7"><number>&lsqb;0389&rsqb;</number> (4) Adjustment of a Coordinate-Position Input Device </paragraph>
<paragraph id="P-0390" lvl="0"><number>&lsqb;0390&rsqb;</number> In the device driver <highlight><bold>507</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 28, a</cross-reference> tool for matching a display position of a mouse cursor on the PDP <highlight><bold>101</bold></highlight> with a touch position obtained by touching the touch surface <highlight><bold>201</bold></highlight> with the fingertip or the pen is available. Description is made hereinafter for an operation of positional correction for matching a display position of a mouse cursor with a touch position. </paragraph>
<paragraph id="P-0391" lvl="0"><number>&lsqb;0391&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 58</cross-reference> is an explanatory view showing one example of a setting screen of the coordinate-position input device <highlight><bold>102</bold></highlight>. When a calibrate button <highlight><bold>3501</bold></highlight> in the setting screen <highlight><bold>3500</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 58</cross-reference> is touched, a display screen of the PDP <highlight><bold>101</bold></highlight> and a correction screen for adjusting coordinates of the touch surface <highlight><bold>201</bold></highlight> in the coordinate-position input device <highlight><bold>102</bold></highlight> appear on the PDP <highlight><bold>101</bold></highlight>. This display screen displays, for instance, three correction points on the upper left side, upper right side, and lower right side of the PDP <highlight><bold>101</bold></highlight>. The user may touch the three points on the PDP <highlight><bold>101</bold></highlight> with his fingertip or the pen. </paragraph>
<paragraph id="P-0392" lvl="0"><number>&lsqb;0392&rsqb;</number> When any of the three correction points are touched by the user, the device driver <highlight><bold>507</bold></highlight> executes positional correction processing for matching the display position of the mouse cursor with the touch position according to the touched position. The result of positional correction is saved in a prespecified file. </paragraph>
<paragraph id="P-0393" lvl="0"><number>&lsqb;0393&rsqb;</number> However, the operation for positional correction is previously performed when the display board system <highlight><bold>100</bold></highlight> is actually shipped as a product, therefore, a user need not perform the procedure for positional correction unless resolution of the PDP <highlight><bold>101</bold></highlight> or the like is changed. </paragraph>
<paragraph id="P-0394" lvl="0"><number>&lsqb;0394&rsqb;</number> It should be noted that, description is made for an outline of other setting items in the setting screen <highlight><bold>3500</bold></highlight>. The reference numeral <highlight><bold>3502</bold></highlight> indicates a mouse button/emulation mode setting column, which is used for setting which processing is to be executed when the touch surface <highlight><bold>201</bold></highlight> is touched with the fingertip or the pen. In the mouse button/emulation mode setting column <highlight><bold>3502</bold></highlight>, for instance, the following settings can be carried out: </paragraph>
<paragraph id="P-0395" lvl="2"><number>&lsqb;0395&rsqb;</number> {circle over (1)} Setting so as to regard when the touch surface <highlight><bold>201</bold></highlight> is touched with a fingertip or a pen as a click, </paragraph>
<paragraph id="P-0396" lvl="2"><number>&lsqb;0396&rsqb;</number> {circle over (2)} Setting so as to regard when a fingertip or a pen having touched the touch surface <highlight><bold>201</bold></highlight> is moved off as a click, </paragraph>
<paragraph id="P-0397" lvl="2"><number>&lsqb;0397&rsqb;</number> {circle over (3)} Setting so as to regard when a fingertip or a pen touching the touch surface <highlight><bold>201</bold></highlight> is moved along the surface in its touched state as drag, and </paragraph>
<paragraph id="P-0398" lvl="2"><number>&lsqb;0398&rsqb;</number> {circle over (4)} Setting so as to regard when the touch surface <highlight><bold>201</bold></highlight> is touched twice in a row with a fingertip or a pen (double touch) as a double click as well as to regard when a fingertip or a pen touching the touch surface <highlight><bold>201</bold></highlight> is moved along the surface in its touched state as drag (this setting is required when the display board software <highlight><bold>506</bold></highlight> is used). </paragraph>
<paragraph id="P-0399" lvl="0"><number>&lsqb;0399&rsqb;</number> Furthermore, the reference numeral <highlight><bold>3503</bold></highlight> indicates an output setting check box for touch sound, and when this check box <highlight><bold>3503</bold></highlight> is checked, a beep is outputted each time when the touch surface <highlight><bold>201</bold></highlight> is touched. The reference numeral <highlight><bold>3504</bold></highlight> indicates a setting button, and when the setting button <highlight><bold>3504</bold></highlight> is touched, a screen for setting a method of connecting the controller <highlight><bold>103</bold></highlight> appears. Furthermore, designated at the reference numeral <highlight><bold>3505</bold></highlight> in the figure is an information button for displaying information on the controller <highlight><bold>103</bold></highlight> as well as on the device driver <highlight><bold>507</bold></highlight>. <highlight><bold>3506</bold></highlight> is a help button for displaying a help screen. <highlight><bold>3507</bold></highlight> is an OK button for validating an item or items set in the setting screen <highlight><bold>3500</bold></highlight>, and <highlight><bold>3508</bold></highlight> is a cancel button for invalidating an item or items set in the setting screen <highlight><bold>3500</bold></highlight> respectively. </paragraph>
<paragraph id="P-0400" lvl="7"><number>&lsqb;0400&rsqb;</number> (5) Use of AV Equipment </paragraph>
<paragraph id="P-0401" lvl="0"><number>&lsqb;0401&rsqb;</number> Connected to the PDP <highlight><bold>101</bold></highlight> in the display board system <highlight><bold>100</bold></highlight>, as shown in <cross-reference target="DRAWINGS">FIG. 27</cross-reference>, are various types of information equipment and AV equipment such as a video player <highlight><bold>108</bold></highlight>, a laser disk player, a DVD player, and a video camera to enable reproduction of video and audio. In addition, an external speaker can be connected to the PDP <highlight><bold>101</bold></highlight> through an amplifier, which allows a user to enjoy a powerful sound with a large-sized display. Signals inputted from the information equipment, AV equipment, or the computer <highlight><bold>104</bold></highlight> to the PDP <highlight><bold>101</bold></highlight> can easily be switched using a remote control or the like which is not shown. </paragraph>
<paragraph id="P-0402" lvl="0"><number>&lsqb;0402&rsqb;</number> As described above, various types of information equipment and AV equipment can be connected to the PDP <highlight><bold>101</bold></highlight> and operated without using the computer <highlight><bold>104</bold></highlight>, so that the PDP <highlight><bold>101</bold></highlight> can be used as a large-sized screen monitor. Thus allows operability, adaptability for handling, and convenience of the display board system <highlight><bold>100</bold></highlight> to be improved without requiring other equipment such as a television to be prepared. </paragraph>
<paragraph id="P-0403" lvl="7"><number>&lsqb;0403&rsqb;</number> (6) Connection to a Network </paragraph>
<paragraph id="P-0404" lvl="0"><number>&lsqb;0404&rsqb;</number> Furthermore, as shown in <cross-reference target="DRAWINGS">FIG. 59</cross-reference>, the display board system <highlight><bold>100</bold></highlight> can be connected to a network such as a LAN or the Internet. Therefore, applicability of the display board system <highlight><bold>100</bold></highlight> can be widened to the extent of: transmitting materials or the like for a conference prepared with the display board software <highlight><bold>506</bold></highlight> to other computer, reading in data prepared by other computer and using it in a conference, teleconferencing by connecting a plurality of display board systems <highlight><bold>100</bold></highlight> to each other, and applying the display board system <highlight><bold>100</bold></highlight> in a video conference system or some other occasions. In addition, the display board system <highlight><bold>100</bold></highlight> can be connected to a network using the radio signals from a Personal Handyphone System. </paragraph>
<paragraph id="P-0405" lvl="7"><number>&lsqb;0405&rsqb;</number> 3. Effects </paragraph>
<paragraph id="P-0406" lvl="0"><number>&lsqb;0406&rsqb;</number> As described above, with the display board system according to Embodiment 3, as the coordinate-position input device described in Embodiments 1 and 2 is used, operability and reliability when input is performed to the display board system can be improved. </paragraph>
<paragraph id="P-0407" lvl="0"><number>&lsqb;0407&rsqb;</number> The display board system <highlight><bold>100</bold></highlight> is configured with the frame unit <highlight><bold>600</bold></highlight> comprising the board section <highlight><bold>601</bold></highlight> forming a display surface and a writing surface of a display board with the PDP <highlight><bold>101</bold></highlight> and coordinate-position input device <highlight><bold>102</bold></highlight> and the equipment accommodating section <highlight><bold>604</bold></highlight> in which the computer <highlight><bold>104</bold></highlight>, video player <highlight><bold>108</bold></highlight>, and printer <highlight><bold>106</bold></highlight> are accommodated in the vertical direction from the bottom. Therefore, movement and installation of the system can easily be performed only by moving the frame unit <highlight><bold>600</bold></highlight>. As the devices are arranged in the order of the heaviest one at the bottom and the lighter ones above the heavier ones in the direction of gravity (vertical direction), stability of the frame unit <highlight><bold>600</bold></highlight> when it is moved and installed can be insured. Namely, with the display board system <highlight><bold>100</bold></highlight> according to Embodiment 3, it is possible to enhance downsizing and integration of the display board system <highlight><bold>100</bold></highlight> as a whole and also improve operability, adaptability of handling, and convenience thereof. </paragraph>
<paragraph id="P-0408" lvl="0"><number>&lsqb;0408&rsqb;</number> In addition, the display board system <highlight><bold>100</bold></highlight> has an angle adjusting mechanism section <highlight><bold>802</bold></highlight> for adjusting an angle of the board section <highlight><bold>601</bold></highlight> with the PDP <highlight><bold>101</bold></highlight> and coordinate-position input device <highlight><bold>102</bold></highlight> accommodated therein, so that incoming interference light into the display surface of the PDP <highlight><bold>101</bold></highlight>, especially, light from lighting equipment such as a fluorescent tube provided on the ceiling can be avoided. Therefore, an image on the screen can easily be seen and convenience of the display board system <highlight><bold>100</bold></highlight> can be improved. </paragraph>
<paragraph id="P-0409" lvl="0"><number>&lsqb;0409&rsqb;</number> Furthermore, the PDP <highlight><bold>101</bold></highlight> can be used as a large-sized screen monitor by using a plurality of connecting terminals for connecting various types of information equipment and AV equipment such as a digital camera, a DVD player, and a video equipment to the system. Therefore, it is possible to provide a display board system <highlight><bold>100</bold></highlight> for enabling connection and operation of the various types of information equipment and AV equipment without using the computer <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0410" lvl="0"><number>&lsqb;0410&rsqb;</number> Next, as Embodiment 4, another display board system applicable to the above mentioned display board system <highlight><bold>100</bold></highlight> according to Embodiment 3 will be described. </paragraph>
<paragraph id="P-0411" lvl="0"><number>&lsqb;0411&rsqb;</number> When the size of a screen of a display unit such as the PDP <highlight><bold>101</bold></highlight> according to Embodiment 3 is about 100 inches wide across the corners, for example, it will be difficult for a presenter standing at the left side of the screen to directly point to a place (touch the touch surface <highlight><bold>201</bold></highlight>) at the upper right corner. Therefore, in Embodiment 4, description is made for a display board system which allows a presenter to perform a pointing operation to an image displayed on the large-sized screen in his natural posture toward the audience. </paragraph>
<paragraph id="P-0412" lvl="0"><number>&lsqb;0412&rsqb;</number> The display board system according to Embodiment 4 displays an icon for selecting a create a point-operating area with the icon such as a press button at some corner of the display screen. When a presenter selects the create a point-operating area with this icon and specifies a position where the point-operating area is created, a pointer area creating section creates a rectangular point-operating area in an instructed position on an image display unit and displays the area. The presenter confirms the displayed point-operating area and points to a position corresponding to a display point on the display screen within the point-operating area instead of directly pointing to the display point on the display screen. When the presenter points to a position corresponding to a display point on the screen within the point-operating area, a pointer moving section moves a pointer (mouse cursor) on the display screen to the display point and points to the display point. Thus, the presenter can easily and accurately point to a display point on a large screen which the presenter can not reach. </paragraph>
<paragraph id="P-0413" lvl="0"><number>&lsqb;0413&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 60</cross-reference> is a view of a display unit forming the display board system according to Embodiment 4. The image display unit <highlight><bold>3700</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 60</cross-reference> is a large-sized screen display comprising an image display section <highlight><bold>3701</bold></highlight> (corresponding to the PDP <highlight><bold>101</bold></highlight> in Embodiment 3) and a coordinate-position input device <highlight><bold>3702</bold></highlight> (corresponding to the coordinate-position input device <highlight><bold>102</bold></highlight> in Embodiment 3) provided on the surface of the image display section <highlight><bold>3701</bold></highlight>. In <cross-reference target="DRAWINGS">FIG. 60</cross-reference>, the reference numeral <highlight><bold>3706</bold></highlight> corresponds to the controller <highlight><bold>103</bold></highlight> in Embodiment 3 (Refer to <cross-reference target="DRAWINGS">FIG. 27</cross-reference>). </paragraph>
<paragraph id="P-0414" lvl="0"><number>&lsqb;0414&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 61</cross-reference> is a block diagram showing a main control section of the display board system according to Embodiment 4 of the present invention. The main control section <highlight><bold>3800</bold></highlight> comprises a CPU <highlight><bold>3801</bold></highlight>, a ROM <highlight><bold>3802</bold></highlight>, a RAM <highlight><bold>3803</bold></highlight>, an I/F <highlight><bold>3804</bold></highlight> with the image display unit <highlight><bold>3700</bold></highlight> and coordinate-position input device <highlight><bold>3702</bold></highlight> connected thereto, a pointer area creating section <highlight><bold>3809</bold></highlight>, a pointer moving section <highlight><bold>3810</bold></highlight> and a pointing section <highlight><bold>3811</bold></highlight>. It should be noted that, the main control section <highlight><bold>3800</bold></highlight> corresponds to the computer <highlight><bold>104</bold></highlight> in Embodiment 3. </paragraph>
<paragraph id="P-0415" lvl="0"><number>&lsqb;0415&rsqb;</number> In the display board system having the configuration described above, description is made for an operation when a point P on the display screen of the image display section <highlight><bold>3701</bold></highlight> is pointed, for example, as shown in <cross-reference target="DRAWINGS">FIG. 60</cross-reference> with reference to the display view in <cross-reference target="DRAWINGS">FIG. 62</cross-reference> and the flow chart in <cross-reference target="DRAWINGS">FIG. 63</cross-reference>. In an ordinary operating situation, when a presenter using the image display unit <highlight><bold>3700</bold></highlight> touches the point P on the screen <highlight><bold>3701</bold></highlight> with his or her fingertip, the situation is regarded as that the presenter points to the point P and the pointer <highlight><bold>3704</bold></highlight> is moved to the point P. However, when the size of a screen of the image display section <highlight><bold>3701</bold></highlight> is about 100 inches in a width across corners, for example, it will be difficult for the presenter standing at the left edge to the screen to directly point to the point P at the upper right side. Therefore, the CPU <highlight><bold>3801</bold></highlight> displays an icon for selecting a create a point-operating area with the icon such as a press button at some corner of the image display section <highlight><bold>3701</bold></highlight>. When the presenter selects the create a point-operating area with this icon and specifies a position where the point-operating area is created (steps S<highlight><bold>4201</bold></highlight> and S<highlight><bold>4202</bold></highlight>), the pointer area creating section <highlight><bold>3809</bold></highlight> reduces the image display section <highlight><bold>3701</bold></highlight> and the coordinate-position input device <highlight><bold>3702</bold></highlight> to an instructed size shown in <cross-reference target="DRAWINGS">FIG. 62</cross-reference>, creates a rectangular point-operating area <highlight><bold>4100</bold></highlight>, and displays the area on the image display section <highlight><bold>3701</bold></highlight> (step S<highlight><bold>4203</bold></highlight>). </paragraph>
<paragraph id="P-0416" lvl="0"><number>&lsqb;0416&rsqb;</number> The presenter having confirmed this point-operating area <highlight><bold>4100</bold></highlight> points to a point B corresponding to the point P within the point-operating area <highlight><bold>4100</bold></highlight> instead of directly pointing to the point P on the screen <highlight><bold>3703</bold></highlight> (step S<highlight><bold>4204</bold></highlight>). In response to this operation, the pointer moving section <highlight><bold>3810</bold></highlight> moves the pointer <highlight><bold>3704</bold></highlight> to the point P on the screen <highlight><bold>3703</bold></highlight> and points to the point P (step S<highlight><bold>4205</bold></highlight>). Thus, the presenter can indirectly point to the point P on the large screen which the presenter can not reach. </paragraph>
<paragraph id="P-0417" lvl="0"><number>&lsqb;0417&rsqb;</number> Then, detailed description is made for operations when a point-operating area <highlight><bold>4100</bold></highlight> is displayed on the image display section <highlight><bold>3701</bold></highlight> and when the displayed point-operating area <highlight><bold>4100</bold></highlight> is deleted with reference to the views for processing steps in <cross-reference target="DRAWINGS">FIGS. 64A</cross-reference> to <highlight><bold>64</bold></highlight>C and the flow chart in <cross-reference target="DRAWINGS">FIG. 65</cross-reference>. As shown in <cross-reference target="DRAWINGS">FIG. 64</cross-reference>A, on the screen <highlight><bold>3703</bold></highlight> of the image display section <highlight><bold>3701</bold></highlight> in its ordinary operating status, when a presenter creates a loop-shaped trail having a geometrical feature previously defined, for instance, a trail <highlight><bold>4300</bold></highlight> similar to a rectangle, the CPU <highlight><bold>3801</bold></highlight> determines through the controller <highlight><bold>3706</bold></highlight> that the presenter&apos;s fingertip <highlight><bold>3705</bold></highlight> have touched an entry area of the coordinate-position input device <highlight><bold>3702</bold></highlight> and continuously records coordinates and times from the point of time when the finger has touched it until the finger <highlight><bold>3705</bold></highlight> moves off the coordinate-position input device <highlight><bold>3702</bold></highlight> in the RAM <highlight><bold>3803</bold></highlight> (steps S<highlight><bold>4401</bold></highlight> to S<highlight><bold>4403</bold></highlight>). </paragraph>
<paragraph id="P-0418" lvl="0"><number>&lsqb;0418&rsqb;</number> The pointer area creating section <highlight><bold>3809</bold></highlight> determines whether the presenter has created a drawing or has pointed to a point by touching the coordinate-position input device <highlight><bold>3702</bold></highlight> according to the coordinates and times recorded in the RAM <highlight><bold>3803</bold></highlight> (S<highlight><bold>4404</bold></highlight>). </paragraph>
<paragraph id="P-0419" lvl="0"><number>&lsqb;0419&rsqb;</number> The pointer area creating section <highlight><bold>3809</bold></highlight> computes, when it is determined that the drawing has been created as shown in FIG. <highlight><bold>64</bold></highlight>A, the center of gravity in a created pattern according to the created drawing <highlight><bold>4300</bold></highlight> (step S<highlight><bold>4405</bold></highlight>), and identifies a type of pattern (step S<highlight><bold>4406</bold></highlight>). When it is determined that the identified pattern is, for instance, a rectangle, the pointer area creating section <highlight><bold>3809</bold></highlight> creates a point-operating area <highlight><bold>4100</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 64B</cross-reference> at the position of the center of gravity n the created pattern as a reference and displays the area on the screen <highlight><bold>3703</bold></highlight> (step S<highlight><bold>4407</bold></highlight>). </paragraph>
<paragraph id="P-0420" lvl="0"><number>&lsqb;0420&rsqb;</number> When the presenter points, in the above state, to the point B corresponding to the point P on the screen <highlight><bold>3703</bold></highlight> by touching the coordinate-position input device <highlight><bold>3702</bold></highlight>, the pointer area creating section <highlight><bold>3809</bold></highlight> determines that the pointing is instructed (steps S<highlight><bold>4401</bold></highlight> to S<highlight><bold>4404</bold></highlight>). When it is determined by the pointer area creating section <highlight><bold>3809</bold></highlight> that the pointing has been instructed, the pointer moving section <highlight><bold>3810</bold></highlight> moves the pointer <highlight><bold>3704</bold></highlight> on the screen <highlight><bold>3703</bold></highlight> to the point P on the screen <highlight><bold>3703</bold></highlight> corresponding to the point B to which pointing is instructed and displays the moved pointer (step S<highlight><bold>4408</bold></highlight>). </paragraph>
<paragraph id="P-0421" lvl="0"><number>&lsqb;0421&rsqb;</number> In the above state, when a trail <highlight><bold>4301</bold></highlight> which is not a loop is created in the point-operating area <highlight><bold>4100</bold></highlight> by the presenter as shown in <cross-reference target="DRAWINGS">FIG. 64</cross-reference>C and coordinates and each time of the trail <highlight><bold>4301</bold></highlight> are stored in the RAM <highlight><bold>3803</bold></highlight>, the pointer area creating section <highlight><bold>3809</bold></highlight> determines that the created trail <highlight><bold>4301</bold></highlight> is a graphic to be deleted and deletes the point-operating area <highlight><bold>4100</bold></highlight> from the screen <highlight><bold>3703</bold></highlight> (steps S<highlight><bold>4409</bold></highlight> and S<highlight><bold>4410</bold></highlight>). When this point-operating area <highlight><bold>4100</bold></highlight> is to be deleted, if the center of gravity in the trail <highlight><bold>4301</bold></highlight> to the center of gravity in the point-operating area <highlight><bold>4100</bold></highlight> is closer to a preset value, the trail <highlight><bold>4301</bold></highlight> is determined as a graphic to be deleted, which makes it possible to suppress redundancy of the operation. </paragraph>
<paragraph id="P-0422" lvl="0"><number>&lsqb;0422&rsqb;</number> Description is made for the processing, when the point B in the point-operating area <highlight><bold>4100</bold></highlight> is instructed to be pointed to as described above, for a case where the coordinates of the instructed point B are transformed to coordinates of the point P on the screen <highlight><bold>3703</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 62</cross-reference>, it is assumed that the point-operating area <highlight><bold>4100</bold></highlight> is displayed by reducing the image display section <highlight><bold>3701</bold></highlight> and the coordinate-position input device <highlight><bold>3702</bold></highlight> at a specified reduction rate. Then, as shown in <cross-reference target="DRAWINGS">FIG. 62</cross-reference>, it is assumed that, by setting the lower left edge of the screen <highlight><bold>3703</bold></highlight>, for instance, to the origin O1, each point of the screen <highlight><bold>3703</bold></highlight> is expressed with X-Y coordinates, and coordinates of a point C1 diagonal to the origin O1 are (x1e, y1e), and that the lower left edge of the point-operating area <highlight><bold>4100</bold></highlight> corresponding to the origin O1 is the origin O2 of the point-operating area <highlight><bold>4100</bold></highlight> and the coordinates of a point C2 in the point-operating area <highlight><bold>4100</bold></highlight> corresponding to the point C1 are (x2e, y2e). As a result the coordinate (x2, y2) of each point in the point-operating area <highlight><bold>4100</bold></highlight> correspond to coordinate (x1, y1) of each point on the screen <highlight><bold>3703</bold></highlight> one for one through a factor K decided based on a relation between the coordinate (x1e, y1e) and the coordinate (x2e, y2e). Therefore, the pointer moving section <highlight><bold>3810</bold></highlight> can accurately move the pointer <highlight><bold>3704</bold></highlight> to the point P by transforming coordinates from the coordinate (x2b, y2b) of the point B pointed in the point-operating area <highlight><bold>4100</bold></highlight> to the coordinate (x1a, y1a) of the point P on the screen <highlight><bold>3703</bold></highlight>. </paragraph>
<paragraph id="P-0423" lvl="0"><number>&lsqb;0423&rsqb;</number> As described above, as each point in the point-operating area <highlight><bold>4100</bold></highlight> corresponds to each point on the screen <highlight><bold>3703</bold></highlight> one for one, the point-operating area <highlight><bold>4100</bold></highlight> is recognized by a user as to be equivalent to a reduced screen of the full screen <highlight><bold>3703</bold></highlight>. Therefore, when the point-operating area <highlight><bold>4100</bold></highlight> is displayed, as shown in <cross-reference target="DRAWINGS">FIG. 66, a</cross-reference> similar reduced object <highlight><bold>4501</bold></highlight> obtained by reducing an object <highlight><bold>4500</bold></highlight> such as characters and graphics displayed on the full screen <highlight><bold>3703</bold></highlight> can be displayed in the point-operating area <highlight><bold>4100</bold></highlight>. </paragraph>
<paragraph id="P-0424" lvl="0"><number>&lsqb;0424&rsqb;</number> As the processing of transforming the coordinates of the instructed point B to the coordinates of the point P on the screen <highlight><bold>3703</bold></highlight>, the case of transforming the coordinate (x2b, y2b) of the point B pointed in the point-operating area <highlight><bold>4100</bold></highlight> to the coordinate (x1a, y1a) of the point P on the screen <highlight><bold>3703</bold></highlight> has been described, but the pointer <highlight><bold>3704</bold></highlight> on the screen <highlight><bold>3703</bold></highlight> can also directly be moved. The processing in this case will be described with reference to <cross-reference target="DRAWINGS">FIG. 67</cross-reference>. </paragraph>
<paragraph id="P-0425" lvl="0"><number>&lsqb;0425&rsqb;</number> Relative values in movement of coordinates in the point-operating area <highlight><bold>4100</bold></highlight> correspond to relative values in movement of the pointer <highlight><bold>3704</bold></highlight> on the screen <highlight><bold>3703</bold></highlight> through the factor K. Therefore, when the presenter instructs to move the pointer <highlight><bold>3704</bold></highlight> from a display position F (x11, y11) on the screen <highlight><bold>3703</bold></highlight> by keeping on pointing to and moving an arbitrary point D (x21, y21) on the coordinate-position input device <highlight><bold>3702</bold></highlight> to a point E (x22, y22) within the point-operating area <highlight><bold>4100</bold></highlight>, a coordinate data row pointed within the point-operating area <highlight><bold>4100</bold></highlight> is inputted with coordinates of X2-Y2. By differentiating or executing differential operation of this inputted coordinate data row, the transform (dx2, dy2) of the inputted coordinate is operated in appropriate time intervals. The coordinate F (x11, y11) of the pointer <highlight><bold>3704</bold></highlight> on the screen <highlight><bold>3703</bold></highlight> can be transformed and displayed based on transformation (dx1, dy1) of the coordinate obtained by multiplying the transformation of the coordinate along time within the point-operating area <highlight><bold>4100</bold></highlight> by the factor K. In this case, although the point D within the point-operating area <highlight><bold>4100</bold></highlight> may not correspond to a display position F of the pointer <highlight><bold>3704</bold></highlight> on the screen <highlight><bold>3703</bold></highlight> one for one, by correlating the transformation (dx2, dy2) of the coordinate to transformation of coordinate of the point F on the screen <highlight><bold>3703</bold></highlight> through the factor K, and the pointer <highlight><bold>3704</bold></highlight> on the screen <highlight><bold>3703</bold></highlight> can be operated in much the same way the mouse is operated. </paragraph>
<paragraph id="P-0426" lvl="0"><number>&lsqb;0426&rsqb;</number> If this processing of operating the pointer <highlight><bold>3704</bold></highlight> on the screen <highlight><bold>3703</bold></highlight> in much the same way the mouse is operated and the processing of using coordinate of a point B pointed on the point-operating area <highlight><bold>4100</bold></highlight> are switched as required, a user can use properly either the mouse emulation or the pointing operation based on absolute coordinate according to the situation. </paragraph>
<paragraph id="P-0427" lvl="0"><number>&lsqb;0427&rsqb;</number> The image display unit <highlight><bold>3700</bold></highlight> is premised on displaying an image generated by a computer. For moving an object in a displayed image or moving an icon or a window in an operating system, an ordinary mouse operation is carried out by moving a pointer over an object, pressing a button (pointing operation) thereon, and moving the object to a desired position in its pressed state. This operation is generally known as an operation of drag. Description is made hereinafter for an operation of drag for moving the pointer over the full screen <highlight><bold>3703</bold></highlight> by pointing to any coordinate within the point-operating area <highlight><bold>4100</bold></highlight>. </paragraph>
<paragraph id="P-0428" lvl="0"><number>&lsqb;0428&rsqb;</number> The display board system according to Embodiment 4 has no button mechanism as that provided in an ordinary mouse because the coordinate-position input device <highlight><bold>3702</bold></highlight> is used therein. As a method of realizing an operation instead of the ordinary mouse operation, a cursor is moved up to target coordinate within the point-operating area <highlight><bold>4100</bold></highlight>, and an object-displayed surface is momentarily pointed thereto with a finger or a pen at the target position. </paragraph>
<paragraph id="P-0429" lvl="0"><number>&lsqb;0429&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 68</cross-reference> shows one example of changes of a state of pointing to an entry area of the coordinate-position input device <highlight><bold>3702</bold></highlight> with the fingertip <highlight><bold>3705</bold></highlight> on the time axis. During the time T1, the fingertip <highlight><bold>3705</bold></highlight> is moved keeping on its pointing to the point-operating area <highlight><bold>4100</bold></highlight> of the coordinate-position input device <highlight><bold>3702</bold></highlight>, and the pointer <highlight><bold>3704</bold></highlight> is moved to a desired object on the screen <highlight><bold>3703</bold></highlight>. During the time T2, when the pointer <highlight><bold>3704</bold></highlight> is moved up to the desired object, the fingertip <highlight><bold>3705</bold></highlight> is moved off the coordinate-position input device <highlight><bold>3702</bold></highlight> once, and at the point of time T3, the object at the position is momentarily pointed to with the fingertip. At the point of time T4 when the operation is ended and thereafter, the pointing section <highlight><bold>3811</bold></highlight> selects a desired object and shifts to a state in which the mouse button has been pressed down (a pointing state). This determination above can be made, for instance, by switching the state of pointing to the point-operating area <highlight><bold>4100</bold></highlight> of the coordinate-position input device <highlight><bold>3702</bold></highlight> to the non-pointing state and vice versa within an appropriate time interval. Furthermore, the pointing section <highlight><bold>3811</bold></highlight> changes the display color of the point-operating area <highlight><bold>4100</bold></highlight> from a first color at a state of not pointing to the area to a second color. According to this change in display color, a user can accurately recognize that the state has been changed to a pointing state even when there is no mechanical button thereon. In this state, the fingertip <highlight><bold>3704</bold></highlight> is touched again in the point-operating area <highlight><bold>4100</bold></highlight>, the pointed object is moved, and the fingertip is moved off the object at the point of time T5, so that the movement of the object is completed and the state of pointing to the object is released. </paragraph>
<paragraph id="P-0430" lvl="0"><number>&lsqb;0430&rsqb;</number> Although description has been made for the case where the state is shifted to the pointing state when the point-operating area <highlight><bold>4100</bold></highlight> is momentarily pointed to at the point of time T3, one of a certain number of states may be selectively specified in the pointing section <highlight><bold>3811</bold></highlight> depending on a number of times of instant pointing. Furthermore, during a state shifting process for shifting to the pointing state, a user can recognize that the current state is in the process of shifting to the other state by switching the display color in the point-operating area <highlight><bold>4100</bold></highlight> to a third color, therefore, malfunction can be reduced. </paragraph>
<paragraph id="P-0431" lvl="0"><number>&lsqb;0431&rsqb;</number> As described above, with the display board system according to Embodiment 4, a point-operating area <highlight><bold>4100</bold></highlight> used for pointing to a display point on a displayed image appears on a desired position according to an instruction by a user, and the user can operate the pointer <highlight><bold>3704</bold></highlight> on the screen <highlight><bold>3703</bold></highlight> in the point-operating area <highlight><bold>4100</bold></highlight>. Therefore, a presenter can easily and accurately point to a position which the presenter can not reach even in the large-sized screen display unit. </paragraph>
<paragraph id="P-0432" lvl="0"><number>&lsqb;0432&rsqb;</number> Furthermore, a position and a size of the point-operating area <highlight><bold>4100</bold></highlight> are instructed on the coordinate-position input device <highlight><bold>3702</bold></highlight>, so that the point-operating area <highlight><bold>4100</bold></highlight> can be displayed on an arbitrary position with a simple operation, and pointing to a display point on the screen <highlight><bold>3703</bold></highlight> can easily be performed. </paragraph>
<paragraph id="P-0433" lvl="0"><number>&lsqb;0433&rsqb;</number> In addition, each coordinate within the point-operating area <highlight><bold>4100</bold></highlight> are displayed in correlation to coordinate within all area on the image display surface one for one, so that a pointed position can easily be specified on the point-operating area <highlight><bold>4100</bold></highlight>. </paragraph>
<paragraph id="P-0434" lvl="0"><number>&lsqb;0434&rsqb;</number> Furthermore, transform of the coordinate to which is pointed with the pointer within the point-operating area <highlight><bold>4100</bold></highlight> is correlated to movement of coordinate of the pointer on an image display surface, and the pointer <highlight><bold>3704</bold></highlight> is moved according to this transform so that the pointer <highlight><bold>3704</bold></highlight> on the screen <highlight><bold>3703</bold></highlight> can be operated in much the same way the mouse is operated. </paragraph>
<paragraph id="P-0435" lvl="0"><number>&lsqb;0435&rsqb;</number> In addition, a user selectably uses a pointing operation based on absolute coordinate and a pointing operation based on transform of coordinate as required, so that the user can use properly either the mouse emulation or the pointing operation based on absolute coordinate according to the situation. </paragraph>
<paragraph id="P-0436" lvl="0"><number>&lsqb;0436&rsqb;</number> Furthermore, layout information of display contents on the entire screen is displayed in the point-operating area <highlight><bold>4100</bold></highlight>, so that a user can check the display contents in the point-operating area <highlight><bold>4100</bold></highlight>, therefore, a pointing operation on a large-sized screen can easily be performed. </paragraph>
<paragraph id="P-0437" lvl="0"><number>&lsqb;0437&rsqb;</number> Furthermore, by momentarily pointing to some point within the point-operating area <highlight><bold>4100</bold></highlight> once or a plurality of times, a plurality of pointing states can be obtained according to a number of times of pointing, so that a pointing operation on a large-sized screen can easily be performed. By changing the display colors of the point-operating area <highlight><bold>4100</bold></highlight> according to a plurality of pointing states, malfunction and a miss operation of the system on pointing can be reduced. </paragraph>
<paragraph id="P-0438" lvl="0"><number>&lsqb;0438&rsqb;</number> For example, if a security function is provided in the display board system according to Embodiment 3 and a personal identification number is inputted through a coordinate-position input device, a PID number to be inputted may be seen by some other persons. Therefore, in Embodiment 5, a display board system that can prevent a PID number from being seen by other persons when a PID number is inputted in the display board system will be explained. Specifically, the display board system according to Embodiment 5 displays a ten-key on a position over which a person entering the number casts his shadow when viewed from other persons, so that the ten-key used for entering a PID number is hidden by the person entering it, which allows the ten-key not to be seen from other persons. </paragraph>
<paragraph id="P-0439" lvl="0"><number>&lsqb;0439&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 69</cross-reference> is a block diagram generally showing a first example of the configuration of the display board system according to Embodiment 5. This display board system comprises a coordinate-position inputting section (corresponding to the coordinate-position input device <highlight><bold>102</bold></highlight> in Embodiment 3) for detecting a position of a pointing body having pointed at an input surface (corresponding to the touch surface <highlight><bold>201</bold></highlight> in Embodiment 3) on the input surface, and an image display section (corresponding to the PDP <highlight><bold>101</bold></highlight> in Embodiment 3) for displaying an image on a screen commonly used as the input surface. The display board system further comprises an image pickup section <highlight><bold>4800</bold></highlight> for picking up an image of a person who enters a PID number, a position detecting section <highlight><bold>4801</bold></highlight> for detecting a position of the person who enters a PID number according to the image picked up by the image pickup section <highlight><bold>4800</bold></highlight>, and a ten-key display position specifying section <highlight><bold>4802</bold></highlight> for displaying the ten-key on the image display section according to the position obtained by the position detecting section <highlight><bold>4801</bold></highlight>. </paragraph>
<paragraph id="P-0440" lvl="0"><number>&lsqb;0440&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 70</cross-reference> is an appearance view showing a first example of the configuration of the display board system. In the first example of the configuration, the image pickup section (camera) <highlight><bold>4800</bold></highlight> for picking up an image of the person who enters a PID number standing in front of the section is provided in the display board system <highlight><bold>4900</bold></highlight>. The image picked up by the camera <highlight><bold>4800</bold></highlight> as the image pickup section <highlight><bold>4800</bold></highlight> is sent to the position detecting section <highlight><bold>4801</bold></highlight> built in the display board system <highlight><bold>4900</bold></highlight>. The position detecting section <highlight><bold>4801</bold></highlight> detects a position of the person from the image of the person picked up by the image pickup section <highlight><bold>4800</bold></highlight>. </paragraph>
<paragraph id="P-0441" lvl="0"><number>&lsqb;0441&rsqb;</number> As a method of detecting a position of a person from an image thereof, various types of methods can be used. For example, at first a local frequency is computed on an inputted full image. Then, the frequency element obtained as described above are subjected to threshold processing, and as described in <cross-reference target="DRAWINGS">FIG. 71</cross-reference> the full image is separated into a portion (area <highlight><bold>5000</bold></highlight>) with a high frequency included and a portion (area <highlight><bold>5001</bold></highlight>) with less high frequency included. This processing is employed based on the fact that the image of a person focused on has comparatively more of high frequency elements but a background which is not focused on has less high frequency elements. Herein the portion (area <highlight><bold>5000</bold></highlight>) with high frequencies included in the full image is predicted as a portion of a person. Then, the center of gravity (GX, GY) in the area <highlight><bold>5000</bold></highlight> where the person is supposed to be photographed is obtained. At which position on the image the person is present can be computed through the processing above. </paragraph>
<paragraph id="P-0442" lvl="0"><number>&lsqb;0442&rsqb;</number> As described above, when the position of the person is detected as, for instance, (GX, GY), on which position of the input surface the ten-key should be displayed is computed from this position (GX, GY) in the ten-key display position specifying section <highlight><bold>4802</bold></highlight>. As a method of deciding a position of the ten-key to be displayed to the position (GX, GY), various types of methods can be used. For instance, as it is conceivable that the same position as that where the person is standing is probably the hardest-to-view position from other persons, so that the ten-key <highlight><bold>4901</bold></highlight> is displayed on that position. Furthermore, positions where not only the person who enters a PID number but also viewers are present are presumed from the images and the ten-key <highlight><bold>4901</bold></highlight> may be displayed on the position obtained through such consideration. </paragraph>
<paragraph id="P-0443" lvl="0"><number>&lsqb;0443&rsqb;</number> As one example, description is made for a method of deciding a displayed position with reference to <cross-reference target="DRAWINGS">FIG. 72</cross-reference>. <cross-reference target="DRAWINGS">FIG. 72</cross-reference> is a view showing the display board system <highlight><bold>4900</bold></highlight> when viewed from the upper side thereof. As shown in <cross-reference target="DRAWINGS">FIG. 72</cross-reference>, for persons <highlight><bold>6001</bold></highlight> and <highlight><bold>6002</bold></highlight>, a position over which a person <highlight><bold>6000</bold></highlight> who enters a PID number casts his shadow is an area <highlight><bold>6003</bold></highlight> indicated by a heavy line, therefore, the ten-key <highlight><bold>4901</bold></highlight> is displayed on a position within this area <highlight><bold>6003</bold></highlight>. Through the processing described above, the ten-key <highlight><bold>4901</bold></highlight> is displayed as shown in <cross-reference target="DRAWINGS">FIG. 70</cross-reference>. Thus, the ten-key <highlight><bold>4901</bold></highlight> for entry of a PID number is hidden behind the person who enters a PID number so that nobody can see the ten-key. </paragraph>
<paragraph id="P-0444" lvl="0"><number>&lsqb;0444&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 73</cross-reference> is a block diagram generally showing a second example of the configuration of the display board system according to Embodiment 5. This display board system comprises a coordinate-position inputting section (corresponding to the coordinate-position input device <highlight><bold>102</bold></highlight> in Embodiment 3) for detecting a position of a pointing body having pointed to an input surface (corresponding to the touch surface <highlight><bold>201</bold></highlight> in Embodiment 3) on the input surface and an image display section (corresponding to the PDP <highlight><bold>101</bold></highlight> in Embodiment 3) for displaying an image on a surface commonly used as the input surface. The display board system further comprises a measuring section <highlight><bold>5100</bold></highlight> for measuring a three-dimensional position of a person who enters a PID number, and a ten-key display position specifying section <highlight><bold>5101</bold></highlight> for displaying a ten-key on the image display section according to the three-dimensional position obtained by the measuring section <highlight><bold>5100</bold></highlight>. </paragraph>
<paragraph id="P-0445" lvl="0"><number>&lsqb;0445&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 74</cross-reference> is an appearance view showing the second example of the configuration of the display board system. In the second example, the measuring section (three-dimensional position measuring device) <highlight><bold>5100</bold></highlight> for computing a three-dimensional position of a person who enters a PID number by standing in front of the display board system <highlight><bold>4900</bold></highlight> is provided. As the three-dimensional position measuring device <highlight><bold>5100</bold></highlight>, various types of device can be used. For example, a device using a principle of stereoscopic vision with a twin-lens camera and a device using an optical cutting method of projecting a reference pattern and reading displacement of the pattern from its image or the like can be used. </paragraph>
<paragraph id="P-0446" lvl="0"><number>&lsqb;0446&rsqb;</number> In the display board system <highlight><bold>4900</bold></highlight>, the measuring section <highlight><bold>5100</bold></highlight> detects a three-dimensional position of a person (RX, RY, RZ), and the ten-key display position specifying section <highlight><bold>5101</bold></highlight> computes on which position of the input surface the ten-key should be displayed. As a method of deciding a position of a ten-key to be displayed with respect to the position (RX, RY, RZ), various types of methods can be used. For example, the method described in the first configuration can be used. When the position of the ten-key to be displayed to the position (RX, RY, RZ) is decided, the ten-key <highlight><bold>4901</bold></highlight> is displayed on the decided display position as shown in <cross-reference target="DRAWINGS">FIG. 74</cross-reference>. Thus, the ten-key <highlight><bold>4901</bold></highlight> for entry of a PID number is hidden behind the person <highlight><bold>6000</bold></highlight> who enters a PID number so as not to be seen from other persons because of the same principle having been described with reference to <cross-reference target="DRAWINGS">FIG. 72</cross-reference>. </paragraph>
<paragraph id="P-0447" lvl="0"><number>&lsqb;0447&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 75</cross-reference> is a block diagram generally showing a third example of the configuration of the display board system according to Embodiment 5. This display board system comprises a coordinate-position inputting section (corresponding to the coordinate-position input device <highlight><bold>102</bold></highlight> in Embodiment 3) for detecting a position of a pointing body having pointing to an input surface (corresponding to the touch surface <highlight><bold>201</bold></highlight> in Embodiment 3) on the input surface and an image display section (corresponding to the PDP <highlight><bold>101</bold></highlight> in Embodiment 3) for displaying an image on a surface commonly used as the input surface. The display board system further comprises a position detecting section <highlight><bold>5300</bold></highlight> for detecting a position of a person who enters a PID number by getting on the section, and a ten-key display position specifying section <highlight><bold>5301</bold></highlight> for displaying a ten-key on the image display section according to the position obtained by the position detecting section <highlight><bold>5300</bold></highlight>. </paragraph>
<paragraph id="P-0448" lvl="0"><number>&lsqb;0448&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 76</cross-reference> is an appearance view showing the third example of the configuration of the display board system. In the third example, sheet type of position detecting section (position detecting device) <highlight><bold>5300</bold></highlight> is provided therein so that a position of a person who enters a PID number standing in front of the display board system <highlight><bold>4900</bold></highlight> can be found out. As a position detecting method by this position detecting device <highlight><bold>5300</bold></highlight>, various types of methods can be used. For example, a method for detecting a position with a pressure applied on a sheet surface as a pressure-sensitive sheet can be used. </paragraph>
<paragraph id="P-0449" lvl="0"><number>&lsqb;0449&rsqb;</number> In the display board system <highlight><bold>4900</bold></highlight>, the position detecting section <highlight><bold>5300</bold></highlight> detects a position of a person (SX, SY), and the ten-key display position specifying section <highlight><bold>5301</bold></highlight> computes on which position of the input surface the ten-key should be displayed. As a method of deciding a position of a ten-key to be displayed to the position (SX, SY), various types of methods can be used. For example, the method described in the first configuration can be used. When the position of the ten-key to be displayed to the position (SX, SY) is decided, the ten-key <highlight><bold>4901</bold></highlight> is displayed on the decided display position as shown in <cross-reference target="DRAWINGS">FIG. 76</cross-reference>. Thus, the ten-key <highlight><bold>4901</bold></highlight> for entry of a PID number is hidden behind the person <highlight><bold>6000</bold></highlight> who enters a PID number so as not to be seen from other persons because of the same principle having been described with reference to <cross-reference target="DRAWINGS">FIG. 72</cross-reference>. </paragraph>
<paragraph id="P-0450" lvl="0"><number>&lsqb;0450&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 77</cross-reference> is a block diagram generally showing a fourth example of the configuration of the display board system according to Embodiment 5. This display board system comprises a coordinate-position inputting section (corresponding to the coordinate-position input device <highlight><bold>102</bold></highlight> in Embodiment 3) for detecting a position of a pointing body having pointed to an input surface (corresponding to the touch surface <highlight><bold>201</bold></highlight> in Embodiment 3) on the input surface and an image display section (corresponding to the PDP <highlight><bold>101</bold></highlight> in Embodiment 3) for displaying an image on a surface commonly used as the input surface. The display board system further comprises a plurality of distance measuring sections <highlight><bold>5500</bold></highlight> located in an array, a position detecting section <highlight><bold>5501</bold></highlight> for detecting a position of a person who enters a PID number according to the distance measured by the distance measuring sections <highlight><bold>5500</bold></highlight>, and a ten-key display position specifying section <highlight><bold>5502</bold></highlight> for displaying a ten-key on the image display section according to the position obtained by the position detecting section <highlight><bold>5501</bold></highlight>. </paragraph>
<paragraph id="P-0451" lvl="0"><number>&lsqb;0451&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 78</cross-reference> is an appearance view showing the fourth example of the configuration of the display board system. In the fourth example, the distance measuring section (an array with a plurality of distance measuring sensors) <highlight><bold>5500</bold></highlight> for measuring a distance up to an object extending in one-dimensional direction (a vertical direction to the input surface) by using ultrasonic waves are arranged in an array on the display board system <highlight><bold>4900</bold></highlight>. With this feature, positional information (distance information) for a person standing in front of the display board <highlight><bold>4900</bold></highlight> can be obtained. The distance information obtained by the distance measuring section <highlight><bold>5500</bold></highlight> comprising a plurality of distance measuring sensors as described above is given to the position detecting section <highlight><bold>5501</bold></highlight>, and the position detecting section <highlight><bold>5501</bold></highlight> identifies a position of a person who enters a PID number according to the distance information obtained from the distance measuring section <highlight><bold>5500</bold></highlight>. As a method of identifying a position of a person who enters a PID number from the distance information obtained from the distance measuring section <highlight><bold>5500</bold></highlight>, various types of methods can be used. For example, a position of the distance measuring sensor which has a shortest distance up to the object can be considered as a position (DX) of the person who enters a PID number. </paragraph>
<paragraph id="P-0452" lvl="0"><number>&lsqb;0452&rsqb;</number> When the position (DX) of the person is obtained as described above, on which position of the input surface from this position (DX) the ten-key should be displayed is computed by the ten-key display position specifying section <highlight><bold>5502</bold></highlight>. As a method of deciding a position of a ten-key to be displayed to the position (DX), various types of methods can be used. For example, the method described in the first configuration can be used. When the position of the ten-key to be displayed to the position (DX) is decided, the ten-key <highlight><bold>4901</bold></highlight> is displayed on the decided display position as shown in <cross-reference target="DRAWINGS">FIG. 78</cross-reference>. Thus, the ten-key <highlight><bold>4901</bold></highlight> for entry of a PID number is hidden behind the person <highlight><bold>6000</bold></highlight> who enters a PID number so as not to be seen from other persons because of the same principle described with reference to <cross-reference target="DRAWINGS">FIG. 72</cross-reference>. </paragraph>
<paragraph id="P-0453" lvl="0"><number>&lsqb;0453&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 79</cross-reference> is a block diagram generally showing a fifth example of the configuration of the display board system according to Embodiment 5. This display board system comprises a coordinate-position inputting section (corresponding to the coordinate-position input device <highlight><bold>102</bold></highlight> in Embodiment 3) for detecting a position of a pointing body having pointed to an input surface (corresponding to the touch surface <highlight><bold>201</bold></highlight> in Embodiment 3) on the input surface and an image display section (corresponding to the PDP <highlight><bold>101</bold></highlight> in Embodiment 3) for displaying an image on a surface commonly used as the input surface. The display board system further comprises a ten-key position specifying section <highlight><bold>5700</bold></highlight> for specifying a position of a ten-key to be displayed, and a ten-key display position specifying section <highlight><bold>5701</bold></highlight> for displaying a ten-key on a position specified by the ten-key position specifying section <highlight><bold>5700</bold></highlight>. </paragraph>
<paragraph id="P-0454" lvl="0"><number>&lsqb;0454&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 80</cross-reference> is an appearance view showing the fifth example of the configuration of the display board system. In the fifth example, the ten-key position specifying section <highlight><bold>5700</bold></highlight> for enabling entry-of a position where a ten-key is to be displayed is provided on the display board system <highlight><bold>4900</bold></highlight>. A person who enters a PID number can specify on which part of an input screen the ten-key should be displayed by using this ten-key position specifying section <highlight><bold>5700</bold></highlight>. As a method of specifying a position of a ten-key using the ten-key position specifying section <highlight><bold>5700</bold></highlight>, various types of methods can be used. For example, methods of manually inputting coordinate of a position, or of displaying a thumbnail image to input a desired position by touching it can be employed. </paragraph>
<paragraph id="P-0455" lvl="0"><number>&lsqb;0455&rsqb;</number> Also in this fifth example of the configuration, an input window (a ten-key display specifying window) for specifying a position of a ten-key to be displayed with gesture or the like may be displayed on an input surface without using the ten-key position specifying section <highlight><bold>5700</bold></highlight>. </paragraph>
<paragraph id="P-0456" lvl="0"><number>&lsqb;0456&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 81</cross-reference> is a block diagram generally showing an example of configuration of a display board system which can display an input window (a ten-key display specifying window) for specifying a ten-key display position on an input surface. The display board system shown in <cross-reference target="DRAWINGS">FIG. 81</cross-reference> comprises a coordinate-position inputting section (corresponding to the coordinate-position input device <highlight><bold>102</bold></highlight> in Embodiment 3) for detecting a position of a pointing body having pointed to an input surface (corresponding to the touch surface <highlight><bold>201</bold></highlight> in Embodiment 3) on the input surface and an image display section (corresponding to the PDP <highlight><bold>101</bold></highlight> in Embodiment 3) for displaying an image on a surface commonly used as the input surface. The display board system further comprises a ten-key display specifying window display section <highlight><bold>5900</bold></highlight> for displaying a ten-key display specifying window for specifying a ten-key display position on the image display section, and a ten-key display position specifying section <highlight><bold>5701</bold></highlight> for displaying the ten-key on a specified position, when an operation of specifying a ten-key display position is performed to the ten-key display specifying window displayed on the image display section by the ten-key display specifying window display section <highlight><bold>5900</bold></highlight>. </paragraph>
<paragraph id="P-0457" lvl="0"><number>&lsqb;0457&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 82</cross-reference> is a block diagram showing an example of hardware configuration of the display board system shown in any of the <cross-reference target="DRAWINGS">FIG. 69</cross-reference>, <cross-reference target="DRAWINGS">FIG. 73</cross-reference>, <cross-reference target="DRAWINGS">FIG. 75</cross-reference>, <cross-reference target="DRAWINGS">FIG. 77</cross-reference>, <cross-reference target="DRAWINGS">FIG. 79</cross-reference> and <cross-reference target="DRAWINGS">FIG. 81</cross-reference>. As shown in <cross-reference target="DRAWINGS">FIG. 81</cross-reference>, various types of processing in the display board system are realized by, for instance, a microcomputer or a DSP (digital signal processor) and software. More specifically, the display board system comprises at least a CPU <highlight><bold>6100</bold></highlight> for providing controls over the system as a whole, a ROM <highlight><bold>6101</bold></highlight> with control programs for the CPU <highlight><bold>6100</bold></highlight> or the like stored therein, a RAM <highlight><bold>6102</bold></highlight> used as a work area for the CPU <highlight><bold>6100</bold></highlight>, a coordinate-position inputting section <highlight><bold>6103</bold></highlight>, and an image display section <highlight><bold>6104</bold></highlight>. </paragraph>
<paragraph id="P-0458" lvl="0"><number>&lsqb;0458&rsqb;</number> Herein the CPU <highlight><bold>6100</bold></highlight> has functions of the position detecting section <highlight><bold>4801</bold></highlight> and ten-key display position specifying section <highlight><bold>4802</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 69</cross-reference>, the measuring section <highlight><bold>5100</bold></highlight> and ten-key display position specifying section <highlight><bold>5101</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 73</cross-reference>, the position detecting section <highlight><bold>5300</bold></highlight> and ten-key display position specifying section <highlight><bold>5301</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 75</cross-reference>, the position detecting section <highlight><bold>5501</bold></highlight> and ten-key display position specifying section <highlight><bold>5502</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 77</cross-reference>, the ten-key position specifying section <highlight><bold>5700</bold></highlight> and ten-key display position specifying section <highlight><bold>5701</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 79</cross-reference>, or the ten-key display specifying window display section <highlight><bold>5900</bold></highlight> and ten-key display position specifying section <highlight><bold>5701</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 81</cross-reference>. </paragraph>
<paragraph id="P-0459" lvl="0"><number>&lsqb;0459&rsqb;</number> It should be noted that, the functions of the CPU <highlight><bold>6100</bold></highlight> described above can be provided in a form of, for example, a software package (more specifically, information recording medium such as a CD-ROM). Therefore, a medium driving unit <highlight><bold>6106</bold></highlight> for driving an information recording medium <highlight><bold>6105</bold></highlight> is provided in the example of <cross-reference target="DRAWINGS">FIG. 82</cross-reference>. </paragraph>
<paragraph id="P-0460" lvl="0"><number>&lsqb;0460&rsqb;</number> In other words, the functions of the display board system in Embodiment 5 can be realized also by making a built-in processor system read a program recorded in the information recording medium such as a CD-ROM and making a microprocessor or the like execute ten-key display processing. In this case, the program (namely, the program used in the hardware system) for executing the processing described in Embodiment 5 can be provided in a state in which the program is recorded in a medium. An information recording medium with a program recorded therein is not limited to a CD-ROM, and any medium such as a ROM, a RAM, a flexible disk, and a memory card may be used. The program recorded in a medium is installed in a storage device incorporated in hardware system, for example, in a RAM <highlight><bold>6102</bold></highlight>, with which this program is executed and the above mentioned processing function can be realized. </paragraph>
<paragraph id="P-0461" lvl="0"><number>&lsqb;0461&rsqb;</number> The program for realizing the processing described in Embodiment 5 may be provided not only in the form of a medium but also through communications (e.g., from a server). </paragraph>
<paragraph id="P-0462" lvl="0"><number>&lsqb;0462&rsqb;</number> It should be noted that the description for each configuration above has assumed the case shown in <cross-reference target="DRAWINGS">FIG. 72</cross-reference> as a method of deciding a display position, but if only one viewer is present there, a ten-key for inputting a PID number may be displayed on an extension between the viewer and a person who enters a PID number. If there are a plurality of viewers, various types of deciding method can be used according to each situation taking into consideration positions of the viewers and the person who enters a PID number, such that a ten-key for a PID number is displayed in a blind area from the viewers. </paragraph>
<paragraph id="P-0463" lvl="0"><number>&lsqb;0463&rsqb;</number> The processing described here is applicable not only to the display board system but also to various types of input device requiring entry of a PID number such as an ATM for bank and a device provided at the entrance of a building that recognizes and allows people to enter inside the building. </paragraph>
<paragraph id="P-0464" lvl="0"><number>&lsqb;0464&rsqb;</number> As described above, with the display board system according to Embodiment 5, a person who enters a PID number is photographed, a position of the person is detected according to the photographed image, and a ten-key is displayed according to the detected position, so that the ten-key can be displayed at the position hidden by the person, therefore, a possibility that a PID number being inputted is seen by other persons can be reduced. </paragraph>
<paragraph id="P-0465" lvl="0"><number>&lsqb;0465&rsqb;</number> Also a three-dimensional position of the person who enters a PID number is determined, and a ten-key is displayed according to the determined three-dimensional position, so that a display position of the ten-key can more accurately be decided. </paragraph>
<paragraph id="P-0466" lvl="0"><number>&lsqb;0466&rsqb;</number> When the person gets on a sheet type of position detecting device, the position of the person is detected, and a ten-key is displayed according to the detected position. Thus, for example, a position where the person stands on the floor in front of an input surface can be detected, therefore, a display position of the ten-key can more accurately be decided. </paragraph>
<paragraph id="P-0467" lvl="0"><number>&lsqb;0467&rsqb;</number> Furthermore, distance up to the object is measured, a position of the person is detected according to the measured value, and a ten-key is displayed according to the detected position, so that a display position of the ten-key can more accurately be decided. </paragraph>
<paragraph id="P-0468" lvl="0"><number>&lsqb;0468&rsqb;</number> Furthermore, a display position of a ten-key is specified, and the ten-key is displayed on the specified position. Thus, for example, a display position of the ten-key can manually be inputted, therefore, a display position of the ten-key can be decided according to situation. </paragraph>
<paragraph id="P-0469" lvl="7"><number>&lsqb;0469&rsqb;</number> Furthermore, a ten-key display specifying window for specifying a display position of a ten-key is displayed, and the ten-key is displayed on a position inputted in the ten-key display specifying window. Thus, a manual input device for specifying a display position of the ten-key can be displayed as software, therefore, a low-cost input device can be provided. </paragraph>
<paragraph id="P-0470" lvl="0"><number>&lsqb;0470&rsqb;</number> A display board system according to Embodiment 6 is applicable to the display board system according to Embodiment 3, and is used for easily generating a software keyboard and enabling insurance of security with a simple operation. </paragraph>
<paragraph id="P-0471" lvl="0"><number>&lsqb;0471&rsqb;</number> The display board system according to Embodiment 6 has a coordinate-position input device (corresponding to the coordinate-position input device <highlight><bold>102</bold></highlight> in Embodiment 3) provided on the surface of an image display unit (corresponding to the PDP <highlight><bold>101</bold></highlight> in Embodiment 3) and a signal control section. The signal control section has a touched area computing section, a touched position detecting section, a touched area determining section, a software keyboard generating section, and a drawing section. Herein, as described in Embodiment 3, the display surface and touch surface (writing surface) of a display board is formed with the image display unit and coordinate-position input device. </paragraph>
<paragraph id="P-0472" lvl="0"><number>&lsqb;0472&rsqb;</number> When the touch surface is touched with a fingertip or the like, the coordinate-position input device outputs signals corresponding to the touched area and touched position to the touched area computing section as well as to the touched position detecting section. The touched position detecting section detects coordinates of the point on the touch surface touched with the fingertip or the like from the signals received from the coordinate-position input device. At the same time, the touched area computing section computes a touched area (area of the touched portion) when the touch surface is touched with the fingertip or the like according to the signals received from the coordinate-position input device. The touched area determining section compares the touched area computed by the touched area computing section to a preset threshold value, and determines that a drawing or the like is created on the touch surface when the computed touched area is smaller than the threshold value. The drawing section executes drawing processing according to the touched area computed in the touched area computing section as well as to the coordinates detected in the touched position detecting section to display an image on the image display unit, and also inputs the coordinate (coordinate group) of the image displayed after being subjected to the drawing processing into a computer. When it is determined that the touched area exceeds the threshold value, the touched area determining section determines that the touch surface has been touched with, for instance, a palm, and the software keyboard generating section generates a software keyboard and displays it on the touched position of the image display unit in a size previously set. </paragraph>
<paragraph id="P-0473" lvl="0"><number>&lsqb;0473&rsqb;</number> By touching the touch surface with, for instance, a palm, a software keyboard can easily be displayed on the image display unit. By operating the displayed software keyboard in the same manner as a keyboard is operated, a user can easily execute various types of operation in the display board system. For example, the display board system can execute authentication processing on permission to access the system according to a PID number inputted through the software keyboard. </paragraph>
<paragraph id="P-0474" lvl="0"><number>&lsqb;0474&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 83</cross-reference> is a block diagram showing a first example of the configuration of a display board system according to Embodiment 6. As shown in <cross-reference target="DRAWINGS">FIG. 83</cross-reference>, the display board system has a coordinate-position input device <highlight><bold>7501</bold></highlight> (corresponding to the coordinate-position input device <highlight><bold>102</bold></highlight> in Embodiment 3), an image display unit <highlight><bold>7502</bold></highlight> (corresponding to the PDP <highlight><bold>101</bold></highlight> in Embodiment 3), and a signal control section <highlight><bold>7503</bold></highlight>. The signal control section <highlight><bold>7503</bold></highlight> has a touched area computing section <highlight><bold>7504</bold></highlight>, a touched position detecting section <highlight><bold>7505</bold></highlight>, a touched area determining section <highlight><bold>7506</bold></highlight>, a software keyboard generating section <highlight><bold>7507</bold></highlight> and a drawing section <highlight><bold>7508</bold></highlight>. </paragraph>
<paragraph id="P-0475" lvl="0"><number>&lsqb;0475&rsqb;</number> When the touch surface is touched with a fingertip or a pen, the coordinate-position input device <highlight><bold>7501</bold></highlight> outputs a signal according to the touched area and touched position as shown in <cross-reference target="DRAWINGS">FIG. 84</cross-reference>. In a screenful time-series signal, by integrating each time when the change is generated, an area of the portion on the touch surface where the fingertip touches can be computed. Then the touched area computing section <highlight><bold>7504</bold></highlight> computes each area of portions A1, A2, and A3 on the touch surface where the fingertip touches according to the screenful time-series signal outputted from the coordinate-position input device <highlight><bold>7501</bold></highlight>. Then the touched position detecting section <highlight><bold>7505</bold></highlight> computes coordinates of portions A1, A2 and A3 from the screenful time-series signal outputted from the coordinate-position input device <highlight><bold>7501</bold></highlight>. The touched area determining section <highlight><bold>7506</bold></highlight> compares the touched area computed by the touched area computing section <highlight><bold>7504</bold></highlight> with a preset threshold value. The software keyboard generating section <highlight><bold>7507</bold></highlight> generates, when it is determined in the touched area determining section <highlight><bold>7506</bold></highlight> that the touched area exceeds the threshold value, a software keyboard and displays it on some position of the image display unit <highlight><bold>7502</bold></highlight> corresponding to the touched position. The drawing section <highlight><bold>7508</bold></highlight> executes, when it is determined in the touched area determining section <highlight><bold>7506</bold></highlight> that the touched area is smaller than the threshold value, drawing processing according to the touched area and touched position on the touch surface, displays an image on the image display unit <highlight><bold>7502</bold></highlight>, and also inputs coordinate (coordinate group) of the image displayed after being subjected to the drawing processing in the computer <highlight><bold>7509</bold></highlight>. </paragraph>
<paragraph id="P-0476" lvl="0"><number>&lsqb;0476&rsqb;</number> Description is made for an operation when the touch surface of the display board system configured as described above is touched with the fingertip or the like with reference to the flow chart in <cross-reference target="DRAWINGS">FIG. 85</cross-reference>. When the touch surface is touched with the fingertip or the like, the coordinate-position input device <highlight><bold>7501</bold></highlight> outputs signals corresponding to the touched area and touched position to the touched area computing section <highlight><bold>7504</bold></highlight> as well as to the touched position detecting section <highlight><bold>7505</bold></highlight> (step S<highlight><bold>7701</bold></highlight>). </paragraph>
<paragraph id="P-0477" lvl="0"><number>&lsqb;0477&rsqb;</number> The touched position detecting section <highlight><bold>7505</bold></highlight> detects coordinates of a position on the touch surface touched with the fingertip or the like from the signal received from the coordinate-position input device <highlight><bold>7501</bold></highlight> (step S<highlight><bold>7702</bold></highlight>). At the same time, the touched area computing section <highlight><bold>7504</bold></highlight> computes an area touched with the fingertip according to the signal received from the coordinate-position input device <highlight><bold>7501</bold></highlight> (step S<highlight><bold>7703</bold></highlight>). </paragraph>
<paragraph id="P-0478" lvl="0"><number>&lsqb;0478&rsqb;</number> The touched area determining section <highlight><bold>7506</bold></highlight> compares the touched area computed by the touched area computing section <highlight><bold>7504</bold></highlight> with the preset threshold value (step S<highlight><bold>7704</bold></highlight>), and determines that a graphic or the like is created on the touch surface when the computed touched area is smaller than the threshold value. In response to this determination, the drawing section <highlight><bold>7508</bold></highlight> executes drawing processing according to the touched area computed in the touched area computing section <highlight><bold>7504</bold></highlight> as well as according to the coordinates detected in the touched position detecting section <highlight><bold>7505</bold></highlight> to display an image on the image display unit <highlight><bold>7502</bold></highlight>, and also inputs coordinate (coordinate group) of the image displayed after being subjected to the drawing processing to the computer <highlight><bold>7509</bold></highlight> (step S<highlight><bold>7705</bold></highlight>). </paragraph>
<paragraph id="P-0479" lvl="0"><number>&lsqb;0479&rsqb;</number> When it is determined that the touched area exceeds the threshold value, the touched area determining section <highlight><bold>7506</bold></highlight> determines that the touch surface has been touched with, for instance, a palm. In response to this determination, the software keyboard generating section <highlight><bold>7507</bold></highlight> generates a software keyboard and displays it on some position of the image display unit <highlight><bold>7502</bold></highlight> corresponding to the touched position in a size previously set (step S<highlight><bold>7706</bold></highlight>). </paragraph>
<paragraph id="P-0480" lvl="0"><number>&lsqb;0480&rsqb;</number> As described above, by touching the touch surface with, for instance, a palm, the software keyboard can easily be displayed on the image display unit <highlight><bold>7502</bold></highlight>. By operating the displayed software keyboard in the same manner as that when a keyboard is operated, various types of operation can easily be executed. </paragraph>
<paragraph id="P-0481" lvl="0"><number>&lsqb;0481&rsqb;</number> In the first example of the configuration, description has been made for the case where a software keyboard in a certain size is generated in the software keyboard generating section <highlight><bold>7507</bold></highlight> and displayed on the image display unit <highlight><bold>7502</bold></highlight>. However, the software keyboard generating section <highlight><bold>7507</bold></highlight> can also display the software keyboard to be displayed on the image display unit <highlight><bold>7502</bold></highlight> in a size specified by an operator. For example, when the user touches the touch surface with the palm, the software keyboard having a size corresponding to the touched area is generated in the software keyboard generating section <highlight><bold>7507</bold></highlight> and displayed on the image display unit <highlight><bold>7502</bold></highlight>. As described above, by displaying the palm-sized software keyboard, the most easy-to-use-sized software keyboard can be displayed. </paragraph>
<paragraph id="P-0482" lvl="0"><number>&lsqb;0482&rsqb;</number> Next description is made for an example of a security function by using the software keyboard displayed on the image display unit <highlight><bold>7502</bold></highlight> as described above. </paragraph>
<paragraph id="P-0483" lvl="0"><number>&lsqb;0483&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 86</cross-reference> is a block diagram showing a second example of the configuration of the display board system. As shown in <cross-reference target="DRAWINGS">FIG. 86</cross-reference>, the display board system has a coordinate-position input device <highlight><bold>7501</bold></highlight>, an image display unit <highlight><bold>7502</bold></highlight>, a signal control section <highlight><bold>7503</bold></highlight>, and a comparing section <highlight><bold>7810</bold></highlight>. The signal control section <highlight><bold>7503</bold></highlight> has a touched area computing section <highlight><bold>7504</bold></highlight>, a touched position detecting section <highlight><bold>7505</bold></highlight>, a touched area determining section <highlight><bold>7506</bold></highlight>, a software keyboard generating section <highlight><bold>7507</bold></highlight>, and in addition, a code generating section <highlight><bold>7811</bold></highlight>, a touched area signal storing section <highlight><bold>7812</bold></highlight>, a code signal storing section <highlight><bold>7813</bold></highlight> and a reference signal storing section <highlight><bold>7814</bold></highlight>. </paragraph>
<paragraph id="P-0484" lvl="0"><number>&lsqb;0484&rsqb;</number> The code generating section <highlight><bold>7811</bold></highlight> converts a coordinate signal of a touched position on the touch surface detected in the touched position detecting section <highlight><bold>7505</bold></highlight> to a code signal according to a preset table. The touched area signal storing section <highlight><bold>7812</bold></highlight> successively stores, when a touched area computed in the touched area computing section <highlight><bold>7504</bold></highlight> is smaller than the threshold value, the computed touched areas therein. The code signal storing section <highlight><bold>7813</bold></highlight> successively stores code signals converted in the code generating section <highlight><bold>7811</bold></highlight>. The reference signal storing section <highlight><bold>7814</bold></highlight> stores a series of code signals for the users previously authorized to use the display board system and also stores a series of touched areas each as reference signals. The comparing section <highlight><bold>7810</bold></highlight> executes authentication processing by comparing an input signal consisting of the touched area signal series stored in the touched area signal storing section <highlight><bold>7812</bold></highlight> and the code signal series stored in the code signal storing section <highlight><bold>7813</bold></highlight> with the reference signals stored in the reference signal storing section <highlight><bold>7814</bold></highlight>. </paragraph>
<paragraph id="P-0485" lvl="0"><number>&lsqb;0485&rsqb;</number> Description is made for an operation of the display board system configured as described above with reference to the flow chart in <cross-reference target="DRAWINGS">FIG. 87</cross-reference>. As described in the first example of the configuration, when the software keyboard is displayed on the image display unit <highlight><bold>7502</bold></highlight> (step S<highlight><bold>7901</bold></highlight>), the user touches the touch surface corresponding to the software keyboard with his or her fingertip or the like to enter a PID number or a password (step S<highlight><bold>7902</bold></highlight>). Herein when a ten-key is displayed as a software keyboard, a PID number is inputted, while a password is inputted when a full key is displayed. </paragraph>
<paragraph id="P-0486" lvl="0"><number>&lsqb;0486&rsqb;</number> The touched position detecting section <highlight><bold>7505</bold></highlight> detects coordinates of each touched position on the coordinate-position input device <highlight><bold>7501</bold></highlight> and sends the coordinates to the code generating section <highlight><bold>7811</bold></highlight> (step S<highlight><bold>7903</bold></highlight>). The code generating section <highlight><bold>7811</bold></highlight> converts the received coordinates into code signals and successively stores the code signals in the code signal storing section <highlight><bold>7813</bold></highlight> (step S<highlight><bold>7904</bold></highlight>). </paragraph>
<paragraph id="P-0487" lvl="0"><number>&lsqb;0487&rsqb;</number> On the other hand, the touched area computing section <highlight><bold>7504</bold></highlight> computes a touched area when the user touches the touch surface with his or her fingertip to enter the PID number or the like, and stores the touched area in the touched area signal storing section <highlight><bold>7812</bold></highlight> (step S<highlight><bold>7905</bold></highlight>). </paragraph>
<paragraph id="P-0488" lvl="0"><number>&lsqb;0488&rsqb;</number> When this operation of inputting a PID number or a password is finished (step <highlight><bold>7906</bold></highlight>), the comparing section <highlight><bold>7810</bold></highlight> reads out the code signal series stored in the code signal storing section <highlight><bold>7813</bold></highlight> and the touched area signal series stored in the touched area signal storing section <highlight><bold>7812</bold></highlight>, and compares the input signals consisting of the read-out code signal series and the touched area signal series with the reference signals consisting of the code signal series of the users authorized to access the computer system and the touched area signal series each previously registered in the reference signal storing section <highlight><bold>7814</bold></highlight> (step S<highlight><bold>7907</bold></highlight>). As this comparing method, a simple template matching can be used for comparison of code signals, and Viterbi decoding based on DP matching and HMM and a neural network technology can be used for comparison of signals in touched area series because the signals in the touched area series are the signals changing with time. </paragraph>
<paragraph id="P-0489" lvl="0"><number>&lsqb;0489&rsqb;</number> As a result of this comparison, when the reference signal coincident with the input signal is registered in the reference signal storing section <highlight><bold>7814</bold></highlight>, it is determined that the user has been registered, and permission to the user to access the system is sent to the computer <highlight><bold>7509</bold></highlight> (steps S<highlight><bold>7908</bold></highlight> and S<highlight><bold>7909</bold></highlight>). When the reference signal coincident with the input signal is not registered in the reference signal storing section <highlight><bold>7814</bold></highlight>, inhibition to access the system is sent to the computer <highlight><bold>7509</bold></highlight> (steps S<highlight><bold>7908</bold></highlight> and S<highlight><bold>7910</bold></highlight>). The computer <highlight><bold>7509</bold></highlight> displays the received result on the image display unit <highlight><bold>7502</bold></highlight>. </paragraph>
<paragraph id="P-0490" lvl="0"><number>&lsqb;0490&rsqb;</number> As described above, determination is made as to whether the user is an authorized person or not according to the code signal series as well as according to the touched area signal series indicating a touched position when the PID number and password are inputted from the software keyboard. Therefore, high-reliability authentication for accessing the system can be verified without user&apos;s any particular operation required for authentication. </paragraph>
<paragraph id="P-0491" lvl="0"><number>&lsqb;0491&rsqb;</number> In the second example of the configuration, description has been made for the case where access to the system should be permitted or not depending on the PID number and password inputted from the software keyboard. However, authentication processing as to whether permission to access the system is given or not may be performed according to handwriting of user&apos;s signature. </paragraph>
<paragraph id="P-0492" lvl="0"><number>&lsqb;0492&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 88</cross-reference> is a block diagram showing a third example of the configuration of the display board system. The display board system according to this third configuration performs authentication processing as to whether permission to access the system is given or not according to the user&apos;s handwriting. The signal control section <highlight><bold>7503</bold></highlight> of the display board system as shown in <cross-reference target="DRAWINGS">FIG. 88</cross-reference> has a touched area computing section <highlight><bold>7504</bold></highlight>, a touched position detecting section <highlight><bold>7505</bold></highlight>, a touched area determining section <highlight><bold>7506</bold></highlight>, a software keyboard generating section <highlight><bold>7507</bold></highlight>, a touched area signal storing section <highlight><bold>7812</bold></highlight>, a coordinate signal storing section <highlight><bold>8015</bold></highlight>, and a reference signal storing section <highlight><bold>7814</bold></highlight><highlight><italic>a. </italic></highlight></paragraph>
<paragraph id="P-0493" lvl="0"><number>&lsqb;0493&rsqb;</number> The coordinate signal storing section <highlight><bold>8015</bold></highlight> stores therein coordinates of a touched position on the touch surface detected by the touched position detecting section <highlight><bold>7505</bold></highlight>. The reference signal storing section <highlight><bold>7814</bold></highlight><highlight><italic>a </italic></highlight>registers therein a coordinate signal series obtained by previously measuring handwritings of users permitted to access the system and a touched area series as reference signals. </paragraph>
<paragraph id="P-0494" lvl="0"><number>&lsqb;0494&rsqb;</number> Description is made for an operation of the display board system configured as described above with reference to the flow chart in <cross-reference target="DRAWINGS">FIG. 89</cross-reference>. When the user touches the touch surface with his or her fingertip or the like, the coordinate-position input device <highlight><bold>7501</bold></highlight> outputs signals corresponding to the touched area and touched position to the touched area computing section <highlight><bold>7504</bold></highlight> as well as to the touched position detecting section <highlight><bold>7505</bold></highlight> (step S<highlight><bold>8101</bold></highlight>). </paragraph>
<paragraph id="P-0495" lvl="0"><number>&lsqb;0495&rsqb;</number> The touched position detecting section <highlight><bold>7505</bold></highlight> detects coordinates of a position on the touch surface touched with the fingertip or the like from a signal received from the coordinate-position input device <highlight><bold>7501</bold></highlight> and stores the values in the coordinate signal storing section <highlight><bold>8015</bold></highlight> (step S<highlight><bold>8102</bold></highlight>). At the same time, the touched area computing section <highlight><bold>7504</bold></highlight> computes an area on the touch surface touched with the fingertip according to the signal received from the coordinate-position input device <highlight><bold>7501</bold></highlight> (step S<highlight><bold>8103</bold></highlight>). </paragraph>
<paragraph id="P-0496" lvl="0"><number>&lsqb;0496&rsqb;</number> The touched area determining section <highlight><bold>7506</bold></highlight> compares the touched area computed by the touched area computing section <highlight><bold>7504</bold></highlight> with the preset threshold value (step S<highlight><bold>8104</bold></highlight>), and determines that the user has touched the touch surface with, for instance, a palm when the computed touched area is larger than the threshold value. In response to this determination, the software keyboard generating section <highlight><bold>7507</bold></highlight> generates a software keyboard and displays the keyboard on a position of the image display unit <highlight><bold>7502</bold></highlight> corresponding to the touched position (steps S<highlight><bold>8104</bold></highlight> and S<highlight><bold>8105</bold></highlight>). </paragraph>
<paragraph id="P-0497" lvl="0"><number>&lsqb;0497&rsqb;</number> On the other hand, when the computed touched area is smaller than the threshold value, the touched area determining section <highlight><bold>7506</bold></highlight> determines that the user has created some graphics on the touch surface, and the touched areas are successively stored in the touched area signal storing section <highlight><bold>7812</bold></highlight> (steps S<highlight><bold>8104</bold></highlight> and S<highlight><bold>8106</bold></highlight>). </paragraph>
<paragraph id="P-0498" lvl="0"><number>&lsqb;0498&rsqb;</number> When inputting to the touch surface is finished, the comparing section <highlight><bold>7810</bold></highlight> reads out the coordinate signal series stored in the coordinate signal storing section <highlight><bold>8015</bold></highlight> and the touched area signal series stored in the touched area signal storing section <highlight><bold>7812</bold></highlight>. Then the comparing section <highlight><bold>7810</bold></highlight> compares the input signals consisting of the read-out coordinate signal series and touched area signal series with the reference signals consisting of the coordinate signal series indicating handwriting of user&apos;s signature authorized to access the computer system and the touched area signal series each previously registered in the reference signal storing section <highlight><bold>7814</bold></highlight><highlight><italic>a </italic></highlight>(steps S<highlight><bold>8107</bold></highlight> and S<highlight><bold>8108</bold></highlight>). </paragraph>
<paragraph id="P-0499" lvl="0"><number>&lsqb;0499&rsqb;</number> As a result of this comparison, when the reference signal coincident with the input signal is registered in the reference signal storing section <highlight><bold>7814</bold></highlight><highlight><italic>a</italic></highlight>, it is determined that the user has been registered, and permission to the user to access the system is sent to the computer <highlight><bold>7509</bold></highlight> (steps S<highlight><bold>8109</bold></highlight> and S<highlight><bold>8110</bold></highlight>). On the other hand, when the reference signal coincident with the input signal is not registered in the reference signal storing section <highlight><bold>7814</bold></highlight><highlight><italic>a</italic></highlight>, inhibition to access the system is sent to the computer <highlight><bold>7509</bold></highlight> (steps S<highlight><bold>8109</bold></highlight> and S<highlight><bold>8111</bold></highlight>). The computer <highlight><bold>7509</bold></highlight> displays the received result on the image display unit <highlight><bold>7502</bold></highlight>. </paragraph>
<paragraph id="P-0500" lvl="0"><number>&lsqb;0500&rsqb;</number> As described above, determination is made as to whether the user is an authorized person or not according to the user&apos;s signature, therefore, high-reliability authentication for accessing the system can be verified with a simple operation. </paragraph>
<paragraph id="P-0501" lvl="0"><number>&lsqb;0501&rsqb;</number> In the third example of the configuration, the coordinate signal series for handwriting of user&apos;s signature detected in the touched position detecting section <highlight><bold>7505</bold></highlight> is stored in the coordinate signal storing section <highlight><bold>8015</bold></highlight>. Then the input signal consisting of the coordinate signal series stored in the coordinate signal storing section <highlight><bold>8015</bold></highlight> and the touched area signal series stored in the touched area signal storing section <highlight><bold>7812</bold></highlight> are compared with the reference signal registered in the reference signal storing section <highlight><bold>7814</bold></highlight><highlight><italic>a</italic></highlight>. However, as shown in the block diagram (the fourth example of the configuration) in <cross-reference target="DRAWINGS">FIG. 90, a</cross-reference> normalizing section <highlight><bold>8216</bold></highlight> and a normalized signal storing section <highlight><bold>8217</bold></highlight> may be provided instead of the coordinate signal storing section <highlight><bold>8015</bold></highlight>, and a coordinate signal series for handwriting of user&apos;s signature detected in the touched position detecting section <highlight><bold>7505</bold></highlight> may be normalized in the normalizing section <highlight><bold>8216</bold></highlight> and stored in the normalized signal storing section <highlight><bold>8217</bold></highlight>. </paragraph>
<paragraph id="P-0502" lvl="0"><number>&lsqb;0502&rsqb;</number> In this case, the input signal consisting of the normalized signal series of the coordinate signal stored in the normalized signal storing section <highlight><bold>8217</bold></highlight> and the touched area signal series stored in the touched area signal storing section <highlight><bold>7812</bold></highlight> is compared with the reference signal consisting of a normalized series of coordinate signals showing handwritings of signatures of the users authorized to access the computer system and the touched area series each previously stored in the reference signal storing section <highlight><bold>7814</bold></highlight><highlight><italic>a</italic></highlight>. As described above, by normalizing a coordinate signal of a handwriting of a user&apos;s signature detected in the touched position detecting section <highlight><bold>7505</bold></highlight>, the user can make a signature of an arbitrary size, which allows convenience to be enhanced. </paragraph>
<paragraph id="P-0503" lvl="0"><number>&lsqb;0503&rsqb;</number> As for each configuration for realizing the security function, as shown in the block diagram (the fifth example of the configuration) in <cross-reference target="DRAWINGS">FIG. 91</cross-reference>, an input start instructing section <highlight><bold>8318</bold></highlight> for inputting an input start instruction to the signal control section <highlight><bold>7503</bold></highlight> and a comparison start instructing section <highlight><bold>8319</bold></highlight> for inputting a comparison start instruction thereto may be provided therein. As a result, when a PID number or a signature is to be inputted, a PID number or the like is inputted according to an input start instruction from the input start instructing section <highlight><bold>8318</bold></highlight>, and when the PID number or the like is to be verified, an operation of comparison can be started according to the comparison start instruction inputted from the comparison start instructing section <highlight><bold>8319</bold></highlight>, so that a PID number or the like can be more accurately verified. A physical switch or a switch like a software keyboard displayed on the image display unit <highlight><bold>7502</bold></highlight> can be used as the input start instructing section <highlight><bold>8318</bold></highlight> and the comparison start instructing section <highlight><bold>8319</bold></highlight>. </paragraph>
<paragraph id="P-0504" lvl="0"><number>&lsqb;0504&rsqb;</number> When a PID number and a password are to be inputted, a touch number counter may be used as the input start instructing section <highlight><bold>8318</bold></highlight> and the comparison start instructing section <highlight><bold>8319</bold></highlight>. As described above, when the touch number counter is used, the touch number counter is reset to &ldquo;0&rdquo; when the displayed software keyboard is first touched, an input start instruction is sent to the signal control section <highlight><bold>7503</bold></highlight>. Then, a number of touches is counted with the touch number counter each time when the user touches the software keyboard, and when the counted value reaches a certain number of times prespecified according to a PID number and a password, a comparison start instruction is sent to the signal control section <highlight><bold>7503</bold></highlight>. As described above, a number of input times of a PID number and a password can also be confirmed. </paragraph>
<paragraph id="P-0505" lvl="0"><number>&lsqb;0505&rsqb;</number> When handwriting of a user&apos;s signature is to be inputted, a timer for measuring an input time may be used as the input start instructing section <highlight><bold>8318</bold></highlight> and the comparison start instructing section <highlight><bold>8319</bold></highlight>. In this case, when a user touches the coordinate-position input device <highlight><bold>7501</bold></highlight> to start signing, the time measured by the timer is reset to &ldquo;0&rdquo; and the measurement is started, and an input start instruction is sent to the signal control section <highlight><bold>7503</bold></highlight>. When a prespecified period of time is over, a comparison start instruction is sent to the signal control section <highlight><bold>7503</bold></highlight>. As described above, even if a number of characters are not certain like in the case of authentication by a signature, an input operation of a signature and a comparing operation can be performed with stability. </paragraph>
<paragraph id="P-0506" lvl="0"><number>&lsqb;0506&rsqb;</number> A status indicating section <highlight><bold>8320</bold></highlight> confirms an input processing standby status before an input start instruction is sent from this input start instructing section <highlight><bold>8318</bold></highlight> to the signal control section <highlight><bold>7503</bold></highlight>, an input processing start status after the input start instruction is sent to the signal control section <highlight><bold>7503</bold></highlight>, a comparison processing status during comparison operation after a comparison start instruction is sent from the comparison start instructing section <highlight><bold>8319</bold></highlight>, and a comparison operation end status. The confirmed status can be displayed on the image display unit <highlight><bold>7502</bold></highlight>. With this feature, a user can accurately recognize each of the processing statuses, which allows convenience to be enhanced. </paragraph>
<paragraph id="P-0507" lvl="0"><number>&lsqb;0507&rsqb;</number> As described above, with the display board system according to Embodiment 6, a software keyboard is generated according to a touched area obtained by a user touching with a fingertip or the like on a touch surface formed with the image display unit and coordinate-position input device, and the software keyboard is displayed on a position of the image display unit corresponding to the touched position, so that the software keyboard can easily be displayed. </paragraph>
<paragraph id="P-0508" lvl="0"><number>&lsqb;0508&rsqb;</number> Furthermore, by displaying a software keyboard in a size according to a size of a touched area obtained by a user touching the touch surface with a fingertip or the like, an arbitrary-sized software keyboard can be displayed, which allows convenience to be enhanced. </paragraph>
<paragraph id="P-0509" lvl="0"><number>&lsqb;0509&rsqb;</number> In addition, by comparing a code signal series as well as a touched area signal series of coordinates of a touched position when a user touches an input surface with a fingertip or the like with a reference signal, determination can be made as to whether the user is an authorized person or not according to the PID number and password inputted through the software keyboard. Therefore, a high-reliability authentication for accessing the system can be verified without any particular operation by the user required for authentication. </paragraph>
<paragraph id="P-0510" lvl="0"><number>&lsqb;0510&rsqb;</number> Furthermore, by comparing a coordinate signal series as well as a touched area series when a user touches a touch surface with a fingertip or the like with a reference signal, authentication for accessing the system can be verified according to handwriting of a user&apos;s signature, and high-reliability authentication can be performed. </paragraph>
<paragraph id="P-0511" lvl="0"><number>&lsqb;0511&rsqb;</number> In addition, by normalizing a coordinate signal series when a user touches a touch surface with a fingertip or the like, an arbitrary-sized signature can be used, which allows convenience to be enhanced. </paragraph>
<paragraph id="P-0512" lvl="0"><number>&lsqb;0512&rsqb;</number> Furthermore, by outputting instruction for inputting data is started through a touch surface or instruction for starting the comparison processing, a PID number or the like can more accurately be recognized. This input start instruction and comparison start instruction are executed with a touch number counting unit for counting a number of times the touch surface is touched or an input time measuring unit for measuring an input time, so that instructions can simply yet accurately be performed. </paragraph>
<paragraph id="P-0513" lvl="0"><number>&lsqb;0513&rsqb;</number> Furthermore, by displaying a status of inputting data into the touch surface or a status of comparison processing on an image display unit, a user can accurately recognize processing statuses, which allows convenience to be enhanced. </paragraph>
<paragraph id="P-0514" lvl="0"><number>&lsqb;0514&rsqb;</number> Each processing in Embodiments 1 to 6 described above can be realized by executing a previously prepared program by a computer. This rogram is recorded in a computer-readable recording medium such as a hard disk, a floppy disk, a CD-ROM, MO, and a DVD, and is executed by reading out from the recording medium by the computer. Furthermore, this program may also be provided through the recording medium as described above or alternately through a network or broadcasting. </paragraph>
<paragraph id="P-0515" lvl="0"><number>&lsqb;0515&rsqb;</number> As described above, with the present invention, an image of a pointing body inserted into an entry area is picked up by at least two image pickup elements, positions where images of the pointing body are formed on the image pickup elements is obtained according to each output from the image pickup elements respectively, and coordinates of a position of the pointing body are identified by using the computed imaging positions. Therefore, coordinates of a position of an entry area pointed using an arbitrary pointing body such as a fingertip or an ordinary pen can be identified without using a particular pointing body, which allows operability of the coordinate-position inputting/detecting device to be enhanced. </paragraph>
<paragraph id="P-0516" lvl="0"><number>&lsqb;0516&rsqb;</number> With the present invention, light is emitted from the light emitting unit into the entry area, an image of the pointing body illuminated by the light emitted from the light emitting unit is picked up by at least two image pickup elements, positions where images of the pointing body are formed on the image pickup elements are computed according to each output from the image pickup elements, and coordinates of the position of the pointing body are identified by using the computed imaging positions. Therefore, coordinates of a position of an entry area pointed using an arbitrary pointing body such as a fingertip or an ordinary pen can be identified without using a particular pointing body, which allows operability of the coordinate-position inputting/detecting device to be enhanced. </paragraph>
<paragraph id="P-0517" lvl="0"><number>&lsqb;0517&rsqb;</number> With the present invention, the light emitting unit and image pickup devices are so placed that the direction of the light emitted from the light emitting unit is substantially the same as the direction from which the pointing body is viewed from each of the image pickup elements. Therefore, the light emitted from the light emitting unit does not directly enter the image pickup elements, and also shadow is not generated on the pointing body as much as possible, which allows an image of a pointing body to accurately be picked up. </paragraph>
<paragraph id="P-0518" lvl="0"><number>&lsqb;0518&rsqb;</number> With the present invention, there is provided an incident light preventing unit for preventing the light emitted from the light emitting unit from directly entering into each of the image pickup elements. Therefore the light emitted from the light emitting unit does not directly enter into the image pickup elements, which allows malfunction of image pickup element to be prevented. </paragraph>
<paragraph id="P-0519" lvl="0"><number>&lsqb;0519&rsqb;</number> With the present invention, the light emitting unit comprises at least a light source and a mirror. Therefore, the light emitted by the light source can be reflected by the mirror and diffused along the entry area, so that, a light that covers the entire entry area can be emitted from the light emitting unit. </paragraph>
<paragraph id="P-0520" lvl="0"><number>&lsqb;0520&rsqb;</number> With the present invention, the angle of the light emitted by the light source can be changed by operating the mirror. Therefore, when the coordinate-position inputting/detecting device is provided, for instance, on the front surface of a display, adjustment is possible so that light emitted from light emitting unit is parallel to a display surface. </paragraph>
<paragraph id="P-0521" lvl="0"><number>&lsqb;0521&rsqb;</number> With the present invention, light reflected by a mirror is received by a light receiving element, and the angle of the mirror is changed according to intensity of the light received by the light-receiving element. Therefore, when the coordinate-position inputting/detecting device is provided, for instance, on the front surface of a display, the work for adjusting the light emitted from light emitting unit so as to be parallel to a display surface can be simplified. </paragraph>
<paragraph id="P-0522" lvl="0"><number>&lsqb;0522&rsqb;</number> With the present invention, reflection preventing means prevents light emitted from light emitting means from its being reflected, so that it is possible to prevent scattered light from its entering image pickup elements, which allows malfunction of an image pickup element to be prevented. </paragraph>
<paragraph id="P-0523" lvl="0"><number>&lsqb;0523&rsqb;</number> With the present invention, when coordinates of the same position are obtained continuously then it is determined that the coordinates are obtained due to dust or something, therefore the coordinates of this position are not stored in the storing unit and also are not outputted to an external device. Therefore, it is possible to prevent coordinates of the position obtained due to dust or something from its being outputted to an external device. </paragraph>
<paragraph id="P-0524" lvl="0"><number>&lsqb;0524&rsqb;</number> With the present invention, optical distortion of an image of a pointing body picked up by each of image pickup elements is electrically corrected, so that higher quality of an image of a pointing body can be obtained. </paragraph>
<paragraph id="P-0525" lvl="0"><number>&lsqb;0525&rsqb;</number> With the present invention, when a plurality of pointing bodies each with a different pattern provided thereto are inserted into the entry area, patterns can be recognized according to each output from the image pickup elements, which allows an entry operation concurrently using a plurality of pointing bodies to be carried out. </paragraph>
<paragraph id="P-0526" lvl="0"><number>&lsqb;0526&rsqb;</number> With the present invention, width of the pointing body is determined according to images of the pointing body picked up by image pickup elements, thus the width of the pointing body can easily be computed. </paragraph>
<paragraph id="P-0527" lvl="0"><number>&lsqb;0527&rsqb;</number> With the present invention, the coordinates of a position of a pointing body identified by coordinate-value identifying unit is corrected by using the width of the pointing body identified by width identifying unit, which allows coordinates of an accurate position to be computed. </paragraph>
<paragraph id="P-0528" lvl="0"><number>&lsqb;0528&rsqb;</number> With the present invention, image of an entry area previously picked up by each of image pickup elements is stored as a reference image, images of the entry area picked up afterward by each of the image pickup elements are extracted. Then, a difference between the corresponding reference images and images of the pointing body inserted into the entry area obtained by the corresponding image pickup elements is extracted. From this difference, a position in the image of each of the image pickup elements where an image of the pointing body is formed is computed and coordinates of the position of the pointing body are obtained using the computed positions of the pointing body. Therefore, coordinates of a position of an entry area pointed using an arbitrary pointing body such as a fingertip or an ordinary pen can be identified without using a particular pointing body, which allows operability of the coordinate-position inputting/detecting device to be enhanced. </paragraph>
<paragraph id="P-0529" lvl="0"><number>&lsqb;0529&rsqb;</number> With the present invention, image of the entry area is picked up by two-dimensional image pickup elements, which allows coordinates of a three-dimensional position of a pointing body to be computed. </paragraph>
<paragraph id="P-0530" lvl="0"><number>&lsqb;0530&rsqb;</number> With the present invention, a reference image consists of an image only of a background plate, so that an image of only a pointing body can easily be extracted from an image with the background plate and the pointing body included therein. </paragraph>
<paragraph id="P-0531" lvl="0"><number>&lsqb;0531&rsqb;</number> With the present invention, a reference pattern can be removed from an image with a background plate and the pointing body included therein according to the reference image. Therefore, an image of only a pointing body can easily be extracted. </paragraph>
<paragraph id="P-0532" lvl="0"><number>&lsqb;0532&rsqb;</number> With the present invention, an area photographable by the image pickup element is restricted by an area restricting unit so that the area is adjusted to the entry area. Therefore, an image pickup element may not be affected by noise such as interference light. </paragraph>
<paragraph id="P-0533" lvl="0"><number>&lsqb;0533&rsqb;</number> With the present invention, when coordinates of the same position are obtained continuously then it is determined that the coordinates are obtained due to dust or something. In such a case the coordinates of this position are not stored in the memory and also are not outputted to an external device. As a result, it is possible to prevent coordinates of the position obtained due to dust or something from its being outputted to an external device With the present invention, by deciding each image of an entry area used to compute coordinates of a position abandoned by updating means as each new reference image, dust existing on the entry area is taken in as a portion of a reference image. Therefore, it is prevented that coordinates of a position of dust are disadvantageously computed. </paragraph>
<paragraph id="P-0534" lvl="0"><number>&lsqb;0534&rsqb;</number> With the present invention, the coordinate-position inputting/detecting device is provided in the front surface of a display unit for displaying characters and images, and a display surface and a writing surface of a display board are formed with the display unit and coordinate-position inputting/detecting device. Therefore, viewability of the display unit and operability as well as reliability of the system can be improved. </paragraph>
<paragraph id="P-0535" lvl="0"><number>&lsqb;0535&rsqb;</number> With the present invention, the coordinate-position inputting/detecting device is provided in the front surface of a display unit for displaying thereon characters and images, and a display surface and a writing surface of the display board are formed with the display unit and coordinate-position inputting/detecting device, therefore, viewability of the display unit and operability as well as reliability of the system can be improved. Furthermore, the display board system comprises a frame unit having a holding section for holding a display surface and a writing surface of the display board at a specified height. A printer accommodating section accommodates the printer therein, and a control unit accommodating section accommodates the control unit therein. The control unit accommodating section, the printer accommodating section, and the holding section are arranged in the vertical direction in this order from the bottom, and as a result of that, transport and installation of the system can easily be carried out, which allows adaptability for handling of the system to be improved. Namely, downsizing and integration of the system as a whole can be achieved, and also adaptability for handling, operability and reliability can be improved. </paragraph>
<paragraph id="P-0536" lvl="0"><number>&lsqb;0536&rsqb;</number> With the present invention, because a plasma display is used as a display unit, in addition to the above mentioned effects that viewability of a display unit and operability as well as reliability of the system can be improved, optimizations of the system can be performed by making use of characteristics of the plasma display that makes a thickness of a display unit thinner, has high brightness as well as a wide viewing angle, and can smoothly reproduce moving pictures. </paragraph>
<paragraph id="P-0537" lvl="0"><number>&lsqb;0537&rsqb;</number> With the present invention, a keyboard placement section for placing a keyboard connected to a personal computer is provided at a position in the upper side of the printer accommodating section and in the lower side of the holding section of a frame unit. Therefore, adaptability for handling of the system can be improved. </paragraph>
<paragraph id="P-0538" lvl="0"><number>&lsqb;0538&rsqb;</number> With the present invention, an angle adjusting unit for adjusting an angle of a display surface and a writing surface of the display board is provided in a holding section. Thus, incoming disturbance light to a display unit (display surface), especially, light from lighting equipment such as a fluorescent tube on a ceiling can be prevented. This allows viewability of the display unit, operability for entry, and adaptability for handling of the system to be improved. </paragraph>
<paragraph id="P-0539" lvl="0"><number>&lsqb;0539&rsqb;</number> With the present invention, a plurality of connecting terminals for connecting various types of information equipment and AV equipment such as a digital camera, a DVD player, and video equipment are provided in a display unit and is usable as a large-sized screen monitor, therefore, it is possible to provide a display board system enabling connection and operation of various types of information equipment and AV equipment without a computer. In addition, it is possible to make use of a display board system at any occasion, which allows general versatility of the display board system to be improved. </paragraph>
<paragraph id="P-0540" lvl="0"><number>&lsqb;0540&rsqb;</number> Although the invention has been described with respect to a specific embodiment for a complete and clear disclosure, the appended claims are not to be thus limited but are to be construed as embodying all modifications and alternative constructions that may occur to one skilled in the art which fairly fall within the basic teaching herein set forth. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A coordinate-position inputting/detecting device comprising: 
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of an entry area into which an arbitrary pointing body is inserted to perform an entry operation for picking up images of the pointing body inserted into said entry area; and </claim-text>
<claim-text>coordinate-value identifying means for computing positions where images of said pointing body are formed on said image pickup elements according to each output from said image pickup elements, and identifying the coordinates of a position of said pointing body by using the computed positions of the image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising: 
<claim-text>storing means for storing therein coordinates of a position of said pointing body identified by said coordinate-value identifying means; </claim-text>
<claim-text>determining means for determining whether the coordinates of the position stored in said storing means are coincident with coordinates of a position newly identified by said coordinate-value identifying means or not; and </claim-text>
<claim-text>updating means for updating the coordinates of the position stored in said storing means using said coordinates of the newly identified position and outputting the updated ones when it is determined by said determining means that both coordinates are not coincident, while abandoning the coordinates of the newly identified position when it is determined by said determining means that both coordinates are coincident and if the same position coordinates are obtained continuously over a prespecified period of time. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising distortion correcting means for electrically correcting the optical distortion of an image of said pointing body picked up by each of said image pickup elements. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> further comprising pattern recognizing means for recognizing the patterns according to each output from said image pickup elements when a plurality of pointing bodies each having a different pattern provided thereon are inserted into said entry area. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A coordinate-position inputting/detecting device comprising: 
<claim-text>light emitting means for emitting light into an entry area into which an arbitrary pointing body is inserted to perform an entry operation; </claim-text>
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of said entry area for picking up images of said pointing body illuminated by the light emitted from said light emitting means; and </claim-text>
<claim-text>coordinate-value identifying means for computing positions where images of said pointing body are formed on said image pickup elements according to each output from said image pickup elements, and identifying the coordinates of a position of said pointing body by using the computed positions of the image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A coordinate-position inputting/detecting device according to claim <highlight><bold>5</bold></highlight>; wherein said light emitting means and said image pickup elements are provided on the peripheral section of said entry area so that the direction of the light emitted from said light emitting means is substantially the same direction as to which said pointing body is viewed from each of said image pickup elements. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A coordinate-position inputting/detecting device according to claim <highlight><bold>5</bold></highlight>; wherein said light emitting means has incident light preventing means for preventing the emitted light from its directly entering into each of said image pickup elements. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A coordinate-position inputting/detecting device according to claim <highlight><bold>5</bold></highlight>; wherein said light emitting means has at least a light source for emitting light; and a mirror for reflecting the light from the light source thereon and diffusing the light along said entry area. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference> further comprising adjusting means for changing an angle of said mirror to adjust a direction of reflecting the light. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A coordinate-position inputting/detecting device according to claim <highlight><bold>9</bold></highlight>; wherein said adjusting means comprises: 
<claim-text>a light receiving element for receiving the light reflected by said mirror; </claim-text>
<claim-text>driving means for changing the angle of said mirror; and </claim-text>
<claim-text>control means for controlling said driving means in order to change the angle of said mirror according to intensity of the light received by said light receiving element. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A coordinate-position inputting/detecting d vice according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> further comprising reflection preventing means for preventing light emitted fro said light emitting means from its being reflected. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> further comprising: 
<claim-text>storing means for storing therein coordinates of a position of said pointing body identified by said coordinate-value identifying means; </claim-text>
<claim-text>determining means for determining whether the coordinates of the position stored in said storing means are coincident with coordinates of a position newly identified by said coordinate-value identifying means or not; and </claim-text>
<claim-text>updating means for updating the coordinates of the position stored in said storing means using said coordinates of the newly identified position and outputting the updated ones when it is determined by said determining means that both coordinates are not coincident, while abandoning the coordinates of the newly identified position when it is determined by said determining means that both coordinates are coincident and if the same position coordinates are obtained continuously over a prespecified period of time. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> further comprising distortion correcting means for electrically correcting the optical distortion of an image of said pointing body picked up by each of said image pickup elements. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> further comprising pattern recognizing means for recognizing the patterns according to each output from said image pickup elements when a plurality of pointing bodies each having a different pattern provided thereon are inserted into said entry area. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference> further comprising a width identifying means for identifying a width of said pointing body according to the images of said pointing body picked up by said image pickup elements. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference> further comprising correcting means for correcting the coordinates of the position of the pointing body identified by said coordinate-value identifying means using the width of said pointing body identified by said width identifying means. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A coordinate-position inputting/detecting device comprising: 
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of an entry area into which an arbitrary pointing body is inserted to perform an entry operation for picking up images of the pointing body; </claim-text>
<claim-text>first storing means for storing therein an image of said entry area previously picked up by each of said image pickup elements as a reference image respectively; </claim-text>
<claim-text>extracting means for extracting each image of the pointing body inserted into said entry area by extracting each image of said entry area picked up by said image pickup elements and each difference of corresponding said reference image respectively; and </claim-text>
<claim-text>coordinate-value identifying means for computing positions where images of said pointing body are formed on said image pickup elements according to each image of the pointing body extracted in said extracting means, and identifying the coordinates of a position of said pointing body by using the computed positions of the image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A coordinate-position inputting/detecting device according to claim <highlight><bold>17</bold></highlight>; wherein said image pickup element is a two-dimensional image pickup element. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> further comprising a background plate provided at a location which is a peripheral section of said entry area and where the whole field of view of said image pickup elements is covered. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A coordinate-position inputting/detecting device according to claim <highlight><bold>19</bold></highlight>; wherein said background plate has an arbitrary pattern provided thereto. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> further comprising area restricting means for restricting an area photographable by said image pickup element so that the area is adjusted to said entry area. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference> further comprising: 
<claim-text>second storing means for storing therein coordinates of a position of said pointing body identified by said coordinate-value identifying means; </claim-text>
<claim-text>determining means for determining whether the coordinates of the position stored in said second storing means are coincident with coordinates of a position newly identified by said coordinate-value identifying means or not; and </claim-text>
<claim-text>updating means for updating the coordinates of the position stored in said second storing means using said coordinates of the newly identified position and outputting the updated ones to an external device when it is determined by said determining means that both coordinates are not coincident, while abandoning the coordinates of the newly identified position when it is determined by said determining means that both coordinates are coincident and if the same position coordinates are continuously identified over a prespecified period of time. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A coordinate-position inputting/detecting device according to <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference> further comprising image updating means for storing each image of said entry area used for computing the coordinates of the position abandoned by said updating means in said first storing means as a new reference image respectively. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A coordinate-position inputting/detecting device comprising: 
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of an entry area into which an arbitrary pointing body is inserted to perform an entry operation for picking up images of the pointing body inserted into said entry area; and </claim-text>
<claim-text>coordinate-value identifying unit for computing the positions where images of said pointing body are formed on said image pickup elements according to each output from said image pickup elements, and identifying the coordinates of a position of said pointing body by using the computed positions of the image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A coordinate-position inputting/detecting device comprising: 
<claim-text>light emitting element for emitting light into an entry area into which an arbitrary pointing body is inserted to perform an entry operation; </claim-text>
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of said entry area for picking up images of said pointing body illuminated by the light emitted from said light emitting means; and </claim-text>
<claim-text>coordinate-value identifying unit for computing positions where images of said pointing body are formed on said image pickup elements according to each output from said image pickup elements, and identifying the coordinates of a position of said pointing body by using the computed positions of the image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. A coordinate-position inputting/detecting device comprising: 
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of an entry area into which an arbitrary pointing body is inserted to perform an entry operation for picking up images of the pointing body; </claim-text>
<claim-text>first memory for storing therein an image of said entry area previously picked up by each of said image pickup elements as a reference image respectively; </claim-text>
<claim-text>extracting unit for extracting each image of the pointing body inserted into said entry area by extracting each image of said entry area picked up by said image pickup elements and each difference of corresponding said reference image respectively; and </claim-text>
<claim-text>coordinate-value identifying unit for computing positions where images of said pointing body are formed on said image pickup elements according to each image of the pointing body extracted in said extracting unit, and identifying the coordinates of a position of said pointing body by using the computed positions. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. A coordinate-position inputting/detecting method comprising the steps of: 
<claim-text>obtaining an image of an arbitrary pointing body inserted into an entry area with at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of the entry area; </claim-text>
<claim-text>computing the positions where images of said pointing body are formed on said image pickup elements according to each output from said image pickup elements; and </claim-text>
<claim-text>computing the coordinates of a position of said pointing body in the entry area from the computed positions on said image pickup elements. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. A coordinate-position inputting/detecting method comprising the steps of: 
<claim-text>emitting a light into an entry area into which an arbitrary pointing body is inserted in order to perform an entry operation; </claim-text>
<claim-text>obtaining an image of an arbitrary pointing body inserted into an entry area with at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of the entry area; </claim-text>
<claim-text>computing the positions where images of said pointing body are formed on said image pickup elements according to each output from said image pickup elements; and </claim-text>
<claim-text>computing the coordinates of a position of said pointing body in the entry area from the computed positions on said image pickup elements. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. A coordinate-position inputting/detecting method comprising the steps of: 
<claim-text>obtaining an image of an arbitrary pointing body inserted into an entry area with at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of the entry area; </claim-text>
<claim-text>storing therein an image of said entry area previously picked up by each of the image pickup elements as a reference image respectively; </claim-text>
<claim-text>extracting each image of the pointing body inserted into said entry area by extracting each image of said entry area picked up by the image pickup elements; </claim-text>
<claim-text>obtaining a difference between the image picked by each of the image pickup elements and a corresponding reference image respectively; </claim-text>
<claim-text>computing the positions where images of said pointing body are formed on said image pickup elements according to each output from said image pickup elements; and </claim-text>
<claim-text>computing the coordinates of a position of said pointing body in the entry area from the computed positions on said image pickup elements. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. A display board system comprising at least: 
<claim-text>display means for displaying thereon characters and images; </claim-text>
<claim-text>a coordinate-position inputting/detecting device with an entry area provided in the front surface of said display means; </claim-text>
<claim-text>control means for providing controls over display by said display means according to input from said coordinate-position inputting/detecting device; and </claim-text>
<claim-text>said display board system capable of forming a display surface and a writing surface of a display board using said display means and said coordinate-position inputting/detecting device; wherein 
<claim-text>said coordinate-position inputting/detecting device having, </claim-text>
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of an entry area into which an arbitrary pointing body is inserted to perform an entry operation for picking up images of the pointing body inserted into said entry area; and </claim-text>
<claim-text>coordinate-value identifying means for computing positions where images of said pointing body are formed on the image pickup elements according to each output from the image pickup elements, and identifying the coordinates of a position of said pointing body by using the computed positions of the image. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. A display board system according to claim <highlight><bold>30</bold></highlight>; wherein said display means is a plasma display. </claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. A display board system according to claim <highlight><bold>30</bold></highlight>; wherein said display means further has a plurality of connecting means for connecting various types of information equipment and AV equipment such as a digital camera, a DVD player, and video equipment, and is usable as a large-sized screen monitor using said connecting means. </claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. A display board system comprising at least: 
<claim-text>display means for displaying thereon characters and images; </claim-text>
<claim-text>a coordinate-position inputting/detecting device with an entry area provided in the front surface of said display means; </claim-text>
<claim-text>control means for providing controls over display by said display means according to input from said coordinate-position inputting/detecting device; and </claim-text>
<claim-text>said display board system capable of forming a display surface and a writing surface of a display board using said display means and said coordinate-position inputting/detecting device; wherein 
<claim-text>said coordinate-position inputting/detecting device having, </claim-text>
<claim-text>light emitting means for emitting light into an entry area into which an arbitrary pointing body is inserted to perform an entry operation; </claim-text>
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of said entry area for picking up images of said pointing body illuminated by the light emitted from said light emitting means; and </claim-text>
<claim-text>coordinate-value identifying means for computing positions where images of said pointing body are formed on the image pickup elements according to each output from the image pickup elements, and identifying the coordinates of a position of said pointing body by using the computed positions of the image. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. A display board system according to claim <highlight><bold>33</bold></highlight>; wherein said display means is a plasma display. </claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. A display board system according to claim <highlight><bold>33</bold></highlight>; wherein said display means further has a plurality of connecting means for connecting various types of information equipment and AV equipment such as a digital camera, a DVD player, and video equipment, and is usable as a large-sized screen monitor using said connecting means. </claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. A display board system comprising at least: 
<claim-text>display means for displaying thereon characters and images; </claim-text>
<claim-text>a coordinate-position inputting/detecting device with an entry area provided in the front surface of said display means; </claim-text>
<claim-text>control means for providing controls over display by said display means according to input from said coordinate-position inputting/detecting device; and </claim-text>
<claim-text>said display board system capable of forming a display surface and a writing surface of a display board using said display means and said coordinate-position inputting/detecting device; wherein 
<claim-text>said coordinate-position inputting/detecting device having, </claim-text>
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of an entry area into which an arbitrary pointing body is inserted to perform an entry operation for picking up images of the pointing body; </claim-text>
<claim-text>first storing means for storing therein an image of said entry area previously picked up by each of the image pickup elements as a reference image respectively; </claim-text>
<claim-text>extracting means for extracting each image of the pointing body inserted into said entry area by extracting each image of said entry area picked up by the image pickup elements and each difference of corresponding said reference image respectively; and </claim-text>
<claim-text>coordinate-value identifying means for computing positions where images of said pointing body are formed on the image pickup elements according to each image of the pointing body extracted in said extracting means, and identifying the coordinates of a position of said pointing body by using the computed positions of the image. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. A display board system according to claim <highlight><bold>36</bold></highlight>; wherein said display means is a plasma display. </claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. A display board system according to claim <highlight><bold>36</bold></highlight>; wherein said display means further has a plurality of connecting means for connecting various types of information equipment and AV equipment such as a digital camera, a DVD player, and video equipment, and is usable as a large-sized screen monitor using said connecting means. </claim-text>
</claim>
<claim id="CLM-00039">
<claim-text><highlight><bold>39</bold></highlight>. A display board system comprising at least: 
<claim-text>display means for displaying thereon characters and images; </claim-text>
<claim-text>a coordinate-position inputting/detecting device with an entry area provided in the front surface of said display means; </claim-text>
<claim-text>printing means for outputting image data onto a recording paper; and </claim-text>
<claim-text>control means for providing controls over the display by said display means as well as over printing operations by said printing means according to input from said coordinate-position inputting/detecting device, </claim-text>
<claim-text>said display board system capable of forming a display surface and a writing surface of the display board using said display means and said coordinate-position inputting/detecting device; wherein 
<claim-text>said coordinate-position inputting/detecting device having, at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of an entry area into which an arbitrary pointing body is inserted to perform an entry operation for picking up images of the pointing body inserted into said entry area; and </claim-text>
<claim-text>coordinate-value identifying means for computing positions where images of said pointing body are formed on the image pickup elements according to each output from the image pickup elements, and identifying the coordinates of a position of said pointing body by using the computed positions of the image; </claim-text>
<claim-text>said control means is a personal computer; and </claim-text>
<claim-text>said display board system further comprising a frame unit having holding means for holding a display surface and a writing surface of the display board at a specified height, a printer accommodating means for accommodating said printing means therein, and control accommodating means for accommodating said control means therein, in which said control accommodating means; wherein said printer accommodating means and said holding means are arranged in the vertical direction in this order from the bottom. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00040">
<claim-text><highlight><bold>40</bold></highlight>. A display board system according to claim <highlight><bold>39</bold></highlight>; wherein said display means is a plasma display. </claim-text>
</claim>
<claim id="CLM-00041">
<claim-text><highlight><bold>41</bold></highlight>. A display board system according to claim <highlight><bold>39</bold></highlight>; wherein said frame unit has a keyboard placement means provided at a position on the upper side of said printer accommodating means but on the lower side of said holding means for placing a keyboard connected to said personal computer. </claim-text>
</claim>
<claim id="CLM-00042">
<claim-text><highlight><bold>42</bold></highlight>. A display board system according to claim <highlight><bold>39</bold></highlight>; wherein said holding means comprises an angle adjusting means for adjusting an angle of a display surface and a writing surface of the display board. </claim-text>
</claim>
<claim id="CLM-00043">
<claim-text><highlight><bold>43</bold></highlight>. A display board system according to claim <highlight><bold>39</bold></highlight>; wherein said display means further has a plurality of connecting means for connecting various types of information equipment and AV equipment such as a digital camera, a DVD player, and video equipment, and is usable as a large-sized screen monitor using said connecting means. </claim-text>
</claim>
<claim id="CLM-00044">
<claim-text><highlight><bold>44</bold></highlight>. A display board system comprising at least: 
<claim-text>display means for displaying thereon characters and images; </claim-text>
<claim-text>a coordinate-position inputting/detecting device with an entry area provided in the front surface of said display means; </claim-text>
<claim-text>printing means for outputting image data onto a recording paper; and </claim-text>
<claim-text>control means for providing controls over the display by said display means as well as over printing operations by said printing means according to input from said coordinate-position inputting/detecting device, </claim-text>
<claim-text>said display board system capable of forming a display surface nd a writing surface of the display board using said display means and said coordinate-position inputting/detecting device; wherein 
<claim-text>said coordinate-position inputting/detecting device having, </claim-text>
<claim-text>light emitting means for emitting light into an entry area into which an arbitrary pointing body is inserted to perform an entry operation; </claim-text>
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of said entry area for picking up images of said pointing body illuminated by the light emitted from said light emitting means; and </claim-text>
<claim-text>coordinate-value identifying means for computing positions where images of said pointing body are formed on the image pickup elements according to each output from the image pickup elements, and identifying the coordinates of a position of said pointing body by using the computed positions of the image; </claim-text>
</claim-text>
<claim-text>said control means is a personal computer; and </claim-text>
<claim-text>said display board system further comprising a frame unit having holding means for holding a display surface and a writing surface of the display board at a specified height, a printer accommodating means for accommodating said printing means therein, and control accommodating means for accommodating said control means therein, in which said control accommodating means; wherein said printer accommodating means and said holding means are arranged in the vertical direction in this order from the bottom. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00045">
<claim-text><highlight><bold>45</bold></highlight>. A display board system according to claim <highlight><bold>44</bold></highlight>; wherein said display means is a plasma display. </claim-text>
</claim>
<claim id="CLM-00046">
<claim-text><highlight><bold>46</bold></highlight>. A display board system according to claim <highlight><bold>44</bold></highlight>; wherein said frame unit has a keyboard placement means provided at a position on the upper side of said printer accommodating means but on the lower side of said holding means for placing a keyboard connected to said personal computer. </claim-text>
</claim>
<claim id="CLM-00047">
<claim-text><highlight><bold>47</bold></highlight>. A display board system according to claim <highlight><bold>44</bold></highlight>; wherein said holding means comprises an angle adjusting means for adjusting an angle of a display surf ace and a writing surf ace of the display board. </claim-text>
</claim>
<claim id="CLM-00048">
<claim-text><highlight><bold>48</bold></highlight>. A display board system according to claim <highlight><bold>44</bold></highlight>; wherein said display means further has a plurality of connecting means for connecting various types of information equipment and AV equipment such as a digital camera, a DVD player, and video equipment, and is usable as a large-sized screen monitor using said connecting means. </claim-text>
</claim>
<claim id="CLM-00049">
<claim-text><highlight><bold>49</bold></highlight>. A display board system comprising at least: 
<claim-text>display means for displaying thereon characters and images; </claim-text>
<claim-text>a coordinate-position inputting/detecting device with an entry area provided in the front surface of said display means; </claim-text>
<claim-text>printing means for outputting image data onto a recording paper; and </claim-text>
<claim-text>control means for providing controls over the display by said display means as well as over printing operations by said printing means according to input from said coordinate-position inputting/detecting device, </claim-text>
<claim-text>said display board system capable of forming a display surface and a writing surface of the display board using said display means and said coordinate-position inputting/detecting device; wherein 
<claim-text>said coordinate-position inputting/detecting device having, </claim-text>
<claim-text>at least two image pickup elements provided with a prespecified space therebetween on a peripheral section of an entry area into which an arbitrary pointing body is inserted to perform an entry operation for picking up images of the pointing body; </claim-text>
<claim-text>first storing means for storing therein an image of said entry area previously picked up by each of the image pickup elements as a reference image respectively; </claim-text>
<claim-text>extracting means for extracting each image of the pointing body inserted into said entry area by extracting each image of said entry area picked up by the image pickup elements and each difference of corresponding said reference image respectively; and </claim-text>
<claim-text>coordinate-value identifying means for computing positions where images of said pointing body are formed on the image pickup elements according to each image of the pointing body extracted in said extracting means, and identifying the coordinates of a position of said pointing body by using the computed positions of the image; </claim-text>
</claim-text>
<claim-text>said control means is a personal computer; and </claim-text>
<claim-text>said display board system further comprising a frame unit having holding means for holding a display surface and a writing surface of the display board at a specified height, a printer accommodating means for accommodating said printing means therein, and control accommodating means for accommodating said control means therein, in which said control accommodating means; wherein said printer accommodating means and said holding means are arranged in the vertical direction in this order from the bottom. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00050">
<claim-text><highlight><bold>50</bold></highlight>. A display board system according to claim <highlight><bold>49</bold></highlight>; wherein said display means is a plasma display. </claim-text>
</claim>
<claim id="CLM-00051">
<claim-text><highlight><bold>51</bold></highlight>. A display board system according to claim <highlight><bold>49</bold></highlight>; wherein said frame unit has a keyboard placement means provided at a position on the upper side of said printer accommodating means but on the lower side of said holding means for placing a keyboard connected to said personal computer. </claim-text>
</claim>
<claim id="CLM-00052">
<claim-text><highlight><bold>52</bold></highlight>. A display board system according to claim <highlight><bold>49</bold></highlight>; wherein said holding means comprises an angle adjusting means for adjusting an angle of a display surface and a writing surface of the display board. </claim-text>
</claim>
<claim id="CLM-00053">
<claim-text><highlight><bold>53</bold></highlight>. A display board system according to claim <highlight><bold>49</bold></highlight>; wherein said display means further has a plurality of connecting means for connecting various types of information equipment and AV equipment such as a digital camera, a DVD player, and video equipment, and is usable as a large-sized screen monitor using said connecting means.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001825A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001825A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001825A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001825A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001825A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001825A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001825A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001825A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001825A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001825A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001825A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030001825A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030001825A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030001825A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030001825A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030001825A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030001825A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030001825A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030001825A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00019">
<image id="EMI-D00019" file="US20030001825A1-20030102-D00019.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00020">
<image id="EMI-D00020" file="US20030001825A1-20030102-D00020.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00021">
<image id="EMI-D00021" file="US20030001825A1-20030102-D00021.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00022">
<image id="EMI-D00022" file="US20030001825A1-20030102-D00022.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00023">
<image id="EMI-D00023" file="US20030001825A1-20030102-D00023.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00024">
<image id="EMI-D00024" file="US20030001825A1-20030102-D00024.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00025">
<image id="EMI-D00025" file="US20030001825A1-20030102-D00025.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00026">
<image id="EMI-D00026" file="US20030001825A1-20030102-D00026.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00027">
<image id="EMI-D00027" file="US20030001825A1-20030102-D00027.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00028">
<image id="EMI-D00028" file="US20030001825A1-20030102-D00028.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00029">
<image id="EMI-D00029" file="US20030001825A1-20030102-D00029.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00030">
<image id="EMI-D00030" file="US20030001825A1-20030102-D00030.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00031">
<image id="EMI-D00031" file="US20030001825A1-20030102-D00031.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00032">
<image id="EMI-D00032" file="US20030001825A1-20030102-D00032.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00033">
<image id="EMI-D00033" file="US20030001825A1-20030102-D00033.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00034">
<image id="EMI-D00034" file="US20030001825A1-20030102-D00034.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00035">
<image id="EMI-D00035" file="US20030001825A1-20030102-D00035.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00036">
<image id="EMI-D00036" file="US20030001825A1-20030102-D00036.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00037">
<image id="EMI-D00037" file="US20030001825A1-20030102-D00037.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00038">
<image id="EMI-D00038" file="US20030001825A1-20030102-D00038.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00039">
<image id="EMI-D00039" file="US20030001825A1-20030102-D00039.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00040">
<image id="EMI-D00040" file="US20030001825A1-20030102-D00040.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00041">
<image id="EMI-D00041" file="US20030001825A1-20030102-D00041.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00042">
<image id="EMI-D00042" file="US20030001825A1-20030102-D00042.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00043">
<image id="EMI-D00043" file="US20030001825A1-20030102-D00043.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00044">
<image id="EMI-D00044" file="US20030001825A1-20030102-D00044.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00045">
<image id="EMI-D00045" file="US20030001825A1-20030102-D00045.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00046">
<image id="EMI-D00046" file="US20030001825A1-20030102-D00046.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00047">
<image id="EMI-D00047" file="US20030001825A1-20030102-D00047.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00048">
<image id="EMI-D00048" file="US20030001825A1-20030102-D00048.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00049">
<image id="EMI-D00049" file="US20030001825A1-20030102-D00049.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00050">
<image id="EMI-D00050" file="US20030001825A1-20030102-D00050.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00051">
<image id="EMI-D00051" file="US20030001825A1-20030102-D00051.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00052">
<image id="EMI-D00052" file="US20030001825A1-20030102-D00052.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00053">
<image id="EMI-D00053" file="US20030001825A1-20030102-D00053.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00054">
<image id="EMI-D00054" file="US20030001825A1-20030102-D00054.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00055">
<image id="EMI-D00055" file="US20030001825A1-20030102-D00055.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00056">
<image id="EMI-D00056" file="US20030001825A1-20030102-D00056.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00057">
<image id="EMI-D00057" file="US20030001825A1-20030102-D00057.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00058">
<image id="EMI-D00058" file="US20030001825A1-20030102-D00058.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00059">
<image id="EMI-D00059" file="US20030001825A1-20030102-D00059.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00060">
<image id="EMI-D00060" file="US20030001825A1-20030102-D00060.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00061">
<image id="EMI-D00061" file="US20030001825A1-20030102-D00061.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00062">
<image id="EMI-D00062" file="US20030001825A1-20030102-D00062.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00063">
<image id="EMI-D00063" file="US20030001825A1-20030102-D00063.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00064">
<image id="EMI-D00064" file="US20030001825A1-20030102-D00064.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00065">
<image id="EMI-D00065" file="US20030001825A1-20030102-D00065.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00066">
<image id="EMI-D00066" file="US20030001825A1-20030102-D00066.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00067">
<image id="EMI-D00067" file="US20030001825A1-20030102-D00067.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00068">
<image id="EMI-D00068" file="US20030001825A1-20030102-D00068.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00069">
<image id="EMI-D00069" file="US20030001825A1-20030102-D00069.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00070">
<image id="EMI-D00070" file="US20030001825A1-20030102-D00070.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00071">
<image id="EMI-D00071" file="US20030001825A1-20030102-D00071.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00072">
<image id="EMI-D00072" file="US20030001825A1-20030102-D00072.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
