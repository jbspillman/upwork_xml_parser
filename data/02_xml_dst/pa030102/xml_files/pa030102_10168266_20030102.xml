<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001757A1-20030102-D00000.TIF SYSTEM "US20030001757A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00001.TIF SYSTEM "US20030001757A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00002.TIF SYSTEM "US20030001757A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00003.TIF SYSTEM "US20030001757A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00004.TIF SYSTEM "US20030001757A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00005.TIF SYSTEM "US20030001757A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00006.TIF SYSTEM "US20030001757A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00007.TIF SYSTEM "US20030001757A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00008.TIF SYSTEM "US20030001757A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00009.TIF SYSTEM "US20030001757A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00010.TIF SYSTEM "US20030001757A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00011.TIF SYSTEM "US20030001757A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00012.TIF SYSTEM "US20030001757A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00013.TIF SYSTEM "US20030001757A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00014.TIF SYSTEM "US20030001757A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00015.TIF SYSTEM "US20030001757A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00016.TIF SYSTEM "US20030001757A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00017.TIF SYSTEM "US20030001757A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00018.TIF SYSTEM "US20030001757A1-20030102-D00018.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00019.TIF SYSTEM "US20030001757A1-20030102-D00019.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00020.TIF SYSTEM "US20030001757A1-20030102-D00020.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00021.TIF SYSTEM "US20030001757A1-20030102-D00021.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00022.TIF SYSTEM "US20030001757A1-20030102-D00022.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00023.TIF SYSTEM "US20030001757A1-20030102-D00023.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00024.TIF SYSTEM "US20030001757A1-20030102-D00024.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00025.TIF SYSTEM "US20030001757A1-20030102-D00025.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00026.TIF SYSTEM "US20030001757A1-20030102-D00026.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00027.TIF SYSTEM "US20030001757A1-20030102-D00027.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00028.TIF SYSTEM "US20030001757A1-20030102-D00028.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00029.TIF SYSTEM "US20030001757A1-20030102-D00029.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00030.TIF SYSTEM "US20030001757A1-20030102-D00030.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00031.TIF SYSTEM "US20030001757A1-20030102-D00031.TIF" NDATA TIF>
<!ENTITY US20030001757A1-20030102-D00032.TIF SYSTEM "US20030001757A1-20030102-D00032.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001757</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10168266</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020617</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>P2000 319418</doc-number>
</priority-application-number>
<filing-date>20001019</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H03M007/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>341</class>
<subclass>050000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Data processing device</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Tetsujiro</given-name>
<family-name>Kondo</family-name>
</name>
<residence>
<residence-non-us>
<city>Tokyo</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Kazutaka</given-name>
<family-name>Ando</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Koji</given-name>
<family-name>Ohta</family-name>
</name>
<residence>
<residence-non-us>
<city>Tokyo</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>William S Frommer</name-1>
<name-2>Frommer Lawrence &amp; Haug</name-2>
<address>
<address-1>745 Fifth Avenue</address-1>
<city>New York</city>
<state>NY</state>
<postalcode>10151</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
<international-conventions>
<pct-application>
<document-id>
<doc-number>PCT/JP01/08970</doc-number>
<document-date>20011012</document-date>
<country-code>WO</country-code>
</document-id>
</pct-application>
</international-conventions>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The present invention relates to a data processing apparatus. Additional information is embedded in coded data obtained by encoding image data, without increasing the amount of the coded data, and the data in which the additional information is embedded is correctly decoded into the image data and the additional information. An embedded compression encoder <highlight><bold>11 </bold></highlight>encodes image data according to a predetermined coding rule, and destroys the coding rule based on additional information, thereby embedding the additional information. A decoder <highlight><bold>12 </bold></highlight>restores the embedded coded data, obtained by embedding the additional information in the coded data, into the coded data encoded according to the coding rule, thereby decoding the additional information and also decoding the coded data into the image data. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">TECHNICAL FIELD </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present invention relates to data processing apparatuses. More specifically, it relates to a data processing apparatus that allows information to be embedded in an image without degrading the quality of decoded image or increasing the amount of data. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND ART </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Methods for embedding information in data without increasing the amount of the data exist, for example, changing the lowest bit or low-order two bits of digital audio data into information to be embedded. The method simply replaces lower bits of digital audio data with information to be embedded, taking advantage of the fact that the lower bits do not significantly affect the quality of sound. Thus, when the digital audio data is played back, the digital audio data with the information embedded therein is output as it is without restoring the lower bits. That is, since it is difficult to restore the lower bits, in which information is embedded, into the original digital audio data, and the lower bits do not significantly affect the quality of sound, the digital audio data is output with the information embedded therein. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> According to the method described above, however, data that differs from the original data is output. Thus, considerable effect is exerted upon the sound quality when the data is audio data or upon the picture quality when the data is video data. </paragraph>
</section>
<section>
<heading lvl="1">DISCLOSURE OF INVENTION </heading>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> The present invention has been made in view of the situation described above, and it allows information to be embedded, for example, in an image without degrading the picture quality or increasing the amount of data. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> A first data processing apparatus according to the present invention includes encoding means for encoding first data to output coded data; and embedding means for embedding second data in the coded data output from the encoding means by modifying a portion of the coded data based on the second data. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> A first data processing method according to the present invention is such that first data is encoded to output coded data, and a portion of the coded data is modified based on the second data so that the second data is embedded in the coded data. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> A first storage medium according to the present invention stores such a program that first data is encoded to output coded data, and a portion of the coded data is modified based on the second data so that the second data is embedded in the coded data. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> According to the first data processing apparatus, data processing method, and storage medium of the present invention, first data is encoded to output coded data. Then, a portion of the coded data is modified based on the second data so that the second data is embedded in the coded data. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> A second data processing apparatus according to the present invention includes coding table creation means for creating a coding table for encoding first data; modified coding table creation means for modifying the coding table created by the coding table creation means based on second data to create a modified coding table; and embedded coded data generation means for encoding the first data based on the modified coding table to generate embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> A second data processing method according to the present invention is such that a coding table for encoding first data is created, the coding table created is modified based on second data to create a modified coding table, and the first data is encoded based on the modified coding table to generate embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> A second storage medium according to the present invention stores such a program that a coding table for encoding first data is created, the coding table created is modified based on second data to create a modified coding table, and the first data is encoded based on the modified coding table to generate embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> According to the second data processing apparatus, data processing method, and storage medium of the present invention, a coding table for encoding first data is created, and the coding table created is modified based on second data to create a modified coding table. Then, the first data is encoded based on the modified coding table to generate embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> A third data processing apparatus according to the present invention includes tentative decoding means for tentatively decoding embedded coded data encoded by embedding second data in first data, based on a coding table, to output tentative decoded data; tentative coding table creation means for creating a tentative coding table based on the tentative decoded data; first decoded data obtaining means for decoding the embedded coded data based on the coding table and the tentative coding table to obtain first decoded data; and second decoded data obtaining means for obtaining second decoded data by comparing the coding table with the tentative coding table. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> A third data processing method according to the present invention is such that embedded coded data encoded by embedding second data in first data is tentatively decoded based on a coding table to output tentative decoded data, a tentative coding table is created based on the tentative decoded data, the embedded coded data is decoded based on the coding table and the tentative coding table to obtain first decoded data, and the coding table is compared with the tentative coding table to obtain second decoded data. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> A third storage medium according to the present invention stores such a program that embedded coded data encoded by embedding second data in first data is tentatively decoded based on a coding table to output tentative decoded data, a tentative coding table is created based on the tentative decoded data, the embedded coded data is decoded based on the coding table and the tentative coding table to obtain first decoded data, and the coding table is compared with the tentative coding table to obtain second decoded data. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> According to the third data processing apparatus, data processing method, and storage medium of the present invention, embedded coded data encoded by embedding second data in first data is tentatively decoded based on a coding table to output tentative decoded data. Furthermore, a tentative coding table is created based on the tentative decoded data, and the embedded coded data is decoded based on the coding table and the tentative coding table to obtain first decoded data. The coding table is compared with the tentative coding table to obtain second decoded data. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> A fourth data processing apparatus according to the present invention includes tentative decoding means for modifying a portion of embedded coded data encoded by embedding second data in first data according to an input parameter, and for tentatively decoding it based on a coding table to output tentative decoded data; re-encoding means for re-encoding the tentative decoded data to output re-encoded data; and decoding means for determining the parameter by comparing the embedded coded data and the re-encoded data, outputting tentative decoded data as first decoded data, obtained by tentatively decoding, based on the coding table, the embedded coded data having been partially modified by the tentative decoding means based on the parameter, and for obtaining second decoded data corresponding to the parameter. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> A fourth data processing method according to the present invention is such that a portion of embedded coded data encoded by embedding second data in first data is modified according to an input parameter, and tentatively decoded based on a coding table to output tentative decoded data, the tentative decoded data is re-encoded to output re-encoded data, and the parameter is determined by comparing the embedded coded data and the re-encoded data, and tentative decoded data obtained by tentatively decoding, based on the coding table, the embedded coded data having been partially modified based on the parameter, is output as first decoded data, and for second decoded data corresponding to the parameter is also obtained. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> A fourth storage medium according to the present invention stores such a program that a portion of embedded coded data encoded by embedding second data in first data is modified according to an input parameter, and tentatively decoded based on a coding table to output tentative decoded data, the tentative decoded data is re-encoded to output re-encoded data, and the parameter is determined by comparing the embedded coded data and the re-encoded data, and tentative decoded data obtained by tentatively decoding, based on the coding table, the embedded coded data having been partially modified based on the parameter, is output as first decoded data, and for second decoded data corresponding to the parameter is also obtained. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> According to the fourth data processing apparatus, data processing method, and storage medium of the present invention, a portion of embedded coded data encoded by embedding second data in first data is modified according to an input parameter, and tentatively decoded based on a coding table to output tentative decoded data. Furthermore, the tentative decoded data is re-encoded to output re-encoded data. The parameter is determined by comparing the embedded coded data and the re-encoded data, and tentative decoded data obtained by tentatively decoding, based on the coding table, the embedded coded data having been partially modified based on the parameter, is output as first decoded data, and for second decoded data corresponding to the parameter is also obtained. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> A fifth data processing apparatus according to the present invention includes encoding means for encoding first data according to a coding rule to output coded data; and modification means for modifying the coding rule based on second data; wherein the encoding means encodes the first data according to a coding rule modified by the modification means, thereby generating embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> A fifth data processing method according to the present invention is such that first data is encoded according to a coding rule to output coded data, the coding rule is modified based on second data, and the first data is encoded according to the modified coding rule to generate embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> A fifth storage medium according to the present invention stores such a program that first data is encoded according to a coding rule to output coded data, the coding rule is modified based on second data, and the first data is encoded according to the modified coding rule to generate embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> According to the fifth data processing apparatus, data processing method, and storage medium of the present invention, first data is encoded according to a coding rule to output coded data. Then, the coding rule is modified based on second data, and the first data is encoded according to the modified coding rule to generate embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> A sixth data processing apparatus according to the present invention includes first decoding means for decoding embedded coded data obtained by embedding second data in first data, to obtain coded data encoded according to an entropy coding rule and to obtain the second data; and second decoding means for decoding the coded data to obtain the first data. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> A sixth data processing method according to the present invention is such that embedded coded data obtained by embedding second data in first data is decoded to obtain coded data encoded according to an entropy coding rule and to obtain the second data, and the coded data is decoded to obtain the first data. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> A sixth storage medium according to the present invention stores such a program that embedded coded data obtained by embedding second data in first data is decoded to obtain coded data encoded according to an entropy coding rule and to obtain the second data, and the coded data is decoded to obtain the first data. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> According to the sixth data processing apparatus, data processing method, and storage medium of the present invention, embedded coded data obtained by embedding second data in first data is decoded to obtain coded data encoded according to an entropy coding rule and to obtain the second data. Furthermore, the coded data is decoded to obtain the first data. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> A data processing system according to the present invention includes an encoding apparatus including encoding means for encoding first data according to a coding rule to output coded data; and modification means for modifying the coding rule based on second data; wherein the encoding means encodes the first data according to a coding rule modified by the modification means to generate embedded data in which the second data is embedded, the data processing system also including a decoding apparatus including first decoding means for decoding embedded coded data to obtain the coded data encoded according to the coding rule and to obtain the second data; and second decoding means for decoding the coded data to obtain the first data. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> According to the data processing system of the present invention, in the encoding apparatus, first data is encoded according to a coding rule to output coded data. Then, the coding rule is modified based on second data, and the first data is encoded according to the modified coding rule to generate embedded data in which the second data is embedded. In the decoding apparatus, embedded coded data is decoded to obtain the coded data encoded according to the coding rule and to obtain the second data. Then, the coded data is decoded to obtain the first data.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a diagram showing an example construction of an embedded compression/decoding system according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram showing a first example construction of an embedded compression encoder <highlight><bold>11</bold></highlight>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram showing an example construction of a variable-length encoding unit <highlight><bold>23</bold></highlight>. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a diagram showing variable-length decoding. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a diagram showing the relationship between the frequencies of occurrence of pixel values and code lengths of codes assigned to the pixel values. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a diagram showing an example Huffman table. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a diagram showing codes assigned in accordance with the frequencies of occurrence of pixel values, and translation of the codes. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a diagram showing an example of embedded coded data. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a diagram showing a method for restoring embedded coded data into original coded data. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flowchart showing an embedded coding process. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a flowchart showing a translation table creation process. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a flowchart showing a coded data translation process. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a block diagram showing a second example construction of the embedded compression encoder <highlight><bold>11</bold></highlight>. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a block diagram showing a first example construction of a decoder <highlight><bold>12</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is a block diagram showing an example construction of a variable-length decoding unit <highlight><bold>52</bold></highlight> and a variable-length decoding unit <highlight><bold>56</bold></highlight>. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a block diagram showing an example construction of a Huffman table creation unit <highlight><bold>53</bold></highlight>. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a block diagram showing an example construction of a reverse translation table creation unit <highlight><bold>54</bold></highlight>. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a flowchart showing a decoding process. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is a block diagram showing a third example construction of the embedded compression encoder <highlight><bold>11</bold></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is a flowchart showing an embedded coding process. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> is a block diagram showing an example construction of an encoding unit <highlight><bold>91</bold></highlight>. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 22</cross-reference> is a diagram showing encoding by vector quantization. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> is a block diagram showing an example construction of an embedding unit <highlight><bold>92</bold></highlight>. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 24</cross-reference> is a diagram showing embedding of additional information by line rotation. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 25</cross-reference> is a flowchart showing an embedded coding process. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 26</cross-reference> is a block diagram showing a second example construction of the decoder <highlight><bold>12</bold></highlight>. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 27</cross-reference> is a flowchart showing a decoding process. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 28</cross-reference> is a block diagram showing an example construction of a coding rule restoring unit <highlight><bold>121</bold></highlight>. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 29</cross-reference> is a block diagram showing an example construction of a decoding unit <highlight><bold>122</bold></highlight>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 30</cross-reference> is a block diagram showing an example construction of a determination unit <highlight><bold>123</bold></highlight>. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 31</cross-reference> is a diagram showing a process executed by the determination unit <highlight><bold>123</bold></highlight>. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 32</cross-reference> is a flowchart showing a decoding process. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 33</cross-reference> is a block diagram showing a third example construction of the decoder <highlight><bold>12</bold></highlight>. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 34</cross-reference> is a block diagram showing an example construction of a computer according to an embodiment of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">BEST MODE FOR CARRYING OUT THE INVENTION </heading>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is an example construction of an embedded compression/decoding system (a system refers to a logical combination of a plurality of apparatuses, irrespective of whether the constituent apparatuses resides in the same casing) according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> The embedded compression/decoding system includes an encoding apparatus <highlight><bold>1</bold></highlight> and a decoding apparatus <highlight><bold>2</bold></highlight>. The encoding apparatus <highlight><bold>1</bold></highlight> encodes, for example, an image to be encoded, and the decoding apparatus <highlight><bold>2</bold></highlight> decodes the result of the encoding into the original image. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> The encoding apparatus <highlight><bold>1</bold></highlight> includes an embedded compression encoder <highlight><bold>11</bold></highlight>. To the embedded compression encoder <highlight><bold>11</bold></highlight>, an image to be encoded and information to be embedded in the image (hereinafter referred to as additional information when appropriate) are supplied. The embedded compression encoder <highlight><bold>11</bold></highlight> encodes the image (digital image data) for compression according to a predetermined coding rule, and modifies or destroys the coding rule based on the additional information (digital data), thereby embedding the additional information to yield embedded coded data for output. The embedded coded data output from the embedded compression encoder <highlight><bold>11</bold></highlight> is recorded on a recording medium <highlight><bold>3</bold></highlight>, for example, a semiconductor memory, a magneto-optical disk, a magnetic disk, an optical disk, a magnetic tape, or a phase-change disk, or transmitted via a transmission medium <highlight><bold>4</bold></highlight>, for example, a terrestrial wave, a satellite link, a CATV (Cable Television) network, the Internet, or a public network, and is thus provided to the decoding apparatus <highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> The decoding apparatus <highlight><bold>2</bold></highlight> includes the decoder <highlight><bold>12</bold></highlight>, which receives the embedded coded data provided via the recording medium <highlight><bold>3</bold></highlight> or the transmission medium <highlight><bold>4</bold></highlight>. The decoder <highlight><bold>12</bold></highlight> restores the embedded coded data into the coded data encoded according to the predetermined coding rule, thereby decoding the additional information embedded therein and also decoding the coded data into the original image. The decoded image is supplied to and displayed on a monitor, not shown, or the like. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> It is to be understood that the additional information may include, for example, text data or sound data associated with the original image, a reduced version of the image, etc., and may include data irrelevant to the original image. That is, arbitrary data (including a program) can be used as the additional information. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> Furthermore, part of an image supplied to the embedded compression encoder <highlight><bold>11</bold></highlight> for encoding may also be used as the additional information. That is, it is possible to supply part of the image as additional information to the embedded compression encoder <highlight><bold>11</bold></highlight> while also supplying the rest of the image as data to be encoded. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows an example construction of the embedded compression encoder <highlight><bold>11</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> A frame memory <highlight><bold>21</bold></highlight> stores image data supplied to the embedded compression encoder <highlight><bold>11</bold></highlight>, for example, on a frame basis. An additional information memory <highlight><bold>22</bold></highlight> stores additional information supplied to the embedded compression encoder <highlight><bold>11</bold></highlight>. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> A variable-length encoding unit <highlight><bold>23</bold></highlight> applies variable-length coding or entropy coding, for example, Huffman coding, on the image data stored in the frame memory <highlight><bold>21</bold></highlight>, and supplies the resulting coded data to a coding rule destroying unit <highlight><bold>25</bold></highlight>. The variable-length encoding unit <highlight><bold>23</bold></highlight> creates a Huffman table in the process of Huffman encoding in a manner to be described later, and supplies the Huffman table to a translation table creation unit <highlight><bold>24</bold></highlight>. Furthermore, the variable-length encoding unit <highlight><bold>23</bold></highlight> supplies information related to Huffman table, to a MUX (multiplexer) <highlight><bold>26</bold></highlight>, which will be required in obtaining the Huffman table output to the translation table creation unit <highlight><bold>24</bold></highlight>. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> The translation table creation unit <highlight><bold>24</bold></highlight> creates, based on the additional information stored in the additional information memory <highlight><bold>22</bold></highlight>, a translation table for translating codes in the Huffman table supplied from the variable-length encoding unit <highlight><bold>23</bold></highlight>. That is, the Huffman table defines association between values to be Huffman-encoded (pixel values of the image herein) and codes having different code lengths (coded data), and the translation table creation unit <highlight><bold>24</bold></highlight> creates a translation table for translating the codes in the Huffman table into codes based on the additional information. The translation table created by the translation table creation unit <highlight><bold>24</bold></highlight> is supplied to the coding rule destroying unit <highlight><bold>25</bold></highlight>. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> The coding rule destroying unit <highlight><bold>25</bold></highlight> modifies or destroys the coding rule in the variable-length encoding unit <highlight><bold>23</bold></highlight> based on the additional information, thereby embedding the additional information. That is, the coding rule destroying unit <highlight><bold>25</bold></highlight> translates (manipulates) the coded data (codes) output from the variable-length encoding unit <highlight><bold>23</bold></highlight>, according to the translation table created by the translation table creation unit <highlight><bold>24</bold></highlight> based on the additional information, thereby yielding coded data encoded according to a coding rule in which the coding rule in the variable-length encoding unit <highlight><bold>23</bold></highlight> is destroyed. The coded data encoded according to the destroyed coding rule is supplied from the coding rule destroying unit <highlight><bold>25</bold></highlight> to the MUX <highlight><bold>26</bold></highlight> as embedded coded data obtained by embedding additional information in the original coded data. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> The MUX <highlight><bold>26</bold></highlight> multiplexes the embedded coded data from the coding rule destroying unit <highlight><bold>25</bold></highlight> and the information related to Huffman table from the variable-length encoding unit <highlight><bold>23</bold></highlight>, outputting the multiplexed data. As described with reference to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the multiplexed data is supplied to the decoding apparatus <highlight><bold>2</bold></highlight> via the recording medium <highlight><bold>3</bold></highlight> or the transmission medium <highlight><bold>4</bold></highlight>. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows an example construction of the variable-length encoding unit <highlight><bold>23</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> Each frame of the image data stored in the frame memory <highlight><bold>21</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is sequentially considered, for example, in time order, and the image data of the frame under consideration is read. The image data of the frame under consideration is supplied to a frequency table creation unit <highlight><bold>31</bold></highlight> and to an encoding unit <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> The frequency table creation unit <highlight><bold>31</bold></highlight> creates a frequency table for the pixels constituting the frame under consideration supplied thereto, in which each pixel value is associated with the frequency of occurrence thereof, and supplies it to a Huffman tree creation unit <highlight><bold>32</bold></highlight>. The frequency table is also supplied from the frequency table creation unit <highlight><bold>31</bold></highlight> to the MUX <highlight><bold>26</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> as information related to Huffman table. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> Although the frequency table is used as information related to Huffman table in the embodiment shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the information related to Huffman table is not specifically limited as long as the information allows a Huffman table created by a Huffman table creation unit <highlight><bold>33</bold></highlight>, which will be described later, to be obtained. Thus, the information related to Huffman table may be, for example, the Huffman table itself created by the Huffman table creation unit <highlight><bold>33</bold></highlight>, as well as the frequency table. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> The Huffman tree creation unit <highlight><bold>32</bold></highlight> creates what is called a Huffman tree based on the frequency table supplied from the frequency table creation unit <highlight><bold>31</bold></highlight>, and supplies it to the Huffman table creation unit <highlight><bold>33</bold></highlight>. The Huffman table creation unit <highlight><bold>33</bold></highlight> creates a Huffman table based on the Huffman tree supplied from the Huffman tree creation unit <highlight><bold>32</bold></highlight>. That is, the Huffman table creation unit <highlight><bold>33</bold></highlight> creates a Huffman table in which pixel values in the frame under consideration are each assigned a code having a shorter code length in accordance with the frequency of occurrence of the pixel value being higher (a code having a longer code length in accordance with the frequency of occurrence being lower). The Huffman table is supplied to the encoding unit <highlight><bold>34</bold></highlight> and also to the translation table creation unit <highlight><bold>24</bold></highlight> shown in FIG. <highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> The encoding unit <highlight><bold>34</bold></highlight> sequentially considers each pixel in the frame under consideration supplied thereto, for example, in order of raster scanning, and translates the pixel value of the pixel under consideration into the corresponding code in the Huffman table supplied from the Huffman table creation unit <highlight><bold>33</bold></highlight>, outputting it as coded data. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> In the variable-length encoding unit <highlight><bold>23</bold></highlight> constructed as described above, the frequency table creation unit <highlight><bold>31</bold></highlight> creates a frequency table for a frame under consideration, which is supplied to the Huffman tree creation unit <highlight><bold>32</bold></highlight>. The Huffman tree creation unit <highlight><bold>32</bold></highlight> creates a Huffman tree based on the frequency table supplied from the frequency table creation unit <highlight><bold>31</bold></highlight>, which is supplied to the Huffman table creation unit <highlight><bold>33</bold></highlight>. The Huffman table creation unit <highlight><bold>33</bold></highlight> creates a Huffman table based on the Huffman tree supplied from the Huffman tree creation unit <highlight><bold>32</bold></highlight>, which is supplied to the encoding unit <highlight><bold>34</bold></highlight>. The encoding unit <highlight><bold>34</bold></highlight> translates each pixel value in the frame under consideration into a code associated with the pixel value in the Huffman table, which is output as coded data. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Now, a variable-length encoding process in the variable-length encoding unit <highlight><bold>23</bold></highlight> will be further described with reference to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> Let is be supposed, for example, that a frequency table as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(A) has been created in the frequency table creation unit <highlight><bold>31</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(A) shows pixel values &lsqb;0&rsqb;, &lsqb;1&rsqb;, &lsqb;2&rsqb;, &lsqb;3&rsqb;, and &lsqb;4&rsqb; as having occurred five times, four times, three times, twice, and once in a frame under consideration, respectively. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> In relation to the frequency table in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(A), the Huffman tree creation unit <highlight><bold>32</bold></highlight> creates a Huffman tree in a bottom-up manner based on the frequency of occurrence of each pixel value, for example, as shown in FIGS. <highlight><bold>4</bold></highlight>(B) to <highlight><bold>4</bold></highlight>(E). </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> More specifically, the Huffman tree creation unit <highlight><bold>32</bold></highlight> selects pixel values with the two lowest frequencies of occurrence from the pixel values in the frequency table, thereby forming a node. Furthermore, the Huffman tree creation unit <highlight><bold>32</bold></highlight> assigns either bit &ldquo;0&rdquo; or bit &ldquo;1&rdquo; to the one with the lower frequency of occurrence of the selected two pixel values, for example, &ldquo;0&rdquo;, assigning &ldquo;1&rdquo; to the other. The Huffman tree creation unit <highlight><bold>32</bold></highlight> assigns the sum of the frequencies of occurrence of the selected two pixel values to the node formed by the selected two pixel values as the frequency of occurrence of the node. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> Thus, in the frequency table shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(A), pixel value &lsqb;4&rsqb; having a frequency of occurrence 1 and pixel value &lsqb;3&rsqb; having a frequency of occurrence 2 are selected, forming a node &num;1, and 3 (&equals;1&plus;2) is assigned as the frequency of occurrence of the node &num;1, as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(B). Furthermore, of the selected two pixel values &lsqb;4&rsqb; and &lsqb;3&rsqb;, bit &ldquo;0&rdquo; is assigned to pixel value &lsqb;4&rsqb;, having a lower frequency of occurrence, and bit &ldquo;1&rdquo; is assigned to pixel value &lsqb;3&rsqb;, having a higher frequency of occurrence. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> In FIGS. <highlight><bold>4</bold></highlight>(B) to <highlight><bold>4</bold></highlight>(E), numerals representing frequencies of occurrence are shown in parentheses. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> If the frequencies of occurrence of the two selected pixel values are the same, bits &ldquo;0&rdquo; or &ldquo;1&rdquo; may be assigned to either one of the pixel values. However, to which of the pixel values bits &ldquo;0&rdquo; or &ldquo;1&rdquo; is to be assigned must be predetermined, for example, assigning bit &ldquo;0&rdquo; to the smaller pixel value. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> The Huffman tree creation unit <highlight><bold>32</bold></highlight> repeats the same process until convergence to a single node is achieved. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> Thus, from the state shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(B), the node &num;1 and pixel value &lsqb;2&rsqb; each having a frequency of occurrence 3 are selected, so that the node &num;1 and pixel value &lsqb;2&rsqb; form a node &num;2, as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(C). Furthermore, the frequency of occurrence of the node &num;2 is set to 6 (&equals;3&plus;3), and bits &ldquo;0&rdquo; and &ldquo;1&rdquo; are assigned to the node &num;1 and pixel value &lsqb;2&rsqb;, respectively. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> From the state shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(C), pixel value &lsqb;1&rsqb; having a frequency of occurrence 4 and pixel value &lsqb;0&rsqb; having a frequency of occurrence 5 are selected, so that pixel values &lsqb;1&rsqb; and &lsqb;0&rsqb; form a node &num;3. Furthermore, the frequency of occurrence of the node &num;3 is set to 9 (&equals;4&plus;5), and bits &ldquo;0&rdquo; and &ldquo;1&rdquo; are assigned to pixel values &lsqb;1&rsqb; and &lsqb;0&rsqb;, respectively, as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(D). </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> From the state shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(D), the node &num;2 having a frequency of occurrence 6 and the node &num;3 having a frequency of occurrence 9 are selected, so that the nodes &num;2 and &num;3 form a node &num;4. Furthermore, the frequency of occurrence of the node &num;4 is set to 15 (&equals;6&plus;9), and bits &ldquo;0&rdquo; and &ldquo;1&rdquo; are assigned to the nodes &num;2 and &num;3, respectively, as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(E). </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> In the state shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(E), the nodes have been converged to the single node &num;4, so that the Huffman tree is complete. The Huffman tree creation unit <highlight><bold>32</bold></highlight> supplies the Huffman tree to the Huffman table creation unit <highlight><bold>33</bold></highlight>. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> The Huffman table creation unit <highlight><bold>33</bold></highlight> recognizes a code assigned to each pixel value by tracking the Huffman tree from the convergence node in the direction of a pixel value. More specifically, for example, the Huffman tree shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(E) is tracked from the node &num;4 in the direction of pixel value &lsqb;0&rsqb;, and a sequence of bits assigned to the nodes (or pixel values) is found as &ldquo;0&rdquo;&rarr;&ldquo;0&rdquo;&rarr;&ldquo;0&rdquo;. Accordingly, the Huffman table creation unit <highlight><bold>33</bold></highlight> recognizes that code &ldquo;000&rdquo; is assigned to pixel value &lsqb;0&rsqb;. Also, the Huffman tree shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(E) is tracked from the node &num;4 in the direction of pixel value &lsqb;1&rsqb;, and a sequence of bits assigned to the nodes is found as &ldquo;0&rdquo;&rarr;&ldquo;0&rdquo;&rarr;&ldquo;1&rdquo;. Accordingly, the Huffman table creation unit <highlight><bold>33</bold></highlight> recognizes that code &ldquo;001&rdquo; is assigned to pixel value &lsqb;1&rsqb;. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> Similarly, the Huffman table creation unit <highlight><bold>33</bold></highlight> recognizes a code assigned to each pixel value, thereby creating a Huffman table representing association between pixel values and codes. Thus, from the Huffman tree shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(E), a Huffman table as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(F) is created. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> The variable-length encoding unit <highlight><bold>23</bold></highlight> may alternatively perform variable-length encoding, for example, in the manner disclosed in U.S. Pat. No. 5,021,782. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> In the Huffman table shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(E), codes &ldquo;11&rdquo;, &ldquo;10&rdquo;, &ldquo;01&rdquo;, &ldquo;001&rdquo;, and &ldquo;000&rdquo; are assigned to pixel values &lsqb;0&rsqb;, &lsqb;1&rsqb;, &lsqb;2&rsqb;, &lsqb;3&rsqb;, and &lsqb;4&rsqb; having frequencies of occurrence 5, 4, 3, 2, and 1, respectively. Thus, basically, codes of shorter code lengths are assigned in accordance with the frequencies of occurrence being higher. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> In the Huffman table shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>(E), although pixel values &lsqb;0&rsqb;, &lsqb;1&rsqb;, &lsqb;2&rsqb;, &lsqb;3&rsqb;, and &lsqb;4&rsqb; have different frequencies of occurrence, codes in two bits are assigned to pixel values &lsqb;0&rsqb;, &lsqb;1&rsqb;, and &lsqb;2&rsqb; having relatively higher frequencies of occurrence, whereas codes in three bits are assigned to pixel values &lsqb;3&rsqb; and &lsqb;4&rsqb; having relatively lower frequencies of occurrence. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> As described above, in a Huffman table, codes having the same code length are sometimes assigned to pixel values having different frequencies of occurrence. The relationship between frequencies of occurrence of pixel values and length of codes assigned to the pixel values are generally as shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, assuming that n-bit codes are assigned to x pixel values (x is an integer not exceeding 2<highlight><superscript>n</superscript></highlight>), the number of patterns of assignment of the n-bit codes to the x pixel values is X&excl; (&excl; denotes factorial), only one of which is adopted based on the rule for creating the Huffman tree described above. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> Even if the pattern of assignment of the n-bit codes to the x pixel value is modified, the amount of codes does not increase. That is, in a Huffman table, even if an n-bit code is assigned to a pixel value instead of another n-bit code, the code length assigned remains as n bits, and thus the amount of codes does not increase. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> Furthermore, even if the pattern of assignment of the n-bit codes to the x pixel values is modified, the pattern of code assignment can be restored, for example, based on the frequencies of occurrence of x pixel values. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> From the above, even if the pattern of assignment of codes of the same length to pixel values is modified in a Huffman table, that is, even if a coding rule for variable-length encoding is destroyed, the amount of codes does not increase, and the modified assignment pattern can be restored to the original one. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> This implies that, by modifying the pattern of assignment of codes to pixel values based on some information, information can be embedded without increasing the total amount of data while allowing the embedded information to be decoded without overhead. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows an example of a Huffman table created for pixel values represented in eight bits (0 to 255). In <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, in addition to pixel values and codes (coded data) assigned to pixel values, the frequency of occurrence of each of the pixel values is shown. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, for example, with regard to seven pixel values from &lsqb;12&rsqb; to &lsqb;18&rsqb;, a nine-bit code is assigned to each of the seven pixel values, and thus 7&excl; patterns of assignment of the nine-bit codes to the seven pixel values exist. Thus, by modifying the pattern of assignment of the nine-bit codes to the seven pixel values, int&lsqb;log<highlight><subscript>2</subscript></highlight>7&excl;&rsqb; bits of information can be embedded. int&lsqb; &rsqb; represents the largest integer value not exceeding the value in &lsqb; &rsqb;. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(A) is a graph showing the respective frequencies of occurrence of pixel values &lsqb;12&rsqb; to &lsqb;18&rsqb; shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, and <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(B) shows nine-bit codes respectively assigned to pixel values &lsqb;12&rsqb; to &lsqb;18&rsqb; in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> Let it be supposed that the code assignment shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(B) is modified based on additional information within int&lsqb;log<highlight><subscript>2</subscript></highlight>7&excl;&rsqb; bits, for example, as shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(C). </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> More specifically, in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(B), codes &ldquo;110111111&rdquo;, &ldquo;110111010&rdquo;, &ldquo;110100001&rdquo;, &ldquo;110011001&rdquo;, &ldquo;11011000&rdquo;, &ldquo;011101011&rdquo;, and &ldquo;010001010&rdquo; are assigned to pixel values &lsqb;12&rsqb; to &lsqb;18&rsqb;, respectively. In <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(C), the assignment is modified so that code &ldquo;110111111&rdquo;, which has been assigned to pixel value &lsqb;12&rsqb;, is now assigned to pixel value &lsqb;15&rsqb;, code &ldquo;110011001&rdquo;, which has been assigned to pixel value &lsqb;15&rsqb;, is now assigned to pixel value &lsqb;12&rsqb;, code &ldquo;11011000&rdquo;, which has been assigned to pixel value &lsqb;16&rsqb;, is now assigned to pixel value &lsqb;17&rsqb;, code &ldquo;011101011&rdquo;, which has been assigned to pixel value &lsqb;17&rsqb;, is now assigned to pixel value &lsqb;18&rsqb;, and code &ldquo;010001010&rdquo;, which has been assigned to pixel value &lsqb;18&rsqb;, is now assigned to pixel value &lsqb;16&rsqb;. Assignment of codes to other pixel values is not modified in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> Also for pixel values to which codes of other code lengths are assigned, pattern of code assignment can be modified based on the additional information. <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows an example of embedded coded data, constituting coded data in which the pattern of code assignment shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> has been modified based on the additional information. <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows, together with the embedded coded data, decoded pixel values obtained by variable-length decoding the embedded coded data according to the Huffman table shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> (pixel values obtained by decoding the embedded coded data according to the Huffman table used in obtaining the coded data). </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, for example, with regard to the seven pixel values from &lsqb;12&rsqb; to &lsqb;18&rsqb;, if the embedded coded data is decoded according to the Huffman table shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, decoded pixel values as shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference> are obtained. That is, letting pixel values obtained by decoding the embedded coded data according to the Huffman table used at the time of encoding be referred to as embedded decoded pixel value, codes &ldquo;110011001&rdquo;, &ldquo;110111010&rdquo;, &ldquo;110100001&rdquo;, &ldquo;110111111&rdquo;, &ldquo;010001010&rdquo;, &ldquo;11011000&rdquo;, and &ldquo;011101011&rdquo; are variable-length decoded into embedded decoded pixel values &lsqb;15&rsqb;, &lsqb;13&rsqb;, &lsqb;14&rsqb;, &lsqb;12&rsqb;, &lsqb;18&rsqb;, &lsqb;16&rsqb;, and &lsqb;17&rsqb;, respectively. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference>(B) shows counts of the frequencies of occurrence of the embedded decoded pixel values &lsqb;12&rsqb; to &lsqb;18&rsqb;. Since codes assigned to pixel values &lsqb;12&rsqb; to &lsqb;18&rsqb; in the Huffman table shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> are modified as shown in FIGS. <highlight><bold>7</bold></highlight>(B) and <highlight><bold>7</bold></highlight>(C), the frequencies of occurrence of pixel values &lsqb;12&rsqb;, &lsqb;15&rsqb;, and &lsqb;16&rsqb; to &lsqb;18&rsqb; do not coincide with those shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(A), and more specifically, they coincide with the frequencies of occurrence of pixel values &lsqb;15&rsqb;, &lsqb;12&rsqb;, &lsqb;18&rsqb;, &lsqb;16&rsqb;, and &lsqb;17&rsqb; prior to variable-length encoding, respectively. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> However, since the frequencies of occurrence of original pixel values &lsqb;12&rsqb; to &lsqb;18&rsqb; (prior to variable-length encoding) and the frequencies of occurrence of pixel values &lsqb;12&rsqb; to &lsqb;18&rsqb; obtained by variable-length decoding are supposed to respectively coincide with each other, it is unnatural (strange) if the frequencies of occurrence differ between prior to variable-length encoding and after variable-length decoding. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> Accordingly, the pattern of assignment of codes (variable-length codes), having been modified based on the additional information, can be restored to the original pattern by comparing the frequencies of occurrence of the original pixel values shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(A) with the frequencies of occurrence of the embedded decoded pixel values shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>(B) and by detecting matching frequencies of occurrence. That is, the embedded coded data can be restored into the coded data encoded according to the Huffman table. Furthermore, the embedded additional information can be decoded based on how the pattern of code assignment is modified when the embedded coded data is restored into the coded data, and also, the original pixel values can be obtained by variable-length decoding the restored coded data. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> More specifically, by comparing the frequencies of occurrence of the original pixel values shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(A) with the frequencies of occurrence of the embedded decoded pixel values shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>(B), the frequencies of occurrence of the embedded decoded pixel values &lsqb;15&rsqb;, &lsqb;13&rsqb;, &lsqb;14&rsqb;, &lsqb;12&rsqb;, &lsqb;17&rsqb;, &lsqb;18&rsqb;, and &lsqb;16&rsqb; can be detected as coinciding with the frequencies of occurrence of the original pixel values &lsqb;12&rsqb; to &lsqb;18&rsqb;, respectively. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> Thus, embedded coded data &ldquo;110011001&rdquo;, &ldquo;110111010&rdquo;, &ldquo;110100001&rdquo;, &ldquo;110111111&rdquo;, &ldquo;010001010&rdquo;, &ldquo;11011000&rdquo;, and &ldquo;011101011&rdquo;, from which embedded decoded pixel values &lsqb;15&rsqb;, &lsqb;13&rsqb;, &lsqb;14&rsqb;, &lsqb;12&rsqb;, &lsqb;17&rsqb;, &lsqb;18&rsqb;, and &lsqb;16&rsqb; have been obtained, can be determined as having been codes &ldquo;110111111&rdquo;, &ldquo;110111010&rdquo;, &ldquo;110100001&rdquo;, &ldquo;110011001&rdquo;, &ldquo;11011000&rdquo;, &ldquo;011101011&rdquo;, and &ldquo;010001010&rdquo; assigned to the original pixel values &lsqb;12&rsqb; to &lsqb;18&rsqb; in the Huffman table shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> prior to embedding of the additional information. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> Thus, by translating the embedded coded data so that the frequencies of occurrence of the original pixel values shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(A) coincide with the frequencies of occurrence of the embedded decoded pixel values shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>(B), as shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>(C), the coded data encoded according to the Huffman table shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> can be restored, and the additional information can be decoded based on the association between the embedded coded data and the restored coded data. Furthermore, by variable-length decoding the restored coded data, the original pixel values can be obtained, as shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>(D). </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> The embedded compression encoder <highlight><bold>11</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> performs an embedded coding process that does not increase the amount of data and that allows decoding without overhead, as described above. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> Now, an embedded coding process executed by the embedded compression encoder <highlight><bold>11</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> will be further described with reference to a flowchart shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> In step S<highlight><bold>1</bold></highlight>, the variable-length encoding unit <highlight><bold>23</bold></highlight> variable-length encodes the pixel value of each pixel in a frame under consideration supplied from the frame memory <highlight><bold>21</bold></highlight>, outputting the resulting coded data to the coding rule destroying unit <highlight><bold>25</bold></highlight>. Furthermore, in the variable-length encoding in step S<highlight><bold>1</bold></highlight>, the variable-length encoding unit <highlight><bold>23</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 3</cross-reference>) outputs a frequency table created by the frequency table creation unit <highlight><bold>31</bold></highlight> to the MUX <highlight><bold>26</bold></highlight> as information related to Huffman table, and also outputs a Huffman table created by the Huffman table creation unit <highlight><bold>33</bold></highlight> to the translation table creation unit <highlight><bold>24</bold></highlight>. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> Then, in step S<highlight><bold>2</bold></highlight>, the translation table creation unit <highlight><bold>24</bold></highlight> modifies the pattern of assignment of codes having the same code length in Huffman table supplied from the variable-length encoding unit <highlight><bold>23</bold></highlight>, based on the additional information supplied from the additional information memory <highlight><bold>22</bold></highlight>, and executes a translation table creation process for creating a translation table associating the codes prior to the modification with codes after the modification. The translation table is supplied from the translation table creation unit <highlight><bold>24</bold></highlight> to the coding rule destroying unit <highlight><bold>25</bold></highlight>. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> In step S<highlight><bold>3</bold></highlight>, the coding rule destroying unit <highlight><bold>25</bold></highlight> executes a coded data translation process for translating the coded data supplied from the variable-length encoding unit <highlight><bold>23</bold></highlight> into embedded coded data according to the translation table supplied from the translation table creation unit <highlight><bold>24</bold></highlight>, supplying the resulting embedded coded data to the MUX <highlight><bold>26</bold></highlight>. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> In step S<highlight><bold>4</bold></highlight>, the MUX <highlight><bold>26</bold></highlight> multiplexes and outputs the embedded coded data of the frame under consideration, supplied from the coding rule destroying unit <highlight><bold>25</bold></highlight>, and the information related to Huffman table, supplied from the variable-length encoding unit <highlight><bold>23</bold></highlight>. The process then proceeds to step S<highlight><bold>5</bold></highlight>. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> In step S<highlight><bold>5</bold></highlight>, it is determined whether a frame next to the frame under consideration is stored in the frame memory <highlight><bold>21</bold></highlight>. If it is determined in step S<highlight><bold>5</bold></highlight> that a next frame is stored in the frame memory <highlight><bold>21</bold></highlight>, with the next frame a new frame to be considered, the process returns to step S<highlight><bold>1</bold></highlight>, repeating the same process. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> If it is determined in step S<highlight><bold>5</bold></highlight> that a next frame is not stored in the frame memory <highlight><bold>21</bold></highlight>, the embedded coding process is exited. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> Now, the translation table creation process executed in step S<highlight><bold>2</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> by the translation table creation unit <highlight><bold>24</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> will be further described with reference to a flowchart shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>. </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> In the translation table creation process, initially, in step S<highlight><bold>11</bold></highlight>, the translation table creation unit <highlight><bold>24</bold></highlight> considers a particular code length of codes in the Huffman table supplied from the variable-length encoding unit <highlight><bold>23</bold></highlight>, recognizing the number of codes having the code length under consideration. That is, the translation table creation unit <highlight><bold>24</bold></highlight> recognizes the number of codes having the same code length as the code length under consideration. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> In step S<highlight><bold>12</bold></highlight>, the translation table creation unit <highlight><bold>24</bold></highlight> calculates the number of bits of additional information that can be embedded in the codes having the code length under consideration, based on the number of codes having the code length under consideration, recognized in step S<highlight><bold>11</bold></highlight>. That is, letting the number of codes having the code length under consideration be denoted by x, the translation table creation unit <highlight><bold>24</bold></highlight> obtains the number of bits y of additional information that can be embedded, by calculating y&equals;int&lsqb;log<highlight><subscript>2</subscript></highlight>(X&excl;)&rsqb;. </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> The process then proceeds to step S<highlight><bold>13</bold></highlight>, in which the translation table creation unit <highlight><bold>24</bold></highlight> reads the additional information for the number of bits y, calculated in step S<highlight><bold>12</bold></highlight>, from the additional information memory <highlight><bold>22</bold></highlight>. The process then proceeds to step S<highlight><bold>14</bold></highlight>. In step S<highlight><bold>14</bold></highlight>, the translation table creation unit <highlight><bold>24</bold></highlight> creates a translation table for the codes having the code length under consideration, based on the additional information read from the additional information memory <highlight><bold>22</bold></highlight> in step S<highlight><bold>13</bold></highlight>. That is, the translation table creation unit <highlight><bold>24</bold></highlight> modifies the pattern of assignment of x codes having the code length under consideration to pixel values, based on the y-bit additional information, thereby creating a translation table for the codes having the code length under consideration, in which the codes prior to the modification are associated with codes after the modification. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> Then, in step S<highlight><bold>15</bold></highlight>, the translation table creation unit <highlight><bold>24</bold></highlight> determines whether further additional information is stored in the additional information memory <highlight><bold>22</bold></highlight>. If it is determined that none is stored, the translation table creation unit <highlight><bold>24</bold></highlight> outputs translation tables created so far for the frame under consideration to the coding rule destroying unit <highlight><bold>25</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 2</cross-reference>). The translation table creation process is then exited. </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> If it is determined in step S<highlight><bold>15</bold></highlight> that further additional information is stored in the additional information memory <highlight><bold>22</bold></highlight>, the process proceeds to step S<highlight><bold>16</bold></highlight>, in which the translation table creation unit <highlight><bold>24</bold></highlight> determines whether a translation table has been created for codes of each code length in the Huffman table. If it is determined that the creation is not complete, the process returns to step S<highlight><bold>11</bold></highlight>. In this case, in step S<highlight><bold>11</bold></highlight>, one of the code lengths for which a translation table has not been created is selected as a new code length to be considered, and then the same process is repeated. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> If it is determined in step S<highlight><bold>16</bold></highlight> that a translation table has been created for codes of each code length in the Huffman table, the translation table creation process is exited. </paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> Next, the coded data translation process executed in step S<highlight><bold>3</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference> by the coding rule destroying unit <highlight><bold>25</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> will be further described with reference to a flowchart shown in <cross-reference target="DRAWINGS">FIG. 12</cross-reference>. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> As described above, the variable-length encoding unit <highlight><bold>23</bold></highlight> considers each pixel in the frame under consideration in order of raster scanning, and variable-length encodes the pixel value of the pixel under consideration, sequentially outputting the resulting coded data. Letting the coded data output for the pixel under consideration by the variable-length encoding unit <highlight><bold>23</bold></highlight> be referred to as coded data under consideration, initially, in step S<highlight><bold>21</bold></highlight>, the coding rule destroying unit <highlight><bold>25</bold></highlight> recognizes the code length of the coded data under consideration. The process then proceeds to step S<highlight><bold>22</bold></highlight>. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> In step S<highlight><bold>22</bold></highlight>, the coding rule destroying unit <highlight><bold>25</bold></highlight> translates the coded data under consideration according to the translation table associated with the code length of the coded data under consideration, recognized in step S<highlight><bold>21</bold></highlight>, and outputs the result to the MUX <highlight><bold>26</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 2</cross-reference>) as embedded coded data. </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> The process then proceeds to step S<highlight><bold>23</bold></highlight>, in which the coding rule destroying unit <highlight><bold>25</bold></highlight> determines whether next coded data supplied from the variable-length encoding unit <highlight><bold>23</bold></highlight> exits. If it is determined that next coded data exists, the coding rule destroying unit <highlight><bold>25</bold></highlight> selects the next coded data as new coded data to be considered. The process then returns to step S<highlight><bold>21</bold></highlight>, repeating the same process. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> If it is determined in step S<highlight><bold>23</bold></highlight> that next coded data does not exist, the coded data translation process is exited. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> The embedded compression encoder <highlight><bold>11</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> yields embedded coded data, in which additional information is embedded, by translating, according to a translation table, coded data yielded by variable-length encoding in the variable-length encoding unit <highlight><bold>23</bold></highlight>. Alternatively, for example, the variable-length encoding unit <highlight><bold>23</bold></highlight> may create a Huffman table in which the association of pixel values with codes is modified (hereinafter referred to as modified Huffman table when appropriate) and use the modified Huffman table to simultaneously perform variable-length encoding and embedding of additional information. That is, the variable-length encoding unit <highlight><bold>23</bold></highlight> may perform variable-length encoding based on a destroyed coding rule. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> shows an example construction of the embedded compression encoder <highlight><bold>11</bold></highlight> that executes such an embedded coding process. In the figure, parts corresponding to those shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> or <cross-reference target="DRAWINGS">FIG. 3</cross-reference> are designated by the same numerals, and descriptions thereof will hereinafter be omitted as appropriate. The embedded compression encoder <highlight><bold>11</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference> does not include the coding rule destroying unit <highlight><bold>25</bold></highlight>; instead, a coding rule destroying unit <highlight><bold>41</bold></highlight> is included in the variable-length encoding unit <highlight><bold>23</bold></highlight>. The embedded compression encoder <highlight><bold>11</bold></highlight> is otherwise constructed the same as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> To the coding rule destroying unit <highlight><bold>41</bold></highlight>, a Huffman table output from the Huffman table creation unit <highlight><bold>33</bold></highlight> and a translation table output from the translation table creation unit <highlight><bold>24</bold></highlight> are supplied. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> The coding rule destroying unit <highlight><bold>41</bold></highlight> modifies codes (coded data) associated with pixel values in the Huffman table into embedded coded data associated with the codes in the translation table, thereby modifying the Huffman table supplied from the Huffman table creation unit <highlight><bold>33</bold></highlight> into a modified Huffman table in which the pixel values are associated with the embedded coded data. The modified Huffman table is supplied to the encoding unit <highlight><bold>34</bold></highlight>, which translates the pixel values according to the modified Huffman table. </paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> Thus, in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>, the encoding unit <highlight><bold>34</bold></highlight> outputs the embedded coded data. </paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> shows an example construction of the decoder <highlight><bold>12</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, in a case where the embedded compression encoder <highlight><bold>11</bold></highlight> is constructed as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> or <cross-reference target="DRAWINGS">FIG. 13</cross-reference>. </paragraph>
<paragraph id="P-0146" lvl="0"><number>&lsqb;0146&rsqb;</number> A DEMUX (demultiplexer) <highlight><bold>51</bold></highlight> demultiplexes, on a frame basis, data provided from the embedded compression encoder <highlight><bold>11</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> or <cross-reference target="DRAWINGS">FIG. 13</cross-reference> into embedded coded data and information related to Huffman table, supplying the embedded coded data for each frame to a variable-length decoding unit <highlight><bold>52</bold></highlight> and to a coding rule restoring unit <highlight><bold>55</bold></highlight> while supplying the information related to Huffman table to the variable-length decoding unit <highlight><bold>52</bold></highlight>, a reverse translation table creation unit <highlight><bold>54</bold></highlight>, and to a variable-length decoding unit <highlight><bold>56</bold></highlight>. </paragraph>
<paragraph id="P-0147" lvl="0"><number>&lsqb;0147&rsqb;</number> The variable-length decoding unit <highlight><bold>52</bold></highlight> sequentially considers each frame of the embedded coded data and the information related to Huffman table output from the DEMUX <highlight><bold>51</bold></highlight>, and creates a Huffman table based on a frequency table constituting the information related to Huffman table associated with the frame under consideration, in the same manner as in the variable-length encoding unit <highlight><bold>23</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, supplying it to the reverse translation table creation unit <highlight><bold>54</bold></highlight>. </paragraph>
<paragraph id="P-0148" lvl="0"><number>&lsqb;0148&rsqb;</number> The Huffman table created from the frequency table constituting the information related to Huffman table is the same one as that used for variable-length encoding in the variable-length encoding unit <highlight><bold>23</bold></highlight>, and will hereinafter be referred to as a true Huffman table when appropriate. The frequency table constituting the information related to Huffman table, used to obtain the true Huffman table, will hereinafter be referred to as a true frequency table when appropriate. </paragraph>
<paragraph id="P-0149" lvl="0"><number>&lsqb;0149&rsqb;</number> The variable-length decoding unit <highlight><bold>52</bold></highlight> then variable-length decodes the embedded coded data of the frame under consideration according to the true Huffman table, and supplies the resulting decoded pixel values, that is, embedded decoded pixel values, to the Huffman table creation unit <highlight><bold>53</bold></highlight>. </paragraph>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> The Huffman table creation unit <highlight><bold>53</bold></highlight> creates a Huffman table for variable-length encoding the embedded decoded pixel values of the frame under consideration, supplied from the variable-length decoding unit <highlight><bold>52</bold></highlight>, and supplies the Huffman table and the frequency table created in the process of creating the Huffman table to the reverse translation table creation unit <highlight><bold>54</bold></highlight>. </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> The Huffman table created by the Huffman table creation unit <highlight><bold>53</bold></highlight> is used for variable-length encoding the embedded decoded pixel values (obtained by variable-length decoding the embedded coded data according to the true Huffman table), and basically does not allow correct decoding of coded data. Thus, the Huffman table obtained from the embedded decoded pixel values will hereinafter be referred to as a false Huffman table when appropriate, as opposed to the true Huffman table. The frequency table used for obtaining the false Huffman table will hereinafter be referred to as a false frequency table when appropriate, as opposed to the true frequency table. </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> The reverse translation table creation unit <highlight><bold>54</bold></highlight> creates a reverse translation table for translating the embedded coded data into the original coded data, based on the true Huffman table supplied from the variable-length decoding unit <highlight><bold>52</bold></highlight>, the true frequency table constituting the information related to Huffman table, supplied from the DEMUX <highlight><bold>51</bold></highlight>, and the false Huffman table and the false frequency table supplied from the Huffman table creation unit <highlight><bold>53</bold></highlight>. That is, the reverse translation table creation unit <highlight><bold>54</bold></highlight> creates the same reverse translation table as the translation table created by the translation table creation unit <highlight><bold>24</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference> (or <cross-reference target="DRAWINGS">FIG. 13</cross-reference>). The reverse translation table is supplied to the coding rule restoring unit <highlight><bold>55</bold></highlight>. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> The coding rule restoring unit <highlight><bold>55</bold></highlight> restores (decodes) the embedded coded data supplied from the DEMUX <highlight><bold>51</bold></highlight> into the coded data encoded according to the true Huffman table constituting the coding rule, according to the reverse translation table supplied from the reverse translation table creation unit <highlight><bold>54</bold></highlight>. Furthermore, the coding rule restoring unit <highlight><bold>55</bold></highlight> decodes the additional information embedded in the embedded coded data, based on the association between the embedded coded data and the restored coded data, that is, the reverse translation table. The coding rule restoring unit <highlight><bold>55</bold></highlight> outputs the restored coded data to the variable-length decoding unit <highlight><bold>56</bold></highlight> and also outputs the additional information that has been decoded as decoded additional information. </paragraph>
<paragraph id="P-0154" lvl="0"><number>&lsqb;0154&rsqb;</number> The variable-length decoding unit <highlight><bold>56</bold></highlight> creates a true Huffman table from the information related to Huffman table supplied from the DEMUX <highlight><bold>51</bold></highlight>, and variable-length decodes the coded data supplied from the coding rule restoring unit <highlight><bold>55</bold></highlight> based on the true Huffman table, outputting the resulting decoded pixel values. </paragraph>
<paragraph id="P-0155" lvl="0"><number>&lsqb;0155&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> shows an example construction of the variable-length decoding unit <highlight><bold>52</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> The embedded coded data output from the DEMUX <highlight><bold>51</bold></highlight> is supplied to a decoding unit <highlight><bold>63</bold></highlight>, and the frequency table constituting the information related to Huffman table, output from the DEMUX <highlight><bold>51</bold></highlight>, is supplied to a Huffman tree creation unit <highlight><bold>61</bold></highlight>. </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> The Huffman tree creation unit <highlight><bold>61</bold></highlight> creates a Huffman tree from the frequency table associated with the frame under consideration, and supplies it to a Huffman table creation unit <highlight><bold>62</bold></highlight>, similarly to the Huffman tree creation unit <highlight><bold>32</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. </paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> The Huffman table creation unit <highlight><bold>62</bold></highlight> creates a Huffman table based on the Huffman tree supplied from the Huffman tree creation unit <highlight><bold>61</bold></highlight>, and supplies it to the decoding unit <highlight><bold>63</bold></highlight>, similarly to the Huffman table creation unit <highlight><bold>33</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> The decoding unit <highlight><bold>63</bold></highlight> decodes the embedded coded data supplied thereto into pixel values (embedded decoded pixel values) according to the Huffman table supplied from the Huffman table creation unit <highlight><bold>62</bold></highlight>, and outputs the result. </paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> The variable-length decoding unit <highlight><bold>56</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is constructed the same as the variable-length decoding unit <highlight><bold>52</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>. </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> shows an example construction of the Huffman table creation unit <highlight><bold>53</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>. </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> In the Huffman table creation unit <highlight><bold>53</bold></highlight>, the embedded decoded pixel values output from the variable-length decoding unit <highlight><bold>52</bold></highlight> are supplied to a frequency table <highlight><bold>71</bold></highlight>. The frequency table <highlight><bold>71</bold></highlight>, a Huffman tree creation unit <highlight><bold>72</bold></highlight>, and a Huffman table creation unit <highlight><bold>73</bold></highlight> executes similar processes as the frequency table creation unit <highlight><bold>31</bold></highlight>, the Huffman tree creation unit <highlight><bold>32</bold></highlight>, and the Huffman table creation unit <highlight><bold>33</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, respectively. </paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> Thus, the frequency table creation unit <highlight><bold>71</bold></highlight> creates a false frequency table, that is, a frequency table for the embedded decoded pixel values of the frame under consideration (not a frequency table for the original pixel values), which is supplied to the reverse translation table creation unit <highlight><bold>54</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 14</cross-reference>). The Huffman table creation unit <highlight><bold>73</bold></highlight> creates a false Huffman table, that is, a Huffman table for translating the embedded decoded pixel values of the frame under consideration into codes having code lengths in accordance with the frequencies of occurrence thereof (not a Huffman table for the original pixel values), which is supplied to the reverse translation table creation unit <highlight><bold>54</bold></highlight>. </paragraph>
<paragraph id="P-0164" lvl="0"><number>&lsqb;0164&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> shows an example construction of the reverse translation table creation unit <highlight><bold>54</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>. </paragraph>
<paragraph id="P-0165" lvl="0"><number>&lsqb;0165&rsqb;</number> As described above, to the reverse translation table creation unit <highlight><bold>54</bold></highlight>, the true Huffman table, the true frequency table, the false Huffman table, and the false frequency table are supplied. Based on these tables, the reverse translation table creation unit <highlight><bold>54</bold></highlight> recognizes the association between the embedded coded data and coded data encoded according to the true Huffman table, and creates a reverse translation table defining the association, as described with reference to FIGS. <highlight><bold>6</bold></highlight> to <highlight><bold>9</bold></highlight>. </paragraph>
<paragraph id="P-0166" lvl="0"><number>&lsqb;0166&rsqb;</number> The true Huffman table and the false Huffman table are supplied to a code association unit <highlight><bold>82</bold></highlight>, while the true frequency table and the false frequency table are supplied to a comparison unit <highlight><bold>81</bold></highlight>. </paragraph>
<paragraph id="P-0167" lvl="0"><number>&lsqb;0167&rsqb;</number> The comparison unit <highlight><bold>81</bold></highlight> compares the true frequency table with the false frequency table to detect, for each code length, pixel values of the same frequency of occurrence in the true frequency table and the false frequency table. Furthermore, the comparison unit <highlight><bold>81</bold></highlight> creates a pixel value association table in which the pixel values of the same frequency in the true frequency table and the false frequency table are associated with each other, and supplies it to the code association unit <highlight><bold>82</bold></highlight>. </paragraph>
<paragraph id="P-0168" lvl="0"><number>&lsqb;0168&rsqb;</number> The code association unit <highlight><bold>82</bold></highlight> searches the true Huffman table and the false Huffman table for the pixel values associated with each other in the pixel value association table supplied from the comparison unit <highlight><bold>81</bold></highlight>, and associates codes respectively associated with the pixel values with each other, thereby creating a reverse translation table. The reverse translation table is supplied to the coding rule restoring unit <highlight><bold>55</bold></highlight>. </paragraph>
<paragraph id="P-0169" lvl="0"><number>&lsqb;0169&rsqb;</number> Now, a decoding process executed by the decoder <highlight><bold>12</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference> will be described with reference to a flowchart shown in <cross-reference target="DRAWINGS">FIG. 18</cross-reference>. </paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> The DEMUX <highlight><bold>51</bold></highlight> demultiplexes data supplied thereto into embedded coded data and information related to Huffman table, supplying the embedded coded data for each frame to the variable-length decoding unit <highlight><bold>52</bold></highlight> and to the coding rule restoring unit <highlight><bold>55</bold></highlight> while supplying the information related to Huffman table to the variable-length decoding unit <highlight><bold>52</bold></highlight>, the reverse translation table creation unit <highlight><bold>54</bold></highlight>, and to the variable-length decoding unit <highlight><bold>56</bold></highlight>. </paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> In step S<highlight><bold>31</bold></highlight>, the variable-length decoding unit <highlight><bold>52</bold></highlight> sequentially considers each frame of the embedded coded data and the information related to Huffman table output from the DEMUX <highlight><bold>51</bold></highlight>, and variable-length decodes the embedded coded data of the frame under consideration. </paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> More specifically, the variable-length decoding unit <highlight><bold>52</bold></highlight> creates a Huffman table (true Huffman table) from a frequency table (true frequency table) constituting the information related to Huffman table of the frame under consideration, and supplies it to the reverse translation table creation unit <highlight><bold>54</bold></highlight>. Furthermore, the variable-length decoding unit <highlight><bold>52</bold></highlight> variable-length decodes the embedded coded data of the frame under consideration according to the true Huffman table, and supplies the resulting embedded decoded pixel values to the Huffman table creation unit <highlight><bold>53</bold></highlight>. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> The process then proceeds to step S<highlight><bold>32</bold></highlight>, in which the Huffman table creation unit <highlight><bold>53</bold></highlight> creates a frequency table (false frequency table) from the embedded decoded pixel values of the frame under consideration, supplied from the variable-length decoding unit <highlight><bold>52</bold></highlight>, and further creates a false Huffman table from the false frequency table. The false frequency table and the false Huffman table are supplied to the reverse translation table creation unit <highlight><bold>54</bold></highlight>. </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> In step S<highlight><bold>33</bold></highlight>, the reverse translation table creation unit <highlight><bold>54</bold></highlight> creates a reverse translation table based on the true Huffman table, the true frequency table constituting the information related to Huffman table, the false Huffman table, and the false frequency table, as described with reference to <cross-reference target="DRAWINGS">FIG. 17</cross-reference>, and supplies it to the coding rule restoring unit <highlight><bold>55</bold></highlight>. </paragraph>
<paragraph id="P-0175" lvl="0"><number>&lsqb;0175&rsqb;</number> In step S<highlight><bold>34</bold></highlight>, the coding rule restoring unit <highlight><bold>55</bold></highlight> decodes the additional information embedded in the embedded coded data, by referencing the association between the embedded coded data and coded data of each code length in the reverse translation table supplied from the reverse translation table creation unit <highlight><bold>54</bold></highlight>, and outputs the resulting decoded additional information. </paragraph>
<paragraph id="P-0176" lvl="0"><number>&lsqb;0176&rsqb;</number> Furthermore, in step S<highlight><bold>35</bold></highlight>, the coding rule restoring unit <highlight><bold>55</bold></highlight> translates the embedded coded data supplied from the DEMUX <highlight><bold>51</bold></highlight> into coded data by referencing the reverse translation table, and supplies it to the variable-length decoding unit <highlight><bold>56</bold></highlight>. </paragraph>
<paragraph id="P-0177" lvl="0"><number>&lsqb;0177&rsqb;</number> The variable-length decoding unit <highlight><bold>56</bold></highlight> creates a true Huffman table from the information related to Huffman table supplied from the DEMUX <highlight><bold>51</bold></highlight>, and variable-length decodes the coded data supplied from the coding rule restoring unit <highlight><bold>55</bold></highlight> based on the true Huffman table, outputting the resulting decoded pixel values. </paragraph>
<paragraph id="P-0178" lvl="0"><number>&lsqb;0178&rsqb;</number> The process then proceeds to step S<highlight><bold>37</bold></highlight>, in which it is determined whether embedded coded data and information related to Huffman table for a next frame has been output from the DEMUX <highlight><bold>51</bold></highlight>. If it is determined that they have been output, with the next frame a new frame to be considered, the process returns to step S<highlight><bold>31</bold></highlight>, repeating the same process. </paragraph>
<paragraph id="P-0179" lvl="0"><number>&lsqb;0179&rsqb;</number> If it is determined in step S<highlight><bold>37</bold></highlight> that embedded coded data and information related to Huffman table for a next frame have not been output from the DEMUX <highlight><bold>51</bold></highlight>, the decoding process is exited. </paragraph>
<paragraph id="P-0180" lvl="0"><number>&lsqb;0180&rsqb;</number> As described earlier, instead of the frequency table, the Huffman table itself may be used as the information related to Huffman table. In that case, however, the Huffman table constituting the information related to Huffman table must be created such that the frequencies of occurrence of pixel values to which codes (coded data) of the same length are assigned can be recognized as being higher or lower relative to each other by referencing the Huffman table (according to a rule that allows such recognition). </paragraph>
<paragraph id="P-0181" lvl="0"><number>&lsqb;0181&rsqb;</number> Furthermore, although Huffman tables are created on a frame basis in the example described above, alternatively, Huffman tables may be created, for example, on a field basis, or on a basis of two or more frames. </paragraph>
<paragraph id="P-0182" lvl="0"><number>&lsqb;0182&rsqb;</number> Furthermore, Huffman tables may be created in advance, for example, using a predetermined image data, so that the embedded compression encoder <highlight><bold>11</bold></highlight> and the decoder <highlight><bold>12</bold></highlight> execute processes according to the Huffman tables created in advance. In that case, however, if Huffman tables created from image data to be processed do not coincide with the Huffman tables created from the predetermined image data, the decoder <highlight><bold>12</bold></highlight> will not be able to restore embedded coded data into coded data. Thus, additional information to be embedded must be limited only to such image data from which the same Huffman tables as those created from the predetermined image data can be obtained. </paragraph>
<paragraph id="P-0183" lvl="0"><number>&lsqb;0183&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> shows another example construction of the embedded compression encoder <highlight><bold>11</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0184" lvl="0"><number>&lsqb;0184&rsqb;</number> To an encoding unit <highlight><bold>91</bold></highlight>, image data to be encoded is supplied. The encoding unit <highlight><bold>91</bold></highlight> encodes the image data according to a predetermined coding rule, outputting the resulting coded data to an embedding unit <highlight><bold>92</bold></highlight>. </paragraph>
<paragraph id="P-0185" lvl="0"><number>&lsqb;0185&rsqb;</number> To the embedding unit <highlight><bold>92</bold></highlight>, additional information is supplied. The embedding unit <highlight><bold>92</bold></highlight> manipulates the coded data supplied from the encoding unit <highlight><bold>91</bold></highlight> based on the additional information to obtain coded data encoded according to a destroyed coding rule, thereby embedding the additional information in the coded data. </paragraph>
<paragraph id="P-0186" lvl="0"><number>&lsqb;0186&rsqb;</number> Now, a process executed by the embedded compression encoder <highlight><bold>11</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference> (embedded coding process) will be described with reference to a flowchart shown in <cross-reference target="DRAWINGS">FIG. 20</cross-reference>. </paragraph>
<paragraph id="P-0187" lvl="0"><number>&lsqb;0187&rsqb;</number> To the encoding unit <highlight><bold>91</bold></highlight>, image data to be encoded is supplied, for example, on a frame basis. The encoding unit <highlight><bold>91</bold></highlight> sequentially considers each frame, and in step S<highlight><bold>41</bold></highlight>, it encodes image data of the frame under consideration according to a predetermined coding rule. The encoding unit <highlight><bold>91</bold></highlight> then outputs the resulting coded data to the embedding unit <highlight><bold>92</bold></highlight>. </paragraph>
<paragraph id="P-0188" lvl="0"><number>&lsqb;0188&rsqb;</number> In step S<highlight><bold>42</bold></highlight>, the embedding unit <highlight><bold>92</bold></highlight> modifies or destroys the coding rule in the encoding unit <highlight><bold>91</bold></highlight> based on the additional information, thereby embedding the additional information. That is, the embedding unit <highlight><bold>92</bold></highlight> manipulates the coded data supplied from the encoding unit <highlight><bold>91</bold></highlight> based on the additional information, thereby embedding the additional information in the coded data. Furthermore, the embedding unit outputs embedded coded data obtained by embedding the additional information in the coded data. The process then proceeds to step S<highlight><bold>43</bold></highlight>. </paragraph>
<paragraph id="P-0189" lvl="0"><number>&lsqb;0189&rsqb;</number> In step S<highlight><bold>43</bold></highlight>, the encoding unit <highlight><bold>91</bold></highlight> determines whether a next frame to be encoded exists. If it is determined that a next frame exists, with the next frame as a new frame to be considered, the process returns to step S<highlight><bold>41</bold></highlight>, repeating the same process. </paragraph>
<paragraph id="P-0190" lvl="0"><number>&lsqb;0190&rsqb;</number> If it is determined in step S<highlight><bold>43</bold></highlight> that no further frame exists to be encoded next, the embedded coding process is exited. </paragraph>
<paragraph id="P-0191" lvl="0"><number>&lsqb;0191&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> shows an example construction of the encoding unit <highlight><bold>91</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>. </paragraph>
<paragraph id="P-0192" lvl="0"><number>&lsqb;0192&rsqb;</number> In the encoding unit <highlight><bold>91</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 21</cross-reference>, for example, if the pixel values constituting image data are represented in RGB (Red, Green, and Blue), each of the pixel values is vector-quantized in the RGB color space, and a code representing a centroid vector (hereinafter referred to as VQ code when appropriate), an error of the pixel value represented by the centroid vector corresponding to the code relative to the original pixel value (hereinafter referred to as VQ residual when appropriate), and a codebook used for the vector quantization are output as coded data. </paragraph>
<paragraph id="P-0193" lvl="0"><number>&lsqb;0193&rsqb;</number> More specifically, image data to be encoded is supplied to a frame memory <highlight><bold>101</bold></highlight>, and the frame memory <highlight><bold>101</bold></highlight> sequentially stores image data supplied thereto, for example, on a frame basis. </paragraph>
<paragraph id="P-0194" lvl="0"><number>&lsqb;0194&rsqb;</number> A codebook creation unit <highlight><bold>102</bold></highlight> sequentially considers each frame of the image data stored in the frame memory <highlight><bold>101</bold></highlight>, and creates a codebook to be used for vector quantization in the color space from the pixel value of each of the pixels constituting the frame under consideration, for example, by what is called the LBG algorithm. The codebook is supplied to a vector quantization unit <highlight><bold>103</bold></highlight>, and is output as (part of) coded data. </paragraph>
<paragraph id="P-0195" lvl="0"><number>&lsqb;0195&rsqb;</number> The vector quantization unit <highlight><bold>103</bold></highlight> reads the frame under consideration from the frame memory <highlight><bold>101</bold></highlight>, and sequentially considers each of the pixels constituting the frame under consideration, for example, in order of raster scanning. The vector quantization unit <highlight><bold>103</bold></highlight> vector-quantizes the pixel value of the pixel under consideration using the codebook supplied from the codebook creation unit <highlight><bold>102</bold></highlight>, outputting the resulting VQ code and VQ residual as (part of) coded data. </paragraph>
<paragraph id="P-0196" lvl="0"><number>&lsqb;0196&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 22</cross-reference>, in the encoding unit <highlight><bold>91</bold></highlight> constructed as described above, the codebook creation unit <highlight><bold>102</bold></highlight> creates a codebook from the pixel value of each of the pixels constituting the frame under consideration, which is supplied to the vector quantization unit <highlight><bold>103</bold></highlight>. The vector quantization unit <highlight><bold>103</bold></highlight> vector-quantizes the pixel value of a pixel under consideration using the codebook supplied from the codebook creation unit <highlight><bold>102</bold></highlight>. </paragraph>
<paragraph id="P-0197" lvl="0"><number>&lsqb;0197&rsqb;</number> That is, the vector quantization unit <highlight><bold>103</bold></highlight> detects, from the codebook, a centroid vector representing a point with the shortest distance to the point on the RGB space represented by the pixel value of the pixel under consideration, outputting a VQ code representing the centroid vector. Furthermore, the vector quantization unit <highlight><bold>103</bold></highlight> calculates the difference between the centroid vector represented by the VQ code and the vector corresponding to the point on the RGB space represented by the pixel value of the pixel under consideration, outputting the resulting difference vector as VQ residual. </paragraph>
<paragraph id="P-0198" lvl="0"><number>&lsqb;0198&rsqb;</number> The encoding unit <highlight><bold>91</bold></highlight> then outputs the codebook, and the VQ code and VQ residual for each of the pixels in the frame under consideration, thus obtained, as coded data associated with the frame under consideration. </paragraph>
<paragraph id="P-0199" lvl="0"><number>&lsqb;0199&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> shows an example construction of the embedding unit <highlight><bold>92</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>, in a case where the encoding unit <highlight><bold>91</bold></highlight> is constructed as shown in <cross-reference target="DRAWINGS">FIG. 21</cross-reference>. </paragraph>
<paragraph id="P-0200" lvl="0"><number>&lsqb;0200&rsqb;</number> The VQ code, VQ residual, and the codebook of the frame under consideration, output from the encoding unit <highlight><bold>91</bold></highlight>, are supplied to and stored in a VQ code memory <highlight><bold>111</bold></highlight>, a VQ residual memory <highlight><bold>112</bold></highlight>, and a codebook memory <highlight><bold>113</bold></highlight>, respectively. </paragraph>
<paragraph id="P-0201" lvl="0"><number>&lsqb;0201&rsqb;</number> The VQ code and the codebook stored respectively in the VQ code memory <highlight><bold>111</bold></highlight> and the codebook memory <highlight><bold>113</bold></highlight> are read therefrom, and supplied to a compression unit <highlight><bold>115</bold></highlight>. </paragraph>
<paragraph id="P-0202" lvl="0"><number>&lsqb;0202&rsqb;</number> A line rotation unit <highlight><bold>114</bold></highlight> sequentially considers each line in the frame under consideration, for example, from top to bottom, and reads the VQ residual of the line under consideration stored in the VQ residual memory <highlight><bold>112</bold></highlight>. Furthermore, letting the number of pixels constituting the line under consideration be denoted by x, the line rotation unit <highlight><bold>114</bold></highlight> receives additional information of the number of bits represented by int&lsqb;log<highlight><subscript>2</subscript></highlight>x&rsqb;, and, for example, as shown in <cross-reference target="DRAWINGS">FIG. 24</cross-reference>, rotates the VQ residual of the line under consideration to the right for the number of bits corresponding to the additional information, thereby embedding the additional information in the line under consideration. That is, with regard to a pixel on the line under consideration, the line rotation basically changes the VQ residual for the pixel from that obtained by the vector quantization, that is, the coding rule for the vector quantization is modified or destroyed. By destroying the coding rule, the additional information is embedded. </paragraph>
<paragraph id="P-0203" lvl="0"><number>&lsqb;0203&rsqb;</number> Then, the line rotation unit <highlight><bold>114</bold></highlight> supplies the VQ residual of the line under consideration with the additional information embedded therein to the compression unit <highlight><bold>115</bold></highlight>. </paragraph>
<paragraph id="P-0204" lvl="0"><number>&lsqb;0204&rsqb;</number> The compression unit <highlight><bold>115</bold></highlight> compresses the VQ code, VQ residual, and codebook supplied thereto, for example, based on spatial correlation or bias of entropy, and outputs the results of the compression to a MUX <highlight><bold>116</bold></highlight>. The MUX <highlight><bold>116</bold></highlight> multiplexes the compressed VQ code, VQ residual, and codebook for output. </paragraph>
<paragraph id="P-0205" lvl="0"><number>&lsqb;0205&rsqb;</number> Now, a process executed by the embedded compression encoder <highlight><bold>11</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference> (embedded coding process), in a case where the encoding unit <highlight><bold>91</bold></highlight> is constructed as shown in <cross-reference target="DRAWINGS">FIG. 21</cross-reference> and the embedding unit <highlight><bold>92</bold></highlight> is constructed as shown in <cross-reference target="DRAWINGS">FIG. 23</cross-reference>, will be described with reference to a flowchart shown in <cross-reference target="DRAWINGS">FIG. 25</cross-reference>. </paragraph>
<paragraph id="P-0206" lvl="0"><number>&lsqb;0206&rsqb;</number> In the encoding unit <highlight><bold>91</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 21</cross-reference>), a predetermined frame stored in the frame memory <highlight><bold>101</bold></highlight> is considered, and in step S<highlight><bold>51</bold></highlight>, each pixel in the frame under consideration is encoded by vector quantization, as described earlier. The VQ code, VQ residual, and codebook, constituting the coded data obtained by vector-quantizing the frame under consideration, are supplied to the embedding unit <highlight><bold>92</bold></highlight>. </paragraph>
<paragraph id="P-0207" lvl="0"><number>&lsqb;0207&rsqb;</number> In the embedding unit <highlight><bold>92</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 23</cross-reference>), the VQ code, VQ residual, and codebook associated with the frame under consideration, supplied from the encoding unit <highlight><bold>91</bold></highlight>, are supplied to and stored in the VQ code memory <highlight><bold>111</bold></highlight>, the VQ residual memory <highlight><bold>112</bold></highlight>, and the codebook memory <highlight><bold>113</bold></highlight>, respectively. In step S<highlight><bold>52</bold></highlight>, the line rotation unit <highlight><bold>114</bold></highlight> determines whether all the lines of the frame under consideration for which a VQ residual is stored in the VQ residual memory <highlight><bold>112</bold></highlight> have been processed. </paragraph>
<paragraph id="P-0208" lvl="0"><number>&lsqb;0208&rsqb;</number> If it is determined in step S<highlight><bold>52</bold></highlight> that all the lines of the frame under consideration for which a VQ residual is stored in the VQ residual memory <highlight><bold>112</bold></highlight> have not been processed yet, the line rotation unit <highlight><bold>114</bold></highlight> selects the uppermost one of the lines yet to be processed in the frame under consideration as a new line to be considered. The process then proceeds to step S<highlight><bold>53</bold></highlight>. </paragraph>
<paragraph id="P-0209" lvl="0"><number>&lsqb;0209&rsqb;</number> In step S<highlight><bold>53</bold></highlight>, the line rotation unit <highlight><bold>114</bold></highlight> rotates each of the pixels in the line under consideration, having VQ residuals as pixel values, to the right for the number of pixels corresponding to the additional information, thereby embedding the additional information in the line under consideration, and supplies the result to the compression unit <highlight><bold>115</bold></highlight>. The process then returns to step S<highlight><bold>52</bold></highlight>, repeating the same process. </paragraph>
<paragraph id="P-0210" lvl="0"><number>&lsqb;0210&rsqb;</number> If it is determined in step S<highlight><bold>52</bold></highlight> that all the lines of the frame under consideration for which a residual is stored in the VQ residual memory <highlight><bold>112</bold></highlight> have been processed, the process proceeds to step S<highlight><bold>54</bold></highlight>, in which the compression unit <highlight><bold>115</bold></highlight> reads the VQ code of the frame under consideration stored in the VQ code memory <highlight><bold>111</bold></highlight>, and also reads the codebook for the frame under consideration stored in the codebook memory <highlight><bold>113</bold></highlight>. In step S<highlight><bold>54</bold></highlight>, the compression unit <highlight><bold>115</bold></highlight> compresses the VQ code and the codebook, and the VQ residual with the additional information embedded therein, supplied from the line rotation unit <highlight><bold>114</bold></highlight>, and supplies the results to the MUX <highlight><bold>116</bold></highlight>. </paragraph>
<paragraph id="P-0211" lvl="0"><number>&lsqb;0211&rsqb;</number> In step S<highlight><bold>55</bold></highlight>, the MUX <highlight><bold>116</bold></highlight> multiplexes the VQ code, VQ residual, and codebook supplied from the compression unit <highlight><bold>115</bold></highlight> for output. The process then proceeds to step S<highlight><bold>56</bold></highlight>. </paragraph>
<paragraph id="P-0212" lvl="0"><number>&lsqb;0212&rsqb;</number> In step S<highlight><bold>56</bold></highlight>, it is determined whether a next frame to be encoded in the encoding unit <highlight><bold>91</bold></highlight> exists. If it is determined that a next frame exists, with the next frame to be encoded as a new frame to be considered, the process returns to step S<highlight><bold>51</bold></highlight>, repeating the same process. </paragraph>
<paragraph id="P-0213" lvl="0"><number>&lsqb;0213&rsqb;</number> If it is determined in step S<highlight><bold>56</bold></highlight> that no further frame exists to be encoded next, the embedded coding process is exited. </paragraph>
<paragraph id="P-0214" lvl="0"><number>&lsqb;0214&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 26</cross-reference> shows an example construction of the decoder <highlight><bold>12</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, in a case where the embedded compression encoder <highlight><bold>11</bold></highlight> is constructed as shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>. </paragraph>
<paragraph id="P-0215" lvl="0"><number>&lsqb;0215&rsqb;</number> The embedded coded data output from the embedding unit <highlight><bold>92</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is supplied to a coding rule restoring unit <highlight><bold>121</bold></highlight>. </paragraph>
<paragraph id="P-0216" lvl="0"><number>&lsqb;0216&rsqb;</number> The coding rule restoring unit <highlight><bold>121</bold></highlight> restores (decodes) the embedded coded data into the coded data encoded according to the coding rule in the encoding unit <highlight><bold>91</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>, thereby decoding the additional information embedded in the embedded coded data. </paragraph>
<paragraph id="P-0217" lvl="0"><number>&lsqb;0217&rsqb;</number> That is, the coding rule restoring unit <highlight><bold>121</bold></highlight> manipulates the embedded coded data based on a parameter supplied from a parameter controller <highlight><bold>124</bold></highlight>, thereby obtaining a candidate of the coded data (hereinafter referred to as tentative coded data when appropriate). Furthermore, the coding rule restoring unit <highlight><bold>121</bold></highlight> obtains a candidate of the additional information (hereinafter referred to as tentative decoded additional information) embedded in the embedded coded data, based on an operation for restoring the embedded coded data into the tentative coded data. The tentative coded data is supplied to a decoding unit <highlight><bold>122</bold></highlight> and to a determination unit <highlight><bold>123</bold></highlight>, while the tentative decoded additional information is supplied to the determination unit <highlight><bold>123</bold></highlight>. </paragraph>
<paragraph id="P-0218" lvl="0"><number>&lsqb;0218&rsqb;</number> The decoding unit <highlight><bold>122</bold></highlight> performs a decoding operation upon the tentative coded data supplied from the coding rule restoring unit <highlight><bold>121</bold></highlight>, based on the coding rule in the encoding unit <highlight><bold>91</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>, thereby obtaining a candidate of the original pixel value (hereinafter referred to as tentative decoded pixel value when appropriate). The tentative decoded pixel value is supplied to the determination unit <highlight><bold>123</bold></highlight>. </paragraph>
<paragraph id="P-0219" lvl="0"><number>&lsqb;0219&rsqb;</number> The determination unit <highlight><bold>123</bold></highlight> controls the parameter controller <highlight><bold>124</bold></highlight> to supply one or more parameter values to the coding rule restoring unit <highlight><bold>121</bold></highlight>, and determines a correct tentative decoded pixel value (coinciding with the original pixel value) from one or more the tentative decoded pixel values obtained respectively in accordance with the one or more parameter values. Furthermore, the determination unit <highlight><bold>123</bold></highlight> selects, from one or more tentative decoded additional information supplied from the coding rule restoring unit <highlight><bold>121</bold></highlight> respectively in association with the one or more tentative decoded pixel values, the tentative decoded additional information associated with the correct decoded pixel value as correct decoded additional information, outputting the correct decoded pixel value and the tentative decoded additional information as the final results of decoding of pixel value and additional information (decoded pixel value and decoded additional information), respectively. </paragraph>
<paragraph id="P-0220" lvl="0"><number>&lsqb;0220&rsqb;</number> The parameter controller <highlight><bold>124</bold></highlight>, under the control of the determination unit <highlight><bold>123</bold></highlight>, supplies a parameter for manipulating the embedded coded data to the coding rule restoring unit <highlight><bold>121</bold></highlight>. </paragraph>
<paragraph id="P-0221" lvl="0"><number>&lsqb;0221&rsqb;</number> Now, a process executed by the decoder <highlight><bold>12</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 26</cross-reference> (decoding process) will be described with reference to a flowchart shown in <cross-reference target="DRAWINGS">FIG. 27</cross-reference>. </paragraph>
<paragraph id="P-0222" lvl="0"><number>&lsqb;0222&rsqb;</number> Initially, in step S<highlight><bold>61</bold></highlight>, the determination unit <highlight><bold>123</bold></highlight> controls the parameter controller <highlight><bold>124</bold></highlight> to set a parameter to be supplied to the coding rule restoring unit <highlight><bold>121</bold></highlight>. Accordingly, the parameter controller <highlight><bold>126</bold></highlight> supplies a parameter, in accordance with the control by the determination unit <highlight><bold>123</bold></highlight>, to the coding rule restoring unit <highlight><bold>121</bold></highlight>. </paragraph>
<paragraph id="P-0223" lvl="0"><number>&lsqb;0223&rsqb;</number> In step S<highlight><bold>62</bold></highlight>, the coding rule restoring unit <highlight><bold>121</bold></highlight> manipulates the embedded coded data based on the parameter supplied from the parameter controller <highlight><bold>124</bold></highlight>, translating it into the tentative coded data, and supplies the tentative coded data to the decoding unit <highlight><bold>122</bold></highlight> and to the determination unit <highlight><bold>123</bold></highlight>. Furthermore, the coding rule restoring unit <highlight><bold>121</bold></highlight>, based on the operation for restoring the embedded coded data into tentative coded data, that is, the parameter supplied from the parameter controller <highlight><bold>124</bold></highlight>, decodes the additional information embedded in the embedded coded, and supplies the result to the determination unit <highlight><bold>123</bold></highlight> as tentative decoded additional information. </paragraph>
<paragraph id="P-0224" lvl="0"><number>&lsqb;0224&rsqb;</number> In step S<highlight><bold>63</bold></highlight>, the decoding unit <highlight><bold>122</bold></highlight> decodes the tentative coded data supplied from the coding rule restoring unit <highlight><bold>121</bold></highlight> based on the coding rule in the encoding unit <highlight><bold>91</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>, and supplies the resulting pixel value to the determination unit <highlight><bold>123</bold></highlight> as tentative decoded pixel value. </paragraph>
<paragraph id="P-0225" lvl="0"><number>&lsqb;0225&rsqb;</number> In step S<highlight><bold>64</bold></highlight>, the determination unit <highlight><bold>123</bold></highlight> determines whether the tentative decoded pixel value supplied from the decoding unit <highlight><bold>122</bold></highlight> is a correct decoding result (coinciding with the original pixel value). If it is determined as not coinciding, the process returns to step S<highlight><bold>61</bold></highlight>. In this case, in step S<highlight><bold>61</bold></highlight>, the determination unit <highlight><bold>123</bold></highlight> sets a new value as a parameter to be output from the parameter controller <highlight><bold>124</bold></highlight>, and the same process is repeated. </paragraph>
<paragraph id="P-0226" lvl="0"><number>&lsqb;0226&rsqb;</number> If it is determined in step S<highlight><bold>64</bold></highlight> that the tentative decoded pixel value is a correct decoding result, the process proceeds to step S<highlight><bold>65</bold></highlight>, in which the determination unit <highlight><bold>123</bold></highlight> outputs the tentative decoded pixel value as decoded pixel value constituting the result of decoding of the original pixel value. Furthermore, the determination unit <highlight><bold>123</bold></highlight> outputs the tentative decoded additional information associated with the decoded pixel value, as decoded additional information constituting the result of decoding of the additional information embedded. The process then proceeds to step S<highlight><bold>66</bold></highlight>. </paragraph>
<paragraph id="P-0227" lvl="0"><number>&lsqb;0227&rsqb;</number> In step S<highlight><bold>66</bold></highlight>, it is determined whether further embedded coded data to be decoded is remaining. If it is determined as remaining, the process returns to step S<highlight><bold>61</bold></highlight>, repeating the same process for the embedded coded data to be decoded. </paragraph>
<paragraph id="P-0228" lvl="0"><number>&lsqb;0228&rsqb;</number> If it is determined in step S<highlight><bold>66</bold></highlight> that further embedded coded data to be decoded does not exist, the decoding process is exited. </paragraph>
<paragraph id="P-0229" lvl="0"><number>&lsqb;0229&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 28</cross-reference> shows an example construction of the coding rule restoring unit <highlight><bold>121</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 26</cross-reference>, in a case where the embedding unit <highlight><bold>92</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is constructed as shown in <cross-reference target="DRAWINGS">FIG. 23</cross-reference>. </paragraph>
<paragraph id="P-0230" lvl="0"><number>&lsqb;0230&rsqb;</number> Data output from the MUX <highlight><bold>116</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 23</cross-reference> is supplied to a DEMUX <highlight><bold>131</bold></highlight>. The DEMUX <highlight><bold>131</bold></highlight> demultiplexes the data supplied thereto into compressed VQ code, VQ residual, and codebook, and supplies them to an expansion unit <highlight><bold>132</bold></highlight>. The expansion unit <highlight><bold>132</bold></highlight> expands the compressed VQ code, VQ residual, and codebook supplied from the DEMUX <highlight><bold>131</bold></highlight>, and supplies the expanded VQ code, VQ residual, and codebook to a VQ code memory <highlight><bold>133</bold></highlight>, a VQ residual memory <highlight><bold>134</bold></highlight>, and to a codebook memory <highlight><bold>135</bold></highlight>, respectively. </paragraph>
<paragraph id="P-0231" lvl="0"><number>&lsqb;0231&rsqb;</number> The VQ code memory <highlight><bold>133</bold></highlight>, the VQ residual memory <highlight><bold>134</bold></highlight>, and the codebook memory <highlight><bold>135</bold></highlight> store, on a frame basis, the VQ code, VQ residual, and codebook supplied from the expansion unit <highlight><bold>132</bold></highlight>, respectively. </paragraph>
<paragraph id="P-0232" lvl="0"><number>&lsqb;0232&rsqb;</number> A line rotation unit <highlight><bold>136</bold></highlight> sequentially considers each line of the frame stored in the VQ residual memory <highlight><bold>134</bold></highlight>, for example, from top to bottom, and reads the VQ residual of the line under consideration stored in the VQ residual memory <highlight><bold>134</bold></highlight>. Furthermore, letting the number of pixels constituting the line under consideration be denoted by x, the line rotation unit <highlight><bold>136</bold></highlight> receives an integer in a range of zero to x as a parameter from the parameter controller <highlight><bold>124</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 26</cross-reference>), and rotates the VQ residual of the line under consideration to the left for the number of pixels corresponding to the parameter. The line rotation unit <highlight><bold>136</bold></highlight> outputs the VQ residual of each line after the rotation as tentative coded data, together with the VQ code stored in the VQ code memory <highlight><bold>133</bold></highlight> and the codebook stored in the codebook memory <highlight><bold>135</bold></highlight>. </paragraph>
<paragraph id="P-0233" lvl="0"><number>&lsqb;0233&rsqb;</number> Furthermore, the line rotation unit <highlight><bold>136</bold></highlight> outputs the parameter value supplied from the parameter controller <highlight><bold>124</bold></highlight> as tentative decoded additional information. </paragraph>
<paragraph id="P-0234" lvl="0"><number>&lsqb;0234&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 29</cross-reference> shows an example construction of the decoding unit <highlight><bold>122</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 26</cross-reference>, in a case where the encoding unit <highlight><bold>91</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is constructed as shown in <cross-reference target="DRAWINGS">FIG. 21</cross-reference>. </paragraph>
<paragraph id="P-0235" lvl="0"><number>&lsqb;0235&rsqb;</number> The decoding unit <highlight><bold>122</bold></highlight> decodes pixel values by inverse vector quantization based on the VQ code, VQ residual, and codebook of a frame, constituting the coded data supplied from the coding rule restoring unit <highlight><bold>121</bold></highlight>. </paragraph>
<paragraph id="P-0236" lvl="0"><number>&lsqb;0236&rsqb;</number> That is, to an inverse vector quantization unit <highlight><bold>141</bold></highlight>, the VQ code and codebook are supplied. The inverse vector quantization unit <highlight><bold>141</bold></highlight> detects a centroid vector corresponding to the VQ code from the codebook, and supplies the centroid vector to an addition unit <highlight><bold>142</bold></highlight>. To the addition unit <highlight><bold>142</bold></highlight>, as well as the centroid vector supplied from the inverse vector quantization unit <highlight><bold>141</bold></highlight>, a difference vector constituting the VQ residual is also supplied. The addition unit <highlight><bold>142</bold></highlight> adds the centroid vector and the difference vector. The addition unit <highlight><bold>142</bold></highlight> outputs pixel values having the components of the vector obtained by the addition as the R, G, and B values as tentative decoded pixel value. </paragraph>
<paragraph id="P-0237" lvl="0"><number>&lsqb;0237&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 30</cross-reference> shows an example construction of the determination unit <highlight><bold>123</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 26</cross-reference>, in a case where the coding rule restoring unit <highlight><bold>121</bold></highlight> and the decoding unit <highlight><bold>122</bold></highlight> are constructed as shown in <cross-reference target="DRAWINGS">FIGS. 28 and 29</cross-reference>, respectively. </paragraph>
<paragraph id="P-0238" lvl="0"><number>&lsqb;0238&rsqb;</number> To a memory <highlight><bold>151</bold></highlight>, the tentative decoded additional information from the coding rule restoring unit <highlight><bold>121</bold></highlight> and the tentative decoded pixel value from the decoding unit <highlight><bold>122</bold></highlight> are supplied. The memory <highlight><bold>151</bold></highlight> temporarily stores the tentative decoded additional information and the tentative decoded pixel value, and reads the tentative decoded additional information and the tentative decoded pixel value under the control of a true/false determination unit <highlight><bold>154</bold></highlight>, outputting them as decoded additional information and decoded pixel value, respectively. </paragraph>
<paragraph id="P-0239" lvl="0"><number>&lsqb;0239&rsqb;</number> To an encoding unit <highlight><bold>152</bold></highlight>, the codebook included in the tentative coded data output from the coding rule restoring unit <highlight><bold>121</bold></highlight> and the tentative decoded pixel value output from the decoding unit <highlight><bold>122</bold></highlight> are supplied. The encoding unit <highlight><bold>152</bold></highlight> encodes the tentative decoded pixel value similarly to the encoding unit <highlight><bold>91</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>. That is, the encoding unit <highlight><bold>152</bold></highlight> vector-quantizes the tentative decoded pixel value using the codebook supplied from the coding rule restoring unit <highlight><bold>121</bold></highlight>, supplying the resulting VQ code and VQ residual to a comparison unit <highlight><bold>153</bold></highlight>. The VQ code and VQ residual obtained by vector-quantizing the tentative decoded pixel value will hereinafter be referred to, when appropriate, as tentative VQ code and tentative VQ residual, respectively. </paragraph>
<paragraph id="P-0240" lvl="0"><number>&lsqb;0240&rsqb;</number> To the comparison unit <highlight><bold>153</bold></highlight>, as well as the tentative VQ code and tentative VQ residual output from the encoding unit <highlight><bold>152</bold></highlight>, the VQ code and VQ residual included in the tentative coded data output from the coding rule restoring unit <highlight><bold>121</bold></highlight> are supplied. The comparison unit <highlight><bold>153</bold></highlight> compares the tentative VQ code with the VQ code in the tentative coded data, and also compares the tentative VQ residual with the VQ residual in the tentative coded data, supplying the results of the comparisons to the true/false determination unit <highlight><bold>154</bold></highlight>. </paragraph>
<paragraph id="P-0241" lvl="0"><number>&lsqb;0241&rsqb;</number> The true/false determination unit <highlight><bold>154</bold></highlight> controls the parameter controller <highlight><bold>124</bold></highlight> to supply the number of bits for line rotation to the coding rule restoring unit <highlight><bold>121</bold></highlight> as a parameter. Furthermore, the true/false determination unit <highlight><bold>154</bold></highlight> determines whether the tentative decoded pixel value is a correct decoding result based on the result of the comparison of the tentative VQ code and the VQ code in the tentative coded data, and the result of the comparison of the tentative VQ residual and the VQ residual in the tentative coded data, supplied from the comparison unit <highlight><bold>153</bold></highlight>, and controls reading of the tentative decoded pixel value and the tentative decoded additional information from the memory <highlight><bold>151</bold></highlight> based on the result of the determination. </paragraph>
<paragraph id="P-0242" lvl="0"><number>&lsqb;0242&rsqb;</number> Now, the principle of determination by the true/false determination unit <highlight><bold>154</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 30</cross-reference> as to whether the tentative decoded pixel value is a correct decoding result will be described with reference to <cross-reference target="DRAWINGS">FIG. 31</cross-reference>. </paragraph>
<paragraph id="P-0243" lvl="0"><number>&lsqb;0243&rsqb;</number> Since the encoding unit <highlight><bold>91</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 19</cross-reference>) performs vector quantization in the RGB space, a centroid vector used in the vector quantization is composed of three components, namely, R, B, and G components. Letting the centroid vector composed of the R, B, and G components be denoted as (R, G, B), and assuming that each of the R, B, and G components of the centroid vector in the codebook is represented by a multiple of ten for simplicity of description, for example, a pixel value with R, B, and G components of 102, 103, and 99, respectively, (hereinafter denoted as pixel value (102, 103, 99) when appropriate) has the shortest distance relative to a centroid vector (100, 100, 100), and thus is vector-quantized into a VQ code associated with the centroid vector (100, 100, 100). For example, let the VQ code associated with the centroid vector (100, 100, 100) be 0. </paragraph>
<paragraph id="P-0244" lvl="0"><number>&lsqb;0244&rsqb;</number> In this case, subtracting the centroid vector (100, 100, 100) from the pixel value (102, 103, 99) yields the VQ residual (2, 3, &minus;1). Thus, the pixel value (102, 103, 99) is encoded into the VQ code 0 and the VQ residual (2, 3, &minus;1). </paragraph>
<paragraph id="P-0245" lvl="0"><number>&lsqb;0245&rsqb;</number> By inversely vector-quantizing the VQ code 0 and the VQ residual (2, 3, &minus;1), constituting the coded data obtained in the encoding unit <highlight><bold>91</bold></highlight>, as shown in <cross-reference target="DRAWINGS">FIG. 31</cross-reference>(A), the centroid vector (100, 100, 100) associated with the VQ code 0 and the VQ residual (2, 3, &minus;1) are added to yield the pixel value (102, 103, 99), and thus correctly decoded to obtain the original pixel value. </paragraph>
<paragraph id="P-0246" lvl="0"><number>&lsqb;0246&rsqb;</number> Furthermore, by vector-quantizing the decoded pixel value (102, 103, 99) again, as shown in <cross-reference target="DRAWINGS">FIG. 31</cross-reference>(A), the VQ code 0 and the VQ residual (2, 3, &minus;1) are obtained again. </paragraph>
<paragraph id="P-0247" lvl="0"><number>&lsqb;0247&rsqb;</number> From the above, by decoding the VQ code and the VQ residual constituting the coded data to obtain correct decoding result, and re-encoding (vector quantization herein) the decoding result, the VQ code and the VQ residual obtained by the encoding coincide with the VQ code and the VQ residual constituting the coded data, respectively. </paragraph>
<paragraph id="P-0248" lvl="0"><number>&lsqb;0248&rsqb;</number> Of the VQ code 0 and VQ residual (2, 3, &minus;1) constituting the coded data obtained in the encoding unit <highlight><bold>91</bold></highlight>, when additional information is embedded by applying line rotation on the VQ residual (2, 3, &minus;1) in the manner described earlier, VQ residual obtained for a different pixel is assigned as VQ residual between the VQ code 0 and the pixel associated with the VQ residual (2, 3, &minus;1). If, for example, the VQ residual of the different pixel is (10, 11, 12) as shown in <cross-reference target="DRAWINGS">FIG. 31</cross-reference>(B), by adding the centroid vector (100, 100, 100) and the VQ residual (10, 11, 12), the VQ code 0 and the VQ residual (10, 11, 12) are decoded as the pixel value (110, 111, 112), and are not decoded correctly into the original pixel value (102, 103, 99). </paragraph>
<paragraph id="P-0249" lvl="0"><number>&lsqb;0249&rsqb;</number> Thus, even if the incorrect decoded pixel value (110, 111, 112) is vector-quantized again, the resulting VQ code and VQ residual do not coincide with the VQ code 0 and the VQ residual (2, 3, &minus;1) constituting the coded data, respectively, as shown in <cross-reference target="DRAWINGS">FIG. 31</cross-reference>(B). </paragraph>
<paragraph id="P-0250" lvl="0"><number>&lsqb;0250&rsqb;</number> More specifically, in this case, since it is assumed that each of the R, B, and G components of a centroid vector in the codebook is represented by a multiple of ten, the centroid vector with the shortest distance to the pixel value (110, 111, 112) is (110, 110, 110). Thus, for example, assuming that the VQ code representing the centroid vector (110, 110, 110) is 1, the pixel value (110, 111, 112) is vector-quantized into the VQ code 1 and the VQ residual (0, 1, 2) (&equals;(110, 111, 112)&minus;(110, 110, 110)). In this case, neither the VQ code nor the VQ residual coincides with the VQ code or the VQ residual (10, 11, 12) constituting the original coded data. </paragraph>
<paragraph id="P-0251" lvl="0"><number>&lsqb;0251&rsqb;</number> From the above, if the number of pixels for the rotation according to the parameter in the line rotation unit <highlight><bold>136</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 28</cross-reference> does not coincide with the additional information, that is, if the tentative coded data does not coincide with the coded data before the additional information is embedded therein, VQ code and VQ residual obtained by re-encoding the tentative decoded pixel value obtained from the tentative coded data do not coincide respectively with the VQ code and the VQ residual constituting the tentative coded data, and thus the tentative decoded pixel value obtained by decoding the tentative coded data can be determined as incorrect decoding result. </paragraph>
<paragraph id="P-0252" lvl="0"><number>&lsqb;0252&rsqb;</number> On the other hand, if the number of pixels for the rotation according to the parameter in the line rotation unit <highlight><bold>136</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 28</cross-reference> coincides with the additional information, that is, if the tentative coded data coincides with the coded data before the additional information is embedded therein, VQ code and VQ residual obtained by re-encoding the tentative decoded pixel value obtained from the tentative coded data coincide respectively with the VQ code and the VQ residual constituting the tentative coded data, and thus the tentative decoded pixel value obtained by decoding the tentative coded data can be determined as correct decoding result. </paragraph>
<paragraph id="P-0253" lvl="0"><number>&lsqb;0253&rsqb;</number> Now, a decoding process executed by the decoder <highlight><bold>12</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 26</cross-reference>, in a case where the coding rule restoring unit <highlight><bold>121</bold></highlight>, the decoding unit <highlight><bold>122</bold></highlight>, and the determination unit <highlight><bold>123</bold></highlight> are constructed as shown in FIGS. <highlight><bold>28</bold></highlight> to <highlight><bold>30</bold></highlight>, respectively, will be described with reference to a flowchart shown in <cross-reference target="DRAWINGS">FIG. 32</cross-reference>. </paragraph>
<paragraph id="P-0254" lvl="0"><number>&lsqb;0254&rsqb;</number> In the decoding process, the DEMUX <highlight><bold>131</bold></highlight> of the coding rule restoring unit <highlight><bold>121</bold></highlight> demultiplexes data supplied thereto into compressed VQ code, VQ residual, and codebook, supplying them to the expansion unit <highlight><bold>132</bold></highlight>. In step S<highlight><bold>71</bold></highlight>, the expansion unit <highlight><bold>132</bold></highlight> expands the compressed VQ code, VQ residual, and codebook supplied from the DEMUX <highlight><bold>131</bold></highlight>, supplying the expanded VQ code, VQ residual, and codebook to and stores them in the VQ code memory <highlight><bold>133</bold></highlight>, the VQ residual memory <highlight><bold>134</bold></highlight>, and the codebook memory <highlight><bold>135</bold></highlight>, respectively. </paragraph>
<paragraph id="P-0255" lvl="0"><number>&lsqb;0255&rsqb;</number> Then, in step S<highlight><bold>72</bold></highlight>, the true/false determination unit <highlight><bold>154</bold></highlight> of the determination unit <highlight><bold>123</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 30</cross-reference>) controls the parameter controller <highlight><bold>124</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 26</cross-reference>) to set a particular parameter value, and supplies the parameter to the coding rule restoring unit <highlight><bold>121</bold></highlight>. </paragraph>
<paragraph id="P-0256" lvl="0"><number>&lsqb;0256&rsqb;</number> The true/false determination unit <highlight><bold>154</bold></highlight>, for example, sequentially sets integers in a range of zero to the number of pixels on one line as the parameter value, each time the process in step S<highlight><bold>72</bold></highlight> is executed for each line of each frame. </paragraph>
<paragraph id="P-0257" lvl="0"><number>&lsqb;0257&rsqb;</number> When the coding rule restoring unit <highlight><bold>121</bold></highlight> receives the parameter from the parameter controller <highlight><bold>124</bold></highlight>, in step S<highlight><bold>73</bold></highlight>, the line rotation unit <highlight><bold>136</bold></highlight> rotates the VQ residual of the line under consideration to the left for the number of pixels corresponding to the parameter, supplying the VQ residual having been left-rotated, together with the VQ code of the line under consideration stored in the VQ code memory <highlight><bold>133</bold></highlight> and the codebook stored in the codebook memory <highlight><bold>135</bold></highlight>, to the decoding unit <highlight><bold>122</bold></highlight> as tentative coded data. Furthermore, the line rotation unit <highlight><bold>136</bold></highlight> supplies the number of pixels for which the line under consideration is rotated to the determination unit <highlight><bold>123</bold></highlight> as tentative decoded additional information. </paragraph>
<paragraph id="P-0258" lvl="0"><number>&lsqb;0258&rsqb;</number> In step S<highlight><bold>74</bold></highlight>, the decoding unit <highlight><bold>122</bold></highlight> performs inverse vector quantization based on the VQ code, VQ residual, and codebook constituting the tentative coded data supplied from the coding rule restoring unit <highlight><bold>121</bold></highlight>, thereby decoding the pixel values of the line under consideration, and supplies the resulting tentative decoded pixel values to the determination unit <highlight><bold>123</bold></highlight>. </paragraph>
<paragraph id="P-0259" lvl="0"><number>&lsqb;0259&rsqb;</number> In the determination unit <highlight><bold>123</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 30</cross-reference>), the tentative decoded additional information output from the coding rule restoring unit <highlight><bold>121</bold></highlight> and the tentative decoded pixel values output from the coding rule restoring unit <highlight><bold>121</bold></highlight> are stored in the memory <highlight><bold>151</bold></highlight>. Furthermore, in step S<highlight><bold>75</bold></highlight>, in the determination unit <highlight><bold>123</bold></highlight>, the encoding unit <highlight><bold>152</bold></highlight> vector-quantizes the tentative decoded pixel values supplied from the decoding unit <highlight><bold>122</bold></highlight>, and supplies the resulting tentative VQ code and tentative VQ residual to the comparison unit <highlight><bold>153</bold></highlight>. </paragraph>
<paragraph id="P-0260" lvl="0"><number>&lsqb;0260&rsqb;</number> The comparison unit <highlight><bold>153</bold></highlight> compares, for each pixel of the line under consideration, the tentative VQ code supplied from the encoding unit <highlight><bold>152</bold></highlight> with the VQ code constituting the tentative coded data, and also compares the tentative VQ residual supplied from the encoding unit <highlight><bold>152</bold></highlight> with the VQ residual constituting the tentative coded data, supplying the results of the comparisons to the true/false determination unit <highlight><bold>154</bold></highlight>. In step S<highlight><bold>76</bold></highlight>, the true/false determination unit <highlight><bold>154</bold></highlight> determines, for each pixel of the line under consideration, whether the tentative VQ code coincides with the VQ code constituting the tentative coded data, and whether the tentative VQ residual coincides with the VQ residual constituting the tentative coded data. If it is determined that one or neither do not coincide for one or more pixels, that is, if the value of the parameter set in the immediately preceding step S<highlight><bold>72</bold></highlight> does not coincide with the additional information, the process returns to step S<highlight><bold>72</bold></highlight>, in which a new parameter value is set, and the same process is repeated. </paragraph>
<paragraph id="P-0261" lvl="0"><number>&lsqb;0261&rsqb;</number> If it is determined in step S<highlight><bold>76</bold></highlight> that the tentative VQ code coincides with the VQ code constituting the tentative coded data and the tentative VQ residual coincides with the VQ residual constituting the tentative coded data for every pixel of the line under consideration, that is, if the parameter value set in the immediately preceding step S<highlight><bold>72</bold></highlight> coincides with the additional information and if the coded data has been restored and the original additional information has been correctly decoded as the tentative decoded additional information, the process proceeds to step S<highlight><bold>77</bold></highlight>, in which the true/false determination unit <highlight><bold>154</bold></highlight> controls the memory <highlight><bold>151</bold></highlight> to output the tentative decoded pixel value and the tentative decoded additional information of each pixel of the line under consideration, stored therein, as correct decoded pixel value and decoded additional information, respectively. The process then proceeds to step S<highlight><bold>78</bold></highlight>. </paragraph>
<paragraph id="P-0262" lvl="0"><number>&lsqb;0262&rsqb;</number> In step S<highlight><bold>78</bold></highlight>, it is determined whether a line to be decoded next exists. If it is determined that a next line exists, the process returns to step S<highlight><bold>72</bold></highlight>, in which the same process is repeated with the next line to be decoded as a new line to be considered. </paragraph>
<paragraph id="P-0263" lvl="0"><number>&lsqb;0263&rsqb;</number> If it is determined in step S<highlight><bold>78</bold></highlight> that no line exists to be decoded next, the decoding process is exited. </paragraph>
<paragraph id="P-0264" lvl="0"><number>&lsqb;0264&rsqb;</number> The decoding process shown in <cross-reference target="DRAWINGS">FIG. 32</cross-reference> is executed for each frame. </paragraph>
<paragraph id="P-0265" lvl="0"><number>&lsqb;0265&rsqb;</number> As described above, a coding rule for obtaining coded data is destroyed (modified) based on additional information, and embedded coded data encoded according to the destroyed coding rule is manipulated in a predetermined manner, whereby tentative coded data is obtained. The tentative coded data is decoded, and it is determined whether encoding the result of decoding yields the same data as the tentative coded data, so that coded data prior to destruction of the coding rule is restored (decoded). Accordingly, by utilizing the destruction and restoration of the coding rule, additional information can be embedded and decoded without increasing the amount of coded data. </paragraph>
<paragraph id="P-0266" lvl="0"><number>&lsqb;0266&rsqb;</number> The applicant has already proposed, in U.S. patent application Ser. No. 09/636,138, a method for embedding additional information in an image based on, for example, correlation of images. According to the proposed method, for example, lines constituting a frame are exchanged based on additional information, and the lines of the frame that have been exchanged are restored to the original positions based on the fact that adjacent lines in the original frame are highly correlated with each other. Depending on cases, the method based on correlation has not always been successful in embedding additional information. That is, simply put, the method based on correlation, with regard to a line of a frame in which additional information is embedded, exchanges a line adjacent to the line with a line that is most highly correlated with the line under consideration, until all the lines are restored to original positions. However, in some images, a line that is most highly correlated with a line under consideration is not necessarily a line to be positioned adjacent to the line under consideration. When such lines are exchanged by embedding additional information, the lines cannot be restored to original positions based on correlation, inhibiting additional information from being embedded. </paragraph>
<paragraph id="P-0267" lvl="0"><number>&lsqb;0267&rsqb;</number> As opposed thereto, the method described earlier is not subject to such a failure of decoding. </paragraph>
<paragraph id="P-0268" lvl="0"><number>&lsqb;0268&rsqb;</number> In the embodiment shown in <cross-reference target="DRAWINGS">FIG. 26</cross-reference>, the decoder <highlight><bold>12</bold></highlight> includes only a single line of the pair of the coding rule restoring unit <highlight><bold>121</bold></highlight> and the decoding unit <highlight><bold>122</bold></highlight>, sequentially obtaining tentative coded data associated with various parameter values by sequentially changing parameters output from the parameter controller <highlight><bold>124</bold></highlight>; however, for example, as shown in <cross-reference target="DRAWINGS">FIG. 33</cross-reference>, the decoder <highlight><bold>12</bold></highlight> may include M lines of coding rule restoring units <highlight><bold>121</bold></highlight><highlight><subscript>1 </subscript></highlight>to <highlight><bold>121</bold></highlight><highlight><subscript>M </subscript></highlight>and decoding units <highlight><bold>122</bold></highlight><highlight><subscript>1 </subscript></highlight>to <highlight><bold>122</bold></highlight><highlight><subscript>M</subscript></highlight>, supplying different parameter values respectively to the each coding rule restoring units <highlight><bold>121</bold></highlight><highlight><subscript>m </subscript></highlight>(m&equals;1, 2, . . . , M) so that tentative coded data respectively associated with the parameter values can be simultaneously obtained. </paragraph>
<paragraph id="P-0269" lvl="0"><number>&lsqb;0269&rsqb;</number> Furthermore, although the encoding unit <highlight><bold>91</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference> performs vector quantization in the example described above, the encoding unit <highlight><bold>91</bold></highlight> may perform, for example, predictive coding instead of vector quantization. In that case, the embedding unit <highlight><bold>92</bold></highlight> is allowed to embed additional information by manipulating prediction residual associated with predictive coding based on the additional information. </paragraph>
<paragraph id="P-0270" lvl="0"><number>&lsqb;0270&rsqb;</number> Furthermore, although additional information is embedded by rotating VQ residual of each line based on the additional information in the example described above, additional information may also be embedded, for example, by rotating a bit sequence of a value representing the VQ residual. </paragraph>
<paragraph id="P-0271" lvl="0"><number>&lsqb;0271&rsqb;</number> Furthermore, although codebooks are created and included in coded data on a frame basis in the example described above, codebooks may be created in advance and stored in each of the embedded compression encoder <highlight><bold>11</bold></highlight> and the decoder <highlight><bold>12</bold></highlight>. Furthermore, codebooks may be created on a basis of a plurality of frames, or on a basis of a predetermined area of a frame. </paragraph>
<paragraph id="P-0272" lvl="0"><number>&lsqb;0272&rsqb;</number> The series of processes described above may be implemented in hardware or in software. When the series of processes is implemented in software, a program constituting the software is installed, for example, on a general-purpose computer. </paragraph>
<paragraph id="P-0273" lvl="0"><number>&lsqb;0273&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 34</cross-reference> shows an example construction of a computer on which a program for executing the series of processes described above is installed. </paragraph>
<paragraph id="P-0274" lvl="0"><number>&lsqb;0274&rsqb;</number> The program may be stored in advance in a recording medium incorporated in the computer, such as a hard disc <highlight><bold>205</bold></highlight> or a ROM <highlight><bold>203</bold></highlight>. </paragraph>
<paragraph id="P-0275" lvl="0"><number>&lsqb;0275&rsqb;</number> Alternatively, the program may be temporarily or permanently stored (recorded) on a removable storage medium <highlight><bold>211</bold></highlight> such as a floppy disk, a CD-ROM (Compact Disc Read Only Memory), an MO (Magneto optical) disc, a DVD (Digital Versatile Disc), a magnetic disc, or a semiconductor memory. The removable recording medium <highlight><bold>211</bold></highlight> can be provided in the form of what is called package software. </paragraph>
<paragraph id="P-0276" lvl="0"><number>&lsqb;0276&rsqb;</number> Instead of installing the program on the computer from the removable recording medium <highlight><bold>211</bold></highlight> as described above, the program may be transferred by wireless to the computer from a downloading site via an artificial satellite for digital satellite broadcasting, or may be transferred to the computer by wired link via a network such as a LAN (Local Area Network) or the Internet, so that the computer receives the program thus transferred via a communication unit <highlight><bold>208</bold></highlight> and then installs the program in an internal hard disc <highlight><bold>205</bold></highlight>. </paragraph>
<paragraph id="P-0277" lvl="0"><number>&lsqb;0277&rsqb;</number> The computer includes a CPU (Central Processing Unit) <highlight><bold>202</bold></highlight>. To the CPU <highlight><bold>202</bold></highlight>, an input/output interface <highlight><bold>210</bold></highlight> is connected via a bus <highlight><bold>201</bold></highlight>. In response to a command input via the input/output interface <highlight><bold>210</bold></highlight> by a user&apos;s operation on an input unit <highlight><bold>207</bold></highlight> including a keyboard, a mouse, a microphone, etc., the CPU <highlight><bold>202</bold></highlight> executes a program stored in a ROM (Read Only Memory) <highlight><bold>203</bold></highlight> according to the command. Alternatively, the CPU <highlight><bold>202</bold></highlight> loads a program stored in the hard disc <highlight><bold>205</bold></highlight>, a program transferred via a satellite or a network, received via the communication unit <highlight><bold>208</bold></highlight>, and installed on the hard disc <highlight><bold>205</bold></highlight>, or a program read from the removable recording medium <highlight><bold>211</bold></highlight> mounted on a drive <highlight><bold>209</bold></highlight> and installed on the hard disc <highlight><bold>205</bold></highlight>, into a RAM (Random Access Memory) <highlight><bold>204</bold></highlight> for execution. The CPU <highlight><bold>202</bold></highlight> thus executes processes according to the flowcharts described above, or processes executed by the constructions shown in the block diagrams described above. The CPU <highlight><bold>202</bold></highlight>, as required, outputs the results of the processes to an output unit <highlight><bold>206</bold></highlight> including an LCD (Liquid Crystal Display), a speaker, etc., transmits them via the communication unit <highlight><bold>208</bold></highlight>, records them on the hard disc <highlight><bold>205</bold></highlight>, etc., for example, via the input/output interface <highlight><bold>210</bold></highlight>. </paragraph>
<paragraph id="P-0278" lvl="0"><number>&lsqb;0278&rsqb;</number> In this specification, the processing steps constituting programs for executing various processes on a computer need not necessarily be executed sequentially in the order shown in the flowcharts, and may be executed in parallel or individually (e.g., parallel processing or processes based on objects). </paragraph>
<paragraph id="P-0279" lvl="0"><number>&lsqb;0279&rsqb;</number> The program may be executed by a single computer or by distributed processing using a plurality of computers. Furthermore, the program may be transferred to and executed on a remote computer. </paragraph>
<paragraph id="P-0280" lvl="0"><number>&lsqb;0280&rsqb;</number> Although image data is encoded in the embodiment, data to be encoded is not limited to image data, and various data such as audio data and computer programs may be used. </paragraph>
</section>
<section>
<heading lvl="1">INDUSTRIAL APPLICABILITY </heading>
<paragraph id="P-0281" lvl="0"><number>&lsqb;0281&rsqb;</number> According to the first data processing apparatus, data processing method, and storage medium of the present invention, first data is encoded to output coded data. Then, a portion of the coded data is modified based on the second data so that the second data is embedded in the coded data. </paragraph>
<paragraph id="P-0282" lvl="0"><number>&lsqb;0282&rsqb;</number> According to the second data processing apparatus, data processing method, and storage medium of the present invention, a coding table for encoding first data is created, and the coding table created is modified based on second data to create a modified coding table. Then, the first data is encoded based on the modified coding table to generate embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0283" lvl="0"><number>&lsqb;0283&rsqb;</number> According to the fifth data processing apparatus, data processing method, and storage medium of the present invention, first data is encoded according to a coding rule to output coded data. Then, the coding rule is modified based on second data, and the first data is encoded according to the modified coding rule to generate embedded coded data in which the second data is embedded. </paragraph>
<paragraph id="P-0284" lvl="0"><number>&lsqb;0284&rsqb;</number> Thus, the second data can be embedded without increasing the amount of data. </paragraph>
<paragraph id="P-0285" lvl="0"><number>&lsqb;0285&rsqb;</number> According to the third data processing apparatus, data processing method, and storage medium of the present invention, embedded coded data encoded by embedding second data in first data is tentatively decoded based on a coding table to output tentative decoded data. Furthermore, a tentative coding table is created based on the tentative decoded data, and the embedded coded data is decoded based on the coding table and the tentative coding table to obtain first decoded data. The coding table is compared with the tentative coding table to obtain second decoded data. </paragraph>
<paragraph id="P-0286" lvl="0"><number>&lsqb;0286&rsqb;</number> According to the fourth data processing apparatus, data processing method, and storage medium of the present invention, a portion of embedded coded data encoded by embedding second data in first data is modified according to an input parameter, and tentatively decoded based on a coding table to output tentative decoded data. Furthermore, the tentative decoded data is re-encoded to output re-encoded data. The parameter is determined by comparing the embedded coded data and the re-encoded data, and tentative decoded data obtained by tentatively decoding, based on the coding table, the embedded coded data having been partially modified based on the parameter, is output as first decoded data, and for second decoded data corresponding to the parameter is also obtained. </paragraph>
<paragraph id="P-0287" lvl="0"><number>&lsqb;0287&rsqb;</number> According to the sixth data processing apparatus, data processing method, and storage medium of the present invention, embedded coded data obtained by embedding second data in first data is decoded to obtain coded data encoded according to an entropy coding rule and to obtain the second data. Furthermore, the coded data is decoded to obtain the first data. </paragraph>
<paragraph id="P-0288" lvl="0"><number>&lsqb;0288&rsqb;</number> Thus, the first and the second data can be correctly decoded. </paragraph>
<paragraph id="P-0289" lvl="0"><number>&lsqb;0289&rsqb;</number> According to the data processing system of the present invention, in the encoding apparatus, first data is encoded according to a coding rule to output coded data. Then, the coding rule is modified based on second data, and the first data is encoded according to the modified coding rule to generate embedded data in which the second data is embedded. In the decoding apparatus, embedded coded data is decoded to obtain the coded data encoded according to the coding rule and to obtain the second data. Then, the coded data is decoded to obtain the first data. Thus, the second data can be embedded without increasing the amount of coded data obtained by encoding the first data. Furthermore, the data in which the second data is embedded can be correctly decoded to obtain the first and the second data. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A data processing apparatus comprising: 
<claim-text>encoding means for encoding first data to output coded data; and </claim-text>
<claim-text>embedding means for embedding second data in the coded data output from said encoding means by modifying a portion of the coded data based on the second data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, 
<claim-text>wherein said encoding means comprises: 
<claim-text>coding table creation means for statistically analyzing data values included in the first data to create a coding table for encoding the data values into coded data; and </claim-text>
<claim-text>coded data output means for generating and outputting coded data by encoding the first data based on the coding table created by said coding table creation means. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, 
<claim-text>wherein said embedding means comprises: 
<claim-text>translation table creation means for creating a translation table for translating coded data in the coding table created by said coding table creation means, based on the second data; and </claim-text>
<claim-text>embedded coded data generation means for translating the coded data output from said coded data output means based on the translation table created by said translation table creation means to generate embedded coded data in which the second data is embedded. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, 
<claim-text>wherein said coding table creation means comprises: 
<claim-text>frequency table creation means for creating and outputting a frequency table representing the frequency of each data value included in the first data; </claim-text>
<claim-text>Huffman tree creation means for creating and outputting a Huffman tree based on the frequency table output from said the frequency table creation means; and </claim-text>
<claim-text>Huffman table creation means for creating a Huffman table associating each of the data values with the coded data, based on the Huffman tree created by said Huffman tree creation means; </claim-text>
<claim-text>and said coded data output means generates and outputs coded data by encoding the first data based on the Huffman table created by said Huffman table creation means. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, 
<claim-text>wherein said translation table creation means comprises: 
<claim-text>pattern number detection means for detecting the number of patterns of coded data of each code length in the Huffman table created by said Huffman table creation means; and </claim-text>
<claim-text>information amount detection means for detecting the amount of information that can be embedded in coded data of each code length in the Huffman table, based on the number of patterns detected by said pattern number detection means; </claim-text>
<claim-text>and said translation table creation means creates and outputs a translation table in which coded data of each code length in the Huffman table having been modified based on a portion of the second data in accordance with the amount of information detected by said information amount detection means is associated with coded data of each code length prior to the modification. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, 
<claim-text>wherein said embedded coded data generation means comprises code length detection means for detecting the code length of coded data under consideration in the coded data output from said coded data output means; </claim-text>
<claim-text>and said embedded coded data generation means translates the coded data under consideration into embedded coded data for output based on the translation table associated with the code length detected by said code length detection means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, 
<claim-text>wherein said coded data output means comprises quantization means for outputting a quantization code generated by quantizing a data value included in the first data based on the coding table, and a quantization error representing an error between the quantization code and the data value. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, 
<claim-text>wherein said embedding means embeds the second data in the coded data output from said quantization means by modifying a portion of the quantization error based on the second data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, 
<claim-text>wherein said coding table creation means comprises codebook creation means for creating and outputting a codebook including a vector quantization code representing a representative vector of a data value included in the first data; </claim-text>
<claim-text>said quantization means comprises vector quantization means for vector-quantizing each data value included in the first data based on the codebook created by said codebook creation means to output a vector quantization code, and for detecting and outputting a vector quantization error representing the difference between the data value and the representative vector represented by the vector quantization code; </claim-text>
<claim-text>and said embedding means embeds the second data in the coded data output from said vector quantization means by modifying a portion of the vector quantization error based on the second data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00008">claim 8</dependent-claim-reference>, 
<claim-text>wherein said embedding means embeds the second data in the coded data output from said quantization means by rotating a portion of the quantization error based on the second data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A data processing apparatus comprising: 
<claim-text>coding table creation means for creating a coding table for encoding first data; </claim-text>
<claim-text>modified coding table creation means for modifying the coding table created by said coding table creation means based on second data to create a modified coding table; and </claim-text>
<claim-text>embedded coded data generation means for encoding the first data based on the modified coding table to generate embedded coded data in which the second data is embedded. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, 
<claim-text>wherein said coding table creation means statistically analyzes data values included in the first data to create the coding table for encoding the data values into coded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, 
<claim-text>wherein said modified coding table creation means comprises translation table creation means for creating a translation table for translating coded data in the coding table created by said coding table creation means based on the second data, </claim-text>
<claim-text>and said modified coding table creation means creates a modified coding table by translating a portion of the coding table based on the translation table created by said translation table creation means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, 
<claim-text>wherein said coding table creation means comprises: 
<claim-text>frequency table creation means for creating and outputting a frequency table representing a frequency of each data value included in the first data; </claim-text>
<claim-text>Huffman tree creation means for creating and outputting a Huffman tree based on the frequency table output from said frequency table creation means; and </claim-text>
<claim-text>Huffman table creation means for creating a Huffman table associating each data value with the coded data, based on the Huffman tree created by said Huffman tree creation means; </claim-text>
<claim-text>and said modified coding table creation means creates a modified Huffman table by translating a portion of the Huffman table created by said Huffman table creation means. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, 
<claim-text>wherein said translation table creation means comprises: 
<claim-text>pattern number detection means for detecting the number of patterns of coded data of each code length in the Huffman table created by said Huffman table creation means; and </claim-text>
<claim-text>information amount detection means for detecting the amount of information that can be embedded in coded data of the code length in the Huffman table, based on the number of patterns detected by said pattern number detection means; </claim-text>
<claim-text>and said translation table creation means creates and outputs a translation table in which coded data of each code length in the Huffman table having been modified based on a portion of the second data in accordance with the amount of information detected by said information amount detection means is associated with coded data of each code length prior to the modification. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, 
<claim-text>wherein said embedded coded data generation means translates the first data into embedded coded data for output based on the modified Huffman table created by said modified coding table creation means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A data processing apparatus comprising: 
<claim-text>tentative decoding means for tentatively decoding embedded coded data encoded by embedding second data in first data, based on a coding table, to output tentative decoded data; </claim-text>
<claim-text>tentative coding table creation means for creating a tentative coding table based on the tentative decoded data; </claim-text>
<claim-text>first decoded data obtaining means for decoding the embedded coded data based on the coding table and the tentative coding table to obtain first decoded data; and </claim-text>
<claim-text>second decoded data obtaining means for obtaining second decoded data by comparing the coding table with the tentative coding table. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, 
<claim-text>wherein said tentative decoding means comprises: 
<claim-text>Huffman tree creation means for creating a Huffman tree based on a frequency table that is input together with the embedded coded data; and </claim-text>
<claim-text>Huffman table creation means for creating a Huffman table associating a data value in the first data with coded data, based on the Huffman tree created by said Huffman tree creation means; </claim-text>
<claim-text>and said tentative decoding means decodes the embedded coded data based on the Huffman table to output embedded decoded data. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, 
<claim-text>wherein said tentative coding table creation means comprises: 
<claim-text>further frequency table creation means for creating a further frequency table representing the frequency of occurrence of each data value in the embedded decoded data based on the embedded decoded data; </claim-text>
<claim-text>further Huffman tree creation means for creating a further Huffman tree based on the further frequency table created by said further frequency table creation means; and </claim-text>
<claim-text>further Huffman table creation means for creating a further Huffman table associating a data value in the first data with embedded coded data, based on the further Huffman tree created by said further Huffman tree creation means. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, further comprising: 
<claim-text>comparison means for comparing the frequencies in the frequency table and the further frequency table to create a data value association table associating the same data values with each other; and </claim-text>
<claim-text>translation table creation means for creating a modified table associating coded data and embedded coded data respectively associated with the data values associated with each other by the data value association table created by said comparison means, based on the Huffman table and the further Huffman table; </claim-text>
<claim-text>wherein said second decoded data obtaining means obtains the second decoded data based on the association between the coded data and the embedded coded data in the translation table. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, 
<claim-text>wherein said first decoded data obtaining means comprises coded data output means for translating the embedded coded data into coded data based on the association between the coded data and the embedded coded data in the translation table, and for outputting the coded data, </claim-text>
<claim-text>and said first decoded data obtaining means decodes the coded data output from said coded data output means based on the Huffman table to obtain the first decoded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. A data processing apparatus comprising: 
<claim-text>tentative decoding means for modifying a portion of embedded coded data encoded by embedding second data in first data according to an input parameter, and for tentatively decoding it based on a coding table to output tentative decoded data; </claim-text>
<claim-text>re-encoding means for re-encoding the tentative decoded data to output re-encoded data; and </claim-text>
<claim-text>decoding means for determining the parameter by comparing the embedded coded data and the re-encoded data, outputting tentative decoded data as first decoded data, obtained by tentatively decoding, based on the coding table, the embedded coded data having been partially modified by said tentative decoding means based on the parameter, and for obtaining second decoded data corresponding to the parameter. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, 
<claim-text>wherein said tentative decoding means modifies a quantization error of coded data including quantization code and quantization error based on the parameter, and tentatively decodes the coded data based on a coding table to output tentative decoded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference>, 
<claim-text>wherein said tentative decoding means rotates a portion of a vector quantization error of coded data including vector quantization code and vector quantization error based on the parameter, and tentatively decodes it based on a codebook to output tentative decoded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference>, 
<claim-text>wherein said tentative decoding means comprises: 
<claim-text>inverse vector quantization means for decoding the vector quantization code based on the codebook to output inverse vector quantization data; and </claim-text>
<claim-text>addition means for adding the rotated vector quantization error to the inverse vector quantization data output from said inverse vector quantization means to obtain the tentative decoded data. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference>, 
<claim-text>wherein said re-encoding means comprises re-vector quantization means for performing vector quantization to detect, based on the codebook, a tentative vector quantization code representing a representative vector that is most approximate to the tentative decoded data, and for detecting a tentative vector quantization error representing the difference between the tentative decoded data and the representative vector represented by the vector quantization code. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference>, 
<claim-text>wherein said decoding means comprises comparison means for comparing the vector quantization code with the tentative vector quantization code and for comparing the vector quantization error and the tentative vector quantization error, </claim-text>
<claim-text>and when the comparisons by said comparison means result in coincidence, said decoding means outputs second decoded data corresponding to the parameter representing the amount of movement by the rotation of the vector quantization error, and also outputs the tentative decoded data as first decoded data, </claim-text>
<claim-text>whereas when the comparisons do not result in coincidence, said decoding means modifies the parameter representing the amount of movement by the rotation of the vector quantization error, and supplies it to said tentative decoding means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, 
<claim-text>comprising a plurality of said tentative decoding means, to which different parameters are respectively input, </claim-text>
<claim-text>wherein said decoding means selects one of the plurality of said tentative decoding means in accordance with the result of the comparison between the embedded coded data and the re-encoded data, outputting the tentative decoded data output from the selected one of said tentative decoding means as first decoded data, and also outputting second decoded data corresponding to the parameter input to the selected one of said tentative decoding means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. A data processing apparatus comprising: 
<claim-text>encoding means for encoding first data according to a coding rule to output coded data; and </claim-text>
<claim-text>modification means for modifying the coding rule based on second data; </claim-text>
<claim-text>wherein said encoding means encodes the first data according to a coding rule modified by said modification means, thereby generating embedded coded data in which the second data is embedded. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, 
<claim-text>wherein said encoding means performs variable-length encoding according to a coding rule in which each data value included in the first data is assigned a coded data having a length based on the frequency of occurrence of the data value. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 30</dependent-claim-reference>, 
<claim-text>wherein said modification means modifies, based on the second data, coded data associated with data values to which coded data of the same length are assigned. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 31</dependent-claim-reference>, 
<claim-text>wherein said modification means modifies, based on the second data, coded data associated with data values to which coded data of the same length are assigned in a coding table associating each data value with coded data to be assigned to the data value based on the frequency of occurrence of each data value in the first data, thereby modifying the coding table to create a modified table, </claim-text>
<claim-text>and said encoding means generates embedded coded data by encoding the first data according to the modified table. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, 
<claim-text>wherein said modification means manipulates, based on the second data, a quantization code and a quantization error output by quantizing the first data, so that the quantization code and the quantization error cause a mismatch, </claim-text>
<claim-text>and said encoding means outputs the manipulated quantization code and quantization error as embedded coded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, 
<claim-text>wherein the first data is image data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. A data processing apparatus comprising: 
<claim-text>first decoding means for decoding embedded coded data obtained by embedding second data in first data, to obtain coded data encoded according to an entropy coding rule and to obtain the second data; and </claim-text>
<claim-text>second decoding means for decoding the coded data to obtain the first data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 35</dependent-claim-reference>, 
<claim-text>wherein said first decoding means decodes the embedded coded data to obtain coded data variable-length encoded according to an entropy coding rule in which coded data of a length based on the frequency of occurrence of each data value in the first data is assigned. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 36</dependent-claim-reference>, 
<claim-text>wherein said first decoding means modifies coded data associated with each data value in the first data, to which coded data of the same length is assigned, based on the frequency of occurrence of each data value in the first data and the frequency of occurrence of each data value in decoded data obtained by variable-length decoding the embedded coded data, thereby restoring the embedded coded data into the coded data variable-length encoded according to the entropy coding rule. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 37</dependent-claim-reference>, 
<claim-text>wherein said first decoding means comprises translation table creation means for creating a translation table for translating coded data in a coding table for variable-length encoding the first data into coded data, based on the frequency of occurrence of each data value in the first data and the frequency of occurrence of each data value in decoded data obtained by variable-length decoding the embedded coded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00039">
<claim-text><highlight><bold>39</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 35</dependent-claim-reference>, 
<claim-text>wherein said first decoding means decodes the embedded coded data to obtain tentative coded data, </claim-text>
<claim-text>said second decoding means decodes the tentative coded data to output tentative decoded data, </claim-text>
<claim-text>said data processing apparatus further comprising determination means for determining whether the tentative decoded data is correct. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00040">
<claim-text><highlight><bold>40</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 39</dependent-claim-reference>, 
<claim-text>wherein said determination means determines whether the tentative decoded data is correct by encoding the tentative decoded data according to the entropy coding rule. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00041">
<claim-text><highlight><bold>41</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00044">claim 40</dependent-claim-reference>, 
<claim-text>wherein said determination means determines whether the tentative decoded data is correct by comparing re-encoded data obtained by encoding the tentative decoded data according to the entropy coding rule with the tentative coded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00042">
<claim-text><highlight><bold>42</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 39</dependent-claim-reference>, 
<claim-text>wherein said first decoding means decodes the embedded coded data obtained by manipulating, based on the second data, a quantization error of coded data including quantization code and quantization error obtained by quantizing the first data, by manipulating the quantization error, thereby obtaining the tentative coded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00043">
<claim-text><highlight><bold>43</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00044">claim 42</dependent-claim-reference>, 
<claim-text>wherein said determination means determines whether a quantization code and a quantization error constituting the tentative coded data are correct by comparing the quantization code and the quantization error constituting the tentative coded data with a re-quantization code and a re-quantization error obtained by re-quantizing tentative decoded data obtained by decoding the quantization code and the quantization error. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00044">
<claim-text><highlight><bold>44</bold></highlight>. A data processing apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 35</dependent-claim-reference>, 
<claim-text>wherein the first data is image data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00045">
<claim-text><highlight><bold>45</bold></highlight>. A data processing system comprising an encoding apparatus comprising: 
<claim-text>encoding means for encoding first data according to a coding rule to output coded data; and </claim-text>
<claim-text>modification means for modifying the coding rule based on second data; </claim-text>
<claim-text>wherein said encoding means encodes the first data according to a coding rule modified by said modification means to generate embedded data in which the second data is embedded, </claim-text>
<claim-text>said data processing system also comprising a decoding apparatus comprising: 
<claim-text>first decoding means for decoding embedded coded data to obtain the coded data encoded according to the coding rule and to obtain the second data; and </claim-text>
<claim-text>second decoding means for decoding the coded data to obtain the first data. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00046">
<claim-text><highlight><bold>46</bold></highlight>. A data processing method, 
<claim-text>wherein first data is encoded to output coded data, </claim-text>
<claim-text>and a portion of the coded data is modified based on the second data so that the second data is embedded in the coded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00047">
<claim-text><highlight><bold>47</bold></highlight>. A data processing method, 
<claim-text>wherein a coding table for encoding first data is created, </claim-text>
<claim-text>the coding table created is modified based on second data to create a modified coding table, </claim-text>
<claim-text>and the first data is encoded based on the modified coding table to generate embedded coded data in which the second data is embedded. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00048">
<claim-text><highlight><bold>48</bold></highlight>. A data processing method, 
<claim-text>wherein embedded coded data encoded by embedding second data in first data is tentatively decoded based on a coding table to output tentative decoded data, </claim-text>
<claim-text>a tentative coding table is created based on the tentative decoded data, </claim-text>
<claim-text>the embedded coded data is decoded based on the coding table and the tentative coding table to obtain first decoded data, </claim-text>
<claim-text>and the coding table is compared with the tentative coding table to obtain second decoded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00049">
<claim-text><highlight><bold>49</bold></highlight>. A data processing method, 
<claim-text>wherein a portion of embedded coded data encoded by embedding second data in first data is modified according to an input parameter, and tentatively decoded based on a coding table to output tentative decoded data, </claim-text>
<claim-text>the tentative decoded data is re-encoded to output re-encoded data, </claim-text>
<claim-text>and the parameter is determined by comparing the embedded coded data and the re-encoded data, and tentative decoded data obtained by tentatively decoding, based on the coding table, the embedded coded data having been partially modified based on the parameter, is output as first decoded data, and for second decoded data corresponding to the parameter is also obtained. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00050">
<claim-text><highlight><bold>50</bold></highlight>. A data processing method, 
<claim-text>wherein first data is encoded according to a coding rule to output coded data, </claim-text>
<claim-text>the coding rule is modified based on second data, </claim-text>
<claim-text>and the first data is encoded according to the modified coding rule to generate embedded coded data in which the second data is embedded. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00051">
<claim-text><highlight><bold>51</bold></highlight>. A data processing method, 
<claim-text>wherein embedded coded data obtained by embedding second data in first data is decoded to obtain coded data encoded according to an entropy coding rule and to obtain the second data, </claim-text>
<claim-text>and the coded data is decoded to obtain the first data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00052">
<claim-text><highlight><bold>52</bold></highlight>. A storage medium storing a program, 
<claim-text>wherein first data is encoded to output coded data, </claim-text>
<claim-text>and a portion of the coded data is modified based on the second data so that the second data is embedded in the coded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00053">
<claim-text><highlight><bold>53</bold></highlight>. A storage medium storing a program, 
<claim-text>wherein a coding table for encoding first data is created, </claim-text>
<claim-text>the coding table created is modified based on second data to create a modified coding table, </claim-text>
<claim-text>and the first data is encoded based on the modified coding table to generate embedded coded data in which the second data is embedded. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00054">
<claim-text><highlight><bold>54</bold></highlight>. A storage medium storing a program, 
<claim-text>wherein embedded coded data encoded by embedding second data in first data is tentatively decoded based on a coding table to output tentative decoded data, </claim-text>
<claim-text>a tentative coding table is created based on the tentative decoded data, </claim-text>
<claim-text>the embedded coded data is decoded based on the coding table and the tentative coding table to obtain first decoded data, </claim-text>
<claim-text>and the coding table is compared with the tentative coding table to obtain second decoded data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00055">
<claim-text><highlight><bold>55</bold></highlight>. A storage medium storing a program, 
<claim-text>wherein a portion of embedded coded data encoded by embedding second data in first data is modified according to an input parameter, and tentatively decoded based on a coding table to output tentative decoded data, </claim-text>
<claim-text>the tentative decoded data is re-encoded to output re-encoded data, </claim-text>
<claim-text>and the parameter is determined by comparing the embedded coded data and the re-encoded data, and tentative decoded data obtained by tentatively decoding, based on the coding table, the embedded coded data having been partially modified based on the parameter, is output as first decoded data, and for second decoded data corresponding to the parameter is also obtained. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00056">
<claim-text><highlight><bold>56</bold></highlight>. A storage medium storing a program, 
<claim-text>wherein first data is encoded according to a coding rule to output coded data, </claim-text>
<claim-text>the coding rule is modified based on second data, </claim-text>
<claim-text>and the first data is encoded according to the modified coding rule to generate embedded coded data in which the second data is embedded. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00057">
<claim-text><highlight><bold>57</bold></highlight>. A storage medium storing a program, 
<claim-text>wherein embedded coded data obtained by embedding second data in first data is decoded to obtain coded data encoded according to an entropy coding rule and to obtain the second data, </claim-text>
<claim-text>and the coded data is decoded to obtain the first data.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001757A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001757A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001757A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001757A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001757A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001757A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001757A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001757A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001757A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001757A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001757A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030001757A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030001757A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030001757A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030001757A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030001757A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030001757A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030001757A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030001757A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00019">
<image id="EMI-D00019" file="US20030001757A1-20030102-D00019.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00020">
<image id="EMI-D00020" file="US20030001757A1-20030102-D00020.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00021">
<image id="EMI-D00021" file="US20030001757A1-20030102-D00021.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00022">
<image id="EMI-D00022" file="US20030001757A1-20030102-D00022.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00023">
<image id="EMI-D00023" file="US20030001757A1-20030102-D00023.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00024">
<image id="EMI-D00024" file="US20030001757A1-20030102-D00024.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00025">
<image id="EMI-D00025" file="US20030001757A1-20030102-D00025.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00026">
<image id="EMI-D00026" file="US20030001757A1-20030102-D00026.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00027">
<image id="EMI-D00027" file="US20030001757A1-20030102-D00027.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00028">
<image id="EMI-D00028" file="US20030001757A1-20030102-D00028.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00029">
<image id="EMI-D00029" file="US20030001757A1-20030102-D00029.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00030">
<image id="EMI-D00030" file="US20030001757A1-20030102-D00030.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00031">
<image id="EMI-D00031" file="US20030001757A1-20030102-D00031.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00032">
<image id="EMI-D00032" file="US20030001757A1-20030102-D00032.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
