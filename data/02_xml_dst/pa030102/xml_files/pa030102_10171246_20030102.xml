<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001890A1-20030102-D00000.TIF SYSTEM "US20030001890A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00001.TIF SYSTEM "US20030001890A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00002.TIF SYSTEM "US20030001890A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00003.TIF SYSTEM "US20030001890A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00004.TIF SYSTEM "US20030001890A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00005.TIF SYSTEM "US20030001890A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00006.TIF SYSTEM "US20030001890A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00007.TIF SYSTEM "US20030001890A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00008.TIF SYSTEM "US20030001890A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00009.TIF SYSTEM "US20030001890A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00010.TIF SYSTEM "US20030001890A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00011.TIF SYSTEM "US20030001890A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00012.TIF SYSTEM "US20030001890A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00013.TIF SYSTEM "US20030001890A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00014.TIF SYSTEM "US20030001890A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00015.TIF SYSTEM "US20030001890A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00016.TIF SYSTEM "US20030001890A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00017.TIF SYSTEM "US20030001890A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00018.TIF SYSTEM "US20030001890A1-20030102-D00018.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00019.TIF SYSTEM "US20030001890A1-20030102-D00019.TIF" NDATA TIF>
<!ENTITY US20030001890A1-20030102-D00020.TIF SYSTEM "US20030001890A1-20030102-D00020.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001890</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10171246</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020612</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G09G005/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>345</class>
<subclass>753000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Interactive communication between a plurality of users</title-of-invention>
</technical-information>
<continuity-data>
<non-provisional-of-provisional>
<document-id>
<doc-number>60298148</doc-number>
<document-date>20010613</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Glen</given-name>
<middle-name>David</middle-name>
<family-name>Brin</family-name>
</name>
<residence>
<residence-us>
<city>Encinitas</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<correspondence-address>
<name-1>FISH &amp; RICHARDSON, PC</name-1>
<name-2></name-2>
<address>
<address-1>4350 LA JOLLA VILLAGE DRIVE</address-1>
<address-2>SUITE 500</address-2>
<city>SAN DIEGO</city>
<state>CA</state>
<postalcode>92122</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A novel system, method, and computer program for interactive communication among a plurality of users. The invention, called Holocene Conversation Mode (&ldquo;HCM&rdquo;), takes advantage of the observation that human beings have developed or utilize a number of real-world characteristics to participate in, perceive, control, and glean subtleties from conversations. These characteristics include proximity and orientation of a listener to other speakers, memory ageing, emphasis by a speaker, relative importance of a speaker to a listener, reputation of a speaker, and the unique human ability to &ldquo;filter&rdquo; words of special interest to a listener from overheard conversations. HCM includes a suite of techniques, including spatial and content compression as a function of some of such characteristics, that can be implemented in various combinations in computer software. HCM supports other forms of user interaction, such as allowing a user to give or send an object to another user, or to allow a user to take an object from another user. In addition, HCM supports &ldquo;kiosks&rdquo;, in which users can interact with non-human resources in the context of a host-defined environment. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">CROSS-REFERENCE TO RELATED APPLICATION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application claims priority to U.S. Provisional Application No. 60/298,148, filed on Jun. 13, 2001, the contents of which are hereby incorporated by reference into this application as if set forth herein in full.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">RESERVATION OF COPYRIGHTS </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office patent file or records, but otherwise reserves all copyright rights whatsoever. </paragraph>
</section>
<section>
<heading lvl="1">TECHNICAL FIELD </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> This invention relates to computerized communications, and more particularly to a method, system, and computer program for interactive communication among a plurality of users. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND </heading>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Computer-based, on-line communications have become quite popular in recent years. Businesses have joined universities and government institutions in linking up via high-speed data transmission lines, while millions of private citizens have joined in using modems and broadband links that connect their personal computers to networks spanning the globe. Among the many uses of on-line communication, the most important are electronic mail (or &ldquo;email&rdquo;), file transfers, direct use and operation of computers at long range, and real-time conversations (&ldquo;chat&rdquo;) between a plurality of individuals via on-screen exchanges of text, visual, and other information. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a diagram of a typical prior art on-line communication system. Each of a plurality of user terminals <highlight><bold>100</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>100</bold></highlight><highlight><italic>b</italic></highlight>, <highlight><bold>100</bold></highlight><highlight><italic>c </italic></highlight>communicates through corresponding communications channels <highlight><bold>102</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>102</bold></highlight><highlight><italic>b</italic></highlight>, <highlight><bold>102</bold></highlight><highlight><italic>c </italic></highlight>of a network <highlight><bold>104</bold></highlight> to a server computer <highlight><bold>106</bold></highlight>. The user terminals <highlight><bold>100</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>100</bold></highlight><highlight><italic>b</italic></highlight>, <highlight><bold>100</bold></highlight><highlight><italic>c </italic></highlight>may be, for example, personal computers, &ldquo;thin&rdquo; clients, hand-held personal digital assistants, and the like, each typically having a display screen or other output device (e.g., speakers) and at least one input device (e.g., keyboard, mouse, touch pad, and/or microphone). The communications channels <highlight><bold>102</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>102</bold></highlight><highlight><italic>b</italic></highlight>, <highlight><bold>102</bold></highlight><highlight><italic>c </italic></highlight>may be of any conventional type, such as telephone modems, digital subscriber line modems, cable modems, dedicated data transmission lines, or wireless links. The network <highlight><bold>104</bold></highlight> may be a local area network, a wide-area private network (e.g., an &ldquo;intranet&rdquo;), or a wide-area public network (e.g., the Internet). </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> In such a configuration, typical &ldquo;chat room&rdquo; and &ldquo;instant message&rdquo; computer program applications allow two or more users to exchange text through the user terminals <highlight><bold>100</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>100</bold></highlight><highlight><italic>b</italic></highlight>, <highlight><bold>100</bold></highlight><highlight><italic>c</italic></highlight>. Each participant types or otherwise inputs (e.g., &ldquo;pastes&rdquo; from another source) text into a screen or &ldquo;window&rdquo; of a user terminal. This information typically is transmitted to the server <highlight><bold>106</bold></highlight> operating under a &ldquo;host&rdquo; protocol. The server <highlight><bold>106</bold></highlight> redistributes the input text to all participants. Most host protocols are programmed to cause the text lines to appear on a user terminal display screen for all participants. This creates the illusion that the users are participating in a conversation. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> In most cases, the text sent by each participant is handled on a line-by-line basis. <cross-reference target="DRAWINGS">FIG. 2A</cross-reference> is a diagram of a typical prior art window-based chat room showing the procession of text input by two participants, P1 and P2. Each participant inputs text within an associated text editing control <highlight><bold>200</bold></highlight> (in this example, an edit cursor bar <highlight><bold>201</bold></highlight> for P1&apos;s input is shown in mid-word). All of the text input by all participants appears in a conversation window <highlight><bold>202</bold></highlight>. All participants in this particular chat room, not just P1 and P2, would see the conversation shown in the example. Further contributions are added sequentially to the bottom of the conversation window <highlight><bold>202</bold></highlight>, in the order that the server computer <highlight><bold>106</bold></highlight> receives them. Meanwhile, earlier lines scroll &ldquo;upward&rdquo; and eventually disappear off the top of each user&apos;s window or screen display. A scroll bar <highlight><bold>204</bold></highlight> may be provided to review prior conversations that have scrolled out of the conversation window <highlight><bold>202</bold></highlight>. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> In the case of a slow, thoughtful conversation, comments and responses can follow one another in an orderly manner, giving a reasonable simulation of a real world conversation. Unfortunately, most on-line conversations are seldom orderly. In fact, problems with prior art chat systems become apparent soon after a user logs onto almost any chat session, bulletin board, or conference forum. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> An immediately apparent problem is interruption. <cross-reference target="DRAWINGS">FIG. 2B</cross-reference> is a diagram of a typical prior art window-based chat room showing the interrupted procession of text input by three participants, P1, P2, and P3. Starting from the top of the conversation window <highlight><bold>202</bold></highlight>, after P1 inputs a first line of text, P2 begins to input text, but before P2 is done, P3 replies to P1&apos;s question. P2&apos;s response then appears. The result can be that three participants hold two simultaneous, intertwined (and thus confusing) conversations. In many chat rooms, the number of participants can rise to one or two dozen, resulting in a visual cacophony of mutual interruptions and parallel conversations that are shuffled together like a randomized deck of cards. However, such interrupted conversations may occur with only two participants. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> None of the known chat systems take any significant advantage of the many techniques human beings have developed for participating in, perceiving, controlling, or gleaning subtleties from real-life conversations. Present systems simply ignore a wide range of talents already possessed by most users that enable them to process information efficiently in daily life. These drawbacks contribute to inefficiency, user fatigue, and interpersonal misunderstandings. The present invention addresses these problems. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY </heading>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The invention provides a novel system, method, and computer program for interactive communication among a plurality of users. The invention, called Holocene Conversation Mode (&ldquo;HCM&rdquo;), takes advantage of the observation that human beings have developed or utilize a number of real-world characteristics to participate in, perceive, control, and glean subtleties from conversations. These characteristics include proximity and orientation of a listener to other speakers, memory ageing, emphasis by a speaker, relative importance of a speaker to a listener, reputation of a speaker, and the unique human ability to &ldquo;filter&rdquo; words of special interest to a listener from overheard conversations of many other speakers. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> More particularly, the invention encompasses a computer-based emulation&mdash;and extension&mdash;of some or all of the following characteristics of natural spoken conversations, such as the type encountered while standing in a room filled with people holding a variety of discussions: </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Proximity&mdash;Distance or proximity is a good indication of the priority that a listener wants to give to the conversation of another person. One aspect of the invention allows each listener to move towards or away from a speaker. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Orientation&mdash;A listener has the option of changing orientation with respect to a speaker in order to pay closer attention. However, a listener can still track conversations occurring outside the listener&apos;s direct view (direction of attention). One aspect of the invention allows each listener to turn towards or away from a speaker. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> Memory Ageing&mdash;Memory ageing is the tendency to selectively let go of short term memories, allowing minor details to be forgotten while holding onto anything that the listener regards as important, unusually noteworthy, or otherwise special to the listener. One aspect of the invention allows older text to be compressed in a manner that mimics memory ageing. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Selective Filtering &amp; Flagging&mdash;One aspect of the invention extends natural human abilities to filter and select conversations by automatically providing filter terms and/or by allowing a user to define and optionally weight key words or phrases to allow computer-assisted filtering of the content of other users&apos; conversations. Other forms of selective filtering and flagging are based on user-defined importance terms, emphasis expressed by other speakers, and the reputation of other speakers. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> HCM includes a suite of techniques that can be implemented in various combinations in computer software. HCM provides users who participate in real-time computerized conversation forums with an interface that is much improved over present chat systems. These improvements are based upon emulating and extending many of the characteristics that humans for ages have found useful in the real-life world of spoken words and auditory conversation. These techniques allow the conveyance on-screen of much more information than can currently be made available by scrolling lines of text alone, eliminating or reducing the problems inherent in present chat systems. In addition, HCM supports other forms of user interaction, such as allowing a user to give or send an object (e.g., a symbol, token, video segment, file, etc.) to another user, or to allow a user to take an object from another user. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> HCM also can be tailored to suit the needs of specialized groups. For example, HCM can provide a more controlled approach in the context of a formal business meeting, or a map-based method of virtual movement ideal for certain types of games. In addition, HCM supports &ldquo;kiosks&rdquo;, in which users can interact with non-human resources in the context of a host-defined environment. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In particular, embodiments of the invention include a &ldquo;conversation display space&rdquo; or &ldquo;conversation display universe&rdquo; or &ldquo;cosmos&rdquo; that encompasses all user conversations. Each user is assigned a &ldquo;conversation space&rdquo; or &ldquo;user space&rdquo; within the conversation display space. A user may move an assigned user space within the conversation display universe using any convenient control. Such movement may be user-centric or display-space centric. Each user space includes a content area that displays text and/or non-text information entered by a user when &ldquo;speaking&rdquo;. The user can add emphasis to content in the form of perception attributes. Each user space also includes an orientation control that is used to direct and indicate the orientation of a user when listening to other users, thereby defining the user&apos;s primary direction of attention. The orientation control may be separate from a user space or integrated with the user space. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Other aspects of the invention include: </paragraph>
<paragraph id="P-0021" lvl="2"><number>&lsqb;0021&rsqb;</number> moving user spaces relative to one another; </paragraph>
<paragraph id="P-0022" lvl="2"><number>&lsqb;0022&rsqb;</number> changing a user space&apos;s primary direction of attention; </paragraph>
<paragraph id="P-0023" lvl="2"><number>&lsqb;0023&rsqb;</number> varying the size of user spaces as function of: distance; orientation (sole or mutual); reputation; time; and time and selected comparison terms; </paragraph>
<paragraph id="P-0024" lvl="2"><number>&lsqb;0024&rsqb;</number> varying the size of the content of user spaces as function of: distance; orientation (sole or mutual); and time; </paragraph>
<paragraph id="P-0025" lvl="2"><number>&lsqb;0025&rsqb;</number> varying the content of user spaces as a function of: distance; orientation (sole or mutual); reputation; time; and time and selected comparison terms; </paragraph>
<paragraph id="P-0026" lvl="2"><number>&lsqb;0026&rsqb;</number> flagging user spaces and/or their content (and optionally &ldquo;paging&rdquo; a user) as a function of: selected comparison terms; reputation; and emphasis applied by other users; </paragraph>
<paragraph id="P-0027" lvl="2"><number>&lsqb;0027&rsqb;</number> allowing object transference between user spaces, or between a user space and a kiosk object; </paragraph>
<paragraph id="P-0028" lvl="2"><number>&lsqb;0028&rsqb;</number> providing a &ldquo;whisper&rdquo; mode such that input by each user in a &ldquo;private&rdquo; conversation is displayed only to other members of the privacy group; </paragraph>
<paragraph id="P-0029" lvl="2"><number>&lsqb;0029&rsqb;</number> providing a number of optional modes of operation and/or implementation. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> Various embodiments of the invention include a method, program, or apparatus for: </paragraph>
<paragraph id="P-0031" lvl="2"><number>&lsqb;0031&rsqb;</number> interactive communication between a plurality of users, including: displaying a conversation display space having at least two dimensions; displaying a plurality of orientation controls, each having a corresponding user space, within the conversation display space; enabling a user to move or reorient an associated orientation control relative to at least one other orientation control within the conversation display space; and enabling communication of content between at least two user spaces corresponding to such orientation controls; </paragraph>
<paragraph id="P-0032" lvl="2"><number>&lsqb;0032&rsqb;</number> interactive communication between a plurality of users, including: displaying a conversation display space having at least two dimensions; displaying a plurality of user spaces within the conversation display space; enabling a user to move or reorient an associated user space relative to at least one other user space within the conversation display space; and enabling communication of content between at least two user spaces; </paragraph>
<paragraph id="P-0033" lvl="2"><number>&lsqb;0033&rsqb;</number> interactive communication between a plurality of users, including: displaying a conversation display universe; displaying, within the conversation display universe, a corresponding user space for each of a plurality of users; enabling each user to input content within the user space corresponding to such user, and communicating such content to the corresponding user space of at least one other user; and for at least one user, displaying selected amounts of content communicated by each other user within the user space corresponding to each such other user; </paragraph>
<paragraph id="P-0034" lvl="2"><number>&lsqb;0034&rsqb;</number> interactive communication between a plurality of users, including: displaying a conversation display universe; displaying, within the conversation display universe, a corresponding user space for each of a plurality of users; enabling each user to input content within the user space corresponding to such user, and communicating such content to the corresponding user space of at least one other user; for at least one user, displaying the content communicated by each other user within the user space corresponding to each such other user; and selectively varying the size of such content; </paragraph>
<paragraph id="P-0035" lvl="2"><number>&lsqb;0035&rsqb;</number> interactive communication between a plurality of users, including: displaying a conversation display universe; displaying, within the conversation display universe, a corresponding user space for each of a plurality of users; enabling each user to input content within the user space corresponding to such user, and communicating such content to the corresponding user space of at least one other user; and varying the size of the user spaces; </paragraph>
<paragraph id="P-0036" lvl="2"><number>&lsqb;0036&rsqb;</number> interactive communication between a plurality of users, including: displaying a conversation display universe; displaying, within the conversation display universe, a corresponding user space for each of a plurality of users; enabling each user to input content within the user space corresponding to such user, and communicating such content to the corresponding user space of at least one other user; and applying filtering criteria to select at least one user space; </paragraph>
<paragraph id="P-0037" lvl="2"><number>&lsqb;0037&rsqb;</number> interactive communication, including: displaying a conversation display space having at least two dimensions; displaying at least one orientation control, each having a corresponding user space, within the conversation display space; displaying at least one kiosk within the conversation display space; enabling a user to move or reorient an associated orientation control relative to the at least one kiosk within the conversation display space; and enabling interaction between the user space corresponding to the orientation control associated with such user and a kiosk; </paragraph>
<paragraph id="P-0038" lvl="2"><number>&lsqb;0038&rsqb;</number> interactive communication, including: displaying a conversation display space having at least two dimensions; displaying at least one user space within the conversation display space; displaying at least one kiosk within the conversation display space; enabling a user to move or reorient an associated user space relative to the at least one kiosk within the conversation display space; and enabling interaction between the user space associated with such user and a kiosk. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> The details of one or more embodiments of the invention are set forth in the accompanying drawings and the description below. Other features, objects, and advantages of the invention will be apparent from the description and drawings, and from the claims.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">DESCRIPTION OF DRAWINGS </heading>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a diagram of a typical prior art on-line communication system. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2A</cross-reference> is a diagram of a typical prior art window-based chat room showing the procession of text input by two participants. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2B</cross-reference> is a diagram of a typical prior art window-based chat room showing the interrupted procession of text input by three participants. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3A</cross-reference> is a diagram of one embodiment of the invention, showing a conversation display space and a user space. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3B</cross-reference> is a diagram of a user space having a second type of movable orientation control. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3C</cross-reference> is a diagram of a user space having a third type of orientation control. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3D</cross-reference> is a diagram of a user space having a fourth type of movable orientation control. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> is a table showing an example of storage of a user&apos;s conversation status. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> is a table showing an example of storage of a user&apos;s conversation content information. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5A</cross-reference> is a diagram showing a conversation display space with four user spaces. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5B</cross-reference> is the diagram of <cross-reference target="DRAWINGS">FIG. 5A</cross-reference> at a subsequent time. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6A</cross-reference> is a diagram of a conversation display space as seen by a first user. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is a diagram of the same conversation display space of <cross-reference target="DRAWINGS">FIG. 6</cross-reference>A, but as seen by a second user. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a diagram showing an optional &ldquo;world view&rdquo; of a conversation display space as seen from a user-centric viewpoint. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a diagram of a user-centric view showing reduction in user space size as a function of distance and/or orientation from a central user. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a diagram of a user-centric view showing content area compression as well as user space compression. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a diagram showing a conversation between two users. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a diagram of a control dialog that allows a user to select various combinations of functions to apply during a forum session. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a diagram of a conversation transcript. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a diagram of a conversation display space in which the user space for one user is near and focused on a kiosk. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a diagram showing an embodiment of the invention in which all user spaces are docked along the edges of a conversation display space, and only the associated orientation controls are moved and reoriented. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is a diagram showing an embodiment of the invention in which all orientation controls are docked along the edges of a conversation display space, and only the user spaces are moved. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a screen shot of another embodiment of the invention in which several user spaces are shown arrayed around a central user&apos;s orientation control within a conversation display space.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> Like reference symbols in the various drawings indicate like elements. </paragraph>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0064" lvl="7"><number>&lsqb;0064&rsqb;</number> Overview </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> The invention provides a novel system, method, and computer program for interactive communication among a plurality of users. The invention, called Holocene Conversation Mode (&ldquo;HCM&rdquo;), takes advantage of the observation that human beings have developed or utilize a number of real-world characteristics to participate in, perceive, control, and glean subtleties from conversations. These characteristics include proximity and orientation of a listener to other speakers, memory ageing, emphasis by a speaker, relative importance of a speaker to a listener, reputation of a speaker, and the unique human ability to &ldquo;filter&rdquo; words of special interest to a listener from overheard conversations of many other speakers. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> More particularly, the invention encompasses a computer-based emulation&mdash;and extension&mdash;of some or all of the following characteristics of natural spoken conversations, such as the type encountered while standing in a room filled with people holding a variety of discussions: </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Proximity&mdash;In real life, each listener is at some distance from each speaker. The conversation of nearer speakers is better heard, while only snippets of conversation of more distant speakers may be perceived. A listener has the option of increasing or decreasing the distance to a speaker. Thus, distance or proximity is a good indication of the priority that a listener wants to accord to a speaker. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> Known chat systems basically ignore this characteristic. At best, this characteristic can only be crudely approximated in present chat systems by exiting one chat session and entering or creating another session, after arranging in advance to rendezvous with other interested parties in that alternative session. This approach involves an all-or-nothing decision, unlike most real-life situations, where a listener&apos;s attention can be divided between two or more simultaneous conversations, with the listener&apos;s attention moving back and forth at will. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Orientation&mdash;In real life conversation environments, each listener has some orientation to each speaker. Conversations in front of a listener are better perceived then conversations to the side of or behind a listener. A listener has the option of changing orientation with respect to a speaker in order to pay closer attention. However, a listener can still track conversations occurring outside the listener&apos;s direct view (direction of attention). Known chat systems ignore this characteristic. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The characteristics of proximity and orientation can be used to control the size of displayed content of other users, and the display space for such content. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> Memory Ageing&mdash;In real life conversation, listeners retain memory of things that were said recently, and refer to them mentally as they follow a train of argument or prepare a response. Memory ageing is the tendency to selectively let go of short term memories, allowing minor details to be forgotten while holding onto anything that the listener regards as important, unusually noteworthy, or otherwise special to the listener. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> In present chat systems, lines of text scroll upward toward the top of a user&apos;s display. A primitive type of &ldquo;ageing&rdquo; information is therefore apparent at sight&mdash;lines that are higher on the display are older. If the chat system includes a scrolling control, older off-screen lines may be recalled and reviewed; otherwise, when a line disappears at the top of the display, it is forever lost. In any case, a user must review all of the prior text to find an item of interest, since such systems are not capable of selectively culling less valuable verbiage and retaining only text of importance to the user. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> Memory ageing can be used to control the size of displayed content of other users, and the display space for such content. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> Selective Filtering &amp; Flagging&mdash;In real life, a listener&apos;s attention varies non-linearly. Although a listener pays closer attention to speakers standing nearby compared to more distant speakers, it is still quite possible for a listener to pick up and take notice of special turns of phrase uttered at a distance. For example, many listeners can hear and notice their name mentioned by speakers holding conversations quite some distance away, even if no other words catch the listeners&apos; attention. One aspect of the invention extends this ability by automatically providing filter terms (such as the user&apos;s name) and/or by allowing a user to define and optionally weight key words or phrases to allow computer-assisted filtering of the content of other users&apos; conversations. Such filtering may be &ldquo;positive&rdquo; (i.e., using filter terms to select conversations of interest) or &ldquo;negative&rdquo; (i.e., using filter terms to suppress or censor conversations). </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> One form of selective filtering is based on importance. People tend to pay more attention to speakers that the listener rates as more important. &ldquo;Importance&rdquo; is a subjective determination made by each listener. However, importance usually includes, as component factors, the speaker&apos;s &ldquo;external&rdquo; (i.e., real world) reputation, the speaker&apos;s &ldquo;internal&rdquo; (i.e., chat room or forum) reputation, the topic of the speaker&apos;s conversations, and the affinity of the listener to the speaker. Thus, a listener may pay attention to (i.e., select) a conversation of a more important speaker over a less important speaker. One aspect of the invention extends this ability by allowing a user to define and weight importance factors to allow computer-assisted filtering of a group of conversations. Known chat systems ignore this characteristic, although users can subjectively determine the importance of other &ldquo;speakers&rdquo;. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> Another form of selective filtering is based on emphasis expressed by other speakers. For example, in real life, speakers can emphasize points of discussion by speaking louder, stressing words or phrases, changing tone, gesturing, etc. Listeners may respond to such emphasis by giving their attention to one speaker over another, in essence using perceived emphasis as a conversation selection mechanism. While some present chat systems allow a user to change type characteristics or attributes (e.g., typeface, point size, weight, style, color) in messages composed by the user, they are not known to utilize such type characteristics as a way of allowing the user to select other conversations to join or allowing such characteristics to actively affect a filtered version of the conversation. One aspect of the invention allows each speaker to use such type characteristics or attributes to indicate emphasis, and extends the concept by using emphasis to allow computer-assisted filtering of a group of conversations. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> Another form of selective filtering is based on the reputation of other users. In real life, listeners tend to pay attention to speakers having a high reputation. One aspect of the invention extends this characteristic by allowing assignment (manually or automatically) of reputation scores to speakers and flagging speakers having selected scores. Further extensions allow a speaker&apos;s reputation (or &ldquo;charisma&rdquo;) to be automatically determined (for example, based on the number of other participants who chat with or listen to the speaker). </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> Selective filtering can be combined with memory ageing to effect a form of content compression, in which a user&apos;s filter terms of all types can be used to determine what portions of other users&apos; content to display as function of time. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> HCM includes a suite of techniques that can be implemented in various combinations in computer software. HCM provide users who participate in real-time computerized conversation forums with an interface that is much improved over present chat systems. These improvements are based upon emulating and extending many of the characteristics that humans for ages have found useful in the real-life world of spoken words and auditory conversation. These techniques allow the conveyance on-screen of much more information than can currently be made available by scrolling lines of text alone, eliminating or reducing the problems inherent in present chat systems. In addition, HCM supports other forms of user interaction, such as allowing a user to give or send an object (e.g., a symbol, token, video segment, file, etc.) to another user, or to allow a user to take an object from another user. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> HCM also can be tailored to suit the needs of specialized groups. For example, HCM can provided a more controlled approach in the context of a formal business meeting, or a map-based method of virtual movement ideal for certain types of games. In addition, HCM supports &ldquo;kiosks&rdquo;, in which users can interact with non-human resources in the context of a host-defined environment. </paragraph>
<paragraph id="P-0081" lvl="7"><number>&lsqb;0081&rsqb;</number> Conversation Display Space &amp; User Spaces </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3A</cross-reference> is a diagram of one embodiment of the invention. A user&apos;s display screen (e.g., such as the display screen of user terminal <highlight><bold>100</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>) would depict some or all of a &ldquo;conversation display space&rdquo; <highlight><bold>300</bold></highlight> that encompasses all user conversations. In some embodiments, the conversation display space <highlight><bold>300</bold></highlight> may comprise the entire display screen or even exceed that size (i.e., a &ldquo;virtual&rdquo; conversation display space <highlight><bold>300</bold></highlight> may be larger than a particular user&apos;s display screen). A conversation display space <highlight><bold>300</bold></highlight> may include various window controls, such as a window control icons <highlight><bold>301</bold></highlight>, scroll bars (a vertical scroll bar <highlight><bold>302</bold></highlight> is shown), drop-down menu (a window-control menu <highlight><bold>303</bold></highlight> is shown), window sizing control <highlight><bold>304</bold></highlight>, and status bar <highlight><bold>305</bold></highlight>. As should be apparent, other controls may be included. While a conventional rectangular window is shown for the conversation display space <highlight><bold>300</bold></highlight>, other shapes (e.g., round or round-corned rectangular) and display objects may be used. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> Each user is assigned a &ldquo;user space&rdquo; <highlight><bold>320</bold></highlight> within the conversation display space <highlight><bold>300</bold></highlight>. Two user spaces <highlight><bold>320</bold></highlight> are needed for one user to hold a conversation with another user, but only one user space <highlight><bold>320</bold></highlight> is needed for a user to interact with non-human resources, as discussed below. A user may move an assigned user space <highlight><bold>320</bold></highlight> within the conversation display space <highlight><bold>300</bold></highlight> using any convenient means, such as a pointing device (e.g., a mouse or touchpad), keyboard commands (e.g., cursor keys), or voice control. Such movement may be user-centric (i.e., all other users&apos; user spaces <highlight><bold>320</bold></highlight> within the conversation display space <highlight><bold>300</bold></highlight> move while a specific user&apos;s user space <highlight><bold>320</bold></highlight> remains stationary) or display-space centric (i.e., a user&apos;s user space <highlight><bold>320</bold></highlight> moves while all other user&apos;s user spaces <highlight><bold>320</bold></highlight> within the conversation display space <highlight><bold>300</bold></highlight> remain stationary). </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Each user space <highlight><bold>320</bold></highlight> includes a content area <highlight><bold>322</bold></highlight> that displays text and/or non-text information (e.g., computer files, images, sounds, videos, etc.) entered by a user when &ldquo;speaking&rdquo;. Input to the content area <highlight><bold>322</bold></highlight> may be by any convenient means, such as by typing on a keyboard, voice dictation, pointing-and-clicking on a display screen-based &ldquo;virtual&rdquo; keyboard or symbol palette, pasting objects from a &ldquo;clipboard&rdquo;, etc. Following current conventions, entered items &ldquo;scroll&rdquo; upwards, so that the oldest entry is at the top of the content area <highlight><bold>322</bold></highlight>. However, the reverse rule can be used as well. Termination of entry of content into the content area <highlight><bold>322</bold></highlight> may be indicated by any desired delimiter, such as the press of the &ldquo;ENTER&rdquo; key of a keyboard. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> While <cross-reference target="DRAWINGS">FIG. 3A</cross-reference> shows that the content area <highlight><bold>322</bold></highlight> is both the entry and display area for user content, separate entry and display areas may be used. Thus, a text edit box may be used to allow a user to type in and edit content, which is only displayed in the content area <highlight><bold>322</bold></highlight> after the user indicates that the text is ready for &ldquo;publication&rdquo; (e.g., by pressing the &ldquo;ENTER&rdquo; key of a keyboard). A user may also choose to separate the entry and display areas of his or her user space <highlight><bold>320</bold></highlight>, allowing one or the other to be hidden when not in use to allow for more display space for the user spaces <highlight><bold>320</bold></highlight> of other users. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> Typically, each user space <highlight><bold>320</bold></highlight> displays a user&apos;s identifier (e.g., actual name, screen name, initials, symbol, picture, or caricature), such as in the title bar <highlight><bold>324</bold></highlight> of the user space <highlight><bold>320</bold></highlight>. User spaces <highlight><bold>320</bold></highlight> may include various window controls and menus, such as a &ldquo;close window&rdquo; icon <highlight><bold>325</bold></highlight>, scroll bars (a vertical scroll bar <highlight><bold>326</bold></highlight> is shown), a window-control drop-down menu <highlight><bold>327</bold></highlight>, window sizing control <highlight><bold>328</bold></highlight>, and status bar <highlight><bold>329</bold></highlight>. As should be apparent, other controls may be included. While a rectangular window is shown for the user space <highlight><bold>320</bold></highlight>, other shapes (e.g., round-cornered rectangular, circular, etc.) and display techniques may be used. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The user space <highlight><bold>320</bold></highlight> includes an &ldquo;orientation control&rdquo; <highlight><bold>350</bold></highlight>. The orientation control <highlight><bold>350</bold></highlight> is used to direct and indicate the orientation of a user when listening to other users, thereby defining the user&apos;s primary direction of attention. A user may manipulate the orientation control <highlight><bold>350</bold></highlight> (e.g., using a pointing device, such as a mouse or touchpad, or using keyboard commands or voice control) in order to choose a particular direction of orientation for &ldquo;listening&rdquo; to other users. For example, the orientation control <highlight><bold>350</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 3A</cross-reference> may be angled by a user to point towards another user, such as by clicking on and dragging the end of the orientation control <highlight><bold>350</bold></highlight> to a new position. A changed position for the orientation control in <cross-reference target="DRAWINGS">FIG. 3A</cross-reference> is depicted in dotted outline at <highlight><bold>350</bold></highlight>&prime;. Other control mechanisms, such as a graphical rotary knob control, may be used to change the orientation of a user&apos;s orientation control <highlight><bold>350</bold></highlight>. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3B</cross-reference> is a diagram of a user space <highlight><bold>320</bold></highlight> having a movable orientation control <highlight><bold>352</bold></highlight>. This orientation control <highlight><bold>352</bold></highlight> may be moved around the perimeter of the user space <highlight><bold>320</bold></highlight> by the user (e.g., by clicking and dragging), as shown in dotted outline at <highlight><bold>352</bold></highlight>&prime; and <highlight><bold>352</bold></highlight>&Prime;. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3C</cross-reference> is a diagram of a user space <highlight><bold>320</bold></highlight> having another orientation control <highlight><bold>354</bold></highlight>, shown as a &ldquo;star&rdquo; of triangles around its perimeter (simple arrows may also be used). A particular &ldquo;point&rdquo; (one example is shown in gray at <highlight><bold>355</bold></highlight>) of the orientation control star <highlight><bold>354</bold></highlight> may be selected by a user to indicate the user&apos;s direction of attention. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3D</cross-reference> is a diagram of a user space <highlight><bold>320</bold></highlight> having another type of movable orientation control. An arrow-like orientation indicator <highlight><bold>360</bold></highlight> may be &ldquo;moved&rdquo; around the periphery of the user space <highlight><bold>320</bold></highlight> by selecting (e.g., by pointing and clicking) one of the control circles <highlight><bold>362</bold></highlight>. Such selection would graphically &ldquo;move&rdquo; the arrow-like orientation indicator <highlight><bold>360</bold></highlight> to the selected position, while a control circle <highlight><bold>362</bold></highlight> would be displayed at the previous location of the orientation indicator <highlight><bold>360</bold></highlight>. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> An orientation control may be embodied in many different ways and with many different shapes. Further, as described below, an orientation control need not be integrated with its associated user space. Different styles of orientation controls may be used together. Users may be assigned an orientation control style, or each user may be allowed to select a personal style of orientation control. </paragraph>
<paragraph id="P-0092" lvl="7"><number>&lsqb;0092&rsqb;</number> User Conversation Information </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> Humans are already well equipped to make use of information about proximity, orientation, memory ageing, reputation, and selective filtering in real life situations. A system implementing HCM may convey some or all of this information in a number of distinct and independent ways by keeping track of various combinations of orientation, position, key words, importance terms, reputation, emphasis, and time for each user&apos;s user space. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> A system implementing HCM may keep track of the relative position of each user&apos;s user space <highlight><bold>320</bold></highlight> within a conversation display space <highlight><bold>300</bold></highlight>. Any convenient coordinate system may be used, including Cartesian (X, Y) and polar (r, &thgr;) for two-dimensional implementations, and Cartesian (X, Y, Z) or spherical (r, (&phgr;, &thgr;) for three-dimensional implementations. The units may be arbitrary, or may be derived from the relative location (e.g., in pixels) of a user&apos;s user space <highlight><bold>320</bold></highlight> with respect to a selected reference point of the conversation display space <highlight><bold>300</bold></highlight> depicted on the user&apos;s display screen. These values might then be rescaled to arbitrary units and stored in an implementing system, since the display screens of users would typically differ in resolution. Preferably, such position information is stored within an appropriate data structure within a system supporting a conversation display space <highlight><bold>300</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> is a table showing an example of how information about a user&apos;s conversation status (including the user&apos;s position) can be stored. In this example, the user space for user &ldquo;Sam&rdquo; has an X, Y position of &ldquo;25, 100&rdquo; (in arbitrary units) within a conversation display space <highlight><bold>300</bold></highlight>. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> A system implementing HCM may keep track of each user&apos;s direction of attention. In a two-dimensional implementation, the direction of attention may be defined as an angle from a reference line (such as a line from the center of the user&apos;s user space <highlight><bold>320</bold></highlight> to the &ldquo;top&rdquo; of the conversation display space <highlight><bold>300</bold></highlight>) to a line indicating the orientation of a user&apos;s orientation control <highlight><bold>350</bold></highlight> (e.g., the angle &thgr; in <cross-reference target="DRAWINGS">FIG. 3A</cross-reference>). In a three dimensional implementation, the direction of attention may be defined as a declination and right ascension from a reference line to a line indicating the orientation of a user&apos;s orientation control <highlight><bold>350</bold></highlight>. Preferably, the direction of attention is stored within an appropriate data structure within a system supporting a conversation display space <highlight><bold>300</bold></highlight>. <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> shows an example of how information about a user&apos;s direction of attention can be stored. In this example, user &ldquo;Sam&rdquo; has a current direction of attention of 30 degrees relative to the top of a conversation display space <highlight><bold>300</bold></highlight>. Alternatively, direction of attention can be coded, such as a number from 1 to 8, each number representing a sector of 45 degrees. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> A system implementing HCM may allow a user to define key words and phrases (with optional weights) to monitor in the conversation of other users. In the example shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>A, user &ldquo;Sam&rdquo; has stored three words or phrases of interest as text strings with a suitable delimiter. Other data structures can be used, including hash codings (e.g., soundex coding, which applies an algorithm for encoding a word so that similar sounding words encode the same). The list of key words may be highlighted if they appear in conversation, even between speakers at the far periphery of a display screen or conversation display space. Examples of key words include the user&apos;s own name, company, or products. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> Similarly, a system implementing HCM may allow a user to define importance terms (with optional weights) to monitor in the conversation of other users. In the example shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>A, user &ldquo;Sam&rdquo; has stored two importance terms as text strings, each with associated weights. Accordingly, any speaker named &ldquo;Asimov&rdquo; will be given top priority over other speakers; otherwise, any speaker discussing the topic of &ldquo;science fiction&rdquo; will be given priority over other speakers. Again, other data structures can be used, including hash codings. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> A system implementing HCM may allow a user to define &ldquo;topics&rdquo; about which the user wishes to converse, in order to attract other participants in a conversation display space <highlight><bold>300</bold></highlight> having similar discussion interests. The topics may be stored, for example, in the user&apos;s conversation status table, as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>A, as another form of &ldquo;meta&rdquo; data. A user&apos;s current topic may be made visible to other participants, such as by display in the title bar of a user&apos;s user space <highlight><bold>320</bold></highlight>. Such a system may also allow a user to enter and store profile data, such as the user&apos;s real name (as opposed to screen name), gender, interests, educational and personal background, etc. Profile information may be stored, for example, in the user&apos;s conversation status table, or in a separate data structure. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> Such a system may also keep track of each user&apos;s &ldquo;external&rdquo; reputation as well as each user&apos;s &ldquo;internal&rdquo; reputation within a conversation environment, as measured or mediated by a host system. For example, an &ldquo;external reputation&rdquo; score may be assigned to each user by the human host of a forum, or automatically by analyzing user profiles. Thus, for example, users indicating that they are lawyers may be automatically assigned a higher &ldquo;external reputation&rdquo; score than users indicating that they are science fiction authors. Similarly, an &ldquo;internal reputation&rdquo; score may be assigned to each user by the human host of a forum, or by a system of secret or open balloting among forum participants, or by keeping track of how often the user is the focus of attention of other participants in the forum. Such scores may be stored in a table such as the type shown in <cross-reference target="DRAWINGS">FIG. 4A</cross-reference>. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> A running timer may be maintained for each user to indicate time elapsed since a user began a conversation session. Alternatively, a time stamp value can be stored once indicating when a conversation session started relative to a fixed time point (e.g., the Universal Time Coordinated time standard); this value may be used in later calculations to compute elapsed time. <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> shows one example of how such information may be stored in a system implementing HCM. In this example, a running timer shows that user &ldquo;Sam&rdquo; has been online in a conversation session for 410 seconds. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> Inputs made in the content area <highlight><bold>322</bold></highlight> of each user space <highlight><bold>322</bold></highlight> are stored in an appropriate data structure. <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> is a table showing one example of how such conversation content information may be stored in a system implementing HCM. In this example, each delimited text entry is stored in a table row. The delimiter may be defined by a host system. A typical delimiter is the &ldquo;ENTER&rdquo; key of a keyboard. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> The content area <highlight><bold>322</bold></highlight> of each user space <highlight><bold>320</bold></highlight> also allows a user to emphasize text by setting various &ldquo;perception attributes&rdquo;, alone or in combination. For example, a user can define text size, typeface, color, weight, thickness (e.g., normal or bold), shape (e.g., upright or italic), and effects (e.g., underlined, shadow, outlined, embossed, engraved, strikethrough, subscript, superscript, capitalization, blinking, background color, highlighting, etc.). Perception attributes can be extended to non-text information, such as allowing a user to vary the loudness of sound input to mimic whispering or shouting, or blinking an image or flashing the background of an image, or attaching sound effects to text. Accordingly, &ldquo;perception attribute&rdquo; encompasses any way of changing the appearance or playback of some or all of a user&apos;s input into a content area <highlight><bold>322</bold></highlight>. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> &ldquo;Perception attribute&rdquo; can also encompass any way of changing the appearance of a user space itself, such as by changing the color or weight of its border or title bar, or flashing the border or title bar, or setting a flag within its status bar. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> A system implementing HCM may keep track of each user&apos;s applied perception attributes. This information may be tracked by character, word, sentence, line, or other input portion. <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> shows one example of how such perception attributes may be stored in a system implementing HCM. In this illustration, three perception attributes (italics, underlined, bold) are tracked in an array <highlight><bold>400</bold></highlight> for each sentence <highlight><bold>401</bold></highlight>, <highlight><bold>402</bold></highlight> of a user&apos;s text input to the content area <highlight><bold>322</bold></highlight> of an associated user space <highlight><bold>320</bold></highlight>. For convenience, each delimited text portion may be given an identification tag (e.g., T<highlight><bold>1</bold></highlight>, T<highlight><bold>2</bold></highlight>) or a &ldquo;line&rdquo; number. The table shown in <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> can be extended to track any desired number of perception attributes, and other data structures (e.g., vectors) may be used to capture such information. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> A system implementing HCM may &ldquo;time stamp&rdquo; each entry made in the content area <highlight><bold>322</bold></highlight>. A time stamp may be set at any desired text delimiter, such as certain punctuation marks (e.g., period, semicolon, question mark, exclamation mark) or a &ldquo;new line&rdquo; indicator (e.g., each press of the &ldquo;ENTER&rdquo; key of a keyboard). <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> shows one example of how each sentence of a user&apos;s input can be time stamped. In this example, the time stamp value is the number of seconds that have elapsed since the user began a conversation session (e.g., &ldquo;logged&rdquo; into a conversation display space <highlight><bold>300</bold></highlight>) until the end of each sentence is reached (here, denoted by a period). Other time schemes could be used, such as the number of seconds (or fractions of a second) elapsed from a fixed time point (e.g., the beginning of the twenty-first century), or a current clock time (rather than elapsed time), possibly referenced to the Universal Time Coordinated standard. Time stamps may also be associated with the entry into the content area <highlight><bold>322</bold></highlight> of non-text information, such as computer files, images, sounds, videos, etc. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> Similar information may be tracked for all users participating at any particular time within a conversation display space <highlight><bold>300</bold></highlight>. Such information typically would be stored within a system controlling a conversation display space <highlight><bold>300</bold></highlight> for a plurality of participants. For example, a master table can be used to store current tables similar to those shown in <cross-reference target="DRAWINGS">FIGS. 4A and 4B</cross-reference> for each user participating at any particular time within a conversation display space <highlight><bold>300</bold></highlight>. By tracking such information and applying simple rules of geometry, the relative orientation and position of each user with respect to every other user can be determined. In addition, each participant&apos;s identity, key words, importance terms, topics, reputation, time-stamped content area information, and perception attributes are known and can be used to mimic memory ageing and provide selective filtering. </paragraph>
<paragraph id="P-0107" lvl="7"><number>&lsqb;0107&rsqb;</number> Multiple User Basic Operation </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5A</cross-reference> is a diagram showing a conversation display space <highlight><bold>300</bold></highlight> with four user spaces <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>320</bold></highlight><highlight><italic>d</italic></highlight>. Of course, more or fewer user spaces <highlight><bold>320</bold></highlight> may be present during any particular conversation session. In the illustrated example, each user is in a passive &ldquo;listening&rdquo; mode (i.e., the orientation controls <highlight><bold>350</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>350</bold></highlight><highlight><italic>d </italic></highlight>are not directed towards other users) within a display-centric embodiment. In this state, content input by each user is displayed within the user space assigned to that user. Thus, in this example, user &ldquo;Sam&rdquo; has input two sentences. That input typically would be transmitted to and stored in a table similar to <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> within a host system supporting the conversation display space <highlight><bold>300</bold></highlight>. In turn, the host system normally would transmit that input to all other users for display in a user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>associated with user &ldquo;Sam&rdquo; and depicted in the conversation display space <highlight><bold>300</bold></highlight> shown on each user&apos;s display screen. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5B</cross-reference> is the diagram of <cross-reference target="DRAWINGS">FIG. 5A</cross-reference> at a subsequent time. User &ldquo;John&rdquo; has moved his user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>from the position shown in dotted outline closer to the user space <highlight><bold>320</bold></highlight><highlight><italic>b </italic></highlight>of user &ldquo;Mary&rdquo;, and redirected his orientation control <highlight><bold>350</bold></highlight><highlight><italic>a </italic></highlight>to point towards &ldquo;Mary&rdquo;. &ldquo;John&rdquo; has also entered text into the content area of his user space <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>. &ldquo;Mary&rdquo; has redirected her orientation control <highlight><bold>350</bold></highlight><highlight><italic>a </italic></highlight>to point towards &ldquo;John&rdquo; and has begun to reply. Additionally, &ldquo;Susan&rdquo; has redirected her orientation control <highlight><bold>350</bold></highlight><highlight><italic>a </italic></highlight>to point towards &ldquo;Sam&rdquo; and entered text into the content area of her user space <highlight><bold>320</bold></highlight><highlight><italic>c</italic></highlight>. &ldquo;Sam&rdquo; at this point has not moved his user space <highlight><bold>320</bold></highlight><highlight><italic>d</italic></highlight>, redirected his orientation control <highlight><bold>350</bold></highlight><highlight><italic>d</italic></highlight>, or entered any text into the content area of his user space <highlight><bold>320</bold></highlight><highlight><italic>d. </italic></highlight></paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> At a glance, each user can determine who is talking to them (based on proximity and the direction of each other user&apos;s orientation control) and can see each &ldquo;speaker&apos;s&rdquo; uninterrupted &ldquo;speech&rdquo; within their corresponding user space <highlight><bold>320</bold></highlight>. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 5A and 5B</cross-reference> thus show three aspects of one embodiment of the invention: dedication of a user space <highlight><bold>320</bold></highlight> per participant, movement of each participant&apos;s user space <highlight><bold>320</bold></highlight> with respect to other participants in a conversation display space <highlight><bold>300</bold></highlight>, and changing the direction of attention of a user space <highlight><bold>320</bold></highlight>. </paragraph>
<paragraph id="P-0112" lvl="7"><number>&lsqb;0112&rsqb;</number> User-Centric Viewpoint </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 6A and 6B</cross-reference> are diagrams showing a conversation display space <highlight><bold>300</bold></highlight> with four user spaces <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>320</bold></highlight><highlight><italic>b</italic></highlight>, <highlight><bold>320</bold></highlight><highlight><italic>c</italic></highlight>, <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>in a &ldquo;user-centric&rdquo; view. <cross-reference target="DRAWINGS">FIG. 6A</cross-reference> is a view of the conversation display space <highlight><bold>300</bold></highlight> seen by user &ldquo;John&rdquo;. In this view, the user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>for &ldquo;John&rdquo; is centrally located in the conversation display space <highlight><bold>300</bold></highlight>. Surrounding &ldquo;John&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>are two user spaces <highlight><bold>320</bold></highlight><highlight><italic>b</italic></highlight>, <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>for users &ldquo;Mary&rdquo; and &ldquo;Sam&rdquo;, respectively. <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is a view of the same conversation display space <highlight><bold>300</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 6</cross-reference>A, but as seen by &ldquo;Mary&rdquo;. In this view, the user space <highlight><bold>320</bold></highlight><highlight><italic>b </italic></highlight>for &ldquo;Mary&rdquo; is centrally located in the conversation display space <highlight><bold>300</bold></highlight>. Surrounding &ldquo;Mary&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>b </italic></highlight>are two user spaces <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>320</bold></highlight><highlight><italic>c </italic></highlight>for users &ldquo;John&rdquo; and &ldquo;Susan&rdquo;, respectively. In this example, &ldquo;John&rdquo; cannot see distant &ldquo;Susan&rdquo;, and &ldquo;Mary&rdquo; cannot see distant &ldquo;Sam&rdquo;. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> In a user-centric embodiment, the user space <highlight><bold>320</bold></highlight> for a user remains substantially centered within the conversation display space <highlight><bold>300</bold></highlight>. Accordingly, when a user &ldquo;moves&rdquo; an associated user space relative to other user spaces, what appears to happen within the conversation display space <highlight><bold>300</bold></highlight> is that the user spaces of all other users move past the &ldquo;central&rdquo; user&apos;s user space in the direction opposite to the central user&apos;s chosen direction of movement. Thus, if a user &ldquo;moves&rdquo; his or her user space <highlight><bold>320</bold></highlight> left, the conversation display space <highlight><bold>300</bold></highlight> shows the user spaces <highlight><bold>320</bold></highlight> for all other users moving right. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> In one embodiment of a user-centric view, each user&apos;s display is generated by a system (e.g., a host server) that uses the coordinates of each user&apos;s user space <highlight><bold>320</bold></highlight> to maintain a &ldquo;global&rdquo; map of the position of all users in a conversation display space <highlight><bold>300</bold></highlight>. The system provides each user with a &ldquo;view&rdquo; of the map sized to fit within the user&apos;s display screen and centered on the user&apos;s own user space <highlight><bold>320</bold></highlight>. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> Movement of a user space with respect to other user spaces may be constrained, if desired, so that a user&apos;s user space cannot pass &ldquo;over&rdquo; another user&apos;s user space (just as a person would not normally walk through a conversation between two other people). In such cases, a user must move (or &ldquo;walk&rdquo;) an associated user space &ldquo;around&rdquo; the user spaces of other users. Alternatively, a user can point to or designate a new location within a conversation display space <highlight><bold>300</bold></highlight> and &ldquo;teleport&rdquo; (instantly transfer) or &ldquo;levitate&rdquo; (e.g., appear to become detached from the plain of a two-dimensional conversation display space <highlight><bold>300</bold></highlight> and &ldquo;float&rdquo; over intervening user spaces) the user&apos;s user space <highlight><bold>320</bold></highlight> to the indicated new location. Further, user spaces may overlap. Other means of indicating and controlling movement of user spaces may also be used as desired. </paragraph>
<paragraph id="P-0117" lvl="7"><number>&lsqb;0117&rsqb;</number> World View </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a diagram showing an optional &ldquo;world view&rdquo; <highlight><bold>700</bold></highlight> of a conversation display space as seen from a user-centric viewpoint. A user would select the world view <highlight><bold>700</bold></highlight> (e.g., from a &ldquo;right-click&rdquo; menu or by pressing a function key) to help see the location of other users within a conversation display space. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> In this example, the user space for user &ldquo;John&rdquo; is represented as an icon <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>&prime;. Near the icon <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>&prime; for &ldquo;John&rdquo; are icons <highlight><bold>320</bold></highlight><highlight><italic>b</italic></highlight>&prime;, <highlight><bold>320</bold></highlight><highlight><italic>c</italic></highlight>&prime;, <highlight><bold>320</bold></highlight><highlight><italic>d</italic></highlight>&prime; for nearby users &ldquo;Mary&rdquo;, &ldquo;Susan&rdquo;, and &ldquo;Sam&rdquo;, respectively. Preferably, each icon also indicates the current direction of attention of the associated user. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> Because entire user spaces <highlight><bold>320</bold></highlight> are not shown in the world view <highlight><bold>700</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, additional space is available within the conversation display space to show more distant participants <highlight><bold>320</bold></highlight><highlight><italic>e</italic></highlight>&prime;-<highlight><bold>320</bold></highlight><highlight><italic>j</italic></highlight>&prime; relative to the central location of user &ldquo;John&rdquo;. Thus, this view allows user &ldquo;John&rdquo; to see the availability of many more participants within the conversation display space <highlight><bold>300</bold></highlight>. User John may also &ldquo;walk&rdquo; to a new location (e.g., by commanding a continuous incremental movement across the display screen using cursor keys or a pointing device), or &ldquo;teleport&rdquo; or &ldquo;levitate&rdquo; to a new location (e.g., by clicking on the world view representation with a pointing device). A world view <highlight><bold>700</bold></highlight> of a conversation display space may be displayed concurrently with a conversation display space <highlight><bold>300</bold></highlight>, so that a user may view a surrounding local area of readable user spaces <highlight><bold>320</bold></highlight> while observing the positions of more distant participants. </paragraph>
<paragraph id="P-0121" lvl="7"><number>&lsqb;0121&rsqb;</number> Compression, Filtering, &amp; Flagging </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> A system implementing HCM can include any of several innovative techniques that allow the system to replicate the effects of variable proximity, orientation, importance, reputation, time, and selective filtering in representing conversations. These techniques allow several types of compression, enabling a user&apos;s screen to contain more information, and cover a broader reach of cyber-space, than would otherwise be possible. Some of these techniques mimic the effects of sound in the real world, as perceived by normal human ears, but others are extensions of the characteristics of natural spoken conversations. In addition, some of these characteristics can be used to automatically flag other conversations of interest to a listener. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> User Space Compression </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> The number of user spaces <highlight><bold>320</bold></highlight> that may be displayed at one time on a user&apos;s display screen is constrained by the limits of readability of text within the user spaces, even if the bounds of a conversation display space <highlight><bold>300</bold></highlight> exceed the size of the display screen (i.e., a &ldquo;virtual&rdquo; conversation display space). Another aspect of the invention that is particularly useful in a user-centric embodiment is to use proximity and/or orientation information to control the displayed size of other users&apos; user spaces. The displayed size of other users&apos; user spaces may also vary as a function of such users&apos; internal and/or external reputation scores. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a diagram of a user-centric view showing reduction in user space <highlight><bold>320</bold></highlight> size as a function of distance and/or orientation from a &ldquo;central&rdquo; user. The user space <highlight><bold>320</bold></highlight><highlight><italic>b </italic></highlight>for user &ldquo;Mary&rdquo;, closest to the user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>for central user &ldquo;John&rdquo;, is shown normal size. The user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>for user &ldquo;Sam&rdquo;, further from the user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>for central user &ldquo;John&rdquo;, is shown at a slightly reduced size. The user space for user &ldquo;Susan&rdquo;, farthest from the user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>for central user &ldquo;John&rdquo;, is shown as a token or icon <highlight><bold>320</bold></highlight><highlight><italic>c</italic></highlight>&prime;. The icon <highlight><bold>320</bold></highlight><highlight><italic>c</italic></highlight>&prime; indicates that the user space for &ldquo;Susan&rdquo; with respect to the user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>for &ldquo;John&rdquo; is beyond a selected distance, and thus out of &ldquo;John&apos;s&rdquo; &ldquo;hearing&rdquo; range. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> In one embodiment, on approaching an edge of the displayed portion of a conversation display space <highlight><bold>300</bold></highlight> with respect to a central user, user spaces begin to shrink in size, getting progressively smaller (a technique called &ldquo;screen warping&rdquo;). User spaces <highlight><bold>320</bold></highlight> at the edges are thus much smaller than those closer to the center, allowing a larger number to fit at the periphery of the display screen than near the center. The central user can thus see that other participants are nearby, even if their current content is not visible. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> User spaces not in the proximity of a user may be displayed as an icon showing only the distant participants&apos; identity, as illustrated in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. Alternatively, very distant users may be shown only as non-identified symbols (e.g., small circles), or not displayed at all (i.e., they &ldquo;vanish&rdquo; from view). An embodiment that displays icons or other symbols can further provide a function that allows the central user to &ldquo;eavesdrop&rdquo; on an associated conversation. For example, a user could &ldquo;click&rdquo; on such an icon and an associated user space <highlight><bold>320</bold></highlight> would pop-up to a readable size, possibly overlaying other conversations temporarily. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> Screen warping is dynamic, in that the size depiction of user spaces changes as a user moves. Thus, in the example of <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, if user &ldquo;John&rdquo; moves his user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>to the right, the user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>for &ldquo;Sam&rdquo; will continue to shrink, until replaced by an icon or other symbol, and then may vanish entirely. Meanwhile, the user space <highlight><bold>320</bold></highlight><highlight><italic>c </italic></highlight>for user &ldquo;Susan&rdquo; will transform from an icon <highlight><bold>320</bold></highlight><highlight><italic>c</italic></highlight>&prime; to a small user space <highlight><bold>320</bold></highlight><highlight><italic>c</italic></highlight>, which will continue to grow to a &ldquo;normal&rdquo; size as &ldquo;John&rdquo; gets closer. Further, new user spaces may appear on the right edge of the screen as &ldquo;John&rdquo; continues to move in that direction, indicating that &ldquo;John&rdquo; is approaching other participants that previously had been out of &ldquo;hearing&rdquo; range. </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> Because the implementing system keeps track of the coordinates of each user, it is straightforward to calculate the distance of each user&apos;s user space with respect to the user space of each other user. For example, if the user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>for user &ldquo;John&rdquo; has X, Y coordinates of &lcub;100, 50&rcub;, and the user space <highlight><bold>320</bold></highlight><highlight><italic>b </italic></highlight>for user &ldquo;Mary&rdquo; has coordinates of &lcub;150, 25&rcub;, then the distance D between the two user spaces can be computed as follows (in this example, D is approximately equal to 56): </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>D</italic></highlight>&equals;{square root}{square root over ((<highlight><italic>x</italic></highlight><highlight><subscript>1</subscript></highlight><highlight><italic>&minus;x</italic></highlight><highlight><subscript>2</subscript></highlight>)<highlight><superscript>2</superscript></highlight>&plus;(<highlight><italic>y</italic></highlight><highlight><subscript>1</subscript></highlight><highlight><italic>&minus;y</italic></highlight><highlight><subscript>2</subscript></highlight>))}</in-line-formula></paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> The computed distances between user user spaces may be determined as specific distances (in real or arbitrary units), or coded into &ldquo;zones&rdquo; (e.g., &ldquo;adjacent&rdquo;, &ldquo;near&rdquo;, &ldquo;far&rdquo;) centered on each user&apos;s own user space. Alternatively, &ldquo;distance&rdquo; may be measured as the number of user spaces that lie between a user&apos;s user space and each other user&apos;s user space. Using this approach, in the example of <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, the &ldquo;distance&rdquo; between &ldquo;John&rdquo; and &ldquo;Mary&rdquo; is zero (i.e., no intervening user spaces), while the &ldquo;distance&rdquo; between &ldquo;Sam&rdquo; and &ldquo;Mary&rdquo; is one (i.e., &ldquo;John&apos;s&rdquo; user space intervenes). </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> A number of algorithms may be used for adjusting the displayed size of each user space. One such algorithm is to let Dij represent the distance between user i&apos;s user space and some other user j&apos;s user space, measured in zones (e.g., 1&equals;&ldquo;adjacent&rdquo;, 2&equals;&ldquo;near&rdquo;, 3&equals;&ldquo;far&rdquo;, 4&equals;&ldquo;off edge&rdquo;) centered relative to user i&apos;s user space. Assume that user spaces for other users j have four display sizes, Sj (e.g., 1&equals;&ldquo;normal&rdquo;, 2&equals;&ldquo;smaller&rdquo;, 3&equals;&ldquo;smallest&rdquo;, 4&equals;token representation). Then simply directly map Sj to Dij (e.g., if Dij&equals;2, the size Sj of user j&apos;s user space would be set to 2). This algorithm can be extended to more or fewer reductions in user space size as distance increases. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> The orientation of the central user can also be used to adjust the displayed size of other users&apos; user spaces. For example, in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, the user space <highlight><bold>320</bold></highlight><highlight><italic>b </italic></highlight>for user &ldquo;Mary&rdquo; is shown normal size in part because &ldquo;John&apos;s&rdquo; orientation control <highlight><bold>350</bold></highlight><highlight><italic>a </italic></highlight>is directed towards &ldquo;Mary&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>b</italic></highlight>. The user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>for &ldquo;Sam&rdquo; is shown at a slightly reduced size in part because it is outside &ldquo;John&apos;s&rdquo; direction of attention. If &ldquo;John&rdquo; were to move his orientation control <highlight><bold>350</bold></highlight><highlight><italic>a </italic></highlight>to point towards &ldquo;Sam&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>d</italic></highlight>, the implementing system can use this change in orientation state to enlarge &ldquo;Sam&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>and diminish the size of &ldquo;Mary&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>b. </italic></highlight></paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> For example, assume that Rij represents the relative orientation of other users j with respect to a central user i, coded into three zones (e.g., 1&equals;&ldquo;front&rdquo;, 2&equals;&ldquo;side&rdquo;, 3&equals;&ldquo;back&rdquo;), and user spaces for other users j have three display sizes, Sj, with Sj&equals;1 being a normal size. Then simply directly map Sj to Rij (e.g., if Rij&equals;2, the size Sj of user j&apos;s user space would be set to 2). This algorithm can be extended to more or fewer reductions in user space size as orientation changes. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> In another variation, the apparent size of display spaces may be based on the mutual orientation of two users rather than just the central user&apos;s orientation. That is, apparent size may depend not only on how a first user is oriented towards a second user, but how the second user is oriented towards the first user. For example, assume that Rij represents the relative mutual orientation of other users j with respect to a central user i, coded into nine zones, and user spaces for other users j have four display sizes, Sj, with Sj&equals;1 being a normal size. A lookup table can be used to map Sj to various values of Rij. For example, the cell entries of Table 1 below could be used to determine the size Sj of each user j&apos;s user space <highlight><bold>320</bold></highlight> with respect to user i as a function of mutual orientation. Other mappings may also be used.  
<table-cwu id="TABLE-US-00001">
<number>1</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="OFFSET" colwidth="14PT" align="left"/>
<colspec colname="1" colwidth="98PT" align="center"/>
<colspec colname="2" colwidth="105PT" align="center"/>
<thead>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="2" align="center">TABLE 1</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry></entry>
<entry></entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="2" align="center" rowsep="1"></entry>
</row>
<row>
<entry></entry>
<entry></entry>
<entry>Orientation of user j</entry>
</row>
<row>
<entry></entry>
<entry>Orientation of user i</entry>
<entry>(1 &equals; front, 2 &equals; side, 3 &equals; back)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="5">
<colspec colname="OFFSET" colwidth="14PT" align="left"/>
<colspec colname="1" colwidth="98PT" align="center"/>
<colspec colname="2" colwidth="28PT" align="center"/>
<colspec colname="3" colwidth="49PT" align="center"/>
<colspec colname="4" colwidth="28PT" align="center"/>
<tbody valign="top">
<row>
<entry></entry>
<entry>(1 &equals; front, 2 &equals; side, 3 &equals; back)</entry>
<entry>1</entry>
<entry>2</entry>
<entry>3</entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="4" align="center" rowsep="1"></entry>
</row>
<row>
<entry></entry>
<entry>1</entry>
<entry>1</entry>
<entry>2</entry>
<entry>3</entry>
</row>
<row>
<entry></entry>
<entry>2</entry>
<entry>2</entry>
<entry>3</entry>
<entry>4</entry>
</row>
<row>
<entry></entry>
<entry>3</entry>
<entry>3</entry>
<entry>4</entry>
<entry>4</entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="4" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> Distance and orientation can be combined to determine the display size of other users&apos; user spaces <highlight><bold>320</bold></highlight>. For example, the cell entries of Table 2 below could be used to determine the size Sj of each user j&apos;s user space <highlight><bold>320</bold></highlight> with respect to user i as a function of distance and orientation. Other mappings may also be used.  
<table-cwu id="TABLE-US-00002">
<number>2</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="77PT" align="center"/>
<colspec colname="2" colwidth="140PT" align="center"/>
<thead>
<row>
<entry namest="1" nameend="2" align="center">TABLE 2</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="2" align="center" rowsep="1"></entry>
</row>
<row>
<entry>Orientation Rij</entry>
<entry>Distance Dij (1 &equals; nearest)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="5">
<colspec colname="1" colwidth="77PT" align="center"/>
<colspec colname="2" colwidth="21PT" align="center"/>
<colspec colname="3" colwidth="49PT" align="center"/>
<colspec colname="4" colwidth="21PT" align="center"/>
<colspec colname="5" colwidth="49PT" align="center"/>
<tbody valign="top">
<row>
<entry>(1 &equals; front)</entry>
<entry>1</entry>
<entry>2</entry>
<entry>3</entry>
<entry>4</entry>
</row>
<row><entry namest="1" nameend="5" align="center" rowsep="1"></entry>
</row>
<row>
<entry>1</entry>
<entry>1</entry>
<entry>2</entry>
<entry>3</entry>
<entry>4</entry>
</row>
<row>
<entry>2</entry>
<entry>2</entry>
<entry>3</entry>
<entry>4</entry>
<entry>4</entry>
</row>
<row>
<entry>3</entry>
<entry>2</entry>
<entry>3</entry>
<entry>4</entry>
<entry>4</entry>
</row>
<row><entry namest="1" nameend="5" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> As should be apparent from the examples of Tables 1 and 2, distance and mutual orientation can also be combined to determine the display size of other users&apos; user spaces <highlight><bold>320</bold></highlight>. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> Other factors may be used to determine the display size of other users&apos; user spaces <highlight><bold>320</bold></highlight>, such as internal and external reputation scores. Thus, for example, a distant user space <highlight><bold>320</bold></highlight> of a participant who has a higher reputation score may be displayed at one size larger than an equally distant user space <highlight><bold>320</bold></highlight> of a participant having a lower reputation score. </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> Content Spatial Compression </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> Another aspect of the invention that is particularly useful in a user-centric embodiment conserves display space and mimics the characteristics of real-world conversations by compressing the contents of other users&apos; content areas as a function of distance and/or orientation. This aspect optionally can be combined with user space compression, described in the previous section. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a diagram of a user-centric view showing content area compression as well as user space compression. Central user &ldquo;John&apos;s&rdquo; orientation control <highlight><bold>350</bold></highlight><highlight><italic>a </italic></highlight>is directed towards &ldquo;Mary&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>b</italic></highlight>, which is also relatively close to &ldquo;John&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>. Accordingly, &ldquo;Mary&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>b </italic></highlight>is shown full size, and no compression is shown of the text in &ldquo;Mary&apos;s&rdquo; content area <highlight><bold>322</bold></highlight><highlight><italic>b. </italic></highlight></paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> However, the implementing system can recognize that, based on the coordinates of the user spaces <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>for &ldquo;John&rdquo; and &ldquo;Sam&rdquo; and the direction of attention of &ldquo;John&apos;s&rdquo; orientation control <highlight><bold>350</bold></highlight><highlight><italic>a</italic></highlight>, &ldquo;Sam&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>is &ldquo;behind&rdquo; &ldquo;John&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>. Accordingly, &ldquo;Sam&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>can be reduced in size (as described in the previous section) and/or part or all of the content in the content area <highlight><bold>322</bold></highlight><highlight><italic>d </italic></highlight>for &ldquo;Sam&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>can be compressed. In particular, a number of different forms of &ldquo;spatial compression&rdquo; can be applied. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> &ldquo;Spatial compression&rdquo; comprises any of several techniques for reducing the size-related perception attributes of the contents of a user space without substantially altering the information depicted by such content. Such techniques include: changing the weighting of a typeface from heavy to light; changing all-capitalized text to sentence case or lower case; changing from a serif typeface to a sans serif typeface; reducing the point size of a typeface; and reducing line separation and/or inter-word separation. Other &ldquo;shrinking&rdquo; techniques may also be used. In particular, spatial compression can be extended to non-text elements, such as graphics. For example, a graphic element can be replaced with a smaller &ldquo;thumbnail&rdquo; version or deleted entirely as a function of distance or orientation. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> One example of an application of some of these techniques is shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, in which the typeface of the text in the content area <highlight><bold>322</bold></highlight><highlight><italic>d </italic></highlight>for user &ldquo;Sam&rdquo; is reduced in point size because &ldquo;Sam&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>is &ldquo;behind&rdquo; central user &ldquo;John&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>a</italic></highlight>. Similarly, the typeface of the text in the content area <highlight><bold>322</bold></highlight><highlight><italic>c </italic></highlight>for user &ldquo;Susan&rdquo; is further reduced in point size because &ldquo;Susan&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>c </italic></highlight>is &ldquo;behind&rdquo; central user &ldquo;John&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>a </italic></highlight>and further away than &ldquo;Sam&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>d. </italic></highlight></paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> A number of spatial compression techniques can be combined. For example, as the distance Dij between user i&apos;s user space to some other user j&apos;s user space increases (e.g., measured in five zones so that 1&equals;&ldquo;adjacent&rdquo; and 5&equals;&ldquo;very distant&rdquo;), the following algorithm can be applied: </paragraph>
<paragraph id="P-0145" lvl="2"><number>&lsqb;0145&rsqb;</number> If Dij&equals;1, no compression; </paragraph>
<paragraph id="P-0146" lvl="2"><number>&lsqb;0146&rsqb;</number> If Dij&equals;2, change all words in bold type to regular text; </paragraph>
<paragraph id="P-0147" lvl="2"><number>&lsqb;0147&rsqb;</number> If Dij&equals;3, change the typeface to a sans serif lightweight typeface; </paragraph>
<paragraph id="P-0148" lvl="2"><number>&lsqb;0148&rsqb;</number> If Dij&equals;4, change the typeface to a smaller point size (e.g., from 12 point to 10 point) and/or reduce line separation. If it is now possible to combine two lines into one line, do so. </paragraph>
<paragraph id="P-0149" lvl="2"><number>&lsqb;0149&rsqb;</number> If Dij&equals;5, change the typeface to a smaller point size (e.g., from 10 point to 8 point) and/or reduce line separation. If it is now possible to combine two lines into one line, do so. </paragraph>
<paragraph id="P-0150" lvl="7"><number>&lsqb;0150&rsqb;</number> This algorithm can be extended to more or fewer reductions in content size as distance increases. </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> A similar algorithm can be applied based on orientation. For example, if Rij represents the relative orientation of other users j with respect to a central user i, coded into three zones (e.g., 1&equals;&ldquo;front&rdquo;, 2&equals;&ldquo;side&rdquo;, 3&equals;&ldquo;back&rdquo;), the following algorithm can be used: </paragraph>
<paragraph id="P-0152" lvl="2"><number>&lsqb;0152&rsqb;</number> If Rij&equals;1, no compression; </paragraph>
<paragraph id="P-0153" lvl="2"><number>&lsqb;0153&rsqb;</number> If Rij&equals;2, change all words in bold type to regular text, and change the typeface to a sans serif lightweight typeface; </paragraph>
<paragraph id="P-0154" lvl="2"><number>&lsqb;0154&rsqb;</number> If Rij&equals;4, change the typeface to a smaller point size (e.g., from 12 point to 10 point) and/or reduce line separation. If it is now possible to combine two lines into one line, do so. </paragraph>
<paragraph id="P-0155" lvl="7"><number>&lsqb;0155&rsqb;</number> This algorithm can be extended to more or fewer reductions in content size as orientation changes. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> As with user space compression, spatial compression can be based on both distance Dij and orientation Rij (either central user orientation or mutual orientation). A lookup table mapping these two variables to various compression actions can be constructed in a manner similar to Tables 1 and 2 above. Alternatively, various compression actions may be determined by combining these two variables (alone or with other variables) using a mathematical algorithm. </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> Spatial compression also can work in reverse as movement occurs among the participants within a conversation display space. That is, as the distance between a central user and a more distant user lessens, or as the direction of attention of the central user changes to a more &ldquo;direct&rdquo; view, previously spatially compressed content can be expanded (for example, by applying the spatial compression algorithm in reverse). This is an extension of the characteristics of natural spoken conversations, in that the history of prior conversations can be &ldquo;resurrected&rdquo; for review by a user as that user gets closer to or more focused on other users. </paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> Content Compression by Selective Filtering </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> Another form of compression based on selective filtering can also be applied to further reduce the amount of screen area occupied by the contents of content areas in users&apos; user spaces. Human ears are very good at picking out sounds or words of specific interest to the individual listener, and ignoring all the rest. A system implementing HCM can emulate this facility by selectively filtering or removing words in reverse order of priority as a function of distance or orientation. </paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> Such &ldquo;content compression&rdquo; is illustrated in part in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, where the top-most line in the content area <highlight><bold>322</bold></highlight><highlight><italic>d </italic></highlight>of user &ldquo;Sam&apos;s&rdquo; user space <highlight><bold>320</bold></highlight><highlight><italic>d </italic></highlight>has been reduced from &ldquo;Has anyone read the new book on SETI&quest;&rdquo; (see <cross-reference target="DRAWINGS">FIG. 5A</cross-reference>) to &ldquo;* read book SETI&quest;&rdquo;. In this example, a preceding asterisk has been added to indicate to other users that the adjacent line has been content compressed. The question mark has also been preserved in this embodiment, since it indicates a question rather than a statement, and thus imparts important semantic content. </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> Selective filtering content compression is applied to text preferentially in user spaces <highlight><bold>320</bold></highlight> farther from the central user or behind or to one side of the central user&apos;s chosen direction of attention. Selective filtering content compression may also be applied to text preferentially in user spaces <highlight><bold>320</bold></highlight> that have internal and/or external reputation scores below a selected threshold. Selective filtering emulates the way people pay closer attention to speakers they are facing, and/or who are closer, and/or who have a higher reputation. This effect works well in conjunction with user space compression, since more distant user spaces are themselves made smaller until, near the edge of the display screen or conversation display space, they may contain only a few key words. Spatial compression of content area text can also be applied to &ldquo;shrink&rdquo; the displayed size of content-compressed text and other user input (e.g., graphics). </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> A number of different algorithms and techniques may be applied to achieve content compression. These include word removal or substitution based on a system-wide list; word removal or substitution based on a user defined list; abbreviation of words or phrases (e.g., &ldquo;BTW&rdquo; for &ldquo;by the way&rdquo;); and lossless and/or lossy compression of graphics. Other content compression techniques may also be applied. </paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> A number of content compression techniques can be combined. For example, one such algorithm might include some or all of the following steps applied as a function of distance Dij or orientation Rij of other users j with respect to each user i: </paragraph>
<paragraph id="P-0164" lvl="2"><number>&lsqb;0164&rsqb;</number> Step 1&mdash;Do not display articles (i.e., &ldquo;a&rdquo;, &ldquo;an&rdquo;, &ldquo;the&rdquo;) and connecting words (e.g., &ldquo;and&rdquo;, &ldquo;or&rdquo;) of little information value and/or replace them with abbreviations (e.g., &ldquo;&amp;&rdquo; instead of &ldquo;and&rdquo;), unless on user i&apos;s key word list (see, e.g., <cross-reference target="DRAWINGS">FIG. 4A</cross-reference>). </paragraph>
<paragraph id="P-0165" lvl="2"><number>&lsqb;0165&rsqb;</number> Step 2&mdash;Do not display weak adjectives and qualifiers (e.g., &ldquo;blue&rdquo;), or else replace them with abbreviations (e.g., substitute &ldquo;st.&rdquo; for &ldquo;state&rdquo; or &ldquo;street&rdquo;) or shorter synonyms (unless on user i&apos;s key word list). </paragraph>
<paragraph id="P-0166" lvl="2"><number>&lsqb;0166&rsqb;</number> Step 3&mdash;Do not display strong adjectives and adverbs (e.g., &ldquo;rapidly&rdquo;), or replace them with abbreviations or shorter synonyms (unless on user i&apos;s key word list). </paragraph>
<paragraph id="P-0167" lvl="2"><number>&lsqb;0167&rsqb;</number> Step 4&mdash;Simplify verbs or replace them with abbreviations or shorter synonyms (unless on user i&apos;s key word list). </paragraph>
<paragraph id="P-0168" lvl="2"><number>&lsqb;0168&rsqb;</number> Step 5&mdash;Simplify nouns or replace them with abbreviations or shorter synonyms (unless on user i&apos;s key word list). </paragraph>
<paragraph id="P-0169" lvl="2"><number>&lsqb;0169&rsqb;</number> Step 6&mdash;Do not display any words not on the user&apos;s key word list. </paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> The system implementing HCM may contain a system-wide or a forum-wide dictionary or look-up table of pre-defined words (e.g., in a hash table) against which the words in particular content areas of other users could be compared at each step. Comparison may be by simple string comparison techniques. This algorithm can be extended to more, fewer, or different steps as proximity or orientation changes. </paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> A variant of content compression by selective filtering is use of intelligent software to interpret the &ldquo;gist&rdquo; of what a speaker has said. For example, a lengthy and convoluted reply may boil down to &ldquo;User A agrees with User B&rdquo;. An example of one type of such software is the &ldquo;autosummarize&rdquo; function of Microsoft Word&reg;. </paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> Content compression can also work in reverse, and become content expansion, as movement occurs among the participants within a conversation display space <highlight><bold>300</bold></highlight>. That is, as the distance between a central user and a more distant user lessens, or as the direction of attention of the central user changes to a more &ldquo;direct&rdquo; view, previously compressed content can be expanded (e.g., by restoring more and more of &plus;he original input from another user&apos;s conversation content table, such as is shown in <cross-reference target="DRAWINGS">FIG. 4B</cross-reference>). This is an extension of the characteristics of natural spoken conversations, in that the history of prior conversations can be &ldquo;resurrected&rdquo; for review by a user as that user gets closer to or more focused on other users. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> Compression as a Function of Ageing </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> Another aspect of the invention takes advantage of the fact that each user&apos;s input can be time stamped. Accordingly, in addition to applying compression as a function of distance and/or orientation, user space compression, spatial compression, and/or content compression can be performed as a function of time. </paragraph>
<paragraph id="P-0175" lvl="0"><number>&lsqb;0175&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a diagram showing a conversation between two users, &ldquo;John&rdquo; and &ldquo;Mary&rdquo;. Each sentence entered by both participants is shown flagged, for convenience of explanation, with a relative time stamp (i.e., T1, T2, T3 for &ldquo;John&rdquo;, T1&prime;, T2&prime;, T3&prime; for &ldquo;Mary&rdquo;); these flags may not be displayed in an actual implementation. As noted above, each time-stamped entry (word, line, sentence, etc., depending on implementation) into a user&apos;s content area <highlight><bold>322</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>322</bold></highlight><highlight><italic>b </italic></highlight>is stored in a conversation content table (see <cross-reference target="DRAWINGS">FIG. 4B</cross-reference>). In order to make more text (and thus context) visible within each user&apos;s user space while allowing more user spaces to be displayed within a conversation display space, &ldquo;older&rdquo; (earlier entered) content can be compressed by applying spatial or content compression. </paragraph>
<paragraph id="P-0176" lvl="0"><number>&lsqb;0176&rsqb;</number> In the example shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, simple spatial compression by font size reduction has been used to decrease the display size of older text. In particular, the earliest entered text (at T1, T1&prime;) for both speakers is shown in 6 point type, the next earliest (at T2, T2&prime;) in 8 point type, and the most recent (at T3, T3&prime;) in 12 point type. The trigger for size reduction of any particular text entry can be, for example, input of a new text entry, or elapse of time, or both. Content compression can also be applied, as described above, using the same or other triggers. In such case, as each user adds text, older text scrolls upwards within the user&apos;s user space. As the text scrolls upward, selective filtering takes effect, so that the oldest entries are shortened. </paragraph>
<paragraph id="P-0177" lvl="0"><number>&lsqb;0177&rsqb;</number> User space compression can also be applied, typically triggered by elapse of time. Thus, if a user has stopped inputting text or other content, the entire entered content will age and be reduced in size. Further, the user&apos;s user space can be compressed in size as well, expanding only when the user again enters new text. </paragraph>
<paragraph id="P-0178" lvl="0"><number>&lsqb;0178&rsqb;</number> Various algorithms can be applied to implement compression as a function of ageing. One algorithm would be to reduce each previously entered text line or sentence by one point when each new line or sentence is entered, stopping at a minimum display size (e.g., 6 points). Another algorithm would be to reduce each previously entered text line or sentence by one point for every period of elapsed time (e.g., 20 seconds) it has been displayed, again stopping at a minimum display size. A third algorithm would combine and extend the first two algorithms: all prior lines are reduced one point as each new line is entered, and if no new line has been entered within a period of elapsed time, all prior lines are reduced by one point (in all cases stopping at a minimum display size); thereafter, content compression is performed on the most spatially compressed lines. </paragraph>
<paragraph id="P-0179" lvl="0"><number>&lsqb;0179&rsqb;</number> Compression as a function of aging can be combined with compression as a function of proximity and orientation. A lookup table mapping these three variables to various compression actions can be constructed in a manner similar to Tables 1 and 2 above. For example, user spaces farther away from or outside the direction of attention of a central user may be &ldquo;aged&rdquo; faster than closer user spaces. Thus, user space compression, spatial compression, and content compression can be applied at a faster rate to more distant user spaces. Ageing can also be extended to non-text elements, such as graphics. For example, a graphic element can be replaced with a smaller &ldquo;thumbnail&rdquo; version or deleted entirely as a function of time. </paragraph>
<paragraph id="P-0180" lvl="0"><number>&lsqb;0180&rsqb;</number> Selective Flagging </paragraph>
<paragraph id="P-0181" lvl="0"><number>&lsqb;0181&rsqb;</number> Another aspect of the invention is a different form of selective filtering, which might be termed &ldquo;selective flagging&rdquo;, since it is not typically applied just to compress content (although it may be used for that purpose). Rather, selective flagging typically is used to draw attention to specific content of other users or to users having specific characteristics (e.g., in terms of topics, importance, or reputation). </paragraph>
<paragraph id="P-0182" lvl="0"><number>&lsqb;0182&rsqb;</number> Selective Flagging Based on Emphasis </paragraph>
<paragraph id="P-0183" lvl="0"><number>&lsqb;0183&rsqb;</number> One aspect of the invention uses the emphasis added by other users to retard or restrict selective filtering (content compression), to draw attention to those users. Whether or not text is emphasized can be determined by examining the perception attributes stored in each user&apos;s conversation content table (see <cross-reference target="DRAWINGS">FIG. 4B</cross-reference>). </paragraph>
<paragraph id="P-0184" lvl="0"><number>&lsqb;0184&rsqb;</number> For example, if another user emphasizes input text by applying bolding or italics, any operational content compression algorithms can be restricted to not eliminate the emphasized text. Similarly, any operational spatial compression algorithm can be restricted to not remove the emphasis. In another implementation, compression is retarded rather than restricted, so that a line or sentence of text, for example, must age longer before any emphasis is removed. In any case, the central user can scan all displayed user spaces within a conversation display space and visually detect any retained emphasis. </paragraph>
<paragraph id="P-0185" lvl="0"><number>&lsqb;0185&rsqb;</number> Selective flagging based on emphasis can also be used to enhance the emphasis added by other users to their text content. Any desired perception attribute can be used to flag a selected speaker. For example, a system implementing HCM can cause emphasized text (e.g., bold text) to blink or flash, in the original or a new color, thereby drawing attention to the text. Alternatively, perception attributes of a user space <highlight><bold>320</bold></highlight> containing such emphasized text can be altered, such as by changing its border color. This feature is particularly useful if the emphasis is applied with respect to text in a user space <highlight><bold>320</bold></highlight> at some distance to a central user, or outside of the central user&apos;s direction of attention. An extension of this feature is to cause icons in a world view representation of the conversation display space <highlight><bold>300</bold></highlight> to flash or otherwise signal a flagged user space <highlight><bold>320</bold></highlight>. Alternatively, the central user may be notified in any desired fashion of the location of a user space <highlight><bold>320</bold></highlight> containing emphasized content (e.g., by paging, as described below). </paragraph>
<paragraph id="P-0186" lvl="0"><number>&lsqb;0186&rsqb;</number> This form of selective flagging may also be used in reverse, to speed up compression. For example, typing in all capital letters (LIKE THIS) is considered by many chat room users to be shouting, and hence rude. Accordingly, a system implementing HCM can allow a user to define such emphasized text as a trigger for speeding up compression (e.g., by assigning a negative weight). </paragraph>
<paragraph id="P-0187" lvl="0"><number>&lsqb;0187&rsqb;</number> Selective Flagging Based on Comparison Terms </paragraph>
<paragraph id="P-0188" lvl="0"><number>&lsqb;0188&rsqb;</number> Another aspect of the invention is another version of selective flagging based on a user&apos;s key word list, list of importance terms, and/or topics list (collectively and more generally, &ldquo;comparison terms&rdquo;). Whereas selective flagging based on emphasis utilizes the perception attributes added by another speaker to flag content of interest, this form of selective flagging generally is based on using the words or terms defined by a user (see <cross-reference target="DRAWINGS">FIG. 4A</cross-reference>) in a &ldquo;positive&rdquo; manner to flag content or speakers or topics of interest. However, this form of selective filtering may be also be used in a &ldquo;negative&rdquo; fashion by using filter terms to suppress or censor conversations (e.g., suppressing display of conversations that contain profanities). </paragraph>
<paragraph id="P-0189" lvl="0"><number>&lsqb;0189&rsqb;</number> Although one list of defined comparison terms could be used in some embodiments, maintaining separate key words, importance terms, and topics can be useful. For example, key words normally would be compared against the content entered by other users. Importance terms can be compared independently against &ldquo;meta&rdquo; information, such as another user&apos;s identification or profile data that may contain, for example, a user&apos;s real name (as opposed to screen name), gender, interests, educational and personal background, etc. This distinction is useful, for instance, in distinguishing conversations about a person from conversations by that person. Further, a user&apos;s topics list can be compared against a current topic of another speaker. </paragraph>
<paragraph id="P-0190" lvl="0"><number>&lsqb;0190&rsqb;</number> This aspect of the invention can be applied to retard or restrict selective filtering (content compression), or to draw attention to users or content that match the central user&apos;s key word, importance terms, or topics. For example, if another user&apos;s identification or content matches an importance term or key word defined by the central user, any operational content compression algorithms can be restricted to not eliminate that users&apos; text. Similarly, any operational spatial compression algorithm can be restricted to not apply to that users&apos; text. In another implementation, compression is retarded rather than restricted, so that a line or sentence of text must age longer before being compressed. Thus, the central user will be able to see more of the content of flagged user spaces compared to unflagged user spaces. </paragraph>
<paragraph id="P-0191" lvl="0"><number>&lsqb;0191&rsqb;</number> This form of selective flagging can also be used to positively notify a user of the presence of user spaces that match a key word or importance term. Any desired indicator of a match can be used. For example, any desired perception attribute can be used to flag the content of a matching user space. Alternatively, perception attributes of the matching user space itself can be altered, such as by changing its border color. For example, a system implementing HCM can cause a user space <highlight><bold>320</bold></highlight> containing matching content or &ldquo;meta&rdquo; information to blink or flash, thereby drawing attention to them. An extension of this feature is to cause icons in a world view representation of the conversation display space <highlight><bold>300</bold></highlight> to flash or otherwise signal a flagged user space. Alternatively, the central user may be notified in any desired fashion of the location of a user space <highlight><bold>320</bold></highlight> containing matching content or &ldquo;meta&rdquo; information. </paragraph>
<paragraph id="P-0192" lvl="0"><number>&lsqb;0192&rsqb;</number> As noted above with respect to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>A, both key words and importance terms can have optional weighting factors (this concept can be extended to topics and similar terms as well). Such weights may be used, for example, to determine the amount of emphasis given to matches. For example, if a user lists &ldquo;oil&rdquo; with a weight of &ldquo;1&rdquo;, and &ldquo;environment&rdquo; with a weight of &ldquo;2&rdquo;, then a more prominent indicator may be used when a match is found for &ldquo;environment&rdquo; (e.g., both a flashing border and highlighting of content) than when &ldquo;oil&rdquo; is matched (e.g., only a flashing border). </paragraph>
<paragraph id="P-0193" lvl="0"><number>&lsqb;0193&rsqb;</number> This form of selective flagging may also be used in reverse, to speed up compression (this is similar to the example of censoring conversations given above, but affects the speed of compression rather than suppressing display outright). For example, a system implementing HCM can allow a user to define keywords which, when matched in other users&apos; content, serve as a trigger for speeding up compression (e.g., by assigning a negative weight). </paragraph>
<paragraph id="P-0194" lvl="0"><number>&lsqb;0194&rsqb;</number> Selective Flagging Based on Reputation </paragraph>
<paragraph id="P-0195" lvl="0"><number>&lsqb;0195&rsqb;</number> Selective flagging may also be based on the internal and/or external reputation scores of other users. This aspect of the invention can be applied, for example, to retard or restrict selective filtering (content compression), or to draw attention to users having certain reputation scores. Any desired indicator of a match can be used. For example, any desired perception attribute can be used to flag the content of a matching user space. Alternatively, perception attributes of the matching user space itself can be altered, such as by changing its border color. Thus, for example, a user space <highlight><bold>320</bold></highlight> of a participant who has a higher reputation score may be displayed with a flashing border or red colored content, while the user space <highlight><bold>320</bold></highlight> of a participant having a lower reputation score may be displayed with default attributes (e.g., black text and a black border). Alternatively, the central user may be notified in any desired fashion of the location of a user space <highlight><bold>320</bold></highlight> containing matching reputation information. </paragraph>
<paragraph id="P-0196" lvl="0"><number>&lsqb;0196&rsqb;</number> This form of selective flagging may also be used in reverse, to speed up compression or to suppress display of persons having reputation scores outside the bounds of a user selectable range. </paragraph>
<paragraph id="P-0197" lvl="7"><number>&lsqb;0197&rsqb;</number> Interdependent Implementation </paragraph>
<paragraph id="P-0198" lvl="0"><number>&lsqb;0198&rsqb;</number> It should be apparent that most of the features described above may be used in various combinations. In implementing a system based on HCM, various parameters (e.g., distance and orientation) affecting the operation of these features must be defined. In addition, certain threshold values may be variable, and thus must be selected or set for each particular application. For example, a human host of a &ldquo;cyberspace&rdquo; forum or discussion area based on a system implementing HCM may set initial default values for certain parameters and threshold values which will determine how various independent variables (e.g., distance, orientation, time stamp values, word values) will affect dependent variables (e.g., age) and various actions (e.g., user space compression, spatial compression, content compression, selective filtering, and selective flagging). In some embodiments, users may alter these default settings within a range set by the host. </paragraph>
<paragraph id="P-0199" lvl="0"><number>&lsqb;0199&rsqb;</number> As an example, one implementation of HCM could define certain independent variables as follows: </paragraph>
<paragraph id="P-0200" lvl="0"><number>&lsqb;0200&rsqb;</number> Dij&equals;distance between users i and j, coded as a number (e.g., 1 to 5, with 5 being the most distant) representing, for example, either a range of absolute distances computed from the coordinates of the user spaces for users i and j, or the number of user spaces that lie between users i and j. </paragraph>
<paragraph id="P-0201" lvl="0"><number>&lsqb;0201&rsqb;</number> Rij&equals;the relative orientation of other users j with respect to a central user i, coded into zones (e.g., 5 zones), where those user spaces near user i&apos;s direction of attention have the lowest zone value and those 180 degrees opposite have the highest zone value. </paragraph>
<paragraph id="P-0202" lvl="0"><number>&lsqb;0202&rsqb;</number> Ti&equals;the time stamp value for each text fragment (e.g., word, sentence, line) assigned to input in user i&apos;s user space. From the time stamp values for each user i, a dependent ageing variable, Aij, can be computed, coded as a number (e.g., 1 to 10, with 10 being the oldest with respect to a current time point) representing the age of a text fragment in user j&apos;s user space with respect to user i (note that i&equals;j is allowed, in order to age a user&apos;s own input). As another alternative, Ai can be defined as a coded value representing the age of a text fragment in user i&apos;s user space <highlight><bold>320</bold></highlight> with respect to current time (e.g., 1&equals;&ldquo;less than 30 seconds old&rdquo;, 2&equals;&ldquo;30-60 seconds old, etc.). As another alternative, line numbers can be used to track the relative age of input, with lower numbers indicating input from earlier in a session. A variant of this technique is to track only line numbers of text currently displayed in each user space. </paragraph>
<paragraph id="P-0203" lvl="0"><number>&lsqb;0203&rsqb;</number> Wik&equals;a word value score assigned to k words, comprising pre-defined application-wide words and each word in user i&apos;s key word list and list of importance terms. This value measures the word&apos;s likely relevance to the user. A high numerical value of Wik for word k means the word has high priority and should be eliminated later in content compression. A low value of Wik for word k means the word has low priority and should be eliminated earlier in content compression. </paragraph>
<paragraph id="P-0204" lvl="0"><number>&lsqb;0204&rsqb;</number> Increasing values of Dij, Rij, and Aij (or &ldquo;older&rdquo; values of Ti) indicate that various forms of compression can be applied. In this example embodiment, these variables can be combined in a linear or non-linear manner to generate a composite score, Xij, indicating whether the content and/or user space of user j should be compressed with respect to user i. The composite score may be compared to pre-set threshold values to determine the appropriate action to take. Whenever the composite score exceeds each threshold, certain actions are triggered that affect a user space. The following examples indicate actions that may be taken for the user space of user j when the composite score exceeds defined thresholds with respect to user i: </paragraph>
<paragraph id="P-0205" lvl="0"><number>&lsqb;0205&rsqb;</number> When X&gt;4, change all words in bold type to plain text. </paragraph>
<paragraph id="P-0206" lvl="0"><number>&lsqb;0206&rsqb;</number> When X&gt;6, reduce the typeface of all text fragments having an age greater than 1 by one point and reduce line separation accordingly. If it is now possible to combine two lines into one, do so. Remove blue highlights, and change red highlights to blue. If the vertical height of the text is less than the display height of the content area for the next smallest user space size, reduce the user space size. </paragraph>
<paragraph id="P-0207" lvl="0"><number>&lsqb;0207&rsqb;</number> When X&gt;10, reduce the typeface of all text fragments having an age greater than 1 by one point, and having an age greater than 3 by two points, and reduce line separation accordingly. If it is now possible to combine two lines into one, do so. Begin selective word filtering, removing all words with priority values of 2 or lower. Abbreviate (if possible) all words with values of 4 or lower. Highlight in flashing blue those words with values of 12 or higher. </paragraph>
<paragraph id="P-0208" lvl="0"><number>&lsqb;0208&rsqb;</number> As should be apparent, other combinations of the available variables can be made, and different threshold values and resulting actions defined. Further, different functions of each variable can be defined and then combined in different ways. For example, a human host of a forum can define such functions and their combination for a particular forum. Alternatively, the functions and/or the &ldquo;combining function&rdquo; may be determined automatically (e.g., the functions may change with the number of participants in a forum). </paragraph>
<paragraph id="P-0209" lvl="0"><number>&lsqb;0209&rsqb;</number> As another alternative, each user may be allowed to select their own set of operational functions. For example, <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a diagram of a control dialog that allows a user to select various combinations of functions to apply during a forum session. In the illustrated example, a user can select one of four distance functions f<highlight><subscript>n</subscript></highlight>(d), orientation functions g<highlight><subscript>n</subscript></highlight>(r), and time or ageing functions h<highlight><subscript>n</subscript></highlight>(t). The distance functions may provide, for example, different numbers and/or sizes of distance zones. The orientation functions may provide for different definitions, such as 2, 4, 6, or 8 zones arrayed radially around the user&apos;s user space <highlight><bold>320</bold></highlight>. The time functions may provide different ageing characteristics, such as from slow to fast. The functions selected by a suer may be combined in a linear or non-linear way to generate a composite score, such as the Xij function described above. </paragraph>
<paragraph id="P-0210" lvl="7"><number>&lsqb;0210&rsqb;</number> Transcript Mode </paragraph>
<paragraph id="P-0211" lvl="0"><number>&lsqb;0211&rsqb;</number> A useful feature of the invention is the ability to create &ldquo;transcripts&rdquo; of conversations. For example, users &ldquo;John&rdquo; and &ldquo;Mary&rdquo; may wish to have an interleaved rendition of their mutual conversation. Since each entry into their respective user space is time stamped, it is straightforward to retrieve their inputs from their respective conversation content tables (see <cross-reference target="DRAWINGS">FIG. 4B</cross-reference>) and display them in a marked, chronologically interleaved manner. <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a diagram of a conversation transcript. A display window <highlight><bold>1200</bold></highlight> depicts three interleaved text entries <highlight><bold>1202</bold></highlight>-<highlight><bold>1206</bold></highlight> marked by speaker and time. A scroll bar <highlight><bold>1208</bold></highlight> is provided to allow longer transcripts to be reviewed, in conventional manner. A user may save a transcript for later review, printout, emailing, etc. </paragraph>
<paragraph id="P-0212" lvl="0"><number>&lsqb;0212&rsqb;</number> In some host environments, it may be permitted for a user who is not part of a particular conversation to nevertheless select a group of other users&mdash;either on the user&apos;s personal screen or in the larger-scale world view&mdash;and request a transcript of what is (or was) said by members of the selected group. A host server may provide a service that notifies such a group that an outsider wishes to eavesdrop, lurk, listen, or create a transcript. Further, a host server may enable such groups to disallow or block such eavesdropping, listening, or transcription by outsiders. </paragraph>
<paragraph id="P-0213" lvl="7"><number>&lsqb;0213&rsqb;</number> Merging of User Spaces </paragraph>
<paragraph id="P-0214" lvl="0"><number>&lsqb;0214&rsqb;</number> In addition to, or in lieu of transcription, two or more users may elect to merge their user spaces into a unified conversation space, creating, in effect, a running transcript of their conversations comprising interleaved comments by different users, each identified by some unique iconic or symbolic representation. In one implementation, a set of users could recreate the manner of &ldquo;chatting&rdquo; that they were familiar with from old-fashioned chat rooms. Outsiders who wish to merge with such a group may be required to ask permission of those already participating in the merged space. </paragraph>
<paragraph id="P-0215" lvl="7"><number>&lsqb;0215&rsqb;</number> Kiosks </paragraph>
<paragraph id="P-0216" lvl="0"><number>&lsqb;0216&rsqb;</number> As noted above, HCM supports &ldquo;kiosks&rdquo;, in which users can interact with non-human information sources or resources or activity centers, typically displayed in a graphical or iconic manner in a conversation display space <highlight><bold>300</bold></highlight>. Kiosks may provide, for example, a service, function, information, object, or other form of interaction. For example, <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a conversation display space <highlight><bold>300</bold></highlight> in which the user space <highlight><bold>320</bold></highlight> for one user, &ldquo;John&rdquo;, is near and focused on a kiosk <highlight><bold>1200</bold></highlight> that is advertising an object that may be downloaded (in the illustrated example, a free software program). By moving his user space <highlight><bold>320</bold></highlight> near the kiosk <highlight><bold>1300</bold></highlight> and activating an appropriate control or command (e.g., from a right-click menu), &ldquo;John&rdquo; can initiate a download of the offered program in conventional fashion. The transfer function can also be initiated in other manners, such as by &ldquo;bumping&rdquo; the user&apos;s user space <highlight><bold>320</bold></highlight> or orientation control <highlight><bold>350</bold></highlight> against the kiosk <highlight><bold>1300</bold></highlight>, or &ldquo;hovering&rdquo; the user space <highlight><bold>320</bold></highlight> over the kiosk <highlight><bold>1300</bold></highlight>. Other kiosk functions can be indicated using various types of shapes or icons; for example, a &ldquo;web&rdquo; phone kiosk <highlight><bold>1302</bold></highlight> is shown depicted by a telephone icon. </paragraph>
<paragraph id="P-0217" lvl="0"><number>&lsqb;0217&rsqb;</number> Similarly, a user may upload an object from a user space to a kiosk, such as an image that the user wishes to have converted to a different format or rendered in a different fashion (e.g., printed on quality photographic paper and mailed back). </paragraph>
<paragraph id="P-0218" lvl="0"><number>&lsqb;0218&rsqb;</number> Kiosks can be used for other purposes, such as posting persistent notes (e.g., so that they may be read by other users in a forum when the poster logs off the forum) or offering telecommunication services (e.g., a web phone, text messaging to cell phones, radio paging, etc.). As another example, &ldquo;touching&rdquo; or activating a kiosk may trigger the appearance of a web page, such as one offering information or items for sale, or a personal site or profile, or access to a web-based information search engine. A kiosk may also serve as a teleportation site or an exit from a current user space <highlight><bold>320</bold></highlight>, offering, for example, &ldquo;transit&rdquo; to another portion of the same conversation display universe, or to a different conversation display universe, or to a web site or another program. </paragraph>
<paragraph id="P-0219" lvl="7"><number>&lsqb;0219&rsqb;</number> Object Transference </paragraph>
<paragraph id="P-0220" lvl="0"><number>&lsqb;0220&rsqb;</number> A system implementing HCM can allow transference of objects (e.g., a symbol, token, or file) between users, similar to the interactions noted above for kiosks. In one embodiment, when a central user&apos;s user space is near and focused on another user&apos;s user space, the central user can give or send an object to the other user by activating a suitable control (e.g., a &ldquo;send to&rdquo; command on a right-click menu). For example, one user can pass a &ldquo;smiley face&rdquo; icon to another user as a token of friendship. Alternatively, the central user can allow the other user to take an object from the central user (the other user would activate a suitable control). The transfer function can also be initiated in other manners, such as by &ldquo;bumping&rdquo; the central user&apos;s user space (or orientation control) against the other user&apos;s user space (or orientation control), or &ldquo;hovering&rdquo; the central user&apos;s user space over the other user&apos;s user space. </paragraph>
<paragraph id="P-0221" lvl="0"><number>&lsqb;0221&rsqb;</number> This aspect of the invention may be particularly useful in a game-oriented implementation of HCM. Users can move around a conversation display space <highlight><bold>300</bold></highlight> that also defines a &ldquo;playing field&rdquo; and give, take, or exchange objects with other players. The objects can be used for a variety of actions, such as opening &ldquo;locked&rdquo; areas of the conversation display space <highlight><bold>300</bold></highlight> or acquiring &ldquo;tools&rdquo; useful for solving puzzles presented by kiosks. </paragraph>
<paragraph id="P-0222" lvl="7"><number>&lsqb;0222&rsqb;</number> Alternative Embodiments </paragraph>
<paragraph id="P-0223" lvl="0"><number>&lsqb;0223&rsqb;</number> A number of alternative embodiments of HCM can be implemented. For example, <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a diagram showing an alternative embodiment of the invention in which all user spaces <highlight><bold>320</bold></highlight> are docked along the edges of a conversation display space <highlight><bold>300</bold></highlight>, and only the associated orientation controls <highlight><bold>350</bold></highlight> are moved and reoriented (in this example, the orientation controls <highlight><bold>350</bold></highlight> are &ldquo;articulated&rdquo;, so that the can bend at one or more points, and proximity can be defined as the distance between orientation controls <highlight><bold>350</bold></highlight>). This embodiment may be useful, for example, in a moderated discussion or presentation, in which most participants are focused on a small number of speakers (&ldquo;Roger&rdquo;, in the illustrated embodiment). Other users can ask questions (as &ldquo;John&rdquo; is doing), or hold side conversations, open or private (as &ldquo;Pam&rdquo; and &ldquo;Susan&rdquo; are about to do in this example by positioning their respective orientation controls <highlight><bold>350</bold></highlight><highlight><italic>a</italic></highlight>, <highlight><bold>350</bold></highlight><highlight><italic>b</italic></highlight>). </paragraph>
<paragraph id="P-0224" lvl="0"><number>&lsqb;0224&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is a diagram showing another embodiment of the invention in which all orientation controls <highlight><bold>350</bold></highlight> are docked along the edges of a conversation display space <highlight><bold>300</bold></highlight>, and only the user spaces <highlight><bold>320</bold></highlight> are moved. In this example, each orientation control <highlight><bold>350</bold></highlight> shows the direction of attention by a darkened quadrant arrow, and proximity can be defined as the distance between user spaces <highlight><bold>320</bold></highlight>. </paragraph>
<paragraph id="P-0225" lvl="0"><number>&lsqb;0225&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a screen shot of another embodiment of the invention in which several user spaces <highlight><bold>320</bold></highlight> are shown arrayed around a central user&apos;s orientation control <highlight><bold>350</bold></highlight> within a conversation display space <highlight><bold>300</bold></highlight>. A graphical &ldquo;tear drop&rdquo; indicator <highlight><bold>1602</bold></highlight> associated with each orientation control <highlight><bold>350</bold></highlight> and user space <highlight><bold>320</bold></highlight> shows the current orientation of each participant. In this embodiment, the central user enters information in a content area <highlight><bold>322</bold></highlight> located at the bottom of the screen, to conserve screen space. A world view <highlight><bold>700</bold></highlight> of the conversation display is also shown, indicating with circles <highlight><bold>1604</bold></highlight> the relative locations of the four participants displayed in the conversation display space <highlight><bold>300</bold></highlight>. </paragraph>
<paragraph id="P-0226" lvl="0"><number>&lsqb;0226&rsqb;</number> As should be apparent, a number of possible geometrical schemes may be used to depict user spaces <highlight><bold>320</bold></highlight> and how they interact with each other. A typical depiction is the non-linear, symmetrical, two-dimensional implementation portrayed in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, utilizing screen-warping to reduce the apparent size of more distant user spaces, enabling more user spaces to fit along the boundaries of a user&apos;s limited view of a current conversation display space <highlight><bold>300</bold></highlight>. Other implementations may include three-dimensional depictions of user spaces <highlight><bold>320</bold></highlight> that have the appearance of height, width, and depth along with visual rendering to emulate real physical objects (e.g., billboard signs, notebooks, newspapers, etc.). </paragraph>
<paragraph id="P-0227" lvl="0"><number>&lsqb;0227&rsqb;</number> In alternative implementations, the conversation display space <highlight><bold>300</bold></highlight> may be graphically depicted as an &ldquo;auditorium&rdquo;, &ldquo;stadium&rdquo;, &ldquo;arena&rdquo;, &ldquo;stage&rdquo;, or the like. Preferably, the conversation display space <highlight><bold>300</bold></highlight> is &ldquo;skinnable&rdquo;, so that a host or a user can vary the graphical depiction at will. In such alternative implementations, various users may find their respective user spaces <highlight><bold>320</bold></highlight> arrayed in fixed &ldquo;geometric&rdquo; positions in order to maximize the visibility of the user space <highlight><bold>320</bold></highlight> of a particular speaker, such as a performer or lecturer. </paragraph>
<paragraph id="P-0228" lvl="0"><number>&lsqb;0228&rsqb;</number> Any of these various graphical and &ldquo;geometric&rdquo; schemes may be used exclusively within a host space, or the host may chose to vary the &ldquo;landscape&rdquo; of a conversation display space <highlight><bold>300</bold></highlight> by allowing users to move from one local geometrical arrangement to another. Indeed, the geometrical rules of a particular local region within a conversation display space <highlight><bold>300</bold></highlight> may be conditional. That is, such rules may change depending on the needs of users present in a region or depending upon the number of users who gather in a region. For example, when a large number of users gather in close proximity, perhaps attracted by an interesting topic or a user with high reputation values, the resulting crowd of user spaces <highlight><bold>320</bold></highlight> may create congestion or interference of one or more perceptual traits. Accordingly, one embodiment of the invention may offer hosts a number of alternate geometry services that would enable users to avoid such interference or congestion. </paragraph>
<paragraph id="P-0229" lvl="0"><number>&lsqb;0229&rsqb;</number> For example, when some number of users (e.g., 6 or more) try to cluster close together, aiming their direction of attention vectors at one individual speaker, the system can detect the number of users and their relative proximities, and automatically impose an &ldquo;amphitheater&rdquo; or &ldquo;auditorium&rdquo; geometry on the group of participants, with the focus or &ldquo;podium&rdquo; position given to the speaker receiving the greatest amount of attention. Alternatively, denizens of a crowded area may be presented with various geometrical solutions to local overcrowding and invited to vote among these options (e.g., &ldquo;form an amphitheater&rdquo; or &ldquo;form a theater in the round&rdquo;) and which user&apos;s user space will be given the podium position. In such group geometries, the moderator and guest user(s) may be displayed in an enhanced manner to all participants while the perceived presence of other users (i.e., the audience) is diminished. </paragraph>
<paragraph id="P-0230" lvl="7"><number>&lsqb;0230&rsqb;</number> Optional Features </paragraph>
<paragraph id="P-0231" lvl="0"><number>&lsqb;0231&rsqb;</number> In a system implementing HCM, application of the following optional rules and behavioral settings may be controlled by a host in order to create an environment better tailored to the needs of particular users. </paragraph>
<paragraph id="P-0232" lvl="0"><number>&lsqb;0232&rsqb;</number> 1) A user may or may not be allowed to move between two user spaces whose orientation controls are aimed directly at each other. </paragraph>
<paragraph id="P-0233" lvl="0"><number>&lsqb;0233&rsqb;</number> 2) User spaces may or may not be allowed to overlap. </paragraph>
<paragraph id="P-0234" lvl="0"><number>&lsqb;0234&rsqb;</number> 3) User spaces <highlight><bold>320</bold></highlight> may be bordered or borderless. </paragraph>
<paragraph id="P-0235" lvl="0"><number>&lsqb;0235&rsqb;</number> 4) The system may or may not be set so that the user&apos;s user space is collapsed to a small icon or symbol having an indicator of the user&apos;s last direction of attention when a participant is not &ldquo;speaking&rdquo;, or has not spoken for a set period of time. </paragraph>
<paragraph id="P-0236" lvl="0"><number>&lsqb;0236&rsqb;</number> 5) A &ldquo;whisper&rdquo; mode may or may not be allowed. If allowed, two or more direct neighbors can invoke a private &ldquo;whisper&rdquo; mode (e.g., by activating a suitable control). When activated, input by each user is displayed only to other members of the privacy group, as controlled by the system. Hosts may set the system to activate a whisper mode indicator showing that a private conversation is taking place. This mimics natural conversations, since people surrounding other people whispering in public know that a conversation is being held, but do not know what information is being exchanged. An example of a private conversation depicted in a &ldquo;world&rdquo; view is shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, where a line joins users &ldquo;Jane&rdquo; and &ldquo;Joe&rdquo; and shading has been applied to their respective icons <highlight><bold>320</bold></highlight><highlight><italic>i</italic></highlight>&prime;, <highlight><bold>320</bold></highlight><highlight><italic>j</italic></highlight>&prime;. In an alternative embodiment, the user spaces for participants in a private conversation are not displayed. </paragraph>
<paragraph id="P-0237" lvl="0"><number>&lsqb;0237&rsqb;</number> 6) Users may or may not be allowed to &ldquo;capture&rdquo; (copy) or record the content displayed in another user&apos;s user space (such as by activating a right-click menu). </paragraph>
<paragraph id="P-0238" lvl="0"><number>&lsqb;0238&rsqb;</number> 7) Users may or may not be allowed to &ldquo;eavesdrop&rdquo; on distant conversations. For example, if allowed, a user could indicate a conversation to monitor (e.g., by clicking on another user&apos;s user space) without having to move. In one embodiment, a temporary window would appear near the user with a readable replica of the other user&apos;s conversation. This mode is particularly useful in a world view of a forum, or when distant user spaces have been reduced to icons or other symbols. The other user may or may not be notified of the &ldquo;intrusion&rdquo;, as selected by the host. </paragraph>
<paragraph id="P-0239" lvl="0"><number>&lsqb;0239&rsqb;</number> 8) Users may or may not be allowed to move or &ldquo;teleport&rdquo; the user space of other users. If allowed, another user can literally be pulled into a conversation. </paragraph>
<paragraph id="P-0240" lvl="0"><number>&lsqb;0240&rsqb;</number> 9) Users may or may not be allowed to have multiple user spaces (thus allowing them to be in two or more places at the same time). </paragraph>
<paragraph id="P-0241" lvl="0"><number>&lsqb;0241&rsqb;</number> 10) A host may or may not allow a &ldquo;meeting mode&rdquo; (useful for a formal business meeting or the like). If allowed, a designated &ldquo;chair&rdquo; sees the contents of the user spaces of all participants, but controls which participant is to be &ldquo;recognized&rdquo; and allowed to &ldquo;speak&rdquo; to the group (i.e., have such content displayed for all to see). In one implementation, the system would display all entered content to the &ldquo;chair&rdquo; participant at all times. Otherwise, each other participant normally would only see their own input and the content of the &ldquo;chair&rdquo; participant&apos;s user space. The &ldquo;chair&rdquo; can &ldquo;recognize&rdquo; one or more other users (e.g., by clicking on their respective user spaces). The system would then provide the content of such recognized participants to all other participants. As a variant, a host may or may not allow the audience members to vary their orientation (i.e., the direction of attention for all audience members is forced to face a selected location). </paragraph>
<paragraph id="P-0242" lvl="0"><number>&lsqb;0242&rsqb;</number> 11) A host may or may not allow &ldquo;paging&rdquo; of a user when an associated selective flag is triggered. That is, when a selective flagging event occurs relative to a user, the system will set an indicator associated with that user. The &ldquo;page&rdquo; indicator may be set within the user&apos;s own user space (e.g., a message in the title bar <highlight><bold>324</bold></highlight>) or set within the conversation display space <highlight><bold>300</bold></highlight> (e.g., a flashing status bar <highlight><bold>305</bold></highlight> indicator). Alternatively, a &ldquo;page&rdquo; message may be sent in an &ldquo;out of channel&rdquo; manner (i.e., not using the conversation forum features directly), such as by telephoning, emailing, or radio paging a user to indicate that a selective flag has been triggered. Another alternative is to allow a participant to use any of these paging mechanisms to actively invite another user to join a conversation. </paragraph>
<paragraph id="P-0243" lvl="0"><number>&lsqb;0243&rsqb;</number> 12) A host may or may not allow users to eliminate display of non-immediately neighboring user spaces <highlight><bold>320</bold></highlight>, thus allowing neighboring user spaces <highlight><bold>320</bold></highlight> to be depicted at a larger size. This may be accomplished, for example, by allowing users to set values for distance codings and the default sizes of user spaces. Alternatively, a user may be allowed to select (e.g., by pointing and clicking) which user spaces <highlight><bold>320</bold></highlight> to suppress, on an ad hoc basis, or define rules for suppressing user spaces <highlight><bold>320</bold></highlight> (e.g., &ldquo;suppress user spaces having a current topic of oil drilling&rdquo;). </paragraph>
<paragraph id="P-0244" lvl="7"><number>&lsqb;0244&rsqb;</number> Implementation </paragraph>
<paragraph id="P-0245" lvl="0"><number>&lsqb;0245&rsqb;</number> The invention may be implemented in hardware or software, or a combination of both (e.g., programmable logic arrays). Unless otherwise specified, the algorithms included as part of the invention are not inherently related to any particular computer or other apparatus. In particular, various general purpose machines may be used with programs written in accordance with the teachings herein, or it may be more convenient to construct more specialized apparatus (e.g., integrated circuits) to perform the stated function. Thus, the invention may be implemented in one or more computer programs executing on one or more programmable computer systems each comprising at least one processor, at least one data storage system (including volatile and non-volatile memory and/or storage elements), at least one input device or port, and at least one output device or port. Program code is applied to input data to perform the functions described herein and generate output information. The output information is applied to one or more output devices, in known fashion. </paragraph>
<paragraph id="P-0246" lvl="0"><number>&lsqb;0246&rsqb;</number> Each such program may be implemented in any desired computer language (including machine, assembly, or high level procedural, logical, or object oriented programming languages) to communicate with a computer system. In any case, the language may be a compiled or interpreted language. </paragraph>
<paragraph id="P-0247" lvl="0"><number>&lsqb;0247&rsqb;</number> Each such computer program is preferably stored on or downloaded to a storage media or device (e.g., solid state memory or media, or magnetic or optical media) readable by a general or special purpose programmable computer, for configuring and operating the computer when the storage media or device is read by the computer system to perform the procedures described herein. The inventive system may also be considered to be implemented as a computer-readable storage medium, configured with a computer program, where the storage medium so configured causes a computer system to operate in a specific and predefined manner to perform the functions described herein. </paragraph>
<paragraph id="P-0248" lvl="0"><number>&lsqb;0248&rsqb;</number> The accompanying appendix includes the JAVA program code for a working prototype of one embodiment of the invention. </paragraph>
<paragraph id="P-0249" lvl="0"><number>&lsqb;0249&rsqb;</number> In the implementations described above, a host system may define various rules of interaction among the user spaces <highlight><bold>320</bold></highlight> of various users. However, a centralized host system is not essential. For example, the invention may be implemented as a &ldquo;peer-to-peer&rdquo; system. In such an implementation, various users can interact with each other under representational formats that are derived ad hoc, when two or more users of an HCM system initially contact each other. Thus, two or more users can define the graphical representation of a conversation display space <highlight><bold>300</bold></highlight> and of user spaces <highlight><bold>320</bold></highlight>, and the &ldquo;rules of engagement&rdquo; for participants. </paragraph>
<paragraph id="P-0250" lvl="0"><number>&lsqb;0250&rsqb;</number> A number of embodiments of the invention have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the invention. For example, a system implementing HCM can incorporate text-to-speech technology to allow use by vision-impaired users. Accordingly, other embodiments are within the scope of the following claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of interactive communication between a plurality of users, including: 
<claim-text>(a) displaying a conversation display space having at least two dimensions; </claim-text>
<claim-text>(b) displaying a plurality of orientation controls, each having a corresponding user space, within the conversation display space; </claim-text>
<claim-text>(c) enabling a user to move or reorient an associated orientation control relative to at least one other orientation control within the conversation display space; and </claim-text>
<claim-text>(d) enabling communication of content between at least two user spaces corresponding to such orientation controls. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the conversation display space is user-centric. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including enabling at least one user to add perception attributes to the user space corresponding to the orientation control associated with such user. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including displaying content entered by a user in the user space corresponding to the orientation control associated with such user, and enabling such user to add perception attributes to at least some of such content. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including varying the size of user spaces. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further including varying the size of user spaces as a function of distance between such user spaces. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further including varying the size of user spaces as a function of orientation between such user spaces. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, further including varying the size of user spaces as a function of user centric orientation between such user spaces. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, further including varying the size of user spaces as a function of mutual orientation between such user spaces. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further including varying the size of user spaces as a function of the reputation of such users. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, further including automatically determining the reputation of such users. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further including varying the size of user spaces as a function of the time content was communicated. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further including varying the size of user spaces as a function of the time content was communicated and as a function of characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein after a user space has been decreased in size, further including enabling a user to restore the size of such user space. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including displaying content communicated by each user in the user space corresponding to the orientation control associated with such user, and varying the size of the content of at least one user space. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, further including varying the size of such content as a function of distance between user spaces. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, further including varying the size of such content as a function of orientation between user spaces. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, further including varying the size of such content as a function of the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, further including automatically determining the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, further including varying the size of such content as a function of the time such content was communicated. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, further including varying the size of such content as a function of the time such content was communicated and as a function of characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including displaying selected amounts of content communicated by each user within the user space corresponding to the orientation control associated with such user. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further including selecting the amount of content displayed as a function of distance between user spaces. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further including selecting the amount of content displayed as a function of orientation between user spaces. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further including selecting the amount of content displayed as a function of the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, further including automatically determining the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further including selecting the amount of content displayed as a function of the time such content was communicated. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further including selecting the amount of content displayed as a function of the time such content was communicated and as a function of characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including displaying content communicated by each user in the user space corresponding to the orientation control associated with such user, and applying filtering criteria to select at least one user space. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, wherein the filtering criteria include characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, wherein the filtering criteria include comparing selected comparison terms against the content of a user space. </claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, wherein the filtering criteria include comparing selected comparison terms against metadata associated with a user space. </claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, wherein the filtering criteria include the reputation of a user. </claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, wherein the filtering criteria include at least one perception attribute associated with the content of a user space. </claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, further including changing at least one perception attribute of a user space or of the content of a user space as a result of meeting the filtering criteria. </claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, further including communicating a paging indicator based as a result of meeting the filtering criteria. </claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including enabling transfer of an object between user spaces. </claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including enabling interaction between a user space and a kiosk. </claim-text>
</claim>
<claim id="CLM-00039">
<claim-text><highlight><bold>39</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 38</dependent-claim-reference>, wherein the interaction includes transfer of an object between the user space and the kiosk. </claim-text>
</claim>
<claim id="CLM-00040">
<claim-text><highlight><bold>40</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including displaying a world view of the user spaces. </claim-text>
</claim>
<claim id="CLM-00041">
<claim-text><highlight><bold>41</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including selectively suppressing display of at least one user space. </claim-text>
</claim>
<claim id="CLM-00042">
<claim-text><highlight><bold>42</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including enabling a privacy mode whereby content of a user is communicated only to selected other users. </claim-text>
</claim>
<claim id="CLM-00043">
<claim-text><highlight><bold>43</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including outputting a chronological interleaved transcript of content communicated among selected users. </claim-text>
</claim>
<claim id="CLM-00044">
<claim-text><highlight><bold>44</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further including displaying all communicated content only to at least one selected user, and enabling such at least one selected user to selectively communicate such content to selected other users. </claim-text>
</claim>
<claim id="CLM-00045">
<claim-text><highlight><bold>45</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein each orientation control is integrated with its corresponding user space. </claim-text>
</claim>
<claim id="CLM-00046">
<claim-text><highlight><bold>46</bold></highlight>. A method of interactive communication between a plurality of users, including: 
<claim-text>(a) displaying a conversation display space having at least two dimensions; </claim-text>
<claim-text>(b) displaying a plurality of user spaces within the conversation display space; </claim-text>
<claim-text>(c) enabling a user to move or reorient an associated user space relative to at least one other user space within the conversation display space; and </claim-text>
<claim-text>(d) enabling communication of content between at least two user spaces. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00047">
<claim-text><highlight><bold>47</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, wherein the conversation display space is user-centric. </claim-text>
</claim>
<claim id="CLM-00048">
<claim-text><highlight><bold>48</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including enabling at least one user to add perception attributes to the user space associated with such user. </claim-text>
</claim>
<claim id="CLM-00049">
<claim-text><highlight><bold>49</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including displaying content entered by a user in the user space associated with such user, and enabling such user to add perception attributes to at least some of such content. </claim-text>
</claim>
<claim id="CLM-00050">
<claim-text><highlight><bold>50</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including varying the size of user spaces. </claim-text>
</claim>
<claim id="CLM-00051">
<claim-text><highlight><bold>51</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 50</dependent-claim-reference>, further including varying the size of user spaces as a function of distance between such user spaces. </claim-text>
</claim>
<claim id="CLM-00052">
<claim-text><highlight><bold>52</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 50</dependent-claim-reference>, further including varying the size of user spaces as a function of orientation between such user spaces. </claim-text>
</claim>
<claim id="CLM-00053">
<claim-text><highlight><bold>53</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 52</dependent-claim-reference>, further including varying the size of user spaces as a function of user centric orientation between such user spaces. </claim-text>
</claim>
<claim id="CLM-00054">
<claim-text><highlight><bold>54</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 52</dependent-claim-reference>, further including varying the size of user spaces as a function of mutual orientation between such user spaces. </claim-text>
</claim>
<claim id="CLM-00055">
<claim-text><highlight><bold>55</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 50</dependent-claim-reference>, further including varying the size of user spaces as a function of the reputation of such users. </claim-text>
</claim>
<claim id="CLM-00056">
<claim-text><highlight><bold>56</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 55</dependent-claim-reference>, further including automatically determining the reputation of such users. </claim-text>
</claim>
<claim id="CLM-00057">
<claim-text><highlight><bold>57</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 50</dependent-claim-reference>, further including varying the size of user spaces as a function of the time content was communicated. </claim-text>
</claim>
<claim id="CLM-00058">
<claim-text><highlight><bold>58</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 50</dependent-claim-reference>, further including varying the size of user spaces as a function of the time content was communicated and as a function of characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00059">
<claim-text><highlight><bold>59</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 50</dependent-claim-reference>, wherein after a user space has been decreased in size, further including enabling a user to restore the size of such user space. </claim-text>
</claim>
<claim id="CLM-00060">
<claim-text><highlight><bold>60</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including displaying content communicated by each user in the user space associated with such user, and varying the size of the content of at least one user space. </claim-text>
</claim>
<claim id="CLM-00061">
<claim-text><highlight><bold>61</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 60</dependent-claim-reference>, further including varying the size of such content as a function of distance between user spaces. </claim-text>
</claim>
<claim id="CLM-00062">
<claim-text><highlight><bold>62</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 60</dependent-claim-reference>, further including varying the size of such content as a function of orientation between user spaces. </claim-text>
</claim>
<claim id="CLM-00063">
<claim-text><highlight><bold>63</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 60</dependent-claim-reference>, further including varying the size of such content as a function of the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00064">
<claim-text><highlight><bold>64</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 63</dependent-claim-reference>, further including automatically determining the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00065">
<claim-text><highlight><bold>65</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 60</dependent-claim-reference>, further including varying the size of such content as a function of the time such content was communicated. </claim-text>
</claim>
<claim id="CLM-00066">
<claim-text><highlight><bold>66</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 60</dependent-claim-reference>, further including varying the size of such content as a function of the time such content was communicated and as a function of characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00067">
<claim-text><highlight><bold>67</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including displaying selected amounts of content communicated by each user the user space associated with such user. </claim-text>
</claim>
<claim id="CLM-00068">
<claim-text><highlight><bold>68</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 67</dependent-claim-reference>, further including selecting the amount of content displayed as a function of distance between user spaces. </claim-text>
</claim>
<claim id="CLM-00069">
<claim-text><highlight><bold>69</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 67</dependent-claim-reference>, further including selecting the amount of content displayed as a function of orientation between user spaces. </claim-text>
</claim>
<claim id="CLM-00070">
<claim-text><highlight><bold>70</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 67</dependent-claim-reference>, further including selecting the amount of content displayed as a function of the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00071">
<claim-text><highlight><bold>71</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00077">claim 70</dependent-claim-reference>, further including automatically determining the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00072">
<claim-text><highlight><bold>72</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 67</dependent-claim-reference>, further including selecting the amount of content displayed as a function of the time such content was communicated. </claim-text>
</claim>
<claim id="CLM-00073">
<claim-text><highlight><bold>73</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00066">claim 67</dependent-claim-reference>, further including selecting the amount of content displayed as a function of the time such content was communicated and as a function of characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00074">
<claim-text><highlight><bold>74</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including displaying content communicated by each user in the user space associated with such user, and applying filtering criteria to select at least one user space. </claim-text>
</claim>
<claim id="CLM-00075">
<claim-text><highlight><bold>75</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00077">claim 74</dependent-claim-reference>, wherein the filtering criteria include characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00076">
<claim-text><highlight><bold>76</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00077">claim 74</dependent-claim-reference>, wherein the filtering criteria include comparing selected comparison terms against the content of a user space. </claim-text>
</claim>
<claim id="CLM-00077">
<claim-text><highlight><bold>77</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00077">claim 74</dependent-claim-reference>, wherein the filtering criteria include comparing selected comparison terms against metadata associated with a user space. </claim-text>
</claim>
<claim id="CLM-00078">
<claim-text><highlight><bold>78</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00077">claim 74</dependent-claim-reference>, wherein the filtering criteria include the reputation of a user. </claim-text>
</claim>
<claim id="CLM-00079">
<claim-text><highlight><bold>79</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00077">claim 74</dependent-claim-reference>, wherein the filtering criteria include at least one perception attribute associated with the content of a user space. </claim-text>
</claim>
<claim id="CLM-00080">
<claim-text><highlight><bold>80</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00077">claim 74</dependent-claim-reference>, further including changing at least one perception attribute of a user space or of the content of a user space as a result of meeting the filtering criteria. </claim-text>
</claim>
<claim id="CLM-00081">
<claim-text><highlight><bold>81</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00077">claim 74</dependent-claim-reference>, further including communicating a paging indicator based as a result of meeting the filtering criteria. </claim-text>
</claim>
<claim id="CLM-00082">
<claim-text><highlight><bold>82</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including enabling transfer of an object between user spaces. </claim-text>
</claim>
<claim id="CLM-00083">
<claim-text><highlight><bold>83</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including enabling interaction between a user space and a kiosk. </claim-text>
</claim>
<claim id="CLM-00084">
<claim-text><highlight><bold>84</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00088">claim 83</dependent-claim-reference>, wherein the interaction includes transfer of an object between the user space and the kiosk. </claim-text>
</claim>
<claim id="CLM-00085">
<claim-text><highlight><bold>85</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including displaying a world view of the user spaces. </claim-text>
</claim>
<claim id="CLM-00086">
<claim-text><highlight><bold>86</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including selectively suppressing display of at least one user space. </claim-text>
</claim>
<claim id="CLM-00087">
<claim-text><highlight><bold>87</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including enabling a privacy mode whereby content of a user is communicated only to selected other users. </claim-text>
</claim>
<claim id="CLM-00088">
<claim-text><highlight><bold>88</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including outputting a chronological interleaved transcript of content communicated among selected users. </claim-text>
</claim>
<claim id="CLM-00089">
<claim-text><highlight><bold>89</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further including displaying all communicated content only to at least one selected user, and enabling such at least one selected user to selectively communicate such content to selected other users. </claim-text>
</claim>
<claim id="CLM-00090">
<claim-text><highlight><bold>90</bold></highlight>. A method of interactive communication between a plurality of users, including: 
<claim-text>(a) displaying a conversation display universe; </claim-text>
<claim-text>(b) displaying, within the conversation display universe, a corresponding user space for each of a plurality of users; </claim-text>
<claim-text>(c) enabling each user to input content within the user space corresponding to such user, and communicating such content to the corresponding user space of at least one other user; and </claim-text>
<claim-text>(d) for at least one user, displaying selected amounts of content communicated by each other user within the user space corresponding to each such other user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00091">
<claim-text><highlight><bold>91</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 90</dependent-claim-reference>, further including selecting the amount of content displayed as a function of distance between user spaces. </claim-text>
</claim>
<claim id="CLM-00092">
<claim-text><highlight><bold>92</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 90</dependent-claim-reference>, further including selecting the amount of content displayed as a function of orientation between user spaces. </claim-text>
</claim>
<claim id="CLM-00093">
<claim-text><highlight><bold>93</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 90</dependent-claim-reference>, further including selecting the amount of content displayed as a function of the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00094">
<claim-text><highlight><bold>94</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 93</dependent-claim-reference>, further including automatically determining the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00095">
<claim-text><highlight><bold>95</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 90</dependent-claim-reference>, further including selecting the amount of content displayed as a function of the time such content was communicated. </claim-text>
</claim>
<claim id="CLM-00096">
<claim-text><highlight><bold>96</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 90</dependent-claim-reference>, further including selecting the amount of content displayed as a function of the time such content was communicated and as a function of characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00097">
<claim-text><highlight><bold>97</bold></highlight>. A method of interactive communication between a plurality of users, including: 
<claim-text>(a) displaying a conversation display universe; </claim-text>
<claim-text>(b) displaying, within the conversation display universe, a corresponding user space for each of a plurality of users; </claim-text>
<claim-text>(c) enabling each user to input content within the user space corresponding to such user, and communicating such content to the corresponding user space of at least one other user; </claim-text>
<claim-text>(d) for at least one user, displaying the content communicated by each other user within the user space corresponding to each such other user; and </claim-text>
<claim-text>(e) selectively varying the size of such content. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00098">
<claim-text><highlight><bold>98</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 97</dependent-claim-reference>, further including varying the size of such content as a function of distance between user spaces. </claim-text>
</claim>
<claim id="CLM-00099">
<claim-text><highlight><bold>99</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 97</dependent-claim-reference>, further including varying the size of such content as a function of orientation between user spaces. </claim-text>
</claim>
<claim id="CLM-00100">
<claim-text><highlight><bold>100</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 97</dependent-claim-reference>, further including varying the size of such content as a function of the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00101">
<claim-text><highlight><bold>101</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 100</dependent-claim-reference>, further including automatically determining the reputation of each user. </claim-text>
</claim>
<claim id="CLM-00102">
<claim-text><highlight><bold>102</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 97</dependent-claim-reference>, further including varying the size of such content as a function of the time such content was communicated. </claim-text>
</claim>
<claim id="CLM-00103">
<claim-text><highlight><bold>103</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00099">claim 97</dependent-claim-reference>, further including varying the size of such content as a function of the time such content was communicated and as a function of characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00104">
<claim-text><highlight><bold>104</bold></highlight>. A method of interactive communication between a plurality of users, including: 
<claim-text>(a) displaying a conversation display universe; </claim-text>
<claim-text>(b) displaying, within the conversation display universe, a corresponding user space for each of a plurality of users; </claim-text>
<claim-text>(c) enabling each user to input content within the user space corresponding to such user, and communicating such content to the corresponding user space of at least one other user; and </claim-text>
<claim-text>(d) varying the size of the user spaces. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00105">
<claim-text><highlight><bold>105</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 104</dependent-claim-reference>, further including varying the size of user spaces as a function of distance between such user spaces. </claim-text>
</claim>
<claim id="CLM-00106">
<claim-text><highlight><bold>106</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 104</dependent-claim-reference>, further including varying the size of user spaces as a function of orientation between such user spaces. </claim-text>
</claim>
<claim id="CLM-00107">
<claim-text><highlight><bold>107</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 106</dependent-claim-reference>, further including varying the size of user spaces as a function of user centric orientation between such user spaces. </claim-text>
</claim>
<claim id="CLM-00108">
<claim-text><highlight><bold>108</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 106</dependent-claim-reference>, further including varying the size of user spaces as a function of mutual orientation between such user spaces. </claim-text>
</claim>
<claim id="CLM-00109">
<claim-text><highlight><bold>109</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 104</dependent-claim-reference>, further including varying the size of user spaces as a function of the reputation of such users. </claim-text>
</claim>
<claim id="CLM-00110">
<claim-text><highlight><bold>110</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 109</dependent-claim-reference>, further including automatically determining the reputation of such users. </claim-text>
</claim>
<claim id="CLM-00111">
<claim-text><highlight><bold>111</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 104</dependent-claim-reference>, further including varying the size of user spaces as a function of the time content was communicated. </claim-text>
</claim>
<claim id="CLM-00112">
<claim-text><highlight><bold>112</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 104</dependent-claim-reference>, further including varying the size of user spaces as a function of the time content was communicated and as a function of characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00113">
<claim-text><highlight><bold>113</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 104</dependent-claim-reference>, wherein after a user space has been decreased in size, further including enabling a user to restore the size of such user space. </claim-text>
</claim>
<claim id="CLM-00114">
<claim-text><highlight><bold>114</bold></highlight>. A method of interactive communication between a plurality of users, including: 
<claim-text>(a) displaying a conversation display universe; </claim-text>
<claim-text>(b) displaying, within the conversation display universe, a corresponding user space for each of a plurality of users; </claim-text>
<claim-text>(c) enabling each user to input content within the user space corresponding to such user, and communicating such content to the corresponding user space of at least one other user; and </claim-text>
<claim-text>(d) applying filtering criteria to select at least one user space. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00115">
<claim-text><highlight><bold>115</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, wherein the filtering criteria include characteristics of such content. </claim-text>
</claim>
<claim id="CLM-00116">
<claim-text><highlight><bold>116</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, wherein the filtering criteria include comparing selected comparison terms against the content of a user space. </claim-text>
</claim>
<claim id="CLM-00117">
<claim-text><highlight><bold>117</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, wherein the filtering criteria include comparing selected comparison terms against metadata associated with a user space. </claim-text>
</claim>
<claim id="CLM-00118">
<claim-text><highlight><bold>118</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, wherein the filtering criteria include the reputation of a user. </claim-text>
</claim>
<claim id="CLM-00119">
<claim-text><highlight><bold>119</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, wherein the filtering criteria include at least one perception attribute associated with the content of a user space. </claim-text>
</claim>
<claim id="CLM-00120">
<claim-text><highlight><bold>120</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, further including changing at least one perception attribute of a user space or of the content of a user space as a result of meeting the filtering criteria. </claim-text>
</claim>
<claim id="CLM-00121">
<claim-text><highlight><bold>121</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, further including communicating a paging indicator based as a result of meeting the filtering criteria. </claim-text>
</claim>
<claim id="CLM-00122">
<claim-text><highlight><bold>122</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, further including applying content compression to the content of a selected user space as a result of meeting the filtering criteria. </claim-text>
</claim>
<claim id="CLM-00123">
<claim-text><highlight><bold>123</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, further including applying spatial compression to the content of a selected user space as a result of meeting the filtering criteria. </claim-text>
</claim>
<claim id="CLM-00124">
<claim-text><highlight><bold>124</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 114</dependent-claim-reference>, further including varying the size of a selected user space as a result of meeting the filtering criteria. </claim-text>
</claim>
<claim id="CLM-00125">
<claim-text><highlight><bold>125</bold></highlight>. A method of interactive communication, including: 
<claim-text>(a) displaying a conversation display space having at least two dimensions; </claim-text>
<claim-text>(b) displaying at least one orientation control, each having a corresponding user space, within the conversation display space; </claim-text>
<claim-text>(c) displaying at least one kiosk within the conversation display space; </claim-text>
<claim-text>(d) enabling a user to move or reorient an associated orientation control relative to the at least one kiosk within the conversation display space; and </claim-text>
<claim-text>(e) enabling interaction between the user space corresponding to the orientation control associated with such user and a kiosk. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00126">
<claim-text><highlight><bold>126</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 125</dependent-claim-reference>, wherein the interaction includes transfer of an object between the user space and the kiosk. </claim-text>
</claim>
<claim id="CLM-00127">
<claim-text><highlight><bold>127</bold></highlight>. A method of interactive communication, including: 
<claim-text>(a) displaying a conversation display space having at least two dimensions; </claim-text>
<claim-text>(b) displaying at least one user space within the conversation display space; </claim-text>
<claim-text>(c) displaying at least one kiosk within the conversation display space; </claim-text>
<claim-text>(d) enabling a user to move or reorient an associated user space relative to the at least one kiosk within the conversation display space; and </claim-text>
<claim-text>(e) enabling interaction between the user space associated with such user and a kiosk. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00128">
<claim-text><highlight><bold>128</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00111">claim 127</dependent-claim-reference>, wherein the interaction includes transfer of an object between the user space and the kiosk.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>5A</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001890A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001890A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001890A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001890A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001890A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001890A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001890A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001890A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001890A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001890A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001890A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030001890A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030001890A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030001890A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030001890A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030001890A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030001890A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030001890A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030001890A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00019">
<image id="EMI-D00019" file="US20030001890A1-20030102-D00019.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00020">
<image id="EMI-D00020" file="US20030001890A1-20030102-D00020.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
