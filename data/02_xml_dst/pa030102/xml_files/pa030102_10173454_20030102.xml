<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001744A1-20030102-D00000.TIF SYSTEM "US20030001744A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001744A1-20030102-D00001.TIF SYSTEM "US20030001744A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001744A1-20030102-D00002.TIF SYSTEM "US20030001744A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001744A1-20030102-D00003.TIF SYSTEM "US20030001744A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001744A1-20030102-D00004.TIF SYSTEM "US20030001744A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001744A1-20030102-D00005.TIF SYSTEM "US20030001744A1-20030102-D00005.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001744</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10173454</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020614</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2001-180516</doc-number>
</priority-application-number>
<filing-date>20010614</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G08B023/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>340</class>
<subclass>573100</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Communication tool and communication support system</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Takashi</given-name>
<family-name>Mizokawa</family-name>
</name>
<residence>
<residence-non-us>
<city>Shizuoka</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Masyuki</given-name>
<family-name>Mizukami</family-name>
</name>
<residence>
<residence-non-us>
<city>Shizuoka</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>KNOBBE MARTENS OLSON &amp; BEAR LLP</name-1>
<name-2></name-2>
<address>
<address-1>2040 MAIN STREET</address-1>
<address-2>FOURTEENTH FLOOR</address-2>
<city>IRVINE</city>
<state>CA</state>
<postalcode>92614</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A communication tool includes a expression data storage section <highlight><bold>107 </bold></highlight>for storing information with regard to a motion device <highlight><bold>113 </bold></highlight>that the user directly moves, a communication control section <highlight><bold>101 </bold></highlight>for transmitting expression data stored in the expression data storage section <highlight><bold>107 </bold></highlight>and receiving the transmitted information from the other communication robot <highlight><bold>3 </bold></highlight>to make the expression data storage section <highlight><bold>107 </bold></highlight>store it, and a motion device control section <highlight><bold>111 </bold></highlight>for operating the motion device <highlight><bold>113 </bold></highlight>based on the expression data stored in the expression data storage section <highlight><bold>107. </bold></highlight></paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to a communication tool and a communication support system for use in communication between remote locations. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Conventionally, there have been known some communication tools, such as a telephone with voices, e-mail with characters and a videophone with voices and images. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> However, all the conventional communication tools described above were those without any substance, so that users often got into frustration as the actual feelings were lacked. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> An object of the present invention is to solve the problems in the conventional communication tool as described above and to provide a communication tool and a communication support system with which users may have actual feelings fully. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> The present invention can achieve at least the above object among others. In an embodiment, the present invention provides a communication tool comprising: (i) a motion device which is physically movable by a user and provides signals corresponding to its movement; (ii) a transmitting information storage for storing the signals; (iii) a transmitter for transmitting the signals stored in the transmitting information storage to another communication tool; (iv) a receiver for receiving signals transmitted from another communication tool; (v) a received information storage for storing the received signals by the receiver; and (vi) a motion reproduction unit for activating the motion device based on the received signals stored in the received information storage. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> In an embodiment, the communication tool further comprises a behavior control unit provided a position between the motion device and the transmitting information storage, between the motion reproduction unit and the received information storage, between the transmitter and the transmitting information storage, and between the receiver and the receiving information storage, so that all signals pass through the behavior control unit which controls flow of the signals. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> In the above, the communication tool may further comprise an environment detection unit for detecting environmental information including the user&apos;s designated motion, said environment detection unit being connected to the behavior control unit, said behavior control unit being configured to activate the motion reproduction unit when the user&apos;s designated Motion is detected. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Further, the communication tool may further comprise an environment detection unit for detecting environmental information including signals inputted by the user, said environment detection unit being connected to the behavior control unit, said behavior control unit being configured to activate the motion reproduction unit when the user&apos;s signals are received. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> In another embodiment, the communication tool may further comprise an environment detection unit for detecting environmental information including ambient temperature and brightness, said environment detection unit being connected to the behavior control unit, said behavior control unit being configured to transmit the environmental information. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In yet another embodiment, the communication tool may further comprise a mode selection unit for selecting an autonomous mode for activating the motion reproduction unit autonomously or an expression transmission mode for following the user&apos;s commands, wherein the behavior control unit includes the autonomous mode and the expression transmission mode. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> In still another embodiment, the communication tool further comprise an operation command input unit for selecting one operation from (i) signal receiving processing, (ii) signal transmitting processing, or (iii) motion reproduction processing, in the expression transmission mode, wherein the expression transmission mode of the behavior control unit includes the signal receiving processing, the signal transmitting processing, and the motion reproduction processing. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Additionally, in an embodiment, the behavior control unit is configured to output information stored in the transmitting information storage to the motion reproduction unit to activate the motion device. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> Further, the behavior control unit may be configured to access an external memory unit to save information stored in either of the transmitting information storage or the received information storage or provide information to either of the transmitting information storage or the received information storage. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> In another aspect, the present invention can equally be applied to a communication method. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> Further, the present invention includes a communication support system as described below. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> For purposes of summarizing the invention and the advantages achieved over the prior art, certain objects and advantages of the invention have been described above. Of course, it is to be understood that not necessarily all such objects or advantages may be achieved in accordance with any particular embodiment of the invention. Thus, for example, those skilled in the art will recognize that the invention may be embodied or carried out in a manner that achieves or optimizes one advantage or group of advantages as taught herein without necessarily achieving other objects or advantages as may be taught or suggested herein. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Further aspects, features and advantages of this invention will become apparent from the detailed description of the preferred embodiments which follow.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> These and other features of this invention will now be described with reference to the drawings of preferred embodiments which are intended to illustrate and not to limit the invention. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a </italic></highlight>is a block diagram showing an embodiment of the communication support system according to the present invention. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b </italic></highlight>is a block diagram showing another embodiment of the communication support system according to the present invention. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>c </italic></highlight>is a block diagram showing an entire constitution of an embodiment of the communication support system according to the present invention. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flowchart of arithmetic processing of the control program executed in the communication robot of <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>c. </italic></highlight></paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a flowchart of the expression transmission control process executed in the arithmetic processing of <cross-reference target="DRAWINGS">FIG. 2</cross-reference>.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Symbols used in the figures are, for example, as follows: <highlight><bold>1</bold></highlight>: Communication line; <highlight><bold>2</bold></highlight>: Terminal device; <highlight><bold>3</bold></highlight>: Communication robot; <highlight><bold>100</bold></highlight>: Com interface; <highlight><bold>101</bold></highlight>: Communication control section; <highlight><bold>102</bold></highlight>: Input device; <highlight><bold>103</bold></highlight>: Recognition section; <highlight><bold>104</bold></highlight>: Mode switching control section; <highlight><bold>105</bold></highlight>: Mode switching device; <highlight><bold>106</bold></highlight>: Behavior control section; <highlight><bold>107</bold></highlight>: Expression data storage section; <highlight><bold>108</bold></highlight>: Removable storage device control section; <highlight><bold>109</bold></highlight>: Removable storage device interface; <highlight><bold>110</bold></highlight>: Expression transmission operating device; <highlight><bold>111</bold></highlight>: Motion device control section; <highlight><bold>112</bold></highlight>: Expression database; <highlight><bold>113</bold></highlight>: Motion device; <highlight><bold>114</bold></highlight>: Expression transmission control section; <highlight><bold>115</bold></highlight>: Autonomous behavior control section; <highlight><bold>116</bold></highlight>: Expression input control section; <highlight><bold>117</bold></highlight>: Expression output control section; <highlight><bold>118</bold></highlight>: Expression reproduction control section; <highlight><bold>119</bold></highlight>: Removable storage device. </paragraph>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT </heading>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The present invention includes, but is not limited to, the following various embodiments: </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>a, </italic></highlight>in an embodiment, the present invention provides a communication tool comprising: (i) a motion device <highlight><bold>15</bold></highlight> which is physically movable by a user and provides signals corresponding to its movement; (ii) a transmitting information storage <highlight><bold>11</bold></highlight> for storing the signals; (iii) a transmitter <highlight><bold>10</bold></highlight> for transmitting the signals stored in the transmitting information storage to another communication tool; (iv) a receiver <highlight><bold>13</bold></highlight> for receiving signals transmitted from another communication tool; (v) a received information storage <highlight><bold>12</bold></highlight> for storing the received signals by the receiver; and (vi) a motion reproduction unit <highlight><bold>14</bold></highlight> for activating the motion device based on the received signals stored in the received information storage. By using this tool, the user can make more sensory communicate with other users than conventional means. The signals transmitted or received by the tool can be accomplished through a communication interface. The transmitting information storage and the received information storage can be stored in respective separate memories or in a common memory using different sections. Communication tools which can be communicated each other can be of the same type or of different types, as long as a basic schematic is the same. For example, a different motion device can be used, so that when a leg of one motion device is moved, a caterpillar of another motion device will move. The motion device can be of a humanoid type, a pet type (dog, cat, etc.), any monster figures, or any other three-dimensional figures or objects. Each movable portion is equipped with a sensor transmitting a signal. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>b, </italic></highlight>in an embodiment, the communication tool further comprises a behavior control unit <highlight><bold>16</bold></highlight> provided a position between the motion device <highlight><bold>15</bold></highlight> and the transmitting information storage <highlight><bold>11</bold></highlight>, between the motion reproduction unit <highlight><bold>14</bold></highlight> and the received information storage <highlight><bold>12</bold></highlight>, between the transmitter <highlight><bold>10</bold></highlight> and the transmitting information storage <highlight><bold>11</bold></highlight>, and between the receiver <highlight><bold>13</bold></highlight> and the receiving information storage <highlight><bold>12</bold></highlight>, so that all signals pass through the behavior control unit <highlight><bold>16</bold></highlight> which controls flow of the signals. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> In the above, the communication tool may further comprise an environment detection unit <highlight><bold>17</bold></highlight> for detecting environmental information including the user&apos;s designated motion. The environment detection unit <highlight><bold>17</bold></highlight> is connected to the behavior control unit <highlight><bold>16</bold></highlight>, and the behavior control unit <highlight><bold>16</bold></highlight> is configured to activate the motion reproduction unit <highlight><bold>14</bold></highlight> when the user&apos;s designated motion is detected. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> In another embodiment, the environment detection unit <highlight><bold>17</bold></highlight> is configured to detect environmental information including signals inputted by the user. Additionally, in another embodiment, the environment detection unit <highlight><bold>17</bold></highlight> is configured to detect environmental information including ambient temperature and brightness. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> In yet another embodiment, the communication tool may further comprise a mode selection unit <highlight><bold>19</bold></highlight> for selecting an autonomous mode for activating the motion reproduction unit autonomously or an expression transmission mode for following the user&apos;s commands, wherein the behavior control unit <highlight><bold>16</bold></highlight> includes the autonomous mode <highlight><bold>21</bold></highlight> and the expression transmission mode <highlight><bold>20</bold></highlight>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> In still another embodiment, the communication tool further comprise an operation command input unit <highlight><bold>18</bold></highlight> for selecting one operation from (i) signal receiving processing, (ii) signal transmitting processing, or (iii) motion reproduction processing, in the expression transmission mode <highlight><bold>20</bold></highlight>, wherein the expression transmission mode <highlight><bold>20</bold></highlight> of the behavior control unit <highlight><bold>16</bold></highlight> includes the signal receiving processing <highlight><bold>20</bold></highlight><highlight><italic>a, </italic></highlight>the signal transmitting processing <highlight><bold>20</bold></highlight><highlight><italic>b, </italic></highlight>and the motion reproduction processing <highlight><bold>20</bold></highlight><highlight><italic>c. </italic></highlight></paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> When the tool is set in the autonomous mode, emotions can be used. Any suitable emotion control techniques can be adapted to this invention, including U.S. Pat. No. 6,175,772 (issued Jan. 16, 2001), U.S. Pat. No. 6,230,111 (issued May 8, 2001, and U.S. Pat. No. 6,249,780 (issued Jun. 19, 2001, and U.S. patent application Ser. No. 09/393,146 (filed Sep. 10, 1999), U.S. Ser. No. 09/393,247 (filed Sep. 10, 1999), and U.S. Ser. No. 09/394,369 (filed Sep. 10, 1999). The disclosure of each reference in its entirety is incorporated herein by reference. Emotion control can also be applied when in the expression transmitting mode. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Additionally, in an embodiment, the behavior control unit is configured to output information stored in the transmitting information storage to the motion reproduction unit to activate the motion device, so that the user can activate the motion device to reproduce the motion the user previously made. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The present invention further includes the following embodiments: </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> 1) A communication tool characterized by comprising: (i) a moving section; (ii) a transmitting information storage means for storing information relating to the moving section directly moved by a user; (iii) a transmission means for transmitting the information stored in the transmitting information storage means; (iv) a receiving means for receiving the information transmitted from other communication tools; (v) a received information storage means for storing the information received by the receiving means; and (vi) a reproduction means for moving the moving section based on the information stored in the received information storage means. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> 2) A communication tool according to item 1, wherein the receiving means comprises a reception notifying means for notifying that the receiving means received the information. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> 3) A communication tool according to item 1 or 2, comprising a detection means for detecting the specific movement of the user, wherein the reproduction means is adapted to move the moving section based on the information stored in the received information storage means, when the receiving means receives the information and when the detection means detects the specific movement. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> 4) A communication tool according to any one of items 1-3, wherein the transmission means is adapted to transmit an execution command, and the reproduction means is adapted to move the moving section based on the information stored in the received information storage means when the receiving means receives the execution command. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> 5) A communication tool according to any one of items 1-4, further comprising a mode switching means for selectively switching an autonomous mode and an expression transmission mode. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> 6) A communication tool according to item <highlight><bold>5</bold></highlight>, wherein the mode switching means is adapted to switch to the expression transmission mode when the receiving means receives the information. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> 7) A communication tool according to any one of items 1-6, further comprising a transmission commanding means for making the transmission means start transmission based on a command of the user. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> 8) A communication tool characterized by comprising: (i) a moving section; (ii) a storage means for storing information relating the moving section directly moved by a user; and (iii) a reproduction means for moving the moving section based on the information stored in the storage means. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> 9) A communication tool according to any one of items 1-8, further comprising an environmental information acquisition means for acquiring information relating to a peripheral environment, wherein the transmitting information storage means is also adapted to store the information acquired by the environmental information acquisition means. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> 10) A communication tool according to any one of items 1-9, further comprising a gesture information acquisition means for acquiring information relating to the gestures of the user, wherein the transmitting information storage means is also adapted to store the information acquired by the gesture information acquisition means. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> 11) A communication tool according to any one of items 1-10, comprising a feeling information acquisition means for acquiring information relating to feelings of the user, wherein the transmitting information storage means is also adapted to store the information acquired by the feeling information acquisition means. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> 12) A communication tool according to any one of items 1-11, further comprising a music reproduction means capable of reproducing music data, wherein the transmitting information storage means is adapted to store the music data, and the reproduction means is adapted to make the music reproduction means reproduce the music data as well as move the moving section, based on the information stored in the received information storage means. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> 13) A communication tool according to any one of items 1-12, further comprising a voice recording means for recording the voice spoken by the user and a voice reproduction means capable of reproducing the voice, wherein the transmitting information storage means is also adapted to store the voice recorded with the voice recording means, and the reproductopn means is adapted to make the voice reproduction means reproduce the voice based on information stored in the received information storage means as well as to move the moving section. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> 14) A communication tool according to any one of items 1-13, wherein the reproduction means has at least one of a forwarding function, a pausing function, a slow replay function, a reverse function, and a repeat function. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> 15) A communication support system characterized by comprising: (a) a communication tool comprising: (i) a moving section; (ii) a transmitting information storage means for storing information relating to the moving section directly moved by a user; and (iii) a transmission means for transmitting the stored information in the transmitting information storage means; and (b) a terminal device comprising: (I) a receiving means for receiving the information transmitted from the communication tool; (II) a received information storage means for storing the information received with the receiving means; (III) an image production means for producing a moving image based on the information stored in the received information storage means; and (IV) an image display means for displaying the image produced with the image production means. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> 16) A communication support system characterized by comprising: (a) a communication tool comprising: (i) a moving section; (ii) a storage means for storing information relating to the moving section directly moved by a user; (iii) a reproduction means for moving the moving section based on the information stored in the storage means; and (iv) a transmission means for transmitting the stored information in the storage means; and (b) a terminal device comprising: (I) a receiving means for receiving information transmitted from the communication tool; (II) a received information storage means for storing the information received with the receiving means; and (III) a transfer means for transferring the information stored in the received information storage means to the storage means of other communication tools. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> 17) A communication support system characterized by comprising: (a) a communication tool comprising: (i) a moving section; (ii) a storage means for storing information relating to the location of the moving section directly moved by a user; (iii) a reproduction means for moving the moving section based on the information stored in the storage means; and (iv) a transmission means for transmitting the identification information of the user and the password with the information stored in the transmitting information storage means; and (b) a server comprising: (I) a receiving means for receiving the information transmitted from the communication tool; (II) a user identification means for verifying the identification information and the password based on the information received by the receiving means; (II) a received information storage means for storing the information received with the receiving means and accounting information when the user identification means verifies that the identification information and the password are correct; and (IV) a transfer means for transferring the information stored in the received information storage means to a terminal device. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> In item 1, the moving section may perform any movement, and the number of the section may be one or plural. Information that makes the transmission means transmit relating to the moving section may be such that the reproduction means move the moving section, for example, information indicating which, how fast, what route, and where the moving section moves can be included. Furthermore, the transmitting information storage means and the received information storage means may be constructed with different storage means or at different storage area in the same storage means. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> In item 2, a method for informing the receiving may be any type of methods, for example, that informs visually by moving with specific movements or lighting up a specific light and also informs with specific sounds. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> In item 3, the specific movement of the user includes a switch operation for operating specific switch, a gesture command, a voice command, a touch sense command, a visual sense command (the colored small tool use) and so on. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> In item 4, the timing of the transmitting the execution command may be that the command is transmitted with information stored in the storage means or after transmitting the information. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> In item 5, the autonomous mode is a mode that makes a communication tool operate autonomously like a creature, and the expression transmission mode is a mode that the user operates so that the user can use it in communications. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Further, in item 9, the information with regard to a peripheral environment may be any kind of information if it relates to the peripheral environment; for example, temperature or brightness can be included. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> In item 10, when information with regard to the user&apos;s gesture is acquired, it is preferable to allow the user to gesture with small tools that have pictorial characteristics, and therefore, information with regard to the gestures can be acquired easily. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> In item 13, the forwarding function is for moving the moving section faster than at storing, and the pausing function is for temporally stopping the moving section, and the slow replay function is for moving the moving section slower than at storing. Furthermore, the reverse function is for moving the moving section in the opposite sequence from at storing, and the repeat function is for repeatedly moving the moving section with the movements stored in the storage means. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> In item 15, the moving image may be any shape, so that it may be the replicative profile of a communication tool and other configurations. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> As explained above, the communication tool relating to item 1 of the present invention first stores and transmits information with regard to the moving section indicating which, how fast, what route, where the moving section moves as the user directly and manually moves any moving section of the communication tool. Next, the other communication tool receiving the transmitting information stores the information and moves the moving section based on the information to reproduce the stored movement. In this manner, since the present invention is a substantial communication tool that transmits the information with regard to the moving section to reproduce the movements, the user can communicate with actual and rich feelings. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Also, since the communication tool relating to item 2 of the present invention is adapted to notify the reception of the transmitting information, the user can easily know the receiving of the above information. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Furthermore, since the communication tool relating to item 3 of the present invention is adapted to move the moving section based on the stored information when it receives the information and detects the specific movement of the user, the user can start the movement easily by only performing the specific movement. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> Since the communication tool relating to item 4 of the present invention is adapted to move the above moving section based on the information stored in the above storage means when it receives the execution command, the user can start the movement at desired timing by only transmitting the execution command. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Furthermore, since the communication tool relating to item 5 of the present invention is adapted to be capable of switching the autonomous mode and the expression transmission mode, it can amuse the user by behaving as a pet in the autonomous mode. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> Since the communication tool relating to item 6 of the present invention is adapted to switch to the expression transmission mode when the information is received, the user can easily realize the reception of the information. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Furthermore, since the communication tool relating to item 7 of the present invention is adapted to start the transmission to the above transmission means based on commands of the user, the user can transmit information easily. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The communication tool relating to item 8 of the present invention first stores information with regard to the position of the moving section into the storage means when the user manually and directly moves any moving section of the communication tool. Next, it is assumed that the user removes the above storage means and hands it to the other user to allow to be installed in the other communication tool. Then, the other communication tool described above moves the moving section based on the information stored in the above storage means and reproduce the movement stored in the above storage means. In this manner, since the present embodiment is a substantial communication tool that stores and reproduces the movements, the user can communicate with actual and rich feelings. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> It is also preferable that the present invention may not only be used in communication by handing to the other user, but also reproduce to enjoy the same movement that itself has directly operated the communication tool to store in the past. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> Furthermore, since the communication tool relating to item 9 of the present invention is adapted to store and transmit information in relation to the peripheral environment such as temperatures or brightness, when the other communication tool receiving the transmitted information moves the above moving section based on the received information, motions corresponding to the peripheral environment can be added, for example, shaking motions are added during the operation in the cold place, so that the user can communicate with more actual and richer feelings. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> Since the communication tool relating to item 10 of the present invention is adapted to allow the user to gesture with gloves having pictorial characteristics such as a red or green color and acquire to store information in relation to the user&apos;s gesture with the image processing device and the like, the user can store the transmitting information easily. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> Furthermore, since the communication tool relating to item 11 of the present invention is adapted to store and transmit information in relation to feelings of the user, when the other communication tool receiving the transmitted information moves the moving section based on the received information, the movements depending on the feelings of the user can be added, for example, an angry movement can be added when the tool is angrily moved, so that the user can communicate with more actual and richer feelings. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> Since the communication tool relating to item 12 of the present invention is adapted to store and transmit music data and make the other communication tool that receives the music data reproduce the music data, as well as to operate the above moving section, the moving section can be moved to dance to music, for example. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> Since the communication tool relating to item 13 of the present invention is adapted to store and transmit voices and make the other communication tool that receives the voices reproduce the voices, as well as to operate the above moving section, the tool can make a bow with a voice, for example &ldquo;I&apos;m sorry&rdquo;, and the user can communicate with more actual and richer feeling. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> The present invention includes the following embodiments, but is not limited thereto. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> Referring now to the drawings, the following example will be described for the construction of the communication support system being capable of using to communicate between separated locations with a communication tool of the present invention. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>c </italic></highlight>is a block diagram, showing entire constitution of the communication support system of this embodiment. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> The communication support system of this embodiment comprises, as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference><highlight><italic>c, </italic></highlight>a terminal device <highlight><bold>2</bold></highlight> (such as a personal computer or a cellular phone) connectable to the predetermined communication line <highlight><bold>1</bold></highlight> and a communication robot <highlight><bold>3</bold></highlight> having a communication interface <highlight><bold>100</bold></highlight> connectable to the terminal device <highlight><bold>2</bold></highlight> through a radio communication equipment or the like. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> The communication robot <highlight><bold>3</bold></highlight> comprises a communication control section <highlight><bold>101</bold></highlight>, an input device <highlight><bold>102</bold></highlight>, a recognition section <highlight><bold>103</bold></highlight>, a mode switching control section <highlight><bold>104</bold></highlight>, a mode switching device <highlight><bold>105</bold></highlight>, a behavior control section <highlight><bold>106</bold></highlight>, an expression data storage section <highlight><bold>107</bold></highlight>, a removable storage device control section <highlight><bold>108</bold></highlight>, a removable storage device interface <highlight><bold>109</bold></highlight>, an expression transmission operating device <highlight><bold>110</bold></highlight>, a motion device control section <highlight><bold>111</bold></highlight>, an expression database <highlight><bold>112</bold></highlight> of feelings, and a motion device <highlight><bold>113</bold></highlight>. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> The behavior control section <highlight><bold>106</bold></highlight> comprises an expression transmission control section <highlight><bold>114</bold></highlight> and an autonomous behavior control section <highlight><bold>115</bold></highlight>, and also, the expression transmission control section <highlight><bold>114</bold></highlight> comprises an expression input control section <highlight><bold>116</bold></highlight>, an expression output control section <highlight><bold>117</bold></highlight>, and an expression reproduction control section <highlight><bold>118</bold></highlight>. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> At first, the communication control section <highlight><bold>101</bold></highlight> receives information transmitted from other communication robot <highlight><bold>3</bold></highlight> to input a switching signal into the mode switching control section <highlight><bold>104</bold></highlight> and to input expression data into the expression data storage section <highlight><bold>107</bold></highlight>. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> The input device <highlight><bold>102</bold></highlight> detects various information such as images, sound, touch senses, environmental information (such as obstacles, temperature, brightness), time, and internal states to input them into the recognition section <highlight><bold>103</bold></highlight>. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> The recognition section <highlight><bold>103</bold></highlight> recognizes gestures, movements of the object, movements of the hands, feet, and the head, user identification, feelings of the user, speeches, touch sense states, and environments to input those recognition results into the autonomous behavior control section <highlight><bold>115</bold></highlight>, based on information input from the input device <highlight><bold>102</bold></highlight>. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> The mode switching control section <highlight><bold>104</bold></highlight> generates a switching command for switching an autonomous mode operating as a pet robot and a expression transmission mode operating as a communication robot to input it into the behavior control section <highlight><bold>106</bold></highlight>, based on the switching signal that is input from the mode switching device <highlight><bold>105</bold></highlight> having a system user directly perform the switching command of the operating mode and the switching signal that is transmitted from the other communication robot <highlight><bold>3</bold></highlight> and input by the communication control section <highlight><bold>101</bold></highlight>. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The behavior control section <highlight><bold>106</bold></highlight> is adapted to generate expression data with the expression input control section <highlight><bold>116</bold></highlight> of the expression transmission control section <highlight><bold>114</bold></highlight> to write it to the expression data storage section <highlight><bold>107</bold></highlight>, based on the recognition result input from the recognition section <highlight><bold>103</bold></highlight> and the switching command input from the mode switching control section <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> The expression transmission control section <highlight><bold>114</bold></highlight> generates a write command with the expression output control section <highlight><bold>117</bold></highlight> to input it into the removable storage device control section <highlight><bold>108</bold></highlight> and generates a transmission command to input it into the communication control section <highlight><bold>101</bold></highlight>, based on an operating command that has a system user operate the expression transmission and is input from the expression transmission operating device <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> The removable storage device control section <highlight><bold>108</bold></highlight> is adapted to write the expression data stored in the expression data storage section <highlight><bold>107</bold></highlight> to the removable storage device <highlight><bold>119</bold></highlight> attached to the removable storage device interface <highlight><bold>109</bold></highlight>, based on the write command input from the expression input control section <highlight><bold>116</bold></highlight>. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> The communication control section <highlight><bold>101</bold></highlight> transmits expression data stored in the expression data storage section <highlight><bold>107</bold></highlight> to the other communication robot <highlight><bold>3</bold></highlight>, based on the transmission command input from the expression output control section <highlight><bold>117</bold></highlight>. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> The expression transmission control section <highlight><bold>114</bold></highlight> generates a read command with the expression reproduction control section <highlight><bold>118</bold></highlight> to input it into the removable storage device control section <highlight><bold>108</bold></highlight>, based on the operating command input from the expression transmission operating device <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> The removable storage device control section <highlight><bold>108</bold></highlight> is adapted to read expression data stored in the removable storage device <highlight><bold>119</bold></highlight> attached to the removable storage device interface <highlight><bold>109</bold></highlight> and write it into the expression data storage section <highlight><bold>107</bold></highlight>, based on the read command input from the expression reproduction control section <highlight><bold>118</bold></highlight>. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> The communication control section <highlight><bold>101</bold></highlight> is adapted to automatically write expression data received from the other communication robot <highlight><bold>3</bold></highlight> to the expression data storage section <highlight><bold>107</bold></highlight>. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> The behavior control section <highlight><bold>106</bold></highlight> is adapted to generate behavior command information in the expression reproduction control section <highlight><bold>118</bold></highlight> and the autonomous behavior control section <highlight><bold>115</bold></highlight> to input it into the motion device control section <highlight><bold>111</bold></highlight>, based on the recognition result in the recognition section <highlight><bold>103</bold></highlight> and the switching command input from the mode switching control section <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> The motion device control section <highlight><bold>111</bold></highlight> generates a motion output control signal to input it into the motion device <highlight><bold>113</bold></highlight>, based on behavior command information input from the autonomous behavior control section <highlight><bold>115</bold></highlight> or the expression reproduction control section <highlight><bold>118</bold></highlight> and the expression database <highlight><bold>112</bold></highlight> of feelings. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> The motion device <highlight><bold>113</bold></highlight> controls hands, feet, and the head (not shown) and sounds, light, the display, and the like, based on the motion output control signal input from the motion device control section <highlight><bold>111</bold></highlight>. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> A control program that is executed when the power supply switch is turned on will be described as follows. An arithmetic processing of this control program is for activating the communication robot <highlight><bold>3</bold></highlight>, and at first it shifts the stage to the step S<highlight><bold>100</bold></highlight> as shown in a <cross-reference target="DRAWINGS">FIG. 2</cross-reference> when it is executed. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> In the step S<highlight><bold>100</bold></highlight>, a system initialization is executed, and then the stage is shifted to the step S<highlight><bold>101</bold></highlight>. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> In the step S<highlight><bold>101</bold></highlight>, the state of the power supply switch is read, and then the stage is shifted to the step S<highlight><bold>102</bold></highlight>. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> In the step S<highlight><bold>102</bold></highlight>, the power supply is adapted to be determined if it is turned off, based on the state of the power supply switch being read in the step S<highlight><bold>101</bold></highlight>, and the stage will be shifted to the step S<highlight><bold>110</bold></highlight> if the power supply is turned off (OFF) or to the step S<highlight><bold>103</bold></highlight> if not (ON). </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> In the step S<highlight><bold>103</bold></highlight>, a switching signal output from the mode switching device <highlight><bold>105</bold></highlight> is read, and then the stage is shifted to the step S<highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> In the step S<highlight><bold>104</bold></highlight>, the operating mode is determined if it is changed based on the switching signal read in the step S<highlight><bold>103</bold></highlight>, the stage will be shifted to the step S<highlight><bold>105</bold></highlight> if there is a change (&ldquo;Changed&rdquo;), or it will be directly shifted to the step S<highlight><bold>106</bold></highlight> if not (&ldquo;No change/Initial state&rdquo;). </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> In the step S<highlight><bold>105</bold></highlight>, a mode change process is executed, and then the stage is shifted to the step S<highlight><bold>106</bold></highlight>. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> In the step S<highlight><bold>106</bold></highlight>, the current operating mode is adapted to be determined based on the switching signal read in the step S<highlight><bold>103</bold></highlight>, the stage will be shifted to the step S<highlight><bold>107</bold></highlight> when the mode is in the autonomous mode (&ldquo;Autonomous mode&rdquo;), or it will be shifted to the step S<highlight><bold>111</bold></highlight> when the mode is in the expression transmission mode (&ldquo;Expression transmission mode&rdquo;). </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> In the step S<highlight><bold>107</bold></highlight>, the autonomous behavior control process is executed, and the stage is shifted to the step S<highlight><bold>108</bold></highlight>. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> In the step S<highlight><bold>108</bold></highlight>, the communication data receiving process is executed, and the stage is shifted to the step S<highlight><bold>109</bold></highlight>. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> In the step S<highlight><bold>109</bold></highlight>, it is adapted to be determined whether information or the like is received from the other communication robot <highlight><bold>3</bold></highlight>, the stage will be shifted to the step S<highlight><bold>110</bold></highlight> when it is received (&ldquo;Yes&rdquo;) or it will be directly shifted to the step S<highlight><bold>112</bold></highlight> if not (&ldquo;No&rdquo;). </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> In the step S<highlight><bold>112</bold></highlight>, the motion generating process is executed in the expression data receiving, and then the stage is shifted to the step S<highlight><bold>112</bold></highlight>. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> On the other hand, in the step S<highlight><bold>111</bold></highlight>, the expression transmission control process described below is executed, and then the stage is shifted to the step S<highlight><bold>112</bold></highlight>. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> In the step S<highlight><bold>112</bold></highlight>, the motion device control process is executed, and then arithmetic processing of this control program is terminated. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> Referring to a flowchart of <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the expression transmission control process executed in the step S<highlight><bold>111</bold></highlight> for the arithmetic processing of the above control program will be described in detail as follows. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> At first, in the step S<highlight><bold>200</bold></highlight>, a type of the process that a system user is prompted to input with the expression transmission operating device <highlight><bold>110</bold></highlight> is read, and then the stage is shifted to the step S<highlight><bold>201</bold></highlight>. As for the type of the process, there are an expression input process for storing expression data into the expression data storage section <highlight><bold>107</bold></highlight>, an expression output process for passing the expression data stored in the expression data storage section <highlight><bold>107</bold></highlight> to the other communication robot <highlight><bold>3</bold></highlight>, and an expression reproduction process for operating the motion device <highlight><bold>113</bold></highlight> based on the expression data stored in the expression data storage section <highlight><bold>107</bold></highlight>. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> In the step S<highlight><bold>201</bold></highlight>, information transmitted from the other communication robot <highlight><bold>3</bold></highlight> is read through the communication interface <highlight><bold>100</bold></highlight>, and the stage is shifted to the step S<highlight><bold>202</bold></highlight>. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> In the step S<highlight><bold>202</bold></highlight>, the executing process is determined based on the information read in the above step S<highlight><bold>200</bold></highlight>, and the stage would be shifted to the step S<highlight><bold>203</bold></highlight> when the expression input process is selected (&ldquo;Expression input&rdquo;), the stage would be shifted to the step S<highlight><bold>208</bold></highlight> when the expression output process is selected (&ldquo;Expression output&rdquo;), or the stage would be shifted to the step S<highlight><bold>216</bold></highlight> when the expression reproduction process is selected (&ldquo;Expression reproduction&rdquo;). </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> In the step S<highlight><bold>203</bold></highlight>, the type of input data, start or end of each input, the end of all inputs, transmission, storage, and so on are prompted to be input from the expression transmission operating device <highlight><bold>110</bold></highlight>, and the stage is shifted to the step S<highlight><bold>204</bold></highlight>. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> In the step S<highlight><bold>204</bold></highlight>, this expression transmission control process determination is adapted to be directly terminated at the input start command waiting (&ldquo;Waite for input start command), but the stage is shifted to the S<highlight><bold>205</bold></highlight> at the new start or continuation (&ldquo;New, Continue&rdquo;), or it is shifted to the step S<highlight><bold>220</bold></highlight> when it is terminated (&ldquo;Performing termination process&rdquo;). </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> In the step S<highlight><bold>205</bold></highlight>, the new input is adapted to be determined, the stage would be shifted to the step S<highlight><bold>206</bold></highlight> at the new input or it would be directly shifted to the step S<highlight><bold>112</bold></highlight> if not (&ldquo;Continue&rdquo;). </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> In the step S<highlight><bold>206</bold></highlight>, the input initialization process is executed, and then the stage is shifted in the step S<highlight><bold>207</bold></highlight>. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> In the step S<highlight><bold>207</bold></highlight>, an input data type is adapted to be determined, a step in response to the type of input data within the range between a step S<highlight><bold>208</bold></highlight><highlight><subscript>l</subscript></highlight>, to S<highlight><bold>208</bold></highlight><highlight><subscript>n</subscript></highlight>, is executed such that the stage would be shifted to the step S<highlight><bold>208</bold></highlight><highlight><subscript>l </subscript></highlight>when the motion of a right hand is input and to S<highlight><bold>208</bold></highlight><highlight><subscript>n </subscript></highlight>when the voice is input, and then the expression transmission control process is terminated. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> On the other hand, in the step S<highlight><bold>209</bold></highlight>, the termination process is executed, and then the stage is shifted to the step S<highlight><bold>210</bold></highlight>. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> In the step S<highlight><bold>210</bold></highlight>, it is adapted to be determined whether the automatic transmission is executed or not, and the stage will be shifted to the step S<highlight><bold>211</bold></highlight> when the automatic transmission is executed (&ldquo;Automatic transmission&rdquo;), or the expression transmission control process will be directly terminated if not. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> In the step S<highlight><bold>211</bold></highlight>, the communication data transmission process is executed, and then the expression transmission control process is terminated. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> On the other hand, in the step S<highlight><bold>212</bold></highlight>, an output device for transmitting or transferring the expression data to the other communication robot <highlight><bold>3</bold></highlight> is prompted to be selected with the expression transmission operating device <highlight><bold>110</bold></highlight>, as well as which expression data stored in the expression data storage section <highlight><bold>107</bold></highlight> is output is selected, and then the stage is shifted to the step S<highlight><bold>213</bold></highlight>. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> In the step S<highlight><bold>213</bold></highlight>, it is adapted to be determined whether the expression data selected in the step S<highlight><bold>212</bold></highlight> is transmitted through the communication line <highlight><bold>1</bold></highlight> or not, based on the selected result in the step S<highlight><bold>212</bold></highlight>, and the stage will be shifted to the step S<highlight><bold>214</bold></highlight> when it is transmitted (&ldquo;Yes&rdquo;) or directly to the step S<highlight><bold>215</bold></highlight> if not (&ldquo;No&rdquo;). </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> In the step S<highlight><bold>214</bold></highlight>, the expression data transmission process by the communication is executed, and the stage is shifted to the step S<highlight><bold>215</bold></highlight>. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> In the step S<highlight><bold>215</bold></highlight>, it is adapted to be determined whether the expression data selected in the step S<highlight><bold>212</bold></highlight> is transferred or not, based on the selected result in the step S<highlight><bold>212</bold></highlight>, and the stage will be shifted to the step S<highlight><bold>216</bold></highlight> when it is transferred (&ldquo;Yes&rdquo;), or the expression transmission control process is directly terminated if not (&ldquo;No&rdquo;). </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> In the step S<highlight><bold>216</bold></highlight>, the expression data selected in the step S<highlight><bold>212</bold></highlight> is read from the expression data storage section <highlight><bold>107</bold></highlight>, as well as it is written in the removable storage device <highlight><bold>119</bold></highlight> attached to the removable storage device interface <highlight><bold>109</bold></highlight>, and then the expression transmission control process is terminated. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> On the other hand, in the step S<highlight><bold>217</bold></highlight>, an input device for receiving the expression data from the other communication robot <highlight><bold>3</bold></highlight> or transferring from the removable storage device <highlight><bold>119</bold></highlight> is prompted to be selected with the expression transmission operating device <highlight><bold>110</bold></highlight>, as well as which expression data stored in the expression data storage section <highlight><bold>107</bold></highlight> is reproduced is selected, and then the stage is shifted to the step S<highlight><bold>218</bold></highlight>. </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> In the step S<highlight><bold>218</bold></highlight>, it is determined whether the data is externally read or not, based on the selected result of the input device being input in the step S<highlight><bold>217</bold></highlight>, and the stage will be shifted to the step S<highlight><bold>219</bold></highlight> when it is read (&ldquo;Yes&rdquo;) or to the step S<highlight><bold>223</bold></highlight> if not. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> In the step S<highlight><bold>219</bold></highlight>, it is adapted to be determined whether the expression data is received through the communication line <highlight><bold>1</bold></highlight> or not, based on the selected result of the input device being input in the step S<highlight><bold>217</bold></highlight>, and the stage will be shifted to the step S<highlight><bold>220</bold></highlight> when it is received (&ldquo;Yes&rdquo;) or directly to the step S<highlight><bold>221</bold></highlight> if not (&ldquo;No&rdquo;). </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> In the step S<highlight><bold>220</bold></highlight>, the expression data receiving process through the communication is executed, and the stage is shifted to the step S<highlight><bold>221</bold></highlight>. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> In the step S<highlight><bold>221</bold></highlight>, it is adapted to be determined whether the expression data is transferred from the removable storage device <highlight><bold>119</bold></highlight> or not, based on the selected result of the input device being input in the step S<highlight><bold>217</bold></highlight>, and the stage will be shifted to the step S<highlight><bold>214</bold></highlight> when it is transferred (&ldquo;Yes&rdquo;) or directly to the step S<highlight><bold>215</bold></highlight> if not (&ldquo;No&rdquo;). </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> In the step S<highlight><bold>222</bold></highlight>, the expression data is read from the removable storage device <highlight><bold>119</bold></highlight>, and the stage is shifted to the step S<highlight><bold>223</bold></highlight>. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> In the step S<highlight><bold>223</bold></highlight>, the reproduction methods such as the reproduction speed or data position or direction are set, and the stage is shifted to the step S<highlight><bold>224</bold></highlight>. </paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> In step S<highlight><bold>224</bold></highlight>, the expressing motion that is added the environment or user status during the data preparation into the command expression is prepared, and the stage is shifted to the step S<highlight><bold>225</bold></highlight>. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> In the step S<highlight><bold>225</bold></highlight>, the motion device control process is executed, and then the expression transmission control process is terminated. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> According to the above flow, when the expression input process is selected in the step S<highlight><bold>202</bold></highlight>, expression data showing the movements of the motion device <highlight><bold>113</bold></highlight> that are manually and directly moved by the system user in the steps S<highlight><bold>203</bold></highlight>-S<highlight><bold>211</bold></highlight> is generated and stored in the expression data storage section <highlight><bold>107</bold></highlight>. </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> Subsequently, when the expression output process is selected in the step S<highlight><bold>203</bold></highlight>, expression data stored in the expression data storage section <highlight><bold>107</bold></highlight> is transmitted to the other communication robot <highlight><bold>3</bold></highlight> in the steps S<highlight><bold>212</bold></highlight>-S<highlight><bold>216</bold></highlight>. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> When the expression reproduction is selected with step S<highlight><bold>202</bold></highlight>, the motion device <highlight><bold>113</bold></highlight> is moved, based on the information stored in the expression data storage section <highlight><bold>107</bold></highlight>, and the movement or the like stored in the expression data storage section <highlight><bold>107</bold></highlight> is reproduced. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> In this manner, since the communication robot <highlight><bold>3</bold></highlight> of the present embodiment is a substantial communication tool that transmits the expression data to reproduce the movement and the like, the user can communicate with actual and rich feelings. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> Because the present embodiment is adapted to store and receive voices into the expression data storage section <highlight><bold>107</bold></highlight> and make the other communication robot <highlight><bold>3</bold></highlight> that receives the voices reproduce the voices, as well as to operate the motion device <highlight><bold>113</bold></highlight>, the robot can make a bow with a voice, for example &ldquo;I&apos;m sorry&rdquo;, and the user can communicate with more actual and richer feeling. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> Furthermore, since the present embodiment is adapted to start the transmission to the communication control section <highlight><bold>101</bold></highlight> based on commands of the user, the user can transmit information easily. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> When the expression input process is selected in the step S<highlight><bold>202</bold></highlight> to store the expression data in the expression data storage section <highlight><bold>107</bold></highlight>, and then the expression reproduction is selected in the step S<highlight><bold>202</bold></highlight>, the motion device <highlight><bold>113</bold></highlight> is moved based on the information stored in the expression data storage section <highlight><bold>107</bold></highlight>, and the movement or the like stored in the expression data storage section <highlight><bold>107</bold></highlight> is reproduced. </paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> In this manner, the communication robot <highlight><bold>3</bold></highlight> of this embodiment not only reproduces the expression data transmitted from the other communication robot <highlight><bold>3</bold></highlight>, but also entertains the user by reproducing the movement that is stored by directly operating the communication robot <highlight><bold>3</bold></highlight> with itself in the past. </paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> In this embodiment, the moving section corresponds to the motion device <highlight><bold>113</bold></highlight>, the transmitting information storage means and the received information storage means correspond to the expression data storage section <highlight><bold>107</bold></highlight>, the transmission means and the receiving means correspond to the communication control section <highlight><bold>101</bold></highlight>, the reproduction means corresponds to the motion device control section <highlight><bold>111</bold></highlight>, the voice recording means corresponds to the input device <highlight><bold>102</bold></highlight>, the voice reproduction means corresponds to the motion device <highlight><bold>113</bold></highlight>, and the transmission commanding means corresponds to the expression transmission operating device <highlight><bold>110</bold></highlight>. </paragraph>
<paragraph id="P-0146" lvl="0"><number>&lsqb;0146&rsqb;</number> Furthermore, the above embodiment shows the example of the communication robot <highlight><bold>3</bold></highlight> related to the present invention and is not limited to an opportunity of the movement start or details of the expression data. </paragraph>
<paragraph id="P-0147" lvl="0"><number>&lsqb;0147&rsqb;</number> For example, when the expression data is received, and the specific movement of a user is detected, the motion device <highlight><bold>113</bold></highlight> may be operated based on the expression data stored in the expression data storage section <highlight><bold>107</bold></highlight>, and it is preferable because the user can easily start the movement. </paragraph>
<paragraph id="P-0148" lvl="0"><number>&lsqb;0148&rsqb;</number> Furthermore, when the execution command is received, for example, the motion device <highlight><bold>113</bold></highlight> may be operated based on the expression data stored in the expression data storage section <highlight><bold>107</bold></highlight>, and the user can starts the movement at desired timing. </paragraph>
<paragraph id="P-0149" lvl="0"><number>&lsqb;0149&rsqb;</number> For example, the receiving the expression data from the other communication robot <highlight><bold>3</bold></highlight> may be notified with the specific movement, and if it is done, the user can easily know the receiving of the above information. </paragraph>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> Furthermore, information in relation to the peripheral environment such as temperatures or brightness may be stored in the expression data storage section <highlight><bold>107</bold></highlight> to add motions corresponding to the peripheral environment in the movement of the motion device <highlight><bold>113</bold></highlight> based on the expression data stored in the expression data storage section <highlight><bold>107</bold></highlight>, for example, when shaking motions are added during the movement in the cold place, the user can communicate with more actual and richer feelings. </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> The present invention exhibits at least the following effects: </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> As discussed above, the communication tool of the present invention comprises the transmitting information storage means storing information in relation to the moving section directly moved by the user, the transmission means for transmitting the stored information in the transmitting information storage means, and the reproduction means for moving the moving section based on the information transmitted from the other communication tool, and it is a substantial communication tool for transmitting to reproduce the motion that the moving section in the other communication tool moves as the user directly moves it with the hands, so that the user can communicate with actual and rich feelings. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> It will be understood by those of skill in the art that numerous and various modifications can be made without departing from the spirit of the present invention. Therefore, it should be clearly understood that the forms of the present invention are illustrative only and are not intended to limit the scope of the present invention. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A communication tool comprising: 
<claim-text>a motion device which is physically movable by a user and provides signals corresponding to its movement; </claim-text>
<claim-text>a transmitting information storage for storing the signals; </claim-text>
<claim-text>a transmitter for transmitting the signals stored in the transmitting information storage to another communication tool; </claim-text>
<claim-text>a receiver for receiving signals transmitted from another communication tool; </claim-text>
<claim-text>a received information storage for storing the received signals by the receiver; and </claim-text>
<claim-text>a motion reproduction unit for activating the motion device based on the received signals stored in the received information storage. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising a behavior control unit provided a position between the motion device and the transmitting information storage, between the motion reproduction unit and the received information storage, between the transmitter and the transmitting information storage, and between the receiver and the receiving information storage, so that all signals pass through the behavior control unit which controls flow of the signals. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, further comprising an environment detection unit for detecting environmental information including the user&apos;s designated motion, said environment detection unit being connected to the behavior control unit, said behavior control unit being configured to activate the motion reproduction unit when the user&apos;s designated motion is detected. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, further comprising an environment detection unit for detecting environmental information including signals inputted by the user, said environment detection unit being connected to the behavior control unit, said behavior control unit being configured to activate the motion reproduction unit when the user&apos;s signals are received. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, further comprising an environment detection unit for detecting environmental information including ambient, temperature and brightness, said environment detection unit being connected to the behavior control unit, said behavior control unit being configured to transmit the environmental information. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, further comprising a mode selection unit for selecting an autonomous mode for activating the motion reproduction unit autonomously or an expression transmission mode for following the user&apos;s commands, wherein the behavior control unit includes the autonomous mode and the expression transmission mode. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, further comprising an operation command input unit for selecting one operation from (i) signal receiving processing, (ii) signal transmitting processing, or (iii) motion reproduction processing, in the expression transmission mode, wherein the expression transmission mode of the behavior control unit includes the signal receiving processing, the signal transmitting processing, and the motion reproduction processing. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the behavior control unit is configured to output information stored in the transmitting information storage to the motion reproduction unit to move the motion device. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the behavior control unit is configured to access an external memory unit to save information stored in either of the transmitting information storage or the received information storage or provide information to either of the transmitting information storage or the received information storage. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A communication method comprising: 
<claim-text>physically manipulating a motion device by a user, said motion device providing signals corresponding to its movement; </claim-text>
<claim-text>for storing the signals in a transmitting information storage; </claim-text>
<claim-text>transmitting the stored signals to another communication tool; </claim-text>
<claim-text>receiving signals transmitted from another communication tool; </claim-text>
<claim-text>storing the received signals in a received information storage; and </claim-text>
<claim-text>activating the motion device based on the received signals stored in the received information storage. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A communication tool characterized by comprising: 
<claim-text>a moving section; </claim-text>
<claim-text>a transmitting information storage means for storing information relating to the moving section directly moved by a user; </claim-text>
<claim-text>a transmission means for transmitting the information stored in the transmitting information storage means; </claim-text>
<claim-text>a receiving means for receiving the information transmitted from other communication tools; </claim-text>
<claim-text>a received information storage means for storing the information received by the receiving means; and </claim-text>
<claim-text>a reproduction means for moving the moving section based on the information stored in the received information storage means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the receiving means comprises a reception notifying means for notifying that the receiving means received the information. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, comprising a detection means for detecting the specific movement of the user, wherein the reproduction means is adapted to move the moving section based on the information stored in the received information storage means, when the receiving means receives the information and when the detection means detects the specific movement. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, wherein the transmission means is adapted to transmit an execution command, and the reproduction means is adapted to move the moving section based on the information stored in the received information storage means when the receiving means receives the execution command. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, further comprising a mode switching means for selectively switching an autonomous mode and an expression transmission mode. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, wherein the mode switching means is adapted to switch to the expression transmission mode when the receiving means receives the information. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, further comprising a transmission commanding means for making the transmission means start transmission based on a command of the user. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A communication tool characterized by comprising: 
<claim-text>a moving section; </claim-text>
<claim-text>a storage means for storing information relating the moving section directly moved by a user; and </claim-text>
<claim-text>a reproduction means for moving the moving section based on the information stored in the storage means. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> or <highlight><bold>18</bold></highlight>, further comprising an environmental information acquisition means for acquiring information relating to a peripheral environment, wherein the transmitting information storage means is also adapted to store the information acquired by the environmental information acquisition means. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> or <highlight><bold>18</bold></highlight>, further comprising a gesture information acquisition means for acquiring information relating to the gestures of the user, wherein the transmitting information storage means is also adapted to store the information acquired by the gesture information acquisition means. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> or <highlight><bold>18</bold></highlight>, comprising a feeling information acquisition means for acquiring information relating to feelings of the user, wherein the transmitting information storage means is also adapted to store the information acquired by the feeling information acquisition means. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> or <highlight><bold>18</bold></highlight>, further comprising a music reproduction means capable of reproducing music data, wherein the transmitting information storage means is adapted to store the music data, and the reproduction means is adapted to make the music reproduction means reproduce the music data as well as move the moving section, based on the information stored in the received information storage means. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> or <highlight><bold>18</bold></highlight>, further comprising a voice recording means for recording the voice spoken by the user and a voice reproduction means capable of reproducing the voice, wherein the transmitting information storage means is also adapted to store the voice recorded with the voice recording means, and the reproductopn means is adapted to make the voice reproduction means reproduce the voice based on information stored in the received information storage means as well as to move the moving section. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The communication tool according to <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference> or <highlight><bold>18</bold></highlight>, wherein the reproduction means has at least one of a forwarding function, a pausing function, a slow replay function, a reverse function, and a repeat function. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A communication support system characterized by comprising: 
<claim-text>a communication tool comprising: 
<claim-text>a moving section; </claim-text>
<claim-text>a transmitting information storage means for storing information relating to the moving section directly moved by a user; and </claim-text>
<claim-text>a transmission means for transmitting the stored information in the transmitting information storage means; and </claim-text>
</claim-text>
<claim-text>a terminal device comprising: 
<claim-text>a receiving means for receiving the information transmitted from the communication tool; </claim-text>
<claim-text>a received information storage means for storing the information received with the receiving means; </claim-text>
<claim-text>an image production means for producing a moving image based on the information stored in the received information storage means; and </claim-text>
<claim-text>an image display means for displaying the image produced with the image production means. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. A communication support system characterized by comprising: 
<claim-text>a communication tool comprising: 
<claim-text>a moving section; </claim-text>
<claim-text>a storage means for storing information relating to the moving section directly moved by a user; </claim-text>
<claim-text>a reproduction means for moving the moving section based on the information stored in the storage means; and </claim-text>
<claim-text>a transmission means for transmitting the stored information in the storage means; and </claim-text>
</claim-text>
<claim-text>a terminal device comprising: 
<claim-text>a receiving means for receiving information transmitted from the communication tool; </claim-text>
<claim-text>a received information storage means for storing the information received with the receiving means; and </claim-text>
<claim-text>a transfer means for transferring the information stored in the received information storage means to the storage means of other communication tools. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. A communication support system characterized by comprising: 
<claim-text>a communication tool comprising: 
<claim-text>a moving section; </claim-text>
<claim-text>a storage means for storing information relating to the location of the moving section directly moved by a user; </claim-text>
<claim-text>a reproduction means for moving the moving section based on the information stored in the storage means; and </claim-text>
<claim-text>a transmission means for transmitting the identification information of the user and the password with the information stored in the transmitting information storage means; and </claim-text>
</claim-text>
<claim-text>a server comprising: 
<claim-text>a receiving means for receiving the information transmitted from the communication tool; </claim-text>
<claim-text>a user identification means for verifying the identification information and the password based on the information received by the receiving means; </claim-text>
<claim-text>a received information storage means for storing the information received with the receiving means and accounting information when the user identification means verifies that the identification information and the password are correct;and </claim-text>
<claim-text>a transfer means for transferring the information stored in the received information storage means to a terminal device.</claim-text>
</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001744A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001744A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001744A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001744A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001744A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001744A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
