<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004942A1-20030102-D00000.TIF SYSTEM "US20030004942A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004942A1-20030102-D00001.TIF SYSTEM "US20030004942A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004942A1-20030102-D00002.TIF SYSTEM "US20030004942A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004942A1-20030102-D00003.TIF SYSTEM "US20030004942A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004942A1-20030102-D00004.TIF SYSTEM "US20030004942A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004942A1-20030102-D00005.TIF SYSTEM "US20030004942A1-20030102-D00005.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004942</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10177193</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020621</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>0115970.6</doc-number>
</priority-application-number>
<filing-date>20010629</filing-date>
<country-code>GB</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F007/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>707</class>
<subclass>003000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method and apparatus of metadata generation</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Colin</given-name>
<family-name>Bird</family-name>
</name>
<residence>
<residence-non-us>
<city>Eastleigh</city>
<country-code>GB</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<assignee>
<organization-name>International Business Machines Corporation</organization-name>
<address>
<city>Armonk</city>
<state>NY</state>
</address>
<assignee-type>03</assignee-type>
</assignee>
<correspondence-address>
<name-1>Gregory M. Doudnikoff</name-1>
<name-2>IBM Corp, IP Law Dept T81/503</name-2>
<address>
<address-1>3039 Cornwallis Road</address-1>
<address-2>PO Box 12195</address-2>
<city>Research Triangle Park</city>
<state>NC</state>
<postalcode>27709-2195</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A method of generating metadata is provided including providing (<highlight><bold>401</bold></highlight>) a plurality of source texts (<highlight><bold>100</bold></highlight>), processing the plurality of source texts (<highlight><bold>100</bold></highlight>) to extract primary metadata in the form of a plurality of sets of words (<highlight><bold>104, 106</bold></highlight>), and comparing (<highlight><bold>407</bold></highlight>) each of the source texts (<highlight><bold>100</bold></highlight>) with each of the sets of words (<highlight><bold>104, 106</bold></highlight>). The method includes using a clustering program to extract the sets of words (<highlight><bold>104, 106</bold></highlight>) from the source texts (<highlight><bold>100</bold></highlight>). The step of comparing is carried out by Latent Semantic Analysis to compare the similarity of meaning of each source text (<highlight><bold>100</bold></highlight>) with each set of words (<highlight><bold>104, 106</bold></highlight>) obtained by the clustering program. The comparison obtains a measure of the extent to which each source text (<highlight><bold>100</bold></highlight>) is representative of a set of words (<highlight><bold>104, 106</bold></highlight>). </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This invention relates to a method and apparatus of metadata generation. In particular for generation of descriptive metadata for collections of multimedia documents. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Metadata, often defined as &ldquo;data about data&rdquo;, is known to be used for the retrieval of required items of information from collections holding a large number of items. The nature of the metadata can range from factual to descriptive and, while usually alphanumeric, is not restricted to being so. Examples of factual metadata are: the name of the creator of the item to which the metadata refers; the date of addition to the collection; and a reference number unique to the institution holding the collection. Descriptive metadata is typically a textual depiction of what the item of information is about, usually comprising one or more keywords. Descriptive metadata often reveals the concepts to which the information relates. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> Metadata can be grouped to provide a comprehensive set of factual and descriptive elements. The Dublin Core is the most prominent initiative in this respect. The Dublin Core initiative promotes the widespread adoption of metadata standards and develops metadata vocabularies for describing resources that enable more intelligent information discovery systems. The first metadata standard developed is the Metadata Element Set which provides a semantic vocabulary for describing core information properties. The set of attributes includes, for example, &ldquo;Name&rdquo;&mdash;the label assigned to the data element, &ldquo;Identifier&rdquo;&mdash;the unique identifier assigned to the data element, &ldquo;Version&rdquo;&mdash;the version of the data element, &ldquo;Registration Authority&rdquo;&mdash;the entity authorised to register the data element, etc. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Descriptive metadata is the most difficult form to obtain. If the item of information is a text, source material is readily available. For non-text media, such as digital images, items are usually preserved with accompanying textual descriptions. In both cases, the task is to extract a number of keywords that capture the essential characteristics of the item. For greatest effectiveness, the words used should be drawn from a controlled vocabulary, appropriate to the subjects the material is about, but in most cases, agreed vocabularies do not yet exist. Authors of metadata will thus be choosing their own keywords and may: omit words that other authors would hold to be significant; include other words as a matter of personal preference; choose words that are in some contexts ambiguous; or misrepresent the true meaning of the item by an inappropriate choice of keywords. Although this extraction of keywords is an inherently unreliable procedure, the results will invariably be significantly better than having no metadata. Of greater concern is the demanding nature of the task such that it becomes too expensive to prepare the metadata. The solution is for the process to become at least semiautomatic, so that the amount of human judgement required is minimal and constrained in its nature. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> At a preliminary level, descriptive metadata can be created by a clustering process, in which the documents comprising the collection are grouped according to the similarity of the topics they cover. At this point, it is important to note that the term &ldquo;document&rdquo; is not restricted to text. The term &ldquo;document&rdquo; may refer to any multimedia item, although for the purposes of this invention it is necessary that some descriptive text is <highlight><bold>15</bold></highlight> associated with any non-text item, such as an image. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Clusters are characterised by a number of words which have been found to be representative of the contents of the document members of the cluster. It is these sets of words that constitute the primary level of metadata. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> An example of a clustering program is the Intelligent Miner for Text of International Business Machines Corporation. In this form of clustering, a document collection is segmented into subsets, called clusters, where each cluster is a group of objects which are more similar to each other than to members of any other group. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Clustering using IBM&apos;s Intelligent Miner for Text program provides a link from a document to primary metadata. This is limited in two respects: (a) the link is unidirectional; and (b) individual documents belong to only one cluster. The link is unidirectional as a document is mapped to a cluster; however, the cluster does not link back to documents which are members of that cluster. Individual documents are only mapped to one cluster or &ldquo;concept&rdquo; which is the cluster which is most representative of the document. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> These limitations are not present in all text clustering algorithms; however, other clustering algorithms are deficient in other respects. A major deficiency in other forms of clustering is that they do not produce clustering that has wide coverage of the subject matter. For general purpose information retrieval, a system of metadata should be capable of wide coverage. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Primary metadata as obtained by clustering methods commonly requires further processing to render it more useful. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> An information specialist can take the primary level of metadata provided by clusters and associate it with context descriptors. For example, a mapping from primary metadata to secondary metadata can be achieved by an information specialist mapping clusters generated with IBM&apos;s Intelligent Miner for Text program to categories from a controlled vocabulary such as the Dewy Decimal Classification. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> The present invention enables an analysis of the relationship between primary metadata and source texts from which the primary metadata was derived. Analysis is achieved by examining the semantics of the words and texts. Semantic analysis can be carried out using known techniques, for example, Latent Semantic Analysis (LAS). </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Latent Semantic Analysis (LAS) is a theory and method for extracting and representing the contextual-usage meaning of words by statistical computations applied to a large body of text. The underlying concept is that the total information about all the word contexts in which a given word does and does not appear provides a set of mutual constraints that largely determines the similarity of meaning of words and set of words to each other. It is a method of determining and representing the similarity of meaning of words and passages by statistical analysis of large bodies of text. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> A description of Latent Semantic Analysis is provided in &ldquo;An Introduction to Latent Semantic Analysis&rdquo; by Lender, T. K., Float, P. W., &amp; Lanham, D., Discourse Processes, <highlight><bold>25, 259-284 </bold></highlight>(1998). Details of the analysis are also provided at http://LSA.colorado.edu </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> As a practical method for statistical characterisation of word usage, LSA produces measures of word-word, word-passage and passage-passage relations that are reasonably well correlated with several human cognitive phenomena involving association or semantic similarity. LSA allows the approximation of human judgement of overall meaning similarity. Similarity estimates derived by LSA are not simple contiguity frequencies or co-occurrence contingencies, but depend on a deeper statistical analysis that is capable of correctly inferring relations beyond first order co-occurrence and, as a consequence, is often a very much better predictor of human meaning-based judgements and performance. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> LSA uses the detailed patterns of occurrences of words over very large numbers of local meaning-bearing contexts, such as sentences and paragraphs, treated as unitary wholes. </paragraph>
</section>
<section>
<heading lvl="1">Disclosure of the Invention </heading>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> According to a first aspect of the present invention there is provided a method of generating metadata comprising the steps of: providing a plurality of source texts; processing the plurality of source texts to extract primary metadata in the form of a plurality of sets of words; comparing a source text with each of the sets of words to obtain a measure of the extent to which the source text is representative of a set of words. This measure of the extent to which a set of words represents a source text provides secondary metadata. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> Each source text may be compared to each of the sets of words. The source texts may be multimedia documents with at least some associated textual content. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> The invention provides a system that allows documents to be indexed and searched for by reference to the extent to which they are representations of more than one concept (characterised in the form of primary metadata). Also, each concept provide an indication of the documents which are representations of that concept. One reason for generating such metadata is to make tractable the task of finding relevant material within a large collection of multimedia documents. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> In an embodiment, the processing step clusters source texts together and produces a set of words representative of the meaning of the source texts in the cluster. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> The comparing step may associate a source text with one or more sets of words with a weighting of the similarity of meaning between the source text and a set of words. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The comparing step may be carried out using Latent Semantic Analysis. The Latent Semantic Analysis may generate a value representing the extent to which a source text is represented by a set of words. The value may represent the similarity of meaning between the source text and the set of words. The value may be compared to a threshold value. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Additional source texts may be added prior to the comparing step and the comparing step is carried out on the combined texts. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> A plurality of sets of words may be merged prior to the comparing step and the comparing step is carried out on the merged sets of words. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> The content of the set of words may optionally be manually refined before the comparing step is carried out. Identifying labels may be allocated to the sets of words. The identifying labels may be used in a graphical user interface. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> According to a second aspect of the present invention there is provided an apparatus for generating metadata comprising: means for providing a plurality of source texts; means for processing the source texts to extract primary metadata in the form of a plurality of sets of words; means for comparing a source text with each of the sets of words to obtain a measure of the extent to which the source text is representative of a set of words. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The apparatus may include an application programming interface for accessing the source texts. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> According to a third aspect of the present invention there is provided a computer program, which maybe made available as a computer program product stored on a computer readable storage medium, comprising computer readable program code means for performing the steps of: providing a plurality of source texts; processing the plurality of source texts to extract primary metadata in the form of a plurality of sets of words; comparing a source text with each of the sets of words to obtain a measure of the extent to which the source text is representative of a set of words. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> This invention describes a process whereby a primary level of metadata can be derived for one or more collections of information. A first step is to form clusters of related items, using a suitable tool, for example, such as IBM&apos;s Intelligent Miner for Text. Other forms of suitable tools for extracting primary metadata could be used. The next step takes the concepts represented by each cluster and weights each item in the collection(s) according to how well the item represents the concept. This latter step can use Latent Semantic Analysis. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> The method performs an analysis for each set of words characterising a cluster against each of the document texts used for the clustering. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Embodiments of the present invention will now be described, by means of example only, with reference to the accompanying drawings in which: </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a diagrammatic representation of documents categorised into clusters in accordance with the present invention; </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flow diagram of a comparison step in a method in accordance with the present invention; </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is an illustration of a process of the comparison step of <cross-reference target="DRAWINGS">FIG. 2</cross-reference>; </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flow diagram of a method in accordance with the present invention; and </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a diagrammatic representation of a method in accordance with the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> A method is described for deriving descriptive metadata for one or more collections of documents. The term &ldquo;documents&rdquo; is used throughout this description to refer to multimedia items with some descriptive text associated with the item. As examples, a document may be a text, a document may be an image with a textual description, or a document may be a video with picture and sound with a transcript of the sound, etc. The textual matter associated with a document is referred to as a &ldquo;source text&rdquo;. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a plurality of documents <highlight><bold>100</bold></highlight>. The documents can be initially provided in groups or sets in the form of collections in which case each collection of documents may be processed separately. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Each document has the textual matter extracted from it which forms a source text. This may involve combining different categories of text from within a document, for example, a description, bibliographic details, etc. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> A set of source texts is input into a clustering program. Altering the composition of the input set of source texts will almost certainly alter the nature and content of the clusters. The clustering program groups the documents in clusters according to the topics that the documents cover. The clusters are characterised by a set of words, which can be in the form of several word-pairs. In general, at least one of the word-pairs is present in each document comprising the cluster. These sets of words constitute a primary level of metadata. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In this described embodiment, the clustering program used is Intelligent Miner for Text provided by International Business Machines Corporation. This is a text mining tool which takes a collection of documents and organises them into a tree-based structure, or taxonomy, based on a similarity between meanings of documents. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The starting point for the Intelligent Miner for Text program are clusters which include only one document and these are referred to as &ldquo;singletons&rdquo;. The program then tries to merge singletons into larger clusters, then to merge those clusters into even larger clusters, and so on. The ideal outcome when clustering is complete is to have as few remaining singletons as possible. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> If a tree-based structure is considered, each branch of the tree can be thought of as a cluster. At the top of the tree is the biggest cluster, containing all the documents. This is subdivided into smaller clusters, and these into still smaller clusters, until the smallest branches which contain only one document. Typically, the clusters at a given level do not overlap, so that each document appears only once, under only one branch. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> The concept of similarity of documents requires a similarity measure. A simple method would be to consider the frequency of single words, and to base similarity on the closeness of this profile between documents. However, this would be noisy and imprecise due to lexical ambiguity and synonyms. The method used in IBM&apos;s Intelligent Miner for Text program is to find lexical affinities within the document. In other words, correlations of pairs of words appearing frequently within short distances throughout the document. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> A similarity measure is then based on these lexical affinities. Identified pairs of terms for a document are collected in term sets, these sets are compared to each other and the term set of a cluster is a merge of the term sets of its sub-clusters. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Common words will produce too many superfluous affinities, so these are removed first. All words are also reduced to their base form; for example, &ldquo;musical&rdquo; is reduced to &ldquo;music&rdquo;. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Other forms of extraction of keywords can be used in place of IBM&apos;s Intelligent Miner for Text program. The aim is to obtain a plurality of sets of words which characterise the concepts represented by the documents. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> plurality of source texts <highlight><bold>100</bold></highlight> is provided. The first three source texts <highlight><bold>101</bold></highlight>, <highlight><bold>102</bold></highlight>, <highlight><bold>103</bold></highlight> are clustered together and the cluster <highlight><bold>104</bold></highlight> is characterised by three pairs of words which have been extracted from the three documents <highlight><bold>101</bold></highlight>, <highlight><bold>102</bold></highlight>, <highlight><bold>103</bold></highlight> by the Intelligent Miner for Text program, namely &ldquo;white, cotton&rdquo;, &ldquo;cotton, dress&rdquo; and &ldquo;cotton, stripe&rdquo;. The set of words for the cluster is &ldquo;cotton, white, dress, stripe&rdquo;. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> The result is that each source text is mapped <highlight><bold>105</bold></highlight> to a set of words which is formed of key words extracted from the source texts. The individual source text may not have all the words of the set of words in its text. In the example of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the first document <highlight><bold>101</bold></highlight> does not include the word &ldquo;stripe&rdquo; but it is one of the words in the set of words for the first cluster <highlight><bold>104</bold></highlight> of which the first document <highlight><bold>101</bold></highlight> is a member. Other groups of the documents <highlight><bold>100</bold></highlight> are clustered in relation to different sets of words <highlight><bold>106</bold></highlight>. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> The sets of words are referred to as the primary level of metadata for the documents. This primary metadata is then compared to the source texts used to generate the primary metadata and, optionally, additional source texts. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> This primary level of metadata can be further characterised, although it is not essential to do so. The characterisation can be carried out manually. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> If a source text is a singleton which means that it has a set of words which are only relevant to that source text, the set of words may optionally be excluded or further processed. Deleting singletons improves the speed of both comparison and subsequently, search. The comparing step is faster because there are fewer sets of words to test. Searching is faster as there are less concepts characterised by the sets of words. Retaining singletons has the opposite effect but might have the advantage of exposing concepts that are relevant to a fresh set of source texts which were not used to generate the primary metadata. Merging singletons into what might be called a &ldquo;compromise cluster&rdquo; is a third option. This may include human intervention. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> The content of the sets of words can also optionally be refined manually. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> An information retrieval system may require the clusters to have identifying labels, possibly for display in a graphical user interface and providing such labels is optional. When supplying these labels, there is also the option to refine the content of the set of words that represent the clusters at this stage. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The next stage of the process is applied to source texts together with the sets of words for each of the clusters. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> Latent Semantic Analysis (LAS) is a fully automatic mathematical/statistical technique for extracting relations of expected contextual usage of words in passages of text. This process is used in the described method. Other forms of Latent Semantic Indexing or automatic word meaning comparisons could be used. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a flow diagram <highlight><bold>200</bold></highlight>, with a Latent Semantic Analysis <highlight><bold>203</bold></highlight> process having two inputs. The first input is a set of words <highlight><bold>201</bold></highlight> which is a set characterising a cluster of documents as extracted by the clustering process described above. The second input is a source text <highlight><bold>202</bold></highlight> from collections of documents. The collections of documents can be the source texts used for generating the clusters. However, different or additional collections of documents could be used. The LSA process <highlight><bold>203</bold></highlight> has an output <highlight><bold>204</bold></highlight> which provides an indication of the correlation between the source text <highlight><bold>202</bold></highlight> and the set of words <highlight><bold>201</bold></highlight> inputted into the process. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Each source text can be processed against each set of words regardless of whether the documents were included in the cluster characterised by the set of words in the clustering process. In effect, once the sets of words have been extracted by the clustering process, the grouping of the source texts in the clusters from the clustering process is ignored. Each source text is compared with each of the sets of words to obtain an indication of the level of similarity of meaning between each source text and each of the sets of words. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> Although a user does not need to understand the internal process of LSA in order to put the invention into practice, for the sake of completeness a brief overview of the LSA process within the automated system is given. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> The text passage or other context given in the columns of the matrix can be chosen to suit the subject-matter and the range of the documents. For example, the text passages can be text from encyclopaedia articles in which case there may be of the order of 30,000 columns in the matrix providing a broad reference of word occurrence in encyclopaedia contexts. Another example is the text from college level psychology textbooks in which each paragraph used as a text passage for a column in the matrix. Contexts can be chosen to suit the subject matter of the documents. For example, medical or legal documents use words in particular contexts and using samples of the contexts provides a good indication of the usage of words for comparisons. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Each cell in the matrix contains the frequency with which the word of its row appears in the passage demoted by its column. The cell entries are subjected to a preliminary transformation in which each cell frequency is weighted by a function that expresses both the word&apos;s importance in the particular passage and the degree to which the word type carries information in the domain of discourse in general. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> The LSA applies singular value decomposition (SVD) to the matrix. This is a general form of factor analysis which condenses the very large matrix of word-by-context data into a much smaller (but still typically 100-500) dimensional representation. In SVD, a rectangular matrix is decomposed into the product of three other matrices. One component matrix describes the original row entities as vectors of derived orthogonal factor values, another describes the original column entities in the same way, and the third is a diagonal matrix containing scaling values such that when the three components are matrix-multiplied, the original matrix is reconstructed. Any matrix can be so decomposed perfectly, using no more factors than the smallest dimension of the original matrix. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> Each word has a vector based on the values of the row in the matrix reduced by SVD for that word. Two words can be compared by measuring the cosine of the angle between the two word&apos;s vectors in a pre-constructed multidimensional semantic space. Similarly, two passages each containing a plurality of words can be compared. Each passage has a vector produced by summing the vectors of the individual words in the passage. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> In this case the passages are a set of words and a source text. The similarity between resulting vectors for passages, as measured by the cosine of their contained angle, has been shown to closely mimic human judgements of meaning similarity. The measurement of the cosine of the contained angle provides a value for each comparison of a set of words with a source text. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> In practice, the set of words and the source text are input into an LSA program and the contexts of words is chosen. For example, the set of words &ldquo;cotton, white, dress, stripe&rdquo; and the words of the source text are input using encyclopaedia contexts. The program outputs a value of correlation between the set of words and the source text. This is repeated for each set of words and for each source text in a one to one mapping until a set of values is obtained, as illustrated in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a table <highlight><bold>350</bold></highlight> in which each of the documents <highlight><bold>100</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> has an LSA generated value <highlight><bold>352</bold></highlight> for each of the sets of words <highlight><bold>104</bold></highlight>, <highlight><bold>105</bold></highlight> of the clusters. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> In this way, Latent Semantic Analysis (LAS) is used to compare the source texts and the cluster definitions in the form of the sets of words. The outcome of each analysis between a source text and a set of words is a value, usually within the range 0.0 to 1.0 but occasionally negative. This value can be subjected to a threshold to determine if the degree of concept representation is adequate. Typically, the threshold can be of the order of 0.3. Above the threshold, the value can be used as a weighting component to the metadata. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 4, a</cross-reference> flow diagram <highlight><bold>400</bold></highlight> of the method of the described embodiment is shown. A first set of source texts is provided <highlight><bold>401</bold></highlight> and accessed via a computer program and is processed <highlight><bold>402</bold></highlight> to extract keywords relating to the source texts in the set. A decision <highlight><bold>403</bold></highlight> is then made as to whether or not there are more sets of source texts. If there are more sets of source texts then a loop <highlight><bold>404</bold></highlight> returns to the beginning of the flow diagram <highlight><bold>400</bold></highlight> to input the next set of source texts <highlight><bold>401</bold></highlight>. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> If there are no more sets of source texts to be entered, the flow diagram <highlight><bold>400</bold></highlight> proceeds to the next step. The next step is an optional step of consolidating the keywords <highlight><bold>405</bold></highlight> from different sets of source texts to form a plurality of sets of words characterising various concepts. An optional step <highlight><bold>406</bold></highlight> can include adding further source texts into the process. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Each source text is then compared <highlight><bold>407</bold></highlight> with each of the sets of words in a one to one mapping. Values <highlight><bold>408</bold></highlight> of each mapping <highlight><bold>407</bold></highlight> are compiled and the values are compared <highlight><bold>409</bold></highlight> to a threshold value. Each source text is then classified <highlight><bold>410</bold></highlight> with a weighting of representation of a concept indicated by a set of words. The source texts are only representative of the concepts characterised by the set of words for which the value of the mapping <highlight><bold>407</bold></highlight> is above the threshold value <highlight><bold>409</bold></highlight>. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the method of the described embodiment is schematically illustrated. A collection of documents <highlight><bold>500</bold></highlight> is provided including three documents <highlight><bold>501</bold></highlight>, <highlight><bold>502</bold></highlight>, <highlight><bold>503</bold></highlight> which are clustered together in a group <highlight><bold>506</bold></highlight> by a clustering program to produce a first set of words <highlight><bold>504</bold></highlight> representing the three documents <highlight><bold>501</bold></highlight>, <highlight><bold>502</bold></highlight>, <highlight><bold>503</bold></highlight>. Other documents <highlight><bold>500</bold></highlight> are clustered into groups each represented by a set of words <highlight><bold>505</bold></highlight>. The sets of words <highlight><bold>504</bold></highlight>, <highlight><bold>505</bold></highlight> characterise concepts. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> The first set of words <highlight><bold>504</bold></highlight> is compared using LSA process <highlight><bold>507</bold></highlight> to each of the documents <highlight><bold>500</bold></highlight> in turn. The comparison is not restricted to the three documents <highlight><bold>501</bold></highlight>, <highlight><bold>502</bold></highlight>, <highlight><bold>503</bold></highlight> from which the first set of words <highlight><bold>504</bold></highlight> was initially obtained. A value <highlight><bold>510</bold></highlight> is obtained for each document <highlight><bold>500</bold></highlight> in relation to the first set of words <highlight><bold>504</bold></highlight>. The values <highlight><bold>511</bold></highlight>, <highlight><bold>512</bold></highlight>, <highlight><bold>513</bold></highlight> for the three documents <highlight><bold>501</bold></highlight>, <highlight><bold>502</bold></highlight>, <highlight><bold>503</bold></highlight> from which the first set of words <highlight><bold>504</bold></highlight> were obtained are fairly high as these three documents are well represented by the concept of the first set of words <highlight><bold>504</bold></highlight>. However, others of the documents <highlight><bold>500</bold></highlight>, for example document <highlight><bold>520</bold></highlight>, may also be well represented by the first set of words <highlight><bold>504</bold></highlight> although they were initially placed in a cluster defined by another set of words. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> All documents <highlight><bold>500</bold></highlight> with a value <highlight><bold>510</bold></highlight> above a threshold are classified in relation to the first set of words <highlight><bold>504</bold></highlight>. The value <highlight><bold>510</bold></highlight> gives a weighting of the degree of similarity between the meaning of the document <highlight><bold>500</bold></highlight> and the concept characterised by the first set of words <highlight><bold>504</bold></highlight>. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> The second set of words <highlight><bold>505</bold></highlight> is then compared to each of the documents <highlight><bold>500</bold></highlight> to obtain a next set of values and the classification is continued. Once all the sets of words have been compared to all the documents <highlight><bold>500</bold></highlight>, a complete classification is provided of the similarity of meaning of documents <highlight><bold>500</bold></highlight> with one or more concepts characterised by sets of words. The sets of words also have mappings to documents which are representative of their concept. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> The method of the described embodiment has two stages. The first stage extracts the keywords from documents. The second stage classifies the documents in relation to the keywords. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> It is optional whether or not the extraction of keywords stage and classification stage use the same set of documents as input. It may be advantageous to combine collections of documents during the classification stage to broaden subject coverage. If a single collection of documents is used for both stages, the subject matter coverage cannot extend beyond that of the collection itself. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> The result of the method is a list of documents that are representative of a concept as characterised by the set of words. A list can also be provided for each document of clusters to which the document belongs. The document lists indicate the extent of similarity of meaning between the document and each concept. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> The metadata accurately describes the document and cross references the document to other documents sharing the same concept. A search interface can use the metadata generated by the described method to recommend a number of documents likely to match a user&apos;s query. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> The present invention is typically implemented as a computer program product, comprising a set of program instructions for controlling a computer or similar device. These instructions can be supplied preloaded into a system or recorded on a storage medium such as a CD-ROM, or made available for downloading over a network such as the Internet or a mobile telephone network. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> Improvements and modifications may be made to the foregoing without departing from the scope of the present invention. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of generating metadata comprising the steps of: 
<claim-text>providing a plurality of source texts; </claim-text>
<claim-text>processing the plurality of source texts to extract primary metadata in the form of a plurality of sets of words; </claim-text>
<claim-text>comparing a source text with each of the sets of words to obtain a measure of the extent to which the source text is representative of a set of words. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein each source text is compared to each of the sets of words. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the source texts are multimedia documents with at least some associated textual content. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the processing step clusters source texts together and produces a set of words representative of the meaning of the source texts in the cluster. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the comparing step associates a source text with a weighting of the similarity of meaning between the source text and a set of words. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the comparing step is carried out using Latent Semantic Analysis. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00006">claim 6</dependent-claim-reference>, wherein the Latent Semantic Analysis generates a value representing the extent to which a source text is represented by a set of words. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the value represents the similarity of meaning between the source text and the set of words. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the value is compared to a threshold value. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein additional source texts are added prior to the comparing step and the comparing step is carried out on the combined texts. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein a plurality of sets of words are merged prior to the comparing step and the comparing step is carried out on the merged sets of words. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the content of the set of words is manually refined before the comparing step is carried out. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein identifying labels are allocated to the sets of words. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A method of generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the identifying labels are used in a graphical user interface. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. An apparatus for generating metadata comprising: 
<claim-text>means for providing a plurality of source texts; </claim-text>
<claim-text>means for processing the source texts to extract primary metadata in the form of a plurality of sets of words; </claim-text>
<claim-text>means for comparing a source text with each of the sets of words to obtain a measure of the extent to which the source text is representative of a set of words. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. An apparatus for generating metadata as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, wherein the apparatus includes an application programming interface for accessing the source texts. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A computer program product stored on a computer readable storage medium, comprising computer readable program code means for performing the steps of: 
<claim-text>providing a plurality of source texts; </claim-text>
<claim-text>processing the plurality of source texts to extract primary metadata in the form of a plurality of sets of words; </claim-text>
<claim-text>comparing a source text with each of the sets of words to obtain a measure of the extent to which the source text is representative of a set of words.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004942A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004942A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004942A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004942A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004942A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004942A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
