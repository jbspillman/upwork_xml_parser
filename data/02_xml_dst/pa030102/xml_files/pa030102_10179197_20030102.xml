<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001961A1-20030102-D00000.TIF SYSTEM "US20030001961A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00001.TIF SYSTEM "US20030001961A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00002.TIF SYSTEM "US20030001961A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00003.TIF SYSTEM "US20030001961A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00004.TIF SYSTEM "US20030001961A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00005.TIF SYSTEM "US20030001961A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00006.TIF SYSTEM "US20030001961A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00007.TIF SYSTEM "US20030001961A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00008.TIF SYSTEM "US20030001961A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00009.TIF SYSTEM "US20030001961A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00010.TIF SYSTEM "US20030001961A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00011.TIF SYSTEM "US20030001961A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00012.TIF SYSTEM "US20030001961A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00013.TIF SYSTEM "US20030001961A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00014.TIF SYSTEM "US20030001961A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00015.TIF SYSTEM "US20030001961A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00016.TIF SYSTEM "US20030001961A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00017.TIF SYSTEM "US20030001961A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030001961A1-20030102-D00018.TIF SYSTEM "US20030001961A1-20030102-D00018.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001961</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10179197</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020626</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2001-199856</doc-number>
</priority-application-number>
<filing-date>20010629</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2002-021502</doc-number>
</priority-application-number>
<filing-date>20020130</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04N005/232</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>348</class>
<subclass>345000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Camera</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Hideo</given-name>
<family-name>Yoshida</family-name>
</name>
<residence>
<residence-non-us>
<city>Saitama-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Yoshikazu</given-name>
<family-name>Mihara</family-name>
</name>
<residence>
<residence-non-us>
<city>Saitama-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>HARNESS, DICKEY &amp; PIERCE, P.L.C.</name-1>
<name-2></name-2>
<address>
<address-1>P.O. BOX 8910</address-1>
<city>RESTON</city>
<state>VA</state>
<postalcode>20195</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">Where a subject is dark, half pressing of a shutter release button causes an auxiliary light for auto-focusing use to be emitted from an electric flash. If half pressing and cancellation take place consecutively, a power of a main capacitor for the electric flash will become in sufficient, it is charged after emission of an auxiliary light. A camera is to be provided which can prevent charge processing from deteriorating an operating convenience by limiting either a duration of charging or a charging voltage then. Where the subject is dark, half pressing of the shutter release button causes the electric flash to emit an auxiliary light (AF pre-emission) and auto-focusing control to be executed. If half pressing of the shutter release button and its cancellation take place consecutively, charging of the main capacitor of the electric flash is performed alternately for different lengths of time, 150 ms and 300 ms. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to a camera, and more particularly to a camera which performs auto-focusing control by a passive system. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> For cameras which perform auto-focusing control in range finding, focus determination and the like by a passive system, what is provided with a device for emitting an auxiliary light for auto-focusing use is proposed because insufficient luminance of the subject prevents auto-focusing control from appropriately functioning. Also is proposed such a device using an electric flash as the source of the auxiliary light (Japanese Patent Application Publication Nos. 55-15154, 59-201009, 2000-111791 and 2000-338386, Japanese Patent No. 3139067 and so forth). </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> While an auxiliary light for auto-focusing use is emitted when, for instance, focusing is done by half pressing the shutter release button, where an electric flash is used for emitting this auxiliary light, if half pressing of the shutter release button and its cancellation are repeated, the electric power needed for real light emission for releasing the shutter may become insufficient. For this reason, it is necessary to charge the main capacitor after emitting an auxiliary light, but if the main capacitor is fully charged every time, when the shutter release button is fully pressed in the charging period, a longer time will be taken before the shutter can be released. Thus, since the shutter cannot be released during the charging period, even if the shutter release button is fully pressed, the user will have to wait until the charging is completed. The user will therefore feel awkward, and the camera itself will suffer the disadvantage of operating inconvenience. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> An object of the present invention, attempted in view of this circumstance, is to provide a camera capable of charging the main capacitor after the emission of an auxiliary light for auto-focusing use with minimum operating inconvenience. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> In order to attain the object stated above, the present invention is directed to a camera, comprising: a sensor having a plurality of light receiving elements which receive light from a subject in a range-finding area; an auto-focusing controller which performs auto-focusing control according to an output of the sensor; a charging device which charges a main capacitor; a light emitting device which is supplied with electric energy by the main capacitor and emits auxiliary light for auto-focusing use and auxiliary light for exposure use to the subject; a shutter release button which, when half pressed, causes auto-focusing control to be started according to the output of the sensor and, when fully pressed, causes shooting to be started; a light emission control device which causes the light emitting device to emit the auxiliary light for auto-focusing use when the shutter release button is half pressed and a desired output value is not obtained from the sensor; and a control device which, the auxiliary light for auto-focusing use emitted from the light emitting device in a state where the main capacitor is fully charged being supposed to be a first auxiliary light and the auxiliary light for auto-focusing use later emitted from the light emitting device when the shutter release button is half pressed again in a state where the main capacitor is not fully charged being supposed to be a second auxiliary light, following the emission of the first auxiliary light from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device as long as a first length of time and, following the emission of the second auxiliary light from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device as long as a second length of time longer than the first length of time. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> According to the present invention, since the main capacitor is not always fully charged after an auxiliary light for auto-focusing use is emitted by half pressing the shutter release button, but it is charged only for a limited length of time, the operating convenience can be prevented from being deteriorated by charging. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Preferably, the control device, following the emission of the auxiliary light of an odd-numbered round from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device as long as the first length of time and, following the emission of the auxiliary light of an even-numbered round from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device as long as the second length of time. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> According to the present invention, by setting that duration of charging to a required length of time for charging the main capacitor to a permissible minimum level to make possible electric flash shooting, impossibility of electric flash shooting due to insufficient charging can be reliably prevented. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> Preferably, the first length of time is a length of time required for enabling the charging device to charge the main capacitor to a permissible minimum level to make possible electric flash shooting. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> According to the present invention, by differentiating the length of time for charging according to whether or not the main capacitor is fully charged before auxiliary light emission, a more satisfactory performance can be achieved. Thus, since the remaining capacitance of the capacitor presumably is smaller after auxiliary light emission in a state in which it is not fully charged than after auxiliary light emission in a fully charged state, rational charging can be processed by charging the capacitor for a shorter period of time in the former case than in the latter case. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> The present invention is also directed to a camera, comprising: a sensor having a plurality of light receiving elements which receive light from a subject in a range-finding area; an auto-focusing controller which performs auto-focusing control according to an output of the sensor; a charging device which charges a main capacitor; a light emitting device which is supplied with electric energy by the main capacitor and emits auxiliary light for auto-focusing use and auxiliary light for exposure use to the subject; a shutter release button which, when half pressed, causes auto-focusing control to be started according to the output of the sensor and, when fully pressed, causes shooting to be started; a light emission control device which causes the light emitting device to emit the auxiliary light for auto-focusing use when the shutter release button is half pressed and a desired output value is not obtained from the sensor; and a control device which, the auxiliary light for auto-focusing use emitted from the light emitting device in a state where the main capacitor is fully charged being supposed to be a first auxiliary light and the auxiliary light for auto-focusing use later emitted from the light emitting device when the shutter release button is half pressed again in a state where the main capacitor is not fully charged being supposed to be a second auxiliary light, following the emission of the first auxiliary light from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device to a permissible minimum level to make possible electric flash shooting and, following the emission of the second auxiliary light from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device to a fully charged level. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> According to the present invention, since the main capacitor is not always fully charged after an auxiliary light for auto-focusing use is emitted by half pressing the shutter release button, but it is charged with a limited charging voltage, the operating convenience can be prevented from being deteriorated by charging. Also, by setting that charging voltage to a permissible minimum level to make possible electric flash shooting, impossibility of electric flash shooting due to insufficient charging can be reliably prevented.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The nature of this invention, as well as other objects and advantages thereof, will be explained in the following with reference to the accompanying drawings, in which like reference characters designate the same or similar parts throughout the figures and wherein: </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a front perspective view of a camera according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a rear perspective view of the camera; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram illustrating a control section of the camera; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a configuration of a subject position determining device by a passive system; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows an example of a sensor image where a distance from a subject position determining device to the subject is short; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows an example of sensor image where the distance from a subject position determining device to a subject is long; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> FIGS. <highlight><bold>7</bold></highlight>(A) to <highlight><bold>7</bold></highlight>(H) visualize a description of range-finding areas and peak selection regions of sensors; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flow chart regarding range-finder processing by a CPU; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a circuit diagram showing a configuration of an electric flash circuit; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flow chart regarding pre-emission processing by the CPU; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> FIGS. <highlight><bold>11</bold></highlight>(A) to <highlight><bold>11</bold></highlight>(E) illustrate sequences of processing for pre-emission of light; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> shows an example of regulating an amount of light emission in accordance with the temperature; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a graph showing a temperature-independence of an amount of electric flash light; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> illustrates processing to charge an electric flash (charging of a main capacitor MC) in connection with pre-emission; </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> further illustrates processing to charge the electric flash (charging of the main capacitor MC) in connection with pre-emission; </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a flow chart showing a procedure of charge processing by a CPU after pre-emission; </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a circuit diagram showing a configuration of an electric flash circuit in a second embodiment according to the invention; and </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a flow chart showing a procedure of charge processing by a CPU after pre-emission in the second embodiment according to the invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> A camera according to a preferred embodiment of the present invention will be described in detail below with reference to the accompanying drawings. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a front perspective view of a camera according to an embodiment of the present invention. As illustrated therein, a camera <highlight><bold>10</bold></highlight> is provided with, among other items, a zoom lens barrel <highlight><bold>12</bold></highlight> provided with a taking lens for forming an image of a subject on a silver halide film, a light emitting device <highlight><bold>16</bold></highlight> for emitting an auxiliary light to supplement the brightness of the subject at the time of shutter releasing (exposure to light) or range finding (auto-focusing), a view-finder window <highlight><bold>18</bold></highlight> for the user to confirm the subject to be shot, an AF window <highlight><bold>22</bold></highlight> with a built-in passive type sensor for measuring the distance to the subject (hereinafter referred to as the subject distance), a photometric window <highlight><bold>25</bold></highlight> with a built-in photometric device for measuring the brightness of the subject, and a shutter button <highlight><bold>34</bold></highlight>, which the user manipulates when instructing a shutter release. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a rear perspective view of the camera <highlight><bold>10</bold></highlight>. As illustrated therein, the camera <highlight><bold>10</bold></highlight> is provided with a display device <highlight><bold>38</bold></highlight> for displaying the date and information including the auxiliary light emitting mode, the auto-focusing mode and the self-timer mode that are set, a flash button <highlight><bold>42</bold></highlight> for the user to set one or another of various modes of auxiliary light emission, a self-timer button <highlight><bold>44</bold></highlight> for setting the self-timer mode, a focusing button <highlight><bold>46</bold></highlight> for setting one or another of various shooting modes regarding auto-focusing, a date button <highlight><bold>48</bold></highlight> for setting the day, hours and minutes the camera <highlight><bold>10</bold></highlight> counts, and a zoom button <highlight><bold>50</bold></highlight> for the user instructs the shooting angle either to be wide-angle or telephoto-angle. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> By manipulating the flash button <highlight><bold>42</bold></highlight>, the user can select one or another of an auto mode for automatically emitting an auxiliary light, a red eye alleviating mode, a forced light emitting mode, a light emission forbidding mode, a night scene portrait mode and so forth. The user also can select desired focusing mode out of an auto-focusing mode, a distant view mode, a macro mode and so forth by manipulating the focusing button <highlight><bold>46</bold></highlight>. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram illustrating a control section of the camera <highlight><bold>10</bold></highlight> described above. As illustrated therein, the camera <highlight><bold>10</bold></highlight> is provided with a CPU <highlight><bold>60</bold></highlight> (data processing device) for controlling the whole camera <highlight><bold>10</bold></highlight> to enable it to acquire information from different sections to be described below and to control these sections through instructions from the CPU <highlight><bold>60</bold></highlight>. The CPU <highlight><bold>60</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> may be an ASIC configured of peripheral circuits such as a CPU core unit, an I/O unit, a watchdog timer and an A/D converter. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Also as shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the camera <highlight><bold>10</bold></highlight> is provided with a regulator <highlight><bold>62</bold></highlight> for boosting and stabilizing the battery voltage and supplying power to the CPU <highlight><bold>60</bold></highlight> and its peripheral circuits, a lens barrel control device <highlight><bold>64</bold></highlight> (having functions of a shooting angle control device and an in-focus position control device) for controlling the zooming position and the focusing position of the zoom lens barrel <highlight><bold>12</bold></highlight> and supplying the CPU <highlight><bold>60</bold></highlight> with information on the zooming position and the focusing position, and a feed control device <highlight><bold>66</bold></highlight> for feeding and rewinding a silver halide film, if used as the image recording means, by a prescribed length and supplying a detection signal required for film feeding. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The camera <highlight><bold>10</bold></highlight> is further provided with a shutter control device <highlight><bold>68</bold></highlight> for controlling the opening and closing actions of the shutter when a picture is taken, a photometric device <highlight><bold>70</bold></highlight> for measuring the luminous energy of the subject on the basis of external light let in through the photometric window <highlight><bold>25</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> light emission control device <highlight><bold>72</bold></highlight> for controlling the charging of the main capacitor for storing light emitting energy and controlling the amount of auxiliary light emission from an electric flash (flash light) or the like on the basis of the brightness of external light measured by the photometric device <highlight><bold>70</bold></highlight>, and a subject position determining device <highlight><bold>74</bold></highlight> for supplying information on the brightness of the subject let in through the AF window <highlight><bold>22</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> and information on the position (the distance from the camera <highlight><bold>10</bold></highlight>) of the subject, the two kinds of information being associated with each other. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The camera <highlight><bold>10</bold></highlight> is further provided with a programmable ROM <highlight><bold>82</bold></highlight> (recording means such as an EEPROM or the like) for rewritably recording parameters, data and processing programs regarding the control of the camera <highlight><bold>10</bold></highlight>, information concerning range finding and other kinds of information, and a display control device <highlight><bold>84</bold></highlight> for supplying the display device <highlight><bold>38</bold></highlight> with signals for displaying graphics, characters, numerals and the like matching various modes in accordance with instructions from the CPU <highlight><bold>60</bold></highlight>. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> From an input device <highlight><bold>86</bold></highlight> comprising the shutter release button <highlight><bold>34</bold></highlight>, the flash button <highlight><bold>42</bold></highlight>, the self-timer button <highlight><bold>44</bold></highlight>, the focusing button <highlight><bold>46</bold></highlight>, the date button <highlight><bold>48</bold></highlight>, the zoom button <highlight><bold>50</bold></highlight> and so forth shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, signals matching manipulation of the different buttons are supplied to an <highlight><bold>1</bold></highlight>/O device provided in the CPU <highlight><bold>60</bold></highlight>. For the shutter release button <highlight><bold>34</bold></highlight>, detection distinguishes between a half pressed state (a state in which SP<highlight><bold>1</bold></highlight> is ON) and a fully pressed state (a state in which SP<highlight><bold>2</bold></highlight> is ON). </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> A driver <highlight><bold>88</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> controls a zoom drive motor and a focusing drive motor provided in the lens barrel control device <highlight><bold>64</bold></highlight> in accordance with instructions from the CPU <highlight><bold>60</bold></highlight>, and thereby makes it possible to drive a film feed motor provided in the feed control device <highlight><bold>66</bold></highlight>. The driver <highlight><bold>88</bold></highlight> can also supply a reference voltage and drive power to the AD converter circuit and the photometric device <highlight><bold>70</bold></highlight> in accordance with instructions from the CPU <highlight><bold>60</bold></highlight>. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> Further, the driver <highlight><bold>88</bold></highlight>, in accordance with an instruction from the CPU <highlight><bold>60</bold></highlight>, can supply a control signal for the shutter, which is opened and closed at the time of shutter release, to a shutter unit <highlight><bold>68</bold></highlight>, and a signal to instruct the start and end of the emission of the auxiliary light to the light emission control device <highlight><bold>72</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows the configuration of subject position determining device <highlight><bold>74</bold></highlight> by a passive system. As illustrated in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the subject position determining device <highlight><bold>74</bold></highlight> (AF sensor) is provided with a lens <highlight><bold>92</bold></highlight> for forming an image of a subject <highlight><bold>90</bold></highlight>, composed of two colors which may be black and white for instance, on the light receiving face of each of the right and left sensors; an R sensor <highlight><bold>94</bold></highlight> on the right and an L sensor <highlight><bold>96</bold></highlight> on the left which photoelectrically convert and supply images formed on the respective light receiving faces; a flexible substrate <highlight><bold>98</bold></highlight> for sensor power to the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> and the voltages of optical signals (luminance signals) obtained by the photoelectric conversion to an IC <highlight><bold>99</bold></highlight>, and the IC <highlight><bold>99</bold></highlight> for transmitting and receiving information and data to and from the CPU <highlight><bold>60</bold></highlight>, controlling the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight>, and processing data reading. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> The R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> are, for instance, CMOS line sensors, each comprising a plurality of cells (light receiving elements) arranged linearly. The cells of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> are to be identified by sensor numbers 1, 2, 3 . . . 233 and 234 sequentially from left to right in the diagrams. Five cells each at the left and right ends, respectively, of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> are dummy cells, which are not actually used. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> From the cells of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> are successively supplied to the IC <highlight><bold>99</bold></highlight> optical signals (luminance signals) matching the luminous energy received by each and associated with sensor numbers. The IC <highlight><bold>99</bold></highlight> integrates (adds up) the luminance signals of the cells obtained from the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight>, on a cell-by-cell basis, and acquires the integral of luminance signals (the integral of the luminous energy) for each cell. In the following description, simple reference to an integral will mean an integral of luminance signals, and that of integration or integral processing will mean integration or integral processing to obtain an integral of luminance signals. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> When the IC <highlight><bold>99</bold></highlight> detects that the integral of any cell has reached a prescribed value (an end-of-integration value) within a peak selection region, which is described afterwards and set in the sensor region (within all the cells) of each of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> (i.e., when the IC <highlight><bold>99</bold></highlight> judges that sufficient data for range finding have been obtained where a prescribed level of luminous energy has been obtained), the IC <highlight><bold>99</bold></highlight> ends integral processing, and supplies the CPU <highlight><bold>60</bold></highlight> with signal indicating the end of integral processing (an end-of-integration signal). The value to be supplied to the CPU <highlight><bold>60</bold></highlight> as integral for each cell is the balance of the subtraction of the luminance signal integral of each cell from a prescribed reference value. The greater the luminous energy received, the smaller the integral. In the following description, the balance of the subtraction of the luminance signal integral from the reference value will be referred to as the luminance signal integral. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> The CPU <highlight><bold>60</bold></highlight> instructs the IC <highlight><bold>99</bold></highlight> to start or forcibly end the above-described integral processing and to read the integral of each cell, and designates the peak selection region, high or low sensor sensitivity (gain of the integral) and so forth. The CPU <highlight><bold>60</bold></highlight>, upon reception of an end-of-integration signal from the IC <highlight><bold>99</bold></highlight> as described above or upon forced ending of integral processing, acquires from the IC <highlight><bold>99</bold></highlight> the integrals of different cells matched with sensor numbers. An image picked up by each of R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> (hereinafter referred to as a sensor image) is thereby acquired. Then, correlation computing between the sensor images of the R sensor <highlight><bold>94</bold></highlight> and of the L sensor <highlight><bold>96</bold></highlight> is performed to find out the discrepancy between the sensor images and thereby to figure out the distance to the subject <highlight><bold>90</bold></highlight> (the principle of trigonometrical measurement). </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> To additionally describe the kinds of input/output signals provided for the IC <highlight><bold>99</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, VDD stands a power supply line, AGND, a ground line for analog signals, and DGND, a ground line for digital signals. There are further provided, as signal lines for inputs to the IC <highlight><bold>99</bold></highlight> from the CPU <highlight><bold>60</bold></highlight>, /AFCEN for instructing the setting of the IC <highlight><bold>99</bold></highlight> into an operating state or a non-operating state, /AFRST for instructing the setting of control data, AFAD for setting control data, and AFCLK for instructing at up edge the timing of reading control data in. On the other hand, as signal lines for outputs from the IC <highlight><bold>99</bold></highlight> to the CPU <highlight><bold>60</bold></highlight>, there are provided AFDATAP to supply as analog data of balances of subtraction of the integrals of luminance signals of cells provided in the sensors from a reference voltage VREF, MDATA to supply as analog data of the maximum integral in the peak selection region set according to AFAD signals, and /AFEND to supply a signal notifying the start timing of integration and indicating that the maximum integral in the peak selection region has reached a prescribed setpoint. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 5 and 6</cross-reference> show examples of sensor image where the distance from the subject position determining device <highlight><bold>74</bold></highlight> to the subject <highlight><bold>90</bold></highlight> is short and long, respectively. Where the distance to the subject <highlight><bold>90</bold></highlight> is short, as shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the integral of luminance signals to sensor numbers <highlight><bold>87</bold></highlight> to <highlight><bold>101</bold></highlight> of the L sensor <highlight><bold>96</bold></highlight> takes on a brighter value (50), and that of luminance signals to its sensor numbers <highlight><bold>102</bold></highlight> to <highlight><bold>150</bold></highlight> takes on a darker value (200). Regarding the R sensor <highlight><bold>94</bold></highlight>, as it is arranged in a different position from the L sensor <highlight><bold>96</bold></highlight>, the integral of luminance signals to sensor numbers <highlight><bold>85</bold></highlight> to <highlight><bold>133</bold></highlight> takes on a brighter value (50) while that of luminance signals to sensor numbers <highlight><bold>134</bold></highlight> to <highlight><bold>148</bold></highlight> takes on a darker value (200). </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> On the other hand, where the distance to the subject <highlight><bold>90</bold></highlight> is long (for instance, almost infinitely long), the integral of luminance energies to sensor numbers <highlight><bold>87</bold></highlight> to <highlight><bold>117</bold></highlight> of the L sensor <highlight><bold>96</bold></highlight> takes on a brighter value (50), while that of luminance energies to its sensor numbers <highlight><bold>118</bold></highlight> to <highlight><bold>150</bold></highlight> takes on a darker value (200) as shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. On the other hand, regarding the R sensor <highlight><bold>94</bold></highlight>, though it is arranged in a different position from the L sensor <highlight><bold>96</bold></highlight> but because the subject position is at a long distance, the integral of luminance energies to sensor numbers <highlight><bold>85</bold></highlight> to <highlight><bold>116</bold></highlight> takes on a brighter value (50), while that of luminance energies to sensor numbers <highlight><bold>117</bold></highlight> to <highlight><bold>148</bold></highlight> takes on a darker value (200). In this case, the CPU <highlight><bold>60</bold></highlight> can judge that there is virtually no lag amount between the sensor images of the R sensor <highlight><bold>94</bold></highlight> and of the L sensor <highlight><bold>96</bold></highlight> and accordingly that the subject is at an almost infinitely long distance. Unlike in this case, where the subject is at a short distance as shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the lag amount of sensor images is greater. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Quantitatively, the subject distance can be computed from the lag amount of sensor images, with the spacing between the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight>, the distance from sensors to the lens <highlight><bold>92</bold></highlight>, and the pitch of cells in the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> (e.g., 12 &mgr;m) among other factors taken into consideration. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> The lag amount of sensor images can be figured out by correlation computing between the sensor images of the R sensor <highlight><bold>94</bold></highlight> and of the L sensor <highlight><bold>96</bold></highlight>. For instance, window regions each containing the same number (total number WO) of cells are set for the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight>, and the integral of luminance signals of numbers i of the cells in those window regions (not the above-mentioned sensor numbers but numbers assigned to cells in the respective window regions of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> in the same arrangement (for instance sequentially, from right to left, <highlight><bold>1</bold></highlight> to WO)) are represented by R(i) for the R sensor <highlight><bold>94</bold></highlight> and L(i) for the L sensor <highlight><bold>96</bold></highlight>. Here, the correlation f is:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>f&equals;&Sgr;&verbar;L</italic></highlight>(<highlight><italic>i</italic></highlight>)&minus;<highlight><italic>R</italic></highlight>(<highlight><italic>i</italic></highlight>)&verbar;(<highlight><italic>i</italic></highlight>&equals;1 to <highlight><italic>WO</italic></highlight>).</in-line-formula></paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Then, if the correlation f is sought for while the relative positions of (distance between) the window regions of the R sensor <highlight><bold>94</bold></highlight> and of the L sensor <highlight><bold>96</bold></highlight> are shifted by, for instance, one cell at a time, a point where the correlation f is at its minimum will be detected. For example, where f(n) represents the correlation where the window regions of the R sensor <highlight><bold>94</bold></highlight> and of the L sensor <highlight><bold>96</bold></highlight> are shifted by an n cells equivalent in the direction of deviating from reference relative positions of window regions (for instance positions in a relationship of giving the minimum correlation f to a subject at an infinitely long distance), n at the time of detection of the minimum correlation f(n) will represent the lag amount of sensor images. The computing to find out the correlation f(n) will hereinafter be referred to as correlation computing. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> In the present embodiment, the sensor region of each of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> is divided into five areas including the &ldquo;right area&rdquo;, &ldquo;center right area&rdquo;, &ldquo;center area&rdquo;, &ldquo;center left area&rdquo; and &ldquo;left area&rdquo; (each of these areas will hereinafter be referred to as a range-finding area) as shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(A), and the correlation computing described above is done individually performed between the matching range-finding areas (between range-finding areas of the same name) of the R sensor <highlight><bold>94</bold></highlight> and of the L sensor <highlight><bold>96</bold></highlight> to figure out the subject distances. Therefore, the subject distances can be determined for a maximum of five range-finding areas. If the zooming position is set more toward the wide-angle side (for instance, in ranges Z<highlight><bold>1</bold></highlight> to Z<highlight><bold>5</bold></highlight> where the zooming position is divided into six ranges Z<highlight><bold>1</bold></highlight> to Z<highlight><bold>6</bold></highlight>) than the prescribed zooming position, the correlation computing is done for all the five range-finding areas, and the subject distance is computed for each range-finding area. The same is true in the macro mode as well. If the zooming position is set more toward the telephoto angle side than is prescribed (in range Z<highlight><bold>6</bold></highlight> of the above-stated division), the correlation computing is done for three range findings areas including the center right, center and center left areas, and the subject distance is computed for each range-finding area. In either case, a plurality of subject distances may be sometimes figured out for a plurality of range-finding areas, the shortest of the figured-out subject distances will be used as a rule for the control of the lens barrel control device <highlight><bold>64</bold></highlight>. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Also, for peak selection regions where it is judged whether or not the integral of any cell has reached an end-of-integration value in ending integral processing, the five divided range-finding areas provide the basis, and one or another of the seven peak selection regions indicated by (1) to (7) in FIGS. <highlight><bold>7</bold></highlight>(B) to <highlight><bold>7</bold></highlight>(H) is set. Peak selection region (<highlight><bold>1</bold></highlight>) consists of the three &ldquo;center right, center and center left&rdquo; range-finding areas, and this is selected when the zooming position is toward the telephoto angle side (the above-described Z<highlight><bold>6</bold></highlight>). The extent of angles of the peak selection region here is &plusmn;3.9 degrees. Peak selection region (<highlight><bold>2</bold></highlight>) consists of all the &ldquo;right, center right, center, center left and left&rdquo; range-finding areas, this is selected when the zooming position is toward the wide-angle side (the above-described Z<highlight><bold>1</bold></highlight> to Z<highlight><bold>5</bold></highlight> and in the macro mode). The extent of angles of the peak selection region here is &plusmn;6.5 degrees. Peak selection regions (<highlight><bold>3</bold></highlight>), (<highlight><bold>4</bold></highlight>) and (<highlight><bold>5</bold></highlight>) respectively consist of the center area, the center left area and the right center area, and peak selection regions (<highlight><bold>4</bold></highlight>) and (<highlight><bold>5</bold></highlight>) in particular are used when the zooming position is toward the telephoto angle side and the luminance of the subject is high. Peak selection regions (<highlight><bold>6</bold></highlight>) and (<highlight><bold>7</bold></highlight>) respectively consist of the &ldquo;right and center right&rdquo; areas and the &ldquo;left and center left&rdquo; areas, and they are used when the zooming position is toward the wide-angle side and the luminance of the subject is high. Peak selection region (<highlight><bold>3</bold></highlight>) is used when the luminance of the subject is high, whether the zooming position is toward the telephoto angle side or toward the wide-angle side. As a rule, the subject distance is figured out by the above-described correlation computing with respect to the range-finding area selected as the peak selection region. What peak selection region is to be used in what case will be explained in detail with reference to the following flow chart. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flow chart regarding range-finder processing by the CPU <highlight><bold>60</bold></highlight> referred to above. When the processing mode of the camera <highlight><bold>10</bold></highlight> is set for shooting mode and the user half-presses the shutter release button <highlight><bold>34</bold></highlight>, the CPU <highlight><bold>60</bold></highlight> acquires from the input device <highlight><bold>86</bold></highlight> an SP<highlight><bold>1</bold></highlight> ON signal indicating that shutter release button <highlight><bold>34</bold></highlight> has been pressed. When the SP<highlight><bold>1</bold></highlight> ON signal is acquired, the CPU <highlight><bold>60</bold></highlight> sets an AE matching the luminance of the subject in order to shoot the subject <highlight><bold>90</bold></highlight>, and starts processing the subject <highlight><bold>90</bold></highlight> which has been specified. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> When it is to perform processing to specify the subject <highlight><bold>90</bold></highlight> for the camera <highlight><bold>10</bold></highlight> and to focus on it, the CPU <highlight><bold>60</bold></highlight> first branches into a processing routine for AF range finding shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> to specify the subject and measure its distance. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> In the processing routine for AF range finding, first the CPU <highlight><bold>60</bold></highlight> references the signal output of the luminous energy supplied by the photometric device <highlight><bold>70</bold></highlight>, and judges whether or not the luminous energy of the subject is at or above a prescribed luminance threshold, which is deemed to be an ultra-high level of luminance (step S<highlight><bold>100</bold></highlight>). If it is judged NO, then the CPU <highlight><bold>60</bold></highlight> acquires information regarding the currently set zooming position (set picture angle) from the lens barrel control device <highlight><bold>64</bold></highlight>, and judges whether the currently set zooming position is toward the telephoto angle side or toward the wide-angle side with respect to the prescribed zooming position (step S<highlight><bold>102</bold></highlight>). If it is judged to be toward the telephoto angle side, the CPU <highlight><bold>60</bold></highlight> instructs the IC <highlight><bold>99</bold></highlight> of the subject position determining device <highlight><bold>74</bold></highlight> to set the peak selection region to the above-described region (<highlight><bold>1</bold></highlight>) (see <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(B)), namely the three &ldquo;center right, center and center left&rdquo; areas, and sets the sensor sensitivities of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> to a high sensitivity level. Then, integral processing is caused to be started (step S<highlight><bold>104</bold></highlight>). Or if it is judged at step S<highlight><bold>102</bold></highlight> to be toward the wide-angle side, the peak selection region is set to the above-described region (<highlight><bold>2</bold></highlight>) (see <cross-reference target="DRAWINGS">FIG. 7</cross-reference>(C)), namely the five &ldquo;right, center right, center, center left and left&rdquo; areas, and sets the sensor sensitivities of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> to a high sensitivity level. Then, integral processing is caused to be started (step S<highlight><bold>106</bold></highlight>). To add, processing at steps S<highlight><bold>104</bold></highlight> and S<highlight><bold>106</bold></highlight> is integral processing to determine the relative luminance level of the subject, and this kind of processing will be hereinafter referred to as high sensitivity pre-integration. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Then the CPU <highlight><bold>60</bold></highlight> judges whether or not the integral processing has ended and, if it has, judges whether the integration took less than 2 ms or not less than 2 ms but less than 4 ms, or has not ended even in 4 ms (step S<highlight><bold>108</bold></highlight>). </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> If the integration has ended in less than 2 ms, trisected low-gain integral processing (and correlation computing) will be executed as will be described afterwards (step S<highlight><bold>110</bold></highlight>). If it has ended in not less than 2 ms but less than 4 ms, collective low-gain integral processing will be executed (step S<highlight><bold>112</bold></highlight>). If it has not ended even in 4 ms, the integration will be continued until 100 ms has passed, and if it still has not ended, pre-emission processing will be executed (step S<highlight><bold>114</bold></highlight>) after switching to collective low-gain integral processing. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> If the judgment at the above-described step S<highlight><bold>100</bold></highlight> is YES, i.e., an ultra-high level of luminance is determined, trisected low-gain integral processing will be executed (step S<highlight><bold>110</bold></highlight>) as in the case of ending in less than 2 ms. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> In the trisected low-gain integral processing at step S<highlight><bold>110</bold></highlight>, the sensor sensitivity of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> is set to a low level, the range-finding area to be used according to the zooming position is trisected, and integral processing is executed sequentially, with each divided area being used as the peak selection region. If integral processing is to be started anew, the integral already obtained by the subject position determining device <highlight><bold>74</bold></highlight> is reset (the same applies hereinafter). </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Thus, if the zooming position is toward the telephoto angle side, the range-finding areas to be used are three including the center right, center and center left range-finding areas, and these range-finding areas are trisected into the center right, center and center left areas, and integral processing is executed sequentially, with each of the range-finding areas being used as the peak selection region. More specifically, first the center area is set to be the peak selection region, and integral processing is executed. Also, on the basis of the integral thereby obtained for each cell within the center area, correlation computing is performed in the center area. Then, the center left area is set to be the peak selection region, and integral processing is executed. As in the foregoing case, correlation computing is performed in the center left area on the basis of the integral obtained for each cell within the center left area. Then, the center right area is set to be the peak selection region, and integral processing is executed. As in the foregoing case, correlation computing is performed in the center right area on the basis of the integral obtained for each cell within the center right area. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> On the other hand, if the zooming position is toward the wide-angle side, the range-finding areas to be used are five including the right, center right, center, center left and left range-finding areas, and these range-finding areas are trisected into the &ldquo;right and center right&rdquo;, center and &ldquo;center left and left&rdquo; areas, and integral processing is executed sequentially, with each area being used as the peak selection region. First, the center area is set to be the peak selection region, and integral processing is executed. Then, as in the foregoing case, correlation computing is performed in the center area on the basis of the integral obtained for each cell within the center area. Next, the &ldquo;center left and left&rdquo; areas are set to be the peak selection region, and integral processing is executed. In this case, with the left area and the center left area being treated as separate areas, correlation computing is performed in the left area and the center left area on the basis of the integral obtained for each cell within the left area and the center left area. Next, the &ldquo;center right and right&rdquo; areas are set to be the peak selection region, and integral processing is executed. Then as in the foregoing case, the right area and the center right area being treated as separate range-finding areas, correlation computing is performed in the right area and the center right area on the basis of the integral obtained for each cell within the right area and the center right area. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> In the collective low-gain integral processing at step S<highlight><bold>112</bold></highlight>, the sensor sensitivity of the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> is set to a low level, and integral processing is executed, with the same area as the range-finding area to be used being assigned as the peak selection region. Thus if the zooming position is toward the telephoto angle side, the range-finding areas to be used are three including the center right, center and center left range-finding areas, and integral processing is executed, with the &ldquo;center right, center and center left&rdquo; range-finding areas are put together being used as the peak selection region. If the zooming position is toward the wide-angle side, the range-finding areas to be used are five including the right, center right, center, center left and left areas, and integral processing is executed, with the &ldquo;right, center right, center, center left and left&rdquo; area into which these range-finding areas are put together being used as the peak selection region. When the integral for each cell in the peak selection region is acquired by step S<highlight><bold>112</bold></highlight>, correlation computing is performed for each range-finding area (step S<highlight><bold>116</bold></highlight>). </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> Pre-emission processing at step <highlight><bold>114</bold></highlight> is processing to execute integral processing with an auxiliary light being emitted from an electric flash (light emitting device <highlight><bold>16</bold></highlight>). Its details will be described afterwards. When the integral for each cell in the peak selection region is acquired by the pre-emission processing, correlation computing is performed for each range-finding area (step S<highlight><bold>116</bold></highlight>). </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Having acquired the correlation by correlation computing for each range-finding area as described so far, the CPU <highlight><bold>60</bold></highlight> determines the lag amount between the sensor images of the R sensor <highlight><bold>94</bold></highlight> and of the L sensor <highlight><bold>96</bold></highlight>, and computes the subject distance for each range-finding area (step S<highlight><bold>118</bold></highlight>). To add, the distances from the R sensor <highlight><bold>94</bold></highlight> and the L sensor <highlight><bold>96</bold></highlight> to the film surface within the camera <highlight><bold>10</bold></highlight> are also taken into account in figuring out the subject distance, and the distance from the film surface to the subject (the subject distance) is figured out. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> Next, the CPU <highlight><bold>60</bold></highlight> performs processing to select the subject distance which is judged to be the most appropriate out of the plurality of subject distances acquired for each range-finding area (step S<highlight><bold>120</bold></highlight>). Usually, it selects the shortest subject distance among the plurality of subject distances. However, in view of the circumstance that a subject not intended by the user may often be present at an extremely short distance, the selection may flexibly respond to different conditions of the subject <highlight><bold>90</bold></highlight> where only one area is at an extremely short distance and all other subject distances are medium or longer by, for instance, selecting the shortest subject distance elsewhere than the extremely short distance instead of selecting the extremely short subject distance. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> Upon completion of step S<highlight><bold>120</bold></highlight>, the CPU <highlight><bold>60</bold></highlight> ends the processing routine of the AF range finding. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> After this, the CPU <highlight><bold>60</bold></highlight> supplies the lens barrel control device <highlight><bold>64</bold></highlight> with information for setting the focusing position of the zoom lens barrel <highlight><bold>12</bold></highlight> to the subject distance selected at the above-described S<highlight><bold>120</bold></highlight>. Upon completion of the setting of the focusing position, the CPU <highlight><bold>60</bold></highlight> notifies the user by displaying on the display device <highlight><bold>38</bold></highlight> or elsewhere information that the setting of the focusing position has ended. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> When the user fully presses the shutter release button <highlight><bold>34</bold></highlight> to instruct shooting, the CPU <highlight><bold>60</bold></highlight> acquires from the input device <highlight><bold>86</bold></highlight> an SP<highlight><bold>2</bold></highlight> ON signal indicating that the shutter release button <highlight><bold>34</bold></highlight> has been fully pressed. Having acquired the SP<highlight><bold>2</bold></highlight> signal, the CPU <highlight><bold>60</bold></highlight> performs processing to set the lens aperture and the shutter speed on the basis of the subject brightness measured by the photometric device <highlight><bold>70</bold></highlight> and the shooting mode set in the camera <highlight><bold>10</bold></highlight>. It then gives an instruction to open and close the shutter to the shutter control device <highlight><bold>68</bold></highlight> and, if the result of measurement by the photometric device <highlight><bold>70</bold></highlight> indicates necessity, an instruction to emit an auxiliary light to the light emission control device <highlight><bold>72</bold></highlight>. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a circuit diagram showing the configuration of an electric flash circuit in the light emission control device <highlight><bold>72</bold></highlight>. As shown in this diagram, the electric flash circuit comprises a xenon gas-enclosed discharge tube <highlight><bold>100</bold></highlight>, a trigger circuit <highlight><bold>102</bold></highlight> for applying a high voltage to the trigger electrode of the discharge tube <highlight><bold>100</bold></highlight> to excite the xenon gas within the discharge tube <highlight><bold>100</bold></highlight> and thereby to reduce the resistance within the discharge tube <highlight><bold>100</bold></highlight>, a main capacitor MC for accumulating electric charges which causes the discharge tube <highlight><bold>100</bold></highlight> to emit light and discharges its charges to the discharge tube <highlight><bold>100</bold></highlight>, and a transformer T which boosts the voltage of a battery E and causes the main capacitor MC and the triggering capacitor in the trigger circuit <highlight><bold>102</bold></highlight> to accumulate charges at a high voltage. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> To the primary side of the transformer T where the battery E is connected is connected a switch circuit <highlight><bold>104</bold></highlight> comprising a transistor Tr<highlight><bold>1</bold></highlight> and resistors R<highlight><bold>1</bold></highlight> and R<highlight><bold>2</bold></highlight>. When a pulse string signal is given to this switch circuit <highlight><bold>104</bold></highlight> from the CPU <highlight><bold>60</bold></highlight> via an FCP signal line, the transistor Tr<highlight><bold>1</bold></highlight> of the switch circuit <highlight><bold>104</bold></highlight> repeats coming on and off, and an alternating current is generated on the primary side of the transformer T. This induces an alternating current of a high voltage on the secondary side of the transformer T. The A.C. voltage induced on the secondary side of the transformer T is rectified by a diode D, and the rectified voltage is applied to the main capacitor MC and the triggering capacitor in the trigger circuit <highlight><bold>102</bold></highlight>. Therefore, when a pulse train signal is provided from the FCP signal line, the main capacitor MC and the triggering capacitor are charged. If the CPU <highlight><bold>60</bold></highlight> stops supplying the pulse train signal to the FCP signal line, the charging is stopped. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> To the main capacitor MC is connected a charge completion detecting circuit <highlight><bold>106</bold></highlight> comprising a Zener diode ZD, a transistor Tr<highlight><bold>2</bold></highlight>, a capacitor C, and resistors R<highlight><bold>3</bold></highlight> and R<highlight><bold>4</bold></highlight> in parallel. The Zener diode ZD has a characteristic that an avalanche current flows in it when a voltage over 300 V (Zener voltage) is applied to it in the inverse direction. When the charge voltage to the main capacitor MC reaches the Zener voltage, a current flows to resistors R<highlight><bold>3</bold></highlight> and R<highlight><bold>4</bold></highlight> of the charge completion detecting circuit <highlight><bold>106</bold></highlight>. This causes a transistor Tr<highlight><bold>2</bold></highlight> to be turned on and reduces the FR signal line to an L level. On the other hand, when the charge voltage to the main capacitor MC has not reached the Zener voltage, the transistor Tr<highlight><bold>2</bold></highlight> is off and the FR signal line is at an H level. Therefore, the CPU <highlight><bold>60</bold></highlight> can know by the voltage of the FR signal line whether or not the charging of the main capacitor MC has been completed. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> Into the trigger circuit <highlight><bold>102</bold></highlight> is entered a pulse signal from the CPU <highlight><bold>60</bold></highlight> via the FT signal line. When the pulse signal is entered from the FT signal line, the trigger circuit <highlight><bold>102</bold></highlight> applies a high voltage to the trigger electrode of the discharge tube <highlight><bold>100</bold></highlight> to reduce the resistance in the discharge tube <highlight><bold>100</bold></highlight> and thereby makes possible discharging from the main capacitor MC to the discharge tube <highlight><bold>100</bold></highlight>. Further to the discharge tube <highlight><bold>100</bold></highlight> is connected a switch circuit <highlight><bold>108</bold></highlight> comprising a transistor (insulated gate type bipolar transistor) IGBT and a resistor R<highlight><bold>5</bold></highlight>, and the same pulse signal as that for the aforementioned trigger circuit <highlight><bold>102</bold></highlight> is entered into this switch circuit <highlight><bold>108</bold></highlight> via the FT signal line. When the pulse signal is entered via the FT signal line, the transistor IGBT is turned on at the H level of that pulse signal and the transistor IGBT is turned off at its L level. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> Therefore, the discharge tube <highlight><bold>100</bold></highlight> emits light only during the period equal to the pulse width of the pulse signal which the CPU <highlight><bold>60</bold></highlight> applies to the trigger circuit <highlight><bold>102</bold></highlight> and the switch circuit <highlight><bold>108</bold></highlight> via the FT signal line. Thus, the pulse width is equal to the duration of light emission by the discharge tube <highlight><bold>100</bold></highlight>. To add, in the pre-emission for range finding, a pulse signal of 8 to 28 &mgr;s per time of emission is entered from the FT signal line, and a pulse signal of 5 ms (though the actual duration of light emission is only about 1 ms) is entered during a real emission (full emission for usual shooting) synchronized with a shutter release. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> Pre-emission processing by the CPU <highlight><bold>60</bold></highlight> at step S<highlight><bold>114</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> will be described below in detail with reference to a flow chart in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. After high sensitivity pre-integration processing is started at step S<highlight><bold>104</bold></highlight> or step S<highlight><bold>106</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, if the processing is judged not to have ended at step S<highlight><bold>108</bold></highlight> even after the lapse of 4 ms in the duration of integration, the CPU <highlight><bold>60</bold></highlight> will shift to pre-emission processing shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. First, while allowing that integral processing to continue, the CPU <highlight><bold>60</bold></highlight> judges in which of the light emission forbidding mode, the night scene portrait mode or any other mode (the auto mode, the red eye alleviating mode or the forced light emitting mode) the shooting mode is set (step S<highlight><bold>130</bold></highlight>). If it is judged to be set in the light emission forbidding mode, the CPU <highlight><bold>60</bold></highlight> judges whether or not integration has been ended (step S<highlight><bold>132</bold></highlight>). If the judgment is NO here, then the CPU <highlight><bold>60</bold></highlight> judges whether or not the duration of integration has reached or surpassed 200 ms (step S<highlight><bold>1134</bold></highlight>). If the judgment is again NO, the process returns to the above-described step S<highlight><bold>132</bold></highlight>. As long as the judgment is NO at both step S<highlight><bold>132</bold></highlight> and step S<highlight><bold>134</bold></highlight>, these procedures of judgment are repeated. If the judgment turns YES at step S<highlight><bold>132</bold></highlight>, i.e., the integration has ended before the its duration reaches 200 ms, the integral of each cell is acquired, and this pre-emission processing is ended without actually executing pre-emission. On the other hand, if the judgment at step S<highlight><bold>134</bold></highlight> is YES, i.e., the duration of integration has reached 200 ms without completion, the integration is forcibly suspended (step S<highlight><bold>136</bold></highlight>), and the integral of each cell at the time is acquired to end this pre-emission processing without actually executing pre-emission. Thus, when the shooting mode is set in the light emission forbidding mode, the integration is continued for a duration of no more than 200 ms, and even if it fails to end within this length of time (i.e., if range finding seems difficult), processing at and after step S<highlight><bold>116</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is executed without performing pre-emission. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> If at the above-described step S<highlight><bold>130</bold></highlight> it is judged that the shooting mode is in the night scene portrait mode, then it is judged whether or not integration has ended (step S<highlight><bold>138</bold></highlight>). If the judgment is NO here, next it is judged whether or not the duration of integration has reached or surpassed 25 ms (step S<highlight><bold>140</bold></highlight>), if the judgment is again NO, the process returns to the above-described step S<highlight><bold>138</bold></highlight>. As long as the judgment is NO at both step S<highlight><bold>138</bold></highlight> and step S<highlight><bold>140</bold></highlight>, these procedures of judgment are repeated. If the judgment turns YES at step S<highlight><bold>138</bold></highlight>, i.e., the integration has ended before the its duration reaches 25 ms, the integral of each cell is acquired, and this pre-emission processing is ended without actually executing pre-emission, followed by the processing at step S<highlight><bold>116</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. On the other hand, if the judgment at step S<highlight><bold>140</bold></highlight> is YES, i.e., the duration of integration has reached 25 ms without completion, the integration is forcibly suspended (step S<highlight><bold>146</bold></highlight>), followed by a shift to step S<highlight><bold>148</bold></highlight> for processing pre-emission. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> If at the above-described step S<highlight><bold>130</bold></highlight> it is judged that the shooting mode is in any other mode than the light emission forbidding mode and the night scene portrait mode, i.e., in the auto mode, the red eye alleviating mode and the forced light emitting mode in the present embodiment, then the CPU <highlight><bold>60</bold></highlight> judges whether or not the integration had ended (step S<highlight><bold>142</bold></highlight>). If the judgment is NO here, the CPU <highlight><bold>60</bold></highlight> judges whether or not the duration of integration has reached or surpassed <highlight><bold>100</bold></highlight> ms (step S<highlight><bold>144</bold></highlight>). If the judgment is NO again, the process returns to the above-described step S<highlight><bold>142</bold></highlight>. As long as the judgment is NO at both step S<highlight><bold>142</bold></highlight> and step S<highlight><bold>144</bold></highlight>, these procedures of judgment are repeated. If the judgment turns YES at step S<highlight><bold>142</bold></highlight>, i.e., the integration has ended before the its duration reaches 100 ms, the integral of each cell is acquired, and this pre-emission processing is ended without actually executing pre-emission, followed by the processing at step S<highlight><bold>116</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. On the other hand, if the judgment at step S<highlight><bold>144</bold></highlight> is YES, i.e., the duration of integration has reached 100 ms without completion, the integration is forcibly suspended (step S<highlight><bold>146</bold></highlight>), followed by a shift to step S<highlight><bold>148</bold></highlight> for processing pre-emission by the light emitting device <highlight><bold>16</bold></highlight>. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> Since in the night scene portrait mode it is judged whether or not integral processing has ended after the lapse of a shorter period of time than in any other mode than the light emission forbidding mode and the night scene portrait mode, i.e., 25 ms as opposed to 100 ms (step S<highlight><bold>140</bold></highlight>), pre-emission is performed in a brighter condition than in other modes. This prevents the trouble that pre-emission is not performed on account of the brightness of the background, and that of focusing on anything in the background is also prevented. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> Suspending the integration at the above-described step S<highlight><bold>146</bold></highlight> and shifting to step S<highlight><bold>148</bold></highlight>, next the CPU <highlight><bold>60</bold></highlight> instructs the IC <highlight><bold>99</bold></highlight> of the subject position determining device <highlight><bold>74</bold></highlight> to set the sensor sensitivity of the R sensor <highlight><bold>94</bold></highlight> and of the L sensor <highlight><bold>96</bold></highlight> to a low level, and causes integration to start in the full peak selection range (step S<highlight><bold>150</bold></highlight>). It then the CPU <highlight><bold>60</bold></highlight> instructs the light emission control device <highlight><bold>72</bold></highlight> to start pre-emission (step S<highlight><bold>152</bold></highlight>). Thus, it applies a pulse signal to the FT signal line of the electric flash circuit shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference> to cause the discharge tube <highlight><bold>100</bold></highlight> to emit light. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Pre-emission is intermittently repeated in a prescribed duration (width of emission) and at prescribed intervals until the conditions for completion in the following judgment processing are satisfied. Details of the duration and intervals of light emission will be described afterwards. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> As an ending condition for pre-emission, the CPU <highlight><bold>60</bold></highlight> first judges whether or not the integration has ended (step S<highlight><bold>154</bold></highlight>). If the judgment is YES, pre-emission is ended (step S<highlight><bold>162</bold></highlight>), and the integral of each cell is acquired to end this pre-emission processing, followed by the processing at step S<highlight><bold>116</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. Or if the judgment is NO, then the CPU <highlight><bold>60</bold></highlight> judges whether or not the number of times of pre-emission has reached a predetermined maximum number of times (four times for instance) (step S<highlight><bold>156</bold></highlight>). If the judgment is YES, the integration is forcibly ended even if it is not completed (step S<highlight><bold>160</bold></highlight>) to end pre-emission (step S<highlight><bold>162</bold></highlight>). The CPU <highlight><bold>60</bold></highlight> acquires the integral of each cell at that point of time to end this pre-emission, and a shift to step S<highlight><bold>116</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> takes place. If at step S<highlight><bold>156</bold></highlight> the judgment is NO, the process returns to the above-described step S<highlight><bold>154</bold></highlight>, and pre-emission is continued, with the foregoing judgment processing repeated until any of the above-stated ending conditions is met. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> The sequence of pre-emission processing so far described will now be described with reference to FIGS. <highlight><bold>11</bold></highlight>(A) to <highlight><bold>11</bold></highlight>(E). Description of the case in which the shooting mode is the light emission forbidding mode will be dispensed with. After starting high sensitivity preintegration by half-pressing the shutter release button <highlight><bold>34</bold></highlight>, when integral processing is ended in less than 100 ms as shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>(A) (in less than 25 ms in the night scene portrait mode), without performing pre-emission, correlation computing is performed using the integrals thereby obtained, and the subject distance is calculated. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> On the other hand, if after the half pressing of the shutter release button <highlight><bold>34</bold></highlight>, high sensitivity pre-integration does not end in less the applicable one of the aforementioned durations as shown in FIGS. <highlight><bold>11</bold></highlight>(B) to <highlight><bold>11</bold></highlight>(E), the sensor sensitivity of the R sensor <highlight><bold>94</bold></highlight> and of the L sensor <highlight><bold>96</bold></highlight> is altered to a low level, and integral processing is started again. Then, after the lapse of 5 ms, the first pre-emission is performed. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> Here in this first pre-emission, the CPU <highlight><bold>60</bold></highlight> shortens the duration of light emission (emission width) so that the luminous energy of emission is smaller than the second or any subsequent pre-emission. If, for instance, the duration of the second or subsequent pre-emission is 28 &mgr;s, the duration of the first pre-emission is 16 &mgr;s. This prevents the trouble of sensor output saturation or the like even if, for instance, the subject is extremely close. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> Further, in view of the fact that the higher the temperature the greater the amount of light emission if the duration of light emission is fixed on account of the temperature characteristic (tangent delta characteristic) of the main capacitor MC, the CPU <highlight><bold>60</bold></highlight> alters the duration of light emission in the first pre-emission according to the ambient temperature (the temperature within the camera). Thus, the higher the ambient temperature is, the shorter the duration of light emission is. Incidentally, a temperature sensor is built into the camera to measure the temperature within, and the CPU <highlight><bold>60</bold></highlight> can measure the temperature within the camera with this temperature sensor. <cross-reference target="DRAWINGS">FIG. 12</cross-reference> shows an example of regulating the duration of light emission in accordance with the temperature. As shown in <cross-reference target="DRAWINGS">FIG. 12</cross-reference>, the temperature range is divided into four-degree segments. The duration is set to 16 &mgr;s up to 26 degrees Celsius, 14 &mgr;s between 26 and 34 degrees Celsius, 12 &mgr;s between 34 and 42 degrees Celsius, 10 &mgr;s between 42 and 50 degrees Celsius, and 8 &mgr;s beyond 50 degrees Celsius. This makes the luminous energy emitted from the electric flash substantially constant irrespective of the temperature as shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> When this first pre-emission brings the integral of any cell within the peak selection region to the end-of-integration value as shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>(B), pre-emission is ended. On the other hand, if the integral does not reach the end-of-integration value as shown in FIGS. <highlight><bold>11</bold></highlight>(C) to <highlight><bold>11</bold></highlight>(E), the lapse of a light emission interval of 25 ms is awaited after the first pre-emission. If the integral reaches the end-of-integration value during this period, the integration is ended. If the integral fails to reach the end-of-integration value in 25 ms after the first pre-emission, the second pre-emission is performed. The second pre-emission is greater in the amount of light emission than the first, and the duration of emission is 28 &mgr;s. If this second pre-emission brings the integral to the end-of-integration value as shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>(C), pre-emission is ended. On the other hand, if the integral does not reach the end-of-integration value as shown in FIGS. <highlight><bold>11</bold></highlight>(D) to <highlight><bold>11</bold></highlight>(E), pre-emission of 28 &mgr;s in duration will be repeated after the lapse of 25 ms as in the second pre-emission until the integral reaches the end-of-integration value. However, if pre-emission reaches the predetermined maximum number of times, the integration is ended when pre-emission ends even if the integral has not reached the end-of-integration value. Incidentally, <cross-reference target="DRAWINGS">FIG. 11</cross-reference>(D) shows a case in which pre-emission is performed three times, and <cross-reference target="DRAWINGS">FIG. 11</cross-reference>(E), a case in which pre-emission is performed four times. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> Next will be described processing of electric flash charging (charging of the main capacitor MC) in connection with pre-emission. As shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>, when the shutter release button <highlight><bold>34</bold></highlight> is half pressed and SP<highlight><bold>1</bold></highlight> is turned ON (H level), the CPU <highlight><bold>60</bold></highlight> performs pre-emission as described above. Then, if the ending conditions of pre-emission are met and the pre-emission end, it charges the electric flash. Thus, a pulse train signal is entered from the FCP signal line shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. If the shutter release button <highlight><bold>34</bold></highlight> is fully pressed and SP<highlight><bold>2</bold></highlight> is turned ON (H level) while the electric flash is being charged, the CPU <highlight><bold>60</bold></highlight> secures a charging duration of at least 150 ms to ensure that the minimum required charge is available for the real emission at the time the shutter is released, and then stops charging the electric flash and allows the shutter to be released. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> On the other hand, if the shutter release button <highlight><bold>34</bold></highlight> is not fully pressed but half-pressing and cancellation take place consecutively, and pre-emission is performed in a state wherein the main capacitor MC is fully charged as at the time of half pressing indicated by a in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, the capacitor is charged only for 150 ms after the end of pre-emission. Thus, the charging is stopped even if the main capacitor MC is not fully charged, but the minimum required charge (permissible minimum) for the real emission (electric flash shooting) at time of releasing the shutter is secured. This can prevent the shutter release from being long delayed even if the shutter release button <highlight><bold>34</bold></highlight> is fully pressed after pre-emission, and the photographer would feel nothing awkward. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> Unlike in this case, if pre-emission is performed in a state in which the main capacitor MC is not fully charged as at the time of half pressing as represented by b in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, the capacitor is charged for 300 ms after the end of pre-emission. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> To add, if the charging after pre-emission does not fully charge the main capacitor MC, the charging is resumed when half pressing is cancelled. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a flow chart showing the procedure of charge processing by the CPU <highlight><bold>60</bold></highlight> after pre-emission. First, the CPU <highlight><bold>60</bold></highlight> judges whether or not an AF pre-emission uncharged flag is set (step S<highlight><bold>200</bold></highlight>). If it is NO, the CPU <highlight><bold>60</bold></highlight> sets the AF pre-emission uncharged flag (step S<highlight><bold>202</bold></highlight>), and keeps it set for a fixed duration (150 ms) (step S<highlight><bold>204</bold></highlight>). Then it executes electric flash charge processing (step S<highlight><bold>206</bold></highlight>). The electric flash charge processing is ended when the charging is completed or a fixed length of time has passed. If the charging is completed, the CPU <highlight><bold>60</bold></highlight> resets an AF pre-emission uncharged flag. Then it resets a fixed length of time (step S<highlight><bold>208</bold></highlight>) to end the processing shown in this flow chart. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> On the other hand, if the judgment is YES at step the above-described S<highlight><bold>200</bold></highlight>, it is kept set for a fixed length of time (300 ms) (step S<highlight><bold>210</bold></highlight>). Then, electric flash charge processing is executed (step S<highlight><bold>212</bold></highlight>). As described above, the electric flash charge processing is ended when the charging is completed or the fixed length of time has passed. If the charging is completed, the CPU <highlight><bold>60</bold></highlight> resets the AF pre-emission uncharged flag. Then it resets the fixed length of time (step S<highlight><bold>214</bold></highlight>), and accepts an SP<highlight><bold>1</bold></highlight> OFF signal (step S<highlight><bold>216</bold></highlight>). If electric flash charging has not ended, electric flash charge processing is resumed (step S<highlight><bold>218</bold></highlight>). This electric flash charge processing is ended when the charging is completed or at an SP<highlight><bold>1</bold></highlight> OFF signal. Upon completion of the processing at step S<highlight><bold>218</bold></highlight>, the whole processing shown in this flow chart ends. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> Although the foregoing description supposes that charging is performed for 300 ms whenever pre-emission is performed in a less than fully charged state (if full charging is achieved within 300 ms, the charging is ended then), it is also acceptable to alternate 300 ms charging and 150 ms charging if pre-emission is consecutively done in a less than fully charged state. Thus, supposing that the charging after pre-emission in a fully charge state is the first charge, and the subsequent charges after pre-emission are counted as the second, third and so forth, it may be acceptable to continue charging for 150 ms in any odd-number and for 300 ms in any even-numbered round. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> Next will be described processing of electric flash charging (charging of the main capacitor MC) in connection with pre-emission with reference to another embodiment of the invention (a second embodiment). </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a circuit diagram showing the configuration of an electric flash circuit in the second embodiment of the invention. Circuit elements either the same as or similar to their respective counterparts in the electric flash circuit shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference> are assigned respectively the same reference signs as in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, and their description is dispensed with. In the electric flash circuit shown in <cross-reference target="DRAWINGS">FIG. 17</cross-reference>, in place of the charge completion detecting circuit <highlight><bold>106</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, there is provided a charging voltage detecting circuit <highlight><bold>202</bold></highlight> configured by resistors R<highlight><bold>10</bold></highlight> and R<highlight><bold>12</bold></highlight> and an A/D converter <highlight><bold>200</bold></highlight> connected in parallel to the main capacitor MC. This charging voltage detecting circuit <highlight><bold>202</bold></highlight> is intended for detecting the charge voltage of the main capacitor MC. The charge voltage of the main capacitor MC is divided by the resistors R<highlight><bold>10</bold></highlight> and R<highlight><bold>12</bold></highlight> into voltages readable by the CPU <highlight><bold>60</bold></highlight>, and the divided voltages are converted by the A/D converter <highlight><bold>200</bold></highlight> into digital signals, which are provided to the CPU <highlight><bold>60</bold></highlight>. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> Next will be described the processing of electric flash charging in connection with pre-emission in the second embodiment of the invention. As stated above, the CPU <highlight><bold>60</bold></highlight> performs pre-emission when SP<highlight><bold>1</bold></highlight> is turned ON and, if the ending conditions of pre-emission are met and the pre-emission ends, it charges the electric flash. Thus, a pulse train signal is entered from the FCP signal line shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. If the shutter release button <highlight><bold>34</bold></highlight> is fully pressed and SP<highlight><bold>2</bold></highlight> is turned ON while the electric flash is being charged, the CPU <highlight><bold>60</bold></highlight>, after charging the electric flash to the minimum required charge (charging voltage) for the real emission at the time the shutter is released, then stops charging the electric flash and allows the shutter to be released. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> On the other hand, if the shutter release button <highlight><bold>34</bold></highlight> is not fully pressed but half pressing and cancellation take place consecutively, and pre-emission is performed in a state wherein the main capacitor MC is fully charged as at the time of half pressing indicated by a in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, the capacitor is charged until the A/D value obtained from the A/D converter <highlight><bold>200</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 17</cross-reference> comes to a voltage that indicates that the charging voltage of the main capacitor MC has reached, for instance, 270 V. Thus, even if the main capacitor MC is not fully charged, the charging is stopped after securing the minimum required charge (permissible minimum) for the real emission (electric flash shooting) at the time of releasing the shutter. This can prevent the shutter release from being long delayed even if the shutter release button <highlight><bold>34</bold></highlight> is fully pressed after pre-emission, and the photographer would feel nothing awkward. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> Unlike in this case, if pre-emission is performed in a state in which the main capacitor MC is not fully charged as at the time of half pressing as represented by b in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, the capacitor is charged until the A/D value obtained from the A/D converter <highlight><bold>200</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 17</cross-reference> comes to a voltage that indicates that the charging voltage of the main capacitor MC has reached a state of full charging (for instance 300 V). </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> To add, if the charging after pre-emission after the state of full charging does not fully charge the main capacitor MC, the charging is resumed when half pressing is cancelled. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a flow chart showing the procedure of charge processing by the CPU <highlight><bold>60</bold></highlight> after pre-emission in the second embodiment of the invention. First, the CPU <highlight><bold>60</bold></highlight> judges whether or not an AF pre-emission uncharged flag is set (step S<highlight><bold>300</bold></highlight>). If it is not, the CPU <highlight><bold>60</bold></highlight> sets the AF pre-emission uncharged flag (step S<highlight><bold>302</bold></highlight>), and sets a charge end voltage of 270 V (step S<highlight><bold>304</bold></highlight>). Then it executes electric flash charge processing (step S<highlight><bold>306</bold></highlight>). The electric flash charge processing is ended when the main capacitor MC reaches the charge end voltage of 270 V. Then it resets the charge end voltage (step S<highlight><bold>308</bold></highlight>) to end the processing shown in this flow chart. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> On the other hand, if the flag is found set at step S<highlight><bold>300</bold></highlight> above, a charge end voltage of 300 V is set (step S<highlight><bold>310</bold></highlight>). Then, electric flash charge processing is executed (step S<highlight><bold>312</bold></highlight>). This electric flash charge processing is ended when the main capacitor MC reaches the charge end voltage of 300 V. Or if the charging is completed, the CPU <highlight><bold>60</bold></highlight> resets the AF pre-emission uncharged flag. Then it resets the charge end voltage (step S<highlight><bold>314</bold></highlight>), and accepts an SP<highlight><bold>1</bold></highlight> OFF signal (step S<highlight><bold>316</bold></highlight>). Upon completion of the processing at step S<highlight><bold>316</bold></highlight>, the whole processing shown in this flow chart ends. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> Though the above-described embodiments concern a camera using a silver halide film, the invention is not limited to this, but can as well be effectively applied to cameras which record images on other kinds of recording medium, including a digital camera. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> Furthermore, though the above-described embodiments refer to the use of a pair of line sensors for passive auto-focusing and assessing the subject distance from the amount of lag between the subject images of each sensor, the invention is not limited to this, but it is also applicable to a camera which carries out auto-focusing control by the so-called contrast method. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> As hitherto described, in this camera according to the present invention, since the main capacitor is not always fully charged after an auxiliary light for auto-focusing use is emitted by half pressing the shutter release button, but it is charged only for a limited length of time or a limited charging voltage, the operating convenience can be prevented from being deteriorated by charging. Also, by setting that duration of charging to a required length of time or a required charging voltage for charging the main capacitor to a permissible minimum level to make possible electric flash shooting, impossibility of electric flash shooting due to insufficient charging can be reliably prevented. Furthermore, by differentiating the length of time for charging according to whether or not the main capacitor is fully charged before auxiliary light emission, a more satisfactory performance can be achieved. Thus, since the remaining capacitance of the capacitor presumably is smaller after auxiliary light emission in a state in which it is not fully charged than after auxiliary light emission in a fully charged state, rational charging can be processed by charging the capacitor for a shorter period of time in the former case than in the latter case. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> It should be understood, however, that there is no intention to limit the invention to the specific forms disclosed, but on the contrary, the invention is to cover all modifications, alternate constructions and equivalents falling within the spirit and scope of the invention as expressed in the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A camera, comprising: 
<claim-text>a sensor having a plurality of light receiving elements which receive light from a subject in a range-finding area; </claim-text>
<claim-text>an auto-focusing controller which performs auto-focusing control according to an output of the sensor; </claim-text>
<claim-text>a charging device which charges a main capacitor; </claim-text>
<claim-text>a light emitting device which is supplied with electric energy by the main capacitor and emits auxiliary light for auto-focusing use and auxiliary light for exposure use to the subject; </claim-text>
<claim-text>a shutter release button which, when half pressed, causes auto-focusing control to be started according to the output of the sensor and, when fully pressed, causes shooting to be started; </claim-text>
<claim-text>a light emission control device which causes the light emitting device to emit the auxiliary light for auto-focusing use when the shutter release button is half pressed and a desired output value is not obtained from the sensor; and </claim-text>
<claim-text>a control device which, the auxiliary light for auto-focusing use emitted from the light emitting device in a state where the main capacitor is fully charged being supposed to be a first auxiliary light and the auxiliary light for auto-focusing use later emitted from the light emitting device when the shutter release button is half pressed again in a state where the main capacitor is not fully charged being supposed to be a second auxiliary light, following the emission of the first auxiliary light from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device as long as a first length of time and, following the emission of the second auxiliary light from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device as long as a second length of time longer than the first length of time. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The camera as set forth in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the first length of time is a length of time required for enabling the charging device to charge the main capacitor to a permissible minimum level to make possible electric flash shooting. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The camera as set forth in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the control device, following the emission of the auxiliary light of an odd-numbered round from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device as long as the first length of time and, following the emission of the auxiliary light of an even-numbered round from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device as long as the second length of time. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The camera as set forth in <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein the first length of time is a length of time required for enabling the charging device to charge the main capacitor to a permissible minimum level to make possible electric flash shooting. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A camera, comprising: 
<claim-text>a sensor having a plurality of light receiving elements which receive light from a subject in a range-finding area; </claim-text>
<claim-text>an auto-focusing controller which performs auto-focusing control according to an output of the sensor; </claim-text>
<claim-text>a charging device which charges a main capacitor; </claim-text>
<claim-text>a light emitting device which is supplied with electric energy by the main capacitor and emits auxiliary light for auto-focusing use and auxiliary light for exposure use to the subject; </claim-text>
<claim-text>a shutter release button which, when half pressed, causes auto-focusing control to be started according to the output of the sensor and, when fully pressed, causes shooting to be started; </claim-text>
<claim-text>a light emission control device which causes the light emitting device to emit the auxiliary light for auto-focusing use when the shutter release button is half pressed and a desired output value is not obtained from the sensor; and </claim-text>
<claim-text>a control device which, the auxiliary light for auto-focusing use emitted from the light emitting device in a state where the main capacitor is fully charged being supposed to be a first auxiliary light and the auxiliary light for auto-focusing use later emitted from the light emitting device when the shutter release button is half pressed again in a state where the main capacitor is not fully charged being supposed to be a second auxiliary light, following the emission of the first auxiliary light from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device to a permissible minimum level to make possible electric flash shooting and, following the emission of the second auxiliary light from the light emitting device, permits electric flash shooting by fully pressing the shutter release button after the charging of the main capacitor by the charging device to a fully charged level.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>3</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001961A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001961A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001961A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001961A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001961A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001961A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001961A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001961A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001961A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001961A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001961A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030001961A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030001961A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030001961A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030001961A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030001961A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030001961A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030001961A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030001961A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
