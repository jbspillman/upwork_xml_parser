<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004701A1-20030102-D00000.TIF SYSTEM "US20030004701A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00001.TIF SYSTEM "US20030004701A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00002.TIF SYSTEM "US20030004701A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00003.TIF SYSTEM "US20030004701A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00004.TIF SYSTEM "US20030004701A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00005.TIF SYSTEM "US20030004701A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00006.TIF SYSTEM "US20030004701A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00007.TIF SYSTEM "US20030004701A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00008.TIF SYSTEM "US20030004701A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00009.TIF SYSTEM "US20030004701A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00010.TIF SYSTEM "US20030004701A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00011.TIF SYSTEM "US20030004701A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00012.TIF SYSTEM "US20030004701A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00013.TIF SYSTEM "US20030004701A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030004701A1-20030102-D00014.TIF SYSTEM "US20030004701A1-20030102-D00014.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004701</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10179734</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020624</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2001-198879</doc-number>
</priority-application-number>
<filing-date>20010629</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G10H001/40</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>704</class>
<subclass>001000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>084</class>
<subclass>636000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Automatic performing apparatus and electronic instrument</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Noriyuki</given-name>
<family-name>Ueta</family-name>
</name>
<residence>
<residence-non-us>
<city>Hamamatsu-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Hideyuki</given-name>
<family-name>Tanaka</family-name>
</name>
<residence>
<residence-non-us>
<city>Hamamatsu-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Akira</given-name>
<family-name>Kawai</family-name>
</name>
<residence>
<residence-non-us>
<city>Hamamatsu-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>DAVIS &amp; BUJOLD, P.L.L.C.</name-1>
<name-2></name-2>
<address>
<address-1>500 NORTH COMMERCIAL STREET</address-1>
<address-2>FOURTH FLOOR</address-2>
<city>MANCHESTER</city>
<state>NH</state>
<postalcode>03101</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">An automatic performing apparatus and an electronic instrument with which a user can carry out an automatic musical performance, even for a complicated arrangement, simply by providing external events at certain intervals or corresponding only to a melody. In such an electronic instrument, at the time of execution of the automatic musical performance, the keyboard events are provided at intervals of one beat. Then, the automatic musical performance is progressed within a certain section corresponding to each of the provided keyboard events. Otherwise, at the time of execution of the automatic musical performance, the keyboard events are provided at the timing of a melody. Then, musical tones for the corresponding melody are generated, while those for accompaniments following the melody are also automatically generated. Furthermore, the tempo of the automatic musical performance is set on the basis of intervals between the keyboard events. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">FIELD OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The present invention relates to an automatic performing apparatus and an electronic instrument capable of executing an automatic musical performance by generating musical tones in accordance with external events. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Conventionally, an electronic instrument has been used which is capable of executing an automatic musical performance by sequentially reading out song data, which are previously stored in a memory, and generating musical tones in response to events from the outside (for example, the action of pressing on keys of a keyboard). </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> By using such an electronic instrument, an automatic musical performance can be carried out only by providing simple external events. Accordingly, anyone can enjoy playing this musical instrument without learning how to play it. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> More particularly, such an electronic instrument can provide children with an opportunity to get familiar with music. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Furthermore, the aged and the physically handicapped, who will often have difficulty in learning to play a musical instrument, are also able to enjoy playing a musical instrument by means of such an electronic instrument. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> However, in conventional electronic instruments, only one musical tone (or sound) is generated in response to one external event. Therefore, in order to achieve an automatic musical performance, it is necessary for a user to provide external events for all pieces of note data (that is, data relating to generation of musical tones among the song data stored in the memory). </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Consequently, it has been sometimes difficult for a user to carry out an automatic musical performance with such a conventional electronic instrument, especially in the case of a complicated arrangement, in which case it is difficult to properly provide external events. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Also, in the case of a song consisting of a melody and accompaniments, if external events are provided only at the timing of the melody, musical tones for the accompaniments are not generated since they do not accord with each other in timing, which has been another problem with the conventional electronic instrument. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> The present invention was made to solve the aforementioned problems. More particularly, the object of the present invention is to provide an automatic performing apparatus and an electronic instrument with which a user can achieve an automatic musical performance without difficulty only by providing external events, for example, at certain intervals, or correspondingly only to a melody, even in the case of a complicated arrangement. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> In order to attain this object, there is provided an automatic performing apparatus for executing an automatic musical performance based on song data in response to external events, wherein the song data are segmented into prescribed sections; at the time of execution of an automatic musical performance, each time an external event is provided, the automatic musical performance progresses within a section corresponding to the external event provided; and tempo of the automatic musical performance is set on the basis of intervals between the external events. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> In this automatic performing apparatus, the song data are segmented into the prescribed sections, and at the time of execution of an automatic musical performance, the automatic musical performance is executed by the section in response to each external event. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> Accordingly, it is not necessary for a user to provide the external events with respect to all pieces of note data, and instead, it is only necessary for him/her to provide an external event, for example, with respect to each section of the song data, which enables the user to carry out an automatic musical performance more easily. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Particularly, in the case of a section comprising two or more pieces of note data, musical tones can be automatically generated based on the two or more pieces of note data in response to only one external event. Accordingly, compared to cases where the external events need to be provided with respect to all pieces of note data, the number of provision of such external events can be reduced. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Also, in the automatic performing apparatus of the invention, the tempo of the automatic musical performance is set on the basis of intervals between the external events. In other words, when the external events are provided with a short interval, the automatic musical performance is executed at a fast tempo. On the contrary, when the external events are provided with a long interval, the automatic musical performance is executed at a slow tempo. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> Consequently, the tempo of the automatic musical performance can be freely changed by varying the intervals between the external events. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Furthermore, due to such changes in the tempo of the automatic musical performance depending on the intervals between the external events, undesired situations, for example, in which the next external event is provided before completion of generation of musical tones based on all pieces of note data within a certain section or, on the contrary, in which there is an unnatural pause inserted between completion of generation of musical tones based on all pieces of note data within a certain section and provision of the next external event, are less likely to occur compared to cases where the automatic musical performance is progressed at a fixed tempo. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> Here, the note data mean some information, for example, that is part of the song data and gives the automatic performing apparatus instructions to generate musical tones. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> In the foregoing automatic performing apparatus, each of the prescribed sections may correspond to one beat of the song data. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In such an automatic performing apparatus, each section corresponding to each external event is equivalent to one beat of a song, and consequently, each time an external event is provided, the automatic musical performance is progressed by the beat. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Accordingly, by using such an automatic performing apparatus, a user can carry out an automatic musical performance only by providing external events at intervals of one beat, which is a very easy operation for the user. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Alternatively, in the foregoing automatic performing apparatus, each of the prescribed sections may comprise a piece of note data for a melody and note data for accompaniments following the piece of note data for the melody. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> In such an automatic performing apparatus, each section corresponding to each external event includes a piece of note data for a melody and note data for accompaniments following the piece of note data for the melody, and consequently, each time an external event is provided, a melody part and accompaniment parts accompanying the melody part are both automatically performed. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Accordingly, a user can achieve an automatic musical performance by providing external events only at the timing of the note data for a melody, and it is thus unnecessary for the user to provide any external events with respect to the note data for accompaniments. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Such an automatic performing apparatus is thus easy to operate for the user. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> In the foregoing automatic performing apparatus, the tempo of the automatic musical performance may be set by means of a ratio of an assumed value of the interval between the external events to an actual measurement thereof. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Here is also provided, by way of example, a method of setting the tempo. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> According to this tempo setting method, for example, an assumed value (i.e., &ldquo;tap clock&rdquo;) of an interval between the external events is compared with an actually measured value (i.e., &ldquo;tap time&rdquo;) thereof. Then, if the actually measured interval is shorter, the tempo is set to be faster than the current tempo. On the contrary, if the actually measured interval is longer, the tempo is set to be slower than the current tempo. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> More specifically, the tempo of the automatic musical performance (i.e., &ldquo;new tempo&rdquo;) is reset, for example, by means of the following formula, each time an external event is provided:</paragraph>
<paragraph lvl="0"><in-line-formula>(New Tempo)&equals;(Old Tempo)&times;(Tap Clock)/(Tap Time)</in-line-formula></paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> The &ldquo;old tempo&rdquo; may be a tempo determined and set by means of the above formula when the previous external event is provided. As to setting of a first tempo set immediately after the automatic musical performance is started, for example, a value previously recorded in the song data may be utilized as the first tempo. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> In such an automatic performing apparatus, the tempo of the automatic musical performance is automatically reset in accordance with changes of the intervals between the external events, and consequently, it is possible for a user to freely change the tempo of the automatic musical performance by varying the intervals between the external events. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Also, due to such changes in the tempo of the automatic musical performance depending on the intervals between the external events, undesired situations, for example, in which the next external event is provided (in other words, the automatic musical performance within the next section is started) before completion of the automatic musical performance within a certain section or, on the contrary, in which there is an unnatural pause inserted between completion of the automatic musical performance within a certain section and provision of the next external event (in other words, start of the automatic musical performance within the next section) are less likely to occur, compared to cases where the automatic musical performance is progressed at a fixed tempo. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The aforementioned assumed value may be, for example, a value previously recorded in the song data as an assumed value of an interval between the external events. This assumed value may be the same for all of the intervals between the external events, or may be different depending on each external event (for example, depending on a first, second, . . . or nth external event in the automatic musical performance). </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> Alternatively, the aforementioned assumed value may be, for example, a difference between a step time (i.e., information included in each piece of note data, which represents timing for generating a musical tone based on each piece of note data) of note data corresponding to an external event and a step time of note data corresponding to the next external event. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> The aforementioned actual measurement (or actually measured value) may be, for example, the clock number of a timer which operates at a prescribed tempo between provisions of two external events. The tempo of the timer may be, for example, the &ldquo;old tempo&rdquo; mentioned above. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Alternatively, in the foregoing automatic performing apparatus, the tempo of the automatic musical performance may be set by means of a tempo determined by the interval between the external events. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Here is also provided, by way of example, another setting method of the tempo. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> According to this setting method, for example, a tempo &ldquo;F&rdquo; at which external events are provided is calculated on the basis of an interval between the external events, and the tempo of the automatic musical performance is set by means of the tempo &ldquo;F&rdquo;. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> For example, each time an external event is provided, the tempo of the automatic musical performance (i.e., &ldquo;new tempo&rdquo;) is reset by means of the following formula:</paragraph>
<paragraph lvl="0"><in-line-formula>(New Tempo)&equals;&agr;(Old Tempo)&plus;(1&minus;&agr;) F</in-line-formula></paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> The &ldquo;old tempo&rdquo; is, for example, a tempo set by means of the above formula when the previous external event is provided. As to a first tempo set immediately after the automatic musical performance is started, for example, a value previously recorded in the song data may be utilized as the first tempo. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The above &ldquo;&agr;&rdquo; is a numerical value larger than zero and smaller than one, which may be, for example, 0.5. If the value of &ldquo;&agr;&rdquo; is larger, a contribution of &ldquo;F&rdquo; to the &ldquo;new tempo&rdquo; becomes smaller, thereby making a change of the &ldquo;new tempo&rdquo; gradual. On the contrary, if the value of &ldquo;&agr;&rdquo; is smaller, it is possible to immediately change the &ldquo;new tempo&rdquo; in accordance with the change of the interval between the external events. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In cases where the interval between the external events is, for example, 0.5 second, the above &ldquo;F&rdquo; is calculated as follows: F&equals;60/0.5&equals;120 (times per minute) </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> In such an automatic performing apparatus, the tempo of the automatic musical performance is automatically reset according to changes of the intervals between the external events, and consequently, a user can freely change the tempo of the automatic musical performance by varying the intervals between the external events. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Also, due to such changes in the tempo of the automatic musical performance depending on the intervals between the external events, undesired situations, for example, in which the next external event is provided (in other words, the automatic musical performance within the next section is started) before completion of the automatic musical performance within a certain section or, on the contrary, in which there is an unnatural pause inserted between completion of the automatic musical performance within a certain section and provision of the next external event (in other words, start of the automatic musical performance within the next section) are less likely to occur, compared to cases where the automatic musical performance is progressed at a fixed tempo. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> In the foregoing automatic performing apparatus, the external events may include information on strength of tones to be generated. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> In such an automatic performing apparatus, information on strength of tones to be generated (i.e., velocity information) is supplied by way of the external events, and consequently, for example, when an external event is provided, the volume of musical tones to be generated in the automatic musical performance is determined in accordance with such velocity information included in the provided external event. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> More specifically, by way of example, the volume of musical tones to be generated in the automatic musical performance may be determined and set in the following manner. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Data on the volume of musical tones (i.e., velocity value) is recorded in each piece of note data, and the volume of musical tones to be generated based on each piece of note data is basically determined in accordance with this velocity value recorded therein at the time of execution of the automatic musical performance. If the velocity information included in an external event is larger than a prescribed value, the velocity value in each piece of note data within a section corresponding to that external event is corrected to be a value one point two (1.2) times the original velocity value. Then, musical tones are generated on the basis of the corrected velocity value. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> On the contrary, if the velocity information included in an external event is smaller than a prescribed value, the velocity value in each piece of note data within a section corresponding to that external event-is corrected to be a value zero point seven (0.7) times the original velocity value, and musical tones are then generated based on the corrected velocity value. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> In such an automatic performing apparatus, the volume of musical tones can be controlled, for example, per section by means of the velocity information included in each external event. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> The external events including the velocity information may be, for example, the action of pressing on keys of a keyboard, operation of a panel switch (i.e., panel SW) in an operation panel, or key-on information inputted as MIDI data. Otherwise, operational information on an analogue device, such as a bender, may be utilized as the external events. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> The velocity information may be, for example, a parameter representing strength (or velocity) with which any key of the keyboard is pressed on when the external events are the action of pressing on keys of a keyboard. Also, when the external events are the operation of a panel switch (i.e. panel SW) in an operation panel, the velocity information may be a parameter representing strength (or velocity) with which the panel SW is pressed on. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> In the foregoing automatic performing apparatus, the external events may mean operation of pressing on keys of a keyboard. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> In such an automatic performing apparatus, the automatic musical performance can be executed in response to a user&apos;s action of pressing on any key of the keyboard to provide an external event. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> In this case, the external events may be caused using all keys of the keyboard, or using particular keys only. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The automatic performing apparatus of the invention may, for example, be a keyboard instrument such as an electronic piano. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> The keyboard may be a part of the automatic performing apparatus. Otherwise, it may be separated from the automatic performing apparatus and connected thereto by way of, for example, a MIDI terminal. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Alternatively, in the foregoing automatic performing apparatus, the external events may mean operation in an operation panel for operating the automatic performing apparatus. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> In such an automatic performing apparatus, the automatic musical performance can be executed, for example, by operating a button provided in the operation panel, thereby causing an external event. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> The operation panel may be a part of the automatic performing apparatus. Otherwise, it may be separated from the automatic performing apparatus and connected thereto by way of, for example, a MIDI terminal.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> The preferred embodiments of the present invention will now be described in detail with reference to the accompanying drawings, in which: </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is an explanatory view showing the entire composition of an electronic instrument according to a first embodiment of the invention; </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 2A and 2B</cross-reference> are explanatory views each showing an indicator in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is an explanatory view showing a ROM and peripheral parts thereof in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is an explanatory view of automatic performance data in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a flow chart showing the entire flow of processing executed in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a flow chart showing panel event processing executed in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flow chart showing keyboard event processing executed in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flow chart showing automatic performance event processing executed in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a flow chart showing song play processing executed in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flow chart showing tempo timer interrupt processing executed in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a flow chart showing automatic performance clock processing executed in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a flow chart showing tonal volume setting processing executed in the electronic instrument according to the first embodiment; </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is an explanatory view of automatic performance data in an electronic instrument according to a second embodiment of the invention; and </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a flow chart showing automatic performance event processing executed in the electronic instrument according to the second embodiment.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> &lsqb;First Embodiment&rsqb;</paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, an electronic instrument (automatic performing apparatus) <highlight><bold>100</bold></highlight> comprises a keyboard <highlight><bold>108</bold></highlight>, a key switch circuit <highlight><bold>101</bold></highlight> for detecting the operational state of the keyboard <highlight><bold>108</bold></highlight>, an operation panel <highlight><bold>109</bold></highlight>, a panel switch circuit <highlight><bold>102</bold></highlight> for detecting the operational state of the operation panel <highlight><bold>109</bold></highlight>, a RAM <highlight><bold>104</bold></highlight>, a ROM <highlight><bold>105</bold></highlight>, a CPU <highlight><bold>106</bold></highlight>, a tempo timer <highlight><bold>115</bold></highlight> and a musical tone generator (or musical tone generating circuit) <highlight><bold>107</bold></highlight>, which are all coupled by means of a bus <highlight><bold>114</bold></highlight>. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> Also, a digital/analogue (D/A) converter <highlight><bold>111</bold></highlight>, an amplifier <highlight><bold>112</bold></highlight> and a speaker <highlight><bold>113</bold></highlight> are serially connected to the musical tone generator <highlight><bold>107</bold></highlight>. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> The operation panel <highlight><bold>109</bold></highlight> comprises a mode selection switch. If a normal performance mode is selected in the mode selection switch, the electronic instrument <highlight><bold>100</bold></highlight> functions as a normal electronic instrument, and if an automatic performance mode is selected therein, the electronic instrument <highlight><bold>100</bold></highlight> functions as an automatic performing apparatus. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> The operation panel <highlight><bold>109</bold></highlight> also has a song selection switch, by means of which a song to be automatically performed can be selected. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> The operation panel <highlight><bold>109</bold></highlight> is further provided with an indicator <highlight><bold>109</bold></highlight><highlight><italic>a </italic></highlight>for indicating timing at which keyboard events (that is, the action of pressing on any key of the keyboard <highlight><bold>108</bold></highlight>; also referred to as external events) are to be provided in execution of an automatic musical performance. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> More specifically, as shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>A, the indicator <highlight><bold>109</bold></highlight><highlight><italic>a </italic></highlight>indicates the timing at which the keyboard events should be provided in the automatic musical performance (large black circles) and the number of note data based on which musical tones are generated in response to each of the provided keyboard events (small black circles). </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> Furthermore, in the indicator <highlight><bold>109</bold></highlight><highlight><italic>a, </italic></highlight>segmentation into each section equivalent to one beat is also indicated. After musical tones have been generated based on some note data in response to some keyboard event, the corresponding large and small black circles are changed into cross marks, as shown in <cross-reference target="DRAWINGS">FIG. 2B</cross-reference>. In <cross-reference target="DRAWINGS">FIGS. 2A and 2B</cross-reference>, P indicates the timing for generation of musical tones, L indicates the segmentation into each section equivalent to one beat, and Q indicates accomplishment of generation of musical tones. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> The tempo timer <highlight><bold>115</bold></highlight> supplies the CPU <highlight><bold>106</bold></highlight> with interrupting signals at certain intervals during execution of the automatic musical performance, and the tempo of the automatic musical performance is thus set on the basis of the tempo timer <highlight><bold>115</bold></highlight>. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> The ROM <highlight><bold>105</bold></highlight> stores a program for controlling the entirety of the electronic instrument <highlight><bold>100</bold></highlight> and various kinds of data. In addition, automatic performance data (i.e., song data) for a plurality of songs and a program for performance control functions are also stored in the ROM <highlight><bold>105</bold></highlight>. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> The automatic performance data are previously stored in the ROM <highlight><bold>105</bold></highlight> with respect to each song (song (<highlight><bold>1</bold></highlight>), song (<highlight><bold>2</bold></highlight>), . . . song (n)), as shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the automatic performance data on each song include tone color data, tonal volume data, tempo data and beat data at the beginning of each song. Also, the automatic performance data include several pieces of note data in each section (beat) equivalent to one beat of a song, and beat data correspondingly provided for each beat (section). </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The tone color data are data to designate the tone color of musical tones to be generated based on the following note data (or note data for a melody and those for accompaniments in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>). </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> The tonal volume data are data to control the tonal volume of the musical tones to be generated. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> The tempo data are data to control the tempo or speed of the automatic musical performance only in a first beat (section) of the song. The tempo in a second and subsequent beats is determined based on the timing of provision of the keyboard events as described below. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> The beat data have recorded therein a &ldquo;tap clock&rdquo; for a corresponding beat (section); more specifically, a value of 96 or 48. For example, if a beat (section) is in three-four time or four-four time, a value of 96 is recorded for that beat (section), and if a beat (section) is in six-eight time, a value of 48 is recorded for that beat (section). </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> The &ldquo;tap clock&rdquo; is an assumed value of the number of times (i.e., clock number) the signals are sent by the tempo timer <highlight><bold>115</bold></highlight> in the corresponding beat (section). </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> Each piece of note data includes key number K, step time S, gate time G, and velocity V. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> Here, the step time S represents timing at which a musical tone is generated based on the corresponding piece of note data, regarding the beginning of the song as a base point. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> The key number K represents a tone pitch. The gate time G represents the duration of generation of a musical tone. Then, the velocity V represents the volume of a musical tone to be generated (i.e., pressure at which a key is pressed). </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> The CPU <highlight><bold>106</bold></highlight> executes the automatic musical performance as described below by means of a program previously stored in the ROM <highlight><bold>105</bold></highlight>. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> Also, the CPU <highlight><bold>106</bold></highlight> performs operational control over the entire electronic instrument <highlight><bold>100</bold></highlight> by reading out and executing various control programs stored in the ROM <highlight><bold>105</bold></highlight>. At this time, the RAM <highlight><bold>104</bold></highlight> is utilized as a memory for temporarily storing various kinds of data in order for the CPU <highlight><bold>106</bold></highlight> to execute various control processings. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> At the time of execution of the automatic musical performance, as shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the RAM <highlight><bold>104</bold></highlight> retains the automatic performance data on a song to be automatically performed, and send the same to the musical tone generator <highlight><bold>107</bold></highlight> according to need. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> The musical tone generator <highlight><bold>107</bold></highlight> generates musical tones on the basis of the prescribed automatic performance data sent from the RAM <highlight><bold>104</bold></highlight> at the time of execution of the automatic musical performance, while it generates musical tones in accordance with keys pressed on the keyboard <highlight><bold>108</bold></highlight> at the time of execution of a normal musical performance. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> Now, the outline of the operation in the automatic performance mode of the electronic instrument <highlight><bold>100</bold></highlight> according to this embodiment will be described. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> When the automatic performance mode is selected in the electronic instrument <highlight><bold>100</bold></highlight>, upon provision of a first keyboard event, an automatic musical performance is progressed from the beginning of a first section to the end thereof on the basis of the automatic performance data. Subsequently, in response to a second keyboard event, the automatic musical performance is progressed from the beginning of a second section to the end thereof. Then, in the same manner, the automatic musical performance is progressed from the beginning of an nth section to the end thereof in response to an nth keyboard event. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> In cases where an (n&plus;1)th keyboard event is provided prior to completion of the automatic musical performance within the nth section, even if there are some note data left without being changed into musical tones, the remaining note data are disregarded and skipped such that the automatic musical performance is recommenced from the beginning of an (n&plus;1)th section. Also, after completion of the automatic musical performance within the nth section, progression of the automatic musical performance is suspended until the next (i.e., (n&plus;1)th) keyboard event is provided. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> The tempo of the automatic musical performance within the nth section executed by the electronic instrument <highlight><bold>100</bold></highlight> is synchronized with the tempo of the tempo timer <highlight><bold>115</bold></highlight>. The latter is reset each time a keyboard event is provided (in other words, with respect to each section of the automatic performance data) by means of the following formula:</paragraph>
<paragraph lvl="0"><in-line-formula>(New Tempo)&equals;(Old Tempo)&times;(Tap Clock)/(Tap Time)</in-line-formula></paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> In this formula, the &ldquo;old tempo&rdquo; means the tempo of the automatic musical performance in the previous section (i.e., (n&minus;1)th section). </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> As to the tempo in the first section of the song, it is set on the basis of the tempo data included in the automatic performance data. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> The &ldquo;tap clock&rdquo; is, as mentioned above, a value (96 or 48) previously recorded in the automatic performance data as an assumed value of the number of times (i.e., clock number) the signals are transmitted by the tempo timer <highlight><bold>115</bold></highlight> during each section. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> The &ldquo;tap time&rdquo; is an actual measurement of the clock number of the tempo timer <highlight><bold>115</bold></highlight> between provisions of the previous keyboard event (i.e., (n&minus;1)th keyboard event) and the current keyboard event (i.e., nth keyboard event). </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> Accordingly, when the &ldquo;tap time&rdquo; is smaller than the &ldquo;tap clock,&rdquo; in other words, when an interval between two successive keyboard events is shorter than assumed, the &ldquo;new tempo&rdquo; is set to be faster than the &ldquo;old tempo.&rdquo; On the contrary, in cases where the &ldquo;tap time&rdquo; is larger than the &ldquo;tap clock,&rdquo; in other words, in cases where an interval between two successive keyboard events is longer than assumed, the &ldquo;new tempo&rdquo; is set to be slower than the &ldquo;old tempo.&rdquo;</paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> On the other hand, when the normal performance mode is selected, the electronic instrument <highlight><bold>100</bold></highlight> carries out the same functions as those of a normal electronic instrument, which functions do not directly relate to the subject matter of the invention and, therefore, no reference is made herein to such functions. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> Now, the operation of the electronic instrument <highlight><bold>100</bold></highlight> according to this embodiment, particularly, in the automatic performance mode, will be specifically described. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> Main routines of the entire processing executed in the electronic instrument <highlight><bold>100</bold></highlight> are shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. Once the power is applied to the electronic instrument <highlight><bold>100</bold></highlight>, initialization processing is first of all executed (step <highlight><bold>10</bold></highlight>). </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> In the initialization processing, the internal state of the CPU <highlight><bold>106</bold></highlight> is reset into the initial condition, while a register, a counter, a flag and others defined in the RAM <highlight><bold>104</bold></highlight> are all initialized. In addition, in the initialization processing, the prescribed data are sent to the musical tone generator <highlight><bold>107</bold></highlight>, and processing for preventing undesired sounds from being generated while the power is on is also carried out. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> Once the initialization processing is ended, panel event processing is subsequently started (step <highlight><bold>20</bold></highlight>). </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> The details of the panel event processing are illustrated in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. In this panel event processing, it is first determined whether or not any operation has been conducted in the operation panel <highlight><bold>109</bold></highlight> (step <highlight><bold>110</bold></highlight>). This determination is achieved in the following manner. First of all, the panel switch circuit <highlight><bold>102</bold></highlight> scans the operation panel <highlight><bold>109</bold></highlight> to obtain data representing the on/off state of each switch (hereinafter referred to as new panel data), and the data are imported as a bit array corresponding to each switch. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> Subsequently, data previously read in and already stored in the RAM <highlight><bold>104</bold></highlight> (hereinafter referred to as old panel data) are compared with the new panel data to create a panel event map in which different bits are turned on. The presence of any panel event is determined by referring to this panel event map. More specifically, if there is existing even only one bit that is on in the panel event map, it is determined that any panel event has been provided. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> In cases where the presence of no panel event is determined at step <highlight><bold>110</bold></highlight>, the processing returns from the panel event processing routines to the main routines. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> On the other hand, in cases where the presence of any panel event is determined at step <highlight><bold>110</bold></highlight>, the processing proceeds to the next step at which it is determined whether or not the panel event is an event of the mode selection switch (step <highlight><bold>120</bold></highlight>). Such determination is made by checking whether or not a bit corresponding to the mode selection switch is on in the panel event map. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> In cases where it is determined that the panel event is not the event of the mode selection switch, the processing proceeds to step <highlight><bold>130</bold></highlight>, while in cases where it is determined that the panel event is the event of the mode selection switch, mode change processing is carried out (step <highlight><bold>150</bold></highlight>). By this mode change processing, the mode is switched over between the normal performance mode and the automatic performance mode. After the mode change processing is ended, the processing proceeds to step <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> At step <highlight><bold>130</bold></highlight>, it is determined whether or not the panel event is an event of the song selection switch. Such determination is made by checking whether or not a bit corresponding to the song selection switch is on in the panel event map. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> In cases where it is determined that the panel event is not the event of the song selection switch, the processing proceeds to step <highlight><bold>140</bold></highlight>, while in cases where it is determined that the panel event is the event of the song selection switch, song selection processing is carried out (step <highlight><bold>160</bold></highlight>). By this song selection processing, a song to be automatically performed is selected, and the song designated by the song selection switch is automatically performed at the time of execution of the automatic musical performance. After the song selection processing is ended, the processing proceeds to step <highlight><bold>140</bold></highlight>. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> At step <highlight><bold>140</bold></highlight>, similar processings are respectively executed for other switches. More specifically, such &ldquo;processings for other switches&rdquo; include the processings of panel events of, for example, a tone color selection switch, acoustic effect selection switch, volume setting switch and others, which processings do not directly relate to the present invention and the description thereof is thus omitted here. After such &ldquo;processings for other switches&rdquo; are ended, the processing returns from the panel event processing routines to the main routines. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> Once the panel event processing is ended, keyboard event processing (step <highlight><bold>30</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>) is then executed. The details of the keyboard event processing are shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> First of all, at step <highlight><bold>210</bold></highlight>, it is determined whether or not the automatic performance mode is being selected. In the case of the automatic performance mode, the processing proceeds to step <highlight><bold>220</bold></highlight> to execute automatic performance event processing as described below. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> On the other hand, in the case of the normal performance mode at step <highlight><bold>210</bold></highlight>, the processing proceeds to step <highlight><bold>230</bold></highlight> to execute normal event processing (that is, musical tone generation processing as a normal electronic instrument). As to the normal event processing, it does not directly relate to the present invention, and the description thereof is thus omitted. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> At step <highlight><bold>220</bold></highlight>, the automatic performance event processing is executed as shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> In the automatic performance event processing, it is first determined, at step <highlight><bold>310</bold></highlight>, whether or not any keyboard event (or external event) has been provided. Such determination is achieved in the following manner. First of all, the keyboard <highlight><bold>108</bold></highlight> is scanned by the key switch circuit <highlight><bold>101</bold></highlight>, thereby importing data representing the pressed state of each key (hereinafter referred to as new key data) as a bit array corresponding to each key. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> Then, data previously read in and already stored in the RAM <highlight><bold>104</bold></highlight> (hereinafter referred to as old key data) are compared with the new key data to check whether or not there are any different bits existing between the old and new key data, thereby creating a keyboard event map in which the different bits are turned on. The presence of any keyboard event is thus determined by referring to this keyboard event map. More specifically, if there is existing even only one bit that is on in the keyboard event map, it is determined that any keyboard event has been provided. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> In cases where the presence of any keyboard event is determined by reference to the keyboard event map created in the aforementioned manner, the processing proceeds to step <highlight><bold>320</bold></highlight>. On the other hand, in cases where the presence of no keyboard event is determined, the processing returns from the automatic performance event processing routines to the main routines. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> At step <highlight><bold>320</bold></highlight>, the tempo of the automatic musical performance (i.e., &ldquo;new tempo&rdquo;) is determined by means of the following formula:</paragraph>
<paragraph lvl="0"><in-line-formula>(New Tempo)&equals;(Old Tempo)&times;(Tap Clock)/(Tap Time)</in-line-formula></paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> In this formula, the &ldquo;old tempo&rdquo; is a tempo determined in the previous automatic performance event processing. The &ldquo;tap clock&rdquo; is a numerical value (i.e., 96 or 48) previously recorded in the automatic performance data as an assumed value of the number of times (i.e., clock number) the tempo timer <highlight><bold>115</bold></highlight> sends the signals during one section of the automatic performance data. The &ldquo;tap time&rdquo; is an actually measured value of the clock number between provisions of the previous keyboard event and the current keyboard event, which is counted up in automatic performance clock processing as described below. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> The &ldquo;new tempo&rdquo; thus determined is set as the tempo (i.e., interruptive interval) of the tempo timer <highlight><bold>115</bold></highlight> until provision of the next keyboard event. Then, the tempo of the tempo timer <highlight><bold>115</bold></highlight> becomes the tempo of the automatic musical performance, as described below, until provision of the next keyboard event. </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> After step <highlight><bold>320</bold></highlight>, the processing proceeds to step <highlight><bold>330</bold></highlight>, at which batch processing for unprocessed clocks is carried out. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> More specifically, when an (n&plus;1)th keyboard event is provided during execution of the automatic musical performance within an nth section of the automatic performance data, the automatic musical performance is progressed at a burst to the beginning of an (n&plus;1)th section, and then, from the beginning of the (n&plus;1)th section, the automatic musical performance is restarted with the tempo detected and set at step <highlight><bold>320</bold></highlight>. </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> Such processing at step <highlight><bold>330</bold></highlight> realizes a function in which, each time a keyboard event is provided, a section of the automatic performance data corresponding to the provided keyboard event is automatically performed. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> After step <highlight><bold>330</bold></highlight>, the processing proceeds to step <highlight><bold>340</bold></highlight>, at which a value stored in the next beat data is set as the &ldquo;tap clock.&rdquo;</paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> At step <highlight><bold>350</bold></highlight>, the &ldquo;tap clock&rdquo; set at step <highlight><bold>340</bold></highlight> is set as a &ldquo;run clock.&rdquo; The &ldquo;run clock&rdquo; is, as described in detail below, a value for prescribing the progress of the processing for the automatic musical performance. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> At step <highlight><bold>360</bold></highlight>, the &ldquo;tap time&rdquo; is set to be zero. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> Once the keyboard event processing is ended, song play processing (step <highlight><bold>40</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>) is next executed. The details of the song play processing are shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> At step <highlight><bold>405</bold></highlight>, it is determined whether or not the &ldquo;run clock&rdquo; is zero. If the &ldquo;run clock&rdquo; is determined not to be zero, the processing proceeds to step <highlight><bold>410</bold></highlight>. On the other hand, if the &ldquo;run clock&rdquo; is determined to be zero, the processing returns from the song play processing routines to the main routines. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> As mentioned above, the value of the &ldquo;tap clock&rdquo; is set as the &ldquo;run clock&rdquo; in the automatic performance event processing, and as described below, subtraction is made therefrom depending on the tempo of the tempo timer <highlight><bold>115</bold></highlight> in the automatic performance clock processing. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> At step <highlight><bold>410</bold></highlight>, it is determined whether or not a &ldquo;seq clock&rdquo; is zero. The &ldquo;seq clock&rdquo; is, as shown in <cross-reference target="DRAWINGS">FIG. 10, a</cross-reference> numerical value incremented by the interrupting signals transmitted from the tempo timer <highlight><bold>115</bold></highlight> and reset to be zero after the song play processing is ended. Accordingly, the &ldquo;seq clock&rdquo; represents the clock number from the immediately preceding song play processing. Also, the tempo at which the tempo timer <highlight><bold>115</bold></highlight> transmits the interrupting signals is the tempo set in the automatic performance event processing as mentioned above. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> In cases where it is determined, at step <highlight><bold>410</bold></highlight>, that the &ldquo;seq clock&rdquo; is zero, it is considered that timing for generation of musical tones for the automatic musical performance has not yet been reached, and the processing thus returns from the song play processing routines to the main routines. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> On the other hand, in cases where it is determined, at step <highlight><bold>410</bold></highlight>, that the &ldquo;seq clock&rdquo; is not zero, the processing proceeds to step <highlight><bold>420</bold></highlight>, at which the automatic performance clock processing is executed. The details of the automatic performance clock processing are shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> At step <highlight><bold>510</bold></highlight> in the automatic performance clock processing, the value of the &ldquo;seq clock&rdquo; is added to the value of the &ldquo;tap time.&rdquo; Accordingly, the &ldquo;tap time&rdquo; is also incremented, just like the &ldquo;seq clock,&rdquo; by each interrupting signal transmitted from the tempo timer <highlight><bold>115</bold></highlight>. </paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> At step <highlight><bold>520</bold></highlight>, it is determined whether or not the &ldquo;seq clock&rdquo; is larger than the &ldquo;run clock.&rdquo;</paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> If it is determined that the &ldquo;seq clock&rdquo; is not larger than the &ldquo;run clock,&rdquo; the processing proceeds to step <highlight><bold>540</bold></highlight>. On the other hand, if it is determined, at step <highlight><bold>520</bold></highlight>, that the &ldquo;seq clock&rdquo; is larger than the &ldquo;run clock,&rdquo; the processing proceeds to step <highlight><bold>530</bold></highlight>, where the value of the &ldquo;run clock&rdquo; is set as the value of the &ldquo;seq clock,&rdquo; and then, the processing proceeds to step <highlight><bold>540</bold></highlight>. </paragraph>
<paragraph id="P-0146" lvl="0"><number>&lsqb;0146&rsqb;</number> At step <highlight><bold>540</bold></highlight>, the value of the &ldquo;seq clock&rdquo; is subtracted from the value of the &ldquo;run clock.&rdquo; Then, the processing returns from the automatic performance clock processing routines to the main routines. </paragraph>
<paragraph id="P-0147" lvl="0"><number>&lsqb;0147&rsqb;</number> Subsequently, the processing again returns to the song play processing routines (in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>). At step <highlight><bold>430</bold></highlight>, sequence progression processing is carried out, and more particularly, among the note data on the basis of which musical tones have not yet been generated, those within a certain range are sequentially read out and sent to the musical tone generator <highlight><bold>107</bold></highlight>. </paragraph>
<paragraph id="P-0148" lvl="0"><number>&lsqb;0148&rsqb;</number> By means of the musical tone generator <highlight><bold>107</bold></highlight>, the pitch and duration of musical tones to be generated are determined in accordance with the key number K and the gate time G, respectively, included in the note data. The musical tone generator <highlight><bold>107</bold></highlight> also determines the volume of the musical tones to be generated in accordance with the velocity V included in the note data and velocity at which keys of the keyboard are pressed on. In this manner, musical tones are generated by the musical tone generator <highlight><bold>107</bold></highlight>. </paragraph>
<paragraph id="P-0149" lvl="0"><number>&lsqb;0149&rsqb;</number> Specific processing relating to setting of the tonal volume is as shown in <cross-reference target="DRAWINGS">FIG. 12</cross-reference>. </paragraph>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> At step <highlight><bold>610</bold></highlight>, it is determined whether or not velocity at which a key of the keyboard is pressed on is larger than a prescribed value A<highlight><bold>1</bold></highlight>. If it is determined that the velocity is not larger than the prescribed value A<highlight><bold>1</bold></highlight>, the processing proceeds to step <highlight><bold>620</bold></highlight>. On the other hand, if it is determined that the velocity is larger than the prescribed value A<highlight><bold>1</bold></highlight>, the processing proceeds to step <highlight><bold>640</bold></highlight>. </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> At step <highlight><bold>620</bold></highlight>, it is determined whether or not the velocity at which the key is pressed on is smaller than a prescribed value A<highlight><bold>2</bold></highlight>. If it is determined that the velocity is not smaller than the prescribed value A<highlight><bold>2</bold></highlight>, the processing proceeds to step <highlight><bold>630</bold></highlight>, while if it is determined that the velocity is smaller than the prescribed value A<highlight><bold>2</bold></highlight>, the processing proceeds to step <highlight><bold>650</bold></highlight>. Here, the prescribed value A<highlight><bold>1</bold></highlight> is larger than the prescribed value A<highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> At step <highlight><bold>630</bold></highlight>, the volume of musical tones to be generated on the basis of the note data within the section corresponding to the provided keyboard event is set in accordance with the velocity V included in the respective pieces of note data. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> If the determination is &ldquo;yes&rdquo; at step <highlight><bold>610</bold></highlight>, the volume of musical tones to be generated based on the note data within the section corresponding to the provided keyboard event is set, at step <highlight><bold>640</bold></highlight>, in accordance with a value which is one point two (1.2) times the velocity V included in the respective pieces of note data. </paragraph>
<paragraph id="P-0154" lvl="0"><number>&lsqb;0154&rsqb;</number> Furthermore, if the determination is &ldquo;yes&rdquo; at step <highlight><bold>620</bold></highlight>, the volume of musical tones to be generated based on the note data within the section corresponding to the provided keyboard event is set, at step <highlight><bold>650</bold></highlight>, in accordance with a value which is zero point seven (0.7) time the velocity V included in the respective pieces of note data. </paragraph>
<paragraph id="P-0155" lvl="0"><number>&lsqb;0155&rsqb;</number> By such processing from step <highlight><bold>610</bold></highlight> to step <highlight><bold>650</bold></highlight>, a user can change the tonal volume with respect to each section at the time of execution of the automatic musical performance, by changing strength at which keys of the keyboard are pressed on. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> After step <highlight><bold>430</bold></highlight>, the processing returns from the song play processing routines to the main routines (in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>). </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> Among the main routines, MIDI reception processing (step <highlight><bold>50</bold></highlight>) is to execute musical tone generation processing, mute processing, or any other processing on the basis of data inputted from an external device (not shown) connected, via a MIDI terminal, to the electronic instrument. However, this processing does not directly relate to the present invention, and the description thereof is thus omitted. </paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> The remaining processing (step <highlight><bold>60</bold></highlight>) among the main routines includes tone color selection processing, volume setting processing and others, which do not directly relate to the present invention and the description thereof is thus omitted as well. </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> Now, by means of the electronic instrument <highlight><bold>100</bold></highlight> according to this first embodiment, the following effects can be achieved. </paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> Firstly, in the electronic instrument <highlight><bold>100</bold></highlight>, the automatic performance data is segmented into each section equivalent to one beat, and each time a keyboard event is provided, the automatic musical performance is progressed by the section. </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> Consequently, it is only necessary for a user to provide keyboard events at intervals of one beat, and it is unnecessary for him/her to provide keyboard events with respect to all pieces of note data. </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> As a result, the user can easily carry out an automatic musical performance. </paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> Secondly, in the electronic instrument <highlight><bold>100</bold></highlight>, the tempo of the automatic musical performance is set on the basis of intervals between the keyboard events. Consequently, the user can freely change the tempo of the automatic musical performance by varying such intervals between the keyboard events. </paragraph>
<paragraph id="P-0164" lvl="0"><number>&lsqb;0164&rsqb;</number> Thirdly, in the electronic instrument <highlight><bold>100</bold></highlight>, the tempo of the automatic musical performance is changed with respect to each beat in accordance with the tempo at which the keyboard events are provided. Consequently, compared to cases where the automatic musical performance is progressed at a fixed tempo, undesired situations are less likely to occur in which there are some note data left without being changed into musical tones when the next keyboard event is provided or, on the contrary, in which there is an unnatural pause inserted after all note data within a certain section have been changed into musical tones and before the next keyboard event is provided. </paragraph>
<paragraph id="P-0165" lvl="0"><number>&lsqb;0165&rsqb;</number> &lsqb;Second Embodiment&rsqb;</paragraph>
<paragraph id="P-0166" lvl="0"><number>&lsqb;0166&rsqb;</number> The composition of an electronic instrument according to a second embodiment of the invention is basically the same as that of the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment as described above, except for a partial difference in composition of the automatic performance data. The composition of the electronic instrument according to the second embodiment corresponding to that of the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment will not be repeated hereinafter. </paragraph>
<paragraph id="P-0167" lvl="0"><number>&lsqb;0167&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>, automatic performance data in an electronic instrument <highlight><bold>200</bold></highlight> according to this second embodiment are segmented into sections, each of such sections comprising a piece of note data for a melody located at the beginning of each section and note data for accompaniments following the melody. </paragraph>
<paragraph id="P-0168" lvl="0"><number>&lsqb;0168&rsqb;</number> Accordingly, the length of each section is not equal, and thus, as the &ldquo;tap clock&rdquo; which is, as mentioned above, an assumed value of the clock number in a section, a different value is calculated for each section. </paragraph>
<paragraph id="P-0169" lvl="0"><number>&lsqb;0169&rsqb;</number> Also, each piece of note data for a melody and for accompaniments includes the key number K, step time S, gate time G, and velocity V. </paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> Now, the outline of the operation of the electronic instrument <highlight><bold>200</bold></highlight> will be described. </paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> In the electronic instrument <highlight><bold>200</bold></highlight>, an automatic musical performance is progressed by the section of the automatic performance data in response to keyboard events, in which respect the electronic instrument <highlight><bold>200</bold></highlight> is the same as the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment. </paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> Also, the tempo of the automatic musical performance until provision of the next keyboard event is reset each time a keyboard event is provided, in which respect the electronic instrument <highlight><bold>200</bold></highlight> is also the same as the electronic instrument <highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> However, in the electronic instrument <highlight><bold>200</bold></highlight>, the sections of the automatic performance data are based on the piece of note data for a melody as mentioned above, and accordingly, each time a keyboard event is provided, the automatic musical performance is progressed by the piece of note data for a melody. </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> More specifically, in response to a first keyboard event, the automatic musical performance is started with the note data for a melody located at the beginning of a first section, and then progressed to the note data for accompaniments following the melody. In the same manner, in response to an nth keyboard event, the automatic musical performance is progressed from the note data for a melody located at the beginning of an nth section to the note data for accompaniments following the melody. </paragraph>
<paragraph id="P-0175" lvl="0"><number>&lsqb;0175&rsqb;</number> The specific operation of the electronic instrument <highlight><bold>200</bold></highlight> at the time of execution of the automatic musical performance is basically the same as that of the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment. </paragraph>
<paragraph id="P-0176" lvl="0"><number>&lsqb;0176&rsqb;</number> As mentioned above, however, in the electronic instrument <highlight><bold>200</bold></highlight>, the sections of the automatic performance data are based on each piece of note data for a melody, and the length of each section (or &ldquo;tap clock&rdquo;) is not equal. </paragraph>
<paragraph id="P-0177" lvl="0"><number>&lsqb;0177&rsqb;</number> Consequently, in the automatic performance data, a different value is calculated for each section as the &ldquo;tap clock.&rdquo; </paragraph>
<paragraph id="P-0178" lvl="0"><number>&lsqb;0178&rsqb;</number> Specifically, in automatic performance event processing of the electronic instrument <highlight><bold>200</bold></highlight>, as shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>, at step <highlight><bold>740</bold></highlight>, a difference between the step time S of the note data for a melody in the current section and that of the note data for a melody in the next section is determined to be the &ldquo;tap clock&rdquo; for the current section. </paragraph>
<paragraph id="P-0179" lvl="0"><number>&lsqb;0179&rsqb;</number> By means of the electronic instrument <highlight><bold>200</bold></highlight> according to this second embodiment, the following effects can be achieved. </paragraph>
<paragraph id="P-0180" lvl="0"><number>&lsqb;0180&rsqb;</number> Firstly, in the electronic instrument <highlight><bold>200</bold></highlight>, each time a keyboard event is provided, musical tones for a melody and accompaniments following the melody are generated. </paragraph>
<paragraph id="P-0181" lvl="0"><number>&lsqb;0181&rsqb;</number> Accordingly, it is only necessary for a user to provide keyboard events in accordance with the timing of the melody, and it is not necessary for him/her to provide keyboard events in accordance with the timing of the accompaniments. </paragraph>
<paragraph id="P-0182" lvl="0"><number>&lsqb;0182&rsqb;</number> As a result, the user can easily carry out an automatic musical performance. </paragraph>
<paragraph id="P-0183" lvl="0"><number>&lsqb;0183&rsqb;</number> Secondly, in the electronic instrument <highlight><bold>200</bold></highlight>, the tempo of the automatic musical performance can be freely changed by varying intervals between the keyboard events, in the same manner as in the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment. </paragraph>
<paragraph id="P-0184" lvl="0"><number>&lsqb;0184&rsqb;</number> Thirdly, in the electronic instrument <highlight><bold>200</bold></highlight>, the tempo of the automatic musical performance is set in accordance with the tempo at which the keyboard events are provided, just like in the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment. Consequently, compared to cases where the automatic musical performance is progressed at a fixed tempo, undesired situations are less likely to occur in which there are some note data left without being changed into musical tones when the next keyboard event is provided or, on the contrary, in which there is an unnatural pause inserted after all note data within a certain section have been changed into musical tones and before the next keyboard event is provided. </paragraph>
<paragraph id="P-0185" lvl="0"><number>&lsqb;0185&rsqb;</number> &lsqb;Third Embodiment&rsqb;</paragraph>
<paragraph id="P-0186" lvl="0"><number>&lsqb;0186&rsqb;</number> The composition and operation of an electronic instrument according to a third embodiment of the invention is basically the same as those of the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment as described above, except for a difference in the setting method for the tempo of the automatic musical performance. The composition and the operation corresponding to those of the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment will not be repeated hereinafter. </paragraph>
<paragraph id="P-0187" lvl="0"><number>&lsqb;0187&rsqb;</number> In an electronic instrument <highlight><bold>300</bold></highlight> according to this third embodiment, in detection of the tempo (step <highlight><bold>320</bold></highlight>) in the automatic performance event processing (in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>), the tempo of the automatic musical performance (i.e., &ldquo;new tempo&rdquo;) is determined by means of the following formula:</paragraph>
<paragraph lvl="0"><in-line-formula>(New Tempo)&equals;&agr;(Old Tempo)&plus;(1&agr;) F</in-line-formula></paragraph>
<paragraph id="P-0188" lvl="0"><number>&lsqb;0188&rsqb;</number> In this formula, the &ldquo;old tempo&rdquo; is a tempo set by means of this formula when, for example, the previous external event is provided. Also, in the setting of a first tempo immediately after the automatic musical performance is started, for example, a value previously recorded in the song data may be used. </paragraph>
<paragraph id="P-0189" lvl="0"><number>&lsqb;0189&rsqb;</number> &ldquo;&agr;&rdquo; is a numerical value larger than zero and smaller than one, which may be, for example, 0.5. If the value of &ldquo;&agr;&rdquo; is larger, a contribution of &ldquo;F&rdquo; to the &ldquo;new tempo&rdquo; becomes smaller, thereby making a change of the &ldquo;new tempo&rdquo; gradual. On the contrary, if the value of &ldquo;&agr;&rdquo; is smaller, it is possible to immediately change the &ldquo;new tempo&rdquo; in accordance with the change of intervals between the external events. </paragraph>
<paragraph id="P-0190" lvl="0"><number>&lsqb;0190&rsqb;</number> By means of the electronic instrument <highlight><bold>300</bold></highlight> according to this third embodiment, the following effects can be achieved. </paragraph>
<paragraph id="P-0191" lvl="0"><number>&lsqb;0191&rsqb;</number> Firstly, a user can easily carry out an automatic musical performance with the electronic instrument <highlight><bold>300</bold></highlight>, since it is only necessary for him/her to provide keyboard events at intervals of one beat, just like in the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment. </paragraph>
<paragraph id="P-0192" lvl="0"><number>&lsqb;0192&rsqb;</number> Secondly, in the electronic instrument <highlight><bold>300</bold></highlight>, the tempo of the automatic musical performance can be freely changed by changing the tempo of provision of the keyboard events, like in the electronic instrument <highlight><bold>100</bold></highlight> according to the first embodiment. Consequently, compared to cases where the automatic musical performance is progressed at a fixed tempo, undesired situations are less likely to occur in which there are some note data left without being changed into musical tones when the next keyboard event is provided or, on the contrary, in which there is an unnatural pause inserted all note data within a certain section have been changed into musical tones and before the next keyboard event is provided. </paragraph>
<paragraph id="P-0193" lvl="0"><number>&lsqb;0193&rsqb;</number> The present invention is, of course, not restricted to the embodiments as described above, and may be practiced or embodied in still other ways without departing from the subject matter thereof. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. An automatic performing apparatus for executing an automatic musical performance based on song data in response to external events, wherein 
<claim-text>the song data are segmented into prescribed sections; </claim-text>
<claim-text>at the time of execution of an automatic musical performance, each time an individual external event is provided, the automatic musical performance is progressed within a prescribed section corresponding to the external event provided; and </claim-text>
<claim-text>a tempo of the automatic musical performance is set on the basis of intervals between the individual external events. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The automatic performing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein each of the prescribed sections corresponds to one beat of the song data. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The automatic performing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein each of the prescribed sections comprises note data for a melody and note data for accompaniments corresponding to the note data for the melody. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The automatic performing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the tempo is set by means of a ratio of an assumed value of the interval between the individual external events to an actual measurement of the interval between the individual external events. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The automatic performing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein a new tempo is set relative to the tempo determined by the interval between the external events. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The automatic performing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the external events include information on strength of tones to be generated. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The automatic performing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the external events includes pressing on keys of a keyboard. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The automatic performing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the external events includes an operation panel for operating the automatic performing apparatus. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. An automatic musical performance instrument comprising: 
<claim-text>an input device for communicating a first selected external input to the instrument; </claim-text>
<claim-text>a storage device for storing musical data segmented into individual portions of musical data and providing a tempo at which the individual portions of musical data is output; </claim-text>
<claim-text>a controller for matching the first selected external inputs with an individual portion of musical data; </claim-text>
<claim-text>an output device for audibly outputting the desired individual portion of musical data in response to the first selected external input; and </claim-text>
<claim-text>wherein the tempo at which the desired individual portion of musical data is output is dependent upon a time interval between the first selected external input and a second external input to the instrument. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein the individual portion of musical data corresponding with the first selected external input is applied to a single beat of a measure. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the individual portion of musical data contains at least one piece of note data which is audibly output by the output device in response to the first selected external input. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein the individual portion of musical data associated with the first selected external input includes accompaniment data correlated with the at least one piece of note data. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein the controller sets the time interval for the tempo according to a ratio between an initial time interval and a measured time interval measured between the first and second external inputs. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the first time interval is an assumed time interval. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the first time interval is a previously measured time interval. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein for each external input the controller provides a new tempo adjusted by the tempo multiplied by a ratio between the first time interval and the measured time interval. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the storage device is further provided with a desired constant, &agr;, being a value between about 0 and 1 and for each external input the controller provides a new tempo adjusted by the constant &agr; multiplied by the tempo and added to a value of 1&minus;&agr; multiplied by the measured time interval. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein the storage device is further provided with a constant velocity value and the controller is further provided with a measured velocity value from the external input and compares the measured velocity value with the constant velocity value to produce a corrected velocity value which is applied to the audible output. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The automatic musical performance instrument according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the measured velocity value is greater than the constant velocity value, the corrected velocity value is equal to about 1.2 multiplied by the constant velocity value, and wherein the measured velocity value is less than the constant velocity value, the corrected velocity value is equal to about 0.7 multiplied by the constant velocity value. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. An automatic musical performance instrument comprising: 
<claim-text>an input device for communicating a selected first external input to the instrument; </claim-text>
<claim-text>a storage device for storing musical data segmented into individual portions of musical data and providing a tempo and a constant velocity value at which the individual portions of musical data is output; </claim-text>
<claim-text>a controller for matching the first selected external inputs with a desired individual portion of musical data; </claim-text>
<claim-text>an output device for audibly outputting the desired individual portion of musical data in response to the first selected external input; and </claim-text>
<claim-text>wherein the controller is provided with a measured velocity value from the external input and compares the measured velocity value with the constant velocity value to produce a corrected velocity value which is applied to the audible output, and the tempo at which the desired individual portion of musical data is audibly output is dependent upon a time interval between the selected first external input and a second external input to the instrument.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004701A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004701A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004701A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004701A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004701A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030004701A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030004701A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030004701A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030004701A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030004701A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030004701A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030004701A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030004701A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030004701A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030004701A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
