<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005028A1-20030102-D00000.TIF SYSTEM "US20030005028A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005028A1-20030102-D00001.TIF SYSTEM "US20030005028A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005028A1-20030102-D00002.TIF SYSTEM "US20030005028A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005028A1-20030102-D00003.TIF SYSTEM "US20030005028A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005028A1-20030102-D00004.TIF SYSTEM "US20030005028A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005028A1-20030102-D00005.TIF SYSTEM "US20030005028A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030005028A1-20030102-D00006.TIF SYSTEM "US20030005028A1-20030102-D00006.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005028</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10180868</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020626</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>01115447.3</doc-number>
</priority-application-number>
<filing-date>20010627</filing-date>
<country-code>DE</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F009/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>709</class>
<subclass>104000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method and apparatus for controlling the number of servers in a hierarchical resource environment</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Greg</given-name>
<middle-name>M.</middle-name>
<family-name>Dritschler</family-name>
</name>
<residence>
<residence-us>
<city>Poughkeepsie</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Guenter</given-name>
<family-name>Vater</family-name>
</name>
<residence>
<residence-non-us>
<city>Rottenburg</city>
<country-code>DE</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Robert</given-name>
<family-name>Vaupel</family-name>
</name>
<residence>
<residence-non-us>
<city>Rottenburg</city>
<country-code>DE</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Peter</given-name>
<middle-name>B.</middle-name>
<family-name>Yocom</family-name>
</name>
<residence>
<residence-us>
<city>Wappingers Falls</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>International Business Machines Corporation</organization-name>
<address>
<city>Armonk</city>
<state>NY</state>
</address>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>William A. Kinnaman, Jr.</name-1>
<name-2>IBM Corporation - M/S P386</name-2>
<address>
<address-1>2455 South Road</address-1>
<city>Poughkeepsie</city>
<state>NY</state>
<postalcode>12601</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The invention relates to the control of servers which process client work requests in a computer system on the basis of resource consumption. Each server contains multiple server instances (also called &ldquo;execution units&rdquo;) which execute different client work requests in parallel. A workload manager determines the total number of server containers and server instances in order to achieve the goals of the work requests. The number of server instances started in each server container depends on the resource consumption of the server instances in each container and on the resource constraints, service goals and service goal achievements of the work units to be executed. At predetermined intervals during the execution of the work units the server instances are sampled to check whether they are active or inactive. Dependent on the number of active server instances the number of server address spaces and server instances is repeatedly adjusted to achieve an improved utilization of the available virtual storage and an optimization of the system performance in the execution of the application programs. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The invention relates to a method and apparatus to be used in a computer system with an operating system having server regions which are managed by a workload manager to provide resources for processing work units received from application programs. The invention also relates to a program and program product. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> In computer systems workload management is a concept whereby units of work that are managed by an operating system are organized into classes (referred to as service classes) which have assigned system resources in accordance with predefined goals. Resources are reassigned from a donor class to a receiver class if the improvement in performance of the receiver class resulting from such reassignment exceeds the degradation in performance of the donor class. Thus, reassignment takes place if there is a net positive effect in performance as determined by predefined performance criteria. Workload management of this type differs from resource management performed by most known operating systems. The assignment of resources is determined not only by its effect on the work units to which the resources are reassigned, but also by its effect on the work units from which they are taken. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Server management combines the effect of workload management with systems in which incoming work requests are placed in a queue for assignment to an available server. Since the frequency at which incoming requests arrive may not be readily controlled, the principal means of controlling the system performance of systems which use work request queues is control of the number of servers. Server management starts and stops servers in a system in compliance with the goal achievement of other work units executing in the system. Server management will only start a server if the performance of other work units is not degraded and will remove servers if more work requests of upper service classes demand resources which are allocated to a server in order to achieve their goals. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Workload and server management of this type are, for example, disclosed in the following patents, incorporated herein by reference: </paragraph>
<paragraph id="P-0007" lvl="2"><number>&lsqb;0007&rsqb;</number> U.S. Pat. No. 5,504,894 to D. F. Ferguson et al., entitled &ldquo;Workload Manager for Achieving Transaction Class Response Time Goals in a Multiprocessing System&rdquo;; </paragraph>
<paragraph id="P-0008" lvl="2"><number>&lsqb;0008&rsqb;</number> U.S. Pat. No. 5,473,773 to J. D. Aman et al., entitled &ldquo;Apparatus and Method for Managing a Data Processing System Workload According to Two or More Distinct Processing Goals&rdquo;; </paragraph>
<paragraph id="P-0009" lvl="2"><number>&lsqb;0009&rsqb;</number> U.S. Pat. No. 5,537,542 to C. K. Eilert et al., entitled &ldquo;Apparatus and Method for Managing a Server Workload According to Client Performance Goals in a Client/Server Data Processing System&rdquo;; </paragraph>
<paragraph id="P-0010" lvl="2"><number>&lsqb;0010&rsqb;</number> U.S. Pat. No. 5,974,462 to C. K. Eilert et al., entitled &ldquo;Method and Apparatus for Controlling the Number of Servers in a Client/Server System&rdquo;; and </paragraph>
<paragraph id="P-0011" lvl="2"><number>&lsqb;0011&rsqb;</number> U.S. Pat. No. 5,675,739 to C. K. Eilert et al., entitled &ldquo;Apparatus and Method for Managing a Distributed Data Processing System Workload According to a Plurality of Distinct Processing Goal Types&rdquo;. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In the known systems the workload management components consider a server as an entity disregarding the fact that the server itself can consist of resources and multiple independent execution units or server instances such as, for example, processes scheduling multiple execution threads. In known computer systems the system programmer creating the operating system for controlling the system or the application programmer creating the server application is responsible for determining the number of parallel execution units or server instances which can execute in a server. The operating system and the workload management component control the effect of the total number of servers with respect to the total system performance and the performance achieved by work units executing in different service classes. They do not manage the effect of balancing execution units per server. For the system programmer it is often difficult to determine a suitable number of execution units per server due to a lack of knowledge of the actual resource constraints to which the server itself is exposed. An application programmer may know about resource constraints of the server but may not be aware of the way the server is utilized at execution time. For example, the developers very often don&apos;t know the actual execution environment. The resource consumption may be influenced by the amount of data to be processed. Therefore, adjusting the number of execution units is very often not optimal or requires a lengthy tuning process by skilled IT personnel. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> It is an object of the invention to control the number of server instances in server address spaces on the basis of the resource consumption. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> It is also an object of the invention to optimize the utilization of the available virtual storage and to improve the system performance in the execution of the application programs. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> It is another object of the invention to allow an optimal management of the number of servers in order to achieve the defined performance goals with a minimized resource consumption of server address spaces in the operating system. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> In particular, it is a further object of the invention to evaluate and control the resource usage of the server address spaces at execution time. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> The environment of the invention is a computer system controlled by an operating system which comprises a pool of servers to service work requests issued by application programs and inserted in work queues. The servers represent sub-components, herein called server instances, in a server address space which is also called a server container. The number of server instances is managed on the basis of both the service classes of the queued work requests and the service classes of competing work in the computer system wherein a service class is a collection of similar work units for which a performance goal has been defined. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> The invention, as defined in the claims, allows managing the server instances of the server address spaces based on their resource consumption. The server instances in a server container are sampled at execution time to determine the resource usage of the server instances which are active during a predetermined sampling interval. The sampled data is evaluated to determine the current resource consumption of the computer system in executing the requested work units. A calculation is performed to determine the number of server instances per server address space. The result is used to manage the number of servers in order to achieve the defined performance goals, to minimize the resource consumption of the server container and to improve the system performance in the execution of application programs.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> An embodiment of the invention is subsequently described with reference to drawings in which: </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram of an example of the invention embodied in the operating system of a computer system; </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a schematic representation of the server region in the system of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a logic flow diagram representing method steps of an embodiment of the invention; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flow diagram representing method steps of the workload management in the operating system of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a logic flow diagram representing method steps and functions of an improved workload control according to the invention; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> plots representing the relationship between the available virtual storage and the server instances per address space as used in the embodiment of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; and </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a plot representing the relationship between the utilization of the local lock and the server instances per address space as used in the embodiment of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF A PREFERRED EMBODIMENT </heading>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a computer system <highlight><bold>100</bold></highlight> which is controlled by an operating system <highlight><bold>101</bold></highlight> such as, for example, the IBM z/OS operating system. The operating system <highlight><bold>101</bold></highlight> executes the steps subsequently described. The computer system <highlight><bold>100</bold></highlight> further comprises an application environment <highlight><bold>111</bold></highlight> which represents the components which are assigned to service the execution of an application program. Except for the enhancements provided by the present invention, computer system <highlight><bold>100</bold></highlight> corresponds to that one disclosed in U.S. Pat. No. 5,675,739, the specification of which is incorporated herein by reference. Although not shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the computer system <highlight><bold>100</bold></highlight> may be one of a plurality of interconnected computer systems that are similarly managed and make up a sysplex. The general server management concept as used by the described embodiment is disclosed in U.S. Pat. No. 5,974,462, the specification of which is incorporated herein by reference. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> A workload manager <highlight><bold>102</bold></highlight>, which is a component of the operating system <highlight><bold>101</bold></highlight>, provides operating system services for a work manager <highlight><bold>130</bold></highlight> to define one or more work queues <highlight><bold>132</bold></highlight> which represent the workload to be executed. The work manager <highlight><bold>130</bold></highlight> receives work requests <highlight><bold>131</bold></highlight> through a data transmission facility <highlight><bold>120</bold></highlight> from outside the computer system <highlight><bold>100</bold></highlight>. The work manager <highlight><bold>130</bold></highlight> transfers the work requests <highlight><bold>131</bold></highlight> to the workload manager <highlight><bold>102</bold></highlight> on behalf of application programs herein also called clients. A work queue <highlight><bold>132</bold></highlight> is created for all work requests <highlight><bold>131</bold></highlight> of the same type. The administrator of the operating system <highlight><bold>101</bold></highlight> classifies work requests <highlight><bold>131</bold></highlight> to service classes and determines for this purpose the type of the work requests <highlight><bold>131</bold></highlight>. The service classes correspond to service goals based on performance criteria. The service classes have a hierarchical relationship to one another. Service classes at the upper level contain work requests with strict performance criteria such as short execution time. In addition, the work queues have assigned importance levels which reflect their importance in relation to other work queues. For example, time-critical applications have a higher importance level than archive updating applications. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> The workload manager <highlight><bold>102</bold></highlight> initially starts one or more server instances <highlight><bold>134</bold></highlight> of a plurality of possible server instances to service work requests <highlight><bold>131</bold></highlight> which are included in a work queue <highlight><bold>132</bold></highlight>. The workload manager <highlight><bold>102</bold></highlight> uses server definitions which are stored with its performance goals in a shared data facility <highlight><bold>110</bold></highlight> to start a server address space <highlight><bold>133</bold></highlight> which is herein also called a server container. There may be a plurality of server address spaces <highlight><bold>133</bold></highlight> active at a certain point of time. The address space <highlight><bold>133</bold></highlight> started by the workload manager <highlight><bold>102</bold></highlight> contains one or more server instances <highlight><bold>134</bold></highlight> which may also be called server tasks, server threads or execution units. A server instance <highlight><bold>134</bold></highlight> obtains a work request <highlight><bold>131</bold></highlight> from a work queue <highlight><bold>132</bold></highlight>, processes the request <highlight><bold>131</bold></highlight> and checks the work queue <highlight><bold>132</bold></highlight> for the next request <highlight><bold>131</bold></highlight>, and repeats these steps until the workload manager <highlight><bold>102</bold></highlight> tells the server instances to terminate. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> The operating system <highlight><bold>101</bold></highlight> comprises a goal adjustment component <highlight><bold>103</bold></highlight> which includes a server manager <highlight><bold>104</bold></highlight> the function of which is to manage the total number of server instances <highlight><bold>134</bold></highlight> in two different ways. In the first way which is described in U.S. Pat. No. 5,974,462 the server manager <highlight><bold>104</bold></highlight> uses a fixed number of server instances <highlight><bold>134</bold></highlight> for each server address space <highlight><bold>133</bold></highlight> to calculate the total number of server instances <highlight><bold>134</bold></highlight> which are required and which can be afforded to service the work requests <highlight><bold>131</bold></highlight>. Each server address space <highlight><bold>133</bold></highlight> can be considered as a container which operates similarly to the computer system <highlight><bold>100</bold></highlight> in providing resources for executable sub-components. By using a fixed number of server instances <highlight><bold>134</bold></highlight> per server address space <highlight><bold>133</bold></highlight>, the resource consumption of the application environment <highlight><bold>111</bold></highlight> may not be optimal. For example, the actual execution environment is not known in advance and the resource consumption may be influenced by the amount of data to be processed. This situation is improved by a second way to manage the total number of servers according to the invention. The second way manages the number of server instances <highlight><bold>134</bold></highlight> for the server address spaces <highlight><bold>133</bold></highlight> of a work queue <highlight><bold>132</bold></highlight> and thus optimizes the resource consumption of the server address spaces <highlight><bold>133</bold></highlight> and of the operating system <highlight><bold>101</bold></highlight>. For this purpose the operating system <highlight><bold>101</bold></highlight> comprises a server instance/task/thread manager <highlight><bold>140</bold></highlight> which controls the resource consumption of the server instances <highlight><bold>134</bold></highlight> while serving the work requests <highlight><bold>131</bold></highlight> of the work queue <highlight><bold>132</bold></highlight>. A sampler <highlight><bold>141</bold></highlight> detects at execution time the resources provided by the server address spaces <highlight><bold>133</bold></highlight> which are registered in a resource consumption evaluator component <highlight><bold>142</bold></highlight>. The result of the resource consumption evaluation is indicated to a server instance optimizer component <highlight><bold>143</bold></highlight> which calculates the optimal number of server instances per server address space <highlight><bold>143</bold></highlight> and provides this result to the server manager <highlight><bold>104</bold></highlight> of the goal adjustment component <highlight><bold>103</bold></highlight>. The result of this calculation is used by the server manager <highlight><bold>104</bold></highlight> as a basis for a determination of the total number of servers <highlight><bold>134</bold></highlight> and the number of server address spaces <highlight><bold>133</bold></highlight> required. It urges the workload manager <highlight><bold>102</bold></highlight> either to start additional server address spaces <highlight><bold>133</bold></highlight>, or to initiate the start of additional server instances <highlight><bold>134</bold></highlight> per server address space <highlight><bold>133</bold></highlight>, or to terminate server instances <highlight><bold>134</bold></highlight> or server address spaces <highlight><bold>133</bold></highlight>. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows the server environment of the computer system <highlight><bold>100</bold></highlight> in more detail. All servers of an application are called an application environment <highlight><bold>111</bold></highlight> comprising an application environment definition <highlight><bold>113</bold></highlight> which is stored in a shared data facility <highlight><bold>110</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>). The application environment definition <highlight><bold>113</bold></highlight> includes an identifier used by the work manager <highlight><bold>130</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>) to identify the application program which issued the work requests. The application environment definition <highlight><bold>111</bold></highlight> further includes a server definition which is used by the workload manager <highlight><bold>102</bold></highlight> to start server address spaces <highlight><bold>133</bold></highlight> containing the server instances <highlight><bold>134</bold></highlight> which process the work requests of the application program. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The application environment definition <highlight><bold>111</bold></highlight> also allows the application program to define a maximum number of server instances <highlight><bold>134</bold></highlight> to be started by the workload manager to service that application, further a minimum number of server instances <highlight><bold>134</bold></highlight> being always available and an indication how that minimum should be distributed over multiple work queues created for the application environment <highlight><bold>111</bold></highlight>. A work queue <highlight><bold>132</bold></highlight> is created as a result of the work classification process initiated by the work manager <highlight><bold>130</bold></highlight>. The classification rules are based on the service goals. They are defined by the administrator of the computer system <highlight><bold>100</bold></highlight> and stored in the shared data facility <highlight><bold>110</bold></highlight>. The administrator associates the work requests <highlight><bold>131</bold></highlight> with service classes according to the service goals and the importance values. The work manager <highlight><bold>130</bold></highlight> classifies all work requests with the assistance of workload manager <highlight><bold>102</bold></highlight> on the basis of the stored service goals and the importance values. The workload manager <highlight><bold>102</bold></highlight> inserts the work requests <highlight><bold>131</bold></highlight> into a work queue <highlight><bold>132</bold></highlight>. A new work queue <highlight><bold>132</bold></highlight> is created whenever the classification process assigns a new service class for a work request <highlight><bold>131</bold></highlight>. The result is a hierarchy of service classes each assigned to a work queue. In this hierarchy the service class having strict service goals and a high importance value represents an upper level service class while a service class having low service goals and a low importance value is assigned to a lower level service class. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> All work queues <highlight><bold>132</bold></highlight> are served by one or more server address spaces <highlight><bold>133</bold></highlight>, each of which contains one or multiple server instances <highlight><bold>134</bold></highlight>. The combination of a work queue <highlight><bold>132</bold></highlight> and the server instances <highlight><bold>134</bold></highlight> serving that work queue <highlight><bold>132</bold></highlight> is named a transaction environment <highlight><bold>112</bold></highlight> because all server instances <highlight><bold>134</bold></highlight> execute work requests of the same service class. The application environment definition <highlight><bold>113</bold></highlight> can also determine the permitted number of parallel server instances <highlight><bold>134</bold></highlight> for each server address space <highlight><bold>133</bold></highlight>. In that case the server instances <highlight><bold>134</bold></highlight> are predefined and the server instance/task/thread manager <highlight><bold>140</bold></highlight> is not in effect. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows the connection of the work queue <highlight><bold>132</bold></highlight> and the server instances <highlight><bold>134</bold></highlight> as well as the operations of the components <highlight><bold>102</bold></highlight>, <highlight><bold>103</bold></highlight> and <highlight><bold>140</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. In step <highlight><bold>320</bold></highlight> the workload manager <highlight><bold>102</bold></highlight> determines the current work queue delay in the transaction environment <highlight><bold>112</bold></highlight> and step <highlight><bold>321</bold></highlight> takes the work queue delay to calculate the total number of server instances <highlight><bold>134</bold></highlight> required for that transaction environment <highlight><bold>112</bold></highlight>. Step <highlight><bold>322</bold></highlight> converts the required number of server instances <highlight><bold>134</bold></highlight> into the required number of server address spaces <highlight><bold>133</bold></highlight>. In step <highlight><bold>323</bold></highlight> a recommendation is made to the workload manager <highlight><bold>102</bold></highlight> on the number of server instances <highlight><bold>134</bold></highlight> and the number of server address spaces <highlight><bold>133</bold></highlight>. By performing step <highlight><bold>324</bold></highlight> the workload manager <highlight><bold>102</bold></highlight> then starts a corresponding number of server address spaces and binds them to the work queue <highlight><bold>132</bold></highlight> and simultaneously indicates a corresponding number of server instances <highlight><bold>134</bold></highlight> in each of these address spaces. In the representation shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference> two server address spaces <highlight><bold>133</bold></highlight> are started and bound to work queue <highlight><bold>132</bold></highlight> each comprising <highlight><bold>5</bold></highlight> server instances which are executing in parallel work units selected from the work queue <highlight><bold>132</bold></highlight>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> During the execution of the work units step <highlight><bold>341</bold></highlight> is performed to learn of the contention on both server address spaces <highlight><bold>133</bold></highlight> by sampling the server instances <highlight><bold>134</bold></highlight> of both address spaces to check whether they are active or inactive. Step <highlight><bold>341</bold></highlight> is performed by components <highlight><bold>141</bold></highlight> and <highlight><bold>142</bold></highlight> at predetermined time intervals which are controlled by the operating system <highlight><bold>101</bold></highlight>. In step <highlight><bold>342</bold></highlight> an updated number of server instances <highlight><bold>134</bold></highlight> per server address space is determined and provided to steps <highlight><bold>322</bold></highlight> and <highlight><bold>323</bold></highlight>. By repeating step <highlight><bold>322</bold></highlight> the number of server address spaces <highlight><bold>133</bold></highlight> is modified or confirmed on the basis of the number of server instances <highlight><bold>134</bold></highlight> determined in step <highlight><bold>342</bold></highlight>, and by repeating step <highlight><bold>323</bold></highlight> a recommendation made to the workload manager <highlight><bold>102</bold></highlight>. Dependent on the number of active server instances this recommendation may confirm the current status or may include a reduction of the number of server address spaces <highlight><bold>133</bold></highlight> and server instances <highlight><bold>134</bold></highlight> if fewer server instances <highlight><bold>134</bold></highlight> are active than were initially started. In the latter case, step <highlight><bold>324</bold></highlight> is repeated to stop the inactive server instances <highlight><bold>134</bold></highlight> and, if appropriate, stop and unbind a server address space which is no longer required. As a result, virtual storage is made available for being used by other application environments <highlight><bold>111</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Furthermore, the result of steps <highlight><bold>341</bold></highlight> and <highlight><bold>342</bold></highlight> may indicate a shortage of service instances. In that case, the steps <highlight><bold>322</bold></highlight>, <highlight><bold>323</bold></highlight>, <highlight><bold>324</bold></highlight> are repeated to increase the number of server address spaces <highlight><bold>133</bold></highlight> and therewith to increase also the number of server instances accordingly. The difference between such change of the number of server address spaces <highlight><bold>133</bold></highlight> and the initial determination of the number of server address spaces <highlight><bold>133</bold></highlight> is that an optimization of managing the available resources according to their actual need is achieved during execution time. The result of the optimization which is performed repeatedly, for example, every 10 seconds an overall improvement of the system performance in the execution of the application programs. <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows the logic flow to assess possibilities of improving the system performance by starting additional server instances <highlight><bold>134</bold></highlight>. The logic flow shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is deployed when a queue delay has been identified as the major bottleneck for the service class to adjust. The mechanism to select performance bottlenecks is described in U.S. Pat. No. 5,974,462 which is herein incorporated by reference. By step <highlight><bold>441</bold></highlight>, a new number of server instances <highlight><bold>134</bold></highlight> is selected to be assessed. The number should be large enough to result in sufficient receiver value, as checked in step <highlight><bold>445</bold></highlight>, to make the change worthwhile. The number should be not so large that the value of additional server instances <highlight><bold>134</bold></highlight> is marginal, i.e., an increase of the number of server instances <highlight><bold>134</bold></highlight> does not significantly increase the total number of queued and running work requests <highlight><bold>131</bold></highlight>. By steps <highlight><bold>442</bold></highlight>, <highlight><bold>443</bold></highlight> and <highlight><bold>444</bold></highlight>, the effect of the new number of server instances <highlight><bold>134</bold></highlight> is calculated. A detailed description of these steps is disclosed in U.S. Pat. No. 5,974,462. By step <highlight><bold>443</bold></highlight> the current and projected queue delays are read from the queue delay graph stored in the workload manager <highlight><bold>102</bold></highlight>. The queue delay graph data is subject to a normalizing operation the result of which is index delta data which is suitable for further processing. In step <highlight><bold>444</bold></highlight> the index delta between the current and projected queue index is calculated. Step <highlight><bold>445</bold></highlight> checks the result of step <highlight><bold>444</bold></highlight> for sufficient receiver value provided by the additional number of server instances <highlight><bold>134</bold></highlight>. If there is sufficient receiver value, step <highlight><bold>451</bold></highlight> performs a check to determine whether a maximum limit of server instances <highlight><bold>134</bold></highlight> has been defined and whether the maximum number of server instances <highlight><bold>134</bold></highlight> for the application environment <highlight><bold>111</bold></highlight> is reached. If this check is negative, more servers can be started without violating the rules for the application environment <highlight><bold>111</bold></highlight>. The steps <highlight><bold>446</bold></highlight>, <highlight><bold>447</bold></highlight>, <highlight><bold>448</bold></highlight> and <highlight><bold>449</bold></highlight> are performed to find donors of server address spaces from a service class of the lowest level for which a performance decrease may be acceptable. If this is not the case, the service class of the next higher level is investigated for the same purpose. If a donor class is found it permits the start of a new server address space <highlight><bold>133</bold></highlight> for the receiver class. The mechanism to handle donor and receiver classes is described in U.S. Pat. No. 5,974,462. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> If a maximum limit for the number of server instances <highlight><bold>134</bold></highlight> is defined and the maximum number of server address spaces <highlight><bold>133</bold></highlight> is already started, it is not possible to start additional server address spaces <highlight><bold>133</bold></highlight>. By step <highlight><bold>452</bold></highlight> a check is made to test whether more than one work queue <highlight><bold>132</bold></highlight> has been created for the application environment <highlight><bold>111</bold></highlight>. If this is the case, it is possible to look for server address spaces <highlight><bold>133</bold></highlight> from another work queue <highlight><bold>132</bold></highlight> of the same application environment <highlight><bold>111</bold></highlight>. Step <highlight><bold>461</bold></highlight> is used to find a lower level work queue <highlight><bold>132</bold></highlight> which may be used as donor work queue for at least one additional server address space <highlight><bold>133</bold></highlight>. By step <highlight><bold>471</bold></highlight>, a check is made whether there is a net value to move one or more server address spaces <highlight><bold>133</bold></highlight> from the donor work queue <highlight><bold>132</bold></highlight> to the receiver work queue <highlight><bold>132</bold></highlight>. As described in U.S. Pat. No. 5,675,739, this may be determined by using one or more of different criteria. The check includes whether the donor is projected to meet its goals after the resource allocation, or whether there is net gain in the combined performance indexes of donor and receiver. If there is a net value in the change, step <highlight><bold>481</bold></highlight> reduces the projected number of server address spaces <highlight><bold>133</bold></highlight> from the donor work queue or queues <highlight><bold>132</bold></highlight> and increases the number of server address spaces <highlight><bold>133</bold></highlight> of the receiver work queue or queues <highlight><bold>132</bold></highlight> accordingly. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows the logic flow to calculate the number of server instances <highlight><bold>134</bold></highlight> per server address space <highlight><bold>133</bold></highlight>. The result of this calculation is a projected count of server instances. Before this count is used in the process described above with reference to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, it is applied to the server address spaces <highlight><bold>133</bold></highlight>. For this reason the projected count is provided to the workload manager <highlight><bold>102</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>) to inform the server address spaces <highlight><bold>133</bold></highlight> on the adjustment of the number of server instances <highlight><bold>134</bold></highlight>. The workload manager <highlight><bold>102</bold></highlight> compares the projected count against the number of started server instances <highlight><bold>134</bold></highlight>. If the result makes it necessary to reduce the number of server instances, the workload manager <highlight><bold>102</bold></highlight> tells excessive server instances <highlight><bold>134</bold></highlight> of a server address space <highlight><bold>133</bold></highlight> to be removed. If the result makes it necessary to increase the number of server instances <highlight><bold>134</bold></highlight>, the workload manager <highlight><bold>102</bold></highlight> informs the server address space <highlight><bold>133</bold></highlight> to start additional server instances <highlight><bold>134</bold></highlight>. The server address spaces <highlight><bold>133</bold></highlight> and the server instances <highlight><bold>134</bold></highlight> apply to the mechanism for reducing and increasing the number of server instances <highlight><bold>134</bold></highlight>. The mechanism described in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> uses the started number of server instances <highlight><bold>134</bold></highlight> per server address space <highlight><bold>133</bold></highlight>. The mechanism in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> depends on sampled data about the resource consumption of server instances <highlight><bold>134</bold></highlight> of the server address spaces <highlight><bold>133</bold></highlight> at execution time. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Server address spaces <highlight><bold>133</bold></highlight> provide resources for executable server instances <highlight><bold>134</bold></highlight> similar as the computer system <highlight><bold>100</bold></highlight> provides resources for the usable address spaces <highlight><bold>133</bold></highlight>. A server address space provides virtual storage that is shared among the programs executed in the address space. In a computer system virtual storage is limited. It depends on the number of bits available in the operating system to address storage and it is limited in order to keep address tables small. Other resources, like common data structures, are locked before the programs update them. The proposed mechanism measures the virtual storage consumption and the utilization of the address space lock to assess the resource consumption of the server address space <highlight><bold>133</bold></highlight>. The data is sampled by component <highlight><bold>141</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>) and plotted on three plots as shown in <cross-reference target="DRAWINGS">FIGS. 6 and 7</cross-reference>. The mechanism learns about the actual resource consumption by component <highlight><bold>142</bold></highlight> through adding more data to the plots over time. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows two plots <highlight><bold>601</bold></highlight>, <highlight><bold>602</bold></highlight> for tracking virtual storage consumption used by the embodiment of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. These plots provide accounting of the allocation of storage to the application programs at execution time. Both plots <highlight><bold>601</bold></highlight>, <highlight><bold>602</bold></highlight> show the available virtual storage as the ordinate (y) value. The plot <highlight><bold>601</bold></highlight> relates to the currently active server instances <highlight><bold>134</bold></highlight> as indicated by the abscissa (x) value. The plot <highlight><bold>602</bold></highlight> relates to the number of started server instances <highlight><bold>134</bold></highlight> as indicated by the abscissa (x) value. The abscissas of both plots <highlight><bold>601</bold></highlight>, <highlight><bold>602</bold></highlight> are related to the server instances per server address space <highlight><bold>133</bold></highlight> but the plots represent in fact the mean values of all sample data generated for all server address spaces <highlight><bold>133</bold></highlight> of a transaction environment <highlight><bold>112</bold></highlight>. The plots <highlight><bold>601</bold></highlight>, <highlight><bold>602</bold></highlight> are stored in the resource consumption evaluation component <highlight><bold>142</bold></highlight> and from there selectively read for being used as subsequently described. Associated with each of the plots <highlight><bold>601</bold></highlight>, <highlight><bold>602</bold></highlight> are predetermined threshold values <highlight><bold>603</bold></highlight>-<highlight><bold>606</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In step <highlight><bold>531</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 5</cross-reference>) the plots <highlight><bold>601</bold></highlight>, <highlight><bold>602</bold></highlight> are compared and the plot with the steeper slope is selected for the following assessment. To determine the present virtual storage utilization, step <highlight><bold>532</bold></highlight> reads the ordinate value for the number of server instances according to the selected virtual storage plot. This value is used as one of the parameters in step <highlight><bold>534</bold></highlight> to determine the action to be taken. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The active server instances <highlight><bold>134</bold></highlight> are sampled for local lock utilization. <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates a lock usage graph <highlight><bold>701</bold></highlight> the data of which is stored in the component <highlight><bold>142</bold></highlight>. The ordinate (y) of this graph shows the percentage of samples which found the local lock function being used by the sampled server instance <highlight><bold>134</bold></highlight> during the sampling interval, while the abscissa (x) shows the average number of active server instances during the sampling period. Graph <highlight><bold>701</bold></highlight> is associated with threshold values <highlight><bold>702</bold></highlight>, <highlight><bold>702</bold></highlight>. By step <highlight><bold>533</bold></highlight> the lock utilization data of graph <highlight><bold>601</bold></highlight> is read to perform the check by a step <highlight><bold>534</bold></highlight>. In this step the virtual storage utilization of the selected plot <highlight><bold>601</bold></highlight> or <highlight><bold>602</bold></highlight> and the local lock data for the active server instances are compared against threshold values <highlight><bold>603</bold></highlight>-<highlight><bold>606</bold></highlight> and <highlight><bold>702</bold></highlight>, <highlight><bold>703</bold></highlight>. The threshold values <highlight><bold>603</bold></highlight>, <highlight><bold>605</bold></highlight> and <highlight><bold>703</bold></highlight> identify points beyond which (above which for points <highlight><bold>603</bold></highlight> and <highlight><bold>605</bold></highlight> and below which for point <highlight><bold>703</bold></highlight>) the number of server instances <highlight><bold>134</bold></highlight> is increased, while the threshold values <highlight><bold>604</bold></highlight>, <highlight><bold>606</bold></highlight> and <highlight><bold>702</bold></highlight> identify points beyond which (below which for points <highlight><bold>604</bold></highlight> and <highlight><bold>606</bold></highlight> and above which for point <highlight><bold>702</bold></highlight>) the number of server instances <highlight><bold>134</bold></highlight> is decreased. The area between the two threshold values of each of the plots <highlight><bold>601</bold></highlight>, <highlight><bold>602</bold></highlight> and <highlight><bold>601</bold></highlight> indicates that no action is taken. Thus, if step <highlight><bold>534</bold></highlight> indicates that the threshold value <highlight><bold>604</bold></highlight>, <highlight><bold>606</bold></highlight> or <highlight><bold>702</bold></highlight> for any plot <highlight><bold>601</bold></highlight>, <highlight><bold>602</bold></highlight> or <highlight><bold>701</bold></highlight> has been crossed, the number of server instances <highlight><bold>134</bold></highlight> is decreased. Otherwise, if step <highlight><bold>534</bold></highlight> indicates that the plot compared is beyond threshold value <highlight><bold>603</bold></highlight>, <highlight><bold>605</bold></highlight> or <highlight><bold>703</bold></highlight>, a calculation is made to add more server instances. The calculation extends to the data of all server address spaces <highlight><bold>133</bold></highlight> of a transaction environment <highlight><bold>112</bold></highlight>. When all server instances <highlight><bold>134</bold></highlight> execute work requests which are classified to the same service class, it may be assumed that the behavior of these server instances <highlight><bold>134</bold></highlight> is similar. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> If it is appropriate to reduce the number of server instances, the mechanism attempts to find a smaller number of server instances which satisfy the check made in step <highlight><bold>534</bold></highlight>. By step <highlight><bold>535</bold></highlight> the number of server instances is stepwise reduced by one starting at the currently started number of server instances. In each step data for the projected number of server instances is obtained from the plots <highlight><bold>601</bold></highlight> or <highlight><bold>602</bold></highlight>, and a check similar to step <highlight><bold>534</bold></highlight> is made to find out whether the projected number of server instances meets the defined resource requirements. The mechanism stops when the check indicates that projected number of server instances meets the resource requirements or when the number of projected server instances is 50% of the started number of server instances. By the latter limit the system is protected against very disruptive changes. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> In the case that step <highlight><bold>534</bold></highlight> indicates that the available virtual storage is above the threshold value <highlight><bold>603</bold></highlight> or <highlight><bold>605</bold></highlight>, or the local lock utilization below the threshold value <highlight><bold>703</bold></highlight>, a higher number of server instances <highlight><bold>134</bold></highlight> than currently started may be determined. Step <highlight><bold>536</bold></highlight> checks the employment status of the server address spaces <highlight><bold>133</bold></highlight>. This test should ensure that enough server instances <highlight><bold>134</bold></highlight> per server address space <highlight><bold>133</bold></highlight> are active to base the decision on stable sampled data. Step <highlight><bold>536</bold></highlight> may determine whether at least 80% of the server instances <highlight><bold>134</bold></highlight> of one server address space <highlight><bold>133</bold></highlight> are active. If this true, step <highlight><bold>537</bold></highlight> performs a check whether a maximum limit of server instances <highlight><bold>134</bold></highlight> for the application environment <highlight><bold>111</bold></highlight> has been defined. If this is not the case, there are no limitations for increasing the number of server instances by step <highlight><bold>571</bold></highlight>. If step <highlight><bold>536</bold></highlight> indicates that the employment status of the server address spaces <highlight><bold>133</bold></highlight> is lower than, for example, 80% no action is taken as indicated at <highlight><bold>538</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> At step <highlight><bold>571</bold></highlight>, a calculation is made to stepwise increase the number of server instances <highlight><bold>134</bold></highlight> per server address space <highlight><bold>133</bold></highlight> by one. The calculation uses the data from the stored plots <highlight><bold>601</bold></highlight>, <highlight><bold>602</bold></highlight> and makes sure that the resource consumption of the projected number of server instances does not violate the rules of check of step <highlight><bold>534</bold></highlight> with regard to the stored threshold values. If there is no value plotted for a higher number of server instances <highlight><bold>134</bold></highlight> than the currently started number of server instances, the ordinate is interpolated from the ordinates of the two highest number of server instances as indicated by the abscissa values of the plots for which sample data is available. In the embodiment described herein the number of server instances will not be increased by more than 20% of the currently started number of server instances <highlight><bold>134</bold></highlight> while the minimum increment is one server instance. If step <highlight><bold>537</bold></highlight> indicates that there is a maximum limit of server instances defined for the application environment <highlight><bold>111</bold></highlight> as indicated by the application environment definition <highlight><bold>113</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 2</cross-reference>), step <highlight><bold>572</bold></highlight> calculates the maximum of server instances <highlight><bold>134</bold></highlight> per server address space <highlight><bold>133</bold></highlight>. Based on the result of this calculation the step <highlight><bold>571</bold></highlight> is performed to stepwise increase the number of server instances <highlight><bold>134</bold></highlight> per server address space <highlight><bold>133</bold></highlight>. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Step <highlight><bold>537</bold></highlight> tests whether a maximum limit for the number of server instances <highlight><bold>134</bold></highlight> has been defined. If a maximum limit has been defined, this limit applies to all server instances <highlight><bold>134</bold></highlight> for all transaction environments <highlight><bold>112</bold></highlight> or work queues <highlight><bold>132</bold></highlight> of an application environment <highlight><bold>111</bold></highlight>. The difficulty is now to ensure that the mechanism described in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> at <highlight><bold>461</bold></highlight> has enough server address spaces <highlight><bold>133</bold></highlight> which can potentially be moved between the work queues <highlight><bold>132</bold></highlight> of the application environment. The following calculation is used to determine an upper boundary for the server instances <highlight><bold>134</bold></highlight> per server address space <highlight><bold>133</bold></highlight>: </paragraph>
<paragraph id="P-0047" lvl="2"><number>&lsqb;0047&rsqb;</number> srv_lm &equals;mn_num_of_srv/max(2, num_of_work_queues) </paragraph>
<paragraph id="P-0048" lvl="7"><number>&lsqb;0048&rsqb;</number> with: </paragraph>
<paragraph id="P-0049" lvl="2"><number>&lsqb;0049&rsqb;</number> srv_lm is the limit of server instances <highlight><bold>134</bold></highlight> which can be started for a server address space <highlight><bold>133</bold></highlight>; </paragraph>
<paragraph id="P-0050" lvl="2"><number>&lsqb;0050&rsqb;</number> mn_num_of_srv is the minimum number of server instances, this value is set to the half of the maximum limit if no minimum limit has been defined or the smaller value of the defined minimum and the maximum limit divided by two; </paragraph>
<paragraph id="P-0051" lvl="2"><number>&lsqb;0051&rsqb;</number> number_of_work_queues is the number of work queues <highlight><bold>132</bold></highlight> created for the application environment <highlight><bold>111</bold></highlight>. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The maximum calculation between two work queues <highlight><bold>132</bold></highlight> and the real number of work queues <highlight><bold>132</bold></highlight> for the application environment <highlight><bold>111</bold></highlight> is performed to ensure less disruptive adjustments in case the maximum number of server instances <highlight><bold>134</bold></highlight> is already started. If the maximum number of server <highlight><bold>134</bold></highlight> is already started, it is necessary to stop server instances <highlight><bold>134</bold></highlight> for the started server address spaces <highlight><bold>133</bold></highlight> and to start new server address spaces <highlight><bold>133</bold></highlight> so that enough server address spaces are available to perform step <highlight><bold>461</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. This change is disruptive to the number of available server instances <highlight><bold>134</bold></highlight> executing work requests because the number of work queues <highlight><bold>132</bold></highlight> is not predetermined and the excess number of server instances <highlight><bold>134</bold></highlight> must be stopped first before additional server address spaces <highlight><bold>133</bold></highlight> are started. This condition is necessary to ensure that for the application environment <highlight><bold>111</bold></highlight> the maximum number of server instances <highlight><bold>134</bold></highlight> is not exceeded. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> While the invention is disclosed with reference to the described embodiment, modifications or other implementations of the invention are within the scope of the invention as defined in the claims.</paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method for use in a computer system controlled by an operating system having server regions that are managed by a workload manager to provide resources for achieving service goals of work units received from application programs, said server regions including a number of server containers each containing a plurality of server instances operating in parallel, comprising the steps of: 
<claim-text>(a) sampling the server instances in a server container at execution time to obtain sample data; </claim-text>
<claim-text>(b) evaluating the sample data to determine the current resource consumption of the computer system in executing the work units; </claim-text>
<claim-text>(c) calculating on the basis of the current resource consumption a number of server instances per server container for executing the work units; and </claim-text>
<claim-text>(d) providing feedback to the workload manager based upon the calculated number of server instances per server container for adjusting the number of server instances in at least one server container. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> in which step (c) comprises the step of determining an optimal number of server instances, executing in parallel in each of the server containers, for executing the work units. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> in which the work units received from the application programs are assigned to service classes according to performance goals defined by the application programs, where at least some of the service classes have a hierarchical relationship to one another. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> in which the work units of each service class are arranged in a work queue and one or more of said work queues contain the work units of one application program and are associated with one server container. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference> in which the number of server instances per server container for executing the work units is managed on the basis of both the service classes of the queued work units and the service classes of competing work in the computer system. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> in which step (d) comprises the step of restricting the number of server instances in each server container on the basis of restrictions on the total number of server instances permitted for all server containers executing work units for one or more service classes. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference> in which step (d) comprises the step of providing feedback to the workload manager for a server container of an upper level, and further comprises the step of adjusting the number of server containers based on the number of active server instances in each of the server containers. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> in which the sample data represents the number of server instances that are active during a predetermined sampling interval. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> in which step (b) comprises the step of determining available virtual storage space on the basis of the number of active server instances per server container. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> in which step (b) comprises the step of determining available virtual storage space on the basis of the number of started server instances per server container. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> in which step (b) comprises the step of determining local lock usage on the basis of the number of active server instances per server container. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> in which step (c) comprises the steps of providing threshold values for current resource consumption and using said threshold values to permit or prevent an adjustment of the number of server instances in at least one of the server containers. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> in which steps (a) to (d) are repeated at predetermined time intervals during execution of the work units. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A computer program comprising program code means for performing all the steps of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> when said program is run on a computer system. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A computer program product comprising program code means stored on a computer readable medium for performing all the steps of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> when said program is run on a computer system. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. Apparatus in a computer system controlled by an operating system that includes a workload manager to provide resources for achieving service goals of work units received from multiple application programs, said operating system including a number of server containers each containing a plurality of server instances that operate in parallel to execute work units of multiple application programs, comprising: 
<claim-text>(a) means for sampling the server instances in a server container to obtain sample data; </claim-text>
<claim-text>(b) means for evaluating the sample data to determine the current resource consumption of the computer system in executing the work units; </claim-text>
<claim-text>(c) means for calculating on the basis of the current resource consumption a number of server instances per server container for executing the work units; and </claim-text>
<claim-text>(d) means for providing feedback to the workload manager based upon the calculated number of server instances per server container for adjusting the number of server instances in at least one server container. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> in which the means for calculating the number of server instance comprises means for determining an optimal number of server instances, executing in parallel in each of the server containers, for executing the work units. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, comprising means for assigning the work units received from the application programs to service classes according to performance goals defined by the application programs, where at least some of the service classes have a hierarchical relationship to one another. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> in which the work units of each service class are arranged in a work queue and one or more of said work queues contain the work units of one application program and are associated with one server container. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, comprising means for managing the number of server instances per server container for executing the work units on the basis of both the service classes of the queued work units and the service classes of competing work in the computer system. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> in which the means for providing feedback to the workload manager for adjusting the number of server instances comprises means for restricting the number of server instances in each server container on the basis of restrictions on the total number of server instances permitted for all server containers executing work units for one or more service classes. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference> in which the feedback providing means comprises means for providing feedback to the workload manager for a server container of an upper level, and the apparatus further comprises means for adjusting the number of server containers based on the number of active server instances in each of the server containers. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> in which the sample data represents the number of server instances that are active during a predetermined sampling interval. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> in which the evaluating means comprises means for determining available virtual storage space on the basis of the number of active server instances per server container. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> in which the evaluating means comprises means for determining available virtual storage space on the basis of the number of started server instances per server container. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> in which the evaluating means comprises means for determining local lock usage on the basis of the number of active server instances per server container. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> in which the calculating means comprises means for providing threshold values for current resource consumption and means for using said threshold values to permit or prevent an adjustment of the number of server instances in at least one of the server containers. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The apparatus of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference> in which the sampling, evaluating and calculating means are activated repeatedly at predetermined time intervals during execution of the work units.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005028A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005028A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005028A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005028A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005028A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005028A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030005028A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
