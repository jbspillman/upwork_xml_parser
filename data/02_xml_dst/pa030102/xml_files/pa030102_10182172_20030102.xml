<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004726A1-20030102-D00000.TIF SYSTEM "US20030004726A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004726A1-20030102-D00001.TIF SYSTEM "US20030004726A1-20030102-D00001.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004726</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10182172</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020725</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>00125914.2</doc-number>
</priority-application-number>
<filing-date>20001127</filing-date>
<country-code>EP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G10L021/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>704</class>
<subclass>273000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Access control arrangement and method for access control</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Meinrad</given-name>
<family-name>Niemoeller</family-name>
</name>
<residence>
<residence-non-us>
<city>Holzkirchen</city>
<country-code>DE</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Reinhart</given-name>
<family-name>Vogl</family-name>
</name>
<residence>
<residence-non-us>
<city>Muenchen</city>
<country-code>DE</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>BELL, BOYD &amp; LLOYD, LLC</name-1>
<name-2></name-2>
<address>
<address-1>P. O. BOX 1135</address-1>
<city>CHICAGO</city>
<state>IL</state>
<postalcode>60690-1135</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
<international-conventions>
<pct-application>
<document-id>
<doc-number>PCT/EP01/13609</doc-number>
<document-date>20011122</document-date>
<country-code>WO</country-code>
</document-id>
</pct-application>
</international-conventions>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A speech-controlled access control arrangement (<highlight><bold>1</bold></highlight>) comprising at least one access control device (<highlight><bold>3&prime;, 5&prime;, 7&prime;, 9</bold></highlight>&prime;) to release or block access, in particular to a delimited room (<highlight><bold>7, 9</bold></highlight>), technical device (<highlight><bold>3, 5</bold></highlight>) or data or telecommunications network, and a mobile speech input unit (<highlight><bold>11</bold></highlight>) connected to the access control device via a telecommunications connection, in particular a wire-free telecommunications connection. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> The invention relates to a method for access control according to the precharacterizing clause of claim 10 and also a corresponding access control arrangement. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The control of access to delimited physical areas, complicated technical devices with demanding operation and high risk potential in the event of erroneous operations and also to data or telecommunications networks constitutes a significant security aspect in the use of such areas or systems. With the increasing large number of areas or systems in daily life, to which particular access conditions apply, the number of keys and codes permitting access in each case and in the possession of many users increases sharply. Keeping them securely, on the one hand, and immediate and reliable access thereto, on the other hand, are therefore becoming increasingly problematic. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> For this reason, many attempts have been made to make life easier for the users by standardizing the &ldquo;keys&rdquo; needed for various rooms, devices, networks etc. However, first of all compatibility problems occur here between various access control systems with different security levels and, secondly, the consequences associated with a loss or theft of the &ldquo;key&rdquo; for the user, on the one hand, and for the systems secured by this one key, on the other hand, overall become more and more critical. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Work has therefore been carried out for a long time on possibilities of using biometric data about the users&mdash;for example the papillary lines, the retinal pattern or the voice or speech&mdash;for access control. In principle, these &ldquo;keys&rdquo; cannot be lost and are also relatively difficult to forge and, above all, their use is extremely simple for the user. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Electronic speaker verification or identification uses methods similar to those of voice recognition. However, their aim is not the conversion of the spoken word into text but in the identification or verification of a person on the basis of their speech. The known speaker verification systems are relatively complex and expensive and therefore have not become very widespread. This has also been added to by the problem that conventional speech recognition systems have to be initialized or trained to the user or users in a process also designated &ldquo;enrolment&rdquo;. This problem has a particularly detrimental effect when a user has to gain access or wishes to gain access to various rooms, buildings, devices, networks or the like by means of speaker identification and in each case has to train the individual system in advance. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> It is therefore an object of the invention to specify a speech-controlled access control system which is simple, can be implemented cost-effectively and is easy for the user or users to handle, and also a corresponding method for access control. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> With regard to its device aspect, this object is achieved by an access control arrangement having the features of claim 1 and, with regard to its method aspect, is achieved by a method having the features of claim 10. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The invention includes the basic idea of dividing up the overall sequence of the access control by speaker identification (from the speech input until the release or blocking of the access) between two subsystems or method subsequences, one of the subsystems or one of the method steps being useable for a large number of access control situations. What is concerned here is a mobile speech input unit, which carries out part of the speaker identification operation, while the other part of the overall arrangement&mdash;more precisely: a large number of possible overall arrangements&mdash;comprises an access control device in each case effecting the actual access control. In said device, another part of the speaker identification is carried out, and in particular, a dictionary used for the authorization of the user is also stored here. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> In a preferred configuration of the arrangement, the or each access control device comprises, in addition to an appropriate control device dictionary store, a control word transmitting unit for transmitting words from the stored dictionary to the speech input unit, and the speech input unit correspondingly has a control word receiving unit for receiving the control words, a microphone and a low-frequency stage connected downstream for the speech input, a speaker feature extraction stage (speech recognizer) and a speaker feature transmitting stage for transmitting an extracted speaker feature set to the respective access control device. The latter additionally has an appropriate speaker feature receiving stage, a speaker feature reference store for storing speaker features of predetermined users and also a speaker feature comparison unit which, on the basis of the result of a comparison between the currently determined speaker features with previously stored speaker features, produces an access release signal or else an access blocking signal. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The mobile speech input unit expediently comprises a buffer, connected between the control word receiving unit and the speaker feature extraction stage or the speech recognizer, for the selected control or identification words received from the access control device, and likewise the access control device expediently has a speaker feature buffer, connected between the speaker feature receiving stage and the speaker feature comparison unit, for the speaker features received from the speech input unit. These buffers can be permanent or semipermanent and, for one and the same access control device, interacting with one and the same speech input unit in an overall system comprising a plurality of speech input units and/or access control devices, depending on the actual system configuration, may ensure more or less long-term storage of a control or identification word set or the features of a speaker wishing to gain access. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> According to the above, the speech input and the feature extraction take place in the mobile speech input unit. However, in the preferred embodiment, the knowledge about the words which are to be spoken by a user wishing to gain access for the purpose of speaker verification is not contained in said mobile speech input unit. As soon as a speech input unit is connected to an access control unit, the speech input unit transmits, for example, a user name or user code to the access control device. The latter transmits back words or a text, using which the speaker verification for the user wishing to gain access is to be carried out. (These words or this text will be referred to here in brief as &ldquo;control words&rdquo;.) In a preferred embodiment, these control words are selected from a predefined list (dictionary) via a random generator. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> The next task of the mobile speech input unit is then to present these words spoken by the user in a verification dialog, to request the user to input speech and to record his spoken work. For this purpose, displays known per se with menu guidance and audio front ends are used. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Then, using speech recognition structures and algorithms known per se&mdash;in particular on the basis of a hidden Markov model or neural network&mdash;the aforementioned extraction of the speaker features is carried out. These features are then transmitted back to the access control device and are there compared with previously stored speaker feature sets or vectors of authorized speakers&mdash;in particular with the speaker feature vector of the specific user identified by the name or user code. A classification stage of the access device, carried out by using a threshold value discriminator, then decides, as a result of a statistical evaluation, whether the speech patterns are sufficiently similar to each other and, as a result of this comparison, outputs an access release signal or access blocking signal. It goes without saying that the arrangement can be trained or initialized for an individual authorized user and access is released only for the latter; in general, however, the speaker feature reference store of the access control device will have a plurality of speaker feature storage areas which can be addressed in each case via a user name or user code. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> The communication between the speech input unit and the access control device or the access control devices expediently takes place by means of wire-free communication, in particular on a radio link. Currently preferred is a radio link based on the bluetooth or DECT standard (for example in the case of a cordless telephone) and the use of a mobile radio network with speech and data transmission in accordance with the GSM or UMTS standard. In this case, in particular the dictionary transmitting unit and the speaker feature receiving stage of the respective access control device, and the dictionary receiving unit and the speech feature transmitting stage of the speech input unit are constructed as radio transmitting and receiving units. In principle, the use of tried and tested infrared interfaces is also possible.</paragraph>
</summary-of-invention>
<detailed-description>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In the preferred embodiment of the speaker feature extraction stage with a phoneme-based hidden Markov model, it is not necessary for the previously stored speaker features used as a reference to have been obtained from the words currently used as control words. Instead, the access control device can predefine new control words for each user wishing to gain access and/or during each access attempt or else at periodic intervals, without renewed training of the speech recognizer in the speech input unit being required. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> In this connection, the training or enrolment plays an important part. In principle, this has to be divided into two parts, namely the recording of a word or of a speech and the calculation of the features on the speech input unit, on the one hand, and the storage of the features with a speaker identification code on an access device, on the other hand. These two parts of the enrolment can also be carried out chronologically separately from each other, and in particular speaker features obtained once on a speech input unit can be transmitted to various access devices. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> Overall, the proposed arrangement and the proposed method provide a large number of advantages as compared with known methods. </paragraph>
<paragraph id="P-0018" lvl="2"><number>&lsqb;0018&rsqb;</number> The words to be spoken in order to gain access authorization (according to a preferred embodiment of the invention) cannot be forged by means of previously produced audio recordings, since the access device decides randomly which words are to be spoken and analyzed in order to gain access authorization. </paragraph>
<paragraph id="P-0019" lvl="2"><number>&lsqb;0019&rsqb;</number> In the access devices, only the components for the word selection, reference feature storage and classification or threshold value discrimination have to be provided as components for speech verification, and this leads to simplification and reduction in costs on the part of the access devices. </paragraph>
<paragraph id="P-0020" lvl="2"><number>&lsqb;0020&rsqb;</number> Since the feature comparison and the classification or threshold value discrimination take place in the access device, the system overall is well protected against penetration from outside. A particularly high degree of encryption of the communication between the speech input unit and the access devices is not necessary, since the words used for the speaker verification are in any case not known before the initiation of the access procedure. </paragraph>
<paragraph id="P-0021" lvl="2"><number>&lsqb;0021&rsqb;</number> The processing-intensive part of the speaker verification, namely the feature extraction, takes place in the speech input unit, which can be used for a large number of access control tasks. This overall reduces the expenditure on hardware and software in the case of complex access control systems. </paragraph>
<paragraph id="P-0022" lvl="2"><number>&lsqb;0022&rsqb;</number> In the case of suitable implementation forms (mobile telephone, cordless telephone and the like), an audio front end (microphone, A/D converter, possibly digital signal processor), which is already present in any case, can be used on the side of the speech input unit. </paragraph>
<paragraph id="P-0023" lvl="2"><number>&lsqb;0023&rsqb;</number> The time-intensive part of the enrolment, namely the (in particular repeated) recording and feature extraction of a training dictionary, needs to be carried out only once in the speech input unit for various access control applications. Since the results are reused when logging in to a new&mdash;naturally system-compatible&mdash;access control device, this logging in is shortened substantially and, overall, the handling of the access system is simplified and made convenient for the user. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Advantages and expedient features of the invention otherwise emerge from the subclaims and the following outline description of exemplary embodiments, to some extent using the figure. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> The latter shows, in the manner of a sketch in a functional block circuit diagram, a complex access control configuration <highlight><bold>1</bold></highlight> comprising a number of devices or objects or rooms to which access is controlled by speaker verification, specifically a television set <highlight><bold>3</bold></highlight>, a computer system <highlight><bold>5</bold></highlight>, a safe <highlight><bold>7</bold></highlight> and a garage door system <highlight><bold>9</bold></highlight>, each of which has an access control unit <highlight><bold>3</bold></highlight>&prime;,<highlight><bold>5</bold></highlight>&prime;,<highlight><bold>7</bold></highlight>&prime; and <highlight><bold>9</bold></highlight>&prime;, and a mobile telephone <highlight><bold>11</bold></highlight> as speech input unit. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> The access control devices <highlight><bold>3</bold></highlight>&prime; to <highlight><bold>9</bold></highlight>&prime; each have a dictionary store <highlight><bold>3</bold></highlight><highlight><italic>a </italic></highlight>to <highlight><bold>9</bold></highlight><highlight><italic>a, </italic></highlight>a control word selection stage <highlight><bold>3</bold></highlight><highlight><italic>b </italic></highlight>to <highlight><bold>9</bold></highlight><highlight><italic>b </italic></highlight>connected thereto and a control word transmitting stage <highlight><bold>3</bold></highlight><highlight><italic>c </italic></highlight>to <highlight><bold>9</bold></highlight><highlight><italic>c </italic></highlight>connected to the latter for the storage, selection and transmission of control words to the speech input unit <highlight><bold>11</bold></highlight> for the speaker verification of a user wishing to gain access in each case. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> Said speech input unit <highlight><bold>11</bold></highlight> has a control word receiving unit <highlight><bold>11</bold></highlight><highlight><italic>a </italic></highlight>for receiving the respective control words and a display unit <highlight><bold>11</bold></highlight><highlight><italic>b </italic></highlight>for displaying the control words to be spoken by the user. Furthermore, it has an audio front end <highlight><bold>11</bold></highlight><highlight><italic>c </italic></highlight>for the speech input by the user and a speaker feature extraction stage <highlight><bold>11</bold></highlight><highlight><italic>d </italic></highlight>connected to the audio front end, on the one hand, and to the control word receiving unit, on the other hand, and implemented as a speech recognizer with a hidden Markov model, and also a speaker feature transmitting stage <highlight><bold>11</bold></highlight><highlight><italic>e </italic></highlight>connected to the output of the speaker feature extraction stage <highlight><bold>11</bold></highlight><highlight><italic>d </italic></highlight>for transmitting speaker features extracted from the speech input to the access control devices <highlight><bold>3</bold></highlight>&prime; to <highlight><bold>9</bold></highlight>&prime;. (To this extent, the functionality of the speech input unit <highlight><bold>11</bold></highlight> goes beyond that of a normal mobile telephone, but in the example it is assumed that the speech input unit is formed by an appropriately &ldquo;armed&rdquo; mobile telephone. The normal components of such a telephone are not illustrated and will not be described here). </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The currently determined speaker features are received in the access control devices <highlight><bold>3</bold></highlight>&prime; to <highlight><bold>9</bold></highlight>&prime; in each case by a speaker feature receiving stage <highlight><bold>3</bold></highlight><highlight><italic>d </italic></highlight>to <highlight><bold>9</bold></highlight><highlight><italic>d, </italic></highlight>which in turn is connected to a speaker feature comparison unit <highlight><bold>3</bold></highlight><highlight><italic>e </italic></highlight>to <highlight><bold>9</bold></highlight><highlight><italic>e. </italic></highlight>The latter is further connected to a speaker feature reference store <highlight><bold>3</bold></highlight><highlight><italic>f </italic></highlight>to <highlight><bold>9</bold></highlight><highlight><italic>f </italic></highlight>for storing speaker features from a predetermined user group as a reference for the speaker verification, and is used to compare the currently determined concomitantly stored speaker feature vectors and to output a degree of agreement as a result of a statistical comparison operation. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Connected downstream thereof in each case is a classifier stage (threshold value discriminator) 3 g to 9 g for classifying the comparison result at a predetermined threshold value of the degree of agreement. This classifier stage ultimately outputs an access release signal or access blocking signal as a final control signal of the store verification on the basis of the result of the threshold value discrimination. The threshold values can be selected differently in the individual access control devices on the basis of the desired level of protection against unauthorized use of the respective room or system to be secured. Likewise, the dictionaries of the individual access control devices can be selected differently, and the extent of the control word set or control text respectively selected from the overall dictionary for the speaker verification can have a different size. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> In this embodiment, the assignment of the user wishing to gain access is carried out by means of an evaluation (not illustrated) of data transmitted to the access control devices&mdash;which of course must have a mobile radio transmitting/receiving part&mdash;from the SIM card of the mobile telephone <highlight><bold>1</bold></highlight>. This additionally increases the security against unauthorized access to the devices, since even the use of the mobile telephone <highlight><bold>11</bold></highlight> is only possible following activation of a PIN known exclusively to the user. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> In a modified embodiment, not illustrated, the first step provided in the access procedure is the speaking of the name of the user and its transmission to the respective access control device for addressing a speaker feature reference store, which has a plurality of storage areas, that can be addressed via the user name, for speaker feature sets. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> Another exemplary embodiment provides for the use of Bluetooth technology for the wire-free communication between a speech input unit and the access control devices. The speech input unit used here, in particular for the domestic sector, is for example a cordless telephone retrofitted with a Bluetooth module or else a PDA or handheld PC, into which the aforementioned speaker feature extraction stage has been integrated. The presence of the necessary audio components permits cost-effective implementation of the speech input unit in this case too. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The implementation of the invention is not restricted to the examples described above; within the scope of the dependent claims, a large number of variations on this implementation are possible which lie within the scope of the specialist trade. </paragraph>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A speech-controlled access control arrangement (<highlight><bold>1</bold></highlight>) having at least one access control device (<highlight><bold>3</bold></highlight>&prime;, <highlight><bold>5</bold></highlight>&prime;, <highlight><bold>7</bold></highlight>&prime;, <highlight><bold>9</bold></highlight>&prime;) to release or block access, in particular to a delimited room (<highlight><bold>7</bold></highlight>, <highlight><bold>9</bold></highlight>), technical device (<highlight><bold>3</bold></highlight>, <highlight><bold>5</bold></highlight>) or data or telecommunications network, and a mobile speech input unit (<highlight><bold>11</bold></highlight>) connected to the access control device via a telecommunications connection, in particular a wire-free telecommunications connection. </claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The access control arrangement as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, characterized in that 
<claim-text>the or each access control device (<highlight><bold>3</bold></highlight>&prime;, <highlight><bold>5</bold></highlight>&prime;, <highlight><bold>7</bold></highlight>&prime;, <highlight><bold>9</bold></highlight>&prime;) comprises a control device dictionary store (<highlight><bold>3</bold></highlight><highlight><italic>a, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>a, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>a, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>a</italic></highlight>) for storing a predetermined dictionary, </claim-text>
<claim-text>a control word transmitting unit (<highlight><bold>3</bold></highlight><highlight><italic>c, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>c, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>c, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>c</italic></highlight>) for transmitting words from the stored dictionary to the speech input unit (<highlight><bold>11</bold></highlight>) as control words, </claim-text>
<claim-text>a speaker feature receiving stage (<highlight><bold>3</bold></highlight><highlight><italic>d, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>d, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>d, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>d</italic></highlight>) for receiving speaker features extracted in the speech input unit, </claim-text>
<claim-text>a speaker feature reference store (<highlight><bold>3</bold></highlight><highlight><italic>f, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>f, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>f, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>f</italic></highlight>) for storing speaker features of predetermined users as feature vectors, and also </claim-text>
<claim-text>a speaker feature comparison unit (<highlight><bold>3</bold></highlight><highlight><italic>e, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>e, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>e, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>e</italic></highlight>) for comparing currently determined speaker feature vectors with stored ones and for outputing an access release signal or access blocking signal as a function of the comparison result, and </claim-text>
<claim-text>the speech input unit (<highlight><bold>11</bold></highlight>) comprises a control word receiving unit (<highlight><bold>11</bold></highlight><highlight><italic>a</italic></highlight>) for receiving the control words transmitted from the control device, a control word display unit (<highlight><bold>11</bold></highlight><highlight><italic>b</italic></highlight>), means for speech input (<highlight><bold>11</bold></highlight><highlight><italic>c</italic></highlight>), a speaker feature extraction stage (<highlight><bold>11</bold></highlight><highlight><italic>d</italic></highlight>), connected to the means for speech input and at least indirectly to the dictionary receiving unit, for obtaining a speaker feature set and a speaker feature transmitting stage (lie) for transmitting the extracted speaker feature set to the access control device. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The access control arrangement as claimed in <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, characterized in that the speech input unit (<highlight><bold>11</bold></highlight>) comprises a control word buffer connected between the control word receiving unit (<highlight><bold>11</bold></highlight><highlight><italic>a</italic></highlight>) and the speaker feature extraction stage (<highlight><bold>11</bold></highlight><highlight><italic>d</italic></highlight>), and the access control device comprises a speaker feature buffer connected between the speaker feature receiving stage (<highlight><bold>3</bold></highlight><highlight><italic>d, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>d, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>d, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>d</italic></highlight>) and the speaker feature comparison unit (<highlight><bold>3</bold></highlight><highlight><italic>e, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>e, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>e, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>e</italic></highlight>). </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The access control arrangement as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> or <highlight><bold>2</bold></highlight>, characterized in that the or each access control device (<highlight><bold>3</bold></highlight>&prime;, <highlight><bold>5</bold></highlight>&prime;, <highlight><bold>7</bold></highlight>&prime;, <highlight><bold>9</bold></highlight>&prime;), in particular its control word transmitting unit (<highlight><bold>3</bold></highlight><highlight><italic>c, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>c, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>c, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>c</italic></highlight>) and speaker feature receiving stage (<highlight><bold>3</bold></highlight><highlight><italic>d, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>d, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>d, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>d</italic></highlight>), and the mobile speech input unit (<highlight><bold>11</bold></highlight>), in particular its control word receiving unit (<highlight><bold>11</bold></highlight><highlight><italic>a</italic></highlight>) and speaker feature transmitting stage (<highlight><bold>11</bold></highlight><highlight><italic>e</italic></highlight>), are constructed as radio transmitting and receiving units, in particular mobile radio transmitting or receiving units or Bluetooth or DECT transmitting and receiving units. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The access control arrangement as claimed in one of the preceding claims, characterized in that the mobile speech input unit (<highlight><bold>11</bold></highlight>) comprises means (<highlight><bold>11</bold></highlight><highlight><italic>b</italic></highlight>) for user guidance during the speech input, based on the control values received from the access control device (<highlight><bold>3</bold></highlight>&prime;, <highlight><bold>5</bold></highlight>&prime;, <highlight><bold>7</bold></highlight>&prime;, <highlight><bold>9</bold></highlight>&prime;). </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The access control arrangement as claimed in one of the preceding claims, characterized in that the or each access control device (<highlight><bold>3</bold></highlight>&prime;, <highlight><bold>5</bold></highlight>&prime;, <highlight><bold>7</bold></highlight>&prime;, <highlight><bold>9</bold></highlight>&prime;) has a selection device (<highlight><bold>3</bold></highlight><highlight><italic>b, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>b, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>b, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>b</italic></highlight>), operating in particular on the random generator principle, for the case by case selection of a set of control words from the stored dictionary. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The access control arrangement as claimed in one of the preceding claims, in particular one of <dependent-claim-reference depends_on="CLM-00002">claims 2</dependent-claim-reference> to <dependent-claim-reference depends_on="CLM-00006">6</dependent-claim-reference>, characterized in that the speaker feature reference store (<highlight><bold>3</bold></highlight><highlight><italic>f, </italic></highlight><highlight><bold>5</bold></highlight><highlight><italic>f, </italic></highlight><highlight><bold>7</bold></highlight><highlight><italic>f, </italic></highlight><highlight><bold>9</bold></highlight><highlight><italic>f</italic></highlight>) of the or each access control device (<highlight><bold>3</bold></highlight>&prime;, <highlight><bold>5</bold></highlight>&prime;, <highlight><bold>7</bold></highlight>&prime;, <highlight><bold>9</bold></highlight>&prime;) comprises a plurality of speaker feature storage areas which can be addressed via a user name or a user code, and the speech input unit (<highlight><bold>11</bold></highlight>) comprises a buffer (<highlight><bold>11</bold></highlight><highlight><italic>b</italic></highlight>) for storing an input user name or user code, said buffer being connected to the speaker feature transmitting stage (<highlight><bold>11</bold></highlight><highlight><italic>e</italic></highlight>) for transmission to the access control device in conjunction with the extracted speaker features. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The access control arrangement as claimed in one of the preceding claims, in particular one of <dependent-claim-reference depends_on="CLM-00002">claims 2</dependent-claim-reference> to <dependent-claim-reference depends_on="CLM-00007">7</dependent-claim-reference>, characterized in that the speaker feature extraction stage (<highlight><bold>11</bold></highlight><highlight><italic>d</italic></highlight>) of the speech input unit (<highlight><bold>11</bold></highlight>) is implemented as a speech recognizer, in which a hidden Markov model or neural network suitable for speaker verification is implemented which is initialized or can be initialized for at least one user, in particular for a plurality of users. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The access control arrangement as claimed in one of the preceding claims, in particular one of <dependent-claim-reference depends_on="CLM-00004">claims 4</dependent-claim-reference> to <dependent-claim-reference depends_on="CLM-00008">8</dependent-claim-reference>, characterized in that a speech input unit (<highlight><bold>11</bold></highlight>) constructed as a mobile radio terminal is designed to transmit user data from the SIM card to the access control device, and 
<claim-text>the access control device has an evaluation device for evaluating the transmitted user data in conjunction with data determined during the speaker feature extraction. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A method for access control, in particular to a delimited room (<highlight><bold>7</bold></highlight>, <highlight><bold>9</bold></highlight>), technical device (<highlight><bold>3</bold></highlight>, <highlight><bold>5</bold></highlight>) or data or telecommunications network, by evaluating the spoken word from at least one user, from which, using methods of speech recognition, a speaker feature set is derived, which is compared with at least one previously stored speaker feature set, access being released or blocked as a result of the comparison, characterized in that the extraction of the speaker features from the spoken word and the comparison of the speaker feature set with the previously stored speaker feature set is carried out in a distributed manner in a speech input device (<highlight><bold>11</bold></highlight>), on the one hand, and an access control device (<highlight><bold>3</bold></highlight>&prime;, <highlight><bold>5</bold></highlight>&prime;, <highlight><bold>7</bold></highlight>&prime;, <highlight><bold>9</bold></highlight>&prime;), on the other hand. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, characterized in that for the spoken word, previously stored control values from a dictionary are predefined, in particular selected on the random principle. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference> or <highlight><bold>11</bold></highlight>, characterized in that the dictionary is stored in the access control device (<highlight><bold>3</bold></highlight>&prime;, <highlight><bold>5</bold></highlight>&prime;, <highlight><bold>7</bold></highlight>&prime;, <highlight><bold>9</bold></highlight>&prime;), the selection of the control words is carried out in the access control device, and the selected control words are buffered in the speech input device (<highlight><bold>11</bold></highlight>) and output to the user within the context of user guidance. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method as claimed in one of <dependent-claim-reference depends_on="CLM-00010">claims 10</dependent-claim-reference> to <dependent-claim-reference depends_on="CLM-00012">12</dependent-claim-reference>, in particular as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 11</dependent-claim-reference>, characterized by wire-free transmission of the selected control words from the access control device (<highlight><bold>3</bold></highlight>&prime;, <highlight><bold>5</bold></highlight>&prime;, <highlight><bold>7</bold></highlight>&prime;, <highlight><bold>9</bold></highlight>&prime;) to the speech input unit (<highlight><bold>11</bold></highlight>) and of the speaker features from the speech input unit to the access control device. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method as claimed in one of <dependent-claim-reference depends_on="CLM-00010">claims 10</dependent-claim-reference> to <dependent-claim-reference depends_on="CLM-00013">13</dependent-claim-reference>, characterized in that in the speech input unit (<highlight><bold>11</bold></highlight>), before the method is carried out, a hidden Markov model or a neural network for speech recognition is initialized in an enrolment, each speaker being identified by speaking identification words and a predetermined speaker feature set being extracted from the speech data spoken by him and being stored together with the user name or a user code. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. Method as claimed in one of <dependent-claim-reference depends_on="CLM-00010">claims 10</dependent-claim-reference> to <dependent-claim-reference depends_on="CLM-00014">14</dependent-claim-reference>, in particular <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, characterized in that the speech data, together with the spoken control word and/or a corresponding phonetic transcription of the control word, are transmitted to an access control device and stored there in a speaker feature reference store. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method as claimed in one of <dependent-claim-reference depends_on="CLM-00010">claims 10</dependent-claim-reference> to <dependent-claim-reference depends_on="CLM-00015">15</dependent-claim-reference>, characterized in that the process of enrolment is divided up into the steps 
<claim-text>(1) of recording the control word and extracting the speaker features and </claim-text>
<claim-text>(2) of transmitting the features with the corresponding control word, the phonetic transcription and a user code or name to an access control device, </claim-text>
<claim-text>it being possible for step (2) to be carried out individually in each case for a plurality of access control devices. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method as claimed in one of <dependent-claim-reference depends_on="CLM-00010">claims 10</dependent-claim-reference> to <dependent-claim-reference depends_on="CLM-00016">16</dependent-claim-reference>, characterized in that 
<claim-text>for each comparison between a currently obtained speaker feature set and a previously stored speaker feature set, a degree of agreement between the speaker features is determined statistically, </claim-text>
<claim-text>discrimination of the degree of agreement is carried out with a predetermined threshold value and </claim-text>
<claim-text>access release is triggered only when the degree of agreement for the corresponding user lies above the threshold value. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method as claimed in one of <dependent-claim-reference depends_on="CLM-00010">claims 10</dependent-claim-reference> to <dependent-claim-reference depends_on="CLM-00017">17</dependent-claim-reference>, characterized in that the storage of the control words in the dictionary store of the access control devices is in each case expanded by storing the corresponding phonetic transcription, in order to facilitate speech recognition on a phoneme basis.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004726A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004726A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
