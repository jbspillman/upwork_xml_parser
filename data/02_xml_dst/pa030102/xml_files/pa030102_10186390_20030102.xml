<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001104A1-20030102-D00000.TIF SYSTEM "US20030001104A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00001.TIF SYSTEM "US20030001104A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00002.TIF SYSTEM "US20030001104A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00003.TIF SYSTEM "US20030001104A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00004.TIF SYSTEM "US20030001104A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00005.TIF SYSTEM "US20030001104A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00006.TIF SYSTEM "US20030001104A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00007.TIF SYSTEM "US20030001104A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00008.TIF SYSTEM "US20030001104A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00009.TIF SYSTEM "US20030001104A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00010.TIF SYSTEM "US20030001104A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00011.TIF SYSTEM "US20030001104A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00012.TIF SYSTEM "US20030001104A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00013.TIF SYSTEM "US20030001104A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00014.TIF SYSTEM "US20030001104A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030001104A1-20030102-D00015.TIF SYSTEM "US20030001104A1-20030102-D00015.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001104</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10186390</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020701</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>199131/2001</doc-number>
</priority-application-number>
<filing-date>20010629</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>089107/2002</doc-number>
</priority-application-number>
<filing-date>20020327</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G01N021/64</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>250</class>
<subclass>458100</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method and apparatus for obtaining fluorescence images, and computer executable program therefor</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Tomonari</given-name>
<family-name>Sendai</family-name>
</name>
<residence>
<residence-non-us>
<city>Kaisei-machi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Katsumi</given-name>
<family-name>Hayashi</family-name>
</name>
<residence>
<residence-non-us>
<city>Kaisei-machi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>FUJI PHOTO FILM CO., LTD</organization-name>
<assignee-type>03</assignee-type>
</assignee>
<correspondence-address>
<name-1>SUGHRUE MION, PLLC</name-1>
<name-2></name-2>
<address>
<address-1>2100 Pennsylvania Avenue, NW</address-1>
<city>Washington</city>
<state>DC</state>
<postalcode>20037-3213</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">When a diagnosis is to be performed using a fluorescence diagnostic image obtained by use of an endoscope apparatus or the like, if obstructing regions containing an obstructing factor such as blood or waste is present on the target subject, the misrecognition thereof as a diseased tissue is prevented. White light and excitation light are projected onto a target subject to obtain respective standard and fluorescence images thereof. Because the color of the obstructing regions is different from that of either normal or diseased tissue, the color data of the standard image is computed, and the obstructing regions detected by determining whether or not the color data is outside a predetermined range. The fluorescence image is subjected to an exceptional display process of rendering the color of the obstructing regions a different color than that of the other regions, and the processed fluorescence diagnostic image is displayed on a monitor. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to a method and apparatus for obtaining fluorescence images by projecting an illuminating light containing excitation light onto a target subject and obtaining a diagnostic fluorescence image of the target subject based on the fluorescence emitted from the target subject upon the irradiation thereof by the excitation light, and a program for causing a computer to execute the fluorescence image obtaining method. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Fluorescence detection apparatuses have been proposed that make use of the fact that the intensity of the fluorescence emitted from a normal tissue differs from the intensity of the fluorescence emitted from a diseased tissue when a target subject (i.e., a living tissue) is irradiated by an excitation light within an excitation wavelength range of the intrinsic fluorophores of the target subject. By detecting the fluorescence emitted from a target subject upon irradiation thereof by an excitation light within a predetermined wavelength range, the location and range of penetration of a diseased tissue is discerned. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Normally, when a target subject is irradiated by an excitation light, because a high-intensity fluorescence is emitted from a normal tissue, as shown by the solid line in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, and a weak-intensity fluorescence is emitted from a diseased tissue, as shown by the broken line in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, by measuring the intensity of the fluorescence emitted from the target subject, it can be determined whether the target subject is in a normal or a diseased state. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Further, methods of imaging fluorescence by use of an imaging element or the like, and displaying a diagnostic fluorescence image corresponding to the intensity of the imaged fluorescence have been proposed. Here, because there is unevenness on the surface of a target subject, the intensity of the excitation light irradiating the target subject is not of a uniform intensity across the entirety of the surface thereof. Further, although the intensity of the fluorescence emitted from the target subject is substantially proportional to the intensity of the excitation light, the intensity of the aforementioned excitation light becomes weaker in inverse proportion to the square of the distance between the excitation light source and the target subject. Therefore, there are cases in which the fluorescence received from a diseased tissue located at a position closer to the excitation light source than a normal tissue is of a higher intensity than the fluorescence received from aforementioned normal tissue. Consequently, the state of the tissue of the target subject cannot be accurately discerned based solely on the data relating to the intensity of the fluorescence received from the target subject upon the irradiation thereof with an excitation light. In order to remedy the problems described above: a method of displaying an image based on the difference between the spectral forms representing the tissue states, that is, a method of dividing the intensities of two types of fluorescence intensities of two fluorescence images, each formed of fluorescence of a mutually different wavelength band (a narrow band near 480 nm and a wide band from near 430-730 nm) to obtain the ratio therebetween and displaying a computed image based on the obtained factor thereof as a fluorescence diagnostic image; a method of obtaining a value representing a fluorescence yield and displaying an image, that is, a method of projecting, as a reference light, onto a target subject a near-infrared light which is absorbed uniformly absorbed by tissues of a variety of tissue states, detecting the intensity of the reflected light reflected from the target subject upon the irradiation thereof by the reference light and dividing the intensity of the reflected light by the intensity of the fluorescence intensity to obtain the ratio therebetween, and displaying a computed image based on the obtained factor thereof as a fluorescence diagnostic image; and the like have been proposed. Further there have been proposed: a method of assigning color data to the factor of the intensities of the fluorescence of two different wavelength bands, or to the factor of a fluorescence intensity and the intensity of the reflected light reflected from the target subject upon the irradiation thereof by a reference light, to form a fluorescence diagnostic image wherein the diseased tissue of the target subject can be discerned from the difference in color within the fluorescence diagnostic image; a method of combining the color image representing the diseased tissue of the target subject by the difference in color and a brightness image formed by assigning brightness data to the intensity of the reflected light reflected from the target subject upon the irradiation thereof by the reference light to display a fluorescence diagnostic image also representing the contour of the surface of the target subject and imparting a three-dimensional sense thereof; such as those described in U.S. Pat. Nos. 5,590,660, 5647368, and Japanese Unexamined Patent Publication Nos. 9(1997)-308604, 10(1998)-225436, and 2001-157658. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> In this manner, by obtaining, displaying on a monitor and observing a fluorescence diagnostic image, an accurate determination can be made as to whether the target subject is in a normal state or a diseased state. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> However, for cases in which a fluorescence diagnostic image is obtained of a target subject when blood, mucus, digestive fluids, saliva, foam, residue, and/or the like (hereinafter referred to as obstructing factors) is present on the target subject, because the obstructing factor is also obtained in the image at the same time, the fluorescence diagnostic image contains an image of the obstructing factor. Here, if an obstructing factor is present on the target subject, the intensity of the fluorescence emitted from the portion on which the obstructing factor is present becomes reduced, and fluorescence of a wavelength greater than or equal to 600 nm is emitted. Therefore, if a diagnosis is carried out using a fluorescence diagnostic image including an obstructing factor, there is a fear that the portion on which the obstructing factor is present will be judged to be a diseased tissue, even though said portion is a normal tissue. Hereinafter, the reasons whereby an obstructing factor leads to misdiagnosis will be explained. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> The spectrum of the fluorescence intensity emitted from the target subject upon the irradiation thereof by the excitation light is that shown in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, and the normalized fluorescence intensity spectrum obtained by normalizing (causing the integral value over the entirety of the wavelength band to become 1) the aforementioned fluorescence intensity spectrum is that shown in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>. As shown in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, the fluorescence intensity (an integral value over the entire wavelength band) emitted from a normal tissue and the fluorescence intensity emitted from a diseased tissue are clearly different. Further, as shown in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, in the normalized fluorescence intensity spectrum, the relative intensity of the fluorescence of a wavelength near 480 nm emitted from the diseased tissue is reduced in comparison to that emitted from the normal tissue state, and the relative intensity of the fluorescence of a wavelength near 630 nm emitted from the diseased tissue is greater in comparison to that emitted from the normal tissue. Accordingly, it can be determined if the target subject is a normal tissue or a diseased tissue based on the fluorescence intensity and the normalized fluorescence intensity. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> On the other hand, <cross-reference target="DRAWINGS">FIG. 17</cross-reference> shows the fluorescence intensity spectrum obtained of the fluorescence emitted from a residue obstructing factor upon the irradiation thereof by an excitation light, and <cross-reference target="DRAWINGS">FIG. 18</cross-reference> shows the normalized fluorescence intensity spectrum thereof. As shown in <cross-reference target="DRAWINGS">FIG. 17</cross-reference>, in the case of residue, the fluorescence intensity spectrum thereof becomes approximately the same degree as that of the fluorescence emitted from a normal tissue; however, as shown in <cross-reference target="DRAWINGS">FIG. 18</cross-reference>, with respect to the normalized fluorescence intensity spectrum of the fluorescence intensity spectrum of the fluorescence emitted from an obstructing factor, the relative intensity of the fluorescence of a wavelength near 480 nm is lower in comparison to that emitted from the normal tissue, and the relative intensity of the fluorescence of a wavelength near 670 nm is greater in comparison to that emitted from the normal tissue. Accordingly, according to the method wherein a computed image based on the factor of the intensities of two different types of fluorescence is employed as a fluorescence diagnostic image as described above, for example, in the case in which a fluorescence diagnostic image reflecting the form of the normalized fluorescence image intensity spectrum is obtained, because the pixel values of a portion in which a residue is present become the same pixel values as that of a diseased tissue, there is a fear that regardless of the fact that the tissue on which an obstructing factor is present is a normal tissue, said tissue will be diagnosed as being a diseased tissue. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The present invention has been developed in view of the forgoing circumstances, and it is an objective of the present invention to provide a fluorescence image obtaining method and apparatus, and a program capable of causing a computer to execute said fluorescence image obtaining method; wherein, an accurate diagnosis can be performed using a fluorescence diagnostic image. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> The fluorescence image obtaining method according to the present invention comprises the steps of: projecting an illuminating light containing excitation light onto a target subject and obtaining a fluorescence diagnostic image based on the fluorescence emitted from said target subject upon the irradiation thereof by said light, wherein </paragraph>
<paragraph id="P-0013" lvl="2"><number>&lsqb;0013&rsqb;</number> obstructing regions representing an obstructing factor present on the target subject are detected. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> The referents of &ldquo;fluorescence diagnostic image&rdquo; can include: an image corresponding to the intensity of the fluorescence emitted from a target subject upon the irradiation thereof by an excitation light; an image representing the ratio between two types of fluorescence intensities obtained of two different wavelength bands; an image representing the ratio of the fluorescence intensity to the intensity of the reflected light reflected from the target subject upon the irradiation thereof by a reference light; an image formed by assigning color data to the ratio between the fluorescence intensities obtained of two different wavelength bands; an image formed by assigning color data to the ratio of the of fluorescence intensity to the reflectance intensity of the reflected light reflected from the target subject upon the irradiation thereof by a reference light; a synthesized image formed by combining a color image to which color data has been assigned and a brightness image obtained by assigning brightness data to the reflectance intensity of the reflected light reflected from the target subject upon the irradiation thereof by a reference light; or the like. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The referents of &ldquo;color data&rdquo; include, for example: the hue, saturation, and/or chromaticity (hue and saturation) of development color systems (HSB/HVC/Lab/Luv/La*b*/Lu*v* color spaces) or a mixed color system (an X,Y,Z color space); the color differences of a visible image signal representative of a TV signal (e.g., the IQ of the YIQ of an NTSC signal, the CbCr of an YCbCr, etc.); the combination ratio of a color signal (R, G, B or C, M, Y, G), etc. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> The referents of &ldquo;brightness data&rdquo; include, for example: the luminosity or brightness of development color systems (HSB/HVC/Lab/Luv/La*b*/Lu*v* color spaces) or a mixed color system (an X,Y,Z color space); the brightness of avisible image signal representative of a TV signal (e.g., the Y of the YIQ of an NTSC signal, the CbCr of an YCbCr, etc.); etc. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> The referents of &ldquo;obstructing regions&rdquo; are the regions representing locations of the target subject on which an obstructing factor such as blood, mucus, digestive fluids, saliva, foam, residue, and/or the like is present. The obstructing regions are regions of which there is a high probability of the misdiagnosis thereof as a diseased tissue, regardless of the fact that the tissue represented therein is in a normal tissue state. Note that according to the present invention, the regions of a fluorescence diagnostic image corresponding to obstructing regions as well as the regions of a standard image corresponding to obstructing regions are referred to as obstructing regions. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> Note that according to the fluorescence image obtaining method of the present invention, a white light can be projected onto the target subject and a standard image of said target subject can be obtained based on the reflected light obtained from said target subject upon the irradiation thereof by the white light, and </paragraph>
<paragraph id="P-0019" lvl="2"><number>&lsqb;0019&rsqb;</number> the obstructing regions included therein can be detected based on the color data of the standard image. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Further, according to the fluorescence image obtaining method of the present invention, the fluorescence data of the target subject can be obtained based on the fluorescence, and </paragraph>
<paragraph id="P-0021" lvl="2"><number>&lsqb;0021&rsqb;</number> the obstructing regions can be detected based on said fluorescence data. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> In this case, the fluorescence intensity and the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands can be used as the fluorescence data. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Further, in this case, based on either the fluorescence intensity or the computed fluorescence value (e.g., the fluorescence intensity), the suspected obstructing regions of the target subject can be detected, and </paragraph>
<paragraph id="P-0024" lvl="2"><number>&lsqb;0024&rsqb;</number> based on the other of either of the fluorescence intensity and the computed fluorescence value (e.g., the computed fluorescence value), the obstructing regions suspected can be detected. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Further, according to the fluorescence image obtaining method of the present invention, a standard image of the target subject can be obtained, based on the reflected light obtained from the target subject upon the irradiation thereof by the white light, and </paragraph>
<paragraph id="P-0026" lvl="2"><number>&lsqb;0026&rsqb;</number> the fluorescence data based on the fluorescence can be obtained, and </paragraph>
<paragraph id="P-0027" lvl="2"><number>&lsqb;0027&rsqb;</number> the obstructing regions can be detected based on the color data of the standard image and the fluorescence data. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> In this case, the fluorescence intensity and the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands can be used as the fluorescence data. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> Further, in this case, based on any one of the color data, the fluorescence intensity, or the computed fluorescence value (e.g., the color data), the suspected obstructing regions of the target subject can be detected, wherein </paragraph>
<paragraph id="P-0030" lvl="2"><number>&lsqb;0030&rsqb;</number> it is preferable that the obstructing regions of said suspected obstructing regions are detected based on one of the data other than that employed in the detection (e.g., the fluorescence intensity or the computed fluorescence value). </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Still further, the fluorescence intensity and the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands can be used as the fluorescence data, and in this case, based on any one of the color data, the fluorescence intensity, or the fluorescence data (e.g., the color data) a first suspected obstructing region of the target subject can be detected, and </paragraph>
<paragraph id="P-0032" lvl="2"><number>&lsqb;0032&rsqb;</number> based on one of the data other than that employed in the detection of said first suspected obstructing region (e.g., the fluorescence intensity), a second suspected obstructing region of the target subject can be detected, and </paragraph>
<paragraph id="P-0033" lvl="2"><number>&lsqb;0033&rsqb;</number> based on one of the data other than that employed in the detection of said second suspected obstructing region (e.g., the computed fluorescence value), the obstructing regions can be detected. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Further, according to the fluorescence image obtaining method of the present invention, the obstructing regions of the fluorescence diagnostic image can be subjected to an exceptional display process, and the fluorescence diagnostic image subjected to said exceptional display process can be displayed. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> The expression &ldquo;exceptional display process&rdquo; refers to a process enabling the display of the fluorescence diagnostic image in a manner wherein each image of an obstructing region included therein can be recognized as such at a glance. More specifically, the images of the obstructing regions can be processed so as to be of a color not appearing in any of the images of the other regions. For example, if the fluorescence diagnostic image is an image having chromatic color, the images of the obstructing regions can be regions having achromatic color, or conversely, if the fluorescence diagnostic image is an image having achromatic color, the images of the obstructing regions can be regions having chromatic color; further, for a case in which the color of the fluorescence diagnostic image changes from a green through yellow color to red in correspondence to the change of the tissue state from normal to diseased, the images of the obstructing regions can be caused to be blue. Still further, the images of the obstructing regions can be caused to be the same color as the background, or transparent. In addition, the images of the regions included in the fluorescence diagnostic image other than the obstructing regions can be caused to be transparent. Also, although there are cases in which the portions regarded to be in the diseased state are indicated by an arrow mark, in this type of case, a process whereby arrow marks are not assigned to obstructing regions is included in the exceptional display processes. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The fluorescence image obtaining apparatus according to the present invention comprises a fluorescence diagnostic image obtaining means for obtaining, based on the fluorescence obtained from a target subject upon the irradiation thereof by an illuminating light containing excitation light, a fluorescence diagnostic image of a target subject, further comprising </paragraph>
<paragraph id="P-0037" lvl="2"><number>&lsqb;0037&rsqb;</number> an obstructing regions detecting means for detecting the obstructing factors present on the target subject. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Note that according to the fluorescence image obtaining apparatus of the present invention, a standard image obtaining means may be further provided for obtaining, based on the reflected light obtained from the target subject upon the irradiation thereof by a white light, a standard image of the target subject, wherein </paragraph>
<paragraph id="P-0039" lvl="2"><number>&lsqb;0039&rsqb;</number> the obstructing regions detecting means is a means for detecting the obstructing regions based on the color data of the standard image. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> Further, according to the fluorescence image obtaining apparatus of the present invention, the obstructing regions detecting means can be a means for obtaining the fluorescence data of the target subject, based on the fluorescence, and detecting the obstructing regions based on said fluorescence data. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> In this case, the fluorescence intensity, and the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands can be used as the fluorescence data. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> Further, in this case, the obstructing regions detecting means can be a means for detecting, based on either the fluorescence intensity or the computed fluorescence value, the suspected obstructing regions of the target subject, and detecting, based on the other of either of the fluorescence intensity and the computed fluorescence value of said suspected obstructing regions, the obstructing regions. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Still further, according to the fluorescence image obtaining apparatus of the present invention, a standard image obtaining means for obtaining, based on the reflected light obtained from the target subject upon the irradiation thereof by the white light, a standard image of the target subject can be further provided, and </paragraph>
<paragraph id="P-0044" lvl="2"><number>&lsqb;0044&rsqb;</number> the obstructing regions detecting means can be a means for obtaining, based on the fluorescence, fluorescence data of the target subject, and detecting, based on the color data of the standard image and the fluorescence data, the obstructing regions. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> In this case, the fluorescence intensity or the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands can be used as the fluorescence data. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Further, in this case, the obstructing regions detecting means can be a means for detecting, based on any one of the color data, the fluorescence intensity, or the computed fluorescence value, the suspected obstructing regions of the target subject, and detecting, based on one of the data other than that employed in the detection of said suspected obstructing regions, the obstructing regions of the suspected obstructing regions. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Still further, the fluorescence intensity and the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands can be used as the fluorescence data. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> In this case, the obstructing regions detecting means can be a means for detecting, based on any one of the color data, the fluorescence intensity, or the fluorescence data a first suspected obstructing region of the target subject, and detecting, based on one of the data other than that employed in the detection of said first suspected obstructing region, a second suspected obstructing region of the target subject, and detecting, based on one of the data other than that employed in the detection of said second suspected obstructing region, the obstructing regions. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> Further, according to the fluorescence image obtaining apparatus of the present invention, it is preferable that an exceptional display process means for subjecting the obstructing regions of the fluorescence diagnostic image to exceptional display processes, and </paragraph>
<paragraph id="P-0050" lvl="2"><number>&lsqb;0050&rsqb;</number> a display means for displaying the fluorescence diagnostic image that has been subjected to said exceptional display processes be further provided. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> Still further, according to the fluorescence image obtaining apparatus according to the present invention, it is preferable that a portion or the entirety of the fluorescence diagnostic image obtaining means be provided in the form of an endoscope to be inserted into the body cavity of a patient. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Note that the fluorescence image obtaining method of the present invention may be provided as a program capable of causing a computer to execute said fluorescence image obtaining method. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> According to the present invention, when a fluorescence diagnostic image is obtained, because the obstructing regions representing the obstructing factor present on the target subject are detected, by causing the obstructing regions to be of a color different from that of the other regions or removing the obstructing regions, etc. and displaying the fluorescence diagnostic image, the fear that an obstructing region will be diagnosed as a tissue in a diseased state is eliminated. Accordingly, an accurate diagnosis can be performed using the fluorescence diagnostic image. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Further, for cases in which a standard image is obtained based on the reflected light obtained from the target subject upon the irradiation thereof by a white light, the obstructing regions included within the standard image become a different color than the other regions. Accordingly, the obstructing regions can be accurately detected based on the color data of the standard image. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Still further, for cases in which the fluorescence intensity emitted from the target subject including obstructing factors upon the irradiation thereof by an excitation light is obtained in a plurality of wavelength bands, and a computed fluorescence data representing the ratio between these plurality of fluorescence intensities has been obtained, the computed fluorescence value of the obstructing regions becomes close to that of a diseased tissue. On the other hand, the fluorescence intensity emitted from the obstructing factors present on the target subject becomes a value close to that of the fluorescence intensity emitted from a normal tissue. Accordingly, the obstructing regions can be distinguished from the other regions of the target subject, based on the fluorescence data such as the fluorescence intensity, the computed fluorescence value, or the like. Therefore, the obstructing regions can be accurately detected based on the fluorescence data. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> In particular, when the obstructing regions are detected based on the fluorescence intensity and the computed fluorescence value, by detecting, based on either of the fluorescence intensity or the computed fluorescence value, the suspected obstructing regions, and further detecting, based on the other of either the fluorescence intensity or the computed fluorescence value, the obstructing regions of the suspected obstructing regions, the amount of computation required for detecting the obstructing regions can be reduced by the detection of the obstructing regions from the suspected obstructing regions compared to the case in which the obstructing regions are detected from the fluorescence data across the entire area of the target subject. For example, for a case in which the suspected obstructing regions have been detected based on the fluorescence intensity, if the obstructing regions are detected, based on the computed fluorescence value, for only the suspected obstructing regions, the amount of calculation required for performing the detection can be reduced. On the other hand, for a case in which the suspected obstructing regions have been detected based on the computed fluorescence value, if the obstructing regions are detected, based on the fluorescence intensity, for only the suspected obstructing regions, the amount of calculation required for performing the detection can be reduced. Accordingly, the amount of calculation required for detecting the obstructing regions can be reduced, and the obstructing regions can be detected at a higher speed. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Further, by detecting the obstructing regions based on the color data and the computed fluorescence value, the parameters for detecting the obstructing regions can be increased, whereby the obstructing regions can be detected more accurately. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Still further, when the color data and the fluorescence intensity or the computed fluorescence value are used to detect the obstructing regions, by detecting, based on the color data and either of the fluorescence intensity or the computed fluorescence value, the suspected obstructing regions, and then detecting, based on the data other than that used in the detection of the suspected obstructing regions, the obstructing regions of the suspected obstructing regions, the amount of computation required for detecting the obstructing regions can be reduced by the detection of the obstructing regions from the suspected obstructing regions compared to the case in which the obstructing regions are detected from the color data and the fluorescence data across the entire area of the target subject; as a result, the obstructing regions can be detected at a higher speed. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> In addition, when the color data, the fluorescence intensity, and the computed fluorescence value are employed to detect the obstructing regions: a first suspected obstructing region is detected based on any of the color data, the fluorescence intensity, and the computed fluorescence value; a second suspected obstructing region is detected based on either of the data other than that used in the detection of the first suspected obstructing region; the obstructing regions of the second suspected obstructing region are detected based on the data other than that used in the detection of the first and second suspected obstructing regions; whereby the amount of computation required for detecting the obstructing regions can be reduced by the detection of the obstructing regions from the second suspected obstructing region, which has been detected from the first suspected obstructing region, in comparison to the case in which the obstructing regions are detected from the color data and the fluorescence data across the entire area of the target subject; and as a result, the obstructing regions can be detected at a higher speed. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Further, by subjecting the obstructing regions occurring in a fluorescence diagnostic image to an exceptional display process when the fluorescence diagnostic image is to be displayed, when the displayed fluorescence diagnostic image is displayed, the obstructing regions can be recognized as such at a glance. Accordingly, the fear that an obstructing region will be misrecognized as a tissue in a diseased state is eliminated, and the diagnosis can be performed more accurately using the fluorescence diagnostic image. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Still further, if a fluorescence diagnostic image in which the images of the regions other than the obstructing regions have been caused to be transparent is superposed over a standard image and displayed, when the displayed standard image is observed, the obstructing regions can be recognized as such at a glance. Accordingly, the fear that a tissue in a diseased state that appears within obstructing region will be overlooked is eliminated, and the accuracy with which the diagnosis can be performed using the fluorescence diagnostic image is improved a level.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a schematic drawing of the main part of a fluorescence endoscope apparatus implementing the fluorescence image obtaining apparatus according to the first embodiment of the present invention, </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a schematic drawing of a CYG filter, </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a schematic drawing of a switching filter, </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flowchart of the operation of the first embodiment from the detection of the obstructing regions to the performance of the exceptional display process, </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a schematic drawing of the main part of a fluorescence endoscope apparatus implementing the fluorescence image obtaining apparatus according to the second embodiment of the present invention, </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a flowchart of the operation of the second embodiment from the detection of the obstructing regions to the performance of the exceptional display process, </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a schematic drawing of the main part of a fluorescence endoscope apparatus implementing the fluorescence image obtaining apparatus according to a variation of the second embodiment of the present invention, </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a schematic drawing of the main part of a fluorescence endoscope apparatus implementing the fluorescence image obtaining apparatus according to the third embodiment of the present invention, </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a flowchart of the operation of the third embodiment from the detection of the obstructing regions to the performance of the exceptional display process, </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flowchart of the operation of the fourth embodiment from the detection of the obstructing regions to the performance of the exceptional display process, </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a flowchart of the operation of the fifth embodiment from the detection of the obstructing regions to the performance of the exceptional display process, </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a flowchart of the operation of the sixth embodiment from the detection of the obstructing regions to the performance of the exceptional display process, </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a schematic drawing of a rotating filter, </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a schematic drawing of a mosaic filter, </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is a graph illustrating the respective intensity distributions of the fluorescence intensity spectrum of a tissue in a normal state and a tissue in a diseased state, </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a graph illustrating the respective intensity distributions of the normalized fluorescence intensity spectrum of a tissue in a normal state and a tissue in a diseased state, </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a graph illustrating the respective intensity distributions of the fluorescence intensity spectrum of a tissue in a normal state and a residue, and </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a graph illustrating the respective intensity distributions of the normalized fluorescence intensity spectrum of a tissue in a normal state and a residue.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> Hereinafter the preferred embodiments of the present invention will be explained with reference to the attached drawings. <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a schematic drawing of the main part of a fluorescence endoscope apparatus implementing the fluorescence image obtaining apparatus according to the first embodiment of the present invention. According to the fluorescence endoscope apparatus of the first embodiment of the present invention: the fluorescence emitted from a target subject upon the irradiation thereof by an excitation light is two-dimensionally detected by an image fiber; a narrow band fluorescence image formed of the fluorescence of a wavelength in the 430-530 nm wavelength band and a wide band fluorescence image formed of the fluorescence of a wavelength in the 530-730 nm wavelength band are obtained; a color image is formed based on the intensities of both fluorescence images, that is, on the factor of each corresponding pixel value of the narrow band fluorescence image and the wide band fluorescence image; an IR reflectance image is obtained of the reflected light reflected from the target subject upon the irradiation thereof by white light; a luminosity image is formed based on the light intensity of the IR reflectance image, that is, on the pixel value of each pixel of the IR reflectance image; the color image and the IR luminosity image are combined to form a synthesized image; and the synthesized image is displayed on a monitor as a fluorescence diagnostic image. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the fluorescence endoscope apparatus according to the first embodiment of the present invention comprises: an endoscope insertion portion <highlight><bold>100</bold></highlight> for insertion into the primary nidus and suspected areas of disease of the patient; and an image signal processing portion <highlight><bold>1</bold></highlight>. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> The image signal processing portion <highlight><bold>1</bold></highlight> comprises: an illuminating unit <highlight><bold>110</bold></highlight> equipped with a light source for emitting a white light L<highlight><bold>1</bold></highlight> (including a reference light L<highlight><bold>5</bold></highlight>) for obtaining a standard image and an IR reflectance image, and an excitation light L<highlight><bold>2</bold></highlight> for obtaining a fluorescence image; an image obtaining unit <highlight><bold>120</bold></highlight> for obtaining two types of fluorescence images formed of different wavelength bands of fluorescence and an IR reflectance image of a target subject <highlight><bold>10</bold></highlight>, and obtaining fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight>, and an IR reflectance image data F<highlight><bold>1</bold></highlight>; a fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> for obtaining a factor between the corresponding pixel values of the respective fluorescence images represented by each of fluorescence image data K<highlight><bold>1</bold></highlight> and K<highlight><bold>2</bold></highlight> and obtaining a color image data H based on the obtained factor, forming a luminosity image data V based on the pixel value of the IR reflectance image represented by the IR reflectance image data F<highlight><bold>1</bold></highlight>, combining the color image data H and the luminosity image data V to form a fluorescence diagnostic image data, and further subjecting the fluorescence diagnostic image data to an exceptional display process, which is described below, to obtain a processed fluorescence diagnostic image data KP representing a processed fluorescence diagnostic image; an image processing unit <highlight><bold>140</bold></highlight> for subjecting the standard image represented by the standard image data N and the processed fluorescence diagnostic image represented by the processed fluorescence diagnostic image data KP to the processes required to display said images as visible images; an obstructing region detecting unit <highlight><bold>150</bold></highlight> for detecting the obstructing regions, which are described below; a controller <highlight><bold>160</bold></highlight> connected to each of the above units for controlling the operation timings thereof; a monitor <highlight><bold>170</bold></highlight> for displaying the normal image data N processed by the image process portion <highlight><bold>140</bold></highlight> as a visible image; and a monitor <highlight><bold>180</bold></highlight> for displaying the processed fluorescence diagnostic image data KP processed by the image process portion <highlight><bold>140</bold></highlight> as a visible image. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> The endoscope insertion portion <highlight><bold>100</bold></highlight> is provided with a light guide <highlight><bold>101</bold></highlight> extending internally to the distal end thereof, A CCD cable <highlight><bold>102</bold></highlight>, and an image fiber <highlight><bold>103</bold></highlight>. An illuminating lens <highlight><bold>104</bold></highlight> and an objective lens <highlight><bold>105</bold></highlight> are provided at the distal end of the light guide <highlight><bold>101</bold></highlight>, that is, at the distal end of the endoscope insertion portion <highlight><bold>100</bold></highlight>. Further, the image fiber <highlight><bold>103</bold></highlight> is a quartz glass fiber, and is provided at the distal end thereof with a condensing lens <highlight><bold>106</bold></highlight>. A CCD imaging element <highlight><bold>107</bold></highlight> (not shown) which is provided with an on-chip color filter is connected to the distal end of the CCD cable <highlight><bold>102</bold></highlight>, and a prism <highlight><bold>108</bold></highlight> is attached to the CCD imaging element <highlight><bold>107</bold></highlight>. Still further, an RGB filter <highlight><bold>109</bold></highlight> provided with R, G, and B band filter elements corresponding to each pixel of the CCD imaging element <highlight><bold>107</bold></highlight> and which are distributed in a mosaic pattern is disposed between the CCD imaging element <highlight><bold>107</bold></highlight> and the prism <highlight><bold>108</bold></highlight>. A white light guide <highlight><bold>101</bold></highlight><highlight><italic>a</italic></highlight>, which is a composite glass fiber, and an excitation light guide <highlight><bold>101</bold></highlight><highlight><italic>b</italic></highlight>, which is a quartz glass fiber are bundled to form the light guide <highlight><bold>101</bold></highlight> as an integrated cable. The white light guide <highlight><bold>101</bold></highlight><highlight><italic>a </italic></highlight>and the excitation light guide <highlight><bold>101</bold></highlight><highlight><italic>b </italic></highlight>are connected to the illuminating unit <highlight><bold>110</bold></highlight>. One end of the CCD cable <highlight><bold>102</bold></highlight> is connected to the image processing unit <highlight><bold>140</bold></highlight>, and one end of the image fiber <highlight><bold>103</bold></highlight> is connected to the image obtaining unit <highlight><bold>120</bold></highlight>. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Note that a CYG filter, such as that shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, which is formed of a C (cyan), a Y (yellow), and a G (green) band pass filters can be used instead of the RGB filter formed of the R, G, B band pass filters. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> The illuminating unit <highlight><bold>110</bold></highlight> comprises: a white light source <highlight><bold>111</bold></highlight>, which is a halogen lamp or the like, for emitting white light L<highlight><bold>1</bold></highlight> (including a reference light L<highlight><bold>5</bold></highlight> formed of near-infrared light) for obtaining standard images and IR reflectance images; a white light power source <highlight><bold>112</bold></highlight> which is electrically connected to the white light source <highlight><bold>111</bold></highlight>; a white light condensing lens <highlight><bold>113</bold></highlight> for focusing the white light L<highlight><bold>1</bold></highlight> emitted from the white light source <highlight><bold>111</bold></highlight>; a GaN semiconductor laser <highlight><bold>114</bold></highlight> for emitting excitation light L<highlight><bold>2</bold></highlight> for obtaining fluorescence images; an excitation light power source <highlight><bold>115</bold></highlight> which is electrically connected to the GaN semiconductor laser <highlight><bold>114</bold></highlight>; and an excitation light condensing lens <highlight><bold>116</bold></highlight> for focusing the excitation light L<highlight><bold>2</bold></highlight> emitted from the GaN semiconductor laser <highlight><bold>114</bold></highlight>. Note that a reference light source that emits the reference light L<highlight><bold>5</bold></highlight> can be provided separate from the white light source. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> The image obtaining unit <highlight><bold>120</bold></highlight> comprises: a collimator lens <highlight><bold>128</bold></highlight> that guides the fluorescence L<highlight><bold>3</bold></highlight> conveyed thereto via the image fiber <highlight><bold>103</bold></highlight>; an excitation light cutoff filter <highlight><bold>121</bold></highlight> that cuts off light having a wavelength less than or equal to the 420 nm wavelength of the excitation light L<highlight><bold>2</bold></highlight> from the fluorescence L<highlight><bold>3</bold></highlight>; a switching filter <highlight><bold>122</bold></highlight>, in which three types of optical transmitting filters are combined; a filter rotating apparatus <highlight><bold>124</bold></highlight>, which is a motor or the like, for rotating the switching filter <highlight><bold>122</bold></highlight>; a condensing lens <highlight><bold>129</bold></highlight> for focusing the fluorescence L<highlight><bold>3</bold></highlight> and the reflected light L<highlight><bold>6</bold></highlight> transmitted by the switching filter <highlight><bold>122</bold></highlight>; a CCD imaging element <highlight><bold>125</bold></highlight> for obtaining the fluorescence image and the IR reflectance image represented by the fluorescence L<highlight><bold>3</bold></highlight> and the reflected light L<highlight><bold>6</bold></highlight>, respectively, focused by the condensing lens <highlight><bold>129</bold></highlight>; and an A/D conversion circuit <highlight><bold>126</bold></highlight> for digitizing the image signals obtained by the CCD imaging element <highlight><bold>125</bold></highlight> to obtain two types of fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight>, and an IR reflectance image data F<highlight><bold>1</bold></highlight>. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The configuration of the switching filter <highlight><bold>122</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. As shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the switching filter <highlight><bold>122</bold></highlight> comprises: an optical filter <highlight><bold>123</bold></highlight><highlight><italic>a</italic></highlight>, which is a band pass filter, that transmits light of a wavelength in the 430-730 wavelength band; an optical filter <highlight><bold>123</bold></highlight><highlight><italic>b</italic></highlight>, which is a band pass filter, that transmits light of a wavelength of 480 nm&plusmn;50 nm; an optical filter <highlight><bold>123</bold></highlight><highlight><italic>c</italic></highlight>, which is a band pass filter, that transmits light of a wavelength in the 750-900 wavelength band. The optical filter <highlight><bold>123</bold></highlight><highlight><italic>a </italic></highlight>is an optical filter for obtaining a wide band fluorescence image; the optical filter <highlight><bold>123</bold></highlight><highlight><italic>b </italic></highlight>is an optical filter for obtaining a narrow band fluorescence image, and the optical filter <highlight><bold>123</bold></highlight><highlight><italic>a </italic></highlight>is an optical filter for obtaining an IR reflectance image. The switching filter <highlight><bold>122</bold></highlight> is controlled by the controller <highlight><bold>160</bold></highlight> via the filter rotating apparatus <highlight><bold>124</bold></highlight> so that the optical filter <highlight><bold>123</bold></highlight><highlight><italic>c </italic></highlight>is disposed along the optical path when the target subject <highlight><bold>10</bold></highlight> is being irradiated by the white light L<highlight><bold>1</bold></highlight>; and the optical filters <highlight><bold>123</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>123</bold></highlight><highlight><italic>b </italic></highlight>are alternately disposed along the optical path when the target subject <highlight><bold>10</bold></highlight> is being irradiated by the excitation light L<highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> The fluorescence diagnostic image forming means <highlight><bold>130</bold></highlight> comprises: an image memory <highlight><bold>131</bold></highlight> for storing the two types of fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight>, and the IR reflectance image data F<highlight><bold>1</bold></highlight> obtained by the A/D conversion circuit <highlight><bold>126</bold></highlight>; a luminosity image computing portion <highlight><bold>132</bold></highlight>, in which a look up table correlating the range of each pixel value of the IR reflectance image represented by the IR reflectance image data F<highlight><bold>1</bold></highlight> to a luminosity in a Munsel display color system is stored, for referring to said look up table and obtaining a luminosity image data V from the IR reflectance image data F<highlight><bold>1</bold></highlight>; a hue computing portion <highlight><bold>133</bold></highlight>, in which a look up table correlating the range of the factor between the two types of fluorescence images represented by the fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight>, to a hue in the hue circle of a Munsel display color system is stored, for referring to said look up table and forming a hue image data H from the factor between said fluorescence images; an image synthesizing portion <highlight><bold>134</bold></highlight> for combining the hue image data H and the luminosity image data V to form a fluorescence diagnostic image data K<highlight><bold>0</bold></highlight> representing a fluorescence diagnostic image; and an exceptional display processing portion <highlight><bold>135</bold></highlight> for subjecting the obstructing portions of the fluorescence diagnostic image to an exceptional display process to obtain a processed fluorescence diagnostic data KP. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> The image memory <highlight><bold>131</bold></highlight> comprises a narrow band fluorescence image data storage region, a wide band fluorescence image data storage region, and an IR reflectance image data storage region, which are not shown in the drawing, wherein: the narrow band fluorescence image data K<highlight><bold>1</bold></highlight> representing the narrow band fluorescence image obtained in the state wherein the excitation light L<highlight><bold>2</bold></highlight> is being emitted and the narrow band fluorescence image optical filter <highlight><bold>123</bold></highlight><highlight><italic>a </italic></highlight>is disposed along the optical path of the fluorescence L<highlight><bold>3</bold></highlight> conveyed by the image fiber <highlight><bold>103</bold></highlight> is recorded in the narrow band fluorescence image storage region; and the wide band fluorescence image data K<highlight><bold>2</bold></highlight> representing the wide band fluorescence image obtained in the state wherein the excitation light L<highlight><bold>2</bold></highlight> is being emitted and the wide band fluorescence image optical filter <highlight><bold>123</bold></highlight><highlight><italic>b </italic></highlight>is disposed along the optical path of the fluorescence L<highlight><bold>3</bold></highlight> conveyed by the image fiber <highlight><bold>103</bold></highlight> is recorded in the wide band fluorescence image storage region. Further, the IR reflectance image data K<highlight><bold>1</bold></highlight> representing the IR reflectance image obtained in the state wherein the reference light L<highlight><bold>5</bold></highlight>, that is the white light L<highlight><bold>1</bold></highlight>, is being emitted and the IR reflectance image optical filter <highlight><bold>123</bold></highlight><highlight><italic>c </italic></highlight>is disposed along the optical path of the reflected light L<highlight><bold>6</bold></highlight>, that is, the reflected light L<highlight><bold>4</bold></highlight> conveyed by the image fiber <highlight><bold>103</bold></highlight>, is recorded in the IR reflectance image storage region. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> The exceptional display processing portion <highlight><bold>135</bold></highlight> performs an exceptional display process on the obstructing regions of the fluorescence diagnostic image represented by the fluorescence diagnostic image data K<highlight><bold>0</bold></highlight>. The exceptional display process is a process that causes the obstructing regions of the fluorescence diagnostic image to be displayed in a different form with respect to the other regions of the fluorescence diagnostic image. More specifically, the pixel values corresponding to the obstructing regions are converted to a color not appearing in any of the other regions of the fluorescence diagnostic image. For example, the pixels values of the obstructing regions can be converted to a blue color for a case in which the color change of the normal tissue and the diseased tissue of the target subject <highlight><bold>10</bold></highlight> range from green through yellow to red. Note that the color of the obstructing regions can be caused to be the same color as the background color, or the obstructing regions can be caused to be transparent. Alternatively, the images of the regions other than the obstructing regions included in the fluorescence diagnostic image can be caused to be transparent. Further, according to the current embodiment, because the fluorescence diagnostic image is a chromatic color image, the obstructing regions can also be caused to be non-chromatic in color. Note that for cases in which the fluorescence diagnostic image is a non-chromatic image, the obstructing regions can be cased to be chromatic. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> Still further, the pixels within the obstructing regions can be displayed as gradation values. More specifically, the average color value Cave obtained of the target subject <highlight><bold>10</bold></highlight> and the standard deviation Cstd can be computed in advance, and the Mahalanobis distance Cm for the pixel value Cxy of each pixel of the obstructing regions can be obtained according to the following formula (1): </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>Cm&equals;</italic></highlight>(<highlight><italic>Cxy&minus;Cave</italic></highlight>)<highlight><superscript>2</superscript></highlight><highlight><italic>/Cstd </italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> The Mahalanobis distance Cm obtained by the formula (1) increases as the possibility of an obstructing region being of a color other than the average color of the target subject <highlight><bold>10</bold></highlight> becomes higher. Accordingly, by assigning a gradation value to the value of the Mahalanobis distance Cm, the obstructing region can be displayed as a gradation image corresponding to the magnitude of the possibility that said obstructing region represents an obstructing factor. Note that instead of the gradation display, it is possible to set and display the obstructing regions at the contour lines corresponding to the Mahalanobis distance Cm. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> Further, for cases in which the portions regarded to be diseased tissue are indicated by an arrow mark, in the case of this type of display, a process whereby arrow marks are not assigned to obstructing regions is included in the exceptional display processes. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> Note that the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> can be a unit for forming a processed fluorescence diagnostic image data KP based on the factor obtained between the corresponding pixel values of the fluorescence diagnostic images represented by the fluorescence diagnostic image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight>, or based on the factor obtained by the performance of a division calculation between the pixel values of either of the fluorescence images and the pixel values of the IR reflectance image. Further, color data can be assigned to the factor obtained between the two fluorescence images or between one of the fluorescence images and the IR reflectance image, and the fluorescence diagnostic image data KP can be formed so as to represent the diseased state of the target subject <highlight><bold>10</bold></highlight> by the differences in color. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> Further, for cases in which the IR reflectance image data F<highlight><bold>1</bold></highlight> is used to form the fluorescence diagnostic image data K<highlight><bold>0</bold></highlight>, the R color data included in the standard image data N or the brightness data computed from the standard image data N can be used instead of the IR reflectance image data F<highlight><bold>1</bold></highlight>. Still further, for cases in which light of each of the colors R, G, and B is projected onto the target subject <highlight><bold>10</bold></highlight> and a standard image is obtained of the reflected light reflected from the target subject <highlight><bold>10</bold></highlight> thereupon, as described below, the color data based on the reflected red light can be used instead of the IR reflectance image data F<highlight><bold>1</bold></highlight>. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> The image processing unit <highlight><bold>140</bold></highlight> comprises a signal processing circuit <highlight><bold>141</bold></highlight> for forming an analog standard image signal of the standard image, which is a color image, represented by the signal obtained by the CCD imaging element <highlight><bold>107</bold></highlight>; an A/D converting circuit <highlight><bold>142</bold></highlight> for digitizing the standard image data formed in the signal processing circuit <highlight><bold>141</bold></highlight> to obtain a digital standard image data N; a standard image memory <highlight><bold>143</bold></highlight> for storing the standard image data N; and a video signal processing circuit <highlight><bold>144</bold></highlight> for converting the standard image data N outputted from the standard image memory <highlight><bold>143</bold></highlight> and the processed fluorescence diagnostic image data KP formed in the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> to video signals. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> The obstructing regions detecting unit <highlight><bold>150</bold></highlight> is means that detects, based on the color data of the standard image represented by a standard image data N, obstructing regions representing regions in which an obstructing factor, such as blood, mucus, digestive fluids, saliva, foam, residue and/or the like is present on the target subject <highlight><bold>10</bold></highlight>. Here, the color data can be that of, for example: the hue, saturation, and/or chromaticity (hue and saturation) of development color systems (HSB/HVC/Lab/Luv/La*b*/Lu*v* color spaces) or a mixed color) system (an X,Y,Z color space); the color differences of a visible image signal representative of a TV signal (e.g., the IQ of the YIQ of an NTSC signal, the CbCr of an YCbCr, etc.); the combination ratio of a color signal (R, G, B or C, M, Y, G), etc. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> More specifically, for the case in which the hue data is used as the color data, the standard image is of a specific hue range for cases in which the target subject <highlight><bold>10</bold></highlight> is a normal tissue and for cases in which the target subject <highlight><bold>10</bold></highlight> is a diseased tissue, respectively. On the other hand, for cases in which obstructing regions are present in the standard image, the hue of the obstructing factors is a hue other than that of either a normal tissue or a diseased tissue. Accordingly, the hue of each pixel of a standard image based on a standard image data N is computed, and a determination is made as to whether or not the hue of each pixel is the outside of a predetermined specific range; regions formed of pixels having a hue outside the predetermined specific range are detected as obstructing regions. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> Further, for the case in which the chromaticity is used as the color data, the standard image is of a specific chromaticity range on the chromaticity chart for cases in which the target subject <highlight><bold>10</bold></highlight> is a normal tissue and for cases in which the target subject <highlight><bold>10</bold></highlight> is a diseased tissue, respectively. On the other hand, for cases in which obstructing regions are present in the standard image, the chromaticity of the obstructing factors is a chromaticity other than that of a normal tissue or a diseased tissue. Accordingly, the chromaticity of each pixel of a standard image based on a standard image data N is computed, and a determination is made as to whether or not the chromaticity of each pixel is the outside of a predetermined specific range; regions formed of pixels having a chromaticity outside the predetermined specific range are detected as obstructing regions. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> Note that because the standard image data N is data formed of the data of each color R, G, B (or C, Y, G); the hue and chromaticity can be easily obtained if each color data is used. On the other hand, for the case in which the obstructing regions are detected based on the difference in color, the color difference signal can be computed from each color data R, G, B (or C, Y, G). However, according to the video signal processing circuit <highlight><bold>144</bold></highlight> according to the current embodiment, the standard image data N is converted to a video signal formed of brightness signals and color difference signals. Accordingly, if the color difference is to be used as the color data, the color difference obtained by the conversion of the standard image data N to a video signal by the video signal processing circuit <highlight><bold>144</bold></highlight> is used thereas; by the detection of the obstructing pixels by the obstructing region detecting unit <highlight><bold>150</bold></highlight>, the step wherein the color difference is computed by the obstructing regions detecting unit <highlight><bold>150</bold></highlight> can be omitted. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> Next, the operation of the first embodiment will be explained. First, the operation occurring when a standard image is to be obtained and displayed will be explained, followed by an explanation of the operations occurring when a reflectance image and a fluorescence image are to be obtained, and then an explanation of the operations occurring when the obstructing regions are detected, the fluorescence diagnostic image is synthesized, and the processed fluorescence diagnostic image is displayed will be explained. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> According to the first embodiment of the present invention, the obtainment of a standard image, an IR reflectance image, and a fluorescence image are performed alternately in a temporal series. When the standard image and the IR reflectance image are to be obtained, the white light source power source <highlight><bold>112</bold></highlight> is activated, based on a signal from the controller <highlight><bold>160</bold></highlight>, and white light L<highlight><bold>1</bold></highlight> is emitted from the white light source <highlight><bold>111</bold></highlight>. The white light L<highlight><bold>1</bold></highlight> is transmitted by the white light condensing lens <highlight><bold>113</bold></highlight> and enters the white light guide <highlight><bold>101</bold></highlight><highlight><italic>a</italic></highlight>, and after being guided to the distal end of the endoscope insertion portion <highlight><bold>100</bold></highlight>, is projected onto the target subject <highlight><bold>10</bold></highlight> from the illuminating lens <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> The reflected light L<highlight><bold>4</bold></highlight> of the white light L<highlight><bold>1</bold></highlight> is focused by the objective lens <highlight><bold>105</bold></highlight>, reflected by the prism <highlight><bold>108</bold></highlight>, transmitted by the RGB filter <highlight><bold>109</bold></highlight>, and focused on the CCD imaging element <highlight><bold>107</bold></highlight>. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> The signal processing circuit <highlight><bold>141</bold></highlight> forms an analog standard image signal, which represents a color image, from the reflected light L<highlight><bold>4</bold></highlight> imaged by the CCD imaging element <highlight><bold>107</bold></highlight>. The analog standard image signal is inputted to the A/D converting circuit <highlight><bold>142</bold></highlight>, and after being digitized therein, is stored in the standard image memory <highlight><bold>143</bold></highlight>. The standard image data N stored in the standard image memory <highlight><bold>143</bold></highlight> is converted to a video signal by the video signal converting circuit <highlight><bold>144</bold></highlight>, and then input to the monitor <highlight><bold>170</bold></highlight> and displayed thereon as a visible image. The series of operations described above are controlled by the controller <highlight><bold>160</bold></highlight>. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> Meanwhile, at the same time, the reflected light L<highlight><bold>4</bold></highlight> of the white light L<highlight><bold>1</bold></highlight> (including the reflected light L<highlight><bold>6</bold></highlight> of the reference light L<highlight><bold>5</bold></highlight>) is focused by the condensing lens <highlight><bold>106</bold></highlight>, enters the distal end of the image fiber <highlight><bold>103</bold></highlight>, passes through the image fiber <highlight><bold>103</bold></highlight> and is focused by the collimator lens <highlight><bold>128</bold></highlight>, and is transmitted by the excitation light cutoff filter <highlight><bold>121</bold></highlight> and the optical filter <highlight><bold>123</bold></highlight><highlight><italic>c </italic></highlight>of the switching filter <highlight><bold>122</bold></highlight>. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> Because the optical filter <highlight><bold>123</bold></highlight><highlight><italic>c </italic></highlight>is a band pass filter that only transmits light of a wavelength in the 750-900 nm wavelength band, only the reflected light L<highlight><bold>6</bold></highlight> of the reference light L<highlight><bold>5</bold></highlight> is transmitted by the optical filter <highlight><bold>123</bold></highlight><highlight><italic>c. </italic></highlight></paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> The reflected light L<highlight><bold>6</bold></highlight> transmitted by the optical filter <highlight><bold>123</bold></highlight><highlight><italic>c </italic></highlight>is received by the CCD imaging element <highlight><bold>125</bold></highlight>. The analog IR reflectance image data obtained by the photoelectric conversion performed by the CCD imaging element <highlight><bold>125</bold></highlight> is digitized by the A/D converting circuit <highlight><bold>126</bold></highlight>, and then stored as an IR reflectance image data F<highlight><bold>1</bold></highlight> in the IR reflectance image region of the image memory <highlight><bold>131</bold></highlight> of the fluorescence image forming unit <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> Next, the operation occurring when the fluorescence image is to be obtained will be explained. The excitation light source power source <highlight><bold>115</bold></highlight> is activated, based on a signal from the controller <highlight><bold>160</bold></highlight>, and a 410 nm wavelength excitation light L<highlight><bold>2</bold></highlight> is emitted from the GaN type semiconductor laser <highlight><bold>114</bold></highlight>. The excitation light L<highlight><bold>2</bold></highlight> is transmitted by the excitation light condensing lens <highlight><bold>116</bold></highlight> and enters the excitation light guide <highlight><bold>10</bold></highlight><highlight><italic>b</italic></highlight>, and after being guided to the distal end of the endoscope insertion portion <highlight><bold>100</bold></highlight>, is projected onto the target subject <highlight><bold>10</bold></highlight> from the illuminating lens <highlight><bold>104</bold></highlight>. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> The fluorescence L<highlight><bold>3</bold></highlight> emitted from the target subject <highlight><bold>10</bold></highlight> upon the irradiation thereof by the excitation light L<highlight><bold>2</bold></highlight> is focused by the condensing lens <highlight><bold>106</bold></highlight>, enters the distal end of the image fiber <highlight><bold>103</bold></highlight>, passes through the image fiber <highlight><bold>103</bold></highlight> and is focused by the collimator lens <highlight><bold>128</bold></highlight>, and is transmitted by the excitation light cutoff filter <highlight><bold>121</bold></highlight> and the optical filters <highlight><bold>123</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>123</bold></highlight><highlight><italic>b </italic></highlight>of the switching filter <highlight><bold>122</bold></highlight>. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> Because the optical filter <highlight><bold>123</bold></highlight><highlight><italic>a </italic></highlight>is a band pass filter that only transmits light of a wavelength in the 430-730 nm wavelength band, the fluorescence L<highlight><bold>3</bold></highlight> transmitted by the optical filter <highlight><bold>123</bold></highlight><highlight><italic>a </italic></highlight>represents a wide band fluorescence image. Because the optical filter <highlight><bold>123</bold></highlight><highlight><italic>b </italic></highlight>is a band pass filter that only transmits light of a wavelength of 480&plusmn;50 nm, the fluorescence L<highlight><bold>3</bold></highlight> transmitted by the optical filter <highlight><bold>123</bold></highlight><highlight><italic>b </italic></highlight>represents a narrow band fluorescence image. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> The fluorescence L<highlight><bold>3</bold></highlight> representing the narrow band fluorescence image and the wide band fluorescence image is received by the CCD imaging element <highlight><bold>125</bold></highlight>, photoelectrically converted thereby, digitized by the A/D converting circuit <highlight><bold>126</bold></highlight>, and then stored as a wide band fluorescence image data K<highlight><bold>1</bold></highlight> in the wide band fluorescence image region and a narrow band fluorescence image data K<highlight><bold>2</bold></highlight> the narrow band fluorescence image region of the image memory <highlight><bold>131</bold></highlight> of the fluorescence image forming unit <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> Hereinafter the operation occurring when a processed fluorescence diagnostic image data KP is to be formed by the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> will be explained. First, the luminosity image computing portion <highlight><bold>132</bold></highlight> determines, utilizing the signal charge and a look up table, a luminosity occurring in a Munsel display color system for each pixel value of the IR reflectance image represented by the IR reflectance image data F<highlight><bold>1</bold></highlight> to obtain a luminosity image data V, and outputs said luminosity image data V to the image synthesizing means <highlight><bold>134</bold></highlight>. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> The hue computing portion <highlight><bold>133</bold></highlight> of the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> divides the pixel value of each pixel of the narrow band fluorescence image represented by the narrow band fluorescence image data K<highlight><bold>2</bold></highlight> by the pixel value of each corresponding pixel of the wide band fluorescence image represented by the in the wide band fluorescence image data K<highlight><bold>1</bold></highlight> stored in the image memory <highlight><bold>131</bold></highlight> to obtain the respective factors thereof, and obtains, utilizing said factors and a prerecorded lookup table, a hue occurring in a Munsel display color system to obtain a hue image data H, and outputs the hue image data H to the image synthesizing portion <highlight><bold>134</bold></highlight>. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> The image synthesizing portion <highlight><bold>134</bold></highlight> synthesizes the hue image data H and the luminosity image data V to form a fluorescence diagnostic image K<highlight><bold>0</bold></highlight> representing a fluorescence diagnostic image. Note that for cases in which the image is to be displayed in color, the image is displayed as a three color image; because the hue, luminosity, and saturation are required, when the image is synthesized, the largest values of the hue and the luminosity are obtained as the saturation S occurring in a Munsel display color system. Note that the fluorescence diagnostic image data K<highlight><bold>0</bold></highlight> is subjected to an RGB conversion process, and becomes an image representing each of color R, G, and B. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> Meanwhile, the obstructing regions detecting unit <highlight><bold>150</bold></highlight> detects, based on the color data of the standard image represented by the standard image data N, the regions of the target subject <highlight><bold>10</bold></highlight> on which an obstructing factor is present. Then, the exceptional display process unit <highlight><bold>135</bold></highlight> of the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> subjects the obstructing regions of the fluorescence diagnostic image represented by the fluorescence diagnostic image data K<highlight><bold>0</bold></highlight> to an exceptional display process to obtain a processed fluorescence diagnostic image data KP. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> Hereinafter, the operations occurring from the detection of the obstructing regions to the performance of the exceptional display process will be explained utilizing the flowchart of <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flowchart of the operations occurring from the detection of the obstructing regions to the performance of the exceptional display process. First, the color data of each pixel of the standard image is computed by the obstructing regions detecting unit <highlight><bold>150</bold></highlight> (step S<highlight><bold>1</bold></highlight>), and then, a determination is made as to whether or not the color data obtained of each pixel of the standard image is outside a predetermined range (step S<highlight><bold>2</bold></highlight>). If the result of the determination made in step S<highlight><bold>2</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, the corresponding pixel thereto of the fluorescence diagnostic image is subjected to no process whatsoever (step S<highlight><bold>3</bold></highlight>). If the result of the determination made in step S<highlight><bold>2</bold></highlight> is a positive, the pixel of which a positive result is obtained is recognized as a pixel representing an obstructing region, and the corresponding pixel thereto of the fluorescence diagnostic image represented by the fluorescence diagnostic image data K<highlight><bold>0</bold></highlight> is subjected to the exceptional display process by the exceptional display process portion <highlight><bold>135</bold></highlight> of the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> to obtain a processed fluorescence diagnostic image data KP (step S<highlight><bold>4</bold></highlight>). </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> The processed fluorescence diagnostic image data KP is outputted to the video signal processing circuit <highlight><bold>144</bold></highlight> of the image processing unit <highlight><bold>140</bold></highlight>. The processed fluorescence diagnostic image data KP which has been converted to a video signal by the video signal processing circuit <highlight><bold>144</bold></highlight> is inputted to the monitor <highlight><bold>180</bold></highlight> and displayed thereon as a visible image. The obstructing regions of the processed fluorescence diagnostic image displayed on the monitor <highlight><bold>180</bold></highlight> have been subjected to the exceptional display process. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> In this manner, the according to the current embodiment, because the obstructing regions within the fluorescence diagnostic image have been detected, by displaying on the monitor <highlight><bold>180</bold></highlight> the processed fluorescence diagnostic image obtained by subjecting the detected obstructing regions therein to an exceptional display process, the obstructing regions included in the fluorescence diagnostic image can be recognized in at a glance. Accordingly, an accurate diagnosis can be performed utilizing the fluorescence diagnostic image with no fear that obstructing regions will be diagnosed to be diseased tissue. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> Further, if the exceptional display process consists of subjecting the images other than the obstructing regions occurring in the fluorescence diagnostic image to a process whereby said other regions are rendered transparent to obtain a processed fluorescence diagnostic image, and said obtained processed fluorescence diagnostic image is superposed over the standard image and displayed on the monitor <highlight><bold>180</bold></highlight>, by observing said displayed standard image, the obstructing regions included therein can be recognized as such at a glance. Accordingly, the fear that a tissue in a diseased state appearing within an obstructing region will be overlooked is eliminated, and the accuracy with which the diagnosis can be performed using the fluorescence diagnostic image is improved a level. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> Still further, if a configuration is adopted wherein the exceptional display process is capable of being selected, by use of an external switch or the like, from a plurality of exceptional display processes, the operational ease and versatility of the present apparatus can be improved a level. In when a standard diagnosis, for example, is to be performed, by displaying a fluorescence diagnostic image in which the obstructing regions included therein are of achromatic color, and the other portions thereof are of chromatic color, the misdiagnosis of obstructing regions as diseased tissue is prevented; on the other hand, by subjecting the images other than the obstructing regions occurring in the fluorescence diagnostic image to a process whereby said other regions are rendered transparent to obtain a processed fluorescence diagnostic image, and superposing said obtained processed fluorescence diagnostic image over the standard image immediately prior to concluding the diagnosis, the overlooking of diseased tissue included within the obstructing regions can be prevented. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> Further, because the color of the obstructing regions differs from the color of the other regions, by detecting the obstructing regions based on the color data of the standard image, the obstructing regions can be detected accurately. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> Next, the second embodiment of the present invention will be explained. <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a schematic drawing of the main part of a fluorescence endoscope apparatus implementing the fluorescence image obtaining apparatus according to the second embodiment of the present invention. Note that elements of the second embodiment that are the same as those of the first embodiment are likewise labeled, and further explanation thereof omitted. As shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the fluorescence endoscope apparatus according to the second embodiment of the present invention differs from that of the first embodiment in that instead of the obstructing regions detecting unit <highlight><bold>150</bold></highlight>, which detects the obstructing regions based on the color data of the standard image, an obstructing regions detecting unit <highlight><bold>151</bold></highlight>, which detects the obstructing regions based on the fluorescence intensity and the factor, that is the ratio between the pixel values of the corresponding pixels of two fluorescence images represented by two fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight>, respectively, is provided. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> Here, the factor (hereinafter referred to as the computed fluorescence value) of the corresponding pixel values between the fluorescence images represented by the fluorescence image data K<highlight><bold>1</bold></highlight> and K<highlight><bold>2</bold></highlight> for an obstructing region is smaller than the value obtained of normal tissue and is close to the value obtained of a diseased tissue. On the other hand, the fluorescence intensity of an obstructing region is close to that of a normal tissue. Accordingly, the obstructing regions detecting unit <highlight><bold>151</bold></highlight> obtains the computed fluorescence value from the fluorescence image data K<highlight><bold>1</bold></highlight> and K<highlight><bold>2</bold></highlight>, and makes a determination as to whether or not the obtained computed fluorescence value is less than or equal to a predetermined threshold value Th<highlight><bold>1</bold></highlight>. Next, a determination is made with respect to only the pixels of which the pixel value thereof has been determined to be less than or equal to the threshold value Th<highlight><bold>1</bold></highlight>, as to whether or not the fluorescence intensity thereof, that is, the fluorescence intensity of the pixel values of the fluorescence image represented by the fluorescence image data K<highlight><bold>1</bold></highlight> or K<highlight><bold>2</bold></highlight> is greater than or equal to a second threshold value Th<highlight><bold>2</bold></highlight>; the pixels of which the fluorescence intensity is determined to be greater than or equal to the threshold value Th<highlight><bold>2</bold></highlight> are detected as obstructing regions. Note that instead of obtaining the computed fluorescence value itself, the obstructing regions detecting unit <highlight><bold>151</bold></highlight> can utilize the factor obtained of the corresponding pixels between the fluorescence images by the hue computing means <highlight><bold>133</bold></highlight> of the fluorescence diagnostic image forming means <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> Next, the operation of the second embodiment will be explained. The operations occurring when the standard image is to be obtained, the standard image is to be displayed, the IR reflectance image is to be obtained, the fluorescence images are to be obtained, and the fluorescence diagnostic image is to be synthesized are the same as those occurring in the first embodiment; therefore, further explanation thereof is omitted. The operations occurring when the obstructing regions are to be detected and the processed fluorescence diagnostic image is to be displayed will be explained. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a flowchart of the operations from the detection of the obstructing regions to the performance of the exceptional display process according to the second embodiment. As shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>: first, the ratio between the fluorescence images represented by the fluorescence image data K<highlight><bold>1</bold></highlight> and K<highlight><bold>2</bold></highlight>, that is, the computed fluorescence value therebetween, is obtained by the obstructing regions detecting unit <highlight><bold>151</bold></highlight> (step S<highlight><bold>11</bold></highlight>); then, a determination as to whether or not the computed fluorescence value of each pixel of the fluorescence images is less than or equal to the threshold value Th<highlight><bold>1</bold></highlight> (step S<highlight><bold>12</bold></highlight>) If the result of the determination made in step S<highlight><bold>12</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, the corresponding pixel thereto of the fluorescence diagnostic image is subjected to no process whatsoever (step S<highlight><bold>13</bold></highlight>). If the result of the determination made in step S<highlight><bold>12</bold></highlight> is a positive, because the possibility is high that the pixel of which a positive result is obtained is a pixel representing an obstructing region, a determination is made as to whether or not the fluorescence intensity thereof is greater than or equal to the threshold value Th<highlight><bold>2</bold></highlight> (step S<highlight><bold>14</bold></highlight>). If the result of the determination made in step S<highlight><bold>14</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, the corresponding pixel thereto of the fluorescence diagnostic image is subjected to no process whatsoever (step S<highlight><bold>13</bold></highlight>). If the result of the determination made in step S<highlight><bold>14</bold></highlight> is a positive, the pixel of the fluorescence image represented by the respective fluorescence image data K<highlight><bold>1</bold></highlight> or K<highlight><bold>2</bold></highlight> is detected as an obstructing region, and the corresponding fluorescence diagnostic image data K<highlight><bold>0</bold></highlight> is subjected to the exceptional display process by the exceptional display process portion <highlight><bold>135</bold></highlight> of the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> to obtain a processed fluorescence diagnostic image data KP (step S<highlight><bold>15</bold></highlight>). </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> The processed fluorescence diagnostic image data KP is outputted to the video signal processing circuit <highlight><bold>144</bold></highlight> of the image processing unit <highlight><bold>140</bold></highlight>, and displayed on the monitor <highlight><bold>180</bold></highlight> as a visible image in the state in which the obstructing regions of the processed fluorescence diagnostic image have been subjected to the exceptional display process, in the same manner as occurred in the first embodiment. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> Note that according to the second embodiment, although the determination performed in step <highlight><bold>14</bold></highlight> as to whether or not the pixel value is greater than or equal to the threshold value Th<highlight><bold>2</bold></highlight> is performed only on the pixels of which the computed fluorescence value has been determined to be less than or equal to the threshold value Th<highlight><bold>1</bold></highlight> is the step S<highlight><bold>12</bold></highlight>, the determination of step S<highlight><bold>14</bold></highlight> can be performed first, and the computed fluorescence value obtained and the process of step S<highlight><bold>11</bold></highlight> and the determination of S<highlight><bold>12</bold></highlight> performed only for pixels that have returned a positive result in step S<highlight><bold>14</bold></highlight>. Further, the process of step S<highlight><bold>11</bold></highlight>, the determination of step S<highlight><bold>12</bold></highlight>, and the determination of step S<highlight><bold>14</bold></highlight> can be performed in a series for all pixels, and the pixels of which the computed fluorescence value is less than or equal to the threshold value Th<highlight><bold>1</bold></highlight> and which also have a pixel value greater than or equal to the threshold value Th<highlight><bold>2</bold></highlight> detected as obstructing regions. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> Further, according to the second embodiment, for cases in which the pixels within the obstructing regions are to be displayed with a display gradation: first, the average value FL ave of the fluorescence intensity obtained of the target subject <highlight><bold>10</bold></highlight> and the standard deviation FL std are computed in advance, and the Mahalanobis distance Fm of each pixel value FL xy included in the obstructing regions is obtained according to the formula (2) below. </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>Fm&equals;</italic></highlight>(<highlight><italic>FLxy&minus;Flave</italic></highlight>)<highlight><superscript>2</superscript></highlight><highlight><italic>/FL std</italic></highlight>&emsp;&emsp;(2) </in-line-formula></paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> The length of the Mahalanobis distance Fm obtained by use of the formula (2) becomes longer in proportion to an increase in the possibility that the fluorescence intensity is that of an obstructing region, which deviates from the average fluorescence intensity of the target subject <highlight><bold>10</bold></highlight>. Accordingly, by assigning a gradation to the value of the Mahalanobis distance Fm, the obstructing regions can be displayed with a display gradation corresponding to the increase in the possibility that the obstructing region represents an obstructing factor. Note that instead of employing the display gradation, a contour line can be set in the obstructing regions in correspondence to the length of the Mahalanobis distance Fm, and displayed as a contour display. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> Further, according to the second embodiment described above, the obtainment of a standard image, an IR reflectance image, and fluorescence images is performed, however, as shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, even if the fluorescence endoscope apparatus comprises only: an endoscope insertion portion <highlight><bold>100</bold></highlight>&prime; provided with only a light guide <highlight><bold>101</bold></highlight>, an image fiber <highlight><bold>103</bold></highlight>, an illuminating lens <highlight><bold>104</bold></highlight>, and a condensing lens <highlight><bold>106</bold></highlight>; an illuminating unit <highlight><bold>110</bold></highlight>&prime; provided with only a GaN type semiconductor laser <highlight><bold>114</bold></highlight>, an excitation light power source <highlight><bold>115</bold></highlight>, and an excitation light condensing lens <highlight><bold>116</bold></highlight>; an image obtaining unit <highlight><bold>120</bold></highlight>&prime; provided with a switching filter <highlight><bold>122</bold></highlight>&prime;, which has only an optical filters <highlight><bold>123</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>123</bold></highlight><highlight><italic>b</italic></highlight>, instead of the switching filter <highlight><bold>122</bold></highlight>; a fluorescence diagnostic image forming means <highlight><bold>130</bold></highlight>&prime; formed only of an image memory <highlight><bold>131</bold></highlight>, a computed fluorescence value obtaining portion <highlight><bold>137</bold></highlight>, and an exceptional display process portion <highlight><bold>135</bold></highlight> for subjecting the obstructing portions of the computed image represented by the computed fluorescence values to obtain a processed fluorescence image data KP; an image process portion <highlight><bold>140</bold></highlight>&prime; formed provided with only a video processing circuit <highlight><bold>144</bold></highlight>; a controller <highlight><bold>160</bold></highlight>; and a monitor <highlight><bold>180</bold></highlight> for displaying the fluorescence diagnostic image; wherein, only fluorescence images are obtained and the computed fluorescence values thereof obtained, and said computed fluorescence values displayed as fluorescence diagnostic images, the obstructing regions can be subjected to the exceptional display process and displayed in the same manner as in the second embodiment. </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> Next, the third embodiment of the present invention will be explained. <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a schematic drawing of the main part of a fluorescence endoscope apparatus implementing the fluorescence image obtaining apparatus according to the third embodiment of the present invention. Note that elements of the third embodiment that are the same as those of the first embodiment are likewise labeled, and further explanation thereof omitted. As shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, the fluorescence endoscope apparatus according to the third embodiment of the present invention differs from that of the first embodiment in that instead of the obstructing regions detecting unit <highlight><bold>150</bold></highlight>, which detects the obstructing regions based on the color data of the standard image, an obstructing regions detecting unit <highlight><bold>152</bold></highlight>, which detects the obstructing regions based on the color data of the standard image and the fluorescence intensity, is provided. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> Here, the color of an obstructing region is different from that of either that the normal or the diseased tissue. Further, the fluorescence intensity (i.e., the pixel values) of an obstructing region is close to that of normal tissue. Accordingly, the obstructing regions detecting unit <highlight><bold>152</bold></highlight> determines whether or not the color data of the standard image is outside a predetermined range, and then determines whether or not the pixel values of the fluorescence image corresponding to the pixels of which the color data is outside the predetermined range are greater than or equal to a predetermined threshold value Th<highlight><bold>3</bold></highlight>; the regions formed from the pixel values determined to be greater than or equal to the threshold value Th<highlight><bold>3</bold></highlight> are detected as obstructing regions. </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> Next, the operation of the third embodiment will be explained. The operations occurring when the standard image is to be obtained, the standard image is to be displayed, the reflectance image is to be obtained, the fluorescence images are to be obtained, and the fluorescence diagnostic image is to be synthesized are the same as those occurring in the first embodiment; therefore, further explanation thereof is omitted. The operations occurring when the obstructing regions are to be detected and the processed fluorescence diagnostic image is to be displayed will be explained. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a flowchart of the operations from the detection of the obstructing regions to the performance of the exceptional display process according to the third embodiment. As shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>: first, the color data of each pixel of the standard image is computed (step S<highlight><bold>21</bold></highlight>); then, a determination as to whether or not the color data of each pixel of the standard image is outside the predetermined range (step S<highlight><bold>22</bold></highlight>). If the result of the determination made in step S<highlight><bold>22</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, no process whatsoever is performed thereon (step S<highlight><bold>23</bold></highlight>). If the result of the determination made in step S<highlight><bold>22</bold></highlight> is a positive, because the possibility is high that the pixel of which a positive result is obtained represents an obstructing region, a determination is made as to whether or not the pixel value of the corresponding pixel of the fluorescence image is greater than or equal to the threshold value Th<highlight><bold>3</bold></highlight> (step S<highlight><bold>24</bold></highlight>). If the result of the determination made in step S<highlight><bold>24</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, no process whatsoever is performed thereon (step S<highlight><bold>23</bold></highlight>). If the result of the determination made in step S<highlight><bold>24</bold></highlight> is a positive, the pixel of which the positive result was returned is recognized as representing an obstructing region, and the corresponding fluorescence diagnostic image data K<highlight><bold>0</bold></highlight> is subjected to the exceptional display process by the exceptional display process portion <highlight><bold>135</bold></highlight> to obtain a processed fluorescence diagnostic image data KP (step S<highlight><bold>35</bold></highlight>). </paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> The processed fluorescence diagnostic image data KP is outputted to the video signal processing circuit <highlight><bold>144</bold></highlight> of the image processing unit <highlight><bold>140</bold></highlight>, and displayed on the monitor <highlight><bold>180</bold></highlight> as a visible image in the state in which the obstructing regions of the processed fluorescence diagnostic image have been subjected to the exceptional display process, in the same manner as occurred in the first embodiment. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> Note that according to the third embodiment, although the determination performed in step <highlight><bold>24</bold></highlight> as to whether or not the pixel value of the fluorescence image is greater than or equal to the threshold value Th<highlight><bold>3</bold></highlight> is performed only on the pixels of which the color data has been determined to be outside the predetermined range in the step S<highlight><bold>22</bold></highlight>, the determination of step S<highlight><bold>24</bold></highlight> can be performed first, and the color data obtained and the determination of S<highlight><bold>22</bold></highlight> performed only for pixels that have returned a positive result in step S<highlight><bold>24</bold></highlight>. Further, the determination of step S<highlight><bold>22</bold></highlight> and the determination of step S<highlight><bold>24</bold></highlight> can be performed in a series for all pixels, and the pixels of the standard image of which the color data is outside the predetermined range and the corresponding pixels in the fluorescence image which also have a pixel value greater than or equal to the threshold value Th<highlight><bold>3</bold></highlight> can be detected as obstructing regions. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> Note that according to the third embodiment, for cases in which the pixels within the obstructing regions are to be displayed with a display gradation or as a contour line: first, using formula (1) or formula (2), the Mahalanobis distances Cm and Fm are obtained, and a display gradation can be assigned thereto or a contour line set therefor. Further, as shown in the formula (3) below, the Mahalanobis distances Cm and Fm can be subjected to a weighted addition process to obtain a total distance Gm, and a display gradation can be assigned to the total distance Gm, or a contour line set corresponding to the total distance Gm: </paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>Gm&equals;</italic></highlight>&agr;&middot;Cm&plus;&bgr;&middot;Fm&emsp;&emsp;(3) </in-line-formula></paragraph>
<paragraph id="P-0138" lvl="2"><number>&lsqb;0138&rsqb;</number> where &agr; and &bgr; are weighing coefficients. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> Next, the fourth embodiment of the present invention will be explained. The fluorescent endoscope according to the fourth embodiment differs from the fluorescence endoscope apparatus according to the third embodiment shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, in that instead of the obstructing regions detecting unit <highlight><bold>152</bold></highlight>, an obstructing regions detecting unit <highlight><bold>153</bold></highlight>, which detects the obstructing regions based on the color data of the standard image and the ratio, that is the factor obtained between the corresponding pixels of the fluorescence images represented by two fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight>, is provided. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> Here, the color of an obstructing region is different from that of either that the normal or the diseased tissue. Further, the factor (hereinafter referred to as the computed fluorescence value) obtained between the corresponding pixels of the fluorescence images represented by the fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight> for an obstructing region is smaller than the value obtained of normal tissue and is close to that obtained of a diseased tissue. Accordingly, the obstructing regions detecting unit <highlight><bold>153</bold></highlight> determines whether or not the color data of the standard image is outside a predetermined range, then obtains the computed fluorescence value from the fluorescence image data K<highlight><bold>1</bold></highlight> and K<highlight><bold>2</bold></highlight> only for the pixels of the fluorescence image corresponding to the pixels that have been determined to be outside the predetermined color range, and makes a determination as to whether or not the obtained computed fluorescence values are less than or equal to a predetermined threshold value Th<highlight><bold>4</bold></highlight>; the pixels of which the computed fluorescence value has been found to be less than or equal to the threshold value Th<highlight><bold>4</bold></highlight> are detected as obstructing regions. Note that instead of obtaining the computed fluorescence value itself, the obstructing regions detecting unit <highlight><bold>153</bold></highlight> can utilize the factor obtained of the corresponding pixels between the fluorescence images by the hue computing means <highlight><bold>133</bold></highlight> of the fluorescence diagnostic image forming means <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> Next, the operation of the fourth embodiment will be explained. The operations occurring when the standard image is to be obtained, the standard image is to be displayed, the IR reflectance image is to be obtained, the fluorescence images are to be obtained, and the fluorescence diagnostic image is to be synthesized are the same as those occurring in the first embodiment; therefore, further explanation thereof is omitted. The operations occurring when the obstructing regions are to be detected and the processed fluorescence diagnostic image is to be displayed will be explained. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flowchart of the operations from the detection of the obstructing regions to the performance of the exceptional display process according to the fourth embodiment. As shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>: first, the color data of each pixel of the standard image is computed (step S<highlight><bold>31</bold></highlight>); then, a determination is made as to whether or not the color data of each pixel of the standard image is outside the predetermined range (step S<highlight><bold>32</bold></highlight>). If the result of the determination made in step S<highlight><bold>32</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, no process whatsoever is performed thereon (step S<highlight><bold>33</bold></highlight>). If the result of the determination made in step S<highlight><bold>22</bold></highlight> is a positive, because the possibility is high that the pixel of which a positive result is obtained represents an obstructing region, the factor between the fluorescence images represented by the fluorescence image data K<highlight><bold>1</bold></highlight> and K<highlight><bold>2</bold></highlight>, that is, the computed fluorescence value therebetween, is obtained only for the pixels corresponding to the pixels of the standard image which are outside the predetermined color range (step S<highlight><bold>34</bold></highlight>). Then, a determination as to whether or not the computed fluorescence value of each pixel of the fluorescence images is less than or equal to the threshold value Th<highlight><bold>4</bold></highlight> (step S<highlight><bold>35</bold></highlight>). If the result of the determination made in step S<highlight><bold>35</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, no process whatsoever is performed thereon (step S<highlight><bold>33</bold></highlight>). If the result of the determination made in step S<highlight><bold>35</bold></highlight> is a positive, the pixel of which the positive result has been returned is recognized as representing an obstructing region, and the fluorescence diagnostic image data K<highlight><bold>0</bold></highlight> corresponding thereto is subjected to the exceptional display process by the exceptional display process portion <highlight><bold>135</bold></highlight> of the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> to obtain a processed fluorescence diagnostic image data KP (step S<highlight><bold>36</bold></highlight>). </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> The processed fluorescence diagnostic image data KP is outputted to the video signal processing circuit <highlight><bold>144</bold></highlight> of the image processing unit <highlight><bold>140</bold></highlight>, and displayed on the monitor <highlight><bold>180</bold></highlight> as a visible image in the state in which the obstructing regions of the processed fluorescence diagnostic image have been subjected to the exceptional display process, in the same manner as occurred in the first embodiment. </paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> Note that according to the fourth embodiment, although obtainment of the computed fluorescence value in step S<highlight><bold>34</bold></highlight> and the determination performed in step <highlight><bold>35</bold></highlight> as to whether or not the computed fluorescence value is less than or equal to the threshold value Th<highlight><bold>4</bold></highlight> is performed only on the pixels of which the color data has been determined to be outside the predetermined range in the step S<highlight><bold>32</bold></highlight>, the determination of step S<highlight><bold>34</bold></highlight> and the process of step S<highlight><bold>34</bold></highlight> can be performed first, and the color data obtained and the determination of S<highlight><bold>32</bold></highlight> performed only for pixels that have returned a positive result in step S<highlight><bold>35</bold></highlight>. Further, the determination of step S<highlight><bold>32</bold></highlight>, the determination of step S<highlight><bold>34</bold></highlight>, and the determination of step S<highlight><bold>35</bold></highlight> can be performed in a series for all pixels, and the pixels of the standard image of which the color data is outside the predetermined range and the pixels corresponding thereto in the fluorescence image which also have a computed fluorescence value less than or equal to the threshold value Th<highlight><bold>4</bold></highlight> can be detected as obstructing regions. </paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> Next, the fifth embodiment of the present invention will be explained. The fluorescent endoscope according to the fifth embodiment differs from the fluorescence endoscope apparatus according to the third embodiment shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, in that instead of the obstructing regions detecting unit <highlight><bold>152</bold></highlight>, an obstructing regions detecting unit <highlight><bold>154</bold></highlight>, which detects the obstructing regions based on the color data of the standard image, the fluorescence intensity and the ratio, that is the factor obtained between the corresponding pixels of the fluorescence images represented by two fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight>, is provided. </paragraph>
<paragraph id="P-0146" lvl="0"><number>&lsqb;0146&rsqb;</number> Here, the color of an obstructing region is different from that of either that the normal or the diseased tissue. Further, the fluorescence intensity obtained of an obstructing region is close to that obtained of a normal tissue. Still further, the factor (hereinafter referred to as the computed fluorescence value) obtained between the corresponding pixels of the fluorescence images represented by the fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight> for an obstructing region is smaller than the value obtained of normal tissue and is close to the value obtained of a diseased tissue. Accordingly, the obstructing regions detecting unit <highlight><bold>154</bold></highlight> determines whether or not the color data of the standard image is outside a predetermined range, determines whether or not the pixel values, corresponding to those of which the color data is outside the predetermined range, of the fluorescence image are greater than the predetermined threshold value Th<highlight><bold>5</bold></highlight>, obtains the computed fluorescence value from the fluorescence image data K<highlight><bold>1</bold></highlight> and K<highlight><bold>2</bold></highlight> only for the pixels having a pixel value greater than or equal to the threshold value Th<highlight><bold>5</bold></highlight>, and determines whether or not the obtained computed fluorescence values are less than or equal to a predetermined threshold value Th<highlight><bold>6</bold></highlight>; the pixels of which the computed fluorescence value has been found to be less than or equal to the threshold value Th<highlight><bold>6</bold></highlight> are detected as obstructing regions. Note that instead of obtaining the computed fluorescence value itself, the obstructing regions detecting unit <highlight><bold>154</bold></highlight> can utilize the factor obtained of the corresponding pixels between the fluorescence images by the hue computing means <highlight><bold>133</bold></highlight> of the fluorescence diagnostic image forming means <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0147" lvl="0"><number>&lsqb;0147&rsqb;</number> Next, the operation of the fifth embodiment will be explained. The operations occurring when the standard image is to be obtained, the standard image is to be displayed, the IR reflectance image is to be obtained, the fluorescence images are to be obtained, and the fluorescence diagnostic image is to be synthesized are the same as those occurring in the first embodiment; therefore, further explanation thereof is omitted. The operations occurring when the obstructing regions are to be detected and the processed fluorescence diagnostic image is to be displayed will be explained. </paragraph>
<paragraph id="P-0148" lvl="0"><number>&lsqb;0148&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a flowchart of the operations from the detection of the obstructing regions to the performance of the exceptional display process according to the fifth embodiment. As shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>: first, the color data of each pixel of the standard image is computed (step S<highlight><bold>41</bold></highlight>); then, a determination as to whether or not the color data of each pixel of the standard image is outside the predetermined range (step S<highlight><bold>42</bold></highlight>). If the result of the determination made in step S<highlight><bold>32</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, no process whatsoever is performed thereon (step S<highlight><bold>43</bold></highlight>). If the result of the determination made in step S<highlight><bold>22</bold></highlight> is a positive, because the possibility is high that the pixel of which a positive result is obtained represents an obstructing region, a determination is made as to whether or not the pixels, corresponding to the pixels of the standard image which are outside the predetermined color range, of the fluorescence images are greater than or equal to the threshold value Th<highlight><bold>5</bold></highlight> (step S<highlight><bold>44</bold></highlight>). If the result of the determination made in step S<highlight><bold>44</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, no process whatsoever is performed thereon (step S<highlight><bold>43</bold></highlight>). If the result of the determination made in step S<highlight><bold>44</bold></highlight> is a positive, because the possibility is high that the pixel of which a positive result is obtained is a pixel representing an obstructing region, the factor, that is the computed fluorescence value between the fluorescence images represented by two fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight> is obtained for only the pixels of which the pixel value is greater than or equal to the threshold Th<highlight><bold>5</bold></highlight> (step S<highlight><bold>45</bold></highlight>). Then, a determination is made as to whether or not the computed fluorescence values are less than or equal to the threshold value Th<highlight><bold>6</bold></highlight> (step S<highlight><bold>46</bold></highlight>). If the result of the determination made in step S<highlight><bold>46</bold></highlight> is a negative, because the pixel of which a negative result is obtained is not a pixel representing an obstructing region, the corresponding pixel thereto of the fluorescence diagnostic image is subjected to no process whatsoever (step S<highlight><bold>43</bold></highlight>). If the result of the determination made in step S<highlight><bold>46</bold></highlight> is a positive, the pixel of which the positive result has been returned is recognized as an obstructing region, and the corresponding fluorescence diagnostic image data K<highlight><bold>0</bold></highlight> is subjected to the exceptional display process by the exceptional display process portion <highlight><bold>135</bold></highlight> of the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight> to obtain a processed fluorescence diagnostic image data KP (step S<highlight><bold>47</bold></highlight>). </paragraph>
<paragraph id="P-0149" lvl="0"><number>&lsqb;0149&rsqb;</number> The processed fluorescence diagnostic image data KP is outputted to the video signal processing circuit <highlight><bold>144</bold></highlight> of the image processing unit <highlight><bold>140</bold></highlight>, and displayed on the monitor <highlight><bold>180</bold></highlight> as a visible image in the state in which the obstructing regions of the processed fluorescence diagnostic image have been subjected to the exceptional display process, in the same manner as occurred in the first embodiment. </paragraph>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> Note that according to the fifth embodiment, the determination in step S<highlight><bold>44</bold></highlight> as to whether or not the pixel values of the fluorescence images are greater than or equal to the threshold value Th<highlight><bold>5</bold></highlight>, the obtainment in step <highlight><bold>45</bold></highlight> of the computed fluorescence value for only the pixels of a pixel value greater than or equal to the threshold value Th<highlight><bold>5</bold></highlight>, and the determination as to whether or not the computed fluorescence values are less than or equal to the threshold value Th<highlight><bold>6</bold></highlight> is performed only on the pixels of which the color data has been determined to be outside the predetermined range in the step S<highlight><bold>42</bold></highlight>; however, any of the steps can be performed first. For example, the determination of step S<highlight><bold>44</bold></highlight>, the determination of step S<highlight><bold>42</bold></highlight>, the process of S<highlight><bold>45</bold></highlight>, and the determination of step S<highlight><bold>46</bold></highlight> can be performed in that order; or alternatively, the determination of step S<highlight><bold>44</bold></highlight>, the obtainment of step S<highlight><bold>45</bold></highlight>, the determination of step S<highlight><bold>46</bold></highlight>, and the determination of step S<highlight><bold>42</bold></highlight> can be performed in that order. Further, the process of S<highlight><bold>45</bold></highlight>, the determination of step S<highlight><bold>46</bold></highlight>, the determination of step S<highlight><bold>42</bold></highlight>, and the determination of step S<highlight><bold>44</bold></highlight> can be performed in that order; alternatively, the obtainment of step S<highlight><bold>45</bold></highlight>, the determination of step S<highlight><bold>46</bold></highlight>, the determination of step S<highlight><bold>44</bold></highlight>, and the determination of step S<highlight><bold>42</bold></highlight> can be performed in that order. </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> Further, the determination of step S<highlight><bold>42</bold></highlight>, the determination of step S<highlight><bold>44</bold></highlight>, the obtainment of step S<highlight><bold>45</bold></highlight>, and the determination of step S<highlight><bold>46</bold></highlight> can be performed as a series on all pixels; and the regions formed of the pixels of the standard image falling outside the predetermined color range, the pixels corresponding thereto of the fluorescence image which also have a pixel value greater than or equal to the threshold value Th<highlight><bold>5</bold></highlight> and of which the computed fluorescence value thereof is less than or equal to the threshold value Th<highlight><bold>6</bold></highlight> can be detected as obstructing regions. </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> Still further, after the determination of step S<highlight><bold>42</bold></highlight> has been performed, the determination of step S<highlight><bold>44</bold></highlight>, followed by the process of step S<highlight><bold>45</bold></highlight> and the determination of step S<highlight><bold>46</bold></highlight> can be performed as a series; alternatively, after the determination of step S<highlight><bold>44</bold></highlight> has been performed, the determination of step S<highlight><bold>42</bold></highlight>, followed by the process of step S<highlight><bold>45</bold></highlight> and the determination of step S<highlight><bold>46</bold></highlight> can be performed as a series. Further, after the process of step S<highlight><bold>45</bold></highlight> and the determination of step S<highlight><bold>46</bold></highlight> have been performed, followed by the determination of step S<highlight><bold>42</bold></highlight> and the determination of step S<highlight><bold>44</bold></highlight> can be performed as a series. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> Note that according to the first through the fifth embodiments described above: when a determination is made as to whether or not the color data is outside the predetermined color range; a determination is made as to whether or not the pixel values of the fluorescence images are greater than or equal to a threshold value and/or as to whether or not the computed fluorescence value is less than or equal to a threshold value is to be made, the pixels of the standard image and/or the fluorescence images may be subjected to a thinning process. By thinning the pixels and performing the determinations in this manner, an increase in processing speed can be expected. Note that after these types of determinations have been performed, it is preferable that the determinations be performed without pixel thinning only for the detected obstructing regions. </paragraph>
<paragraph id="P-0154" lvl="0"><number>&lsqb;0154&rsqb;</number> Further, according to the first through the fifth embodiments: it is also possible to project in sequence onto the target subject <highlight><bold>10</bold></highlight> R light, G light, B light, reference light, and excitation light to obtain a standard image, an IR reflectance image and fluorescence images. Hereinafter, this will be described as the sixth embodiment. <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a schematic drawing of the main part of a fluorescence endoscope apparatus implementing the fluorescence image obtaining apparatus according to the sixth embodiment of the present invention. Note that elements of the sixth embodiment that are the same as those of the first embodiment are likewise labeled, and further explanation thereof omitted. As shown in <cross-reference target="DRAWINGS">FIG. 12</cross-reference>, the fluorescence endoscope apparatus according to the third embodiment of the present invention comprises an endoscope insertion portion <highlight><bold>200</bold></highlight> and an image signal processing portion <highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0155" lvl="0"><number>&lsqb;0155&rsqb;</number> The endoscope insertion portion <highlight><bold>200</bold></highlight> is provided with a light guide <highlight><bold>201</bold></highlight>, an image fiber <highlight><bold>203</bold></highlight>, an illuminating lens <highlight><bold>204</bold></highlight>, an objective lens <highlight><bold>205</bold></highlight>, and a condensing lens <highlight><bold>206</bold></highlight>, which are the same as the light guide <highlight><bold>101</bold></highlight>, an image fiber <highlight><bold>103</bold></highlight>, an illuminating lens <highlight><bold>104</bold></highlight>, an objective lens <highlight><bold>105</bold></highlight>, and a condensing lens <highlight><bold>106</bold></highlight> configuring the endoscope insertion portion <highlight><bold>100</bold></highlight> of the first embodiment. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> The image signal processing portion <highlight><bold>2</bold></highlight> comprises: an illuminating unit <highlight><bold>210</bold></highlight> for sequentially emitting R light, G light, B light (hereinafter collectively referred to as illuminating light L<highlight><bold>1</bold></highlight>&prime;), a reference light L<highlight><bold>5</bold></highlight>, and an excitation light L<highlight><bold>2</bold></highlight>; an image obtaining unit <highlight><bold>220</bold></highlight> for imaging a standard image, two types of fluorescence images of two different wavelength bands, and an IR reflectance image, and obtaining a standard image data N, fluorescence image data K<highlight><bold>1</bold></highlight> and K<highlight><bold>2</bold></highlight>, and an IR reflectance image data F<highlight><bold>1</bold></highlight>; a fluorescence diagnostic image forming means <highlight><bold>130</bold></highlight>; an image processing unit <highlight><bold>240</bold></highlight> for subjecting the standard image represented by the standard image data N and the processed fluorescence diagnostic image represented by the processed fluorescence diagnostic image data KP to the processes required to display said images as visible images; an obstructing region detecting unit <highlight><bold>150</bold></highlight> for detecting the obstructing regions; a controller <highlight><bold>260</bold></highlight>; a monitor <highlight><bold>170</bold></highlight>; and a monitor <highlight><bold>180</bold></highlight>. </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> The illuminating unit <highlight><bold>210</bold></highlight> comprises: a white light source <highlight><bold>211</bold></highlight>, which is a halogen lamp or the like, for emitting white light; a white light power source <highlight><bold>212</bold></highlight> which is electrically connected to the white light source <highlight><bold>211</bold></highlight>; a white light condensing lens <highlight><bold>213</bold></highlight>; a rotating filter <highlight><bold>214</bold></highlight> for sequentially separating the colors or type of the emitted light into R light, G light, B light, reference light L<highlight><bold>5</bold></highlight> and excitation light L<highlight><bold>2</bold></highlight>; and a motor <highlight><bold>215</bold></highlight> for rotating the rotating filter <highlight><bold>214</bold></highlight>. </paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> The configuration of the switching filter is shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>. As shown in <cross-reference target="DRAWINGS">FIG. 13</cross-reference>, the switching filter <highlight><bold>214</bold></highlight> comprises filter elements <highlight><bold>214</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>214</bold></highlight><highlight><italic>e </italic></highlight>that transmit: R light, G light, B light; near-infrared (IR) light of a wavelength in the 750-900 wavelength band; and excitation light L<highlight><bold>2</bold></highlight> light of having a wavelength of 410 nm. </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> The image obtaining unit <highlight><bold>220</bold></highlight> comprises: a collimator lens <highlight><bold>228</bold></highlight> that guides the reflected light L<highlight><bold>4</bold></highlight> of the R light, G, light, and B light, the reference light L<highlight><bold>5</bold></highlight> the reflected light L<highlight><bold>6</bold></highlight> and the fluorescence L<highlight><bold>3</bold></highlight> conveyed thereto via the image fiber <highlight><bold>203</bold></highlight>; an excitation light cutoff filter <highlight><bold>221</bold></highlight> that cuts off light having a wavelength less than or equal to the 420 nm wavelength of the excitation light L<highlight><bold>2</bold></highlight> from the reflected light L<highlight><bold>4</bold></highlight>, L<highlight><bold>6</bold></highlight>, and the fluorescence L<highlight><bold>3</bold></highlight>; a condensing lens <highlight><bold>229</bold></highlight> for focusing the reflected light L<highlight><bold>4</bold></highlight>, L<highlight><bold>6</bold></highlight> and the fluorescence L<highlight><bold>3</bold></highlight>; a CCD imaging element <highlight><bold>225</bold></highlight> for imaging the standard image, the IR reflectance image, and the fluorescence image represented by the reflected light L<highlight><bold>4</bold></highlight>, L<highlight><bold>6</bold></highlight>, and the fluorescence L<highlight><bold>3</bold></highlight> respectively, which have been focused by the condensing lens <highlight><bold>229</bold></highlight>; and an A/D conversion circuit <highlight><bold>226</bold></highlight> for digitizing the image signals obtained by the CCD imaging element <highlight><bold>225</bold></highlight> to obtain a standard image data N, an IR reflectance image data F<highlight><bold>1</bold></highlight>, and two types of fluorescence image data K<highlight><bold>1</bold></highlight>, K<highlight><bold>2</bold></highlight>; and a standard image memory <highlight><bold>224</bold></highlight> for recording a standard image data N. </paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a drawing of the configuration of the mosaic filter <highlight><bold>227</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>, the mosaic filter <highlight><bold>227</bold></highlight> comprises wide band filter element <highlight><bold>227</bold></highlight><highlight><italic>a </italic></highlight>that transmits all light of a wavelength in the 400-900 nm wavelength band, and narrow band filter elements <highlight><bold>227</bold></highlight><highlight><italic>b </italic></highlight>that transmit light of a wavelength in the 430-530 nm wavelength band, which are combined alternately to form a mosaic pattern; each of the filter elements <highlight><bold>227</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>227</bold></highlight><highlight><italic>b </italic></highlight>are in a relation of a one-to-one correspondence with the pixels of the CCD imagining element <highlight><bold>225</bold></highlight>. </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> Note that by the rotation of the rotating filter, the R light, the G light and B light, the IR near-infrared light and the excitation light are repeatedly projected onto the target subject <highlight><bold>10</bold></highlight>. Here, while the R light, G light, B light, and reference light L<highlight><bold>5</bold></highlight> are being projected onto the target subject <highlight><bold>10</bold></highlight>, only the fluorescence image transmitted by the wide band filter elements <highlight><bold>227</bold></highlight><highlight><italic>a </italic></highlight>of the mosaic filter <highlight><bold>227</bold></highlight> is detected by the CCD imaging element <highlight><bold>225</bold></highlight>, and while the excitation light L<highlight><bold>2</bold></highlight> is being projected onto the target subject, the respective fluorescence images passing through the wide band filter elements <highlight><bold>227</bold></highlight><highlight><italic>a </italic></highlight>and the narrow band filter elements <highlight><bold>227</bold></highlight><highlight><italic>b </italic></highlight>are detected by the CD imaging element <highlight><bold>225</bold></highlight>. </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> The image processing unit <highlight><bold>240</bold></highlight> is provided with a video signal processing circuit <highlight><bold>244</bold></highlight>, which is of the same configuration as the video signal processing circuit <highlight><bold>144</bold></highlight> of the first embodiment. </paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> Next, the operation of the sixth embodiment will be explained. The operations occurring when the obstructing regions are to be detected and the processed fluorescence diagnostic image is to be displayed are the same as those occurring in the first embodiment; therefore, further explanation thereof is omitted. The operations occurring when the standard image is to be obtained, the standard image is to be displayed, and the IR reflectance image and the fluorescence images are to be obtained will be explained. </paragraph>
<paragraph id="P-0164" lvl="0"><number>&lsqb;0164&rsqb;</number> According to the endoscope apparatus of the sixth embodiment of the present invention, the obtainment of a standard image upon the irradiation of the target subject <highlight><bold>10</bold></highlight> with a R light, G light, and B light, the obtainment of an IR reflectance image, and the obtainment of a fluorescence image are performed alternately in a temporal series. Therefore, by causing the rotating filter <highlight><bold>214</bold></highlight> of the illuminating unit <highlight><bold>210</bold></highlight> is to rotate so that the white light emitted from the white light source <highlight><bold>211</bold></highlight> is transmitted by the rotating filter <highlight><bold>214</bold></highlight>, the R light, the G light and B light, the IR near-infrared light and the excitation light are sequentially projected onto the target subject <highlight><bold>10</bold></highlight>. </paragraph>
<paragraph id="P-0165" lvl="0"><number>&lsqb;0165&rsqb;</number> First, the operation occurring when a standard image is to be displayed will be explained. First, the R light is projected onto the target subject <highlight><bold>10</bold></highlight>, and the reflected light L<highlight><bold>1</bold></highlight> of the R light reflected from the target subject <highlight><bold>10</bold></highlight> is focused by the condensing lens <highlight><bold>206</bold></highlight>, enters the distal end of the image fiber <highlight><bold>203</bold></highlight>, passes through the image fiber <highlight><bold>203</bold></highlight> and is focused by the collimator lens <highlight><bold>228</bold></highlight>, is transmitted by the excitation light cutoff filter <highlight><bold>221</bold></highlight>, is focused by the condensing lens <highlight><bold>229</bold></highlight>, transmitted by the wide band filter elements <highlight><bold>227</bold></highlight><highlight><italic>a </italic></highlight>of the mosaic filter <highlight><bold>227</bold></highlight>, and is received by the CCD imaging element <highlight><bold>225</bold></highlight>. </paragraph>
<paragraph id="P-0166" lvl="0"><number>&lsqb;0166&rsqb;</number> After the reflected light L<highlight><bold>4</bold></highlight> of the R light received at the CCD imaging element <highlight><bold>225</bold></highlight> has been photoelectrically converted therein, and then converted to a digital signal by the A/D converting circuit <highlight><bold>226</bold></highlight> to obtain an R light image data, the R light image data is stored in the R light image data region recording region of the standard image memory <highlight><bold>224</bold></highlight>. </paragraph>
<paragraph id="P-0167" lvl="0"><number>&lsqb;0167&rsqb;</number> After the passage of a predetermined period of time, the rotating filter <highlight><bold>214</bold></highlight> is caused to rotate to switch the filter element disposed along the optical path of the white light emitted from the white light source from the R light filter element <highlight><bold>214</bold></highlight><highlight><italic>a </italic></highlight>to the G light filter element <highlight><bold>214</bold></highlight><highlight><italic>b</italic></highlight>, and the G light image data is obtained according to the same operation described above. Further, after the passage of a predetermined period of time, the rotating filter <highlight><bold>214</bold></highlight> is caused to rotate so as to switch to the B light filter element <highlight><bold>214</bold></highlight><highlight><italic>c</italic></highlight>, and the B light image data is obtained. The G light image data and the B light image data are stored in the G light image data recording region and the B light image data recording region, respectively, of the standard image memory <highlight><bold>224</bold></highlight>. </paragraph>
<paragraph id="P-0168" lvl="0"><number>&lsqb;0168&rsqb;</number> When the image data for the three colors have been stored in the standard image memory <highlight><bold>224</bold></highlight>, said three images are synchronized and outputted simultaneously as a standard image data N to the video signal processing circuit <highlight><bold>244</bold></highlight>. The video signal processing circuit <highlight><bold>244</bold></highlight> converts said inputted signals to video signals and outputs said video signals to the monitor <highlight><bold>170</bold></highlight>, and said video signals are displayed thereon as a visible image. </paragraph>
<paragraph id="P-0169" lvl="0"><number>&lsqb;0169&rsqb;</number> Next, the operation occurring when a fluorescence image is to be obtained will be explained. The rotating filter <highlight><bold>214</bold></highlight> is again caused to rotate, based on a control signal from the controller <highlight><bold>260</bold></highlight>, from the filter element <highlight><bold>214</bold></highlight><highlight><italic>d </italic></highlight>to the filter element <highlight><bold>214</bold></highlight><highlight><italic>e</italic></highlight>; wherein, the filter element <highlight><bold>214</bold></highlight><highlight><italic>e </italic></highlight>is positioned along the optical path of the white light emitted from the illuminating unit <highlight><bold>210</bold></highlight>. In this manner, the excitation light L<highlight><bold>2</bold></highlight> is projected onto the target subject <highlight><bold>10</bold></highlight>. </paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> The fluorescence L<highlight><bold>3</bold></highlight> emitted from the target subject <highlight><bold>10</bold></highlight> upon the irradiation thereof by the excitation light L<highlight><bold>2</bold></highlight> is focused by the condensing lens <highlight><bold>206</bold></highlight>, is focused by the condensing lens <highlight><bold>206</bold></highlight>, enters the distal end of the image fiber <highlight><bold>203</bold></highlight>, passes through the image fiber <highlight><bold>203</bold></highlight> and is focused by the collimator lens <highlight><bold>228</bold></highlight>, is transmitted by the excitation light cutoff filter <highlight><bold>221</bold></highlight>, is focused by the condensing lens <highlight><bold>229</bold></highlight>, transmitted by the wide band filter elements <highlight><bold>227</bold></highlight><highlight><italic>a </italic></highlight>and the narrow band filter element <highlight><bold>227</bold></highlight><highlight><italic>b </italic></highlight>of the mosaic filter <highlight><bold>227</bold></highlight>, and is received by the CCD imaging element <highlight><bold>225</bold></highlight>. </paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> After the fluorescence L<highlight><bold>3</bold></highlight> received at the CCD imaging element <highlight><bold>225</bold></highlight> has been photoelectrically converted for pixel each corresponding to the wide band filter elements <highlight><bold>227</bold></highlight><highlight><italic>a </italic></highlight>and the narrow band filter element <highlight><bold>227</bold></highlight><highlight><italic>b</italic></highlight>, and then converted to a digital signal by the A/D converting circuit <highlight><bold>226</bold></highlight> to obtain a wide band fluorescence image data K<highlight><bold>1</bold></highlight> and a narrow band fluorescence image data K<highlight><bold>2</bold></highlight>, the wide band fluorescence image data K<highlight><bold>1</bold></highlight> and the narrow band fluorescence image data K<highlight><bold>2</bold></highlight> are stored in the wide band fluorescence image data recording region and the narrow band fluorescence image data recording region, respectively, of the image memory <highlight><bold>131</bold></highlight> of the fluorescence diagnostic image forming unit <highlight><bold>130</bold></highlight>. </paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> Then, in the same manner as occurs in the first embodiment, the image synthesizing portion <highlight><bold>134</bold></highlight> of the fluorescence diagnostic image forming means synthesizes a fluorescence diagnostic image data K<highlight><bold>0</bold></highlight>. Meanwhile, the obstructing regions detecting unit <highlight><bold>150</bold></highlight> detects, based on the color data of the standard image, the obstructing regions. The exceptional display process portion <highlight><bold>135</bold></highlight> subjects the detected obstructing regions are to an exceptional display process to obtain a processed fluorescence diagnosis image data KP. The processed fluorescence diagnosis image data KP is converted to video signals by the video signal processing circuit <highlight><bold>244</bold></highlight>, inputted to the monitor <highlight><bold>180</bold></highlight>, and displayed thereon as a visible image. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> Note that the second through the fifth embodiments can also utilize, in the same manner as described above, an illuminating unit <highlight><bold>220</bold></highlight> and an image processing portion <highlight><bold>240</bold></highlight> instead of the illuminating unit <highlight><bold>110</bold></highlight>, the image obtaining unit <highlight><bold>120</bold></highlight>, and the image processing portion <highlight><bold>240</bold></highlight>. </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> Further, according to the first through sixth embodiments described above, the CCD imaging element for obtaining fluorescence images has been provided within the image processing portion; however, a CCD imaging element equipped with the on-chip mosaic filter <highlight><bold>227</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference> can be disposed in the distal end of the endoscope insertion portion. In addition, if the CCD imaging element is a charge multiplying type CCD imaging element, such as that described in Japanese Unexamined Patent Publication No. 7 (1995)-176721, for amplifying the obtained signal charge, the obtainment of the fluorescence images can be performed at a higher sensitivity, and the noise component of the fluorescence images can be further reduced. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A fluorescence image obtaining method implemented by: 
<claim-text>projecting an illuminating light containing excitation light onto a target subject and obtaining a fluorescence diagnostic image based on the fluorescence obtained from said target subject upon the irradiation thereof by said light, further comprising the step of </claim-text>
<claim-text>detecting the obstructing regions representing an obstructing factor present on the target subject. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A fluorescence image obtaining method as defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein 
<claim-text>a white light is projected onto the target subject and a standard image of said target subject is further obtained based on the reflected light obtained from said target subject upon the irradiation thereof by the white light, and </claim-text>
<claim-text>the obstructing regions included therein are detected based on the color data of the standard image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A fluorescence image obtaining method as defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein 
<claim-text>the fluorescence data of the target subject is obtained based on the fluorescence, and the obstructing regions are detected based on said fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A fluorescence image obtaining method as defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein 
<claim-text>a white light is projected onto the target subject and a standard image of said target subject is further obtained based on the reflected light obtained from said target subject upon the irradiation thereof by the white light, and </claim-text>
<claim-text>the fluorescence data based on the fluorescence is obtained, and the obstructing regions is detected based on the color data of the standard image and the fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A fluorescence image obtaining method as defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein 
<claim-text>the fluorescence intensity and/or the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands are used as the fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A fluorescence image obtaining method as defined in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising the steps of 
<claim-text>subjecting the obstructing regions of the fluorescence diagnostic image to an exceptional display process, and </claim-text>
<claim-text>displaying the fluorescence diagnostic image subjected to said exceptional display process. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A fluorescence image obtaining apparatus comprising: 
<claim-text>a fluorescence diagnostic image obtaining means for obtaining, based on the fluorescence obtained from a target subject upon the irradiation thereof by an illuminating light containing excitation light, a fluorescence diagnostic image of a target subject, further comprising 
<claim-text>an obstructing regions detecting means for detecting the obstructing factors present on the target subject. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A fluorescence image obtaining apparatus as defined in <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, further comprising 
<claim-text>a standard image obtaining means for obtaining, based on the reflected light obtained from the target subject upon the irradiation thereof by a white light, a standard image of the target subject, wherein 
<claim-text>said obstructing regions detecting means is a means for detecting the obstructing regions based on the color data of the standard image. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A fluorescence image obtaining apparatus as defined in <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein 
<claim-text>said obstructing regions detecting means is a means for obtaining the fluorescence data of the target subject, based on the fluorescence, and detecting the obstructing regions based on said fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A fluorescence image obtaining apparatus as defined in <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein 
<claim-text>the fluorescence intensity and the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands are used as the fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A fluorescence image obtaining apparatus as defined in <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein 
<claim-text>said obstructing regions detecting means is a means for detecting, based on either the fluorescence intensity or the computed fluorescence value, the suspected obstructing regions of the target subject, and detecting, based on the other of either of the fluorescence intensity and the computed fluorescence value of said suspected obstructing regions, the obstructing regions. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A fluorescence image obtaining apparatus as defined in <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, further comprising 
<claim-text>a standard image obtaining means for obtaining, based on the reflected light obtained from the target subject upon the irradiation thereof by the white light, a standard image of the target subject, wherein 
<claim-text>said obstructing regions detecting means is a means for obtaining, based on the fluorescence, fluorescence data of the target subject, and detecting, based on the color data of the standard image and the fluorescence data, the obstructing regions. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A fluorescence image obtaining apparatus as defined in <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein 
<claim-text>the fluorescence intensity or the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands is used as the fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A fluorescence image obtaining apparatus as defined in <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein 
<claim-text>said obstructing regions detecting means is a means for detecting, based on any one of the color data, the fluorescence intensity, or the computed fluorescence value, the suspected obstructing regions of the target subject, and further detecting, based on one of the data other than that employed in the detection of said suspected obstructing regions, the obstructing regions of the suspected obstructing regions. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A fluorescence image obtaining apparatus as defined in <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein 
<claim-text>the fluorescence intensity and the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands are used as the fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A fluorescence image obtaining apparatus as defined in <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, wherein 
<claim-text>said obstructing regions detecting means is a means for detecting, based on any one of the color data, the fluorescence intensity, or the fluorescence data a first suspected obstructing region of the target subject, and detecting, based on one of the data other than that employed in the detection of said first suspected obstructing region, a second suspected obstructing region of the target subject, and detecting, based on one of the data other than that employed in the detection of said second suspected obstructing region, the obstructing regions. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A fluorescence image obtaining apparatus as defined in any of the claims <highlight><bold>7</bold></highlight>, <highlight><bold>8</bold></highlight>, <highlight><bold>9</bold></highlight>, <highlight><bold>10</bold></highlight>, <highlight><bold>11</bold></highlight>, <highlight><bold>12</bold></highlight>, <highlight><bold>13</bold></highlight>, <highlight><bold>14</bold></highlight>, <highlight><bold>15</bold></highlight>, and <highlight><bold>16</bold></highlight>, further comprising 
<claim-text>an exceptional display process means for subjecting the obstructing regions of the fluorescence diagnostic image to exceptional display processes, and </claim-text>
<claim-text>a display means for displaying the fluorescence diagnostic image that has been subjected to said exceptional display processes. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. A fluorescence image obtaining apparatus as defined in any of the claims <highlight><bold>7</bold></highlight>, <highlight><bold>8</bold></highlight>, <highlight><bold>9</bold></highlight>, <highlight><bold>10</bold></highlight>, <highlight><bold>11</bold></highlight>, <highlight><bold>12</bold></highlight>, <highlight><bold>13</bold></highlight>, <highlight><bold>14</bold></highlight>, <highlight><bold>15</bold></highlight>, and <highlight><bold>16</bold></highlight>, wherein 
<claim-text>a portion or the entirety of the fluorescence diagnostic image obtaining means be provided in the form of an endoscope to be inserted into the body cavity of a patient. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. A fluorescence image obtaining apparatus as defined in the <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, wherein 
<claim-text>a portion or the entirety of the fluorescence diagnostic image obtaining means be provided in the form of an endoscope to be inserted into the body cavity of a patient. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. A program for causing a computer to execute a fluorescence image obtaining method of projecting an illuminating light containing excitation light onto a target subject and obtaining a fluorescence diagnostic image based on the fluorescence obtained from said target subject upon the irradiation thereof by said light, further comprising the procedure of 
<claim-text>detecting the obstructing regions representing an obstructing factor present on the target subject. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. A program as defined in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, further comprising the procedures of 
<claim-text>projecting a white light is onto the target subject to further obtain a standard image of said target subject is based on the reflected light obtained from said target subject upon the irradiation thereof by the white light, wherein 
<claim-text>said obstructing regions detecting procedure is procedure for detecting the obstructing regions included therein based on the color data of the standard image. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. A program as defined in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, further comprising the procedures of 
<claim-text>obtaining the fluorescence data of the target subject, based on the fluorescence, and </claim-text>
<claim-text>detecting the obstructing regions, based on said fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A program as defined in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, further comprising the procedure of 
<claim-text>projecting a white light onto the target subject and further obtaining a standard image of said target subject, based on the reflected light obtained from said target subject upon the irradiation thereof by the white light, and </claim-text>
<claim-text>obtaining the fluorescence data based on the fluorescence, and </claim-text>
<claim-text>detecting the obstructing regions, based on the color data of the standard image and the fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A program as defined in either of the claims <highlight><bold>22</bold></highlight> or <highlight><bold>23</bold></highlight>, wherein 
<claim-text>the fluorescence intensity and/or the computed fluorescence value representing the ratio between a plurality of fluorescence intensities obtained of different wavelength bands are used as the fluorescence data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A program as defined in any of the claims <highlight><bold>20</bold></highlight>, <highlight><bold>21</bold></highlight>, <highlight><bold>22</bold></highlight>, or <highlight><bold>23</bold></highlight>, further comprising the procedures of 
<claim-text>subjecting the obstructing regions of the fluorescence diagnostic image to an exceptional display process, and </claim-text>
<claim-text>displaying the fluorescence diagnostic image subjected to said exceptional display process. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. A program as defined in claims <highlight><bold>24</bold></highlight>, further comprising the procedures of 
<claim-text>subjecting the obstructing regions of the fluorescence diagnostic image to an exceptional display process, and </claim-text>
<claim-text>displaying the fluorescence diagnostic image subjected to said exceptional display process.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001104A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001104A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001104A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001104A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001104A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001104A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001104A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001104A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001104A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001104A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001104A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030001104A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030001104A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030001104A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030001104A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030001104A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
