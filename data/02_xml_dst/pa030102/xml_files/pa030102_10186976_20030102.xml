<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030003925A1-20030102-D00000.TIF SYSTEM "US20030003925A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00001.TIF SYSTEM "US20030003925A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00002.TIF SYSTEM "US20030003925A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00003.TIF SYSTEM "US20030003925A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00004.TIF SYSTEM "US20030003925A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00005.TIF SYSTEM "US20030003925A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00006.TIF SYSTEM "US20030003925A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00007.TIF SYSTEM "US20030003925A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00008.TIF SYSTEM "US20030003925A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00009.TIF SYSTEM "US20030003925A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00010.TIF SYSTEM "US20030003925A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00011.TIF SYSTEM "US20030003925A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00012.TIF SYSTEM "US20030003925A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00013.TIF SYSTEM "US20030003925A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00014.TIF SYSTEM "US20030003925A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00015.TIF SYSTEM "US20030003925A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00016.TIF SYSTEM "US20030003925A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00017.TIF SYSTEM "US20030003925A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00018.TIF SYSTEM "US20030003925A1-20030102-D00018.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00019.TIF SYSTEM "US20030003925A1-20030102-D00019.TIF" NDATA TIF>
<!ENTITY US20030003925A1-20030102-D00020.TIF SYSTEM "US20030003925A1-20030102-D00020.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030003925</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10186976</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020702</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2001-201275</doc-number>
</priority-application-number>
<filing-date>20010702</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04Q007/20</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>455</class>
<subclass>456000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>455</class>
<subclass>556000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>System and method for collecting image information</title-of-invention>
</technical-information>
<inventors>
<first-named-inventor>
<name>
<given-name>Ryo</given-name>
<family-name>Suzuki</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<assignee>
<organization-name>FUJI PHOTO FILM CO., LTD.</organization-name>
<assignee-type>03</assignee-type>
</assignee>
<correspondence-address>
<name-1>SUGHRUE MION, PLLC</name-1>
<name-2></name-2>
<address>
<address-1>2100 PENNSYLVANIA AVENUE, N.W.</address-1>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20037</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A system and a method for collecting image information wherein high-quality image information representing desired scenes is obtained with certainty. A subject is shot by cameras from mutually different directions and image information thus acquired is stored on a hard disk. When the subject is shot, location information of the subject is obtained from a radio signal transmitted by a marker which has been provided at the subject in advance. On the basis of the location information, a control device controls shooting angle setting devices for changing respective shooting directions of the cameras so that each of the cameras is oriented in a direction from which the subject can be shot. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to a system and a method for collecting image information, and more particularly, to a system and a method for collecting image information representing motion images, still images, and the like. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Conventionally, images of desired scenes shot at an event, such as an athletic event, have been acquired by, for example, capturing images of those scenes from televised images or by selecting images of the desired scenes from still images taken by photographers. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> However, acquisition of high-quality images from televised images has not been possible because the resolution of the televised images is low. In addition, images that are televised are usually shot for a general audience without concern for each and every element or person in the event being shot. For instance, in the case of an athletic event, images that are televised are usually shot without concern for each participating athlete, and it has been difficult for people attempting to obtain images of a particular athlete to obtain the images sought. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Further, when images of desired scenes are selected from still images, there is a drawback in that the images have been shot from a confined position within a limited range. Moreover, when still images of a moving subject are shot, it is difficult to continually track the motion of and shoot the subject at precisely the desired point in time. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> The present invention has been devised in order to solve the above-described problems. An object of the invention is to provide a system and a method for reliably collecting high-quality image information representing desired scenes. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> A first aspect of the invention for accomplishing the above-described object is a system for collecting image information comprising: a transmission device provided at a subject for transmitting a radio signal representing a location of the subject; shooting devices for shooting the subject from mutually different directions to generate image information of the subject; a storage device for storing the generated image information; changing devices for changing shooting directions of the shooting devices; and a control device for receiving the radio signal transmitted from the transmission device and controlling the changing devices on the basis of location information of the subject represented by the signal so that at least one of the shooting devices is directed to shoot the subject. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> According to the system for collecting image information of the first aspect of the invention, the transmission device provided at the subject transmits the radio signal representing the location of the subject. The radio signal may or may not include information indicating the subject&apos;s location (such as latitude, longitude, altitude, and the like). Information indicating the subject&apos;s location can be detected using the Global Positioning System (GPS) or the Personal Handy-phone System (PHS). When a radio signal which does not include information indicating the subject&apos;s location is transmitted, the radio signal is received by antennas (or receivers) placed at mutually different positions, and the location of the subject can be identified by identifying the source of the radio signal using triangulation. Further, the radio signal may be a radio wave, or light such as infrared light. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Moreover, in the first aspect of the invention, the subject is shot from different directions by the shooting devices, and the acquired image information is stored in the storage device. The shooting devices may be digital cameras, such as digital video cameras and digital electronic still cameras. The storage device may be: a memory, such as a random access memory (RAM), an electrically erasable programmable read-only memory (EEPROM), or Flash memory; a portable storage medium, such as a medium included among Smart Media, a compact flash, an AT attachment card (ATA card), a floppy disk, a CD-Recordable disc (CD-R), a CD-Rewritable disc (CD-RW), a magnetic optical disc, or a magnetic tape; or a fixed storage medium, such as a hard disk or an external storage device provided at a server computer connected to a network. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The control device controls the changing devices for changing shooting directions of the shooting devices on the basis of the location information represented by the radio signal so that at least one of the shooting devices is directed to shoot the subject. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In other words, by shooting the subject with the shooting devices, whose shooting directions are respectively controlled on the basis of the location information of the subject, the subject can be reliably shot in focus by at least one of the shooting devices even when the subject is in motion. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> As described above, according to the system for collecting image information of the first aspect of the invention, image information representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Further, in the system for collecting image information of the first aspect, the control device may calculate distances from the shooting devices to the subject on the basis of the location information of the subject represented by the radio signal, and may control each of the shooting devices so that optical magnification for shooting increases as distance increases, whereby the subject is magnified at the time the subject is shot. Therefore, further magnification of the subject by electronic zooming when the acquired image information is reproduced can be reduced, thereby reducing degradation of image quality resulting from the electronic zooming. Therefore, high-quality image information capable of reproducing high-quality images can be obtained. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> The system for collecting image information may further comprise collecting means for collecting sound information of sound generated at at least one of the subject and surroundings thereof while the subject is shot by the shooting devices; and extracting means, connected to the collecting means and the storage device, for extracting, from the image information stored in the storage device, image information acquired during particular time spans including times, at which an intensity of sound represented by the sound information has exceeded a predetermined level. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> Generally, spectators at an event respond with cheers and applause or loud jeers when something exciting or noteworthy occurs to draw their attention, and the intensity of sound increases at that point in time. Utilizing this fact, time spans including the times at which the intensity of sound has exceeded the predetermined level are regarded as time spans during which noteworthy scenes have been shot, and the image information acquired via the shooting devices during these time spans can be automatically extracted, as image information to be reproduced, from the image information stored in the storage device. In this manner, noteworthy scenes can be easily extracted from the stored image information. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> The subject herein may be at least one of an athlete and a ball used in an athletic event. The athletic event may be any sport involving a ball, wherein players (athletes) move, such as soccer, basketball, handball, water polo, and the like, or any sport not including a ball, such as track events including the sprint, middle distance running, long distance running, the long jump, the high jump, and the like, or other sports such as swimming, cycling, and the like. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> A second aspect of the invention for accomplishing the above-described object is a method for collecting image information of a subject using shooting devices for shooting the subject from mutually different directions and a storage device for storing the image information of the subject, comprising the steps of: providing the subject with a transmission device for transmitting a radio signal representing a location of the subject; receiving the radio signal and controlling a shooting direction of at least one of the shooting devices on the basis of location information of the subject represented by the radio signal so that at least one of the shooting devices shoots the subject; and storing the image information acquired via the shooting devices in the storage device. Thus, image information representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Further, distances from the shooting devices to the subject may be calculated on the basis of the location information of the subject represented by the radio signal, and each of the shooting devices may be controlled so that optical magnification for shooting increases as distance increases. In this manner, high-quality image information capable of reproducing high-quality images can be obtained. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Furthermore, sound information generated at at least one of the subject and surroundings thereof may be collected while the subject is shot by the shooting devices, and image information acquired during particular time spans including times at which the intensity of sound represented by the sound information has exceeded a predetermined level may be extracted from the image information stored in the storage device. In this manner, noteworthy scenes can be easily extracted from the stored image information acquired by shooting. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> It should be noted that the subject may be at least one of an athlete and a ball used in an athletic event. The athletic event may be any sport involving a ball, wherein players (athletes) move, such as soccer, basketball, handball, water polo, and the like, or any sport not including a ball, such as track events including the sprint, middle distance running, long distance running, the long jump, the high jump, and the like, or other sports such as swimming, cycling, and the like. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> A third aspect of the invention for accomplishing the above-described object is a system for collecting image information comprising: a transmission device provided at a subject for transmitting a radio signal representing a location of the subject; shooting devices for shooting the subject to generate image information including images of the subject, the shooting devices being positioned so that at least one of the shooting devices can shoot the subject; a storage device for storing the image information acquired via the shooting devices; and an extracting device for extracting, from the image information stored in the storage device, image information including images representing at least the subject on the basis of the location information of the subject represented by the radio signal transmitted from the transmission device. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> In the third aspect of the invention, the transmission device for transmitting a radio signal representing the location is provided at the subject, image information acquired via the shooting devices for shooting the subject from mutually different positions is stored in the storage device, and image information including image information representing at least the subject is extracted from the image information stored in the storage device on the basis of the location information of the subject represented by the radio signal transmitted from the transmission device. Therefore, image information representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> The third aspect of the invention may further include sound information collecting means for collecting information representing a sound intensity, and the image information extracting device may extract image information including image information representing at least the subject from the image information which has been acquired via the shooting devices during time spans including times at which the intensity of sound represented by the information collected by the sound information collecting means has exceeded the predetermined level. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> That is, generally, spectators at an event respond with cheers and applause or loud jeers when something exciting or noteworthy occurs to draw their attention, and the intensity of sound increases at that point in time. Utilizing this fact, the time spans including the times at which the intensity of sound has exceeded the predetermined level are regarded as time spans during which noteworthy scenes have been shot, and image information including image information representing at least the subject is automatically extracted from the image information acquired via the shooting devices during the time spans. In this manner, noteworthy scenes can be easily extracted from the image information acquired by shooting. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> Further, the shooting devices may be placed in mutually different positions around an area to be shot in such a manner that substantially all of the area to be shot can be shot by combining shooting areas of the shooting devices. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> Thus, the subject can be shot almost certainly by the shooting devices wherever in the area to be shot the subject is located. As a result, image information representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> Moreover, image synthesizing means for synthesizing the image information extracted by the image information extracting device may be included, and the synthesis may be performed in such a manner that image information acquired via the shooting devices whose shooting areas are adjacent to each other become successive in order of time. By reproducing thus synthesized image information, a scene, which appears substantially the same as when the subject located in the area to be shot is continuously observed (shot) while changing the observing (shooting) point, can be reproduced. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> It should be noted that, when the image synthesizing means synthesizes image information, it is preferable that image information corresponding to a synthesized image to be positioned between two pieces of image information, which are acquired by shooting and successive (i.e., neighboring) in the shooting time thereof, is newly generated using an interpolation approach such as Morphing, and is inserted between the two pieces of image information (in other words, additional image information to be inserted between two pieces of successive (i.e., neighboring) image information, which have been acquired by shooting, in a synthesized image sequence is preferably generated using an interpolation approach such as Morphing). This makes a synthesized image information appear more natural when it is reproduced. Morphing is a technique for generating motion image information based on two pieces of image information such that (shapes in) an image represented by one of the image information gradually and smoothly changes into (shapes in) an image represented by the other. The word &ldquo;Morphing&rdquo; is derived from &ldquo;move&rdquo;, &ldquo;morphology&rdquo;. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> As described above, when the image information extracted from the image information stored in the storage device is synthesized in such a manner that image information acquired via the shooting devices whose shooting areas are adjacent to each other become successive in order of time, a scene, which appears substantially the same as when the subject located in the area to be shot is continuously observed (shot) while changing the observing (shooting) point, can be reproduced. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> A fourth aspect of the invention is a method for collecting image information of a subject using shooting devices and a storage device for storing the image information, comprising the steps of: providing the subject with a transmission device for transmitting a radio signal representing a location of the subject; shooting the subject using the shooting devices in such a manner that at least one of the shooting devices can shoot the subject to generate image information including images of the subject; storing the image information in the storage device; and extracting, from the image information stored in the storage device, image information including images representing at least the subject on the basis of the received location information of the subject. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> According to the above-described method for collecting image information, image information representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The method for collecting image information according to the fourth aspect of the invention may further include the step of collecting information representing an intensity of sound, and the image information including image information representing at least the subject may be extracted from image information acquired via the shooting devices during time spans including times, at which an intensity of sound represented by the collected sound information has exceeded a predetermined level. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Therefore, extraction of noteworthy scenes from the image information acquired by shooting can be easily performed. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Moreover, in the above-described method for collecting image information, the shooting devices are placed in mutually different positions around the area to be shot and substantially all of the area to be shot can be shot by combining shooting areas of the shooting devices. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Therefore, the subject can be shot almost certainly by the shooting devices wherever in the area to be shot the subject is located. As a result, image information representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> Further, the image information extracted from the storage device may be synthesized in such a manner that image information shot by the shooting devices whose shooting areas are adjacent to each other become successive in order of time. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> Thus, a scene, which appears substantially the same as when the subject located in the area to be shot is continuously observed (shot) while changing the observing (shooting) point, can be reproduced. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> A fifth aspect of the invention for accomplishing the above-described object is a system for collecting image information comprising: obtaining means for obtaining location information representing a location of a subject; shooting devices for shooting the subject to generate image information, the shooting devices being placed in mutually different positions so that at least one of the shooting devices can shoot the subject; a storage device for storing the image information acquired via the shooting devices; extracting means for extracting, from the image information stored in the storage device, image information representing images of the subject; and output changing means for changing, on the basis of the obtained location information, a range of the image information from at least one of the extracting means and the shooting devices, so that the extracted image information includes the image information of the subject. The output changing means may control at least one of the shooting devices and the image information extracting means so that images including the subject are collected. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The location information representing the location of the subject is obtained by the location information obtaining means. It should be noted that the location information includes latitude, longitude and altitude representing the location of the subject. Further, the obtaining means obtains the location information by utilizing GPS, PHS, or the like. The shooting devices and the storage devices used in this aspect may be the same as those used in the previous aspects of the invention. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The output changing means changes the range of image information to be output on the basis of the location information obtained by the location information obtaining means so that the output image information includes image information representing the subject. It should be noted that, for changing the output range of image information by the changing means, a technique wherein the output range of image information acquired via the shooting devices is changed by changing shooting directions of the shooting devices so that the subject located at a position represented by the location information can be shot, a technique wherein the output range of image information is changed by extracting, from the image information stored in the storage device, the image information including image information representing the subject located at a position represented by the location information and outputting it to the storage device or an external device, or the like, can be applied. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> In other words, in the invention, the output range of the image information acquired via the shooting devices is changed on the basis of the obtained location information so that the image information representing at least the subject is included. Therefore, the image information representing images including the subject, i.e., image information representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> A sixth aspect of the invention for accomplishing the above-described object is a method for collecting image information of a subject using shooting devices placed in mutually different positions and a storage device for storing the image information, comprising the steps of: obtaining location information representing a location of the subject; shooting the subject using the shooting devices in such a manner that at least one of the shooting devices can shoot the subject to generate image information including images of the subject; storing the image information in the storage device; extracting, from the image information stored in the storage device, image information representing images of the subject; and changing, on the basis of the obtained location information, a range of the image information obtained by at least one of shooting and extracting, so that the extracted image information includes the image information of the subject. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> In the sixth aspect of the invention, the output range may be changed by controlling, on the basis of the location information, image information output by at least one of shooting the subject and extracting image information from the storage device so that the extracted image information include images of the subject. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Thus, image information representing desired scenes can be obtained with certainty.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram showing a configuration of an image information collection system according to a first embodiment of the present invention. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram showing a configuration of a marker according to the embodiment of the invention. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram showing a configuration of a control device according to the embodiment of the invention. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a perspective view showing an appearance of a shooting angle setting device according to the first embodiment of the invention. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a block diagram showing a configuration of the shooting angle setting device according to the first embodiment of the invention. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a perspective view showing an example of placement of the marker, cameras and a microphone in the image information collection system according to the first embodiment of the invention. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a schematic view showing contents of data stored on a hard disk included in an image file server according to the first embodiment of the invention. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flow chart showing a flow of actions in a tracking program according to the first embodiment of the invention. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a flow chart showing a flow of actions in an image accumulating program according to the embodiment of the invention. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flow chart showing a flow of actions in a noteworthy time storing program according to the embodiment of the invention. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a graph for explaining the actions in the noteworthy time storing program according to the embodiment of the invention. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a flow chart showing a flow of actions in a noteworthy scene extracting program according to the first embodiment of the invention. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a schematic view for explaining an example of processing digital image data. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a block diagram showing a configuration of a marker utilizing a PHS. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15A</cross-reference> is a block diagram showing a configuration of a marker used in a case in which the marker transmits an electric wave and the source of the electric wave is specified, and <cross-reference target="DRAWINGS">FIG. 15B</cross-reference> is a perspective view showing an example of placement of components of the image information collecting system in this case. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a block diagram showing a configuration of an information collecting system according to a second embodiment. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a perspective view showing an example of placement of a marker, cameras and microphones in the image information collection system according to the second embodiment. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a schematic view showing contents of data stored in a hard disk included in an image file server according to the second embodiment. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is a flow chart showing a flow of actions in a subject location recording program according to the second embodiment. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is a flow chart showing a flow of actions in a noteworthy scene extracting program according to the second embodiment. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 21A</cross-reference> to <highlight><bold>21</bold></highlight>E are schematic views for explaining a synthesized image obtained through the noteworthy scene extracting program according to the second embodiment.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> An embodiment of an image information collecting system <highlight><bold>10</bold></highlight> of the present invention will now be described in detail with reference to the drawings. It should be noted that, description is given of an example in which the invention is applied to collecting image information of a particular player (a subject) in a soccer match. </paragraph>
<paragraph id="P-0068" lvl="7"><number>&lsqb;0068&rsqb;</number> First Embodiment </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> First, referring to <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> configuration of the image information collecting system <highlight><bold>10</bold></highlight> according to this embodiment is described. As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the image information collecting system <highlight><bold>10</bold></highlight> of this embodiment comprises: a marker <highlight><bold>20</bold></highlight> carried by the subject player; a control device <highlight><bold>30</bold></highlight> for controlling overall operation of the image information collecting system <highlight><bold>10</bold></highlight>; high-resolution digital video cameras <highlight><bold>40</bold></highlight>A, <highlight><bold>40</bold></highlight>B and <highlight><bold>40</bold></highlight>C (hereinafter simply referred to as &ldquo;the cameras <highlight><bold>40</bold></highlight>&rdquo;); shooting angle setting devices <highlight><bold>50</bold></highlight>A, <highlight><bold>50</bold></highlight>B and <highlight><bold>50</bold></highlight>C (hereinafter simply referred to as &ldquo;the shooting angle setting devices <highlight><bold>50</bold></highlight>&rdquo;) for mechanically changing shooting angles of the cameras <highlight><bold>40</bold></highlight> respectively mounted thereon; an image file server <highlight><bold>70</bold></highlight> including a hard disk <highlight><bold>70</bold></highlight>A for storing image information (hereinafter referred to as digital image data) acquired mainly via the cameras <highlight><bold>40</bold></highlight>; and a microphone <highlight><bold>90</bold></highlight> for collecting sound mainly generated at audience seats. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The control device <highlight><bold>30</bold></highlight> is interconnected with the cameras <highlight><bold>40</bold></highlight>, the shooting angle setting devices <highlight><bold>50</bold></highlight> and the image file server <highlight><bold>70</bold></highlight> via a high-speed LAN <highlight><bold>80</bold></highlight>, so that various information and commands can be communicated between them. The microphone <highlight><bold>90</bold></highlight> is connected to the control device <highlight><bold>30</bold></highlight> so that a signal representing sound collected by the microphone <highlight><bold>90</bold></highlight> is always input to the control device <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the marker <highlight><bold>20</bold></highlight> according to this embodiment comprises: a central processing unit (CPU) <highlight><bold>21</bold></highlight> for controlling overall operation of the marker <highlight><bold>20</bold></highlight>; a RAM <highlight><bold>22</bold></highlight> that is used as a work area, and the like, when the CPU <highlight><bold>21</bold></highlight> performs various operations; a ROM <highlight><bold>23</bold></highlight> for storing various parameters, programs, and the like; a reception controller <highlight><bold>25</bold></highlight> including an antenna <highlight><bold>24</bold></highlight> for receiving GPS signals from GPS satellites; and a transmission controller <highlight><bold>27</bold></highlight> including a ground-wave antenna <highlight><bold>26</bold></highlight> for transmitting a ground wave; all of which are interconnected via a bus <highlight><bold>29</bold></highlight>. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> The CPU <highlight><bold>21</bold></highlight> controls the reception controller <highlight><bold>25</bold></highlight> so that GPS signals from three or more GPS satellites are received via the antenna <highlight><bold>24</bold></highlight>, derives positional information representing a location of the marker <highlight><bold>20</bold></highlight> (latitudinal and longitudinal information in this embodiment) on the basis of the received GPS signals using well-known calculations, and controls the transmission controller <highlight><bold>27</bold></highlight> so that the derived positional information is transmitted as a radio signal via the ground-wave antenna <highlight><bold>26</bold></highlight>. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the control device <highlight><bold>30</bold></highlight> according to this embodiment comprises: a CPU <highlight><bold>31</bold></highlight> for controlling overall operation of the control device <highlight><bold>30</bold></highlight>; a RAM <highlight><bold>32</bold></highlight> used as a work area, and the like, when the CPU <highlight><bold>31</bold></highlight> performs various operations; a ROM <highlight><bold>33</bold></highlight> for storing various parameters, programs, and the like; an image processor <highlight><bold>34</bold></highlight> for performing various processing, such as compression of digital image data acquired via the cameras <highlight><bold>40</bold></highlight> according to a predetermined image compression technology (the MPEG (Moving Picture Experts Group) technology is used in this embodiment) and decompression of the compressed digital image data according to an employed image compression technology, and the like; a reception controller <highlight><bold>36</bold></highlight> including a ground-wave antenna <highlight><bold>35</bold></highlight> for receiving the radio signal transmitted from the marker <highlight><bold>20</bold></highlight>; and an input/output (I/O) port <highlight><bold>37</bold></highlight> connectable with the high-speed LAN <highlight><bold>80</bold></highlight> and the microphone <highlight><bold>90</bold></highlight>; all of which are interconnected via a bus <highlight><bold>39</bold></highlight>. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> The CPU <highlight><bold>31</bold></highlight> controls the reception controller <highlight><bold>36</bold></highlight> so that the radio signal transmitted from the marker <highlight><bold>20</bold></highlight> is received via the ground-wave antenna <highlight><bold>35</bold></highlight>. Based on the positional information representing the location of the marker <highlight><bold>20</bold></highlight> included in the received radio signal, the CPU <highlight><bold>31</bold></highlight> generates shooting angle data for setting a shooting angle of each of the cameras <highlight><bold>40</bold></highlight>, so that the cameras <highlight><bold>40</bold></highlight> can shoot the marker <highlight><bold>20</bold></highlight>, and transmits the shooting angle data to each of the shooting angle setting devices <highlight><bold>50</bold></highlight>. Further, the CPU <highlight><bold>31</bold></highlight> computes distances from the cameras <highlight><bold>40</bold></highlight> to the marker <highlight><bold>20</bold></highlight>, derives optical magnification (for each of the cameras <highlight><bold>40</bold></highlight>) so that it increases as distance increases, and transmits data representing the optical magnification to each of the cameras <highlight><bold>40</bold></highlight>. It should be noted that, in this embodiment, optical magnification is derived so that the size of the subject carrying the marker <highlight><bold>20</bold></highlight> (represented by acquired image data) is substantially the same, regardless of the distances from the cameras <highlight><bold>40</bold></highlight> to the marker <highlight><bold>20</bold></highlight>. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> Further, the CPU <highlight><bold>31</bold></highlight> compresses the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> using the image processor <highlight><bold>34</bold></highlight> according to a predetermined image compression format, and then transmits the compressed digital image data to the image file server <highlight><bold>70</bold></highlight>. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows an appearance of the shooting angle setting device <highlight><bold>50</bold></highlight> according to this embodiment. As shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the shooting angle setting device <highlight><bold>50</bold></highlight> comprises: a horizontal motor accommodating portion <highlight><bold>56</bold></highlight> for accommodating a horizontal motor <highlight><bold>56</bold></highlight>A; a vertical motor accommodating portion <highlight><bold>57</bold></highlight> for accommodating a vertical motor <highlight><bold>57</bold></highlight>A; a fixing base <highlight><bold>58</bold></highlight>, on which the vertical motor accommodating portion <highlight><bold>57</bold></highlight> is mounted and fixed, with the fixing base <highlight><bold>58</bold></highlight> including a tapped hole in a lower surface thereof for attaching a tripod, or the like; and a mount <highlight><bold>60</bold></highlight> including a screw <highlight><bold>62</bold></highlight> at an upper surface thereof for mounting the camera <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> The horizontal motor accommodating portion <highlight><bold>56</bold></highlight> is rotated in the directions of arrow V in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> by the vertical motor <highlight><bold>57</bold></highlight>A accommodated in the vertical motor accommodating portion <highlight><bold>57</bold></highlight>. The mount <highlight><bold>60</bold></highlight> is rotated in the directions of arrow H in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> by the horizontal motor <highlight><bold>56</bold></highlight>A accommodated in the horizontal motor accommodating portion <highlight><bold>56</bold></highlight>. In this manner, the shooting direction of the camera <highlight><bold>40</bold></highlight> fixed on the upper surface of the mount <highlight><bold>60</bold></highlight> via the screw <highlight><bold>62</bold></highlight> can be arbitrarily changed. It should be noted that the fixing base <highlight><bold>58</bold></highlight> is attached to a tripod via the tapped hole provided in the lower surface of the fixing base <highlight><bold>58</bold></highlight>. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 5, a</cross-reference> control system of the shooting angle setting device <highlight><bold>50</bold></highlight> according to this embodiment comprises: a CPU <highlight><bold>51</bold></highlight> for controlling overall operation of the shooting angle setting device <highlight><bold>50</bold></highlight>; a RAM <highlight><bold>52</bold></highlight> used as a work area, and the like, when the CPU <highlight><bold>51</bold></highlight> performs various operations; a ROM <highlight><bold>53</bold></highlight> for storing various parameters, programs, and the like; an input/output (I/O) port <highlight><bold>54</bold></highlight> connectable with the high-speed LAN <highlight><bold>80</bold></highlight>; and a motor driver <highlight><bold>55</bold></highlight> for rotatably driving the horizontal motor <highlight><bold>56</bold></highlight>A and the vertical motor <highlight><bold>57</bold></highlight>A respectively accommodated in the horizontal motor accommodating portion <highlight><bold>56</bold></highlight> and the vertical motor accommodating portion <highlight><bold>57</bold></highlight>; all of which are interconnected via a bus <highlight><bold>59</bold></highlight>. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> The CPU <highlight><bold>51</bold></highlight> controls the motor driver <highlight><bold>55</bold></highlight> so that the horizontal motor <highlight><bold>56</bold></highlight>A and the vertical motor <highlight><bold>57</bold></highlight>A are rotatably driven based on data received from the control device <highlight><bold>30</bold></highlight> through the high-speed LAN <highlight><bold>80</bold></highlight> and the I/O port <highlight><bold>54</bold></highlight>. In this manner, the shooting direction of the camera <highlight><bold>40</bold></highlight> fixed on the shooting angle setting device <highlight><bold>50</bold></highlight> can be directed toward the subject carrying the marker <highlight><bold>20</bold></highlight>. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows an example of placement of the marker <highlight><bold>20</bold></highlight>, the cameras <highlight><bold>40</bold></highlight> and the microphone <highlight><bold>90</bold></highlight>. In this example, the marker <highlight><bold>20</bold></highlight> is carried by a player H, the cameras <highlight><bold>40</bold></highlight> are placed so as to surround a soccer field to be shot, and the microphone <highlight><bold>90</bold></highlight> is placed between the soccer field and audience seats (not shown). It should be noted that each of the cameras <highlight><bold>40</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is actually fixed, via the screw <highlight><bold>62</bold></highlight>, on the upper surface of the mount <highlight><bold>60</bold></highlight> of the shooting angle setting device <highlight><bold>50</bold></highlight> mounted on the tripod. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> schematically shows contents of data stored in the hard disk <highlight><bold>70</bold></highlight>A according to this embodiment. As shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, the hard disk <highlight><bold>70</bold></highlight>A includes: an image data area for storing digital image data acquired via the cameras <highlight><bold>40</bold></highlight> and compressed by the image processor <highlight><bold>34</bold></highlight> of the control device <highlight><bold>30</bold></highlight>; a time data area for storing time data described later; and a noteworthy scene image data area for storing noteworthy scene image data described later. The image data area and the noteworthy scene image data area are partitioned so as to store image data for each of the cameras <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> The marker <highlight><bold>20</bold></highlight> corresponds to a transmission device and obtaining means of the invention, the control device <highlight><bold>30</bold></highlight> corresponds to a control device and a changing device of the invention, the cameras <highlight><bold>40</bold></highlight> correspond to shooting devices of the invention, the shooting angle setting devices <highlight><bold>50</bold></highlight> correspond to shooting direction changing devices of the invention, the hard disk <highlight><bold>70</bold></highlight>A corresponds to a storage device of the invention, and the microphone <highlight><bold>90</bold></highlight> corresponds to sound information collecting means of the invention. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> Next, operation of the image information collecting system <highlight><bold>10</bold></highlight> according to this embodiment is described. First, referring to <cross-reference target="DRAWINGS">FIG. 8, a</cross-reference> tracking process performed by the control device <highlight><bold>30</bold></highlight> is described. It should be noted that <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flow chart illustrating a flow of actions in a tracking program, which is repeated at a predetermined time interval, performed by the CPU <highlight><bold>31</bold></highlight> included in the control device <highlight><bold>30</bold></highlight> during the tracking process. The tracking program has been prestored in a predetermined area of the ROM <highlight><bold>33</bold></highlight>. Further, in this example, a power switch (not shown) of the marker <highlight><bold>20</bold></highlight> carried by the player H has been turned on and the radio signal representing the positional information of the marker <highlight><bold>20</bold></highlight> is transmitted from the marker <highlight><bold>20</bold></highlight> at a predetermined time interval. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> In step <highlight><bold>100</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 8, a</cross-reference> loop for waiting reception of the radio signal transmitted from the marker <highlight><bold>20</bold></highlight> is executed. When the signal is received, the process proceeds to step <highlight><bold>102</bold></highlight>. In step <highlight><bold>102</bold></highlight>, latitudinal and longitudinal data representing the location of the player H carrying the marker <highlight><bold>20</bold></highlight> is derived from the received radio signal. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> In step <highlight><bold>104</bold></highlight>, for one of the cameras <highlight><bold>40</bold></highlight> used in the image information collecting system <highlight><bold>10</bold></highlight>, a shooting angle (angles in horizontal and vertical directions from a predetermined reference shooting direction) for setting the shooting direction of the target camera <highlight><bold>40</bold></highlight> so that it can shoot the player H, and focal length and optical magnification of the camera <highlight><bold>40</bold></highlight> (depending on the distance from the camera <highlight><bold>40</bold></highlight> to the player H) are calculated on the basis of the obtained data representing the location of the player H. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> In step <highlight><bold>106</bold></highlight>, the data representing the shooting angle calculated in step <highlight><bold>104</bold></highlight> is transmitted via the high-speed LAN <highlight><bold>80</bold></highlight> to the shooting angle setting device <highlight><bold>50</bold></highlight>, on which the target camera <highlight><bold>40</bold></highlight> is mounted. In response to this, the CPU <highlight><bold>51</bold></highlight> of the shooting angle setting device <highlight><bold>50</bold></highlight> generates signals for driving the horizontal motor <highlight><bold>56</bold></highlight>A and the vertical motor <highlight><bold>57</bold></highlight>A so as to set a shooting angle of the mounted camera <highlight><bold>40</bold></highlight> at the shooting angle (the angles in horizontal and vertical directions) represented by the received data, and then outputs the signals to the motor driver <highlight><bold>55</bold></highlight> for rotatably driving the horizontal motor <highlight><bold>56</bold></highlight>A and the vertical motor <highlight><bold>57</bold></highlight>A. Thus, the shooting direction of the target camera <highlight><bold>40</bold></highlight> is set so that the camera <highlight><bold>40</bold></highlight> is oriented in a direction from which the player H can be shot. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> Further, in step <highlight><bold>106</bold></highlight>, the data representing the focal distance and the optical magnification calculated in step <highlight><bold>104</bold></highlight> are transmitted to the target camera <highlight><bold>40</bold></highlight> via the high-speed LAN <highlight><bold>80</bold></highlight>. In response to this, relevant portions (not shown) of the camera <highlight><bold>40</bold></highlight> are controlled so that the focal distance and the optical magnification of the target camera <highlight><bold>40</bold></highlight> are set at values represented by the received data. Thus, the camera <highlight><bold>40</bold></highlight> focuses on the player H and the optical magnification is increased as the distance between the camera <highlight><bold>40</bold></highlight> and the player H is increased, whereby the player H can be shot at an appropriate size. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> In step <highlight><bold>108</bold></highlight>, whether or not the actions in steps <highlight><bold>104</bold></highlight>-<highlight><bold>106</bold></highlight> have been performed for all the cameras <highlight><bold>40</bold></highlight> is determined. If the determination is negative, the process returns to step <highlight><bold>104</bold></highlight> to repeat the actions in steps <highlight><bold>104</bold></highlight>-<highlight><bold>106</bold></highlight>, and the tracking process ends when an affirmative determination is made. It should be noted that, when steps <highlight><bold>104</bold></highlight>-<highlight><bold>106</bold></highlight> are repeated, one of the cameras <highlight><bold>40</bold></highlight> which has not yet been subjected to the process is set as the target camera <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> By repeating the above-described tracking process at the predetermined time interval, all of the cameras <highlight><bold>40</bold></highlight> track the player H for shooting, thereby shooting the player H in focus and at an appropriate size. Therefore, the cameras <highlight><bold>40</bold></highlight> perform shooting while the tracking process is executed, and sequentially transmit acquired digital image data to the control device <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> Next, referring to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, an image accumulating process performed by the control device <highlight><bold>30</bold></highlight> is described. It should be noted that <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a flow chart illustrating a flow of actions performed in an image accumulating program executed by the CPU <highlight><bold>31</bold></highlight> of the control device <highlight><bold>30</bold></highlight> as an interruption process when digital image data (of an amount) corresponding to a predetermined number of frames is received from any of the cameras <highlight><bold>40</bold></highlight> while the above-described tracking process is executed. The image accumulating program has also been prestored in a predetermined area of the ROM <highlight><bold>33</bold></highlight>. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> In step <highlight><bold>200</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, the received digital image data (of the amount) corresponding to the predetermined number of frames is compressed by the image processor <highlight><bold>34</bold></highlight> according to the predetermined image compression format. In step <highlight><bold>202</bold></highlight>, the compressed digital image data, time data representing a shooting time from a point when the shooting (acquisition) of the digital image data has been started, and a command instructing storage of the data into the image data area of the hard disk <highlight><bold>70</bold></highlight>A are transferred to the image file server <highlight><bold>70</bold></highlight>, and the image accumulating process ends. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> The image file server <highlight><bold>70</bold></highlight> stores the compressed digital image data and the time data, which are associated with each other, in a free space in an area preallocated to the camera <highlight><bold>40</bold></highlight>, from which the digital image data is transmitted, within the image data area of the hard disk <highlight><bold>70</bold></highlight>A. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> By performing the image accumulating process, the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> can be stored on the hard disk <highlight><bold>70</bold></highlight>A for each of the cameras <highlight><bold>40</bold></highlight>, with the digital image data being compressed and associated with the time data representing the shooting time. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> Next, referring to <cross-reference target="DRAWINGS">FIG. 10, a</cross-reference> noteworthy time storing process performed by the control device <highlight><bold>30</bold></highlight> is described. It should be noted that <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flow chart illustrating a flow of actions performed in a noteworthy time storing program executed by the CPU <highlight><bold>31</bold></highlight> of the control device <highlight><bold>30</bold></highlight> as an interruption process when an intensity of sound represented by the sound signal input from the microphone <highlight><bold>90</bold></highlight> exceeds a predetermined level while the above-described tracking process is executed. The noteworthy time storing program has also been prestored in a predetermined area of he ROM <highlight><bold>33</bold></highlight>. In the embodiment, a predetermined value obtained by experimentation or computer simulation is used as the value of the predetermined level, and values (sound intensities) that exceed the predetermined level are regarded as points in time when loud cheers and applause (or jeers) have erupted from the audience. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> In step <highlight><bold>300</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, time data representing a shooting time from a point when the shooting (acquisition) of the digital image data has begun, which data is also transferred to the image file server <highlight><bold>70</bold></highlight> in step <highlight><bold>202</bold></highlight> of the image accumulating process (see also <cross-reference target="DRAWINGS">FIG. 9</cross-reference>), and a command instructing storage of the time data into the time data area of the hard disk <highlight><bold>70</bold></highlight>A are transmitted to the image file server <highlight><bold>70</bold></highlight>. Receiving the time data and the command, the image file server <highlight><bold>70</bold></highlight> stores the time data in a free space in the time data area of the hard disk <highlight><bold>70</bold></highlight>A, and the noteworthy time storing process ends. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> By performing the noteworthy time storing process, time data representing times which can be regarded as points in time when cheers and applause (or jeers) have erupted from the audience can be sequentially stored in the time data area of the hard disk <highlight><bold>70</bold></highlight>A. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> Next, referring to <cross-reference target="DRAWINGS">FIG. 12, a</cross-reference> noteworthy scene extracting process performed by the control device <highlight><bold>30</bold></highlight> is described. It should be noted that <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a flow chart illustrating a flow of actions performed in a noteworthy scene extracting program executed by the CPU <highlight><bold>31</bold></highlight> of the control device <highlight><bold>30</bold></highlight> after the above-described tracking process (see also <cross-reference target="DRAWINGS">FIG. 8</cross-reference>) has ended. The noteworthy scene extracting program has also been prestored in a predetermined area of the ROM <highlight><bold>33</bold></highlight>. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> In step <highlight><bold>400</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 12</cross-reference>, one piece of the time data stored in the time data area of the hard disk <highlight><bold>70</bold></highlight>A during the above-described noteworthy time storing process (see also <cross-reference target="DRAWINGS">FIG. 10</cross-reference>) is retrieved. In step <highlight><bold>402</bold></highlight>, (a portion of) the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> during a particular time span, which includes the shooting time represented by the retrieved time data, is retrieved from the image data area of the hard disk <highlight><bold>70</bold></highlight>A. In step <highlight><bold>404</bold></highlight>, the retrieved digital image data and a command instructing storage of the digital image data into the noteworthy scene image data area of the hard disk <highlight><bold>70</bold></highlight>A are transmitted to the image file server <highlight><bold>70</bold></highlight>. Thus, the retrieved digital image data is transferred to a free space in an area allocated to the camera <highlight><bold>40</bold></highlight>, which has shot the image, within the noteworthy scene image data area of the hard disk <highlight><bold>70</bold></highlight>A. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> In step <highlight><bold>406</bold></highlight>, whether or not the actions in steps <highlight><bold>400</bold></highlight>-<highlight><bold>404</bold></highlight> have been completed for all of the time data stored in the time data area of the hard disk <highlight><bold>70</bold></highlight>A is determined. If the determination is negative, the process returns to step <highlight><bold>400</bold></highlight> and steps <highlight><bold>400</bold></highlight>-<highlight><bold>404</bold></highlight> are repeated. When an affirmative determination is made, the noteworthy scene extracting process ends. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> It should be noted that when steps <highlight><bold>400</bold></highlight>-<highlight><bold>406</bold></highlight> are repeated, time data which has not yet been retrieved is retrieved in step <highlight><bold>400</bold></highlight>. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> By performing the noteworthy scene extracting process, only digital image data which has been acquired during time spans including moments at which noteworthy plays have been made, such as a moment at which a goal has been scored, can be extracted from the digital image data stored in the image data area to be stored in the noteworthy scene image data area of the hard disk <highlight><bold>70</bold></highlight>A. Therefore, by reading the extracted digital image data from the noteworthy scene image data area and reproducing the images, images of interest to the audience are obtained. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> Further, by using the digital image data stored in the noteworthy scene image data area for each of the cameras <highlight><bold>40</bold></highlight> and applying known computer graphics techniques, digital image data representing a motion image which appears as if a moving subject is successively (continuously) shot by one camera <highlight><bold>40</bold></highlight> at mutually different shooting positions surrounding the subject, as shown in FIG. <highlight><bold>13</bold></highlight>, can be generated. The noteworthy scene extracting process corresponds to image information extracting means of the invention. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> As described in detail above, in the image information collecting system <highlight><bold>10</bold></highlight> according to this embodiment, the positional information (information including latitude and longitude) representing the location of the subject (player H) is obtained, the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> for shooting the subject from mutually different directions or positions is stored in the hard disk <highlight><bold>70</bold></highlight>A, and, on the basis of the positional information, an output range of digital image data from each of the cameras <highlight><bold>40</bold></highlight> is changed so that image information representing at least the subject is included therein. Therefore, digital image data representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> In other words, in the image information collecting system <highlight><bold>10</bold></highlight> according to this embodiment, the subject (player H) is provided with the marker <highlight><bold>20</bold></highlight> for transmitting the radio signal representing the location, and the shooting direction of at least one of the cameras <highlight><bold>40</bold></highlight>, which shoot the subject from mutually different positions, is controlled to shoot the subject on the basis of the location of the subject represented by the transmitted radio signal, and the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> is stored on the hard disk <highlight><bold>70</bold></highlight>A. Therefore, digital image data representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> Further, in the image information collecting system <highlight><bold>10</bold></highlight> according to this embodiment, the distance from each of the cameras <highlight><bold>40</bold></highlight> to the subject is calculated based on the location of the subject represented by the radio signal, and at least one of the cameras <highlight><bold>40</bold></highlight> is controlled so that optical magnification for shooting increases as distance increases. Therefore, when the digital image data acquired by shooting by the cameras is reproduced, electronic zooming magnification for enlarging the subject can be suppressed, thereby providing high-quality digital image data which can provide high-quality images. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> Furthermore, in the image information collecting system <highlight><bold>10</bold></highlight> according to this embodiment, the sound information is collected during the shooting, and the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> during particular time spans including the times at which the intensity of sound represented by the collected information has exceeded the predetermined level are extracted, as image information to be reproduced, from the digital image data stored on the hard disk <highlight><bold>70</bold></highlight>A. This facilitates extraction of noteworthy scenes from the acquired digital data. </paragraph>
<paragraph id="P-0107" lvl="7"><number>&lsqb;0107&rsqb;</number> Second Embodiment </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> In an image information collecting system according to a second embodiment of the invention, image information acquired via the shooting devices is stored in the storage device, and image information including image information representing the subject is extracted from the image information stored in the storage device on the basis of the location of the subject. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, first, a configuration of the image information collecting system <highlight><bold>10</bold></highlight>B according to the second embodiment is described. It should be noted that components which are the same as those shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference> are designated by the same reference numerals in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, and explanation thereof is omitted. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, differences between the image information collecting system <highlight><bold>10</bold></highlight>B of the second embodiment and the image information collecting system <highlight><bold>10</bold></highlight> of the first embodiment lie in that the shooting angle setting devices <highlight><bold>50</bold></highlight> are not included, that there are a plurality of microphones <highlight><bold>90</bold></highlight> for collecting sound raised mainly at the audience seats as sound signals, and that the hard disk included in the image file server <highlight><bold>70</bold></highlight> is a hard disk <highlight><bold>70</bold></highlight>B for storing information, which is different from that stored in the hard disk <highlight><bold>70</bold></highlight>A in the previous embodiment. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> The microphones <highlight><bold>90</bold></highlight> (<highlight><bold>90</bold></highlight>A and <highlight><bold>90</bold></highlight>B) are connected to the control device <highlight><bold>30</bold></highlight>, and sound signals collected by the microphones <highlight><bold>90</bold></highlight> are continuously input to the control device <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> shows an example of placement of the marker <highlight><bold>20</bold></highlight>, the cameras <highlight><bold>40</bold></highlight> and the microphones <highlight><bold>90</bold></highlight> in the image information collecting system <highlight><bold>10</bold></highlight>B according to the second embodiment. In the example shown in <cross-reference target="DRAWINGS">FIG. 17</cross-reference>, the marker <highlight><bold>20</bold></highlight> is carried by the particulars player H, the cameras <highlight><bold>40</bold></highlight> are placed in mutually different positions so as to surround the soccer field to be shot, and the microphones <highlight><bold>90</bold></highlight> are placed in mutually different positions between the soccer field and audience seats (not shown). </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> The cameras <highlight><bold>40</bold></highlight> of the second embodiment are positioned so that all of the area to be shot (the all area of the field in the example shown in <cross-reference target="DRAWINGS">FIG. 17</cross-reference>) can be shot by combining shooting areas respectively covered by the cameras <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> schematically shows contents of data stored in the hard disk <highlight><bold>70</bold></highlight>B according to this embodiment. As shown in <cross-reference target="DRAWINGS">FIG. 18</cross-reference>, the hard disk <highlight><bold>70</bold></highlight>B includes an image data area for storing digital image data acquired via the cameras <highlight><bold>40</bold></highlight> and compressed by the image processor <highlight><bold>34</bold></highlight> of the control device <highlight><bold>30</bold></highlight>; a location data area for storing location data described later; a time data area for storing time data similarly to the first embodiment; and a noteworthy scene synthesized image data area for storing noteworthy scene synthesized image data described later. The image data area is partitioned so as to store image data for each of the cameras <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> Configurations of the marker <highlight><bold>20</bold></highlight> and the control device <highlight><bold>30</bold></highlight> in the second embodiment are the same as those in the first embodiment (see <cross-reference target="DRAWINGS">FIGS. 2 and 3</cross-reference>), and explanations thereof are omitted. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> The marker <highlight><bold>20</bold></highlight> corresponds to a location signal transmission device and obtaining means of the invention, the control device <highlight><bold>30</bold></highlight> corresponds to a changing device, an image information extracting device and image synthesizing means of the invention, the cameras <highlight><bold>40</bold></highlight> correspond to shooting devices of the invention, the hard disk <highlight><bold>70</bold></highlight>B corresponds to a storage device of the invention, and the microphones <highlight><bold>90</bold></highlight> correspond to sound information collecting means of the invention. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> Next, operation of the image information collecting system <highlight><bold>10</bold></highlight>B according to the second embodiment is described. It should be noted that, in this example, a power switch (not shown) of the marker <highlight><bold>20</bold></highlight> carried by the player <highlight><bold>20</bold></highlight> has been turned on and the radio signal representing the location information is transmitted by the marker <highlight><bold>20</bold></highlight> at a predetermined time interval. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> In the image information collecting system <highlight><bold>10</bold></highlight>B according to the second embodiment, in order to start shooting by the cameras <highlight><bold>40</bold></highlight>, the control device <highlight><bold>30</bold></highlight> transmits a start-shooting instruction command for instructing to start shooting to each of the cameras <highlight><bold>40</bold></highlight>, and stores the time at this point (equivalent to the above-described point when the shooting has been started) at a predetermined address in the RAM <highlight><bold>32</bold></highlight>. Each of the cameras <highlight><bold>40</bold></highlight> which has received the start-shooting instruction command starts shooting, and transmits digital image data representing the motion image acquired by shooting to the control device <highlight><bold>30</bold></highlight>. In order to stop the shooting, the control device <highlight><bold>30</bold></highlight> transmits a stop-shooting instruction command for instructing to stop shooting to each of the cameras <highlight><bold>40</bold></highlight>. In response to the command, each of the cameras <highlight><bold>40</bold></highlight> stops shooting. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> In the control device <highlight><bold>30</bold></highlight> according to the second embodiment, when digital image data (of an amount) corresponding to a predetermined number of frames is received from any of the cameras <highlight><bold>40</bold></highlight>, the image accumulating program is executed as an interruption process similarly to the first embodiment as shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. In this manner, the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> can be stored in the image data area of the hard disk <highlight><bold>70</bold></highlight>B for each of the cameras <highlight><bold>40</bold></highlight> in a state in which the digital image data is compressed and is associated with the above-described time data representing the shooting time from the point when the shooting has been started. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> Further, in the control device <highlight><bold>30</bold></highlight> according to the second embodiment, when an intensity of sound represented by the sound signal input from any of the microphones <highlight><bold>90</bold></highlight> exceeds a predetermined level while shooting by the cameras <highlight><bold>40</bold></highlight> is performed, the noteworthy time storing process (see <cross-reference target="DRAWINGS">FIG. 10</cross-reference>) is executed as an interruption process similarly to the first embodiment. A predetermined value obtained by experimentation or computer simulation is used as the value of the predetermined level, and values (sound intensities) that exceed the predetermined level are regarded as points in time when loud cheers and applause (or jeers) have erupted from the audience. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> By performing the noteworthy time storing process, the time data representing the shooting time from the point when the shooting has been started, which can be considered to coincide with the time at which the audience raised cheers, as shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, can be sequentially stored in the time data area of the hard disk <highlight><bold>70</bold></highlight>B. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> Next, referring to <cross-reference target="DRAWINGS">FIG. 19, a</cross-reference> subject location recording process performed by the control device <highlight><bold>30</bold></highlight> according to the second embodiment is described. It should be noted that <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is a flow chart illustrating a flow of actions performed in a subject location recording program executed by the CPU <highlight><bold>31</bold></highlight> included in the control device <highlight><bold>30</bold></highlight> repeatedly at a predetermined time interval, while shooting by the cameras <highlight><bold>40</bold></highlight> is carried out. This program has been stored in a predetermined area of the ROM <highlight><bold>33</bold></highlight> in advance. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> In step <highlight><bold>500</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 19, a</cross-reference> loop for waiting reception of the radio signal transmitted from the marker <highlight><bold>20</bold></highlight> is executed. When the signal is received, the process proceeds to step <highlight><bold>502</bold></highlight>. In step <highlight><bold>502</bold></highlight> next, data including latitude and longitude representing the location of the player H carrying the marker <highlight><bold>20</bold></highlight> is derived from the received radio signal. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> In step <highlight><bold>504</bold></highlight> next, the data including the latitude and the longitude derived in step <highlight><bold>502</bold></highlight> is stored, through the image file server <highlight><bold>70</bold></highlight>, in the location data area of the hard disk <highlight><bold>70</bold></highlight>B as the location data representing the location of the player H in association with the time data representing the shooting time from the point when the shooting has been started, and then the subject location recording process ends. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> By performing the subject location recording process, the location data representing the location of the player H from the start to the end of the shooting can be recorded on the hard disk <highlight><bold>70</bold></highlight>B. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> Next, referring to <cross-reference target="DRAWINGS">FIG. 20, a</cross-reference> noteworthy scene extracting process performed by the control device <highlight><bold>30</bold></highlight> according to the second embodiment is described. It should be noted that <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is a flow chart illustrating a flow of actions performed in a noteworthy scene extracting program executed by the CPU <highlight><bold>31</bold></highlight> of the control device <highlight><bold>30</bold></highlight> according to the second embodiment after the shooting by the cameras <highlight><bold>40</bold></highlight> has ended. This program has also been stored in a predetermined area of the ROM <highlight><bold>33</bold></highlight> in advance. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> In step <highlight><bold>600</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 20</cross-reference>, one of the time data stored in the time data area of the hard disk <highlight><bold>70</bold></highlight>B through the above-described noteworthy time storing process (see also <cross-reference target="DRAWINGS">FIG. 10</cross-reference>) is retrieved. In step <highlight><bold>602</bold></highlight> next, a portion of the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> during a time span, which includes the shooting time represented by the retrieved time data, and the location data stored during a time span to be processed, through the above-described subject location recording process, are retrieved from the image data area and the location data area of the hard disk <highlight><bold>70</bold></highlight>B. The time span in this embodiment has a length of 20 seconds including 10 seconds before the relevant shooting time and 10 seconds after the relevant shooting time, and is referred hereinafter as &ldquo;time span to be processed&rdquo;. In step <highlight><bold>604</bold></highlight> next, the retrieved digital image data is synthesized in order of time as described below. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> First, on the basis of the location data retrieved in step <highlight><bold>602</bold></highlight> and positions of the cameras <highlight><bold>40</bold></highlight>, a distance between the player H and each of the cameras <highlight><bold>40</bold></highlight> and a location of the player H in a shooting area of each of the cameras <highlight><bold>40</bold></highlight> during the time span to be processed are calculated. </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> Then, on the basis of the distance between the player H and each of the cameras <highlight><bold>40</bold></highlight> and the location of the player H in the shooting area of each of the cameras <highlight><bold>40</bold></highlight> during the time span to be processed, which have been calculated above, digital image data including image data representing the player H is extracted from the digital image data retrieved in step <highlight><bold>602</bold></highlight> above. It should be noted that, in this embodiment, the extraction is performed in such a manner that a ratio of the image data representing the player H is the greatest at the central time in the time span to be processed, and gradually decreases forward and backward from the central time regardless of the distances between the player H and the cameras <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> Next, electronic zooming is performed on each of the extracted digital image data so that numbers of pixels in a horizontal direction and a vertical direction become equal to those of digital image data acquired via the cameras <highlight><bold>40</bold></highlight>. Thus, sizes of the extracted digital image data can be made the same. </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> Finally, the digital image data for each of the cameras <highlight><bold>40</bold></highlight> which have been subjected to electronic zooming are synthesized. The synthesis is performed such that digital image data shot by the cameras <highlight><bold>40</bold></highlight> whose shooting areas are adjacent to each other become successive in order of time. It should be noted that, when the synthesis is performed, additional digital image data corresponding to an image which should be present between two pieces of successive digital image data is generated using an interpolation approach such as morphing and is inserted between the two pieces of digital image data. This makes a reproduced motion image synthesized from the image data appear more natural. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 21A</cross-reference> to <highlight><bold>21</bold></highlight>E schematically show an example of an image reproduced from the digital image data obtained by the above-described image synthesizing process. In this example, a reproduction time progresses in the order of <highlight><bold>21</bold></highlight>A,<highlight><bold>21</bold></highlight>B,<highlight><bold>21</bold></highlight>C,<highlight><bold>21</bold></highlight>D and <highlight><bold>21</bold></highlight>E. Further, although the images in <cross-reference target="DRAWINGS">FIGS. 21A</cross-reference> to <highlight><bold>21</bold></highlight>E are shown as still images, actually these images are reproduced as motion images. Furthermore, when the images shown in <cross-reference target="DRAWINGS">FIGS. 21A</cross-reference> to <highlight><bold>21</bold></highlight>E are joined, additional digital images (not shown) to be inserted between the images shown in <cross-reference target="DRAWINGS">FIGS. 21A</cross-reference> to <highlight><bold>21</bold></highlight>E, which correspond to time spans between the images shown in <cross-reference target="DRAWINGS">FIGS. 21A</cross-reference> to <highlight><bold>21</bold></highlight>E, may be synthesized using an interpolation approach such as morphing. </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIGS. 21A</cross-reference> to <highlight><bold>21</bold></highlight>E, digital image data representing a motion image of the player H, which has been continuously shot from mutually different positions around the player H during the time span to be processed, can be obtained through the above-described image synthesizing process. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> In step <highlight><bold>606</bold></highlight> next, the synthesized digital image data obtained through the process in step <highlight><bold>604</bold></highlight> and an instruction command for instructing storage of the digital image data in the noteworthy scene synthesized image data area of the hard disk <highlight><bold>70</bold></highlight>B are transmitted to the image file server <highlight><bold>70</bold></highlight>, and the synthesized digital image data is stored in a free space in the noteworthy scene synthesized image data area of the hard disk <highlight><bold>70</bold></highlight>B. </paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> In step <highlight><bold>608</bold></highlight> next, whether or not the actions in steps <highlight><bold>600</bold></highlight> to <highlight><bold>606</bold></highlight> have been completed for all of the time data stored in the time data area of the hard disk <highlight><bold>70</bold></highlight>B is determined. If the determination is negative, the process returns to step <highlight><bold>600</bold></highlight> to repeat steps <highlight><bold>600</bold></highlight>-<highlight><bold>606</bold></highlight>, and when an affirmative determination is made, the noteworthy scene extracting process ends. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> It should be noted that, when steps <highlight><bold>600</bold></highlight>-<highlight><bold>608</bold></highlight> are repeated, one piece of the time data which has not yet been retrieved is retrieved. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> By performing the noteworthy scene extracting process, only digital image data which has been acquired during time spans including moments at which noteworthy plays have been made, such as a moment at which a goal has been scored, can be extracted from the digital image data stored in the image data area and synthesized in order of time, and then can be stored in the noteworthy scene synthesized image data area of the hard disk <highlight><bold>70</bold></highlight>B. Therefore, by reading the extracted digital image data from the noteworthy scene synthesized image data area and reproducing the images, images of interest to the audience are reproduced (obtained) as shown in <cross-reference target="DRAWINGS">FIGS. 21A</cross-reference> to <highlight><bold>21</bold></highlight>E. </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> As described in detail above, in the image information collecting system <highlight><bold>10</bold></highlight>B according to this embodiment, the positional information (information including latitude and longitude) representing the location of the subject (player H) is obtained, the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> for shooting the subject from mutually different positions is stored in the image data area of the hard disk <highlight><bold>70</bold></highlight>B, and, on the basis of the positional information, image data including that representing at least the subject is extracted from the digital image data stored in the hard disk <highlight><bold>70</bold></highlight>B, thereby changing an output range of digital image data to be output to the noteworthy scene synthesized image data area of the hard disk <highlight><bold>70</bold></highlight>B. Therefore, digital image data representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> In other words, in the image information collecting system <highlight><bold>10</bold></highlight>B according to this embodiment, the subject (player H) carries the marker <highlight><bold>20</bold></highlight> for transmitting the radio signal representing the location, the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> for shooting the subject from mutually different positions is stored in the hard disk <highlight><bold>70</bold></highlight>B, and, on the basis of the location of the subject represented by the radio signal transmitted from the marker <highlight><bold>20</bold></highlight>, digital image data including image data representing at least the subject is extracted from the digital image data stored in the hard disk <highlight><bold>70</bold></highlight>B, thereby changing an output range of digital image data to be output to the noteworthy scene synthesized image data area of the hard disk <highlight><bold>70</bold></highlight>B. Therefore, digital image data representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> Further, in the image information collecting system <highlight><bold>10</bold></highlight>B according to this embodiment, the information representing a sound intensity is collected, and digital image data including image data representing at least the subject is extracted from the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> during time spans including the times at which the intensity of sound represented by the collected information has exceeded the predetermined level. Therefore, extraction of noteworthy scenes from the digital image data acquired by shooting can be easily performed. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> Furthermore, in the image information collecting system <highlight><bold>10</bold></highlight>B according to this embodiment, the cameras <highlight><bold>40</bold></highlight> are placed in mutually different positions around the area to be shot, and the all of the area to be shot can be shot by combining the shooting areas of the cameras <highlight><bold>40</bold></highlight>. Therefore, the subject can be shot almost certainly by the cameras <highlight><bold>40</bold></highlight> wherever in the area to be shot the subject is located. As a result, digital image data representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> Moreover, in the image information collecting system <highlight><bold>10</bold></highlight>B according to this embodiment, the extracted digital image data is synthesized such that digital image data shot by the cameras <highlight><bold>40</bold></highlight> whose shooting areas are adjacent to each other become successive in order of time. Therefore, a motion image, which appears substantially the same as when the subject located in the area to be shot is continuously observed (shot) while changing the observing (shooting) point, can be reproduced. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> It should be noted that, although a case in which the location of the subject is specified using the GPS is described in the embodiments above, this is not intended to limit the invention. The location of the subject may be specified by any means, for example, by using the PHS, or by making the marker transmit an electric wave and specifying the source of the electric wave. </paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> shows an exemplary configuration of a marker <highlight><bold>20</bold></highlight>B used when the location of the subject is specified using the PHS. As shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>, the marker <highlight><bold>20</bold></highlight>B comprises a PHS antenna <highlight><bold>24</bold></highlight>B and a transmission/reception controller <highlight><bold>25</bold></highlight>B for communicating with PHS base stations, instead of the GPS antenna <highlight><bold>24</bold></highlight> and the reception controller <highlight><bold>25</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> In this case, the CPU <highlight><bold>21</bold></highlight> uses the PHS antenna <highlight><bold>24</bold></highlight>B and the transmission/reception controller <highlight><bold>25</bold></highlight>B to communicate with available PHS base stations to receive positional information from each of the base stations, which positional information is always transmitted from PHS base stations. Based on the positional information received from the base stations, the CPU <highlight><bold>21</bold></highlight> derives a location of the marker <highlight><bold>20</bold></highlight> and transmits data representing the location as a radio signal via the transmission controller <highlight><bold>27</bold></highlight> through the ground-wave antenna <highlight><bold>26</bold></highlight>. The control device <highlight><bold>30</bold></highlight> according to the above-described first embodiment sets the shooting direction and optical magnification, and the like, of the cameras <highlight><bold>40</bold></highlight> so that the cameras <highlight><bold>40</bold></highlight> shoot the subject at the location of the marker <highlight><bold>20</bold></highlight>B represented by the received radio signal. Further, in the control device <highlight><bold>30</bold></highlight> according to the above-described second embodiment, the location of the marker <highlight><bold>20</bold></highlight>B represented by the received radio signal is recorded through the subject location recording process (see <cross-reference target="DRAWINGS">FIG. 19</cross-reference>). </paragraph>
<paragraph id="P-0146" lvl="0"><number>&lsqb;0146&rsqb;</number> It should be noted that, in this case, the positional information received by the marker <highlight><bold>20</bold></highlight>B from the base stations may be transmitted as a radio signal to the control device <highlight><bold>30</bold></highlight> by the transmission controller <highlight><bold>27</bold></highlight> via the ground-wave antenna <highlight><bold>26</bold></highlight>, and the control device <highlight><bold>30</bold></highlight> may specify the location of the marker <highlight><bold>20</bold></highlight>B on the basis of the positional information received from the base stations. </paragraph>
<paragraph id="P-0147" lvl="0"><number>&lsqb;0147&rsqb;</number> In the above-described system <highlight><bold>10</bold></highlight> using the PHS, computation for specifying the location performed by the marker <highlight><bold>20</bold></highlight>B can be simplified when compared with the image information collecting system <highlight><bold>10</bold></highlight> using the GPS, although accuracy of specification of the subject location is lowered. </paragraph>
<paragraph id="P-0148" lvl="0"><number>&lsqb;0148&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15A</cross-reference> shows an exemplary configuration of a marker <highlight><bold>20</bold></highlight>C used when the marker transmits a radio wave and a source of the radio wave is specified. <cross-reference target="DRAWINGS">FIG. 15B</cross-reference> shows an exemplary placement of the components of the image information collecting system <highlight><bold>10</bold></highlight> in this case. </paragraph>
<paragraph id="P-0149" lvl="0"><number>&lsqb;0149&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>A, the marker <highlight><bold>20</bold></highlight>C does not include the GPS antenna <highlight><bold>24</bold></highlight> and the reception controller <highlight><bold>25</bold></highlight>, which are necessary for the marker <highlight><bold>20</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, and therefore the marker <highlight><bold>20</bold></highlight>C can be made smaller and lighter than the marker <highlight><bold>20</bold></highlight>. </paragraph>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> The marker <highlight><bold>20</bold></highlight>C transmits a radio wave of a predetermined frequency via the ground-wave antenna <highlight><bold>26</bold></highlight> and the transmission controller <highlight><bold>27</bold></highlight>. Further, as shown in <cross-reference target="DRAWINGS">FIG. 15</cross-reference>B, the ground-wave antennas <highlight><bold>35</bold></highlight>, which are connected to the reception controller <highlight><bold>36</bold></highlight> of the control device <highlight><bold>30</bold></highlight>, are placed at mutually different positions around a space to be shot. </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> In this case, a horizontal position (latitude and longitude) of the subject is specified by triangulation on the basis of directions of the source (i.e., the marker <highlight><bold>20</bold></highlight>C) of the radio wave, which is received by the ground-wave antennas <highlight><bold>35</bold></highlight>, from the ground-wave antennas <highlight><bold>26</bold></highlight>, and distances between the antennas <highlight><bold>35</bold></highlight>. Since the marker <highlight><bold>20</bold></highlight>C does not need a function for transmitting and receiving GPS signals or PHS signals, it can be produced at a low cost and made compact. </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> Although the system <highlight><bold>10</bold></highlight> utilizing the GPS according to the above-described embodiments has been described with respect to a case where latitudinal and longitudinal information is derived, this is not intended to limit the invention. For example, in addition to latitude and longitude, altitude may be included in the information to be derived. In this case, GPS signals must be received from at least four GPS satellites. Since a height of the subject can also be found in this case, the invention can also be applied to sports in which the subject also moves in a vertical dimension, such as basketball, the pole vault, the running high jump, and the like. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> Further, although the above-described embodiments have been described with respect to a case in which there is only one subject, this is not intended to limit the invention, and there may be two or more subjects. </paragraph>
<paragraph id="P-0154" lvl="0"><number>&lsqb;0154&rsqb;</number> When there are two or more subjects (and therefore two or more markers), the CPU <highlight><bold>21</bold></highlight> of the marker <highlight><bold>20</bold></highlight> derives the positional information based on GPS signals received via the GPS antenna <highlight><bold>24</bold></highlight> and the reception controller <highlight><bold>25</bold></highlight>, and controls the transmission controller <highlight><bold>27</bold></highlight> so as to transmit, as a radio signal, a combination of the derived positional information and identification information for specifying the marker <highlight><bold>20</bold></highlight>. The control device <highlight><bold>30</bold></highlight> specifies the player carrying the marker <highlight><bold>20</bold></highlight> transmitting the radio signal on the basis of the identification information included in the received radio signal, and performs the tracking process, the image accumulating process, the noteworthy scene extracting process, and the like, in the same manner as previously described. </paragraph>
<paragraph id="P-0155" lvl="0"><number>&lsqb;0155&rsqb;</number> The identification information may be an identification number uniquely allocated to each marker <highlight><bold>20</bold></highlight>. However, this is not intended to limit the invention, and any type of information which differs between the markers <highlight><bold>20</bold></highlight> can be applied. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> Furthermore, in the above-described embodiments, the location of the marker <highlight><bold>20</bold></highlight> has been specified by the marker <highlight><bold>20</bold></highlight> itself on the basis of the received GPS signals. However, this is not intended to limit the invention. For example, the marker <highlight><bold>20</bold></highlight> may transmit the received GPS signals to the control device <highlight><bold>30</bold></highlight>, and the control device <highlight><bold>30</bold></highlight> may specify the location of the marker <highlight><bold>20</bold></highlight>. This reduces computational load at the marker <highlight><bold>20</bold></highlight>, and allows an inexpensive CPU to be used for the CPU <highlight><bold>31</bold></highlight> of the marker <highlight><bold>20</bold></highlight>. </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> Moreover, in the above-described embodiments, the digital image data acquired via the cameras <highlight><bold>40</bold></highlight> is accumulated on the hard disk <highlight><bold>70</bold></highlight>A (<highlight><bold>70</bold></highlight>B) through the control device <highlight><bold>30</bold></highlight>. However, this is not intended to limit the invention. For example, the digital image data may be accumulated on the hard disk <highlight><bold>70</bold></highlight>A (<highlight><bold>70</bold></highlight>B) directly from the cameras <highlight><bold>40</bold></highlight>. This reduces processing load at the control device <highlight><bold>30</bold></highlight>, thereby improving performance of the cameras <highlight><bold>40</bold></highlight> in tracking the subject. </paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> In addition, in the above-described embodiments, the subject is an athlete. However, this is not intended to limit the invention. For example, the subject may be a ball used in an athletic event. Since shooting is performed by tracking the ball, to which most of the audience pays attention in the image information collecting system <highlight><bold>10</bold></highlight> of the above-described first embodiment, or digital image data is extracted by tracking the ball in the image information collecting system <highlight><bold>10</bold></highlight> of the above-described second embodiment, images satisfying a general audience can be collected. </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> Further, in the above-described embodiments, digital video cameras for shooting motion images have been used as the shooting devices in the invention. However, this is not intended to limit the invention. For example, digital still cameras may be used in the invention. In this case, still images are shot by the still cameras at a predetermined time interval, and are sequentially stored on the hard disk <highlight><bold>70</bold></highlight>A (<highlight><bold>70</bold></highlight>B). The effects of the above-described embodiments can be similarly obtained in this case (modification). </paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> It should be noted that the flows of the processing programs described in the above-described embodiments (see FIGS. <highlight><bold>8</bold></highlight>-<highlight><bold>10</bold></highlight>, <highlight><bold>12</bold></highlight>, <highlight><bold>19</bold></highlight> and <highlight><bold>20</bold></highlight>) are examples, and can be modified without departing from the scope and spirit of the invention. </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> As described above, in the system for collecting image information according to the first aspect of the invention and the method for collecting image information according to the second aspect of the invention, the subject is provided with the transmission device for transmitting the radio signal representing the subject&apos;s location, the shooting directions of the shooting devices which shoot the subject from mutually different directions are controlled to shoot the subject on the basis of the location of the subject represented by the radio signal transmitted from the transmission device, and the image information acquired via the shooting devices are stored in the storage device. Therefore, image information representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> Further, in the system for collecting image information according to the third aspect of the invention and the method for collecting image information according to the fourth aspect of the invention, the subject is provided with the transmission device for transmitting the radio signal representing the subject&apos;s location, image information acquired via the shooting devices for shooting the subject from mutually different positions is stored in the storage device, and image information including image information representing at least the subject is extracted from the image information stored in the storage device on the basis of the location of the subject represented by the radio signal transmitted from the transmission device. Therefore, image information representing desired scenes can be obtained with certainty. </paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> Furthermore, in the system for collecting image information according to the fifth aspect of the invention and the method for collecting image information according to the sixth aspect of the invention, the location signal representing the location of the subject is obtained, image information acquired via the shooting devices for shooting the subject from mutually different directions or positions is stored in the storage device, and the output range of the image information is changed on the basis of the location information so that image information representing at least the subject is included. Therefore, image information representing desired scenes can be obtained with certainty. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A system for collecting image information comprising: 
<claim-text>a transmission device provided at a subject for transmitting a radio signal representing a location of the subject; </claim-text>
<claim-text>shooting devices for shooting the subject from mutually different directions to generate image information of the subject; </claim-text>
<claim-text>a storage device for storing the generated image information; </claim-text>
<claim-text>changing devices for changing shooting directions of the shooting devices; and </claim-text>
<claim-text>a control device for receiving the radio signal transmitted from the transmission device and controlling the changing devices on the basis of location information of the subject represented by the signal so that at least one of the shooting devices is directed to shoot the subject. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The system for collecting image information of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the control device calculates distances from the shooting devices to the subject on the basis of the location information of the subject and controls each of the shooting devices so that an optical magnification for shooting increases as distance increases. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The system for collecting image information of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>collecting means for collecting sound information of sound generated at at least one of the subject and surroundings thereof while the subject is shot by the shooting devices; and </claim-text>
<claim-text>extracting means, connected to the collecting means and the storage device, for extracting, from the image information stored in the storage device, image information acquired during particular time spans including times, at which an intensity of sound represented by the sound information has exceeded a predetermined level. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The system for collecting image information of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the subject is at least one of an athlete and a ball used in an athletic event. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A method for collecting image information of a subject using shooting devices for shooting the subject from mutually different directions and a storage device for storing the image information of the subject, comprising the steps of: 
<claim-text>providing the subject with a transmission device for transmitting a radio signal representing a location of the subject; </claim-text>
<claim-text>receiving the radio signal and controlling a shooting direction of at least one of the shooting devices on the basis of location information of the subject represented by the radio signal so that at least one of the shooting devices shoots the subject; and </claim-text>
<claim-text>storing the image information acquired via the shooting devices in the storage device. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method for collecting image information of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further comprising the steps of: 
<claim-text>calculating distances from the shooting devices to the subject on the basis of the location information of the subject; and </claim-text>
<claim-text>controlling each of the shooting devices so that optical magnification for shooting increases as distance increases. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method for collecting image information of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further comprising the steps of: 
<claim-text>collecting sound information of sound generated at at least one of the subject and surroundings thereof while the subject is shot by the shooting devices; and </claim-text>
<claim-text>extracting, from the image information stored in the storage device, image information acquired during particular time spans including times, at which an intensity of sound represented by the sound information has exceeded a predetermined level. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method for collecting image information of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein the subject is at least one of an athlete and a ball used in an athletic event. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A system for collecting image information comprising: 
<claim-text>a transmission device provided at a subject for transmitting a radio signal representing a location of the subject; </claim-text>
<claim-text>shooting devices for shooting the subject to generate image information including images of the subject, the shooting devices being positioned so that at least one of the shooting devices can shoot the subject; </claim-text>
<claim-text>a storage device for storing the image information acquired via the shooting devices; and </claim-text>
<claim-text>an extracting device for extracting, from the image information stored in the storage device, image information including images representing at least the subject on the basis of the location information of the subject represented by the radio signal transmitted from the transmission device. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The system for collecting image information of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein the shooting devices are placed in mutually different positions around an area to be shot and substantially all of the area to be shot can be shot by combining shooting areas of the shooting devices. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The system for collecting image information of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, further comprising image synthesizing means for synthesizing the image information extracted by the extracting device such that image information shot by the shooting devices whose shooting areas are adjacent to each other become successive in order of time. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The system for collecting image information of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, further comprising: 
<claim-text>collecting means for collecting sound information of sound generated at at least one of the subject and surroundings thereof while the subject is shot by the shooting devices; and </claim-text>
<claim-text>extracting means, connected to the collecting means and the storage device, for extracting, from the image information stored in the storage device, image information acquired during particular time spans including times, at which an intensity of sound represented by the sound information has exceeded a predetermined level. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The system for collecting image information of <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein the storage device stores, together with the image information, time information representing a shooting time at which an image has been shot. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The system for collecting image information of <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the storage device stores time information corresponding to the times at which the intensity of sound represented by the sound information has exceeded the predetermined level. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The system for collecting image information of <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein, on the basis of time information corresponding to the times at which the intensity of sound has exceeded the predetermined level, the extracting means extracts, from the storage device, the image information acquired during the particular time spans including the times. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A method for collecting image information of a subject using shooting devices and a storage device for storing the image information, comprising the steps of: 
<claim-text>providing the subject with a transmission device for transmitting a radio signal representing a location of the subject; </claim-text>
<claim-text>shooting the subject using the shooting devices in such a manner that at least one of the shooting devices can shoot the subject to generate image information including images of the subject; </claim-text>
<claim-text>storing the image information in the storage device; and </claim-text>
<claim-text>extracting, from the image information stored in the storage device, image information including images representing at least the subject on the basis of the received location information of the subject. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method for collecting image information of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein the shooting devices are placed in mutually different positions around an area to be shot and substantially all of the area to be shot can be shot by combining shooting areas of the shooting devices. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method for collecting image information of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, further comprising the step of synthesizing the extracted image information such that image information shot by the shooting devices whose shooting areas are adjacent to each other become successive in order of time. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The method for collecting image information of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein sound information of sound generated at at least one of the subject and surroundings thereof is collected while the subject is shot by the shooting devices, and image information acquired during particular time spans including times, at which an intensity of sound represented by the sound information has exceeded a predetermined level, is extracted from the image information stored in the storage device. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method for collecting image information of <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, wherein the storage device stores, together with the image information, time information representing a shooting time at which an image has been shot. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The method for collecting image information of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the storage device stores time information corresponding to the times at which the intensity of sound represented by the sound information has exceeded the predetermined level. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The method for collecting image information of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein, on the basis of time information corresponding to the times at which the intensity of sound has exceeded the predetermined level, the image information acquired during the particular time spans including the times is extracted from the storage device. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. A system for collecting image information comprising: 
<claim-text>obtaining means for obtaining location information representing a location of a subject; </claim-text>
<claim-text>shooting devices for shooting the subject to generate image information, the shooting devices being placed in mutually different positions so that at least one of the shooting devices can shoot the subject; </claim-text>
<claim-text>a storage device for storing the image information acquired via the shooting devices; </claim-text>
<claim-text>extracting means for extracting, from the image information stored in the storage device, image information representing images of the subject; and </claim-text>
<claim-text>output changing means for changing, on the basis of the obtained location information, a range of the image information from at least one of the extracting means and the shooting devices, so that the extracted image information includes the image information of the subject. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A method for collecting image information of a subject using shooting devices placed in mutually different positions and a storage device for storing the image information, comprising the steps of: 
<claim-text>obtaining location information representing a location of the subject; </claim-text>
<claim-text>shooting the subject using the shooting devices in such a manner that at least one of the shooting devices can shoot the subject to generate image information including images of the subject; </claim-text>
<claim-text>storing the image information in the storage device; </claim-text>
<claim-text>extracting, from the image information stored in the storage device, image information representing images of the subject; and </claim-text>
<claim-text>changing, on the basis of the obtained location information, a range of the image information obtained by at least one of shooting and extracting, so that the extracted image information includes the image information of the subject.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>8</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030003925A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030003925A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030003925A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030003925A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030003925A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030003925A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030003925A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030003925A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030003925A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030003925A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030003925A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030003925A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030003925A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030003925A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030003925A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030003925A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030003925A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030003925A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030003925A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00019">
<image id="EMI-D00019" file="US20030003925A1-20030102-D00019.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00020">
<image id="EMI-D00020" file="US20030003925A1-20030102-D00020.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
