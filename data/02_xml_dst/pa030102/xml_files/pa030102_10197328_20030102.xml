<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002579A1-20030102-M00001.NB SYSTEM "US20030002579A1-20030102-M00001.NB" NDATA NB>
<!ENTITY US20030002579A1-20030102-M00001.TIF SYSTEM "US20030002579A1-20030102-M00001.TIF" NDATA TIF>
<!ENTITY US20030002579A1-20030102-D00000.TIF SYSTEM "US20030002579A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002579A1-20030102-D00001.TIF SYSTEM "US20030002579A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002579A1-20030102-D00002.TIF SYSTEM "US20030002579A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002579A1-20030102-D00003.TIF SYSTEM "US20030002579A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002579A1-20030102-D00004.TIF SYSTEM "US20030002579A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002579A1-20030102-D00005.TIF SYSTEM "US20030002579A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002579A1-20030102-D00006.TIF SYSTEM "US20030002579A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002579A1-20030102-D00007.TIF SYSTEM "US20030002579A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002579A1-20030102-D00008.TIF SYSTEM "US20030002579A1-20030102-D00008.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002579</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10197328</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020717</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04N007/12</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>375</class>
<subclass>240100</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>375</class>
<subclass>240160</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Scalable video coding system</title-of-invention>
</technical-information>
<continuity-data>
<continuations>
<continuation-of>
<parent-child>
<child>
<document-id>
<doc-number>10197328</doc-number>
<kind-code>A1</kind-code>
<document-date>20020717</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09867891</doc-number>
<document-date>20010530</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>PENDING</parent-status>
</parent-child>
</continuation-of>
</continuations>
<continuations>
<continuation-of>
<parent-child>
<child>
<document-id>
<doc-number>09867891</doc-number>
<document-date>20010530</document-date>
<country-code>US</country-code>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09110616</doc-number>
<document-date>19980706</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>GRANTED</parent-status>
<parent-patent>
<document-id>
<doc-number>6292512</doc-number>
<country-code>US</country-code>
</document-id>
</parent-patent>
</parent-child>
</continuation-of>
</continuations>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Hayder</given-name>
<family-name>Radha</family-name>
</name>
<residence>
<residence-us>
<city>Mahwah</city>
<state>NJ</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Yingwei</given-name>
<family-name>Chen</family-name>
</name>
<residence>
<residence-us>
<city>Ossining</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Robert</given-name>
<middle-name>A.</middle-name>
<family-name>Cohen</family-name>
</name>
<residence>
<residence-us>
<city>Ossining</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>U.S. PHILIPS CORPORATION</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>Corporate Patent Counsel</name-1>
<name-2>U.S. Philips Corporation</name-2>
<address>
<address-1>580 White Plains Road</address-1>
<city>Tarrytown</city>
<state>NY</state>
<postalcode>10591</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A system for coding video data comprised of one or more frames codes a portion of the video data using a frame-prediction coding technique, and generates residual images based on the video data and the coded video data. The system then codes the residual images using a fine-granular scalability coding technique, and outputs the coded video data and at least one of the coded residual images to a receiver. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention is directed to a scalable video coding system which codes video data using both frame-prediction and fine-granular scalable images. The invention has particular utility in connection with variable-bandwidth networks and computer systems that are able to accommodate different bit rates, and hence different quality images. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Scalable video coding in general refers to coding techniques which are able to provide different levels, or amounts, of data per frame of video. Currently, such techniques are used by lead video coding standards, such as MPEG-2 and MPEG-4 (i.e., &ldquo;Motion Picture Experts Group&rdquo; coding), in order to provide flexibility when outputting coded video data. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In the scalable coding techniques currently employed by MPEG-2 and MPEG-4, an encoder codes frames of video data and divides the coded frames into a base layer (&ldquo;BL&rdquo;) and an enhancement layer (&ldquo;EL&rdquo;). Typically, the base layer comprises a minimum amount of data required to decode the coded video data. The enhancement layer, on the other hand, comprises additional information which enhances (e.g., improves the quality of) the base layer when it is decoded. In operation, the encoder transmits all frames from the base layer to a receiving device, which can be a personal computer or the like. However, the encoder only transmits frames from the enhancement layer in cases where the receiving device has sufficient processing power to handle those additional frames and/or the medium over which the frames are transmitted has sufficient bandwidth. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 1 and 2</cross-reference> show &ldquo;scalability structures&rdquo; which are currently used in MPEG-2 and MPEG-4 for the base layer and the enhancement layer. More specifically, <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a scalability structure <highlight><bold>1</bold></highlight> which employs frame-prediction in base layer <highlight><bold>2</bold></highlight> to generate predicative (or &ldquo;P&rdquo;) frames from an intra (or &ldquo;I&rdquo;) frame or from a preceding P frame. As shown in the figure, frame-prediction is also used in the enhancement layer to generate P frames based on frames in the base layer. <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows another scalability structure <highlight><bold>3</bold></highlight> which is currently used in MPEG-2 and MPEG-4. In the scalability structure shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, frame-prediction is again employed to determine P frames in the base layer. Unlike scalability structure <highlight><bold>1</bold></highlight>, however, scalability structure <highlight><bold>3</bold></highlight> also uses frame-prediction in the enhancement layer to generate bi-directional (or &ldquo;B&rdquo;) frames which, in this case, are interpolated from preceding frames in the enhancement layer and contemporaneous frames in the base layer. In general, MPEG-2 and MPEG-4 encoders use frame prediction in the manner set forth above to increase data compression and thus increase coding efficiency. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Another well-known scalable video coding technique is called fine-granular scalability coding. Fine-granular scalability coding codes the same image (e.g., a frame of video) using progressively more data each time coding takes place. For example, as shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, image <highlight><bold>4</bold></highlight> is initially encoded using data sufficient to produce image <highlight><bold>5</bold></highlight>. Thereafter, additional data is coded which is sufficient to produce enhanced images <highlight><bold>6</bold></highlight>, <highlight><bold>7</bold></highlight> and <highlight><bold>8</bold></highlight> in succession. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Fine-granular scalability coding has several advantages over the frame-prediction techniques described above. Specifically, because fine-granular scalability coding can provide a wider range of enhanced images than frame-prediction techniques, fine-granular scalability coding is generally preferred in environments, such as the Internet, which have a wide range of available bandwidth. For similar reasons, fine-granular scalability coding is also generally preferred when dealing with receiving devices that have varying processing capabilities and/or bandwidth. That is, because fine-granular scalability coding produces a wide range of enhanced images, it is possible to match the appropriate image relatively closely to an amount of available bandwidth. As a result, in theory, it is possible to obtain the most amount of data for an image for a given amount of available bandwidth. On the down-side, fine-granular scalability coding does not permit the use of frame-prediction. As a result, it requires more data than the frame-prediction techniques described above and, consequently, degrades coding efficiency. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Thus, there exists a need for a scalable video coding technique which incorporates the efficiency of frame-prediction coding and the accuracy of fine-granular scalability coding. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The present invention addresses the foregoing need by coding a portion (e.g., a base layer) of input video data using a frame-prediction coding technique and then coding another portion (e.g., residual images in an enhancement layer) of the video data using fine-granular scalability coding. By coding a base layer using a frame-prediction coding technique, the present invention reduces the amount of bits required to code the video data and thus maintains coding efficiency. By coding the residual images using fine-granular scalability coding, the present invention is able to provide a wide range of residual images, one or more of which can be selected for transmission based, e.g., on an available bandwidth of a receiving device. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> Thus, according to one aspect, the present invention is a system (i.e., a method, an apparatus, and computer-executable process steps) for coding video data comprised of one or more frames. The system codes a portion (e.g., a base layer) of the video data using a frame-prediction coding technique, and then generates residual images based on the video data and the coded video data. Thereafter, the system codes the residual images using a fine-granular scalability coding technique, and outputs the coded video data and at least one of the coded residual images to a receiver, such as a variable-bandwidth network or a networked device thereon. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In preferred embodiments of the invention, the system determines a bandwidth of the receiver, and then selects which of the coded residual images to output based on the bandwidth of the receiver. By doing this, the invention is able to output a coded residual image which is most appropriate for the available bandwidth. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> In other preferred embodiments, the system codes the portion of the video data at a plurality of different bit rates so as to produce multiple versions of the coded video data, and generates a plurality of residual images for each version of the coded video data. In these embodiments, the system codes the residual images using a fine-granular scalability coding technique, determines variations in a bandwidth of the receiver over time, and then selects which one of the multiple versions and the coded residual images to output based on the variations in the bandwidth of the receiver. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> By way of example, for a receiver bandwidth increasing from B<highlight><subscript>1 </subscript></highlight>to B<highlight><subscript>2</subscript></highlight>, where B<highlight><subscript>1</subscript></highlight>&lt;B<highlight><subscript>2</subscript></highlight>, the system selects a first version of the coded video data and successively selects coded residual images corresponding to each frame of the first version of the coded video data, which are coded at successively higher bit rates. For a receiver bandwidth increasing from B<highlight><subscript>2 </subscript></highlight>to B<highlight><subscript>3</subscript></highlight>, where B<highlight><subscript>2</subscript></highlight>&lt;B<highlight><subscript>3</subscript></highlight>, the system selects a second version of the coded video data and successively selects coded residual images corresponding to each frame of the second version of the coded video data, which are coded at successively higher bit rates. Conversely, for a receiver bandwidth decreasing from B<highlight><subscript>3 </subscript></highlight>to B<highlight><subscript>2</subscript></highlight>, where B<highlight><subscript>3</subscript></highlight>&gt;B<highlight><subscript>2</subscript></highlight>, the system selects a first version of the coded video data and successively selects coded residual images corresponding to each frame of the first version of the coded video data, which are coded at successively lower bit rates. Likewise, for a receiver bandwidth decreasing from B<highlight><subscript>2 </subscript></highlight>to B<highlight><subscript>1</subscript></highlight>, where B<highlight><subscript>2</subscript></highlight>&gt;B<highlight><subscript>1</subscript></highlight>, the system selects a second version of the coded video data and successively selects coded residual images corresponding to each frame of the second version of the coded video data, which are coded at successively lower bit rates. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> As is clear from the foregoing, by coding a base layer at a plurality of different bit rates and then selecting versions of the base layer and the residual images based on a range of available bandwidth, during display the present invention is able to provide a relatively smooth transition between different versions of the base layer. That is, in conventional &ldquo;simulcast&rdquo; systems (i.e., systems such as this where a base layer has been coded at different bit rates), there is a substantial jump in image quality at the transition from a first bit rate to a second bit rate. The present invention, however, provides for a smoother transition by selecting and outputting fine-granular coded residual images between the different versions of the base layer. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> According to another aspect, the present invention is a network system that includes an encoder which receives input video data and which outputs frames of coded video data therefrom, a variable-bandwidth network over which the frames of coded video data are transmitted, a decoder which receives the frames of coded video data from the variable-bandwidth network and which decodes the coded video data, and a display which displays the decoded video data. The encoder includes a processor and a memory which stores computer-executable process steps. The processor executes process steps stored in the memory so as to produce the frames of coded video data by (i) coding a base layer from the input video data using a frame-prediction coding technique, (ii) coding an enhancement layer from the input video data using a fine-granular scalability coding technique, (iii) determining a bandwidth of the variable-bandwidth network, and (iv) selecting, for output, the base layer and, in a case that the bandwidth of the variable-bandwidth network is greater than a predetermined value, a portion of the enhancement layer. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> According to still another aspect, the present invention is a system for decoding video data comprised of an enhancement layer bitstream and a base layer bitstream, where the base layer bitstream is coded using a frame-prediction coding technique and the enhancement layer bitstream is encoded using a fine-granular scalability coding technique. The system receives the coded video data, decodes the base layer bitstream using a frame-prediction decoder, and decodes the enhancement layer bitstream using a fine-granular scalability decoder. Thereafter, the system combines (e.g., adds) decoded video data from the base layer bitstream and from the enhancement layer bitstream to form a video image. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> According to still another aspect, the present invention is a system for coding video data and outputting coded video data to a plurality of receivers. The system codes a first portion of the video data using a frame-prediction coding technique to produce a first bitstream, and then codes a second portion of the video data using a fine-granular scalability coding technique to produce a second bitstream. The first bitstream is output to the plurality of receivers, whereafter the second bitstream is divided into two or more sub-streams. Finally, the two or more sub-streams are output to the plurality of receivers. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> By virtue of the foregoing aspect of the invention, it is possible to multicast video data to a plurality of receivers. In other words, it is possible to broadcast coded data to the receivers at multiple bandwidths. These receivers may then accept only those bandwidths that they are able to process and/or receive. Thus, each receiver is able to receive and process as much data as it can handle, thereby resulting in more accurate image reproduction thereby. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> This brief summary has been provided so that the nature of the invention may be understood quickly. A more complete understanding of the invention can be obtained by reference to the following detailed description of the preferred embodiments thereof in connection with the attached drawings. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> depicts a scalability structure used with a conventional frame-prediction-type scalable coding technique. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> depicts an alternative scalability structure used with a conventional frame-prediction-type scalable coding technique. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> depicts images generated using a fine-granular scalability coding/decoding technique. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> depicts a computer system on which the present invention may be implemented. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> depicts the architecture of a personal computer in the computer system shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a functional block diagram showing elements of the first and second embodiments of the present invention. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flow diagram describing the scalability coding technique of the present invention. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows a scalability structure generated by the present invention. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a block diagram of a decoder in accordance with the present invention. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a graph depicting image quality versus bit-rate for simulcast bitstreams generated by the second embodiment of the present invention. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a functional block diagram showing elements of the third embodiment of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a representative embodiment of a computer system <highlight><bold>9</bold></highlight> on which the present invention may be implemented. As shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, personal computer (&ldquo;PC&rdquo;) <highlight><bold>10</bold></highlight> includes network connection <highlight><bold>11</bold></highlight> for interfacing to a network, such as a variable-bandwidth network or the Internet, and fax/modem connection <highlight><bold>12</bold></highlight> for interfacing with other remote sources such as a video camera (not shown). PC <highlight><bold>10</bold></highlight> also includes display screen <highlight><bold>14</bold></highlight> for displaying information (including video data) to a user, keyboard <highlight><bold>15</bold></highlight> for inputting text and user commands, mouse <highlight><bold>13</bold></highlight> for positioning a cursor on display screen <highlight><bold>14</bold></highlight> and for inputting user commands, disk drive <highlight><bold>16</bold></highlight> for reading from and writing to floppy disks installed therein, and CD-ROM drive <highlight><bold>17</bold></highlight> for accessing information stored on CD-ROM. PC <highlight><bold>10</bold></highlight> may also have one or more peripheral devices attached thereto, such as a scanner (not shown) for inputting document text images, graphics images, or the like, and printer <highlight><bold>19</bold></highlight> for outputting images, text, or the like. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows the internal structure of PC <highlight><bold>10</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, PC <highlight><bold>10</bold></highlight> includes memory <highlight><bold>20</bold></highlight>, which comprises a computer-readable medium such as a computer hard disk. Memory <highlight><bold>20</bold></highlight> stores data <highlight><bold>23</bold></highlight>, applications <highlight><bold>25</bold></highlight>, print driver <highlight><bold>24</bold></highlight>, and operating system <highlight><bold>26</bold></highlight>. In preferred embodiments of the invention, operating system <highlight><bold>26</bold></highlight> is a windowing operating system, such as Microsoft&reg; Windows95; although the invention may be used with other operating systems as well. Among the applications stored in memory <highlight><bold>20</bold></highlight> are scalable video coder <highlight><bold>21</bold></highlight> and scalable video decoder <highlight><bold>22</bold></highlight>. Scalable video coder <highlight><bold>21</bold></highlight> performs scalable video data encoding in the manner set forth in detail below, and scalable video decoder <highlight><bold>22</bold></highlight> decodes video data which has been coded in the manner prescribed by scalable video coder <highlight><bold>21</bold></highlight>. The operation of these applications is described in detail below. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> Also included in PC <highlight><bold>10</bold></highlight> are display interface <highlight><bold>29</bold></highlight>, keyboard interface <highlight><bold>30</bold></highlight>, mouse interface <highlight><bold>31</bold></highlight>, disk drive interface <highlight><bold>32</bold></highlight>, CD-ROM drive interface <highlight><bold>34</bold></highlight>, computer bus <highlight><bold>36</bold></highlight>, RAM <highlight><bold>37</bold></highlight>, processor <highlight><bold>38</bold></highlight>, and printer interface <highlight><bold>40</bold></highlight>. Processor <highlight><bold>38</bold></highlight> preferably comprises a microprocessor or the like for executing applications, such those noted above, out of RAM <highlight><bold>37</bold></highlight>. Such applications, including scalable video coder <highlight><bold>21</bold></highlight> and scalable video decoder <highlight><bold>22</bold></highlight>, may be stored in memory 20 (as noted above) or, alternatively, on a floppy disk in disk drive <highlight><bold>16</bold></highlight> or a CD-ROM in CD-ROM drive <highlight><bold>17</bold></highlight>. Processor <highlight><bold>38</bold></highlight> accesses applications (or other data) stored on a floppy disk via disk drive interface <highlight><bold>32</bold></highlight> and accesses applications (or other data) stored on a CD-ROM via CD-ROM drive interface <highlight><bold>34</bold></highlight>. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Application execution and other tasks of PC <highlight><bold>4</bold></highlight> may be initiated using keyboard <highlight><bold>15</bold></highlight> or mouse <highlight><bold>13</bold></highlight>, commands from which are transmitted to processor <highlight><bold>38</bold></highlight> via keyboard interface <highlight><bold>30</bold></highlight> and mouse interface <highlight><bold>31</bold></highlight>, respectively. Output results from applications running on PC <highlight><bold>10</bold></highlight> may be processed by display interface <highlight><bold>29</bold></highlight> and then displayed to a user on display <highlight><bold>14</bold></highlight> or, alternatively, output via network connection <highlight><bold>11</bold></highlight>. For example, input video data which has been coded by scalable video coder <highlight><bold>21</bold></highlight> is typically output via network connection <highlight><bold>11</bold></highlight>. On the other hand, coded video data which has been received from, e.g., a variable bandwidth-network is decoded by scalable video decoder <highlight><bold>22</bold></highlight> and then displayed on display <highlight><bold>14</bold></highlight>. To this end, display interface <highlight><bold>29</bold></highlight> preferably comprises a display processor for forming video images based on decoded video data provided by processor <highlight><bold>38</bold></highlight> over computer bus <highlight><bold>36</bold></highlight>, and for outputting those images to display <highlight><bold>14</bold></highlight>. Output results from other applications, such as word processing programs, running on PC <highlight><bold>10</bold></highlight> may be provided to printer <highlight><bold>19</bold></highlight> via printer interface <highlight><bold>40</bold></highlight>. Processor <highlight><bold>38</bold></highlight> executes print driver <highlight><bold>24</bold></highlight> so as to perform appropriate formatting of such print jobs prior to their transmission to printer <highlight><bold>19</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="7"><number>&lsqb;0036&rsqb;</number> First Embodiment </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> Turning to scalable video coder <highlight><bold>21</bold></highlight>, this module comprises computer-executable process steps which code video data comprised of one or more successive frames. In brief, these process steps code a portion of the video data using a frame-prediction coding technique, generate residual images based on the video data and the coded video data, and code the residual images using a fine-granular scalability coding technique. The steps then output the coded video data and at least one of the coded residual images to a receiver which, generally speaking, can comprise a network (variable-bandwidth or otherwise), a PC, or other video-supporting networkable devices including, but not limited to, digital televisions/settop boxes and video conferencing equipment. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a block diagram depicting a video source <highlight><bold>42</bold></highlight>, a variable-bandwidth network <highlight><bold>43</bold></highlight>, and modules used to effect the foregoing process steps. <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flow diagram which explains the functionality of the modules shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. To begin, in step S<highlight><bold>701</bold></highlight> original uncoded video data is input into the present invention. This video data may be input via network connection 11, fax/modem connection <highlight><bold>12</bold></highlight>, or, as shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, via a video source. For the purposes of the present invention, video source <highlight><bold>42</bold></highlight> can comprise any type of video capturing device, an example of which is a digital video camera. As shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, video data from the video source is input to both BL encoder <highlight><bold>44</bold></highlight> and residual image computation block <highlight><bold>45</bold></highlight>. The reason for this is apparent below. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Next, step S<highlight><bold>702</bold></highlight> codes a portion (i.e., a base layer, or BL) of the original video data using a standard frame-prediction coding technique. Step S<highlight><bold>702</bold></highlight> is performed by BL encoder <highlight><bold>44</bold></highlight>, which, in preferred embodiments of the invention, is an MPEG-1, an MPEG-2 or an MPEG-4 encoder. A general overview of the MPEG standard is provided in &ldquo;MPEG: A Video Compression Standard For Multimedia Applications&rdquo;, by Didier LeGall, Communications of the ACM, Vol. 34, No. 4 (April 1991). BL encoder <highlight><bold>44</bold></highlight> compresses the video data at a predetermined bit-rate, R<highlight><subscript>BL</subscript></highlight>. In preferred embodiments of the invention, R<highlight><subscript>BL </subscript></highlight>is determined by calculation block <highlight><bold>48</bold></highlight> based on a current bandwidth of a receiver, such as variable-bandwidth network <highlight><bold>43</bold></highlight> (or, e.g., a computer system having variable processing capabilities). </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> More specifically, calculation block <highlight><bold>48</bold></highlight> measures a minimum bit-rate (&ldquo;R<highlight><subscript>MIN</subscript></highlight>&rdquo;), a maximum bit-rate (&ldquo;R<highlight><subscript>MAX</subscript></highlight>&rdquo;), and a current available bandwidth (&ldquo;R&rdquo;) of variable-bandwidth network <highlight><bold>43</bold></highlight>. Calculation block <highlight><bold>48</bold></highlight> then sets R<highlight><subscript>BL </subscript></highlight>to a value between R<highlight><subscript>MIN </subscript></highlight>and R. In most cases, calculation block <highlight><bold>48</bold></highlight> sets R<highlight><subscript>BL </subscript></highlight>to R<highlight><subscript>MIN</subscript></highlight>, so as to ensure that, even at its lowest bandwidths, variable-bandwidth network <highlight><bold>43</bold></highlight> will be able to accommodate coded video data output by the present invention. This is especially true in cases where base layer encoding takes place off-line. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> shows an example of a scalability structure which is generated by the present invention. As shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, this scalability structure includes both a base layer (&ldquo;BL&rdquo;) and an enhancement layer (&ldquo;EL&rdquo;). Base layer <highlight><bold>47</bold></highlight> includes frames, such as frame <highlight><bold>49</bold></highlight>. These frames are compressed at a bit-rate of R<highlight><subscript>BL </subscript></highlight>by BL encoder <highlight><bold>44</bold></highlight>. Enhancement layer <highlight><bold>50</bold></highlight>, however, includes fine-granular coded images corresponding to contemporaneous frames in the base layer. The following describes how the invention generates enhancement layer <highlight><bold>50</bold></highlight>. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> More specifically, step S<highlight><bold>703</bold></highlight> generates residual images <highlight><bold>51</bold></highlight> based on the original video data input from video source <highlight><bold>42</bold></highlight> and based on coded video data (i.e. the base layer) provided by BL encoder <highlight><bold>44</bold></highlight>. In the block diagram shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, step S<highlight><bold>703</bold></highlight> is performed by residual image computation block <highlight><bold>45</bold></highlight>. In operation, residual image computation block <highlight><bold>45</bold></highlight> receives coded video data from BL encoder <highlight><bold>44</bold></highlight> and then decodes that coded video data. Thereafter, residual images <highlight><bold>51</bold></highlight> are generated based on a difference between pixels in this decoded video data and pixels in the original video data. Generally speaking, the residual images correspond to the difference between frames in the base layer (which comprises the minimum number of frames and/or the minimum amount of data required by a decoder to decode a video signal) and frames in the original video data. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Residual image computation block <highlight><bold>45</bold></highlight> may use one or more of variety of different methods to generate residual images <highlight><bold>51</bold></highlight>. For example, in one embodiment of the invention, a simple pixel-by-pixel subtraction is performed between frames in the base layer and frames in the original video data. The resulting difference between these two sets of frames (i.e., the residual images) includes differences in the frames&apos; resolutions. In cases where the base layer does not include entire frames of the original video data, the residual images include these missing frames. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> In another embodiment of the invention, residual image computation block <highlight><bold>45</bold></highlight> generates residual images <highlight><bold>51</bold></highlight> by first filtering the decoded video data and then determining a difference between this filtered video data and the original video data. This technique has the advantage of removing unwanted noise and the like from the decoded video data caused, e.g., by the coding and decoding processes. In preferred embodiments of the invention, a deblocking filter is used to filter the decoded video data; although the invention is not limited to the use of this type of filter. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> In still another embodiment of the invention, residual image computation block <highlight><bold>45</bold></highlight> generates residual images <highlight><bold>51</bold></highlight> by filtering both the decoded video and the original video data, and then determining a difference between both of these types of filtered data. in this embodiment, the same type of filter (e.g., a deblocking filter) may be applied to both the original video data and the decoded video data. Alternatively, different types of filters may be applied to the original video data and to the decoded video data. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> In general, when filtering is used to generate residual images <highlight><bold>51</bold></highlight>, a decoder for receiving video data that has been coded in accordance with the present invention should be &ldquo;in synch&rdquo; with the type of filtering used thereby, meaning that substantially the same type of filtering should be applied at the decoder in order to compensate for the effects of filtering. For example, if residual images <highlight><bold>51</bold></highlight> are coded based on filtered decoded video data, that same filtering should be applied to the residual images during decoding thereof. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> Returning to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, after step S<highlight><bold>703</bold></highlight>, processing proceeds to step S<highlight><bold>704</bold></highlight>. Step S<highlight><bold>704</bold></highlight> codes the residual images using an embedded fine-granular scalability coding technique, as shown in the enhancement layer of the scalability structure of <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. In the embodiment of the invention shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, this step is performed by fine-granular scalable EL encoder <highlight><bold>54</bold></highlight>. EL encoder <highlight><bold>54</bold></highlight> codes residual images <highlight><bold>51</bold></highlight> at a bit-rate of R<highlight><subscript>MAX</subscript></highlight>-R<highlight><subscript>BL </subscript></highlight>(i.e., the difference between the base layer bandwidth and maximum bandwidth of network <highlight><bold>43</bold></highlight>) using a fine-granular coding technique. At this point, it is noted that, since a fine-granular scaling technique is used to code frames for the enhancement layer, frame prediction is not employed therein. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, values for R<highlight><subscript>MAX </subscript></highlight>and R<highlight><subscript>BL </subscript></highlight>are provided to EL encoder <highlight><bold>54</bold></highlight> by calculation block <highlight><bold>48</bold></highlight>. Any of a variety, of well-known fine-granular coding techniques may be used by EL encoder <highlight><bold>54</bold></highlight>. Examples of these include an embedded discrete cosine transform (&ldquo;DCT&rdquo;) technique and a scalable matching pursuit (&ldquo;MP&rdquo;) technique. Preferred embodiments of the invention, however, use one of the family of wavelet transforms (e.g., zero tree wavelet transforms) to effect enhancement layer coding. For example, the preferred embodiment of the invention uses the still-image coding technique provided in MPEG-4 to perform fine-granular scalability coding. This approach codes images as whole using wavelet transforms. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> Regardless of what type of fine-granular scalability coding is used by EL encoder <highlight><bold>54</bold></highlight>, an EL bitstream is output therefrom which has a bit-rate of R<highlight><subscript>MAX</subscript></highlight>-R<highlight><subscript>BL</subscript></highlight>. This EL bitstream comprises a plurality of embedded fine-granular scalable images, meaning that the bitstream is comprised of an initial coarse image and one or more enhancements thereto. For example, the EL bitstream may include a coarse image comprised of a predetermined number of bits (e.g., the first 100 bits) in the bitstream; an enhancement image comprising the coarse image and the next predetermined number of bits (e.g., the next 100 bits) in the bitstream; a further enhancement image comprising the coarse image, the enhancement image, and the next predetermined number of bits (e.g., the next 100 bits) in the bitstream; and so on. The number of bits used to enhance these images (100 bits in this example) is referred to as the image&apos;s granularity. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> At this point, it is noted that the present invention is not limited to using 100 bit granularity, or even to using the same number of bits to enhance the image. In fact, the granularity used by the invention can vary and, in preferred embodiments, can reach down to the byte level or even to the single bit level wherein single bits are used to enhance an image. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the EL bitstream is provided to real-time scalable video rate controller <highlight><bold>55</bold></highlight> which performs, in real-time, steps S<highlight><bold>705</bold></highlight> and S<highlight><bold>706</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. In step S<highlight><bold>705</bold></highlight>, controller <highlight><bold>55</bold></highlight> receives R<highlight><subscript>BL</subscript></highlight>. R<highlight><subscript>MAX </subscript></highlight>and R from calculation block <highlight><bold>48</bold></highlight>, and then selects, for each frame in the base layer, one or more of the coded residual images in enhancement layer <highlight><bold>50</bold></highlight> (see <cross-reference target="DRAWINGS">FIG. 8</cross-reference>) based on these values. In particular, controller <highlight><bold>55</bold></highlight> selects image(s) from the enhancement layer which have a bandwidth that substantially corresponds to R-R<highlight><subscript>BL</subscript></highlight>, i.e., the difference between the actual bandwidth of network <highlight><bold>43</bold></highlight> and the bandwidth of the base layer. Controller <highlight><bold>55</bold></highlight> selects these images by transmitting images from the EL bitstream (e.g., a coarse image and/or image enhancements) having a bandwidth that corresponds to R-R<highlight><subscript>BL</subscript></highlight>, and blocking transmission of those image enhancements which fall outside of that range. By implementing the invention using a relatively fine granularity, such as single-bit granularity, the invention is able to fill substantially all of the bandwidth between R and R<highlight><subscript>BL</subscript></highlight>. In these cases, the invention is able to provide substantially the maximum amount of video data for the given amount of available bandwidth. Of course, in cases&apos; where the receiver can handle only coded images from the base layer, controller <highlight><bold>55</bold></highlight> will not transmit any fine-granular scalable images from the enhancement layer. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Assuming, however, that these images are to be transmitted, once the appropriate fine-granular scalable images (i.e., coded residual images) have been selected by controller <highlight><bold>55</bold></highlight>, processing proceeds to step S<highlight><bold>706</bold></highlight>. In step S<highlight><bold>706</bold></highlight>, controller <highlight><bold>55</bold></highlight> outputs the base layer and the fine-granular scalable images selected in step S<highlight><bold>705</bold></highlight>. As shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the images are output to variable-bandwidth network <highlight><bold>43</bold></highlight> as a BL stream and an EL stream. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> A decoder, a functional block diagram for which is shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, then receives these coded bitstreams and decodes the data therein. Decoder <highlight><bold>57</bold></highlight> may comprise a PC, such as that shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference> or, alternatively, any of the other receivers mentioned above. As shown in the figure, decoder <highlight><bold>57</bold></highlight> includes a scalable video decoder module <highlight><bold>58</bold></highlight> which is executed by a processor therein. This scalable video decoder module is comprised of a fine-granular scalable EL decoding module <highlight><bold>59</bold></highlight> for decoding data in the EL bitstream and a frame-prediction BL decoding module <highlight><bold>60</bold></highlight> for decoding frames in the BL bitstream. In preferred embodiments of the present invention, BL decoding module <highlight><bold>60</bold></highlight> comprises an MPEG-1, MPEG-2 or MPEG-4 decoding module. Due to the fine granularity of the EL bitstream, the EL decoder can decode any appropriate portion of the EL bitstream limited, e.g., by decoder processing constraints or the like. Once the respective decoding modules have decoded the streams of video data, frames therefrom are added and reordered, if necessary, by processing block <highlight><bold>61</bold></highlight>. These frames may then be displayed to a user. </paragraph>
<paragraph id="P-0054" lvl="7"><number>&lsqb;0054&rsqb;</number> Second Embodiment </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The second embodiment of the present invention generates a scalability structure like that shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference> for each of a plurality of &ldquo;simulcast&rdquo; bitstreams. Briefly, in the second embodiment of the present invention, scalable video coder <highlight><bold>21</bold></highlight> includes computer-executable process steps to code a portion (e.g., the base layer) of input video data at a plurality of different bit rates so as to produce multiple versions of coded video data, to generate a plurality of residual images for each version of the coded video data, to code the plurality of residual images for each version of the coded video data using a fine-granular scalability coding technique, and then to output one version (e.g., one base layer) of the coded video data together with one or more coded residual images therefor. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> More specifically, in this embodiment of the invention, BL encoder <highlight><bold>44</bold></highlight> codes the base layer at a plurality of different bit rates R<highlight><subscript>B1</subscript></highlight>, R<highlight><subscript>B2</subscript></highlight>, R<highlight><subscript>B3 </subscript></highlight>. . . R<highlight><subscript>BN</subscript></highlight>, where </paragraph>
<paragraph lvl="0"><in-line-formula>R<highlight><subscript>MIN</subscript></highlight>&lt;R<highlight><subscript>B1</subscript></highlight>&lt;R<highlight><subscript>B2</subscript></highlight>&lt;R<highlight><subscript>B3 </subscript></highlight>. . . &lt;R<highlight><subscript>BN</subscript></highlight>&lt;R<highlight><subscript>MAX</subscript></highlight>. </in-line-formula></paragraph>
<paragraph id="P-0057" lvl="7"><number>&lsqb;0057&rsqb;</number> For each of these resulting simulcast coded bitstreams, residual image computation block <highlight><bold>45</bold></highlight> generates residual images in the manner described above. Thereafter, EL encoder <highlight><bold>54</bold></highlight> generates corresponding fine-granular coded images for each set of residual images. These fine-granular coded images have bit-rates of R<highlight><subscript>E1</subscript></highlight>, R<highlight><subscript>E2</subscript></highlight>, R<highlight><subscript>E3 </subscript></highlight>. . . R<highlight><subscript>EN</subscript></highlight>, which are determined in substantially the same manner as those of the EL bitstream of the first embodiment. That is,  
<math-cwu id="MATH-US-00001">
<number>1</number>
<math>
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mtable>
          <mtr>
            <mtd>
              <mrow>
                <msub>
                  <mi>R</mi>
                  <mi>E1</mi>
                </msub>
                <mo>=</mo>
                <mrow>
                  <msub>
                    <mi>R</mi>
                    <mrow>
                      <mi>E1</mi>
                      <mo>&it;</mo>
                      <mstyle>
                        <mtext>&emsp;</mtext>
                      </mstyle>
                      <mo>&it;</mo>
                      <mi>MAX</mi>
                    </mrow>
                  </msub>
                  <mo>-</mo>
                  <msub>
                    <mi>R</mi>
                    <mi>B1</mi>
                  </msub>
                </mrow>
              </mrow>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <mrow>
                <msub>
                  <mi>R</mi>
                  <mi>E2</mi>
                </msub>
                <mo>=</mo>
                <mrow>
                  <msub>
                    <mi>R</mi>
                    <mrow>
                      <mi>E2</mi>
                      <mo>&it;</mo>
                      <mstyle>
                        <mtext>&emsp;</mtext>
                      </mstyle>
                      <mo>&it;</mo>
                      <mi>MAX</mi>
                    </mrow>
                  </msub>
                  <mo>-</mo>
                  <msub>
                    <mi>R</mi>
                    <mi>B2</mi>
                  </msub>
                </mrow>
              </mrow>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <mi>&vellip;</mi>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <mrow>
                <msub>
                  <mi>R</mi>
                  <mrow>
                    <mi>E</mi>
                    <mo>&af;</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>N</mi>
                        <mo>-</mo>
                        <mn>1</mn>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                </msub>
                <mo>=</mo>
                <mrow>
                  <msub>
                    <mi>R</mi>
                    <mrow>
                      <mrow>
                        <mi>E</mi>
                        <mo>&af;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>N</mi>
                            <mo>-</mo>
                            <mn>1</mn>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>&it;</mo>
                      <mstyle>
                        <mtext>&emsp;</mtext>
                      </mstyle>
                      <mo>&it;</mo>
                      <mi>MAX</mi>
                    </mrow>
                  </msub>
                  <mo>-</mo>
                  <msub>
                    <mi>R</mi>
                    <mrow>
                      <mi>B</mi>
                      <mo>&af;</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>N</mi>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </msub>
                </mrow>
              </mrow>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <mrow>
                <mrow>
                  <msub>
                    <mi>R</mi>
                    <mi>N</mi>
                  </msub>
                  <mo>=</mo>
                  <mrow>
                    <msub>
                      <mi>R</mi>
                      <mi>MAX</mi>
                    </msub>
                    <mo>-</mo>
                    <msub>
                      <mi>R</mi>
                      <mrow>
                        <mi>B</mi>
                        <mo>&it;</mo>
                        <mstyle>
                          <mtext>&emsp;</mtext>
                        </mstyle>
                        <mo>&it;</mo>
                        <mi>N</mi>
                      </mrow>
                    </msub>
                  </mrow>
                </mrow>
                <mo>,</mo>
              </mrow>
            </mtd>
          </mtr>
        </mtable>
        <mo>&AutoLeftMatch;</mo>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>1</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
<mathematica-file id="MATHEMATICA-00001" file="US20030002579A1-20030102-M00001.NB"/>
<image id="EMI-M00001" wi="216.027" he="54.97065" file="US20030002579A1-20030102-M00001.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0058" lvl="7"><number>&lsqb;0058&rsqb;</number> where R<highlight><subscript>EM</subscript></highlight>&isin;&lsqb;R<highlight><subscript>BM</subscript></highlight>, R<highlight><subscript>MAX</subscript></highlight>&rsqb; and M&isin;&lsqb;1,N&rsqb;. In a case that the maximum EL bit-rate for a particular BL bitstream is set as the minimum bit-rate of a next simulcast BL bitstream, equations (1) reduce to </paragraph>
<paragraph lvl="0"><in-line-formula>R<highlight><subscript>E1</subscript></highlight>&equals;R<highlight><subscript>B2</subscript></highlight>&minus;R<highlight><subscript>B1 </subscript></highlight></in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>R<highlight><subscript>E2</subscript></highlight>&equals;R<highlight><subscript>B3</subscript></highlight>&minus;R<highlight><subscript>B2 </subscript></highlight></in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>&bull;</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>&bull;</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>&bull;</in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>R<highlight><subscript>E(N&minus;1)</subscript></highlight>&equals;R<highlight><subscript>BN</subscript></highlight>&minus;R<highlight><subscript>B(N&minus;1) </subscript></highlight></in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>R<highlight><subscript>N</subscript></highlight>&equals;R<highlight><subscript>MAX</subscript></highlight>&minus;R<highlight><subscript>BN</subscript></highlight>.&emsp;&emsp;(2) </in-line-formula></paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is an example of a graph of image quality versus bit-rate which explains the case corresponding to equations (2). More specifically, as shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, the invention initially selects a scalability structure having a base layer with a bit-rate R<highlight><subscript>B1 </subscript></highlight>(which, in this case is R<highlight><subscript>MIN</subscript></highlight>). The invention then monitors parameters of variable-bandwidth network <highlight><bold>43</bold></highlight> via calculation block <highlight><bold>48</bold></highlight>, and determines a new bandwidth R therefor periodically. As the bandwidth of variable-bandwidth network <highlight><bold>43</bold></highlight> increases over time, controller <highlight><bold>55</bold></highlight> selects progressively more detailed fine-granular coded residual images for each frame of the selected scalability structure/base layer, and outputs those images to the receiver. The receiver then provides those image to a display, such as display <highlight><bold>14</bold></highlight> above, thereby leading to the progressive increase in image quality shown by line <highlight><bold>64</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. However, using the scalability structure for R<highlight><subscript>B1</subscript></highlight>, it is only possible to provide a limited increase in image quality, as shown by dotted line <highlight><bold>65</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Accordingly, once the bandwidth R of variable bandwidth network <highlight><bold>43</bold></highlight> reaches a predetermined level (which may be pre-set in controller <highlight><bold>55</bold></highlight>), the scalability structure for bit-rate R<highlight><subscript>B2 </subscript></highlight>is selected. As was the case above, the invention then continues to monitor variable-bandwidth network <highlight><bold>43</bold></highlight> via calculation block <highlight><bold>48</bold></highlight>, and to re-calculate the bandwidth thereof over time. As the bandwidth of variable-bandwidth network <highlight><bold>43</bold></highlight> increases, controller <highlight><bold>55</bold></highlight> selects progressively more detailed fine-granular coded residual images for each frame of the selected scalability structure/base layer, and outputs those images to the receiver. The receiver then provides those image to a display, such as display <highlight><bold>14</bold></highlight> above, thereby leading to the further progressive increase in image quality shown by line <highlight><bold>66</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. A process similar to this is performed up to R<highlight><subscript>MAX</subscript></highlight>. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> By virtue of the foregoing process, this embodiment of the invention is able to use simulcast bitstreams to provide an overall increase image quality without large &ldquo;jumps&rdquo; at transition points R<highlight><subscript>B2 </subscript></highlight>and R<highlight><subscript>B3</subscript></highlight>. That is, conventional systems which use simulcast bitstreams to increase image quality have a large &ldquo;jump&rdquo; at each transition point between two simulcast bitstreams. This results in an abrupt transition in the displayed image. In contrast, because the present invention uses fine-granular images between the transition points, the invention is able to provide a gradual transition between bitstreams, along with a continuous increase in image quality over time. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Of course, the converse of the foregoing occurs for variable-bandwidth networks that have decreasing bandwidth. That is, for a receiver bandwidth decreasing from B<highlight><subscript>3 </subscript></highlight>to B<highlight><subscript>2</subscript></highlight>, where B<highlight><subscript>3</subscript></highlight>&gt;B<highlight><subscript>2</subscript></highlight>, the invention selects a first base layer and successively selects fine-granular coded residual images corresponding to each frame of the first base layer that are coded at successively lower bit rates. As the bandwidth decreases from B<highlight><subscript>2 </subscript></highlight>to B<highlight><subscript>1</subscript></highlight>, where B<highlight><subscript>2</subscript></highlight>&gt;B<highlight><subscript>1</subscript></highlight>, the invention selects a second base layer and successively selects fine-granular coded residual images corresponding to each frame of the second base layer that are coded at successively lower bit rates. This results in a relatively smooth decrease in image quality, as opposed to an abrupt transition. Of course, relatively smooth transitions are also achieved by the present invention for variable-bandwidth networks that have neither continuously increasing nor continuously decrease bandwidths, but rather have fluctuating or oscillating bandwidths. Such is also the case for computer systems or the like which have varying processing capabilities </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> At this point, it is noted that although the first two embodiments of the present invention have been described with respect to a variable-bandwidth network, these embodiments can be used outside of a network context. That is, rather than measuring network bandwidth, the invention may measure the processing capabilities of a receiving device (e.g., a PC) and then vary coding accordingly. </paragraph>
<paragraph id="P-0064" lvl="7"><number>&lsqb;0064&rsqb;</number> Third Embodiment </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> depicts a third embodiment of the present invention. In brief, this embodiment is a method and corresponding apparatus and process steps for coding video data and for multicasting coded video data to a plurality of receivers. In this embodiment, scalable video coder <highlight><bold>21</bold></highlight> codes a first portion of the video data (e.g., the base layer) using a frame-prediction coding technique to produce a first bitstream (e.g., the BL bitstream), and then codes a second portion of the video data (e.g., the enhancement layer) using a fine-granular scalability coding technique to produce a second bitstream (e.g., the EL bitstream). Thereafter, the first bitstream is output to one or more of the plurality of receivers, and the second bitstream is divided into two or more sub-streams These two or more sub-streams are then also output to the plurality of receivers. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, the third embodiment of the invention includes video source <highlight><bold>70</bold></highlight>, BL encoder <highlight><bold>71</bold></highlight>, residual image computation block <highlight><bold>72</bold></highlight>, and EL encoder <highlight><bold>73</bold></highlight>. These features are identical to those described above with respect to the first embodiment. Accordingly, detailed descriptions thereof are omitted herein for the sake of brevity. As shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, the third embodiment also includes multicast rate controller <highlight><bold>74</bold></highlight> and calculation block <highlight><bold>75</bold></highlight>. Detailed descriptions of these features of the invention are as follows. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Calculation block <highlight><bold>75</bold></highlight> is similar to calculation block <highlight><bold>48</bold></highlight> described above in that it determines R<highlight><subscript>MIN</subscript></highlight>, R<highlight><subscript>MAX </subscript></highlight>and R<highlight><subscript>BL</subscript></highlight>. In this embodiment, however, R<highlight><subscript>MIN </subscript></highlight>comprises the minimum bandwidth among plural receivers (e.g., PCs) on network <highlight><bold>76</bold></highlight> and R<highlight><subscript>MAX </subscript></highlight>comprises the maximum bandwidth among the plural receivers on network <highlight><bold>76</bold></highlight>. As above, calculation block <highlight><bold>75</bold></highlight> sets R<highlight><subscript>BL </subscript></highlight>to a value between R<highlight><subscript>MIN </subscript></highlight>and R<highlight><subscript>MAX</subscript></highlight>, and usually to R<highlight><subscript>MIN </subscript></highlight>so as to ensure that even the lowest bandwidth receiver will be able to process coded video data output by the present invention. As shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, in this embodiment of the invention, calculation block <highlight><bold>75</bold></highlight> also determines bandwidths R<highlight><subscript>1</subscript></highlight>, R<highlight><subscript>2 </subscript></highlight>. . . R<highlight><subscript>N </subscript></highlight>for corresponding categories of receivers 1, 2 . . . N (not shown) on network <highlight><bold>76</bold></highlight>. This may be done by monitoring the network for traffic to and from these receivers and/or issuing status inquiries to the respective receivers. Thereafter, these values for R<highlight><subscript>1</subscript></highlight>, R<highlight><subscript>2 </subscript></highlight>. . . R<highlight><subscript>N </subscript></highlight>are provided to multicast rate controller <highlight><bold>74</bold></highlight>. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> Multicast rate controller <highlight><bold>74</bold></highlight> uses R<highlight><subscript>1</subscript></highlight>, R<highlight><subscript>2 </subscript></highlight>. . . R<highlight><subscript>N </subscript></highlight>to divide the EL bitstream into sub-streams ranging from 0 bits to RN bits. That is, as shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, multicast rate controller <highlight><bold>74</bold></highlight> divides the EL bitstream into sub-streams having bandwidths of: </paragraph>
<paragraph lvl="0"><in-line-formula>0&rarr;R<highlight><subscript>1 </subscript></highlight></in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>R<highlight><subscript>1</subscript></highlight>&rarr;R<highlight><subscript>2 </subscript></highlight></in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>R<highlight><subscript>N&minus;1</subscript></highlight>&rarr;R<highlight><subscript>N</subscript></highlight>,&emsp;&emsp;(3) </in-line-formula></paragraph>
<paragraph id="P-0069" lvl="7"><number>&lsqb;0069&rsqb;</number> where R<highlight><subscript>N </subscript></highlight>is less than or equal to R<highlight><subscript>MAX</subscript></highlight>-R<highlight><subscript>BL</subscript></highlight>. Each of these sub-streams corresponds to embedded fine-granular coded residual images. Specifically, the 0 to R<highlight><subscript>1 </subscript></highlight>bitstream comprises a coarse image; the R<highlight><subscript>1 </subscript></highlight>to R<highlight><subscript>2 </subscript></highlight>sub-stream comprises an enhancement to the coarse image; and so on. The sub-streams described in expression (3) above are then output to receivers on network <highlight><bold>76</bold></highlight>, together with the BL bitstream. These receivers will then accept the BL bitstream and one, some, all, or none of these sub-streams, depending upon the processing capabilities of the receiver and/or the network. Decoders, such as that shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, at these receivers may then be used to decode the bitstreams. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> Of course, those skilled in the art will realize that it is also possible to combine the second and third embodiments of the invention so as to produce an encoder which multicasts sub-streams for a plurality of simulcast BL bitstreams. In addition, although this embodiment has been described with respect to networked receivers, it is noted that the embodiment can be used with non-networked receivers as well. The invention can also be used to provide coded data to a plurality of variable-bandwidth networks connected, e.g., to a single PC or the like via plural network connections. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> Likewise, although the three embodiments of the invention described herein are preferably implemented as computer code, all or some of the components shown in <cross-reference target="DRAWINGS">FIGS. 6 and 11</cross-reference> can be implemented using discrete hardware elements and/or logic circuits. The same is true for the decoder shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. Thus, for example, calculation blocks <highlight><bold>48</bold></highlight> and <highlight><bold>75</bold></highlight> can comprise a workstation, PC or other operator-driven device for inputting and selecting required control and command parameters. Lastly, while the encoding and decoding techniques of the present invention have been described in a PC environment, these techniques can be used in any type of video devices including, but not limited to, digital televisions/settop boxes, video conferencing equipment, and the like. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> In this regard, the present invention has been described with respect to particular illustrative embodiments. It is to be understood that the invention is not limited to the above-described embodiments and modifications thereto, and that various changes and modifications may be made by those of ordinary skill in the art without departing from the spirit and scope of the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of coding video data comprised of one or more frames, the method comprising: 
<claim-text>a first coding step for producing coded video data by coding a portion of the video data using a frame-prediction coding technique; </claim-text>
<claim-text>a generating step for generating residual images based on the video data and the coded video data; </claim-text>
<claim-text>a second coding step for producing coded residual images by coding the residual images using a fine-granular scalability coding technique; and </claim-text>
<claim-text>an outputting step for outputting the coded video data and one or more of the coded residual images to a receiver. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising the steps of: 
<claim-text>determining a bandwidth of the receiver; and </claim-text>
<claim-text>selecting which of the coded residual images to output in the outputting step based on the bandwidth of the receiver. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the coded residual images comprise, for each frame of the coded video data, a plurality of different fine-granular scalable images each coded at a different bit rate; and 
<claim-text>wherein the selecting step selects, for each frame of the coded video data, a coded residual image having a highest bit rate that can be accommodated by the bandwidth of the receiver. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, Wherein the selecting step is performed in real-time by a real-time scalable video rate controller. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the first coding step codes the portion of the video data using one of MPEG-1, MPEG-2 and MPEG-4. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the generating step comprises the steps of: 
<claim-text>decoding the coded video data to produce decoded video data; and </claim-text>
<claim-text>determining the residual images by determining a difference between pixels in the video data and pixels in the decoded video data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the generating step comprises the steps of: 
<claim-text>decoding the coded video data to produce decoded video data; </claim-text>
<claim-text>filtering the decoded video data to produce filtered video data; and </claim-text>
<claim-text>determining the residual images by determining a difference between pixels in the video data and pixels in the filtered video data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein the filtering step is performed using a deblocking filter. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the generating step comprises the steps of: 
<claim-text>filtering the video data to produce first filtered video data; </claim-text>
<claim-text>decoding the coded video data to produce decoded video data; </claim-text>
<claim-text>filtering the decoded video data to produce second filtered video data; and </claim-text>
<claim-text>determining the residual images by determining a difference between pixels in the first filtered video data and pixels in the second filtered video data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the fine-granular coding technique comprises a member of the wavelet transform family of coding techniques. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the fine-granular coding technique comprises an embedded discrete cosine transform (&ldquo;DCT&rdquo;) coding technique. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the fine-granular coding technique comprises a scalable matching pursuit (&ldquo;MP&rdquo;) coding technique. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the receiver comprises a variable-bandwidth network. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the first coding step comprises coding the portion of the video data at a plurality of different bit rates so as to produce multiple versions of the coded video data; 
<claim-text>wherein the generating step comprises generating a plurality of residual images for each version of the coded video data; </claim-text>
<claim-text>wherein the second coding step comprises coding the plurality of residual images for each version of the coded video data using a fine-granular scalability coding technique; and </claim-text>
<claim-text>wherein the outputting step comprises outputting one version of the coded video data together with at least one corresponding coded residual image therefor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein the outputting step comprises the steps of: 
<claim-text>determining variations in a bandwidth of the receiver over time; and </claim-text>
<claim-text>selecting which one of the multiple versions of the coded video data and which of the coded residual images to output over time based on the variations in the bandwidth of the receiver. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, wherein, for a receiver bandwidth increasing from B<highlight><subscript>1 </subscript></highlight>to B<highlight><subscript>2</subscript></highlight>, where B<highlight><subscript>1</subscript></highlight>&lt;B<highlight><subscript>2</subscript></highlight>, the selecting step selects a first version of the coded video data and successively selects coded residual images corresponding to each frame of the first version of the coded video data, which are coded at successively higher bit rates; and 
<claim-text>wherein for a receiver bandwidth increasing from B<highlight><subscript>2 </subscript></highlight>to B<highlight><subscript>3</subscript></highlight>, where B<highlight><subscript>2</subscript></highlight>&lt;B<highlight><subscript>3</subscript></highlight>, the selecting step selects a second version of the coded video data and successively selects coded residual images corresponding to each frame of the second version of the coded video data, which are coded at successively higher bit rates. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, wherein, for a receiver bandwidth decreasing from B<highlight><subscript>3 </subscript></highlight>to B<highlight><subscript>2</subscript></highlight>, where B<highlight><subscript>3</subscript></highlight>&gt;B<highlight><subscript>2</subscript></highlight>, the selecting step selects a first version of the coded video data and successively selects coded residual images corresponding to each frame of the first version of the coded video data, which are coded at successively lower bit rates; and 
<claim-text>wherein, for a receiver bandwidth decreasing from B<highlight><subscript>2 </subscript></highlight>to B<highlight><subscript>1</subscript></highlight>, where B<highlight><subscript>2</subscript></highlight>&gt;B<highlight><subscript>1</subscript></highlight>, the selecting step selects a second version of the coded video data and successively selects coded residual images corresponding to each frame of the second version of the coded video data, which are coded at successively lower bit rates. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. An apparatus for coding video data comprised of one or more frames, the apparatus comprising: 
<claim-text>a memory which stores computer-executable process steps; and </claim-text>
<claim-text>a processor which executes the process steps stored in the memory so as (i) to produce coded video data by coding a portion of the video data using a frame-prediction coding technique, (ii) to generate residual images based on the video data and the coded video data, (iii) to produce coded residual images by coding the residual images using a fine-granular scalability coding technique, and (iv) to output the coded video data and at least one of the coded residual images to a receiver. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. An apparatus to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the processor executes process steps stored in the memory so as (i) to determine a bandwidth of the receiver, and (ii) to select which of the coded residual images to output in the outputting step based on the bandwidth of the receiver. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 19</dependent-claim-reference>, wherein the coded residual images comprise, for each frame of the coded video data, a plurality of different fine-granular scalable images each coded at a different bit rate; and 
<claim-text>wherein the processor selects, for each frame of the coded video data, a coded residual image having a highest bit rate that can be accommodated by the bandwidth of the receiver. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the processor executes a real-time scalable video rate controller to perform the outputting. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the processor codes the portion of the video data using one of MPEG-1, MPEG-2 and MPEG-4. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the processor generates the residual images by (i) decoding the coded video data to produce decoded video data, and (ii) determining the residual images by determining a difference between pixels in the video data and pixels in the decoded video data. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the processor generates the residual images by (i) decoding the coded video data to produce decoded video data, (ii) filtering the decoded video data to produce filtered video data, and (iii) determining the residual images by determining a difference between pixels in the filtered video data and pixels in the video data. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00022">claim 24</dependent-claim-reference>, wherein the processor filters the decoded video data using a deblocking filter. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the processor generates the residual images by (i) filtering the video data to produce first filtered video data, (ii) decoding the coded video data to produce decoded video data, (iii) filtering the decoded video data to produce second filtered video data, and (iv) determining the residual images by determining a difference between pixels in the first filtered video data and pixels in the second filtered video data. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the fine-granular coding technique comprises a member of the wavelet transform family of coding techniques. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the fine-granular coding technique comprises an embedded discrete cosine transform (&ldquo;DCT&rdquo;) coding technique. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the fine-granular coding technique comprises a scalable matching pursuit (&ldquo;MP&rdquo;) coding technique. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the receiver comprises a variable-bandwidth network. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the processor (i) codes the portion of the video data at a plurality of different bit rates so as to produce multiple versions of the coded video data, (ii) generates a plurality of residual images for each version of the coded video data, (iii) codes the plurality of residual images for each version of the coded video data using a fine-granular scalability coding technique, and (iv) outputs one version of the coded video data together with at least one corresponding coded residual image therefor. </claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 31</dependent-claim-reference>, wherein the processor outputs the one version of the coded video data together with at least one corresponding coded residual image therefor by (i) determining variations in a bandwidth of the receiver over time, and (ii) selecting which one of the multiple versions of the coded video data and which of the coded residual images to output over time based on the variations in the bandwidth of the receiver. </claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, wherein, for a receiver bandwidth increasing from B<highlight><subscript>1 </subscript></highlight>to B<highlight><subscript>2</subscript></highlight>, where B<highlight><subscript>1</subscript></highlight>&lt;B<highlight><subscript>2</subscript></highlight>, the processor selects a first version of the coded video data and successively selects coded residual images corresponding to each frame of the first version of the coded video data, which are coded at successively higher bit rates; and 
<claim-text>wherein, for a receiver bandwidth increasing from B<highlight><subscript>2 </subscript></highlight>to B<highlight><subscript>3</subscript></highlight>, where B<highlight><subscript>2</subscript></highlight>&lt;B<highlight><subscript>3</subscript></highlight>, the processor selects a second version of the coded video data and successively selects coded residual images corresponding to each frame of the second version of the coded video data, which are coded at successively higher bit rates. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, wherein, for a receiver bandwidth decreasing from B<highlight><subscript>3 </subscript></highlight>to B<highlight><subscript>2</subscript></highlight>, where B<highlight><subscript>3</subscript></highlight>&gt;B<highlight><subscript>2</subscript></highlight>, the processor selects a first version of the coded video data and successively selects coded residual images corresponding to each frame of the first version of the coded video data, which are coded at successively lower bit rates; and 
<claim-text>wherein for a receiver bandwidth decreasing from B<highlight><subscript>2 </subscript></highlight>to B<highlight><subscript>1</subscript></highlight>, where B<highlight><subscript>2</subscript></highlight>&gt;B<highlight><subscript>1</subscript></highlight>, the processor selects a second version of the coded video data and successively selects coded residual images corresponding to each frame of the second version of the coded video data, which are coded at successively lower bit rates. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. Computer-executable process steps to code video data comprised of one or more frames, the computer-executable process steps being stored on a computer-readable medium and comprising: 
<claim-text>a coding step to produce coded video data by coding a portion of the video data using a frame-prediction coding technique; </claim-text>
<claim-text>a generating step to generate residual images based on the video data and the coded video data; </claim-text>
<claim-text>a coding step to produce coded residual images by coding the residual images using a fine-granular scalability coding technique; and </claim-text>
<claim-text>an outputting step to output the coded video data and at least one of the coded residual images to a receiver. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. An apparatus for coding video data comprised of one or more frames, the apparatus comprising: 
<claim-text>a first coding means for producing coded video data by coding a portion of the video data using a frame-prediction coding technique; </claim-text>
<claim-text>a generating means for generating residual images based on the video data and the coded video data; </claim-text>
<claim-text>a second coding means for producing coded residual images by coding the residual images using a fine-granular scalability coding technique; and </claim-text>
<claim-text>an outputting means for outputting the coded video data and at least one of the coded residual images to a receiver. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. A network system comprising: 
<claim-text>an encoder which receives input video data and which outputs frames of coded video data therefrom; </claim-text>
<claim-text>a variable-bandwidth network over which the frames of coded video data are transmitted; </claim-text>
<claim-text>a decoder which receives the frames of coded video data from the variable-bandwidth network and which decodes the coded video data; and </claim-text>
<claim-text>a display which displays video data that has been decoded by the decoder; </claim-text>
<claim-text>wherein the encoder comprises: 
<claim-text>a memory which stores computer-executable process steps; and </claim-text>
<claim-text>a processor which executes the process steps stored in the memory so as to produce the frames of coded video data by (i) coding a base layer from the input video data using a frame-prediction coding technique, (ii) coding an enhancement layer from the input video data using a fine-granular scalability coding technique, (iii) determining a bandwidth of the variable-bandwidth network, and (iv) selecting, for output, the base layer and, in a case that the bandwidth of the variable-bandwidth network is greater than a predetermined value, a portion of the enhancement layer. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. A network system according to <dependent-claim-reference depends_on="CLM-00033">claim 37</dependent-claim-reference>, wherein the predetermined value comprises a bandwidth that can accommodate the base layer. </claim-text>
</claim>
<claim id="CLM-00039">
<claim-text><highlight><bold>39</bold></highlight>. A method of decoding coded video data comprised of an enhancement layer bitstream and a base layer bitstream, where the base layer bitstream is coded using a frame-prediction coding technique and the enhancement layer bitstream is encoded using a fine-granular scalability coding technique, the method comprising the steps of: 
<claim-text>receiving the coded video data; </claim-text>
<claim-text>decoding the base layer bitstream using a frame-prediction decoder; </claim-text>
<claim-text>decoding the enhancement layer bitstream using a fine-granular scalability decoder; and </claim-text>
<claim-text>combining decoded video data from the base layer bitstream and from the enhancement layer bitstream to form a video image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00040">
<claim-text><highlight><bold>40</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00044">claim 43</dependent-claim-reference>, wherein the frame-prediction decoder comprises one of an MPEG-1 decoder, an MPEG-2 decoder, and an MPEG-4 decoder </claim-text>
</claim>
<claim id="CLM-00041">
<claim-text><highlight><bold>41</bold></highlight>. An apparatus for decoding coded video data comprised of an enhancement layer bitstream and a base layer bitstream, where the base layer bitstream is coded using a frame-prediction coding technique and the enhancement layer bitstream is encoded using a fine-granular scalability coding technique, the apparatus comprising: 
<claim-text>a memory which stores computer-executable process steps; and </claim-text>
<claim-text>a processor which executes the process steps stored in the memory so as (i) to receive the coded video data, (ii) to decode the base layer bitstream using a frame-prediction decoder, (iii) to decode the enhancement layer bitstream using a fine-granular scalability decoder, and (iv) to combine decoded video data from the base layer bitstream and from the enhancement layer bitstream to form a video image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00042">
<claim-text><highlight><bold>42</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00044">claim 41</dependent-claim-reference>, wherein the frame-prediction decoder comprises one of an MPEG-1 decoder, an MPEG-2 decoder, and an MPEG-4 decoder </claim-text>
</claim>
<claim id="CLM-00043">
<claim-text><highlight><bold>43</bold></highlight>. Computer-executable process steps stored on a computer-readable medium, the computer-executable process steps to decode coded video data comprised of an enhancement layer bitstream and a base layer bitstream, where the base layer bitstream is coded using a frame-prediction coding technique and the enhancement layer bitstream is encoded using a fine-granular scalability coding technique, the computer-executable process steps comprising: 
<claim-text>a receiving step to receive the coded video data; </claim-text>
<claim-text>a decoding step to decode the base layer bitstream using a frame-prediction decoder; </claim-text>
<claim-text>a decoding step to decode the enhancement layer bitstream using a fine-granular scalability decoder; and </claim-text>
<claim-text>a combining step to combine decoded video data from the base layer bitstream and from the enhancement layer bitstream to form a video image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00044">
<claim-text><highlight><bold>44</bold></highlight>. A method for coding video data and for outputting coded video data to a plurality of receivers, the method comprising the steps of: 
<claim-text>coding a first portion of the video data using a frame-prediction coding technique to produce a first bitstream; </claim-text>
<claim-text>coding a second portion of the video data using a fine-granular scalability coding technique to produce a second bitstream; </claim-text>
<claim-text>outputting the first bitstream to the plurality of receivers; </claim-text>
<claim-text>dividing the second bitstream into two or more sub-streams; and </claim-text>
<claim-text>outputting the two or more sub-streams to the plurality of receivers. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00045">
<claim-text><highlight><bold>45</bold></highlight>. A method according to <dependent-claim-reference depends_on="CLM-00044">claim 44</dependent-claim-reference>, further comprising the step of determining a maximum bit-rate among the plurality of receivers (R<highlight><subscript>MAX</subscript></highlight>); 
<claim-text>wherein the first portion of the video data is coded at a first bit-rate (R<highlight><subscript>BL</subscript></highlight>), and the dividing step divides the second bitstream into sub-streams ranging from 0 bits to R<highlight><subscript>MAX</subscript></highlight>-R<highlight><subscript>BL </subscript></highlight>bits. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00046">
<claim-text><highlight><bold>46</bold></highlight>. An apparatus for coding video data and for outputting coded video data to a plurality of receivers, the apparatus comprising: 
<claim-text>a memory which stores process steps; and </claim-text>
<claim-text>a processor which executes the process steps stored in the memory so as (i) to code a first portion of the video data using a frame-prediction coding technique to produce a first bitstream, (ii) to code a second portion of the video data using a fine-granular scalability coding technique to produce a second bitstream, (iii) to output the first bitstream to the plurality of receivers, (iv) to divide the second. bitstream into two or more sub-streams, and (v) to output the two or more sub-streams to the plurality of receivers. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00047">
<claim-text><highlight><bold>47</bold></highlight>. An apparatus according to <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, wherein the processor determines a maximum bit-rate among the plurality of receivers (R<highlight><subscript>MAX</subscript></highlight>); and 
<claim-text>wherein the first portion of the video data is coded at a first bit-rate (R<highlight><subscript>BL</subscript></highlight>), and the processor divides the second bitstream into sub-streams ranging from 0 bits to R<highlight><subscript>MAX</subscript></highlight>-R<highlight><subscript>BL </subscript></highlight>bits. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00048">
<claim-text><highlight><bold>48</bold></highlight>. Computer-executable process steps stored on a computer-readable medium, the computer-executable process steps to code video data and to output coded video data to a plurality of receivers, the computer-executable process steps comprising: 
<claim-text>a coding step to code a first portion of the video data using a frame-prediction coding technique to produce a first bitstream; </claim-text>
<claim-text>a coding step to code a second portion of the video data using a fine-granular scalability coding technique to produce a second bitstream; </claim-text>
<claim-text>an outputting step to output the first bitstream to the plurality of receivers; </claim-text>
<claim-text>a dividing step to divide the second bitstream into two or more sub-streams; and </claim-text>
<claim-text>an outputting step to output the two or more sub-streams to the plurality of receivers.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>6</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002579A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002579A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002579A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002579A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002579A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002579A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002579A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002579A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002579A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
