<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002726A1-20030102-M00001.NB SYSTEM "US20030002726A1-20030102-M00001.NB" NDATA NB>
<!ENTITY US20030002726A1-20030102-M00001.TIF SYSTEM "US20030002726A1-20030102-M00001.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00001.TIF SYSTEM "US20030002726A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00002.TIF SYSTEM "US20030002726A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00003.TIF SYSTEM "US20030002726A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00004.TIF SYSTEM "US20030002726A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00005.TIF SYSTEM "US20030002726A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00006.TIF SYSTEM "US20030002726A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00007.TIF SYSTEM "US20030002726A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00008.TIF SYSTEM "US20030002726A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00009.TIF SYSTEM "US20030002726A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00010.TIF SYSTEM "US20030002726A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00011.TIF SYSTEM "US20030002726A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00012.TIF SYSTEM "US20030002726A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00013.TIF SYSTEM "US20030002726A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00014.TIF SYSTEM "US20030002726A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00015.TIF SYSTEM "US20030002726A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030002726A1-20030102-D00016.TIF SYSTEM "US20030002726A1-20030102-D00016.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002726</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10206575</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020729</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2000-99673</doc-number>
</priority-application-number>
<filing-date>20000331</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>2001-69620</doc-number>
</priority-application-number>
<filing-date>20010313</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06K009/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>382</class>
<subclass>132000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Image processing apparatus and image processing program</title-of-invention>
</technical-information>
<continuity-data>
<continuations>
<continuation-of>
<parent-child>
<child>
<document-id>
<doc-number>10206575</doc-number>
<kind-code>A1</kind-code>
<document-date>20020729</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>PCT/JP01/02691</doc-number>
<document-date>20010329</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>UNKNOWN</parent-status>
</parent-child>
</continuation-of>
</continuations>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Akio</given-name>
<family-name>Ozawa</family-name>
</name>
<residence>
<residence-non-us>
<city>Kawasaki</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Kohei</given-name>
<family-name>Murao</family-name>
</name>
<residence>
<residence-non-us>
<city>Kawasaki</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>Fujitsu Limited</organization-name>
<address>
<city>Kawasaki</city>
<country>
<country-code>JP</country-code>
</country>
</address>
<assignee-type>03</assignee-type>
</assignee>
<correspondence-address>
<name-1>STAAS &amp; HALSEY LLP</name-1>
<name-2></name-2>
<address>
<address-1>700 11TH STREET, NW</address-1>
<address-2>SUITE 500</address-2>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20001</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">An original image is subjected to an opening processing and to a closing processing to obtain a blurred image by using an average value between the result of the opening processing and the result of the closing processing as a reference for correcting the brightness. The brightness of the original image is corrected by multiplying a difference between the blurred image and the original image, by a ratio of an upper limit value of brightness to a difference between the upper limit value of brightness and the blurred image. Then, the brightness of the original image is corrected based on the blurred image which enhances the contrast of a highly bright portion of a predetermined area or more while lowering the brightness of that portion. Contrast and brightness of the whole image can be adapted to the sensitivity of human eyes. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application is a continuation of PCT/JP01/02691, filed on Mar. 29, 2001.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">TECHNICAL FIELD </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to technology for adapting the contrast and brightness of the whole image to the sensitivity of human eyes. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND ART </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The X-ray image (CR image) for medical treatment is usually so shot that the portions where a transmission amount of X-ray is large appear dark, and is read by medical doctors. In the thus shot X-ray image, however, highly bright portions appear to be dazzling. Therefore, doctors who have to read many X-ray images a day often cover the highly bright portions with a paper for the purpose of lowering fatigue in the eyes. However, the highly bright portions have low detection sensitivity of the X-rays from the first. Besides, human eyes have low sensitivity to the highly bright portions. Therefore, it is difficult for doctors to read the highly bright portions. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> In recent years, digitization of images for medical use has been developed, and the following image processing has been performed to solve the above-mentioned problem. That is, to read dark portions in detail, the image is so processed as to widen a range of low brightness by sacrificing the highly bright portions. To read bright portions in detail, on the other hand, the image is so processed as to widen a range of high brightness to cover even low brightness by sacrificing the lowly bright portions. With this image processing, however, either the dark portions or the bright portions become clear, but it is impossible to simultaneously read the dark portions and the bright portions, leading a possibility of overlooking the lesion sites. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In order to make the whole image more easy to read, therefore, there have been proposed methods called dynamic range filter for suppressing the highly bright portions and unsharp masking for enhancing the contrast (see Lecture 14 on the Science of Medical Radiogenics, &ldquo;Medical Image Engineering&rdquo;). </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The dynamic range filter is not capable of enhancing the contrast of fine texture in the highly bright portions. Therefore, the contrast becomes weak in the bright portions, and the image as a whole becomes to appear flat. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> The unsharp masking, on the other hand, creates an averaged blurred image or creates a blurred image utilizing the frequency conversion, and enhances a difference between the original image and the blurred image to improve the contrast. The highly bright portions, however, are still dazzling. In the portions where the contrast is high from the first, there occurs Gibbs&apos; phenomenon as shown in <cross-reference target="DRAWINGS">FIG. 18</cross-reference>, leading a possibility of misdiagnosis. In the case of a CR image of the chest shot in a health examination, the contrast is very strong along the circumference of the lung. If the unsharp masking is effected, therefore, a shadow-like portion appears along the edge of the lung, leading a possibility to misdiagnose as pneumothorax. By effecting the unsharp masking, further, an upper limit value of brightness is often exceeded in the highly bright portions. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> In view of the above-mentioned problems, therefore, it is an object of the present invention to provide an image processing apparatus and an image processing program capable of adapting the contrast and brightness of the whole image to the sensitivity of human eyes, while preventing Gibbs&apos; phenomenon in the high contrast portions. </paragraph>
</section>
<section>
<heading lvl="1">DISCLOSURE OF THE INVENTION </heading>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> In order to achieve the above-mentioned object, an image processing apparatus according to the present invention comprises a blurred image creating device for creating a blurred image by subjecting an original image to an erosion processing and to a dilation processing, and a brightness correction device for correcting the brightness of the original image based on the blurred image created by the blurred image creating device. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> According to this constitution, the blurred image is created by subjecting the original image to the erosion processing and to the dilation processing. In the thus created blurred image, a variation of the brightness in a region narrower than a predetermined area is neglected, while a change in the variation of the brightness in a region of the predetermined area or more is correctly reflected. Then, the brightness of the original image is corrected based on the blurred image. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> In the original image, therefore, the brightness in the highly bright portion of the predetermined area or more is lowered, while the contrast becomes high in this portion. Thus, it is possible to adapt the contrast and brightness of the whole image to the sensitivity of human eyes while preventing the occurrence of Gibbs&apos; phenomenon on the portions where the contrast is high. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> The blurred image creating device may be constructed to comprise an opening processing device for realizing an opening processing by subjecting the original image to the erosion processing and to the dilation processing successively; a closing processing device for realizing a closing processing by subjecting the original image to the dilation processing and to the erosion processing successively; and a brightness average value computing device for computing an average value between brightness of the original image subjected to the opening processing by the opening processing device and brightness of the original image subjected to the closing processing by the closing processing device, to use the computed result as the blurred image. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> According to this constitution, the opening processing is realized by subjecting the original image to the erosion processing and to the dilation processing successively, and the closing processing is realized by subjecting the original image to the dilation processing and to the erosion processing successively. Then, the average value between brightness of the original image subjected to the opening processing and brightness of the original image subjected to the closing processing, is computed, and the computed result is used as the blurred image. Therefore, it is possible to easily create the blurred image as a brightness correction reference for enhancing the contrast of the highly bright portion the predetermined area or more, while lowering the brightness of that portion. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Further, the brightness correction device may correct the brightness of the original image by multiplying a difference between the blurred image created by the blurred image creating device and the original image, by a ratio of an upper limit value of brightness to a difference between the upper limit value of brightness and the blurred image. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> According to this constitution, the brightness of the original image is corrected by multiplying the difference between the blurred image and the original image by the ratio of the upper limit value of brightness to the difference between the upper limit value of brightness and the burred image. It is therefore possible to simultaneously realize the lowering of brightness and the enhancement of contrast of highly bright portions the predetermined area or more through one time of processing. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> There may be further provided a brightness specifying device for specifying a minimum brightness with which the brightness is corrected, and the brightness correction device corrects the brightness of the original image for only pixels having brightness equal to or greater than the minimum brightness specified by the brightness specifying device. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> According to this constitution, the brightness of the original image is corrected for only pixels having brightness equal to or greater than the minimum brightness specified by the brightness specifying device. By setting the minimum brightness depending on the state of the original image, therefore, it is possible to prevent the lowering of the brightness of the lowly bright portions. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> There may be further provided a region specifying device for specifying a region of which brightness is to be corrected, and the brightness correction device corrects the brightness of the original image for only pixels included in the region specified by the region specifying device. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> According to this constitution, the brightness of the original image is corrected for only pixels included in the region specified by the region specifying device. Therefore, it becomes possible to perform the image processing for only regions to where the users pay attention, thereby enabling to improve performance of the image processing apparatus without performing unnecessary image processing. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> An image processing program according to the present invention, on the other hand, is characterized to realize on a computer a blurred image creating function for creating a blurred image by subjecting an original image to an erosion processing and to a dilation processing, and a brightness correction function for correcting the brightness of the original image based on the blurred image created by the blurred image creating function. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> According to this constitution, in addition to the function and effect of the image processing apparatus of the present invention, the image processing apparatus of the present invention can be easily constructed by downloading the program through an electric communication line, provided that the image processing program to realize the blurred image creating function and the brightness correction function on the computer has been registered on a server connected to Internet.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF DRAWINGS </heading>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a diagram illustrating the constitution of an image processing apparatus according to the present invention; </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flowchart illustrating the content of image processing in the image processing apparatus according to the present invention; </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a flow diagram illustrating a processing for creating a blurred image; </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a diagram illustrating an erosion processing, wherein <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> is a diagram of a structural element and <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> is a diagram explaining a processing by using the structural element of <cross-reference target="DRAWINGS">FIG. 4A</cross-reference>; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a diagram explaining a program for realizing the erosion processing; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a diagram illustrating a specific example of the erosion processing, wherein <cross-reference target="DRAWINGS">FIG. 6A</cross-reference> is a diagram of a structural element, <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is a diagram of an original image, <cross-reference target="DRAWINGS">FIG. 6C</cross-reference> is a diagram illustrating the order of processing, and <cross-reference target="DRAWINGS">FIG. 6D</cross-reference> is a diagram explaining the processed result; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a diagram explaining a dilation processing; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a diagram explaining a program for realizing the dilation processing for the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference>; </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a diagram explaining the result of the dilation processing; </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a diagram explaining the result of an opening processing; </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> is a diagram explaining the result of a closing processing; </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is a diagram illustrating the result of the opening processing for the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference>; </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is a diagram explaining the result of the closing processing for the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference>; </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a diagram illustrating a principle for creating the blurred image, wherein <cross-reference target="DRAWINGS">FIG. 14A</cross-reference> is a diagram illustrating the result of the closing processing, <cross-reference target="DRAWINGS">FIG. 14B</cross-reference> is a diagram illustrating the result of the opening processing, and <cross-reference target="DRAWINGS">FIG. 14C</cross-reference> is a diagram explaining a blurred image created; </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is a diagram of a blurred image created from the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference>; </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is a diagram illustrating a brightness correction based on the blurred image, wherein <cross-reference target="DRAWINGS">FIG. 16A</cross-reference> is a diagram of a threshold value for the original image and the blurred image, <cross-reference target="DRAWINGS">FIG. 16B</cross-reference> is a diagram illustrating the correction of the blurred image by using the threshold value; and <cross-reference target="DRAWINGS">FIG. 16C</cross-reference> is a diagram explaining the correction result of brightness; </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a diagram explaining the result of correcting the brightness of the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference>; and </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a diagram explaining a problem of an unsharp masking.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">BEST MODE FOR CARRYING OUT THE INVENTION </heading>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The present invention will now be described below in detail with reference to the accompanying drawings. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, an image processing apparatus according to the present invention (hereinafter simply referred to as &ldquo;image processing apparatus&rdquo;) is constructed on a computer system which includes a central processing unit (CPU) <highlight><bold>10</bold></highlight>, a memory <highlight><bold>12</bold></highlight> which is a main storage unit, an inpuvoutput channel <highlight><bold>14</bold></highlight>, a display unit <highlight><bold>16</bold></highlight> and a mouse <highlight><bold>18</bold></highlight>. In the image processing apparatus, an image processing that will be described later is performed in accordance with a program loaded in the memory <highlight><bold>12</bold></highlight>. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The program loaded in the memory <highlight><bold>12</bold></highlight> realizes a blurred image creating device, a brightness correction device, a opening processing device, a closing processing device, a brightness average value computing device, a brightness specifying device, a region specifying device, a blurred image creating function and a brightness correction function. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flowchart illustrating the outline of the content of the image processing. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> At step <highlight><bold>1</bold></highlight> (abbreviated as &ldquo;S<highlight><bold>1</bold></highlight>&rdquo; in the figure, the same rule is applied hereinafter), a processing region is specified for the image processing. The processing region includes a highly bright region, an arbitrary region, a specific site region, etc. The highly bright region is the one where the image is processed for only pixels having brightness equal to or higher than predetermined brightness (minimum brightness), and is specified via a threshold value that specifies the predetermined brightness. The arbitrary region is the one where the image is processed for only pixels included in a specified region, and is specified through the mouse <highlight><bold>18</bold></highlight>. The specific site region is the one where the image is processed for only a specified site of the image, such as lung in a CR image of chest, and is specified in cooperation with a site recognizing function. The processing region may be specified by combining at least two of the highly bright region, arbitrary region and specific site region. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> Here, a device for specifying the threshold value related to the highly bright region corresponds to the brightness specifying device, and a device for specifying the region related to the arbitrary region corresponds to the region specifying device. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> At step <highlight><bold>2</bold></highlight>, there is created a blurred image that serves as a reference for correcting the brightness of an original image. The blurred image is created by a method called morphology for analyzing a structure of image in compliance with a flow diagram shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. Creation of the blurred image will now be described in detail as follows. A processing at step <highlight><bold>2</bold></highlight> corresponds to the blurred image creating device and to the blurred image creating function. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> First, the original image is subjected to an opening processing and to a closing processing. The opening processing is the one for smoothing small protuberances of the image, and the closing processing is the one for smoothing small dents of the image. The opening processing and the closing processing are realized by a combination of an erosion processing and a dilation processing. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> The erosion processing and the dilation processing are the ones for removing dents and protuberances smaller than a structural element from the image. Here, the structural element is the one used for the computation of the image, and is, for example, a region surrounded by a circle of a diameter which is {fraction (1/40)} the number of pixels along one side of the image. When the scale among the pixels is obvious, the diameter of the structural element can be defined to be 9 cm. That is, in the morphology, the structural element constituted by an arbitrary region can be specified. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> In the erosion processing as shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, protuberances smaller than the structural element are removed from the image. That is, by using the structural element shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>A, when the origin is moved in parallel along the original image in a state where the structural element is turned upside down as shown in <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> of, a minimum value of brightness in the width W of the original image becomes an output image. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> If an input image is f({overscore (x)}), the structural element is g({overscore (x)}) and a value that can be assumed by the structural element g({overscore (x)}) is {overscore (z)}, then, the erosion processing is realized by the program shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. That is, after the output image out({overscore (x)}) is initialized, a minimum value of the input image f({overscore (x)}) becomes an output image out({overscore (x)}) in the region of the structural element g({overscore (x)}). In <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, MINVALUE and MAXVALUE represent a minimum value of brightness and a maximum value thereof (upper limit value of brightness). The erosion processing (f&ominus;g)({overscore (x)}) is defined as follows. </paragraph>
<paragraph lvl="0"><in-line-formula>(<highlight><italic>f&ominus;g</italic></highlight>)(<highlight><italic>{overscore (x)}</italic></highlight>)&equals;min (<highlight><italic>f</italic></highlight>(<highlight><italic>{overscore (x)}&plus;{overscore (z)}</italic></highlight>)&minus;<highlight><italic>g</italic></highlight>(<highlight><italic>{overscore (z)}</italic></highlight>)) </in-line-formula></paragraph>
<paragraph id="P-0051" lvl="2"><number>&lsqb;0051&rsqb;</number> {overscore (z)}&egr;G </paragraph>
<paragraph id="P-0052" lvl="2"><number>&lsqb;0052&rsqb;</number> {overscore (x)}&plus;{overscore (z)}&egr;F </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> where F is a region where the input image f({overscore (x)})is defined and G is a region where the structural element g({overscore (x)}) is defined (the same rule is applied hereinafter). </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> Next, described below is what it will be if the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is subjected to the erosion processing by using a structural element of a crossing shape shown in <cross-reference target="DRAWINGS">FIG. 6A</cross-reference>. In the structural element of <cross-reference target="DRAWINGS">FIG. 6</cross-reference>A, &ldquo;&lt; &gt;&rdquo; represents origin and &ldquo;*&rdquo; represents outside the region. Further, numerals in the regions of the structural element represent values that can be assumed by the structural element. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> When the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is to be subjected to the erosion processing, the processing is executed for the pixels from the left upper part of the original image toward the right lower part thereof as shown in <cross-reference target="DRAWINGS">FIG. 6C</cross-reference>. If the definition formula in the erosion processing is adapted when the structural element is located on the left upper part in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>C, then, </paragraph>
<paragraph lvl="0"><in-line-formula>min (2&minus;0, 0&minus;0, 2&minus;0, 8&minus;0, 8&minus;0)&equals;0 </in-line-formula></paragraph>
<paragraph id="P-0056" lvl="7"><number>&lsqb;0056&rsqb;</number> and the computed value becomes 0. Further, if the definition formula in the erosion processing is adapted when the structural element is located on the right upper part in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>C, then, </paragraph>
<paragraph lvl="0"><in-line-formula>min (8&minus;0, 6&minus;0, 2&minus;0, 2&minus;0, 6&minus;0)&equals;2 </in-line-formula></paragraph>
<paragraph id="P-0057" lvl="7"><number>&lsqb;0057&rsqb;</number> and the computed value becomes 2. If the erosion processing is executed for the whole pixels, then, the result becomes as shown in <cross-reference target="DRAWINGS">FIG. 6D</cross-reference>. Here, the values of pixels in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> to <cross-reference target="DRAWINGS">FIG. 6D</cross-reference> represent brightness (the same rule is applied hereinafter). </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> In the dilation processing as shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, dents smaller than the structural element are removed from the image. That is, by using the same structural element (refer to <cross-reference target="DRAWINGS">FIG. 4A</cross-reference>) as that of the erosion processing, when the origin of the structural element is moved in parallel along the original image, a maximum value of brightness in the width W of the original image becomes an output image. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> The dilation processing is realized by a program shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. That is, after the output image out({overscore (x)}) is initialized, a maximum value of the input image f({overscore (x)}) becomes an output image out({overscore (x)}) in the region of the structural element g({overscore (x)}). The dilation processing (f&oplus;g)({overscore (x)}) is defined as follows. </paragraph>
<paragraph lvl="0"><in-line-formula>(<highlight><italic>f&oplus;g</italic></highlight>)(<highlight><italic>{overscore (x)}</italic></highlight>)&equals;max (<highlight><italic>f</italic></highlight>(<highlight><italic>{overscore (x)}&minus;{overscore (z)}</italic></highlight>)&plus;<highlight><italic>g</italic></highlight>(<highlight><italic>{overscore (z)}</italic></highlight>)) </in-line-formula></paragraph>
<paragraph id="P-0060" lvl="2"><number>&lsqb;0060&rsqb;</number> {overscore (z)}&egr;G </paragraph>
<paragraph id="P-0061" lvl="2"><number>&lsqb;0061&rsqb;</number> {overscore (x)}&minus;{overscore (z)}&egr;F </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Next, described below is what it will be if the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is subjected to the dilation processing by using the structural element of the crossing shape shown in <cross-reference target="DRAWINGS">FIG. 6A</cross-reference> like in the erosion processing. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> When the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is to be subjected to the erosion processing, the processing is executed for the pixels from the left upper part of the original image toward the right lower part thereof as shown in <cross-reference target="DRAWINGS">FIG. 6C</cross-reference>. If the definition formula in the dilation processing is adapted when the structural element is located on the left upper part in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>C, then, </paragraph>
<paragraph lvl="0"><in-line-formula>max (2&plus;0, 0&plus;0, 2&plus;0, 8&plus;0, 8&plus;0)&equals;8 </in-line-formula></paragraph>
<paragraph id="P-0064" lvl="7"><number>&lsqb;0064&rsqb;</number> and the computed value becomes 8. Further, if the definition formula in the dilation processing is adapted when the structural element is located on the right upper part in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>C, then, </paragraph>
<paragraph lvl="0"><in-line-formula>max (8&plus;0, 6&plus;0, 2&plus;0, 2&plus;0, 6&plus;0)&equals;8 </in-line-formula></paragraph>
<paragraph id="P-0065" lvl="7"><number>&lsqb;0065&rsqb;</number> and the computed value becomes 8. If the dilation processing is executed for the whole pixels, then, the result becomes as shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> The opening processing and the closing processing are realized by a combination of the above-mentioned erosion processing and dilation processing. That is, if the definition formula of the opening processing is (f&compfn;g)({overscore (x)}) and the definition formula of the closing processing is (f&Circlesolid;g)({overscore (x)}), then, </paragraph>
<paragraph lvl="0"><in-line-formula>(<highlight><italic>f&compfn;g</italic></highlight>)(<highlight><italic>{overscore (x)}</italic></highlight>)&equals;(<highlight><italic>f</italic></highlight>&oplus;(<highlight><italic>f&oplus;g</italic></highlight>))(<highlight><italic>{overscore (x)}</italic></highlight>) </in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>(<highlight><italic>f&Circlesolid;g</italic></highlight>)(<highlight><italic>{overscore (x)}</italic></highlight>)&equals;(<highlight><italic>f</italic></highlight>&ominus;(<highlight><italic>f&oplus;g</italic></highlight>))(<highlight><italic>{overscore (x)}</italic></highlight>) </in-line-formula></paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> In effect, the opening processing is realized by subjecting the dilation processing subsequently to the erosion processing, and the closing processing is realized by subjecting the erosion processing subsequently to the dilation processing. By subjecting the opening processing and the closing processing, small dents and protuberances in the original image are smoothed as shown in <cross-reference target="DRAWINGS">FIGS. 10 and 11</cross-reference>. <cross-reference target="DRAWINGS">FIGS. 12 and 13</cross-reference> show the results that the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> is subjected to the opening processing and to the closing processing. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> A series of processing for realizing the opening processing and the closing processing by combining the erosion processing and the dilation processing corresponds to the opening processing device and to the closing processing device. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Thereafter, the result of the opening processing shown in <cross-reference target="DRAWINGS">FIG. 14</cross-reference>A and the result of the closing processing shown in <cross-reference target="DRAWINGS">FIG. 14B</cross-reference> are simply averaged to create a blurred image as shown in <cross-reference target="DRAWINGS">FIG. 14C</cross-reference>. <cross-reference target="DRAWINGS">FIG. 15</cross-reference> illustrates the blurred image created from the original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference>. Here, the processing for creating the blurred image by simply averaging the result of the opening processing and the result of the closing processing, corresponds to the brightness average value computing device. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> At step <highlight><bold>3</bold></highlight>, the brightness is corrected based on the blurred image. The processing at step <highlight><bold>3</bold></highlight> corresponds to the brightness correction device and to the brightness correction function. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> That is, in correcting the brightness for the pixels having brightness equal to or greater than the threshold value, if the input image is f({overscore (x)}), the blurred image is b({overscore (x)}), a load coefficient is k and the threshold value is t, then, the output image out({overscore (x)}) is defined as follows.  
<math-cwu id="MATH-US-00001">
<number>1</number>
<math>
<mrow>
  <mrow>
    <mi>o</mi>
    <mo>&it;</mo>
    <mstyle>
      <mtext>&emsp;</mtext>
    </mstyle>
    <mo>&it;</mo>
    <mi>u</mi>
    <mo>&it;</mo>
    <mstyle>
      <mtext>&emsp;</mtext>
    </mstyle>
    <mo>&it;</mo>
    <mrow>
      <mi>t</mi>
      <mo>&af;</mo>
      <mrow>
        <mo>(</mo>
        <mover>
          <mi>x</mi>
          <mi>_</mi>
        </mover>
        <mo>)</mo>
      </mrow>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mo>{</mo>
    <mtable>
      <mtr>
        <mtd>
          <mrow>
            <mstyle>
              <mtext>&emsp;</mtext>
            </mstyle>
            <mo>&it;</mo>
            <mrow>
              <mi>f</mi>
              <mo>&af;</mo>
              <mrow>
                <mo>(</mo>
                <mover>
                  <mi>x</mi>
                  <mi>_</mi>
                </mover>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mrow>
        </mtd>
        <mtd>
          <mrow>
            <mstyle>
              <mtext>&emsp;</mtext>
            </mstyle>
            <mo>&it;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mrow>
                  <mrow>
                    <mi>when</mi>
                    <mo>&it;</mo>
                    <mstyle>
                      <mtext>&emsp;</mtext>
                    </mstyle>
                    <mo>&it;</mo>
                    <mrow>
                      <mi>k</mi>
                      <mo>&CenterDot;</mo>
                      <mrow>
                        <mi>b</mi>
                        <mo>&af;</mo>
                        <mrow>
                          <mo>(</mo>
                          <mover>
                            <mi>x</mi>
                            <mi>_</mi>
                          </mover>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                    </mrow>
                  </mrow>
                  <mo>-</mo>
                  <mi>t</mi>
                </mrow>
                <mo>&leq;</mo>
                <mn>0</mn>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mrow>
            <mstyle>
              <mtext>&emsp;</mtext>
            </mstyle>
            <mo>&it;</mo>
            <mrow>
              <mi>M</mi>
              <mo>&it;</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mi>I</mi>
              <mo>&it;</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mi>N</mi>
              <mo>&it;</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mi>V</mi>
              <mo>&it;</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mi>A</mi>
              <mo>&it;</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mi>L</mi>
              <mo>&it;</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mi>U</mi>
              <mo>&it;</mo>
              <mstyle>
                <mtext>&emsp;</mtext>
              </mstyle>
              <mo>&it;</mo>
              <mi>E</mi>
            </mrow>
          </mrow>
        </mtd>
        <mtd>
          <mrow>
            <mstyle>
              <mtext>&emsp;</mtext>
            </mstyle>
            <mo>&it;</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mrow>
                  <mrow>
                    <mi>when</mi>
                    <mo>&it;</mo>
                    <mstyle>
                      <mtext>&emsp;</mtext>
                    </mstyle>
                    <mo>&it;</mo>
                    <mrow>
                      <mi>f</mi>
                      <mo>&af;</mo>
                      <mrow>
                        <mo>(</mo>
                        <mover>
                          <mi>x</mi>
                          <mi>_</mi>
                        </mover>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </mrow>
                  <mo>-</mo>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mrow>
                        <mi>k</mi>
                        <mo>&CenterDot;</mo>
                        <mrow>
                          <mi>b</mi>
                          <mo>&af;</mo>
                          <mrow>
                            <mo>(</mo>
                            <mover>
                              <mi>x</mi>
                              <mi>_</mi>
                            </mover>
                            <mo>)</mo>
                          </mrow>
                        </mrow>
                      </mrow>
                      <mo>-</mo>
                      <mi>t</mi>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>&leq;</mo>
                <mn>0</mn>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mrow>
            <mstyle>
              <mtext>&emsp;</mtext>
            </mstyle>
            <mo>&it;</mo>
            <mrow>
              <mrow>
                <mo>{</mo>
                <mrow>
                  <mrow>
                    <mi>f</mi>
                    <mo>&af;</mo>
                    <mrow>
                      <mo>(</mo>
                      <mover>
                        <mi>x</mi>
                        <mi>_</mi>
                      </mover>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>-</mo>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mrow>
                        <mi>k</mi>
                        <mo>&CenterDot;</mo>
                        <mrow>
                          <mi>b</mi>
                          <mo>&af;</mo>
                          <mrow>
                            <mo>(</mo>
                            <mover>
                              <mi>x</mi>
                              <mi>_</mi>
                            </mover>
                            <mo>)</mo>
                          </mrow>
                        </mrow>
                      </mrow>
                      <mo>-</mo>
                      <mi>t</mi>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>}</mo>
              </mrow>
              <mo>&CenterDot;</mo>
              <mfrac>
                <mi>MAXVALUE</mi>
                <mtable>
                  <mtr>
                    <mtd>
                      <mrow>
                        <mi>MAXVALUE</mi>
                        <mo>-</mo>
                      </mrow>
                    </mtd>
                  </mtr>
                  <mtr>
                    <mtd>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mrow>
                            <mi>k</mi>
                            <mo>&CenterDot;</mo>
                            <mrow>
                              <mi>b</mi>
                              <mo>&af;</mo>
                              <mrow>
                                <mo>(</mo>
                                <mover>
                                  <mi>x</mi>
                                  <mi>_</mi>
                                </mover>
                                <mo>)</mo>
                              </mrow>
                            </mrow>
                          </mrow>
                          <mo>-</mo>
                          <mi>t</mi>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mtd>
                  </mtr>
                </mtable>
              </mfrac>
            </mrow>
          </mrow>
        </mtd>
        <mtd>
          <mrow>
            <mstyle>
              <mtext>&emsp;</mtext>
            </mstyle>
            <mo>&it;</mo>
            <mrow>
              <mo>(</mo>
              <mi>others</mi>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mtd>
      </mtr>
    </mtable>
  </mrow>
</mrow>
</math>
<mathematica-file id="MATHEMATICA-00001" file="US20030002726A1-20030102-M00001.NB"/>
<image id="EMI-M00001" wi="216.027" he="69.1173" file="US20030002726A1-20030102-M00001.TIF" imf="TIFF" ti="MF"/>
</math-cwu>
</paragraph>
<paragraph id="P-0072" lvl="7"><number>&lsqb;0072&rsqb;</number> Here, the load coefficient k (0&lE;k&lE;1) provides a function for finely adjusting the brightness; i.e., the brightness in the highly bright portion is lowered and the contrast is enhanced as the load coefficient k approaches 1. Usually, the load coefficient k is set to be approximately 0.8. In the case of the CR image of the chest, for example, the threshold value t is set to be approximately 25% of the whole tones in order to maintain the brightness nearly the same as that of inside the lung. In the image having 1024 tones, the threshold value t is set to be 256. The load coefficient k and the threshold value t can be set by the users. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> Then, as shown in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>A and <cross-reference target="DRAWINGS">FIG. 16</cross-reference>B, the blurred image is lowered by the amount of the threshold value and is expanded until the brightness 0 is reached with the upper limit value of brightness as a base line, thereby to correct the brightness as shown in <cross-reference target="DRAWINGS">FIG. 16C</cross-reference>. That is, the brightness of the original image is corrected by multiplying a difference between the blurred image and the original image, by a ratio of an upper limit value of brightness to a difference between the upper limit value of brightness and the blurred image. The original image shown in <cross-reference target="DRAWINGS">FIG. 6B</cross-reference> becomes finally as shown in <cross-reference target="DRAWINGS">FIG. 17</cross-reference>. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> At step <highlight><bold>4</bold></highlight>, the image of which brightness has been corrected is displayed on the display unit <highlight><bold>16</bold></highlight>. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> According to the above-mentioned processing, as shown in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>C, the brightness of the original image is lowered and the contrast thereof is enhanced in the portions having brightness higher than the threshold value t and having areas wider than the structural element. Therefore, without the lowering of brightness in the lowly bright portions having brightness lower than the threshold value t, the contrast can be enhanced while lowering the brightness in the highly bright portion. Further, the contrast and the brightness of the whole image can be adapted to the sensitivity of human eyes while preventing the occurrence of the Gibbs&apos; phenomenon in the portions where the contrast is strong. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> As a result, it is possible to obtain an image of which quality is so high that the whole image can be read at a glance. In reading the CR image, therefore, it is possible for the doctors to diagnose the lesion sites from the whole image, to improve diagnosis accuracy. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> If the image processing program according to the present invention is registered on a server connected to the Internet, the image processing apparatus according to the present invention can be easily constructed by down-loading the program through an electric communication line. </paragraph>
</section>
<section>
<heading lvl="1">INDUSTRIAL APPLICABILITY </heading>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> As described above, the image processing apparatus and the image processing program according to the present invention make it possible to adapt the contrast and brightness of the whole image to the sensitivity of human eyes while preventing the occurrence of Gibbs&apos; phenomenon in the portions where the contrast is strong. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. An image processing apparatus comprising a blurred image creating device for creating a blurred image by subjecting an original image to an erosion processing and to a dilation processing, and a brightness correction device for correcting the brightness of said original image based on the blurred image created by the blurred image creating device. </claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, 
<claim-text>wherein said blurred image creating device comprises: 
<claim-text>an opening processing device for realizing an opening processing by subjecting said original image to the erosion processing and to the dilation processing successively; a closing processing device for realizing a closing processing by subjecting said original image to the dilation processing and to the erosion processing successively; and a brightness average value computing device for computing an average value between brightness of the original image subjected to the opening processing by said opening processing device and brightness of the original image subjected to the closing processing by said closing processing device, to use the computed result as the blurred image. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, 
<claim-text>wherein said brightness correction device corrects the brightness of said original image by multiplying a difference between the blurred image created by said blurred image creating device and the original image, by a ratio of an upper limit value of brightness to a difference between the upper limit value of brightness and the blurred image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising a brightness specifying device for specifying a minimum brightness with which the brightness is corrected, and said brightness correction device corrects the brightness of said original image for only pixels having brightness equal to or greater than the minimum brightness specified by said brightness specifying device. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. An image processing apparatus according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising a region specifying device for specifying a region of which brightness is to be corrected, and said brightness correction device corrects the brightness of said original image for only pixels included in the region specified by said region specifying device. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. An image processing program for realizing on a computer, a blurred image creating function for creating a blurred image by subjecting an original image to an erosion processing and to a dilation processing, and a brightness correction function for correcting the brightness of said original image based on the blurred image created by said blurred image creating function.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>NONE</representative-figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002726A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002726A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002726A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002726A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002726A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002726A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002726A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002726A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030002726A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030002726A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030002726A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030002726A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030002726A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030002726A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030002726A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030002726A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
