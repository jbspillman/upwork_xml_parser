<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001880A1-20030102-D00000.TIF SYSTEM "US20030001880A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00001.TIF SYSTEM "US20030001880A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00002.TIF SYSTEM "US20030001880A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00003.TIF SYSTEM "US20030001880A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00004.TIF SYSTEM "US20030001880A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00005.TIF SYSTEM "US20030001880A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00006.TIF SYSTEM "US20030001880A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00007.TIF SYSTEM "US20030001880A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00008.TIF SYSTEM "US20030001880A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00009.TIF SYSTEM "US20030001880A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00010.TIF SYSTEM "US20030001880A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00011.TIF SYSTEM "US20030001880A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00012.TIF SYSTEM "US20030001880A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00013.TIF SYSTEM "US20030001880A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00014.TIF SYSTEM "US20030001880A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00015.TIF SYSTEM "US20030001880A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00016.TIF SYSTEM "US20030001880A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00017.TIF SYSTEM "US20030001880A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00018.TIF SYSTEM "US20030001880A1-20030102-D00018.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00019.TIF SYSTEM "US20030001880A1-20030102-D00019.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00020.TIF SYSTEM "US20030001880A1-20030102-D00020.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00021.TIF SYSTEM "US20030001880A1-20030102-D00021.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00022.TIF SYSTEM "US20030001880A1-20030102-D00022.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00023.TIF SYSTEM "US20030001880A1-20030102-D00023.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00024.TIF SYSTEM "US20030001880A1-20030102-D00024.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00025.TIF SYSTEM "US20030001880A1-20030102-D00025.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00026.TIF SYSTEM "US20030001880A1-20030102-D00026.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00027.TIF SYSTEM "US20030001880A1-20030102-D00027.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00028.TIF SYSTEM "US20030001880A1-20030102-D00028.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00029.TIF SYSTEM "US20030001880A1-20030102-D00029.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00030.TIF SYSTEM "US20030001880A1-20030102-D00030.TIF" NDATA TIF>
<!ENTITY US20030001880A1-20030102-D00031.TIF SYSTEM "US20030001880A1-20030102-D00031.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001880</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10208810</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020801</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G09G005/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>345</class>
<subclass>716000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>Method, system, and computer program product for producing and distributing enhanced media</title-of-invention>
</technical-information>
<continuity-data>
<continuations>
<continuation-in-part-of>
<parent-child>
<child>
<document-id>
<doc-number>10208810</doc-number>
<kind-code>A1</kind-code>
<document-date>20020801</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09836239</doc-number>
<document-date>20010418</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>PENDING</parent-status>
</parent-child>
</continuation-in-part-of>
</continuations>
<non-provisional-of-provisional>
<document-id>
<doc-number>60309788</doc-number>
<document-date>20010806</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
<non-provisional-of-provisional>
<document-id>
<doc-number>60386753</doc-number>
<document-date>20020610</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Alex</given-name>
<family-name>Holtz</family-name>
</name>
<residence>
<residence-us>
<city>Jacksonville</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Robert</given-name>
<middle-name>J.</middle-name>
<family-name>Snyder</family-name>
</name>
<residence>
<residence-us>
<city>St. Augustine</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Marcel</given-name>
<family-name>LaRocque</family-name>
</name>
<residence>
<residence-us>
<city>Jacksonville</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>William</given-name>
<middle-name>H.</middle-name>
<family-name>Couch</family-name>
</name>
<residence>
<residence-us>
<city>Fernandina Beach</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Benjamin</given-name>
<family-name>McAllister</family-name>
</name>
<residence>
<residence-us>
<city>Jacksonville</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Charles</given-name>
<middle-name>M.</middle-name>
<family-name>Hoeppner</family-name>
</name>
<residence>
<residence-us>
<city>Jacksonville</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Keith</given-name>
<middle-name>Gregory</middle-name>
<family-name>Tingle</family-name>
</name>
<residence>
<residence-us>
<city>Neptune Beach</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>David</given-name>
<middle-name>A.</middle-name>
<family-name>Armbruster</family-name>
</name>
<residence>
<residence-us>
<city>Jacksonville Beach</city>
<state>FL</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>ParkerVision, Inc.</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>STERNE, KESSLER, GOLDSTEIN &amp; FOX PLLC</name-1>
<name-2></name-2>
<address>
<address-1>1100 NEW YORK AVENUE, N.W., SUITE 600</address-1>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20005-3934</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A method, system, and computer program product are provided to edit and encode enriched multimedia productions for live, delayed, or on-demand web casts or other distribution. The present invention is configured to operate independent of the system platform and media format. Hence, the present invention has the ability to operate with any type of manual or automated video production system. The multimedia production is produced according to an electronic show rundown. The rundown includes instructions for encoding the production for webcasting. In an embodiment, the multimedia is produced and broadcast over conventional channels simultaneously with a live or delayed web cast. The web cast material is edited, fragmented, tagged and/or archived during the simulcast. In another embodiment, the multimedia is produced and archived for on-demand web cast. Auxiliary information is added to enhance the multimedia production. Auxiliary information includes web sites, extended video segments, related media productions, advertisements, and the like. During pre-production, production, or post-production, auxiliary information can be altered or deleted for web casts. The encoding process permits the enriched multimedia to be partitioned, cataloged, and indexed for personalized viewing over the Internet. A user can select one or more events from a menu of categorized media productions, determine an order for viewing, and receive a seamless assembly of productions. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application is a continuation-in-part of U.S. patent application Ser. No. 09/836,239, filed Apr. 18, 2001, by Holtz et al., entitled &ldquo;Method, System and Computer Program Product for Producing and Distributing Enhanced Media Downstreams,&rdquo; incorporated herein by reference in its entirety. </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> This application also claims the benefit of U.S. Patent Application Serial No. 60/309,788, filed Aug. 6, 2001, by Holtz, entitled &ldquo;Webcasting and Business Models,&rdquo; incorporated herein by reference in its entirety, and the benefit of U.S. Patent Application Serial No. 60/386,753, filed Jun. 10, 2002, by Holtz et al., entitled &ldquo;Method, System and Computer Program Product for Producing and Distributing Enhanced Media,&rdquo; incorporated herein by reference in its entirety.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">CROSS-REFERENCE TO RELATED APPLICATIONS </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> The following United States and PCT utility patent applications have a common assignee and contain some common disclosure: </paragraph>
<paragraph id="P-0004" lvl="2"><number>&lsqb;0004&rsqb;</number> &ldquo;Real Time Video Production System and Method,&rdquo; U.S. patent application Ser. No. 09/215,161, by Holtz et al., filed Dec. 18, 1998, incorporated herein by reference; </paragraph>
<paragraph id="P-0005" lvl="2"><number>&lsqb;0005&rsqb;</number> &ldquo;System and Method for Real Time Video Production and Multicasting,&rdquo; U.S. patent application Ser. No. 09/482,683, by Holtz et al., filed Jan. 14, 2000, incorporated herein by reference; </paragraph>
<paragraph id="P-0006" lvl="2"><number>&lsqb;0006&rsqb;</number> &ldquo;System and Method for Real Time Video Production and Multicasting,&rdquo; U.S. patent application Ser. No. 09/488,578, by Snyder et al., filed Jan. 21, 2000, incorporated herein by reference; </paragraph>
<paragraph id="P-0007" lvl="2"><number>&lsqb;0007&rsqb;</number> &ldquo;System and Method for Real Time Video Production and Multicasting,&rdquo; U.S. patent application Ser. No. 09/634,735, by Snyder et al., filed Aug. 8, 2000, incorporated herein by reference; </paragraph>
<paragraph id="P-0008" lvl="2"><number>&lsqb;0008&rsqb;</number> &ldquo;System and Method For Real Time Video Production and Multicasting,&rdquo; PCT Patent Application Serial No. PCT/US01/00547, by Snyder et al., filed Jan. 9, 2001, incorporated herein by reference; </paragraph>
<paragraph id="P-0009" lvl="2"><number>&lsqb;0009&rsqb;</number> &ldquo;Method, System and Computer Program Product for Full News Integration and Automation in a Real Time Video Production Environment,&rdquo; U.S. patent application Ser. No. 09/822,855, by Holtz et al., filed Apr. 2, 2001, incorporated herein by reference; </paragraph>
<paragraph id="P-0010" lvl="2"><number>&lsqb;0010&rsqb;</number> &ldquo;Method, System and Computer Program Product for Full News Integration and Automation in a Real Time Video Production Environment,&rdquo; PCT Patent Application Serial No. PCT/US01/10306, by Holtz et al., filed Apr. 2, 2001, incorporated herein by reference; </paragraph>
<paragraph id="P-0011" lvl="2"><number>&lsqb;0011&rsqb;</number> &ldquo;Interactive Tutorial Method, System and Computer Program Product for Real Time Media Production,&rdquo; U.S. patent application Ser. No. 09/832,923, by Holtz et al., filed Apr. 12, 2001, incorporated herein by reference; </paragraph>
<paragraph id="P-0012" lvl="2"><number>&lsqb;0012&rsqb;</number> &ldquo;Distance Learning Curriculum and System,&rdquo; U.S. Patent Application Serial No. 60/309,880, by Holtz, filed Aug. 6, 2001, incorporated herein by reference; </paragraph>
<paragraph id="P-0013" lvl="2"><number>&lsqb;0013&rsqb;</number> &ldquo;Advertisement Management Method, System, and Computer Program Product,&rdquo; U.S. Patent Application Serial No. 60/323,328, by Holtz, filed Sep. 20, 2001, incorporated herein by reference; and </paragraph>
<paragraph id="P-0014" lvl="2"><number>&lsqb;0014&rsqb;</number> &ldquo;Sales Module to Support System for On-Demand Internet Deliver of News Content,&rdquo; U.S. Patent Application Serial No. 60/363,098, by Holtz, filed Mar. 12, 2002, incorporated herein by reference. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> The present invention relates generally to media production, and more specifically, to distributing live or live-to-tape media productions over a communications network. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> 2. Related Art </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> Conventionally, the production of a live or live-to-tape video show (such as a network news broadcast, talk show, or the like) is largely a manual process involving a team of specialized individuals working together in a video production environment having a studio and a control room. The video production environment is comprised of many diverse types of video production devices, such as video cameras, microphones, video tape recorders (VTRs), video switching devices, audio mixers, digital video effects devices, teleprompters, and video graphic overlay devices, etc. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> In a conventional production environment, the video production devices are manually operated by a production crew (which does not include the performers and actors, also known as the &ldquo;talent&rdquo;) of artistic and technical personnel working together under the direction of a director. A standard production crew is made up of nine or more individuals, including camera operators (usually one for each camera, where there are usually three cameras), a video engineer who controls the camera control units (CCUs) for each camera, a teleprompter operator, a character generator operator, a lighting director who controls the studio lights, a technical director who controls the video switcher, an audio technician who controls an audio mixer, tape operator(s) who control(s) a bank of VTRs, and a floor director inside the studio who gives cues to the talent. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Typically, the director coordinates the entire production crew by issuing verbal instructions to them according to a script referred to as a director&apos;s rundown sheet. Generally, each member of the production crew is equipped with a headset and a microphone to allow constant communication with each other and the director through an intercom system. The video produced by crew is delivered or transmitted to a master control system that, in turn, broadcasts the video over traditional mediums to a television set. Traditional mediums include the appropriate ranges of the frequency spectrum for television, satellite communications, and cable transmissions. The global Internet and other computer networks present a new distribution medium for video productions and like. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> Therefore, what is needed is a media production and distribution system and method that are adapted for traditional and other distribution mediums. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> A method, system and computer program product are provided to produce, edit, store, and/or distribute enhanced media productions, including news programs, television programming (such as, documentaries, situation comedies, dramas, variety shows, interviews, or the like), sporting events, concerts, infomercials, movies, video rentals, or any other content. In an embodiment, the media production is tagged, partitioned, and organized automatically so that it can be broadcast over traditional mediums (e.g., airwaves, cable, satellite, etc.) and/or network infrastructure (including the global Internet). </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> In an embodiment, the present invention combines automated and/or manual media production, webcasting, and additional technology to achieve a delivery system that is operable to stream various forms of media over, for example, the World Wide Web where each user receives live or customized programming on demand. Advertising is linked to portions of each production so that the user when viewing the live or customized programming also views the associated advertising. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> In an embodiment, the present invention also links other forms of auxiliary information, including advertisements, to enrich or enhance the content of a production. Auxiliary information includes extended video/audio, hyperlinks to related web sites, email addresses, statistics, related documents, etc. The production is configured such that specified auxiliary information is presented to a user when its corresponding portion of the production also is being presented. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> In an embodiment, the present invention is adapted to produce and encode a media production for computer network distributions concurrently with an original broadcast over traditional mediums. In an embodiment, the network distribution is executed and delivered to a display or other data processing device at substantially the same time as the broadcast over traditional mediums. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> An embodiment of the present invention enables the association of auxiliary information to be modified at any time during pre-production, production, or post-production. Additionally, during a simulcast over traditional mediums and computer network mediums, embodiments of the present invention permit a production rundown for a network transmission to be modified and synchronized with changes made to a broadcast rundown.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS/FIGURES </heading>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> The accompanying drawings, which are incorporated herein and form part of the specification, illustrate the present invention and, together with the description, further serve to explain the principles of the invention and to enable one skilled in the pertinent art(s) to make and use the invention. In the drawings, generally, like reference numbers indicate identical or functionally similar elements. Additionally, generally, the leftmost digit(s) of a reference number identifies the drawing in which the reference number first appears. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates an operational flow diagram for delivering parallel live productions according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates an operational flow for formatting media for transmissions according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates an operational flow diagram for delivering parallel live productions according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates an operational flow diagram for delivering parallel live productions according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates an operational flow diagram for delivering parallel live productions according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates an operational flow diagram for editing post-productions according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> illustrates an operational flow diagram for providing an enhanced media viewer according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates an operational flow diagram for requesting and distributing enhanced media according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates an enhanced media production and distribution system according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> illustrates an example computer system useful for implementing the present invention. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> illustrates an electronic rundown graphical user interface (GUI) according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> illustrates an electronic rundown GUI according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> illustrates an alternative view of the electronic rundown GUI of <cross-reference target="DRAWINGS">FIG. 11</cross-reference> or <cross-reference target="DRAWINGS">FIG. 12</cross-reference>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> illustrates an encode mark configuration GUI according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> illustrates an alternative view of the electronic rundown GUI of <cross-reference target="DRAWINGS">FIG. 11</cross-reference> or <cross-reference target="DRAWINGS">FIG. 12</cross-reference>. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> illustrates an encode object configuration GUI according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> illustrates an electronic rundown GUI according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> illustrates an electronic rundown GUI according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> illustrates an operational flow diagram for fragmenting media according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> illustrates an enhanced media streamer according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> illustrates an enhanced media streamer according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 22</cross-reference> illustrates an enhanced media streamer according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> illustrates an electronic rundown GUI for a news automation system according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 24</cross-reference> illustrates stages for producing and distributing a media production according to an embodiment of the present invention. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 25</cross-reference> illustrates an operational flow diagram for requesting and distributing enhanced media according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 26</cross-reference> illustrates an operational flow diagram for requesting and distributing enhanced media according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 27</cross-reference> illustrates an operational flow diagram for requesting and distributing enhanced media according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 28</cross-reference> illustrates an operational flow diagram for requesting and distributing enhanced media according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 29</cross-reference> illustrates an operational flow diagram for requesting and distributing enhanced media according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 30</cross-reference> illustrates an operational flow diagram for requesting and distributing enhanced media according to another embodiment of the present invention. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 31</cross-reference> illustrates an operational flow diagram for requesting and distributing enhanced media according to another embodiment of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
</section>
<section>
<heading lvl="1">Table of Contents </heading>
<paragraph id="P-0059" lvl="1"><number>&lsqb;0059&rsqb;</number> I. Enhanced Media Production and Distribution </paragraph>
<paragraph id="P-0060" lvl="1"><number>&lsqb;0060&rsqb;</number> II. Producing Media for Parallel Distribution </paragraph>
<paragraph id="P-0061" lvl="1"><number>&lsqb;0061&rsqb;</number> III. Post-Production Disposition </paragraph>
<paragraph id="P-0062" lvl="1"><number>&lsqb;0062&rsqb;</number> IV. Benefit of Invention Using an Example Web Cast </paragraph>
<paragraph id="P-0063" lvl="1"><number>&lsqb;0063&rsqb;</number> V. System Overview of Enhanced Media Production and Distribution </paragraph>
<paragraph id="P-0064" lvl="1"><number>&lsqb;0064&rsqb;</number> VI. Enhanced Media Production and Storage </paragraph>
<paragraph id="P-0065" lvl="1"><number>&lsqb;0065&rsqb;</number> VII. Web Cast Production </paragraph>
<paragraph id="P-0066" lvl="1"><number>&lsqb;0066&rsqb;</number> VIII. Auxiliary Information </paragraph>
<paragraph id="P-0067" lvl="2"><number>&lsqb;0067&rsqb;</number> 1. Advertisements </paragraph>
<paragraph id="P-0068" lvl="2"><number>&lsqb;0068&rsqb;</number> 2. Supporting Information </paragraph>
<paragraph id="P-0069" lvl="2"><number>&lsqb;0069&rsqb;</number> 3. Extended Audio-Video </paragraph>
<paragraph id="P-0070" lvl="2"><number>&lsqb;0070&rsqb;</number> 4. Opinion Research </paragraph>
<paragraph id="P-0071" lvl="2"><number>&lsqb;0071&rsqb;</number> 5. Hyperlinks to Related Sites </paragraph>
<paragraph id="P-0072" lvl="2"><number>&lsqb;0072&rsqb;</number> 6. Methods of Entering Auxiliary Information </paragraph>
<paragraph id="P-0073" lvl="1"><number>&lsqb;0073&rsqb;</number> IX. Viewer Interface </paragraph>
<paragraph id="P-0074" lvl="2"><number>&lsqb;0074&rsqb;</number> 1. Media Viewer </paragraph>
<paragraph id="P-0075" lvl="2"><number>&lsqb;0075&rsqb;</number> 2. Viewer Controls </paragraph>
<paragraph id="P-0076" lvl="2"><number>&lsqb;0076&rsqb;</number> 3. Media Index </paragraph>
<paragraph id="P-0077" lvl="2"><number>&lsqb;0077&rsqb;</number> 4. Auxiliary Media </paragraph>
<paragraph id="P-0078" lvl="2"><number>&lsqb;0078&rsqb;</number> 5. Opinion Media </paragraph>
<paragraph id="P-0079" lvl="2"><number>&lsqb;0079&rsqb;</number> 6. Media Access Area </paragraph>
<paragraph id="P-0080" lvl="2"><number>&lsqb;0080&rsqb;</number> 7. Banner </paragraph>
<paragraph id="P-0081" lvl="2"><number>&lsqb;0081&rsqb;</number> 8. Alternative Skins </paragraph>
<paragraph id="P-0082" lvl="1"><number>&lsqb;0082&rsqb;</number> X. Conclusion </paragraph>
<paragraph id="P-0083" lvl="7"><number>&lsqb;0083&rsqb;</number> I. Enhanced Media Production and Distribution </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> In an embodiment of the present invention, live or live-to-tape media productions are encoded and transmitted over a computer network, such as the global Internet, a local intranet, private virtual networks, or any other communication network, medium, and/or mode. During the encoding process, auxiliary information is associated with stories or story elements within the media production, such that the auxiliary information is presented with the media production when it is streamed, downloaded, or otherwise transferred, transmitted, or provided to a display device. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> As used herein, the term &ldquo;media production&rdquo; includes the production of any and all forms of media or multimedia in accordance with the method, system, and computer program product of the present invention. Additionally, the term &ldquo;enhanced media&rdquo; refers to a media production that has been supplemented according to the present invention to enhance the value and/or substance of the media production. In an embodiment, enhanced media is produced by associating auxiliary information, such as graphics, extended play segments, opinion research data, universal resource locators (URLs), advertisements, computer programs, Java or similar code, spreadsheets, audio in any format, video in any format, multimedia, or other auxiliary information deemed desirable. The term &ldquo;live-to-tape&rdquo; refers to a live media production that has been stored to any type of record playback device (RPD), including a video tape recorder/player (VTR), video recorder/server, virtual recorder (VR), digital audio tape (DAT) recorder, or any mechanism that stores, records, generates, or plays back via magnetic, optical, electronic, or any other storage media. It should be understood that &ldquo;live-to-tape&rdquo; represents only one embodiment of the present invention. The present invention is equally applicable to any other type of production that uses or does not use live talent (such as cartoons, computer-generated characters, animation, etc.). Accordingly, reference herein to &ldquo;live&rdquo; or &ldquo;live-to-tape&rdquo; is made for illustration purposes, and is not limiting. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> As such, the method, system, and computer program product of the present invention enable an individual to view a real-time or customized media production, which is transmitted over a network (e.g., the World Wide Web), onto their personal computer (PC), personal digital assistant (PDA), telephone, or other display or data processing device. The media productions include, but are not limited to, video of news programs, television programming (such as, documentaries, situation comedies, dramas, variety shows, interviews, or the like), sporting events, concerts, infomercials, movies, video rentals, or any other content. For example, media productions can include streaming video related to corporate communications and training, educational distance learning, or home shopping video-based &ldquo;e&rdquo; or &ldquo;t&rdquo;-commerce. Media productions also include live or recorded audio (including radio broadcast), graphics, animation, computer generated, text, and other forms of media and multimedia. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> In an &ldquo;on-demand&rdquo; embodiment, a live news program or other type of program (as noted above) is recorded at a hosting facility (e.g., television station, or other location(s)), segmented, categorized, and indexed for easy retrieval and viewing. These operations can be performed automatically using the PVTV Production Automation System&trade; (previously referred to in the applications cited above as the CameraManSTUDIO&trade; automation system) available from ParkerVision, Inc. of Jacksonville, Fla., although it is not necessary to use this system. Alternatively, these operations (or subsets thereof) can be performed manually. Examples of automated and manual media production systems are described in greater detail below. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> In a &ldquo;live broadcast&rdquo; embodiment of the present invention, a media production is broadcast over traditional airwaves or other mediums (e.g., cable, satellite, etc.) to a television set. At the same time (or substantially the same time), the production is enhanced and encoded for distribution over a computer network. The traditional and network distribution modes/methods are synchronized and transmitted substantially at the same time. The distribution can be live or repurposed from previously stored media. In an embodiment, the media production is distributed only via a traditional medium. In another embodiment, the media production is distributed only over a computer network. In an embodiment, the computer network includes the Internet, and the enhanced media is formatted in hypertext markup language (HTML) for distribution over the World Wide Web. The network transmission or web cast is delivered to a display device within an approximate twenty-second delay from the live broadcast. However, the present invention is not limited to the Internet, and the transmission latency will vary based on a number of factors, such as geographies, equipment used, system loading, etc. </paragraph>
<paragraph id="P-0089" lvl="7"><number>&lsqb;0089&rsqb;</number> II. Producing Media for Parallel Distribution </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> As discussed above, embodiments of the present invention support parallel distribution of a media production over different mediums (such as, a traditional medium and a computer network). <cross-reference target="DRAWINGS">FIG. 24</cross-reference> illustrates four stages in producing and distributing a media production in accordance with an embodiment of the present invention. As shown, the four stages include a pre-production stage, production stage, post-production stage, and on-demand stage. During the pre-production stage, a show rundown <highlight><bold>2402</bold></highlight> is planned and prepared by an appropriate member of the production crew. As an example, a show&apos;s producer, who is the architect of the show, typically prepares show rundown <highlight><bold>2402</bold></highlight> initially. The director then takes show rundown <highlight><bold>2402</bold></highlight>, &ldquo;marks it&rdquo; (which is a term used in the broadcast industry to denote the adding of source and effect information), and subsequently coordinates the entire production crew by issuing verbal instructions to them according to the director&apos;s show rundown <highlight><bold>2402</bold></highlight>. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> In accordance with the present invention, show rundown <highlight><bold>2402</bold></highlight> can be implemented as a paper or electronic embodiment. As an electronic embodiment, show rundown <highlight><bold>2402</bold></highlight> can be executed to provide automated, semi-automated, or manual control of a show&apos;s production, as described in greater detail below. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> During the production stage, the show&apos;s director steps through show rundown <highlight><bold>2402</bold></highlight> to issue media production instructions. As a result, the production crew operates the appropriate equipment to produce a traditional show <highlight><bold>2406</bold></highlight>. In accordance with the present invention, traditional show <highlight><bold>2406</bold></highlight> is produced by manually operating the production equipment, or by using an automated or semi-automated production system. Traditional show <highlight><bold>2406</bold></highlight> (i.e., the media production) is captured and transmitted to master control. The master control system switches between feeds, local production, and/or commercial insertion. Master control sends a signal out to the transmitter and broadcasts traditional show <highlight><bold>2406</bold></highlight> over the airwaves or other traditional mediums and/or modes (such as cable, satellite, etc.). </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> During the post-production stage, traditional show <highlight><bold>2406</bold></highlight> is encoded and recorded to a storage medium as an archived show <highlight><bold>2410</bold></highlight>. A post-production editing and approval application file <highlight><bold>2409</bold></highlight> is provided to modify, add, delete, or insert stories, extended play, or related story links, URLs, scripts, graphics, or other data, video, or text to enhance or edit the content for &ldquo;on-demand&rdquo; access. Post-production editing and approval application file <highlight><bold>2409</bold></highlight> enables one to edit or modify archived show <highlight><bold>2410</bold></highlight>. Using post-production editing and approval application file <highlight><bold>2409</bold></highlight>, one can recall all or part of archived show <highlight><bold>2410</bold></highlight>, so that it can be &ldquo;fine-tuned&rdquo; via editing of the beginning or end of a segment or story. A story can be further segmented or deleted as necessary to only allow specific stories to be accessed for &ldquo;on-demand&rdquo; retrieval. The start and end of individual segments or stories are marked such that, once the stories are encoded, they become independent stories or portions thereof (shown as segments <highlight><bold>2412</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2412</bold></highlight><highlight><italic>x</italic></highlight>), and stored. One or more of segments <highlight><bold>2412</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2412</bold></highlight><highlight><italic>x </italic></highlight>are linked with metadata that includes a filename, an address or path to its storage location, or an address or path to any auxiliary information associated with segment <highlight><bold>2412</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2412</bold></highlight><highlight><italic>x</italic></highlight>. In addition, runtime data, story name, show name, segment length, date produced, and category of story segment are also stored and linked. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> During the on-demand stage, the content archived during the post-production stage is queried for a subsequent viewing. As discussed, embodiments of the present invention support customized selection and viewing of archived content. As such, an on-line user can access an archived show <highlight><bold>2410</bold></highlight>, select one or more segments <highlight><bold>2412</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2412</bold></highlight><highlight><italic>x</italic></highlight>, and request the selected segments <highlight><bold>2412</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2412</bold></highlight><highlight><italic>x </italic></highlight>to be transmitted to a display device in a specified order. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> The four stages have been described with reference to a traditional distribution and post-production. However, the present invention permits a broadcast to be simultaneously or alternatively transmitted over a second (or more) distribution medium in parallel with the primary distribution. The primary distribution is shown in <cross-reference target="DRAWINGS">FIG. 24</cross-reference> by traditional show <highlight><bold>2406</bold></highlight>. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> The primary distribution can be &ldquo;shadowed&rdquo; by shadow rundown <highlight><bold>2404</bold></highlight> and electronic show <highlight><bold>2408</bold></highlight> for parallel or alternative distribution. In other words, during the pre-production stage, another member of the crew prepares or receives a shadow rundown <highlight><bold>2404</bold></highlight> that is based on show rundown <highlight><bold>2402</bold></highlight>, or &ldquo;marks&rdquo; the same electronic rundown <highlight><bold>2402</bold></highlight> as a separate client, i.e., the director as opposed to the producer or &ldquo;second&rdquo; director. Shadow rundown <highlight><bold>2404</bold></highlight> includes instructions for formatting a media production to be transmitted over a computer network. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> Shadow rundown <highlight><bold>2404</bold></highlight> is executed during the production stage to thereby transmit the formatted media production (shown as electronic show <highlight><bold>2408</bold></highlight>) over, for example, the Internet or other computer mediums. Electronic show <highlight><bold>2408</bold></highlight> also is saved as archived show <highlight><bold>2410</bold></highlight>. As previously discussed, post-production editing and approval application file <highlight><bold>2409</bold></highlight> is used to edit archived show <highlight><bold>2410</bold></highlight>. Afterwards, archived show <highlight><bold>2410</bold></highlight> or portions thereof are available for future viewing as on-demand show <highlight><bold>2414</bold></highlight>. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> The present invention can be implemented in various configurations for producing and simultaneously transmitting via traditional distribution modes/methods and computer network transmissions. Referring to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, flowchart <highlight><bold>100</bold></highlight> represents the general operational flow of an embodiment of the present invention. More specifically, flowchart <highlight><bold>100</bold></highlight> shows an example of a control flow for sending simulcasts from the same processing device according to the present invention. In other words, the processing device includes two video/audio output ports: one port to a master control for traditional distribution; and a second port for transmitting the output sources to an encoder that formats and transmits the media streams over a computer network. The processing device, thus, executes instructions to produce video for a show, and encode the video for transport over a computer network. It is noted that this implementation represents only an example embodiment of the present invention. Other implementations will be apparent to one skilled in the relevant art(s) based on the herein teachings. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> The control flow of flowchart <highlight><bold>100</bold></highlight> begins at step <highlight><bold>101</bold></highlight> and passes immediately to step <highlight><bold>103</bold></highlight>. At step <highlight><bold>103</bold></highlight>, electronic show rundown <highlight><bold>2402</bold></highlight> is prepared to specify element-by-element instructions for producing a live or non-live show. As discussed, the show&apos;s director may prepare show rundown <highlight><bold>2402</bold></highlight>. However, electronic rundown <highlight><bold>2402</bold></highlight> of the present invention is often prepared by the show director, a web master, web cast director, or the like. Electronic rundown <highlight><bold>2402</bold></highlight> can be a text-based or an object-oriented listing of production commands. An exemplary embodiment of an electronic rundown is described in greater detail below with reference to <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, and it further described in the applications referred above. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> When executed, electronic rundown <highlight><bold>2402</bold></highlight> is converted into computer readable broadcast instructions to automate the execution of a show without the need of an expensive production crew to control the media production devices. In an embodiment, the broadcast instructions are created from the Transition Macro&trade; multimedia production control program developed by ParkerVision, Inc. (Jacksonville, Fla.) that can be executed to control an automated multimedia production system. The Transition Macro&trade; program is described in the application entitled &ldquo;System and Method for Real Time Video Production and Multicasting&rdquo; (U.S. patent application Ser. No. 09/634,735), which is incorporated herein by reference as though set forth in its entirety. As described in the aforesaid application, the Transition Macro&trade; program is an event-driven application that allows serial and parallel processing of media production commands to automate the control of a multimedia production environment. Each media production command is associated with a timer value and at least one media production device. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> At step <highlight><bold>106</bold></highlight>, electronic rundown <highlight><bold>2402</bold></highlight> is modified to include instructions for post-production disposition of show elements. For instance, the director can &ldquo;mark&rdquo; an element on rundown <highlight><bold>2402</bold></highlight> to specify the beginning and/or the end of a story. The director can also mark or tag an element to be archived, encoded for transmission over a computer network, both, or neither. Techniques and methodologies for &ldquo;marking&rdquo; rundown <highlight><bold>2402</bold></highlight>, or the like, are described in greater detail below with reference to FIGS. <highlight><bold>11</bold></highlight>-<highlight><bold>18</bold></highlight>. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> At step <highlight><bold>109</bold></highlight>, electronic rundown <highlight><bold>2402</bold></highlight> is marked or edited to classify elements. In an embodiment, each element is given a major and minor classification. For example, an element of a newscast may be assigned to a major classification such as local sports, and a minor classification such as high school football. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> At step <highlight><bold>112</bold></highlight>, auxiliary information is associated with one or more elements listed on electronic rundown <highlight><bold>2402</bold></highlight>. Electronic rundown <highlight><bold>2402</bold></highlight> is marked or edited to provide an address to the auxiliary information, or some other indication of the auxiliary information (including inserting the information itself), such that the auxiliary information can be presented with its associated element or requested by an on-line user during the element&apos;s presentation. For example, a media production is enhanced by associating related stories, related web sites, advertisement banners, flash media, script for the currently presented element, or the like. If a story comprises multiple elements, the auxiliary information can be associated at an element or story level, as determined by the director or other responsible crew member. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> At step <highlight><bold>115</bold></highlight>, the director executes electronic rundown <highlight><bold>2402</bold></highlight> to produce the show. The markings (for post-production disposition) are likewise executed in real time as an associated element is produced. As described in detail below with reference to FIGS. <highlight><bold>17</bold></highlight>-<highlight><bold>18</bold></highlight>, the instructions from the markings are later used in post-production editing and approval application file <highlight><bold>2409</bold></highlight> to edit (if necessary), prepare, and archive individual stories (e.g., segments <highlight><bold>2412</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2412</bold></highlight><highlight><italic>x</italic></highlight>) for &ldquo;on-demand&rdquo; retrieval in whatever order a user prefers. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> Referring back to step <highlight><bold>115</bold></highlight>, each produced element is simultaneously transmitted according to rundown <highlight><bold>2402</bold></highlight> over parallel output ports. Hence, the media stream is split for the appropriate port. One media stream is transmitted from an output port to a master control system for a traditional distribution, as traditional show <highlight><bold>2406</bold></highlight>. A second media stream is transmitted to the encoder, compressed and formatted for network transmissions, and forwarded through a second port over a computer network (e.g., the Internet or other computer medium), as electronic show <highlight><bold>2408</bold></highlight>. Other operations are possible. For example, the stream can be transmitted over traditional mediums (as traditional show <highlight><bold>2406</bold></highlight>), and prepared for later transmission over a communication network (as electronic show <highlight><bold>2408</bold></highlight>). In this example, the media stream could be transmitted digitally either over traditional broadcast licensed RF spectrum, or via digital cable, satellite DBS, microwave, or other licensed or unlicensed wireless radio frequency air interface technology spectrum, directly to a consumer&apos;s digital set-top box or digital television set or other digital appliance. Alternatively, the broadcast can be transmitted over a computer network (as electronic show <highlight><bold>2408</bold></highlight>), but not transmitted over traditional mediums (as traditional show <highlight><bold>2406</bold></highlight>). Any combination of operations is within the scope of the present invention. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> At step <highlight><bold>118</bold></highlight>, the director is able to dynamically adjust, during production, electronic rundown <highlight><bold>2402</bold></highlight> to account for any changes in the live studio production. During a live broadcast, many unforeseeable events can occur that influences the production. Equipment can fail, talent may miss a cue, or breaking news may require real-time insertion. The present invention enables the director to revise electronic rundown <highlight><bold>2402</bold></highlight>, during the production, to account for these occurrences. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> At step <highlight><bold>121</bold></highlight>, advertising is served during the commercial breaks of electronic show <highlight><bold>2408</bold></highlight> by the &ldquo;commercial insertion application&rdquo; (CIA) software according to an ad traffic scheduler that defines ad placement by show and show break block &ldquo;A&rdquo;, &ldquo;B&rdquo;, &ldquo;C&rdquo;, &ldquo;D&rdquo;, etc. for video based streaming ads. The over-the-air broadcast ads are served the traditional method from a commercial insertion system through master control. Video streaming ads may be the same or different compared to the over-the-air broadcast ads. Banner and button ads are served by the processing device and/or software according to element/story classifications (specified in step <highlight><bold>109</bold></highlight>). As used herein, the term &ldquo;advertisement&rdquo; refers to any message designed to attract attention or patronage, and includes without limitation, paid advertisements, public service announcements, community notices, promotions, etc. For instance, a promotional or product advertisement is transmitted prior to or following an associated element/story. After the live production has been transmitted with the associated auxiliary information including advertisements, the control flow ends as indicated at step <highlight><bold>195</bold></highlight>. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> As discussed above with reference to step <highlight><bold>115</bold></highlight>, the enhanced media production is delivered over a computer network to a display device. Prior to transmitting the media production, the enhanced media production is formatted for network transport. Referring to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, flowchart <highlight><bold>200</bold></highlight> represents the general operational flow of an embodiment for formatting enhanced media productions. More specifically, flowchart <highlight><bold>200</bold></highlight> shows an example of a control flow for formatting media and associated metadata for webcasting. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> The control flow of flowchart <highlight><bold>200</bold></highlight> begins at step <highlight><bold>201</bold></highlight> and passes immediately to step <highlight><bold>203</bold></highlight>. At step <highlight><bold>203</bold></highlight>, the media production (such as electronic show <highlight><bold>2408</bold></highlight>) is compressed into packets. In an embodiment, the packets are formatted to support multimedia applications available from RealNetworks, Inc. (Seattle, Wash.), Microsoft Corporation (Redmond, Wash.), Apple Computer, Inc. (Cupertino, Calif.), or vendors of like applications as would be apparent to one skilled in the relevant art(s). In addition to the aforementioned proprietary formats, the media production formats can include, but are not limited to, MPEG-2 and MPEG-4 non-proprietary formats. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> At step <highlight><bold>206</bold></highlight>, metadata concerning any auxiliary information is integrated with the packets. As described, auxiliary information can be associated with one or more elements to enhance a media production. Thus, at step <highlight><bold>206</bold></highlight>, the present invention ensures the association is preserved during the encoding process. In an embodiment, data frames containing the auxiliary information are formatted and concatenated to the media packets. Instructions are included to inform the client to display the auxiliary information with the associated elements. In another embodiment, addresses to the auxiliary information are added to the packets or a header. Accordingly, instructions are included to inform the client to request the associated auxiliary information for presentation. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> For example, if a media production is formatted for Microsoft&apos;s Windows Media&trade; application, metafiles are prepared to serve as links from web pages to content formatted to support the Windows Media&trade; application. Hence, a metafile contains the URL of multimedia content on a server. A complex metafile contains multiple files or streams arranged in a playlist, instructions for playing the files or streams, text and graphic elements associated with the video and topic being streamed, hyperlinks associated with elements as they are displayed by a Windows Media&trade; application, or the like. As such, a metafile is prepared, in an embodiment, to include links and instructions for presenting auxiliary information with associated elements. In addition, show metadata (i.e., show name, date aired, etc.) is linked to each story so that a playlist can be generated, organized, and presented to the consumer either by show or by story classification. In addition, story metadata (i.e., story name, category, duration, and story association to show and air date) can also be illustrated for consumer identification, selection, and request. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> At step <highlight><bold>209</bold></highlight>, the packetized enhanced media and metadata are fragmented or concatenated based on available bandwidth and other network parameters. At step <highlight><bold>212</bold></highlight>, the packets are transmitting over the network or any time of data processing communication medium to a client display device(s). After the production (i.e., electronic show <highlight><bold>2408</bold></highlight>) has been transmitted with the associated auxiliary information, the control flow ends as indicated at step <highlight><bold>295</bold></highlight>. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> The embodiment described with reference to <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is premised on the use of a single processing device that produces a live or non-live show and formats the show for a simultaneous traditional distribution (e.g., traditional show <highlight><bold>2406</bold></highlight>) and web cast (e.g., electronic show <highlight><bold>2408</bold></highlight>). Thus, the single processing device enables automated or semi-automated multimedia productions. However, the present invention can also be implemented in various configurations that do not utilize a processing device to automate a production. For instance, the present invention also supports synchronized parallel live or non-live productions in a manual or semi-automated multimedia production environment. As such, a web director or like crew member is able to duplicate the operations of a show director while the show director steps through all or part of a production. This process is referred to as newscast &ldquo;shadowing.&rdquo;</paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, flowchart <highlight><bold>300</bold></highlight> represents the general operational flow of an embodiment of the present invention for production shadowing. More specifically, flowchart <highlight><bold>300</bold></highlight> shows an example of a control flow for sending a media production (e.g., electronic show <highlight><bold>2408</bold></highlight>) over a computer network. The media production is created in a manual or semi-automated studio environment, and broadcast (e.g., traditional show <highlight><bold>2406</bold></highlight>) over television airwaves or other traditional mediums and/or modes. A processing device and/or software program is used to &ldquo;shadow&rdquo; the production for purposes of distribution (e.g., electronic show <highlight><bold>2408</bold></highlight>) over a computer network, where such distribution is performed in a simulcast mode and/or an on-demand mode. In particular, a processing device and/or software program is provided to receive a feed of the production, and to encode and transmit the media over a computer network. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> The control flow of flowchart <highlight><bold>300</bold></highlight> begins at step <highlight><bold>301</bold></highlight> and passes immediately to step <highlight><bold>303</bold></highlight>. At step <highlight><bold>303</bold></highlight>, show rundown <highlight><bold>2402</bold></highlight> is prepared to specify the element-by-element instructions for producing a live or non-live show. Since, in this embodiment, it is being used in manual or semi-automated environment, show rundown <highlight><bold>2402</bold></highlight> can be a paper or electronic embodiment. A shadow electronic rundown <highlight><bold>2404</bold></highlight> is prepared from show rundown <highlight><bold>2402</bold></highlight>. Shadow electronic rundown <highlight><bold>2404</bold></highlight> can be a text-based or an object-oriented listing of production commands. However, unlike the show rundown <highlight><bold>2402</bold></highlight> at step <highlight><bold>103</bold></highlight>, show electronic rundown <highlight><bold>2402</bold></highlight> and shadow electronic rundown <highlight><bold>2402</bold></highlight>, in this embodiment, do not necessarily provide automated or semi-automated control of media production devices during the production. The show director and crew manually can control some or all production devices. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> The shadow electronic rundown <highlight><bold>2404</bold></highlight>, in this embodiment, includes instructions for formatting the production, such that it can be properly transmitted over a computer network. Thus, when executed, shadow electronic rundown <highlight><bold>2404</bold></highlight> is converted into computer readable broadcast instructions to automate the encoding process. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> At step <highlight><bold>306</bold></highlight>, shadow electronic rundown <highlight><bold>2404</bold></highlight> is modified to include instructions for post-production disposition of each show element. For instance, a web director can specify that an element be archived, encoded for transmission over a computer network, both, or neither. At step <highlight><bold>309</bold></highlight>, shadow electronic rundown <highlight><bold>2404</bold></highlight> is edited to classify elements. In an embodiment, each element is given a major and minor classification. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> At step <highlight><bold>312</bold></highlight>, auxiliary information is associated with one or more elements listed on shadow electronic rundown <highlight><bold>2404</bold></highlight>. Shadow electronic rundown <highlight><bold>2404</bold></highlight> is edited to provide an address or other instructions to the auxiliary information, such that the information can be presented with the element or requested by an on-line user during the element&apos;s presentation. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> At step <highlight><bold>315</bold></highlight>, the web director executes shadow electronic rundown <highlight><bold>2404</bold></highlight> to encode and produce the show (e.g., electronic show <highlight><bold>2408</bold></highlight>) for transmission over the computer network. Hence, while the manual production is being transmitted to a master control system for a traditional distribution (e.g., traditional show <highlight><bold>2406</bold></highlight>), the encoded media stream is being formatted for network transmissions (e.g., electronic show <highlight><bold>2408</bold></highlight>) and forwarded through an output port over, for example, the Internet or other computer mediums. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> At step <highlight><bold>318</bold></highlight>, the web director is able to dynamically adjust shadow electronic rundown <highlight><bold>2404</bold></highlight> during the production to account for any changes made by the show director in show rundown <highlight><bold>2402</bold></highlight> for the studio production, as described above with reference to step <highlight><bold>118</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. At step <highlight><bold>321</bold></highlight>, advertising is served during the commercial breaks in electronic show <highlight><bold>2408</bold></highlight> by the &ldquo;commercial insertion application&rdquo; (CIA) software according to an ad traffic scheduler that defines ad placement by show and show break block &ldquo;A&rdquo;, &ldquo;B&rdquo;, &ldquo;C&rdquo;, &ldquo;D&rdquo;, etc. for video based streaming ads. Banner and button ads are served by the processing device and/or software according to element/story classifications. After the production has been transmitted with the associated auxiliary information, the control flow ends as indicated at step <highlight><bold>395</bold></highlight>. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> In another embodiment, the present invention can be implemented in various configurations that utilizes two or more processing devices. One processing device (or set of processing devices) is operable to encode a media production (e.g., electronic show <highlight><bold>2408</bold></highlight>) for distribution over a computer network. The second processing device (or another set of processing devices) is operable to support the actual media production (e.g., traditional show <highlight><bold>2406</bold></highlight>) that is broadcast over airwaves or other traditional mediums and/or modes. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, flowchart <highlight><bold>400</bold></highlight> represents the general operational flow of an embodiment of the present invention for production shadowing. More specifically, flowchart <highlight><bold>400</bold></highlight> shows an example of a control flow for sending a live or non-live media production (e.g., electronic show <highlight><bold>2408</bold></highlight>) over a computer network. In this embodiment, the media production is created in either a manual studio environment, or an automated multimedia production environment (e.g., using the PVTV Production Automation System available from ParkerVision, Inc.). Subsequently, the media production is broadcast (e.g., traditional show <highlight><bold>2406</bold></highlight>) over television airwaves or other traditional mediums (such as cable, satellite, etc.). A dedicated processing device is operable to receive an electronic version (e.g., shadow rundown <highlight><bold>2404</bold></highlight>) of the director&apos;s rundown (e.g., show rundown <highlight><bold>2402</bold></highlight>), and a feed of the production (e.g., traditional show <highlight><bold>2406</bold></highlight>). The production is, thereafter, encoded and transmitted (e.g., electronic show <highlight><bold>2408</bold></highlight>) over a computer network (as noted above, such operation is called &ldquo;shadowing&rdquo;). </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> The control flow of flowchart <highlight><bold>400</bold></highlight> begins at step <highlight><bold>401</bold></highlight> and passes immediately to step <highlight><bold>403</bold></highlight>. At step <highlight><bold>403</bold></highlight>, an electronic show rundown <highlight><bold>2402</bold></highlight> is prepared to specify the element-by-element instructions for producing a live or non-live show. As described at step <highlight><bold>103</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, electronic rundown <highlight><bold>2402</bold></highlight> can be a text-based or an object-oriented listing of production commands. If using an automated media production system, electronic rundown <highlight><bold>2402</bold></highlight> provides automated or semi-automated control of media production devices during the live production. However, if a manual production system is being used, the show director and crew manually control all production devices. As such in a manual environment, electronic rundown <highlight><bold>2402</bold></highlight> is a non-functional listing of production commands. For example, a news automation system can be used to develop an electronic rundown sheet of non-functional data. Such news automation systems are available from iNEWS&trade; (i.e., the iNEWS&trade; news service available on the iNews.com web site), Newsmaker, Comprompter, and the Associated Press (AP). </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> At step <highlight><bold>406</bold></highlight>, electronic rundown <highlight><bold>2402</bold></highlight> is modified to include instructions for post-production disposition of show elements. For instance, the director can specify that an element be archived, encoded for transmission over a computer network, both, or neither. At step <highlight><bold>409</bold></highlight>, electronic rundown <highlight><bold>2402</bold></highlight> is edited to classify elements. In an embodiment, each element is given a major and minor classification. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> At step <highlight><bold>412</bold></highlight>, auxiliary information is associated with one or more elements listed on electronic rundown <highlight><bold>2402</bold></highlight>. Electronic rundown <highlight><bold>2402</bold></highlight> is edited to provide an address to, or other indication of, the auxiliary information, such that the information can be presented with the element or requested by an on-line user during the element&apos;s presentation. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> At step <highlight><bold>415</bold></highlight>, electronic rundown <highlight><bold>2402</bold></highlight> is imported into an encoding processing station that is used to create shadow rundown <highlight><bold>2404</bold></highlight>. Shadow rundown <highlight><bold>2404</bold></highlight> includes instructions for formatting the production (e.g., electronic show <highlight><bold>2408</bold></highlight>), such that it can be properly transmitted over a computer network. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> At step <highlight><bold>418</bold></highlight>, the web director executes shadow rundown <highlight><bold>2404</bold></highlight> to encode and produce the show (e.g., electronic show <highlight><bold>2408</bold></highlight>) for transmission over the computer network. Hence, while the manual or automated production is being transmitted to a master control system for a traditional distribution (e.g., traditional show <highlight><bold>2406</bold></highlight>), the encoded media stream is being formatted for network transmissions (e.g., electronic show <highlight><bold>2408</bold></highlight>) and forwarded through an output port over, for example, the Internet or other computer medium. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> At step <highlight><bold>421</bold></highlight>, the web director is able to dynamically adjust, during production, shadow rundown <highlight><bold>2404</bold></highlight> to account for any changes made by the show director in the studio production, as described above with reference to step <highlight><bold>118</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. At step <highlight><bold>424</bold></highlight>, advertising is served during the commercial breaks by the &ldquo;commercial insertion application&rdquo; (CIA) software according to an ad traffic scheduler that defines ad placement by show and show break block &ldquo;A&rdquo;, &ldquo;B&rdquo;, &ldquo;C&rdquo;, &ldquo;D&rdquo;, etc. for video based streaming ads. Banner and button ads are served by the processing device and/or software according to element/story classifications. After the production has been transmitted with the associated auxiliary information, the control flow ends as indicated at step <highlight><bold>495</bold></highlight>. </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> In the above embodiment described with reference to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, an electronic rundown <highlight><bold>2402</bold></highlight> is prepared and modified to include encoding instructions. Afterwards, electronic rundown <highlight><bold>2402</bold></highlight> is imported into an encoding processing device(s) that creates, or otherwise provides, shadow rundown <highlight><bold>2404</bold></highlight> for execution. In another embodiment involving two or more processing devices, electronic rundown <highlight><bold>2402</bold></highlight> does not include any encoding instructions. Encoding instructions are included after electronic rundown <highlight><bold>2402</bold></highlight> is imported into the encoding processing device(s) to create shadow rundown <highlight><bold>2404</bold></highlight>. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, flowchart <highlight><bold>500</bold></highlight> represents the general operational flow of another embodiment of the present invention for production shadowing. More specifically, flowchart <highlight><bold>500</bold></highlight> shows an example of a control flow for sending a live or non-live media production (e.g., electronic show <highlight><bold>2408</bold></highlight>) over a computer network. In this embodiment, the media production is created in either a manual studio environment, or an automated multimedia production environment. Subsequently, the media production is broadcast (e.g., traditional show <highlight><bold>2406</bold></highlight>) over television airwaves or other traditional mediums and/or modes. A dedicated processing device is operable to receive an electronic version of the director&apos;s rundown (i.e., show rundown <highlight><bold>2402</bold></highlight>), and a feed of the live production. The production is, thereafter, encoded and transmitted over a computer network. </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> The control flow of flowchart <highlight><bold>500</bold></highlight> begins at step <highlight><bold>501</bold></highlight> and passes immediately to step <highlight><bold>503</bold></highlight>. At step <highlight><bold>503</bold></highlight>, an electronic show rundown <highlight><bold>2402</bold></highlight> is prepared to specify the element-by-element instructions for producing a live or non-live show. As described at step <highlight><bold>403</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, electronic rundown <highlight><bold>2402</bold></highlight> can be a text-based or an object-oriented listing of production commands. If using an automated media production system, electronic rundown <highlight><bold>2402</bold></highlight> provides automated or semi-automated control of media production devices during the production. However, if a manual production system is being used, the show director and crew manually control all production devices. Therefore in manual environments, electronic rundown <highlight><bold>2402</bold></highlight> is a non-functional listing of production commands, and can be prepared with the aid of a news automation system. However, unlike step <highlight><bold>403</bold></highlight>, electronic rundown <highlight><bold>2402</bold></highlight> is not modified at step <highlight><bold>503</bold></highlight> to include any post-production disposition instructions. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> Instead, at step <highlight><bold>506</bold></highlight>, electronic rundown <highlight><bold>2402</bold></highlight> is imported into an encoding processing station that is used to create a shadow rundown <highlight><bold>2404</bold></highlight>. At step <highlight><bold>509</bold></highlight>, shadow rundown <highlight><bold>2404</bold></highlight> is modified to include instructions for post-production disposition of show elements. At step <highlight><bold>512</bold></highlight>, shadow rundown <highlight><bold>2404</bold></highlight> is edited to classify elements as previously described. </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> At step <highlight><bold>515</bold></highlight>, auxiliary information is associated with one or more elements listed on shadow rundown <highlight><bold>2404</bold></highlight>. Shadow rundown <highlight><bold>2404</bold></highlight> is edited to provide an address to, or other indication of, the auxiliary information, such that the information can be presented with the element or requested by an on-line user during the element&apos;s presentation. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> At step <highlight><bold>518</bold></highlight>, the web director executes shadow rundown <highlight><bold>2404</bold></highlight> to encode and produce the show (e.g., electronic show <highlight><bold>2408</bold></highlight>) for transmission over the computer network. Hence, while the manual or automated production is being transmitted to a master control system for a traditional distribution (e.g., traditional show <highlight><bold>2406</bold></highlight>), the encoded media stream is being formatted for network transmissions and forwarded through an output port over, for example, the Internet. </paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> At step <highlight><bold>521</bold></highlight>, the web director is able to dynamically adjust, during the production, shadow rundown <highlight><bold>2404</bold></highlight> to account for any changes made by the show director in the studio production, as described above with reference to step <highlight><bold>118</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. At step <highlight><bold>524</bold></highlight>, advertising is served during the commercial breaks by the &ldquo;commercial insertion application&rdquo; (CIA) software according to an ad traffic scheduler that defines ad placement by show and show break block &ldquo;A&rdquo;, &ldquo;B&rdquo;, &ldquo;C&rdquo;, &ldquo;D&rdquo;, etc. for video based streaming ads. Banner and button ads are served by the processing device and/or software according to element/story classifications. After the production has been transmitted with the associated auxiliary information, the control flow ends as indicated at step <highlight><bold>595</bold></highlight>. </paragraph>
<paragraph id="P-0136" lvl="7"><number>&lsqb;0136&rsqb;</number> III. Post-Production Disposition </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> After a live or non-live show has been produced and distributed (e.g., traditional show <highlight><bold>2406</bold></highlight> and/or electronic show <highlight><bold>2408</bold></highlight>) as described above, an embodiment of the present invention provides a system, method, and computer program product for editing and archiving the post-production show (e.g., archived show <highlight><bold>2410</bold></highlight>). Referring to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, flowchart <highlight><bold>600</bold></highlight> represents the general operational flow of an embodiment of the present invention. More specifically, flowchart <highlight><bold>600</bold></highlight> shows an example of a control flow for implementing post-production instructions for a media production. It is noted that, while flowchart <highlight><bold>600</bold></highlight> can operate with a show produced as described above, flowchart <highlight><bold>600</bold></highlight> is also operable with shows produced from other sources and/or using other techniques. </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> The control flow of flowchart <highlight><bold>600</bold></highlight> begins at step <highlight><bold>601</bold></highlight> and passes immediately to step <highlight><bold>603</bold></highlight>. At step <highlight><bold>603</bold></highlight>, a post-production editing and approval application file <highlight><bold>2409</bold></highlight> is received or retrieved from a storage location. Post-production editing and application file <highlight><bold>2409</bold></highlight> is derived, or otherwise provided, from the execution of the show while synchronizing metadata and auxiliary information with the video and audio output. The element definitions, metadata, and auxiliary information are derived from the electronic rundown <highlight><bold>2402</bold></highlight> or shadow rundown <highlight><bold>2404</bold></highlight> whose encoding instructions have been executed in accordance with FIGS. <highlight><bold>1</bold></highlight>-<highlight><bold>5</bold></highlight>, above, or through some other source and/or means. In an embodiment, post-production editing and approval application file <highlight><bold>2409</bold></highlight> is processed using an object-oriented user interface that provides an interactive display. An exemplary embodiment of post-production editing and approval application file <highlight><bold>2409</bold></highlight> is described in greater detail below. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> At step <highlight><bold>606</bold></highlight>, a web director interacts with post-production editing and approval application file <highlight><bold>2409</bold></highlight> to edit or modify elements from the media production (e.g., traditional show <highlight><bold>2406</bold></highlight> and/or electronic show <highlight><bold>2408</bold></highlight>). The media production is stored to a storage medium as archived show <highlight><bold>2410</bold></highlight>, and post-production editing and approval application file <highlight><bold>2409</bold></highlight> enables the web director to edit or modify archived show <highlight><bold>2410</bold></highlight>. Post-production editing and approval application file <highlight><bold>2409</bold></highlight> can be modified to change beginning and end points of a specific story. Post-production editing and approval application file <highlight><bold>2409</bold></highlight> can also be modified to delete or cut the elements/stories. Elements/stories of the show can be cut or fragmented by using the fragmentation process, discussed in detail below with reference to FIGS. <highlight><bold>17</bold></highlight>-<highlight><bold>19</bold></highlight>. Post-production editing and approval application file <highlight><bold>2409</bold></highlight> can also be modified to concatenate elements into a single unit or video clip. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> At step <highlight><bold>609</bold></highlight>, the web director interacts with post-production editing and approval application file <highlight><bold>2409</bold></highlight> to make edits or revisions to the current classification of an element. The web director can change or provide a major or minor classification. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> At step <highlight><bold>612</bold></highlight>, post-production editing and approval application file <highlight><bold>2409</bold></highlight> is updated to edit or modify the addresses to, or other indication of, auxiliary information associated with each element. Post-production editing and approval application file <highlight><bold>2409</bold></highlight> can also be altered to associate new or different auxiliary information. For example, post-production editing and approval application file <highlight><bold>2409</bold></highlight> can be modified to add metadata and auxiliary information for data window display (such as URLs that include HTML pages with data, graphics, text, photos, video, and animation in addition to related story and/or extended play segment URLs, and web site reference URLs). Post-production editing and approval application file <highlight><bold>2409</bold></highlight> can also be modified to add script to facilitate captioning and/or the provisioning of complete transcripts. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> At step <highlight><bold>615</bold></highlight>, the post-production disposition instructions can be reviewed and altered. Elements previously tagged for archive can be deleted, or vice versa. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> At step <highlight><bold>618</bold></highlight>, the &ldquo;updated&rdquo; post-production editing and approval application file <highlight><bold>2409</bold></highlight> is approved by the web director, and at step <highlight><bold>621</bold></highlight>, post-production editing and approval application file <highlight><bold>2409</bold></highlight> is executed to implement the post-production disposition instructions. As the post-production disposition instructions are executed, archived show <highlight><bold>2410</bold></highlight> is appropriately modified in accordance with the instructions. The resulting archived show <highlight><bold>2410</bold></highlight> is stored to a storage medium for future recall. As shown in <cross-reference target="DRAWINGS">FIG. 24</cross-reference>, archive show <highlight><bold>2410</bold></highlight> can be stored as multiple segments <highlight><bold>2412</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2412</bold></highlight><highlight><italic>x</italic></highlight>. A segment <highlight><bold>2412</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2412</bold></highlight><highlight><italic>x </italic></highlight>can represent one or multiple elements or one or more stories, as determined by the web director. Referring back to <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, upon execution of the post-disposition instructions, the control flow ends as indicated at step <highlight><bold>695</bold></highlight>. </paragraph>
<paragraph id="P-0144" lvl="7"><number>&lsqb;0144&rsqb;</number> IV. Benefit of Invention Using an Example Web Cast </paragraph>
<paragraph id="P-0145" lvl="0"><number>&lsqb;0145&rsqb;</number> In an embodiment of the present invention, an on-line user can visit a portal or web site that is hosted by an entity or individual having produced and/or archived content according to the present invention, or an entity or individual associated with or having access to such content. As such, hosting facilities provide portals for visitors to receive a live or customized program on demand. The hosting facilities can be operated by a local television, radio station, newspaper, webcasting station, or like media &ldquo;hosting&rdquo; environment. </paragraph>
<paragraph id="P-0146" lvl="0"><number>&lsqb;0146&rsqb;</number> As an example implementation of the present invention, a thirty minute news program is produced and broken up into separate topics, including national news, local news, sports, weather, business, and the like. These news topics are segmented and appropriately categorized (e.g., sports can be categorized to football or Jacksonville Jaguars). An index is then established using these categories so that individuals can easily query the index and select the news segments they want to view. The selection index can be organized by show (with categories underneath with stories to that specific show), category (lists all stories within each category for multiple shows), or a keyword search can be performed. Alternatively, the user can set up a template (user profile) so that a news program is automatically generated based on personal preference. The profile is maintained in a database so that upon login by the user, a &ldquo;personalized newscast&rdquo; can be downloaded without the user having to assemble it. Without a profile, the user will have to build their personalized show each time upon login. The information gathered from the profile can also be used to sell targeted ads. The user can modify their profile at any time to change their preferences. Once the profile is set, the user upon login can play it as is, modify their personalized newscast, or build a new personalized newscast from scratch (as if they did not enter a profile). The news program is then compiled, potentially with advertisements, and downloaded to the user&apos;s display device in real time or near term. </paragraph>
<paragraph id="P-0147" lvl="0"><number>&lsqb;0147&rsqb;</number> As described, an embodiment of the present invention enables a visitor to interact with a web site and select enhanced media content to be displayed on a display device. The browser for the display device directs media streams to a viewer launched by the display device. In an embodiment, the visitor builds a show via the viewer which, in turn, sends a request for a metafile. The metafile is a list of all of the files/stories requested, including video advertisements. Show segments assembled and requested by the viewer are sent to a server. The viewer gets back an ASX play list that includes, for example, an introduction video, advertisement videos and story videos. The ASX file plays the multiple WMV files or like formats. Each file represents a story or segment that contains all content and associated links. </paragraph>
<paragraph id="P-0148" lvl="0"><number>&lsqb;0148&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, flowchart <highlight><bold>700</bold></highlight> represents the general operational flow of an embodiment of the present invention. More specifically, flowchart <highlight><bold>700</bold></highlight> shows an example of a control flow for providing an enhanced media viewer according to the present invention. </paragraph>
<paragraph id="P-0149" lvl="0"><number>&lsqb;0149&rsqb;</number> The control flow of flowchart <highlight><bold>700</bold></highlight> begins at step <highlight><bold>701</bold></highlight> and passes immediately to step <highlight><bold>702</bold></highlight>. At step <highlight><bold>702</bold></highlight>, an on-line user operates a display device to gain access to the portal of a media host. The portal&apos;s server delivers a web page (not shown) that provides various data disseminated by the media host. In an embodiment, an icon resides on the web page that allows the user to request a media production that is assembled according to the methods of the present invention. Activating the icon sends the request to the portal&apos;s server. As apparent to one skilled in the relevant art(s), other methods can be used to send a request to the portal&apos;s server for a media production, such as sending a URL address; activating hyperlinks, hypertext, or hot spots; or the like. </paragraph>
<paragraph id="P-0150" lvl="0"><number>&lsqb;0150&rsqb;</number> At step <highlight><bold>704</bold></highlight>, the server analyzes the request to identify or authenticate the user. Usernames, password, user profiles, cookies, or similar identification methods can be used to identify the user. The first time a user sends a request for a media production (or if specified in the user profile), the control flow passes to step <highlight><bold>706</bold></highlight>. At step <highlight><bold>706</bold></highlight>, the server prepares a standard viewer. The standard viewer includes a standardized listing of available media selections (e.g., news stories) displayed in a menu format. </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> If, however, the user has established a profile for customized programming, the control flow would pass from step <highlight><bold>704</bold></highlight> to step <highlight><bold>708</bold></highlight>. At step <highlight><bold>708</bold></highlight>, the server prepares a customized viewer that includes a customized listing of available media selections. The customized listing identifies, for example, news stories specified in the user profile. In an embodiment, the user registers and completes a profile that specifies preferred topics or categories of interest. The user can specify other parameters, such as the duration of a customized program, start or end time, geographic source of the content, or the like. In another embodiment, the present invention queries search engines, inference engines, profiling engines, or the like to extract user preferences from past behavior, psychographics, demographics, or the like. </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> At step <highlight><bold>710</bold></highlight>, the server sends the viewer to be displayed by the user&apos;s display device. Notwithstanding the receipt of a standard or customized viewer, the user can opt to switch to a different viewer or change the customization parameters. Upon receipt of the viewer, the control flow ends as indicated at step <highlight><bold>795</bold></highlight>. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> In an embodiment of the present invention, a portal visitor interacts with a standard or customized viewer to assemble and request a media production. The visitor&apos;s request can be based on the actual demands or behavioral patterns of the visitor. Referring to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, flowchart <highlight><bold>800</bold></highlight> represents the general operational flow of an embodiment of the present invention. More specifically, flowchart <highlight><bold>800</bold></highlight> shows an example of a control flow for producing and distributing enhanced media according to the present invention. </paragraph>
<paragraph id="P-0154" lvl="0"><number>&lsqb;0154&rsqb;</number> The control flow of flowchart <highlight><bold>800</bold></highlight> begins at step <highlight><bold>801</bold></highlight> and passes immediately to step <highlight><bold>803</bold></highlight>. At step <highlight><bold>803</bold></highlight>, a visitor logs onto a web site operated by a media host. The visitor&apos;s display device sends a request for a list of available media productions. The host&apos;s server extracts metadata (including filename and URL addresses) from post-production disposition instructions, and/or provide a searchable catalog that is transmitted to the display device. The catalog lists the available media productions at the story or, if applicable, element level. </paragraph>
<paragraph id="P-0155" lvl="0"><number>&lsqb;0155&rsqb;</number> At step <highlight><bold>806</bold></highlight>, the display device receives and displays the searchable catalog. In an embodiment, the visitor&apos;s display device receives or launches a standard or customized viewer as described in steps <highlight><bold>701</bold></highlight>-<highlight><bold>795</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 7</cross-reference>. The visitor is able to view, for example, the news stories displayed in the standard or customized listing. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> At step <highlight><bold>809</bold></highlight>, the visitor interacts with the display device to select one or more stories or story elements or other content from the catalog, and assemble the selection into a personalized show. The visitor can request to view all or a subset of the catalog listing in any order. The visitor operates the display device to send the selection request to the server, and the request is forwarded back to the server. </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> At step <highlight><bold>812</bold></highlight>, the server verifies or confirms the availability and location of the selections. Subsequently, at step <highlight><bold>815</bold></highlight>, the server retrieves, assembles, and encodes the selections for transmission. During this process, the server integrates various auxiliary information into the media stream with the news stories. In an embodiment, the server updates or changes the auxiliary information associated with the requested media. As described, the auxiliary information includes extended play video, related web sites, supporting graphics, scripts, keyers, special effects, or the like. Additionally, the server links national or local advertisements with the media streams. The advertisements include active banners, pre-roll commercials, email correspondence, or similar promotions. </paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> At step <highlight><bold>818</bold></highlight>, the requested media production, including associated auxiliary information, is transmitted to the visitor&apos;s display device. In an embodiment, the enhanced media production is continuously fed to the display device to produce a seamless or near seamless display. Although the visitor operating the display device only experiences a single download, buffering process and playout, an embodiment of the present invention actually provides multiple files in the requested order to be played in a seamless or near seamless manner. This is achieved by the development of a video fragmentation technique, discussed in detail below with reference to <cross-reference target="DRAWINGS">FIG. 19</cross-reference>. In other words, the server assembles an entire media production as requested by the visitor. The media production is fragmented such that a portion of the media production is sent downstream to the display device to be buffered for playout. As the buffer is emptied for display, an additional media stream is sent to the buffer such that the display device is creating a seamless or near seamless display on its viewer. </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> However in another embodiment, the media production can be downloaded for delayed viewing. In another embodiment, the media production can be saved on a local memory of the display device for future viewing. Upon distribution of the requested media production, including associated auxiliary information, to the requesting display device, the control flow ends as indicated at step <highlight><bold>895</bold></highlight>. </paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> Accordingly, an embodiment of the present invention enables a portal&apos;s server to assemble and stream over the World Wide Web each customized program for each visitor, in real time or near term. From the visitor&apos;s perspective, the customized program appears seamless. The visitor is provided with the customized program as soon as the visitor indicates that the program is to start. The segments, which make up the customized program, are automatically sequenced together with the linked advertisements in such a fashion that the program appears to have been created for the visitor according to a subject matter specification indicated by the visitor. </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> Thus, an embodiment of the present invention permits a visitor to specify the desired content of a customized program by using subject matter specifications. These specifications define the desired subject matter, the geographical source of the subject matter, the creation time and date of the subject matter, when the program is to begin and how long it is to last, or other user defined parameters. A menu format can be used by the viewer launched by the display device to assist the visitor in defining the specifications. Alternately, the viewer can provide predefined specifications, or can allow the visitor to upload specifications generated by a program or database search engine. </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> In an embodiment, profiles are generated automatically or manually. An automatic profile allows the media host to accumulate demographics and metrics for the sale of advertising, and the definition and scheduling of programming. This is performed automatically by the use of cookies, or similar user identifiers, loaded onto a display device. Each time a media host&apos;s server is accessed, data is captured and stored to develop a profile of the visitor. Every time the same display device or visitor logs onto the server, the display device receives a customized preprogrammed show according to the visitor&apos;s profile. The visitor then has the ability to accept or reject the pre-defined customized show. A modified or a totally brand new show also can be requested and assembled. Alternatively, the present invention also allows a visitor to complete a visitor profile with more detailed information. In an embodiment, the present invention allows the broadcaster to offer an incentive and password protection for the purpose of obtaining profile data from the visitor. </paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> Thus, the present invention provides a method, system, and computer program product for distributing enhanced media and advertisements over a widely distributed network in response to the actual demands and behavioral patterns of on-line users. The present invention permits advertisements to be linked to the enhanced media and presented to the users who are most likely to purchase the promoted item. The cost for such advertisements is based on the actual distribution to the user, (or alternatively, ads can be sold based on &ldquo;time durations&rdquo; similar to a traditional distribution model, or a combination of both), and the resulting revenue is apportioned according to various models, as described in the application entitled &ldquo;Method, System and Computer Program Product for Producing and Distributing Enhanced Media Downstreams&rdquo; (U.S. patent application Ser. No. 09/836,239), which is incorporated herein by reference as though set forth in its entirety. </paragraph>
<paragraph id="P-0164" lvl="0"><number>&lsqb;0164&rsqb;</number> The above reference to a news program is made for illustrative purposes only. The present invention is equally applicable to live and non-live productions of any type and subject, using, for example, live talent, animation, computer-generated characters, etc. As intimated above, the production is not limited to video or multimedia streams. The present invention also supports customizable productions of other types/forms of information, including for example, text, electronic messaging, advertisements, etc. </paragraph>
<paragraph id="P-0165" lvl="0"><number>&lsqb;0165&rsqb;</number> For example, the present invention can be configured to automatically compile a customized show related to traffic. This can be established to be sent in the mornings and afternoons to facilitate a user&apos;s commute. Such operation can be established to occur automatically via appropriate setting of preferences, or by sending an appropriate request. Other applications are also possible. For example, in the above, local weather stories can be sent to the user at predetermined times to assist with commute or travel. Restaurant and/or show reviews can be sent to the user on Friday evenings, for example (i.e., before the weekend). These and other calendar examples are shown in Table 1 below.  
<table-cwu id="TABLE-US-00001">
<number>1</number>
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217PT" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" align="center">TABLE 1</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry></entry>
</row>
<row><entry namest="1" nameend="1" align="center" rowsep="1"></entry>
</row>
<row>
<entry>Calendar Options</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="OFFSET" colwidth="14PT" align="left"/>
<colspec colname="1" colwidth="98PT" align="left"/>
<colspec colname="2" colwidth="105PT" align="left"/>
<tbody valign="top">
<row>
<entry></entry>
<entry>Topic</entry>
<entry>Delivery Time</entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="2" align="center" rowsep="1"></entry>
</row>
<row>
<entry></entry>
<entry>Information/stories related</entry>
<entry>6 a.m. and 4 p.m.</entry>
</row>
<row>
<entry></entry>
<entry>to traffic and/or weather</entry>
</row>
<row>
<entry></entry>
<entry>Information related to</entry>
<entry>1 week before Thanksgiving</entry>
</row>
<row>
<entry></entry>
<entry>turkey dinners/recipes</entry>
<entry>and Christmas</entry>
</row>
<row>
<entry></entry>
<entry>Informational stories related</entry>
<entry>2 weeks before kid&apos;s</entry>
</row>
<row>
<entry></entry>
<entry>to kid&apos;s parties and gifts</entry>
<entry>birthdays and Christmas</entry>
</row>
<row>
<entry></entry>
<entry>Information/stories related</entry>
<entry>Every Friday evening</entry>
</row>
<row>
<entry></entry>
<entry>to family activities</entry>
</row>
<row>
<entry></entry>
<entry>Information/stories related</entry>
<entry>1 hour before every game</entry>
</row>
<row>
<entry></entry>
<entry>to local teams (or specified</entry>
</row>
<row>
<entry></entry>
<entry>teams)</entry>
</row>
<row>
<entry></entry>
<entry>Software automatically</entry>
<entry>Daily</entry>
</row>
<row>
<entry></entry>
<entry>parses user&apos;s calendars to</entry>
</row>
<row>
<entry></entry>
<entry>identify keywords (such as</entry>
</row>
<row>
<entry></entry>
<entry>&ldquo;New York&rdquo;), and</entry>
</row>
<row>
<entry></entry>
<entry>compile/deliver stories</entry>
</row>
<row>
<entry></entry>
<entry>related to that keyword</entry>
</row>
<row>
<entry></entry>
<entry namest="OFFSET" nameend="2" align="center" rowsep="1"></entry>
</row>
</tbody>
</tgroup>
</table>
</table-cwu>
</paragraph>
<paragraph id="P-0166" lvl="0"><number>&lsqb;0166&rsqb;</number> Table 1 lists several example implementations of the present invention. Each topic represents a customizable media presentation that a user has the option of selecting or defining. The delivery time stipulates when the user prefers to receive the media presentation. The above examples are further explained with reference to FIGS. <highlight><bold>25</bold></highlight>-<highlight><bold>31</bold></highlight>. </paragraph>
<paragraph id="P-0167" lvl="0"><number>&lsqb;0167&rsqb;</number> First referring to <cross-reference target="DRAWINGS">FIG. 25</cross-reference>, flowchart <highlight><bold>2500</bold></highlight> represents the general operational flow of an embodiment of the present invention. More specifically, flowchart <highlight><bold>2500</bold></highlight> shows an example of a control flow for customizing a production based on a calendar event, such as, but not limited to, the events shown in Table 1. </paragraph>
<paragraph id="P-0168" lvl="0"><number>&lsqb;0168&rsqb;</number> The control flow of flowchart <highlight><bold>2500</bold></highlight> begins at step <highlight><bold>2501</bold></highlight> and passes immediately to step <highlight><bold>2503</bold></highlight>. At step <highlight><bold>2503</bold></highlight>, a profile is established for the user. This can be accomplished via a registration process, an email request from the user, or any other well-known method for indicating a user&apos;s request/preference. As described above, the user specifically indicates one or more topics of interest, or a profiling engine or the like generates topic(s) based on demographic, psychographic, or behavioral patterns. However, in another embodiment, passive techniques are employed to generate the user&apos;s preferences by monitoring the user&apos;s Internet usage, mailing list memberships, e-commerce purchase history, or the like. </paragraph>
<paragraph id="P-0169" lvl="0"><number>&lsqb;0169&rsqb;</number> At step <highlight><bold>2506</bold></highlight>, the user&apos;s profile is collected and analyzed to identify or select the topic(s) of interest, as specified in the user profile or determined by a profiling engine. At step <highlight><bold>2509</bold></highlight>, the user&apos;s other preferences are considered. The user may indicate a preferred date or time to receive media content. The user may also indicate a preferred duration or file size. If the user has adequate storage capacity on the client display device, the user may specify file size. Other preferences can be indicated as stated above. For example, the user may specify certain formats for video (e.g., avi), text (e.g., html), audio (e.g., wav format), images (e.g., bmp), or the like. </paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> At step <highlight><bold>2512</bold></highlight>, the user&apos;s profile is executed to select media matching the user&apos;s interests. As described herein, the media includes video, text articles, web sites, merchandising, audio feeds, etc. The selected media is assembled and compiled for transmission. </paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> At step <highlight><bold>2515</bold></highlight>, the media production is transmitted to the user&apos;s client as described above. The media production is transmitted at the designated time and format specified by the user. After the customized media presentation has been transmitted, the control flow ends as indicated at step <highlight><bold>2595</bold></highlight>. </paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> A second example of a control flow for customizing a production is shown in <cross-reference target="DRAWINGS">FIG. 26</cross-reference>. Referring to <cross-reference target="DRAWINGS">FIG. 26</cross-reference>, flowchart <highlight><bold>2600</bold></highlight> represents the general operational flow of another embodiment of the present invention. More specifically, flowchart <highlight><bold>2600</bold></highlight> shows an example of a control flow for customizing a production based on the first topic shown in Table <highlight><bold>1</bold></highlight>. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> The control flow of flowchart <highlight><bold>2600</bold></highlight> begins at step <highlight><bold>2601</bold></highlight> and passes immediately to step <highlight><bold>2603</bold></highlight>. At step <highlight><bold>2603</bold></highlight>, a profile is established for the user. Referring to the first topic in Table 1, the user actively requests topics related to traffic and/or weather. However, in another embodiment, passive techniques are employed to generate the user&apos;s preferences by monitoring the user&apos;s Internet usage, mailing list memberships, e-commerce purchase history, or the like. Referring back to the first example shown in Table 1, a profiling engine or the like would determine the user prefers topics related to traffic and/or weather. </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> At step <highlight><bold>2606</bold></highlight>, the user&apos;s profile is collected and analyzed to identify or select the topic(s) of interest. In this case, the topic is traffic and/or weather, as specified in the user profile or determined by a profiling engine. At step <highlight><bold>2609</bold></highlight>, the user&apos;s other preferences are considered. The user may indicate a preferred time to receive media content. Referring back to Table 1, in the first example, the user specifies 6 a.m. and 4 p.m. which correspond to the user&apos;s morning and evening commute. </paragraph>
<paragraph id="P-0175" lvl="0"><number>&lsqb;0175&rsqb;</number> The user may also indicate a preferred duration or file size. For example, if the commute is thirty minutes, the user may specify the compiled presentation to be less than twenty minutes. If the user has adequate storage capacity on the client display device, the user may specify file size. Other preferences can be indicated as stated above. For example, the user may specify certain formats for video (e.g., avi), text (e.g., html), audio (e.g., wav format), images (e.g., bmp), or the like. </paragraph>
<paragraph id="P-0176" lvl="0"><number>&lsqb;0176&rsqb;</number> At step <highlight><bold>2612</bold></highlight>, the user&apos;s profile is executed to select media matching the user&apos;s interests. As described herein, the media includes video, text articles, web sites, merchandising, audio feeds, etc. The selected media is assembled and compiled for transmission. </paragraph>
<paragraph id="P-0177" lvl="0"><number>&lsqb;0177&rsqb;</number> At step <highlight><bold>2615</bold></highlight>, the media production is transmitted to the user&apos;s client as described above. The media production is transmitted at the designated time and format specified by the user. In the first example shown in Table 1, the production is delivered at 6 a.m. and 4 p.m. After the customized media presentation has been transmitted, the control flow ends as indicated at step <highlight><bold>2695</bold></highlight>. </paragraph>
<paragraph id="P-0178" lvl="0"><number>&lsqb;0178&rsqb;</number> A third example of a control flow for customizing a production is shown in <cross-reference target="DRAWINGS">FIG. 27</cross-reference>. Referring to <cross-reference target="DRAWINGS">FIG. 27</cross-reference>, flowchart <highlight><bold>2700</bold></highlight> represents the general operational flow of another embodiment of the present invention. More specifically, flowchart <highlight><bold>2700</bold></highlight> shows an example of customizing a production based on the second topic shown in Table 1. </paragraph>
<paragraph id="P-0179" lvl="0"><number>&lsqb;0179&rsqb;</number> The control flow of flowchart <highlight><bold>2700</bold></highlight> begins at step <highlight><bold>2701</bold></highlight> and passes immediately to step <highlight><bold>2703</bold></highlight>. At step <highlight><bold>2703</bold></highlight>, a user profile is established to designate topics related to turkey dinners or recipes. As described above, the user can specifically indicate an interest in this topic to help plan for an upcoming event or holiday. The user may have so established this interest at an earlier date, such that the operation of the invention serves as a reminder to the user. Alternatively, an inference engine or the like can consider the user&apos;s demographic, psychographic, or behavioral patterns to infer an interest in this topic. </paragraph>
<paragraph id="P-0180" lvl="0"><number>&lsqb;0180&rsqb;</number> At step <highlight><bold>2706</bold></highlight>, the user&apos;s profile is collected and analyzed to identify or select the topic(s) of interest. In this case, the topic is turkey dinners or recipes, as specified in the user profile or determined by an inference engine. At step <highlight><bold>2709</bold></highlight>, the user&apos;s other preferences are considered. Referring back to Table 1, in the second example, the user specifies a preferred time for receiving the media content as being one week prior to Thanksgiving and Christmas. </paragraph>
<paragraph id="P-0181" lvl="0"><number>&lsqb;0181&rsqb;</number> As discussed, the user may also indicate a preferred duration or file size. For example, if requesting a collection of on-demand video of cooking programs, the user may specify the compiled production to average one hour. If the user has adequate storage capacity on the client display device, the user may specify file size. Other preferences can be indicated as stated above. </paragraph>
<paragraph id="P-0182" lvl="0"><number>&lsqb;0182&rsqb;</number> At step <highlight><bold>2712</bold></highlight>, the user&apos;s profile is executed to select media matching the user&apos;s interests. As described herein, the media includes video, text articles, web sites, merchandising, audio feeds, etc. The selected media is assembled and compiled for transmission. </paragraph>
<paragraph id="P-0183" lvl="0"><number>&lsqb;0183&rsqb;</number> At step <highlight><bold>2715</bold></highlight>, the media production is transmitted to the user&apos;s client as described above. The media production is transmitted at the designated time and format specified by the user. In the second example shown in Table 1, the production is delivered one week before Thanksgiving and Christmas. After the customized media presentation has been transmitted, the control flow ends as indicated at step <highlight><bold>2795</bold></highlight>. </paragraph>
<paragraph id="P-0184" lvl="0"><number>&lsqb;0184&rsqb;</number> A fourth example of a control flow for customizing a production is shown in <cross-reference target="DRAWINGS">FIG. 28</cross-reference>. Referring to <cross-reference target="DRAWINGS">FIG. 28</cross-reference>, flowchart <highlight><bold>2800</bold></highlight> represents the general operational flow of another embodiment of the present invention. More specifically, flowchart <highlight><bold>2800</bold></highlight> shows an example of customizing a production based on the third topic shown in Table 1. </paragraph>
<paragraph id="P-0185" lvl="0"><number>&lsqb;0185&rsqb;</number> The control flow of flowchart <highlight><bold>2800</bold></highlight> begins at step <highlight><bold>2801</bold></highlight> and passes immediately to step <highlight><bold>2803</bold></highlight>. At step <highlight><bold>2803</bold></highlight>, a user profile is established to designate topics related to children parties and/or gifts. For example, a parent, school official, or other individual may have interests in planning an upcoming event for a child&apos;s birthday, recital, batmitzvah, or the like. The individual may be interested in gift ideas, decorations, hiring clowns, etc. As described above, the user can specifically indicate an interest in this topic, or an inference engine or the like can consider the user&apos;s demographic, psychographic, or behavioral patterns to infer an interest in this topic. </paragraph>
<paragraph id="P-0186" lvl="0"><number>&lsqb;0186&rsqb;</number> At step <highlight><bold>2806</bold></highlight>, the user&apos;s profile is collected and analyzed to identify or select the topic(s) of interest. In this case, the topic is parties and/or gifts for children, as specified in the user profile or determined by an inference engine. At step <highlight><bold>2809</bold></highlight>, the user&apos;s other preferences are considered. Referring back to Table 1, in the third example, the user specifies a preferred time for receiving the media content as being two weeks prior to a child&apos;s birthday and Christmas. If using the present invention for multiple children, the user would designate the birthday for each child. The user can also tailor the profile for the specific interests, preferences, age, gender, or the like, for each child. For example, one child may prefer video games, a second child may prefer musical instruments, a third child may prefer nineteenth century American literature, a fourth child may prefer camping or gaming, etc. </paragraph>
<paragraph id="P-0187" lvl="0"><number>&lsqb;0187&rsqb;</number> As discussed, the user may also indicate a preferred duration or file size. Other preferences can be indicated as stated above. </paragraph>
<paragraph id="P-0188" lvl="0"><number>&lsqb;0188&rsqb;</number> At step <highlight><bold>2812</bold></highlight>, the user&apos;s profile is executed to select media matching the user&apos;s interests. As described herein, the media includes video, text articles, web sites, merchandising, audio feeds, etc. The selected media is assembled and compiled for transmission. </paragraph>
<paragraph id="P-0189" lvl="0"><number>&lsqb;0189&rsqb;</number> At step <highlight><bold>2815</bold></highlight>, the media production is transmitted to the user&apos;s client as described above. The media production is transmitted at the designated time and format specified by the user. In the third example shown in Table 1, the production is delivered two weeks before a child&apos;s birthday and Christmas. After the customized media presentation has been transmitted, the control flow ends as indicated at step <highlight><bold>2895</bold></highlight>. </paragraph>
<paragraph id="P-0190" lvl="0"><number>&lsqb;0190&rsqb;</number> A fifth example of a control flow for customizing a production is shown in <cross-reference target="DRAWINGS">FIG. 29</cross-reference>. Referring to <cross-reference target="DRAWINGS">FIG. 29</cross-reference>, flowchart <highlight><bold>2900</bold></highlight> represents the general operational flow of another embodiment of the present invention. More specifically, flowchart <highlight><bold>2900</bold></highlight> shows an example of customizing a production based on the fourth topic shown in Table 1. </paragraph>
<paragraph id="P-0191" lvl="0"><number>&lsqb;0191&rsqb;</number> The control flow of flowchart <highlight><bold>2900</bold></highlight> begins at step <highlight><bold>2901</bold></highlight> and passes immediately to step <highlight><bold>2903</bold></highlight>. At step <highlight><bold>2903</bold></highlight>, a user profile is established to designate topics related to family activities. As described above, the user can specifically indicate an interest in this topic so that the present invention can be implemented to help plan for future events and/or activities. Alternatively, an inference engine or the like can consider the user&apos;s demographic, psychographic, or behavioral patterns to infer an interest in this topic. </paragraph>
<paragraph id="P-0192" lvl="0"><number>&lsqb;0192&rsqb;</number> At step <highlight><bold>2906</bold></highlight>, the user&apos;s profile is collected and analyzed to identify or select the topic(s) of interest. In this case, the topic is family activities, as specified in the user profile or determined by an inference engine. At step <highlight><bold>2909</bold></highlight>, the user&apos;s other preferences are considered. Referring back to Table 1, in the fourth example, the user specifies a preferred time for receiving the media content as being every Friday evening. </paragraph>
<paragraph id="P-0193" lvl="0"><number>&lsqb;0193&rsqb;</number> As discussed, the user may also indicate a preferred duration, file size or other preferences, as stated above. For example, if the user has expressed an interest in receiving on-demand video of movies or television programs, the user can set limitations on the length of the movie or rating time (e.g., G, PG-13, R, etc.). The user can request the video to be downloaded to a storage device for family viewing. For example, the user may specify certain formats for video (e.g., avi), text (e.g., html), audio (e.g., wav format), images (e.g., bmp), or the like. </paragraph>
<paragraph id="P-0194" lvl="0"><number>&lsqb;0194&rsqb;</number> At step <highlight><bold>2912</bold></highlight>, the user&apos;s profile is executed to select media matching the user&apos;s interests. As described herein, the media includes video, text articles, web sites, merchandising, audio feeds, etc. The selected media is assembled and compiled for transmission. </paragraph>
<paragraph id="P-0195" lvl="0"><number>&lsqb;0195&rsqb;</number> At step <highlight><bold>2915</bold></highlight>, the media production is transmitted to the user&apos;s client as described above. The media production is transmitted at the designated time and format specified by the user. In the fourth example shown in Table 1, the production is delivered every Friday evening. After the customized media presentation has been transmitted, the control flow ends as indicated at step <highlight><bold>2995</bold></highlight>. </paragraph>
<paragraph id="P-0196" lvl="0"><number>&lsqb;0196&rsqb;</number> A sixth example of a control flow for customizing a production is shown in <cross-reference target="DRAWINGS">FIG. 30</cross-reference>. Referring to <cross-reference target="DRAWINGS">FIG. 30</cross-reference>, flowchart <highlight><bold>3000</bold></highlight> represents the general operational flow of another embodiment of the present invention. More specifically, flowchart <highlight><bold>3000</bold></highlight> shows an example of customizing a production based on the fifth topic shown in Table 1. </paragraph>
<paragraph id="P-0197" lvl="0"><number>&lsqb;0197&rsqb;</number> The control flow of flowchart <highlight><bold>3000</bold></highlight> begins at step <highlight><bold>3001</bold></highlight> and passes immediately to step <highlight><bold>3003</bold></highlight>. At step <highlight><bold>3003</bold></highlight>, a user profile is established to designate topics related to local teams, or a specified local or national team, such as the Florida State University Seminoles or the Washington Redskins. As described above, the user can specifically indicate an interest in this topic, or an inference engine or the like can consider the user&apos;s demographic, psychographic, or behavioral patterns to infer an interest in this topic. </paragraph>
<paragraph id="P-0198" lvl="0"><number>&lsqb;0198&rsqb;</number> At step <highlight><bold>3006</bold></highlight>, the user&apos;s profile is collected and analyzed to identify or select the topic(s) of interest. In this case, the topic is local or specified teams, as specified in the user profile or determined by an inference engine. At step <highlight><bold>3009</bold></highlight>, the user&apos;s other preferences are considered. Referring back to Table 1, in the fifth example, the user specifies a preferred time for receiving the media content as being one hour before every game. The user can enter the game schedule, or the present invention can obtain the schedule from a search engine or the like, such as a resource available through the Internet. </paragraph>
<paragraph id="P-0199" lvl="0"><number>&lsqb;0199&rsqb;</number> As discussed, the user may also indicate a preferred duration, file size, or other preferences. At step <highlight><bold>3012</bold></highlight>, the user&apos;s profile is executed to select media matching the user&apos;s interests. As described herein, the media includes video, text articles, web sites, merchandising, audio feeds, etc. The selected media is assembled and compiled for transmission. </paragraph>
<paragraph id="P-0200" lvl="0"><number>&lsqb;0200&rsqb;</number> At step <highlight><bold>3015</bold></highlight>, the media production is transmitted to the user&apos;s client as described above. The media production is transmitted at the designated time and format specified by the user. In the fifth example shown in Table 1, the production is delivered one hour before an upcoming game. After the customized media presentation has been transmitted, the control flow ends as indicated at step <highlight><bold>3095</bold></highlight>. </paragraph>
<paragraph id="P-0201" lvl="0"><number>&lsqb;0201&rsqb;</number> A seventh example of a control flow for customizing a production is shown in <cross-reference target="DRAWINGS">FIG. 31</cross-reference>. Referring to <cross-reference target="DRAWINGS">FIG. 31</cross-reference>, flowchart <highlight><bold>3100</bold></highlight> represents the general operational flow of another embodiment of the present invention. More specifically, flowchart <highlight><bold>3100</bold></highlight> shows an example of customizing a production based on the sixth topic shown in Table 1. </paragraph>
<paragraph id="P-0202" lvl="0"><number>&lsqb;0202&rsqb;</number> The control flow of flowchart <highlight><bold>3100</bold></highlight> begins at step <highlight><bold>3101</bold></highlight> and passes immediately to step <highlight><bold>3103</bold></highlight>. At step <highlight><bold>3103</bold></highlight>, a user profile is established to designate topics related the user&apos;s calendar. The user can expressly opt to have topics derived from the user&apos;s calendar. Alternatively, the present invention can automatically implement this embodiment. Accordingly, an inference engine or the like automatically parses the user&apos;s calendar to process information in the calendar events, appointments, tasks, etc. Keywords are selected from the parsed information, such as &ldquo;New York.&rdquo; Additionally, the user&apos;s demographic, psychographic, or behavioral patterns are analyzed from the calendar to infer an interest in one or more topic(s). For example, if the user has scheduled a significant quantity of lunch meetings, an interest in restaurants can be inferred. In another example, if the user receives a substantial quantity of email from educational institutions, an interest in education and training can be inferred. </paragraph>
<paragraph id="P-0203" lvl="0"><number>&lsqb;0203&rsqb;</number> At step <highlight><bold>3106</bold></highlight>, the user&apos;s profile is collected and analyzed to identify or select the topic(s) of interest. In this case, the topic is &ldquo;New York,&rdquo; as inferred from parsing the calendar. At step <highlight><bold>3109</bold></highlight>, the user&apos;s other preferences are considered, if designated. As discussed, such preferences include media type, format, duration, etc. The present invention may automatically execute this embodiment on a periodically scheduled basis, such as daily, weekly, or bi-monthly. </paragraph>
<paragraph id="P-0204" lvl="0"><number>&lsqb;0204&rsqb;</number> At step <highlight><bold>3112</bold></highlight>, the user&apos;s profile is executed to select media matching the user&apos;s interests. As described herein, the media includes video, text articles, web sites, merchandising, audio feeds, etc. The selected media is assembled and compiled for transmission. </paragraph>
<paragraph id="P-0205" lvl="0"><number>&lsqb;0205&rsqb;</number> At step <highlight><bold>3115</bold></highlight>, the media production is transmitted to the user&apos;s client as described above. The media production is transmitted at the designated time and format specified by the user, if specified. Otherwise, a default setting is implemented. After the customized media presentation has been transmitted, the control flow ends as indicated at step <highlight><bold>3195</bold></highlight>. </paragraph>
<paragraph id="P-0206" lvl="7"><number>&lsqb;0206&rsqb;</number> V. System Overview of Enhanced Media Production and Distribution </paragraph>
<paragraph id="P-0207" lvl="0"><number>&lsqb;0207&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates a block diagram of an enhanced media production and distribution system <highlight><bold>900</bold></highlight> (herein referred to as &ldquo;system <highlight><bold>900</bold></highlight>&rdquo;) useful for implementing an embodiment of the present invention. System <highlight><bold>900</bold></highlight> includes an enhanced media server <highlight><bold>915</bold></highlight> and one or more enhanced media clients <highlight><bold>920</bold></highlight>. In an embodiment, enhanced media server <highlight><bold>915</bold></highlight> provides web pages for a hosting portal, homepage, or web site. The operator of the portal is a local television, radio station, newspaper, webcasting station, or other media &ldquo;hosting&rdquo; environment. </paragraph>
<paragraph id="P-0208" lvl="0"><number>&lsqb;0208&rsqb;</number> A network infrastructure <highlight><bold>910</bold></highlight> provides a medium for communication among enhanced media server <highlight><bold>915</bold></highlight> and enhanced media clients <highlight><bold>920</bold></highlight>. Network infrastructure <highlight><bold>910</bold></highlight> includes wired and/or wireless local area networks (LAN) or wide area networks (WAN), such as an organization&apos;s intranet, a local internet, the global-based Internet (including the World Wide Web (WWW)), an extranet, a virtual private network, licensed wireless telecommunications spectrum for digital cell (including CDMA, TDMA, GSM, EDGE, GPRS, CDMA2000, WCDMA FDD and/or TDD or TD-SCDMA technologies), or the like. Network infrastructure <highlight><bold>910</bold></highlight> includes wired, wireless, or both transmission media, including satellite, terrestrial (e.g., fiber optic, copper, coaxial, hybrid fiber-coaxial (HFC), or the like), radio, microwave, and/or any other form or method of transmission. </paragraph>
<paragraph id="P-0209" lvl="0"><number>&lsqb;0209&rsqb;</number> Each enhanced media client <highlight><bold>920</bold></highlight> is a personal computer, personal digital assistant (PDA), telephone, television, MP3 player, or other device operable for wired or wireless exchanges over network infrastructure <highlight><bold>910</bold></highlight>. Enhanced media clients <highlight><bold>920</bold></highlight> include a display having the ability to select one or more media segments. In an embodiment, enhanced media client <highlight><bold>920</bold></highlight> is located in an automobile, and can be a MP3 stereo or personal computer with a hard drive or flash data storage memory and capable of downloading music or music video files. Moreover, the user of an enhanced media client <highlight><bold>920</bold></highlight> includes human operators requesting a web page from enhanced media server <highlight><bold>915</bold></highlight> over the Internet, or another web site host, television or radio broadcaster, or the like. </paragraph>
<paragraph id="P-0210" lvl="0"><number>&lsqb;0210&rsqb;</number> Enhanced media server <highlight><bold>915</bold></highlight> is connected to a streaming server <highlight><bold>925</bold></highlight>, information management (IM) server <highlight><bold>930</bold></highlight>, and advertisement server <highlight><bold>935</bold></highlight>. Streaming server <highlight><bold>925</bold></highlight> supports live and on-demand streaming functionality of system <highlight><bold>900</bold></highlight>. Streaming server <highlight><bold>925</bold></highlight> transmits media streams by interacting with media encoding system <highlight><bold>940</bold></highlight>, media production system <highlight><bold>945</bold></highlight>, media production information management system (IMS) <highlight><bold>950</bold></highlight>, extended-media encoding system <highlight><bold>955</bold></highlight>, and extended-media IMS <highlight><bold>960</bold></highlight>. Streaming server <highlight><bold>925</bold></highlight> and enhanced media server <highlight><bold>915</bold></highlight> are configurable to provide continuous, seamless streams for real-time or near-term presentations, as well as download data files to enhanced media client <highlight><bold>920</bold></highlight> for delayed playback. The media streams can either be continuous as represented by a complete show broadcast over traditional mediums, or modified according to the interests of the user of enhanced media client <highlight><bold>920</bold></highlight>, reassembled and streamed in the new configuration. In either case, the streaming process only requires a single download, buffering and playout process. In another embodiment, it is contemplated that for on-demand requests, that a user (client) can schedule the request in advance, have the media files transferred or expedited (FTP or some other file transfer technology) for local storage on the client ready for playout upon user access and/or request. </paragraph>
<paragraph id="P-0211" lvl="0"><number>&lsqb;0211&rsqb;</number> IM server <highlight><bold>930</bold></highlight> is an indexing system that enables the other system components to query system <highlight><bold>900</bold></highlight> for data and metadata. For example, enhanced media server <highlight><bold>915</bold></highlight> is operable to query IM server <highlight><bold>930</bold></highlight> for the location or filename of a specific video segment. The query results from IM server <highlight><bold>930</bold></highlight> are communicated to streaming server <highlight><bold>925</bold></highlight> which, in turn, locates the requested video segment for transmission to the requesting enhanced media client <highlight><bold>920</bold></highlight>. </paragraph>
<paragraph id="P-0212" lvl="0"><number>&lsqb;0212&rsqb;</number> Finally, advertisement server <highlight><bold>935</bold></highlight> is connected to an advertising administration system <highlight><bold>965</bold></highlight> and an advertisement (AD) IMS <highlight><bold>970</bold></highlight>. Advertisement server <highlight><bold>935</bold></highlight> provides advertisements (such as, commercials in audio or video format, banners, active media, or the like) that are integrated into a media stream (e.g., video segment) requested by an online user. As described in detail below, advertisements can be requested by any of the other system components and integrated into a media stream at any point in the media production process. </paragraph>
<paragraph id="P-0213" lvl="0"><number>&lsqb;0213&rsqb;</number> Enhanced media server <highlight><bold>915</bold></highlight> commands and controls the operational capabilities of system <highlight><bold>900</bold></highlight>. As a result, enhanced media server <highlight><bold>915</bold></highlight> functions as a portal to process or service requests for media produced or archived within system <highlight><bold>900</bold></highlight>. Enhanced media server <highlight><bold>915</bold></highlight> also implements policies and rules to enforce security protocols to protect system and data integrity, including user authentication, user roles, or the like. </paragraph>
<paragraph id="P-0214" lvl="0"><number>&lsqb;0214&rsqb;</number> In an embodiment, enhanced media server <highlight><bold>915</bold></highlight> or at least one of its supporting system components (i.e., streaming server <highlight><bold>925</bold></highlight>, IM server <highlight><bold>930</bold></highlight>, advertisement server <highlight><bold>935</bold></highlight>, media encoding system <highlight><bold>940</bold></highlight>, media production system <highlight><bold>945</bold></highlight>, etc.) is located at the facilities of a local television, radio station, newspaper, webcasting station, or other media hosting environment. However, enhanced media server <highlight><bold>915</bold></highlight> or at least one of its supporting system components can also be remotely located and configured to communicate with a television or radio station functioning as a content source. In other embodiments, enhanced media server <highlight><bold>915</bold></highlight> or at least one of its supporting system components are locally or remotely positioned at a private residence, place of business, educational institution, government agency, or the like, and utilized for media production and network distribution. </paragraph>
<paragraph id="P-0215" lvl="0"><number>&lsqb;0215&rsqb;</number> The system components are operable to query and write to various archival and retrieval systems, such as media production IMS <highlight><bold>950</bold></highlight>, extended-media IMS <highlight><bold>960</bold></highlight>, and advertisement IMS <highlight><bold>970</bold></highlight>. In an embodiment, a media production is stored in an archival and retrieval system after the content is created or retrieved, and labeled (if not properly marked with a content production code, URL, or the like). The archival and retrieval system can include a secondary memory (such as, secondary memory <highlight><bold>1010</bold></highlight> described with reference to <cross-reference target="DRAWINGS">FIG. 10</cross-reference> below). To support larger volumes of content, one or more integrated databases or a data warehouse system is used to store the content to support the respective server as described herein. In an embodiment, the archival and retrieval system includes a relational or object oriented (OO)/component based database management system (not shown), or the like, that controls the storing, retrieving and updating of data and metadata in the database records. The database management system also controls data integration, enforces integrity rules and constraints (including data integrity and referential integrity), and enforces security constraints. </paragraph>
<paragraph id="P-0216" lvl="0"><number>&lsqb;0216&rsqb;</number> The archival and retrieval system is a scalable system that stores data on multiple disk arrays. Data warehousing can be implemented with the SQL Server 2000 application available from Microsoft Corporation, the Oracle 9i&trade; database available from Oracle Corporation (Redwood City, Calif.), or the like. The archival and retrieval system supports Open DataBase Connectivity (ODBC) or Java DataBase Connectivity (JDBC) protocols. </paragraph>
<paragraph id="P-0217" lvl="0"><number>&lsqb;0217&rsqb;</number> The archival and retrieval system can be centrally located or a widely distributed system. In an embodiment, one or more components of the archival and retrieval system are located at the same facilities of the querying system. In another embodiment, one or more components of the archival and retrieval system are located at the facilities of the originator of the content. Accordingly, the querying system component (e.g., media production system <highlight><bold>945</bold></highlight>) requests the content (e.g., video of a news story) by a content production code, URL, or the like. In another embodiment, one or more components of the archival and retrieval system is located or managed by a third party. Therefore, the content originator would send or license the content to the third party, and the querying system component (e.g., media production system <highlight><bold>945</bold></highlight>) would request the content by using the content production code, URL, or the like. </paragraph>
<paragraph id="P-0218" lvl="0"><number>&lsqb;0218&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> represents a conceptual illustration of system <highlight><bold>900</bold></highlight> to allow a structural explanation of the present invention. That is, one or more of the blocks can be performed by the same piece of hardware or module of software. It should also be understood that embodiments of the present invention can be implemented in hardware, software, firmware, or a combination thereof. In such an embodiment, the various components and steps would be implemented in hardware, firmware, and/or software to perform the functions of the present invention. </paragraph>
<paragraph id="P-0219" lvl="0"><number>&lsqb;0219&rsqb;</number> In an embodiment, each server within system <highlight><bold>900</bold></highlight> represents one or more computers providing various shared resources with each other and to the other network computers. In another embodiment, a single computer functions as all servers in system <highlight><bold>900</bold></highlight>, and provides various shared resources to the other network computers (e.g., enhanced media client <highlight><bold>920</bold></highlight>). In another embodiment, only server <highlight><bold>915</bold></highlight> is a single computer providing shared resources. As apparent to one skilled in the relevant art(s), other system components of system <highlight><bold>900</bold></highlight> can be combined or separated, and are considered to be within the scope of the present invention. </paragraph>
<paragraph id="P-0220" lvl="0"><number>&lsqb;0220&rsqb;</number> The shared resources include files for programs, web pages, databases and libraries; output devices, such as, printers, plotters, display monitors and facsimile machines; and communications devices, such as modems and Internet access facilities. The communications devices can support wired or wireless communications, including satellite, terrestrial (fiber optic, copper, coaxial, and the like), radio, microwave and any other form or method of transmission. </paragraph>
<paragraph id="P-0221" lvl="0"><number>&lsqb;0221&rsqb;</number> In an embodiment, each server is configured to support the standard Internet Protocol (IP) developed to govern communications over public and private Internet backbones. The protocol is defined in Internet Standard (STD) 5, Request for Comments (RFC) 791 (Internet Architecture Board). The servers also support transport protocols, such as, Transmission Control Protocol (TCP), User Datagram Protocol (UDP), Real Time Transport Protocol (RTP), or Resource Reservation Protocol (RSVP). The transport protocols support various types of data transmission standards, such as File Transfer Protocol (FTP), Hypertext Transfer Protocol (HTTP), Simple Network Management Protocol (SNMP), Network Time Protocol (NTP), or the like. </paragraph>
<paragraph id="P-0222" lvl="0"><number>&lsqb;0222&rsqb;</number> In an embodiment, each server is configured to support various operating systems, such as, the Netware&trade; operating system available from Novell, Inc. (Provo, Utah); the MS-DOS&reg;, Windows NT&reg; and Windows&reg; 3.xx/95/98/2000 operating systems available from Microsoft Corporation; the Linux&reg; operating system available from Linux Online Inc. (Laurel, Md.); the Solaris&trade; operating system available from Sun Microsystems, Inc. (Palo Alto, Calif.); or the like as would be apparent to one skilled in the relevant art(s). </paragraph>
<paragraph id="P-0223" lvl="0"><number>&lsqb;0223&rsqb;</number> Additionally, the present invention (e.g., system <highlight><bold>900</bold></highlight> or any part thereof) can be implemented in one or more computer systems or other processing systems. In fact, in an embodiment, the invention is directed toward one or more computer systems capable of carrying out the functionality described herein. </paragraph>
<paragraph id="P-0224" lvl="0"><number>&lsqb;0224&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, an example computer system <highlight><bold>1000</bold></highlight> useful in implementing the present invention is shown. The computer system <highlight><bold>1000</bold></highlight> includes one or more processors, such as processor <highlight><bold>1004</bold></highlight>. The processor <highlight><bold>1004</bold></highlight> is connected to a communication infrastructure <highlight><bold>1006</bold></highlight> (e.g., a communications bus, crossover bar, or network). Various software embodiments are described in terms of this exemplary computer system. After reading this description, it will become apparent to one skilled in the relevant art(s) how to implement the invention using other computer systems and/or computer architectures. </paragraph>
<paragraph id="P-0225" lvl="0"><number>&lsqb;0225&rsqb;</number> Computer system <highlight><bold>1000</bold></highlight> can include a display interface <highlight><bold>1002</bold></highlight> that forwards graphics, text, and other data from the communication infrastructure <highlight><bold>1006</bold></highlight> (or from a frame buffer not shown) for display on the display unit <highlight><bold>1030</bold></highlight>. </paragraph>
<paragraph id="P-0226" lvl="0"><number>&lsqb;0226&rsqb;</number> Computer system <highlight><bold>1000</bold></highlight> also includes a main memory <highlight><bold>1008</bold></highlight>, preferably random access memory (RAM), and can also include a secondary memory <highlight><bold>1010</bold></highlight>. The secondary memory <highlight><bold>1010</bold></highlight> can include, for example, a hard disk drive <highlight><bold>1012</bold></highlight> and/or a removable storage drive <highlight><bold>1014</bold></highlight>, representing a floppy disk drive, a magnetic tape drive, an optical disk drive, etc. The removable storage drive <highlight><bold>1014</bold></highlight> reads from and/or writes to a removable storage unit <highlight><bold>1018</bold></highlight> in a well-known manner. Removable storage unit <highlight><bold>1018</bold></highlight>, represents a floppy disk, magnetic tape, optical disk, etc. which is read by and written to removable storage drive <highlight><bold>1014</bold></highlight>. As will be appreciated, the removable storage unit <highlight><bold>1018</bold></highlight> includes a computer usable storage medium having stored therein computer software and/or data. </paragraph>
<paragraph id="P-0227" lvl="0"><number>&lsqb;0227&rsqb;</number> In alternative embodiments, secondary memory <highlight><bold>1010</bold></highlight> can include other similar means for allowing computer programs or other instructions to be loaded into computer system <highlight><bold>1000</bold></highlight>. Such means can include, for example, a removable storage unit <highlight><bold>1022</bold></highlight> and an interface <highlight><bold>1020</bold></highlight>. Examples of such can include a program cartridge and cartridge interface (such as that found in video game devices), a removable memory chip (such as an EPROM, or PROM) and associated socket, and other removable storage units <highlight><bold>1022</bold></highlight> and interfaces <highlight><bold>1020</bold></highlight> which allow software and data to be transferred from the removable storage unit <highlight><bold>1022</bold></highlight> to computer system <highlight><bold>1000</bold></highlight>. </paragraph>
<paragraph id="P-0228" lvl="0"><number>&lsqb;0228&rsqb;</number> Computer system <highlight><bold>1000</bold></highlight> can also include a communications interface <highlight><bold>1024</bold></highlight>. Communications interface <highlight><bold>1024</bold></highlight> allows software and data to be transferred between computer system <highlight><bold>1000</bold></highlight> and external devices. Examples of communications interface <highlight><bold>1024</bold></highlight> can include a modem, a network interface (such as an Ethernet card), a communications port, a PCMCIA slot and card, etc. Software and data transferred via communications interface <highlight><bold>1024</bold></highlight> are in the form of signals <highlight><bold>1028</bold></highlight> which can be electronic, electromagnetic, optical, or other signals capable of being received by communications interface <highlight><bold>1024</bold></highlight>. These signals <highlight><bold>1028</bold></highlight> are provided to communications interface <highlight><bold>1024</bold></highlight> via a communications path (i.e., channel) <highlight><bold>1026</bold></highlight>. This channel <highlight><bold>1026</bold></highlight> carries signals <highlight><bold>1028</bold></highlight> and can be implemented using wire or cable, fiber optics, a phone line, a cellular phone link, an RF link, and other communications channels. </paragraph>
<paragraph id="P-0229" lvl="0"><number>&lsqb;0229&rsqb;</number> In this document, the terms &ldquo;computer program medium&rdquo; and &ldquo;computer usable medium&rdquo; are used to generally refer to media such as removable storage drive <highlight><bold>1014</bold></highlight>, a hard disk installed in hard disk drive <highlight><bold>1012</bold></highlight>, and signals <highlight><bold>1028</bold></highlight>. These computer program products are means for providing software to computer system <highlight><bold>1000</bold></highlight>. The invention is directed to such computer program products. </paragraph>
<paragraph id="P-0230" lvl="0"><number>&lsqb;0230&rsqb;</number> Computer programs (also called computer control logic) are stored in main memory <highlight><bold>1008</bold></highlight> and/or secondary memory <highlight><bold>1010</bold></highlight>. Computer programs can also be received via communications interface <highlight><bold>1024</bold></highlight>. Such computer programs, when executed, enable the computer system <highlight><bold>1000</bold></highlight> to perform the features of the present invention as discussed herein. In particular, the computer programs, when executed, enable the processor <highlight><bold>1004</bold></highlight> to perform the features of the present invention. Accordingly, such computer programs represent controllers of the computer system <highlight><bold>1000</bold></highlight>. </paragraph>
<paragraph id="P-0231" lvl="0"><number>&lsqb;0231&rsqb;</number> In an embodiment where the invention is implemented using software, the software can be stored in a computer program product and loaded into computer system <highlight><bold>1000</bold></highlight> using removable storage drive <highlight><bold>1014</bold></highlight>, hard drive <highlight><bold>1012</bold></highlight> or communications interface <highlight><bold>1024</bold></highlight>. The control logic (software), when executed by the processor <highlight><bold>1004</bold></highlight>, causes the processor <highlight><bold>1004</bold></highlight> to perform the functions of the invention as described herein. </paragraph>
<paragraph id="P-0232" lvl="0"><number>&lsqb;0232&rsqb;</number> In another embodiment, the invention is implemented primarily in hardware using, for example, hardware components such as application specific integrated circuits (ASICs). Implementation of the hardware state machine so as to perform the functions described herein will be apparent to one skilled in the relevant art(s). </paragraph>
<paragraph id="P-0233" lvl="0"><number>&lsqb;0233&rsqb;</number> In yet another embodiment, the invention is implemented using a combination of both hardware and software. </paragraph>
<paragraph id="P-0234" lvl="7"><number>&lsqb;0234&rsqb;</number> VI. Enhanced Media Production and Storage </paragraph>
<paragraph id="P-0235" lvl="0"><number>&lsqb;0235&rsqb;</number> As discussed, the present invention supports live and on-demand distribution of media productions over a widely distributed computer network. In an embodiment, present invention is configurable to receive, generate, or transmit media productions from a variety of sources. Referring back to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, media production system <highlight><bold>945</bold></highlight> is one media source for system <highlight><bold>900</bold></highlight>. Media production system <highlight><bold>945</bold></highlight> is representative of a manual multimedia production environment, or an automated multimedia production system, as discussed above with reference to FIGS. <highlight><bold>1</bold></highlight>-<highlight><bold>5</bold></highlight>. The application entitled &ldquo;Method, System and Computer Program Product for Producing and Distributing Enhanced Media Downstreams&rdquo; (U.S. patent application Ser. No. 09/836,239) describes representative embodiments of manual and automated multimedia production systems that are implementable with the present invention, and are incorporated herein. </paragraph>
<paragraph id="P-0236" lvl="0"><number>&lsqb;0236&rsqb;</number> In an automated multimedia production environment, a media production processing device, such as media production system <highlight><bold>945</bold></highlight>, automatically or semi-automatically commands and controls the operation of a variety of media production devices in analog and/or digital video environments. The term &ldquo;media production device&rdquo; includes video switcher, digital video effects device (DVE), audio mixer, teleprompting system, video cameras and robotics (for pan, tilt, zoom, focus, and iris control), record/playback device (RPD), character generator, still store, studio lighting devices, news automation devices, master control/media management automation systems, commercial insertion devices, compression/decompression devices (codec), virtual sets, or the like. The term &ldquo;RPD&rdquo; includes VTRs, video recorders/servers (e.g., media production IMS <highlight><bold>950</bold></highlight>), virtual recorder (VR), digital audio tape (DAT) recorder, or any mechanism that stores, records, generates or plays back via magnetic, optical, electronic, or any other storage media. In an embodiment, the media production processing device receives and routes live feeds (such as, field news reports, news services, sporting events, or the like) from any type of communications source, including satellite, terrestrial (e.g., fiber optic, copper, coaxial, HFC, or the like), radio, microwave, or any other form or method of video transmission, in lieu of, or in addition to, producing a live show within a studio. </paragraph>
<paragraph id="P-0237" lvl="0"><number>&lsqb;0237&rsqb;</number> In addition to controlling media production devices, an automated media production processing device is configurable to convert an electronic show rundown (e.g., show rundown <highlight><bold>2402</bold></highlight>) into computer readable broadcast instructions to automate the execution of a show without the need of an expensive production crew to control the media production devices. As previously discussed, in an embodiment, the broadcast instructions are created from the Transition Macro&trade; multimedia production control program developed by ParkerVision, Inc. </paragraph>
<paragraph id="P-0238" lvl="0"><number>&lsqb;0238&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> illustrates an embodiment of an object-oriented, electronic show rundown (e.g., show rundown <highlight><bold>2402</bold></highlight>) created by an event-driven application on a graphical user interface (GUI) <highlight><bold>1100</bold></highlight>. The electronic rundown includes a horizontal timeline <highlight><bold>1102</bold></highlight> and one or more horizontal control lines <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>p</italic></highlight>. Automation control icons <highlight><bold>1106</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>are positioned onto control lines <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>p </italic></highlight>at various locations relative to timeline <highlight><bold>1102</bold></highlight>, and configured to be associated with one or more media production commands and at least one media production device. </paragraph>
<paragraph id="P-0239" lvl="0"><number>&lsqb;0239&rsqb;</number> A timer (not shown) is integrated into timeline <highlight><bold>1102</bold></highlight>, and operable to activate a specific automation control icon <highlight><bold>1106</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>as a timer indicator <highlight><bold>1108</bold></highlight> travels across timeline <highlight><bold>1102</bold></highlight> to reach a location linked to the specific automation control icon <highlight><bold>1106</bold></highlight>. As a result, media production processing device would execute the media production commands to operate the associated media production device. </paragraph>
<paragraph id="P-0240" lvl="0"><number>&lsqb;0240&rsqb;</number> In regards to automation control icons <highlight><bold>1106</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>t</italic></highlight>, label icon <highlight><bold>1106</bold></highlight><highlight><italic>a </italic></highlight>permits a director to name one or more elements, segments, or portions of the electronic rundown. In embodiment, the director would drag and drop a label icon <highlight><bold>1106</bold></highlight><highlight><italic>a </italic></highlight>onto control line <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>, and double click on the positioned label icon <highlight><bold>1106</bold></highlight><highlight><italic>a </italic></highlight>to open up a dialogue box to enter a text description. The text would be displayed on the positioned label icon <highlight><bold>1106</bold></highlight><highlight><italic>a</italic></highlight>. Referring to <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, exemplary label icons <highlight><bold>1106</bold></highlight><highlight><italic>a </italic></highlight>have been generated to designate &ldquo;A01,&rdquo; &ldquo;CUE,&rdquo; &ldquo;OPEN,&rdquo; &ldquo;A02,&rdquo; etc. </paragraph>
<paragraph id="P-0241" lvl="0"><number>&lsqb;0241&rsqb;</number> Control line <highlight><bold>1104</bold></highlight><highlight><italic>a </italic></highlight>is also operable to receive a step mark icon <highlight><bold>1106</bold></highlight><highlight><italic>b</italic></highlight>, a general purpose input/output (GPI/O) mark icon <highlight><bold>1106</bold></highlight><highlight><italic>c</italic></highlight>, a user mark icon <highlight><bold>1106</bold></highlight><highlight><italic>d</italic></highlight>, and an encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e</italic></highlight>. Encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>is described in detail below with reference to <cross-reference target="DRAWINGS">FIG. 13</cross-reference>. Step mark icon <highlight><bold>1106</bold></highlight><highlight><italic>b </italic></highlight>and GPI/O mark icon <highlight><bold>1106</bold></highlight><highlight><italic>c </italic></highlight>are associated with rundown step commands. The rundown step commands instruct timer indicator <highlight><bold>1108</bold></highlight> to start or stop running until deactivated or reactivated by the director or another media production device. For example, step mark icon <highlight><bold>1106</bold></highlight><highlight><italic>b </italic></highlight>and GPI/O mark icon <highlight><bold>1106</bold></highlight><highlight><italic>c </italic></highlight>can be placed onto control line <highlight><bold>1104</bold></highlight><highlight><italic>a </italic></highlight>to specify a time when timer indicator <highlight><bold>1108</bold></highlight> would automatically stop running. In other words, timer indicator <highlight><bold>1108</bold></highlight> would stop moving across timeline <highlight><bold>1102</bold></highlight> without the director having to manually stop the process, or without another device (e.g., a teleprompting system (not shown)) having to transmit a timer stop command. If a step mark icon <highlight><bold>1106</bold></highlight><highlight><italic>b </italic></highlight>is activated to stop timer indicator <highlight><bold>1108</bold></highlight>, timer indicator <highlight><bold>1108</bold></highlight> can be restarted either manually by the director or automatically by another external device transmitting a step command. If a GPI/O mark icon <highlight><bold>1106</bold></highlight><highlight><italic>c </italic></highlight>is used to stop timer indicator <highlight><bold>1108</bold></highlight>, timer indicator <highlight><bold>1108</bold></highlight> can be restarted by a GPI or GPO device transmitting a GPI/O signal. </paragraph>
<paragraph id="P-0242" lvl="0"><number>&lsqb;0242&rsqb;</number> In an embodiment, step mark icon <highlight><bold>1106</bold></highlight><highlight><italic>b </italic></highlight>and GPI/O mark icon <highlight><bold>1106</bold></highlight><highlight><italic>c </italic></highlight>are used to place a logically break between two elements on the electronic rundown. In other words, step mark icon <highlight><bold>1106</bold></highlight><highlight><italic>b </italic></highlight>and GPI/O mark icon <highlight><bold>1106</bold></highlight><highlight><italic>c </italic></highlight>are placed onto control line <highlight><bold>1140</bold></highlight><highlight><italic>a </italic></highlight>to designate segments within a media production. One or more configuration files can also be associated with a step mark icon <highlight><bold>1106</bold></highlight><highlight><italic>b </italic></highlight>and GPI/O mark icon <highlight><bold>1106</bold></highlight><highlight><italic>c </italic></highlight>to link metadata with the designated segment. </paragraph>
<paragraph id="P-0243" lvl="0"><number>&lsqb;0243&rsqb;</number> Transition icons <highlight><bold>1106</bold></highlight><highlight><italic>f</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>g </italic></highlight>are associated with automation control commands for controlling video switching equipment. Thus, transition icons <highlight><bold>1106</bold></highlight><highlight><italic>f</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>g </italic></highlight>can be positioned onto control lines <highlight><bold>1104</bold></highlight><highlight><italic>b</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>c </italic></highlight>to control one or more devices to implement a variety of transition effects or special effects into a media production. Such transition effects include, but are not limited to, fades, wipes, DVE, downstream keyer (DSK) effects, and the like. DVE includes, but is not limited to, warps, dual-box effects, page turns, slab effects, and sequences. DSK effects include DVE and DSK linear, chroma and luma keyers. </paragraph>
<paragraph id="P-0244" lvl="0"><number>&lsqb;0244&rsqb;</number> Keyer control icon <highlight><bold>1106</bold></highlight><highlight><italic>h </italic></highlight>is positioned on control line <highlight><bold>1104</bold></highlight><highlight><italic>d</italic></highlight>, and used to prepare and execute keyer layers either in linear, luma, chroma or a mix thereof for preview or program output. The keyers can be upstream or downstream of the DVE. </paragraph>
<paragraph id="P-0245" lvl="0"><number>&lsqb;0245&rsqb;</number> Audio icon <highlight><bold>1106</bold></highlight><highlight><italic>i </italic></highlight>can be positioned onto control line <highlight><bold>1104</bold></highlight><highlight><italic>e </italic></highlight>and is associated with commands for controlling audio equipment, such as audio mixers, digital audio tape (DAT), cassette equipment, other audio sources (e.g., CDs and DATs), and the like. Teleprompter icon <highlight><bold>1106</bold></highlight><highlight><italic>j </italic></highlight>can be positioned onto control line <highlight><bold>1104</bold></highlight><highlight><italic>f </italic></highlight>and is associated with commands for controlling a teleprompting system to integrate a script into the timeline. Character generator (CG) icon <highlight><bold>1106</bold></highlight><highlight><italic>k </italic></highlight>can be positioned onto control line <highlight><bold>1104</bold></highlight><highlight><italic>g </italic></highlight>and is associated with commands for controlling a CG or still store to integrate a CG page into the timeline. Camera icons <highlight><bold>1106</bold></highlight><highlight><italic>l</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>n </italic></highlight>can be positioned onto control lines <highlight><bold>1104</bold></highlight><highlight><italic>h</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>j </italic></highlight>and are associated with commands for controlling the movement and settings of one or more cameras. VTR icons <highlight><bold>1106</bold></highlight><highlight><italic>p</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>r </italic></highlight>can be positioned onto control lines <highlight><bold>1104</bold></highlight><highlight><italic>k</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>m </italic></highlight>and are associated with commands for controlling VTR settings and movement. GPO icon <highlight><bold>1106</bold></highlight><highlight><italic>s </italic></highlight>can be positioned onto control line <highlight><bold>1104</bold></highlight><highlight><italic>n </italic></highlight>and is associated with commands for controlling GPI or GPO devices. Encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>can be positioned onto control line <highlight><bold>1104</bold></highlight><highlight><italic>p </italic></highlight>and is associated with encoding commands which are described in detail below with respect to <cross-reference target="DRAWINGS">FIG. 15</cross-reference>. </paragraph>
<paragraph id="P-0246" lvl="0"><number>&lsqb;0246&rsqb;</number> User mark icon <highlight><bold>1106</bold></highlight><highlight><italic>d </italic></highlight>is provided to precisely associate or align one or more automation control icons <highlight><bold>1106</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>c </italic></highlight>and <highlight><bold>1104</bold></highlight><highlight><italic>e</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>t </italic></highlight>with a particular time value. For example, if a director desires to place teleprompter icon <highlight><bold>1106</bold></highlight><highlight><italic>j </italic></highlight>onto control line <highlight><bold>1104</bold></highlight><highlight><italic>f </italic></highlight>such that the timer value associated with teleprompter icon <highlight><bold>1106</bold></highlight><highlight><italic>j </italic></highlight>is exactly 10 seconds, the director would first drag and drop user mark icon <highlight><bold>1106</bold></highlight><highlight><italic>d </italic></highlight>onto control line <highlight><bold>1104</bold></highlight><highlight><italic>a </italic></highlight>at the ten second mark. The director would then drag and drop teleprompter icon <highlight><bold>1106</bold></highlight><highlight><italic>j </italic></highlight>onto the positioned user mark icon <highlight><bold>1106</bold></highlight><highlight><italic>d</italic></highlight>. Teleprompter icon <highlight><bold>1106</bold></highlight><highlight><italic>j </italic></highlight>is then automatically placed on control line <highlight><bold>1104</bold></highlight><highlight><italic>f </italic></highlight>such that the timer value associated with teleprompter icon <highlight><bold>1106</bold></highlight><highlight><italic>j </italic></highlight>is ten seconds. In short, any icon that is drag and dropped onto the user mark <highlight><bold>1106</bold></highlight><highlight><italic>d </italic></highlight>is automatically placed on the appropriate control line and has a timer value of ten seconds. This feature helps to provide multiple icons with the exact same timer value. </paragraph>
<paragraph id="P-0247" lvl="0"><number>&lsqb;0247&rsqb;</number> After the appropriate automation control icons <highlight><bold>1106</bold></highlight> have been properly position onto the electronic rundown, the electronic rundown can be stored in a file for later retrieval and modification. Accordingly, a show template or generic electronic rundown can be re-used to produce a variety of different shows. A director could recall the show template by filename, make any required modifications (according to a new electronic rundown), and save the electronic rundown with a new filename. </paragraph>
<paragraph id="P-0248" lvl="0"><number>&lsqb;0248&rsqb;</number> As described above, one media production device is a teleprompting system (not shown) that includes a processing unit and one or more displays for presenting a teleprompting script (herein referred to as &ldquo;script&rdquo;) to the talent. In an embodiment, the teleprompting system is the SCRIPT Viewer&trade;, available from ParkerVision, Inc. As described in the application entitled &ldquo;Method, System and Computer Program Product for Producing and Distributing Enhanced Media Downstreams&rdquo; (U.S. patent application Ser. No. 09/836,239), a teleprompting system can be used to create, edit, and run scripts of any length, at multiple speeds, in a variety of colors and fonts. In an embodiment of the present invention, the teleprompting system is operable to permit a director to use a text editor to insert media production commands into a script (herein referred to as &ldquo;script commands&rdquo;). The text editor can be a personal computer or like workstation, or the text editor can be an integrated component of electronic rundown GUI <highlight><bold>1100</bold></highlight>. Referring to <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, text window <highlight><bold>1110</bold></highlight> permits a script to be viewed, including script commands. Script controls <highlight><bold>1112</bold></highlight> are a set of graphical controls that enable a director to operate the teleprompting system and view changes in speed, font size, script direction and other parameters of the script in text window <highlight><bold>1110</bold></highlight>. </paragraph>
<paragraph id="P-0249" lvl="0"><number>&lsqb;0249&rsqb;</number> The script commands that can be inserted by the teleprompting system include a cue command, a delay command, a pause command, a rundown step command, and an enhanced media command. As discussed below, enhanced media commands permit the synchronization of auxiliary information to be linked for display or referenced with a script and video. This allows the display device to display streaming video, HTML or other format graphics, or related topic or extended-play URLs and data. The present invention is not limited to the aforementioned script commands. As would be apparent to one skilled in the relevant art(s), commands other than those just listed can be inserted into a script. </paragraph>
<paragraph id="P-0250" lvl="7"><number>&lsqb;0250&rsqb;</number> VII. Web Cast Production </paragraph>
<paragraph id="P-0251" lvl="0"><number>&lsqb;0251&rsqb;</number> As discussed, embodiments of the present invention are operable to receive, generate, or transmit media productions from a variety of sources over a widely diverse computer network. Referring back to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, in an embodiment, enhanced media server <highlight><bold>915</bold></highlight> supports client requests for on-demand and customizable broadcasts of a show or selected segments from a show. To enable this functionality, encoded metadata that is descriptive of the segments is created during a media production and saved in an archival and retrieval system (e.g., media production IMS <highlight><bold>950</bold></highlight>, extended-media IMS <highlight><bold>960</bold></highlight>, etc.) in real time. Subsequently, the video frames from a show can be retrieved by the associated metadata, such as the content production code (e.g., time code, frame code, or the like). </paragraph>
<paragraph id="P-0252" lvl="0"><number>&lsqb;0252&rsqb;</number> Referring back to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, an encoding process is implemented by media encoding system <highlight><bold>940</bold></highlight> or extended-media encoding system <highlight><bold>955</bold></highlight>. Irrespective of whether the content is prepared by manual or automated production techniques, media production system <highlight><bold>945</bold></highlight> or media production IMS <highlight><bold>950</bold></highlight> transmits the content to media encoding system <highlight><bold>940</bold></highlight> to be prepared for transmissions over network infrastructure <highlight><bold>910</bold></highlight>. Similarly, extended-media encoding system <highlight><bold>955</bold></highlight> operates to prepare extended-media content from extended-media IMS <highlight><bold>960</bold></highlight> for online transmissions. In an embodiment, media encoding system <highlight><bold>940</bold></highlight> and extended-media encoding system <highlight><bold>955</bold></highlight> use a serial digital interface (SDI) to receive the content. However, the present invention can also be implemented with composite, Y/C, RGB or component analog video or any other parallel interfacing. </paragraph>
<paragraph id="P-0253" lvl="0"><number>&lsqb;0253&rsqb;</number> In an embodiment, media encoding system <highlight><bold>940</bold></highlight> and extended-media encoding system <highlight><bold>955</bold></highlight> (collectively referred to as &ldquo;encoding system&rdquo;) multiplexes media content (e.g., video segment) and metadata into a single media stream. The extended-media encoding system <highlight><bold>955</bold></highlight> also provides a secondary encoder to enter additional source video and/or ad video or any other source that requires encoding while the media encoding system <highlight><bold>940</bold></highlight> is in operation. In an embodiment, the encoding system converts uncompressed video or audio data to compressed digital streams or files. The encoding system is configurable to compress video files (e.g., avi format), audio clips (e.g., wav format), and still images (e.g., bmp or jpg formats) into an MPEG format or the like. The encoding system is also configurable to re-encode an existing MPEG file, or the like, to modulate the file parameters (e.g., bit rate, video dimensions, frame rates, sampling rates, and the like). Finally, the encoding system can be configured to index or catalog the encoded media streams, or segments of the encoded media streams. Indexing or cataloging reduces the encoding processing time and memory requirements for future transmissions of the same streams. </paragraph>
<paragraph id="P-0254" lvl="0"><number>&lsqb;0254&rsqb;</number> As described above, the encoding system of the present invention is operable with both an automated and manually-operated configuration of media production system <highlight><bold>945</bold></highlight>. With both content sources, the encoding system formats the media content with timeline-based techniques or methodologies. </paragraph>
<paragraph id="P-0255" lvl="0"><number>&lsqb;0255&rsqb;</number> Referring back to <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, GUI <highlight><bold>1100</bold></highlight> illustrates an embodiment of an electronic rundown (e.g., rundown <highlight><bold>2404</bold></highlight>) that can be used to encode a media production from an automated environment. As discussed above, control lines <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>n </italic></highlight>contain automation control icons <highlight><bold>1106</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>s </italic></highlight>that are operable to automatically control media production devices and produce a video show. However, control lines <highlight><bold>1104</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>1104</bold></highlight><highlight><italic>p </italic></highlight>are used to enter encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t</italic></highlight>, respectively, that are associated with encoding commands. As timer indicator <highlight><bold>1108</bold></highlight> moves across timeline <highlight><bold>1102</bold></highlight>, the associated encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>send commands to the encoding system to format the media streams. </paragraph>
<paragraph id="P-0256" lvl="0"><number>&lsqb;0256&rsqb;</number> In an embodiment, a director can enter encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>onto control lines <highlight><bold>1104</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>1104</bold></highlight><highlight><italic>p</italic></highlight>, respectively, when the director uses media production system <highlight><bold>1145</bold></highlight> to place the other automation control icons <highlight><bold>1106</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>d </italic></highlight>and <highlight><bold>1106</bold></highlight><highlight><italic>f</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>s </italic></highlight>that are associated with other media production commands onto control lines <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>n</italic></highlight>. In another embodiment, a director can enter encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>after the media production has been completed and approved. In this embodiment, the director could use either media production system <highlight><bold>1145</bold></highlight> or media encoding system <highlight><bold>1140</bold></highlight> to enter encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t. </italic></highlight></paragraph>
<paragraph id="P-0257" lvl="0"><number>&lsqb;0257&rsqb;</number> Thus, the presence of encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and/or encode object <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>transforms GUI <highlight><bold>1100</bold></highlight> into an encoder rundown (e.g., show rundown <highlight><bold>2402</bold></highlight> or shadow rundown <highlight><bold>2404</bold></highlight>). Referring back to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, show rundown <highlight><bold>2402</bold></highlight> includes instructions (e.g., encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and/or encode object <highlight><bold>1106</bold></highlight><highlight><italic>t</italic></highlight>) for formatting a media steam for transmission (e.g., electronic show <highlight><bold>2408</bold></highlight>) over a computer network. In this embodiment, show rundown <highlight><bold>2402</bold></highlight> functions as an encoder rundown. Likewise, referring back to FIGS. <highlight><bold>3</bold></highlight>-<highlight><bold>5</bold></highlight>, shadow rundown <highlight><bold>2404</bold></highlight> includes instructions (e.g., encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and/or encode object <highlight><bold>1106</bold></highlight><highlight><italic>t</italic></highlight>) for formatting a media steam for transmission (e.g., electronic show <highlight><bold>2408</bold></highlight>) over a computer network. As such, shadow rundown <highlight><bold>2404</bold></highlight> also functions as an encoder rundown. </paragraph>
<paragraph id="P-0258" lvl="0"><number>&lsqb;0258&rsqb;</number> In an embodiment where encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and/or encode object <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>are not present, GUI <highlight><bold>1100</bold></highlight> is only an electronic rundown (e.g., show rundown <highlight><bold>2402</bold></highlight>) for automated media production. Referring back to FIGS. <highlight><bold>3</bold></highlight>-<highlight><bold>5</bold></highlight>, show rundown <highlight><bold>2402</bold></highlight> does not include instructions (e.g., encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and/or encode object <highlight><bold>1106</bold></highlight><highlight><italic>t</italic></highlight>) for formatting a media stream for transmission (e.g., electronic show <highlight><bold>2408</bold></highlight>) over a computer network. Show rundown <highlight><bold>2402</bold></highlight>, in these embodiments, only provide media production commands for producing traditional show <highlight><bold>2406</bold></highlight>. </paragraph>
<paragraph id="P-0259" lvl="0"><number>&lsqb;0259&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 12</cross-reference>, GUI <highlight><bold>1200</bold></highlight> illustrates another embodiment of an encoder rundown (e.g., shadow rundown <highlight><bold>2404</bold></highlight>) used to encode a media production from an automated environment. Control lines <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>n </italic></highlight>are enabled to receive automation control icons <highlight><bold>1106</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>s </italic></highlight>that are operable to automatically control media production devices and produce a video show. However, in embodiment, the encoder rundown (e.g., shadow rundown <highlight><bold>2404</bold></highlight>) is only used to encode the media production, and, therefore, most of control lines <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>n </italic></highlight>are inoperable. Nonetheless, control lines <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>n </italic></highlight>allows a web director to integrate and/or control auxiliary information associated with a media production. As shown, teleprompter icon <highlight><bold>1106</bold></highlight><highlight><italic>j </italic></highlight>can be positioned onto control line <highlight><bold>1104</bold></highlight><highlight><italic>f </italic></highlight>and enables a script to be linked to the media production to support captioning or like features. </paragraph>
<paragraph id="P-0260" lvl="0"><number>&lsqb;0260&rsqb;</number> Control lines <highlight><bold>1104</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>1104</bold></highlight><highlight><italic>p </italic></highlight>are available to receive encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t</italic></highlight>, respectively, that are associated with encoding commands. As described, each activated encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>and encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>send commands to the encoding system to format the media streams. </paragraph>
<paragraph id="P-0261" lvl="0"><number>&lsqb;0261&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> illustrates the top region of GUI <highlight><bold>1100</bold></highlight> or GUI <highlight><bold>1200</bold></highlight> (shown as GUI <highlight><bold>1300</bold></highlight>) to provide a view of control line <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>. Control line <highlight><bold>1104</bold></highlight><highlight><italic>a </italic></highlight>is used to enter icons <highlight><bold>1106</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1106</bold></highlight><highlight><italic>d </italic></highlight>that are associated with step commands and icon alignment commands, as discussed above. Another automation control icon that can be placed on control line <highlight><bold>1104</bold></highlight><highlight><italic>a </italic></highlight>is encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e</italic></highlight>. In an embodiment, encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>operates like a Web Mark&trade; developed by ParkerVision, Inc. During the encoding process, encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>identifies a distinct segment within a media production. As timer indicator <highlight><bold>1108</bold></highlight> advances beyond encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e</italic></highlight>, the encoding system is instructed to index the beginning of a new segment. In an embodiment, as the encoding process is executed, media encoding system <highlight><bold>940</bold></highlight> automatically clips the media production into separate files based on the placement of encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e</italic></highlight>. This facilitates the indexing, cataloging and future recall of segments identified by the encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e. </italic></highlight></paragraph>
<paragraph id="P-0262" lvl="0"><number>&lsqb;0262&rsqb;</number> In an embodiment, the properties of each encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>are established by activating encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>to open a configuration GUI. <cross-reference target="DRAWINGS">FIG. 14</cross-reference> illustrates an embodiment of an encode mark configuration GUI <highlight><bold>1400</bold></highlight>. GUI <highlight><bold>1400</bold></highlight> can be used to set the time for initiating the encoding commands associated with encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e</italic></highlight>. The time can be manually entered or is automatically entered at the time of placing encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>on control line <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>. GUI <highlight><bold>1400</bold></highlight> also permits an operator to designate a name for the segment, and specify the segment type classification. Segment type classification includes a major and minor classification. For example, a major classification or topic can be sports, weather, headline news, traffic, health watch, elections, and the like. Exemplary minor classifications or category can be local sports, college basketball, NFL football, high school baseball, local weather, national weather, local politics, local community issues, local crime, editorials, national news, and the like. Classifications can expand beyond two levels to an unlimited number of levels for additional granularity and resolution for segment type identification and advertisement targeting. In short, the properties associated with each encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>provide a set of metadata that can linked to a specific segment. These properties can be subsequently searched to identify or retrieve the segment from an archive. </paragraph>
<paragraph id="P-0263" lvl="0"><number>&lsqb;0263&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> illustrates the bottom region of GUI <highlight><bold>1100</bold></highlight> or GUI <highlight><bold>1200</bold></highlight> (shown as GUI <highlight><bold>1500</bold></highlight>) to provide a view of control line <highlight><bold>1104</bold></highlight><highlight><italic>p</italic></highlight>. Control line <highlight><bold>1104</bold></highlight><highlight><italic>p </italic></highlight>is used to enter icons automation control icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>that is associated with encoded transmission commands. The encoded transmission commands instructs the encoding system to start or stop the encoding process until deactivated or reactivated by an operator or another media production device. </paragraph>
<paragraph id="P-0264" lvl="0"><number>&lsqb;0264&rsqb;</number> Encode object icons <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>are placed on control line <highlight><bold>1104</bold></highlight><highlight><italic>p </italic></highlight>to produce encode objects. In an embodiment, encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>operates like Web Objects&trade; developed by from ParkerVision, Inc. <cross-reference target="DRAWINGS">FIG. 16</cross-reference> illustrates an embodiment of a configuration GUI <highlight><bold>1600</bold></highlight> that can be used to set the searchable properties of each encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t</italic></highlight>. In this embodiment, start stream object <highlight><bold>1602</bold></highlight>, data object <highlight><bold>1604</bold></highlight> and stream stop object <highlight><bold>1606</bold></highlight> are three types of encode object icons <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>that can be used. Start stream object <highlight><bold>1602</bold></highlight> initializes the encoding system and starts the encoding process. In comparison with encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e</italic></highlight>, start stream object <highlight><bold>1602</bold></highlight> instructs the encoding system to start the encoding process to identify a distinct show, whereas encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>instructs the encoding system to designate a portion of the media stream as a distinct segment. The metadata contained in start stream object <highlight><bold>1602</bold></highlight> is used to provide a catalog of available shows, and the metadata in encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>is used to provide a catalog of available show segments. </paragraph>
<paragraph id="P-0265" lvl="0"><number>&lsqb;0265&rsqb;</number> Data object <highlight><bold>1604</bold></highlight> is used to identify auxiliary information to be displayed with the media stream. As described in detail below, auxiliary information includes graphics or text in a HTML page and is referenced in GUI <highlight><bold>1600</bold></highlight> by its URL address. </paragraph>
<paragraph id="P-0266" lvl="0"><number>&lsqb;0266&rsqb;</number> Stream stop object <highlight><bold>1606</bold></highlight> is used to stop the encoding process and designate the end of a distinct show. Once timer indicator <highlight><bold>1108</bold></highlight> passes the stream stop object <highlight><bold>1606</bold></highlight>, the encoding system would start the post-production processes, such as, including indexing segments, cataloging segments, pacing script, and the like. </paragraph>
<paragraph id="P-0267" lvl="0"><number>&lsqb;0267&rsqb;</number> The encoding start and stop times can be manually entered into GUI <highlight><bold>1600</bold></highlight> or automatically updated upon placement of start stream object <highlight><bold>1602</bold></highlight>, data object <highlight><bold>1604</bold></highlight> or stop stream object <highlight><bold>1606</bold></highlight> onto control line <highlight><bold>1104</bold></highlight><highlight><italic>p</italic></highlight>. GUI <highlight><bold>1600</bold></highlight> also permits one to designate a show identifier, show name or description for the production. Other properties include the scheduled or projected air date and air time for the production. A copyright field is provided to specify any restrictions placed on the use or re-use of a specific show or show segment. For example, a broadcasting studio may not have a license to transmit a specific content on the Internet, but may have permission to provide the content over a private network or the airwaves, or vice versa. The content can be restricted for educational uses, single broadcast, transmissions to designated clients, or the like. In an embodiment, the appropriate component of system <highlight><bold>900</bold></highlight> (e.g., enhanced media server <highlight><bold>915</bold></highlight>, streaming server <highlight><bold>925</bold></highlight>, IM server <highlight><bold>930</bold></highlight>, etc.) verifies the copyright field prior to streaming the content to an enhanced media client <highlight><bold>920</bold></highlight>. </paragraph>
<paragraph id="P-0268" lvl="0"><number>&lsqb;0268&rsqb;</number> Referring back to <cross-reference target="DRAWINGS">FIG. 11</cross-reference> and <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, as timer indicator <highlight><bold>1108</bold></highlight> moves or passes over each encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>(i.e., start stream object <highlight><bold>1602</bold></highlight>, data object <highlight><bold>1604</bold></highlight>, or stop stream object <highlight><bold>1606</bold></highlight>), the associated encoding commands are automatically processed. However, the present invention enables an operator to manually alter the encoding process during execution. In particular, encoding control region <highlight><bold>1502</bold></highlight> provides a set of graphical controls that enable an operator to modify the encoding process. The encoding graphical controls include a ready control <highlight><bold>1504</bold></highlight>, start control <highlight><bold>1506</bold></highlight>, stop control <highlight><bold>1508</bold></highlight>, and data control <highlight><bold>1510</bold></highlight>. </paragraph>
<paragraph id="P-0269" lvl="0"><number>&lsqb;0269&rsqb;</number> Ready control <highlight><bold>1504</bold></highlight> has an &ldquo;activate&rdquo; state and &ldquo;de-activate&rdquo; state. As such, ready control <highlight><bold>1504</bold></highlight> is operable to send &ldquo;read&rdquo; or &ldquo;not read&rdquo; commands to timer indicator <highlight><bold>1108</bold></highlight> depending on whether ready control <highlight><bold>1504</bold></highlight> is operating in an activate or de-activate state, respectively. In an embodiment, when ready control <highlight><bold>1504</bold></highlight> is operating in an activate state, timer indicator <highlight><bold>1108</bold></highlight> signals the encoding system to read and process the associated encoding commands as timer indicator <highlight><bold>1108</bold></highlight> passes each encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>and encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e</italic></highlight>. Similarly, when deactivated, ready control <highlight><bold>1504</bold></highlight> instructs timer indicator <highlight><bold>1108</bold></highlight> to signal the encoding system to not read the encoding commands associated with each encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>and encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e</italic></highlight>. Therefore, when ready control <highlight><bold>1504</bold></highlight> is de-activated, ready control <highlight><bold>1504</bold></highlight> allows directors to perform test runs to preview a show prior to the broadcast. A preview mode is desirable to allow directors to check the show to make sure that the correct sources and transitions are selected. </paragraph>
<paragraph id="P-0270" lvl="0"><number>&lsqb;0270&rsqb;</number> Start control <highlight><bold>1506</bold></highlight> is used to initiate the encoding system manually. In an embodiment, start control <highlight><bold>1506</bold></highlight> is operable to manually override a deactivate state established by ready control <highlight><bold>1504</bold></highlight> or stop control <highlight><bold>1508</bold></highlight> (discussed below). Start control <highlight><bold>1506</bold></highlight> can be used to manually activate the encoding process to send media streams to streaming server <highlight><bold>925</bold></highlight> that contain time-sensitive production elements, such as a breaking news element, or other manually prepared media productions. </paragraph>
<paragraph id="P-0271" lvl="0"><number>&lsqb;0271&rsqb;</number> Stop control <highlight><bold>1508</bold></highlight> is operable to deactivate the encoding process and stop transmissions to streaming server <highlight><bold>925</bold></highlight>. Stop control <highlight><bold>1508</bold></highlight> would deactivate an encoding process initiated by either ready control <highlight><bold>1504</bold></highlight> or start control <highlight><bold>1506</bold></highlight>. Stop control <highlight><bold>1508</bold></highlight> provides directors with the ability to stop the encoding system manually to avoid airing any unauthorized content as an example. </paragraph>
<paragraph id="P-0272" lvl="0"><number>&lsqb;0272&rsqb;</number> Data control <highlight><bold>1510</bold></highlight> is used to enter auxiliary information and link the information to a specific segment or an entire show. The auxiliary information is entered by typing the URL reference in reference window <highlight><bold>1512</bold></highlight> and activating data control <highlight><bold>1510</bold></highlight>. Accordingly, auxiliary information can be entered via the configuration GUI <highlight><bold>1600</bold></highlight> for data object <highlight><bold>1604</bold></highlight> or reference window <highlight><bold>1512</bold></highlight>. Data control <highlight><bold>710</bold></highlight> enables directors to enter URLs at any time during manual operations. </paragraph>
<paragraph id="P-0273" lvl="0"><number>&lsqb;0273&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> illustrates another embodiment of an interactive electronic rundown GUI <highlight><bold>1700</bold></highlight> for encoding a media production. GUI <highlight><bold>1700</bold></highlight> is primarily configured to support a stand-alone embodiment for processing media produced from manual or conventional media production methodologies or techniques, but is also used in automated environments as an approval process to fine tune the beginning and end of segments. Additionally in an automated environment, GUI <highlight><bold>1700</bold></highlight> can be configured to add, delete or modify segments and links before preparing them for on-demand access. In either case, the media content does not need to be produced in an automated production environment. Even if the media is produced in an automated production environment, the encoding system can be implemented without the media production commands provided from control lines <highlight><bold>1104</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1104</bold></highlight><highlight><italic>n </italic></highlight>shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>. </paragraph>
<paragraph id="P-0274" lvl="0"><number>&lsqb;0274&rsqb;</number> Referring back to <cross-reference target="DRAWINGS">FIG. 17</cross-reference>, GUI <highlight><bold>1700</bold></highlight> includes a descriptive bar <highlight><bold>1702</bold></highlight>, horizontal timeline <highlight><bold>1102</bold></highlight>, timer indicator <highlight><bold>1108</bold></highlight>, and control lines <highlight><bold>1704</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>1704</bold></highlight><highlight><italic>b</italic></highlight>. Descriptive bar <highlight><bold>1702</bold></highlight> identifies specific segments of a media production. For example, if the media production is a newscast, each region within descriptive bar <highlight><bold>1702</bold></highlight> can be used to label each story or feature of the broadcast, such as finance, weather, sports, health watch, commercial advertisement, story 1, story 2, or the like. </paragraph>
<paragraph id="P-0275" lvl="0"><number>&lsqb;0275&rsqb;</number> An editor or director uses control line <highlight><bold>1704</bold></highlight><highlight><italic>a </italic></highlight>to place a segment mark icon <highlight><bold>1706</bold></highlight> (shown as <highlight><bold>1706</bold></highlight><highlight><italic>a </italic></highlight>and <highlight><bold>1706</bold></highlight><highlight><italic>b</italic></highlight>). Segment mark icon <highlight><bold>1706</bold></highlight> identifies the start of an element, segment, or show. By default, segment mark icon <highlight><bold>1706</bold></highlight> also identifies a stopping point for a respective element. Since these icons identify each element individually, they allow the editor or director to edit out any particular story, commercial, or the like. Segment mark icon <highlight><bold>1706</bold></highlight> is similar to encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>by being configurable to initiate encoding commands to designate a segment name, and specify a segment type classification. </paragraph>
<paragraph id="P-0276" lvl="0"><number>&lsqb;0276&rsqb;</number> Segment mark icon <highlight><bold>1706</bold></highlight> can also be used to cut, edit, or fragment a media production. When activated, segment mark icon <highlight><bold>1706</bold></highlight> instructs the encoding system to label and catalog the designated region of the media stream, so that a specific segment can be retrieved for future productions. Segment mark icon <highlight><bold>1706</bold></highlight> is also used to cut a segment prior to its actual completion. This can be used to remove unwanted portions of a segment. It can also be used to remove a segment portion to insert another video segment or commercial. </paragraph>
<paragraph id="P-0277" lvl="0"><number>&lsqb;0277&rsqb;</number> For example, descriptive bar <highlight><bold>1702</bold></highlight> show twelve news story elements (i.e., Story 1, Story 2, etc.) and four feature elements (i.e., Finance, Weather, etc.) from a previously broadcast or recorded news program. Segment icons <highlight><bold>1706</bold></highlight><highlight><italic>a </italic></highlight>designates the start and end points for each element. An editor or director preparing the program to be broadcast or re-broadcast would place segment icons <highlight><bold>1706</bold></highlight><highlight><italic>b </italic></highlight>at desired locations to insert, for example, a commercial feed or another story. In this example, segment icon <highlight><bold>1706</bold></highlight><highlight><italic>b </italic></highlight>would be used to cut Story 3, Story 6 and Story 10 at the indicated positions on the timeline. Hence, block <highlight><bold>1720</bold></highlight><highlight><italic>a </italic></highlight>designates the first section of the news program that precedes the first commercial feed inserted at block <highlight><bold>1720</bold></highlight><highlight><italic>b</italic></highlight>. Likewise, block <highlight><bold>1720</bold></highlight><highlight><italic>c </italic></highlight>designates the next section of the news program preceding the second commercial feed at <highlight><bold>1720</bold></highlight><highlight><italic>d</italic></highlight>, and so forth with respect to blocks <highlight><bold>1720</bold></highlight><highlight><italic>e</italic></highlight>, <highlight><bold>1720</bold></highlight><highlight><italic>f </italic></highlight>and <highlight><bold>1720</bold></highlight><highlight><italic>g</italic></highlight>. As intimated, the above example has been provided for illustrative purposes. As would be apparent to one skilled in the relevant art(s), other methodologies or techniques can be implemented to edit a media production and insert additional elements. For example, in lieu of cutting any portion of a video segment, the editor or director could shift the start or stop time for the respective element to make room for a new element (e.g., commercial) on the timeline. Additionally, the editor or director could adjust the properties defined by encode object <highlight><bold>1710</bold></highlight>. </paragraph>
<paragraph id="P-0278" lvl="0"><number>&lsqb;0278&rsqb;</number> Control line <highlight><bold>1704</bold></highlight><highlight><italic>b </italic></highlight>is used for the placement of encode object <highlight><bold>1710</bold></highlight>. Similar to start stream object <highlight><bold>1602</bold></highlight>, data object <highlight><bold>1604</bold></highlight>, and stop stream object <highlight><bold>1606</bold></highlight>, encode object <highlight><bold>1710</bold></highlight> is configurable to instruct the encoding system to integrate metadata with the associated media segment(s) to label and catalog a show and specify auxiliary information to be transmitted with the media segment(s). </paragraph>
<paragraph id="P-0279" lvl="0"><number>&lsqb;0279&rsqb;</number> GUI <highlight><bold>1700</bold></highlight> also includes graphical controls that enable an editor or director to control or reconfigure the encoding process. Ready control <highlight><bold>1504</bold></highlight>, start control <highlight><bold>1506</bold></highlight>, stop control <highlight><bold>1508</bold></highlight>, data control <highlight><bold>1510</bold></highlight>, and reference window <highlight><bold>1512</bold></highlight> have been described with reference to <cross-reference target="DRAWINGS">FIG. 15</cross-reference>. Approve control <highlight><bold>1712</bold></highlight> provides the director or editor with the ability to approve an encoded media production prior to being transmitted to streaming server <highlight><bold>925</bold></highlight>. </paragraph>
<paragraph id="P-0280" lvl="0"><number>&lsqb;0280&rsqb;</number> In an embodiment, GUI <highlight><bold>1700</bold></highlight> is a component of a video editing processor. As pre-recorded video is processed by the editing station, GUI <highlight><bold>1700</bold></highlight> is operable to mark, reformat and edit the video consistent with the encoding commands associated with the appropriate icons <highlight><bold>1706</bold></highlight>, <highlight><bold>1708</bold></highlight> and <highlight><bold>1710</bold></highlight>. As such, the encoding system of the present invention can be used to provide enhance media content to any media production regardless of its source. </paragraph>
<paragraph id="P-0281" lvl="0"><number>&lsqb;0281&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 18</cross-reference>, GUI <highlight><bold>1800</bold></highlight> is another embodiment of an interactive rundown (e.g., post-production editing and approval application file <highlight><bold>2409</bold></highlight>) encoding or editing encoded media productions. GUI <highlight><bold>1800</bold></highlight> includes a viewer <highlight><bold>1801</bold></highlight> that displays a media production during the encoding and post-production editing process. Viewer controls <highlight><bold>1808</bold></highlight> enables an operator to play, pause, stop, fast-forward, and/or rewind the production. In another embodiment, controls to &ldquo;skip&rdquo; to the next story or &ldquo;skip back&rdquo; to the previous story is provided. Text window <highlight><bold>1802</bold></highlight> displays various production and/or encoding commands as the operator reviews and edits the media production. Horizontal timeline <highlight><bold>1102</bold></highlight> interacts with viewer <highlight><bold>1801</bold></highlight>. As a media production is displayed on viewer <highlight><bold>1801</bold></highlight>, a timer (not shown) activates a timer indicator (not show) that travels across timeline <highlight><bold>1102</bold></highlight>. </paragraph>
<paragraph id="P-0282" lvl="0"><number>&lsqb;0282&rsqb;</number> GUI <highlight><bold>1800</bold></highlight> also includes an URL control line <highlight><bold>1804</bold></highlight>. An URL icon <highlight><bold>1811</bold></highlight> positioned on URL control line <highlight><bold>1804</bold></highlight> operates to synchronize and/or edit auxiliary information associated with the media production. If an encoder rundown (e.g., show rundown <highlight><bold>2402</bold></highlight> or shadow rundown <highlight><bold>2404</bold></highlight>), such as the electronic rundown shown in GUI <highlight><bold>1100</bold></highlight> or <highlight><bold>1200</bold></highlight>, is imported into GUI <highlight><bold>1800</bold></highlight>, URL icons <highlight><bold>1811</bold></highlight> are automatically positioned by the encoder rundown. However, an operator can alter the position of an icon by activating the icon to open a window or dragging-and-dropping the icon with an input device. </paragraph>
<paragraph id="P-0283" lvl="0"><number>&lsqb;0283&rsqb;</number> A script control line <highlight><bold>1805</bold></highlight> enables an operator to synchronize and/or edit script with a media production. In embodiment, a script icon (not shown) is positioned onto script control line <highlight><bold>1805</bold></highlight> to associate script with the media production. Script icons can be automatically positioned with an encoder rundown is imported, or positioned by an operator. An operator can also activate a script icon to read or edit portions of the script. An operator can add script to a media production if it was omitted during an initial encoding process. An operator can also delete the script, as appropriate. </paragraph>
<paragraph id="P-0284" lvl="0"><number>&lsqb;0284&rsqb;</number> A story control line <highlight><bold>1806</bold></highlight> provides a visual display of each story with a media production. Input control line <highlight><bold>1807</bold></highlight> provides a user-friendly indication of specific locations within a story. Input control line <highlight><bold>1807</bold></highlight> displays still images of the beginning of video frame at a designated location. A user can use viewer controls <highlight><bold>1808</bold></highlight> to play the production so as to identify where to start and stop a story element. At any time during the editing or encoding process, an operator can activate approve control <highlight><bold>1712</bold></highlight>, archive control <highlight><bold>1809</bold></highlight>, and/or cancel control <highlight><bold>1810</bold></highlight>. Approve control <highlight><bold>1712</bold></highlight> enables an operator to approve an encoded media production for archival. Archive control <highlight><bold>1809</bold></highlight> enables the media production to be archived for future recall. Cancel control <highlight><bold>1810</bold></highlight> deletes the media production and encoding instructions. </paragraph>
<paragraph id="P-0285" lvl="0"><number>&lsqb;0285&rsqb;</number> In an embodiment, an operator clicks and activates the image shown in input control line <highlight><bold>1807</bold></highlight> to perform various functions. For example, the operator can seek the beginning location of a video corresponding with the image shown in input control line <highlight><bold>1807</bold></highlight>. The beginning of the video would display in viewer <highlight><bold>1801</bold></highlight>. Similarly, the operator can seek the end location of a video corresponding with the image shown in input control line <highlight><bold>1807</bold></highlight>. The operator can also interact with GUI <highlight><bold>1800</bold></highlight> to synchronize an image displayed on viewer <highlight><bold>1801</bold></highlight> image with an image displayed by input control line <highlight><bold>1807</bold></highlight>, and vice versa. Upon synchronization, the operator can mark the synchronized images as being the end or beginning of an element. This feature is used to fragment a story element and to refine the start and end points of a story element. Accordingly, GUI <highlight><bold>1800</bold></highlight> permits an operator to edit and/or fragment stories into files for storage and on-demand recall. </paragraph>
<paragraph id="P-0286" lvl="0"><number>&lsqb;0286&rsqb;</number> As discussed in the above embodiment, to cut or fragment a media production, an operator manually enters a segment mark icon <highlight><bold>1706</bold></highlight> on GUI <highlight><bold>1700</bold></highlight>, or uses the seek and synchronize features of GUI <highlight><bold>1800</bold></highlight> to instruct the encoding system to fragment the media at the designated location. An embodiment of a fragmentation process used by the encoding system is shown in <cross-reference target="DRAWINGS">FIG. 19</cross-reference>. Flowchart <highlight><bold>1900</bold></highlight> represents an example of a control flow for fragmenting media productions according to the present invention. </paragraph>
<paragraph id="P-0287" lvl="0"><number>&lsqb;0287&rsqb;</number> The control flow of flowchart <highlight><bold>1900</bold></highlight> begins at step <highlight><bold>1901</bold></highlight> and passes immediately to step <highlight><bold>1904</bold></highlight>. At step <highlight><bold>1904</bold></highlight>, the encoding system uses a reader (not shown) to scan an input file that contains the media production. The encoding system also includes a timer (not shown) that is set at a start time (e.g., zero). From a beginning point within the file, the reader scans the media production until the reader detects the first keyframe used to designate a desired location for cutting. If no keyframe is detected, the control flow ends at step <highlight><bold>1995</bold></highlight>. The encoding system can be configured to repeat the scanning processes of step <highlight><bold>1904</bold></highlight> for a predetermined number of times or time period, prior to passing to step <highlight><bold>1995</bold></highlight>. </paragraph>
<paragraph id="P-0288" lvl="0"><number>&lsqb;0288&rsqb;</number> If a keyframe is detected, the control flow passes to step <highlight><bold>1908</bold></highlight>. At step <highlight><bold>1908</bold></highlight>, the reader suspends the scanning process and notes the keyframe time. The timer is also reset to the start time. </paragraph>
<paragraph id="P-0289" lvl="0"><number>&lsqb;0289&rsqb;</number> At step <highlight><bold>1912</bold></highlight>, the reader restarts at the beginning point within the media production and collects uncompressed media (e.g., video and/or audio) until the timer reaches the time noted as the keyframe time. </paragraph>
<paragraph id="P-0290" lvl="0"><number>&lsqb;0290&rsqb;</number> At step <highlight><bold>1916</bold></highlight>, the encoding system uses a writer (not shown) to write the uncompressed media (e.g., video and/or audio) through a codec device (not shown) for compression. </paragraph>
<paragraph id="P-0291" lvl="0"><number>&lsqb;0291&rsqb;</number> At step <highlight><bold>1920</bold></highlight>, the mode is changed to reconfigure the reader to return compressed media and the writer to not use the codec device. The new beginning point is designated as being the point after the keyframe. Afterwards, the control flow returns to step <highlight><bold>1904</bold></highlight> to repeat the fragmentation process until all keyframes have been detected. </paragraph>
<paragraph id="P-0292" lvl="0"><number>&lsqb;0292&rsqb;</number> The fragmentation method embodied by <cross-reference target="DRAWINGS">FIG. 19</cross-reference> produces a newly cut file with a keyframe at the start of the clip instead of using delta frames. Additionally, the present invention provides a method for minimizing the requirements for recompression, which in turn improves the quality of the production. Since the entire clip does not have to be recompressed, the fragmentation method of the present invention imparts a significant improvement over conventional video editing methodologies, because the present invention permits faster, real-time productions and allows the encoding system to insert better start and stop points between segments that enable near seamless smooth transitions. In addition, conventional systems perform editing functions on uncompressed video. The present invention encodes video into a streaming format first, then edits accordingly. </paragraph>
<paragraph id="P-0293" lvl="0"><number>&lsqb;0293&rsqb;</number> In an embodiment, the encoding process of the present invention is implemented at multiple simultaneous rates. For example, a media production can be encoded simultaneously at 56 kbps, 100 kbps and 300 kbps. Therefore, the fragmentation process described in <cross-reference target="DRAWINGS">FIG. 19</cross-reference> can be performed in parallel with other encoding processes. </paragraph>
<paragraph id="P-0294" lvl="7"><number>&lsqb;0294&rsqb;</number> VIII. Auxiliary Information </paragraph>
<paragraph id="P-0295" lvl="0"><number>&lsqb;0295&rsqb;</number> As discussed above, a media production can be formatted to include various types of auxiliary information. Accordingly, the media streams transmitted to a display device includes instructions to present auxiliary information along with the media production. The auxiliary information includes, but is not limited to, advertisements, graphics, extended play segments, polling data, URLs, articles, animations, documents, court rulings, other data, and the like. As a result, the present invention provides the user with a multimedia and interactive experience that extends beyond the capabilities of traditional and personal television. </paragraph>
<paragraph id="P-0296" lvl="0"><number>&lsqb;0296&rsqb;</number> 1. Advertisements </paragraph>
<paragraph id="P-0297" lvl="0"><number>&lsqb;0297&rsqb;</number> The present invention can be used to allow a broadcaster or other media hosting facility to automatically link advertisements to a specific show or show element/story by time, duration, and/or topic, or any other desired criteria. Advertisements include video or audio commercials; dynamic or static banners; sponsorship advertisements; pre-roll advertisements; active or passive advertisements; email correspondence, or like forms of media and multimedia promotions. </paragraph>
<paragraph id="P-0298" lvl="0"><number>&lsqb;0298&rsqb;</number> Video or audio commercials can be integrated into a media stream such that the commercial feed can be presented to the user while the user views the media production. For example, the commercial feed can be presented after one or more news stories, at the beginning of the media production, at the end, between scenes within a video production, or at any other place designated by the video director. </paragraph>
<paragraph id="P-0299" lvl="0"><number>&lsqb;0299&rsqb;</number> The advertisements also include banners. A banner includes any combination of text, graphics and other forms of media and multimedia that promotes a good or service, or otherwise provides information or an announcement. The banner can be strictly descriptive, or include hypertext, a hot spot, or a hyperlink to open additional banners, place an order, or send a request for additional information to the server of the host portal or another server. The banner can be a static banner that only displays the promotional advertisement. However, the banner can also be an active banner that blinks, spins, fades, and the like. The banner can also be a scrolling banner that includes a scroll bar that allows the user to move through contents of the banner. Resizable banners can also be used to allow the user to expand or enlarge the banner to receive more data. The aforementioned is a representative list of banners that can be used with the present invention, it should be understood that any other type of banner capable of promoting a product, including, but not limited to, banners developed with Macromedia&reg; Flash&trade; or Macromedia&reg; Shockwave&reg;, or the like, as would be apparent to one skilled in the relevant art(s), could be easily included and would not change the scope of the invention. </paragraph>
<paragraph id="P-0300" lvl="0"><number>&lsqb;0300&rsqb;</number> The advertisements can also be active or passive. An active advertisement requires interaction from the user, such as clicking-through, scrolling and the like. Passive advertisements are displayed and require no interaction from the user. Additionally, the advertisements can take the form of pre-roll advertisements. Such advertisements are commercials, banners, or the like that are transmitted to the display device prior to the startup-of the media production. </paragraph>
<paragraph id="P-0301" lvl="0"><number>&lsqb;0301&rsqb;</number> As such, the present invention supports all types of advertisements that can be transmitted over a client-server network to a display device. As a video show is being transmitted, the advertisements are streamed at specified intervals and durations with the video show. In an embodiment, the advertisements are presented on the side panels of the same frame or window in which the video show is displayed. In another embodiment, the advertisements are streamed in separate frames. In another embodiment, the advertisements are streamed prior to the display of the related segment video. The advertisements can also include a hyperlink to a web site for the sponsor of the advertisement. </paragraph>
<paragraph id="P-0302" lvl="0"><number>&lsqb;0302&rsqb;</number> In an embodiment, metadata associated with an advertisement includes a copyright field that specifies any restrictions placed on the use or re-use of an advertisement. For example, a media host may not have a license to transmit a specific content on the Internet, but may have permission to provide the content over a private network or the airwaves, or vice versa. The advertisement can be restricted for educational uses, single broadcast, transmissions to designated clients, or the like. </paragraph>
<paragraph id="P-0303" lvl="0"><number>&lsqb;0303&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, in an embodiment, media encoding system <highlight><bold>940</bold></highlight> queries advertising administration system <highlight><bold>965</bold></highlight> or AD server <highlight><bold>935</bold></highlight> to multiplex the advertisements with a media production. In another embodiment, streaming server <highlight><bold>925</bold></highlight> or enhanced media server <highlight><bold>915</bold></highlight> queries AD server <highlight><bold>935</bold></highlight> for an advertisement to be included with a media production. Thus, advertisements can be integrated into a media stream at any stage during media production. </paragraph>
<paragraph id="P-0304" lvl="0"><number>&lsqb;0304&rsqb;</number> Although either AD server <highlight><bold>935</bold></highlight> or advertising administration system <highlight><bold>965</bold></highlight> can manage the queries for advertisements from the other supporting system components, advertising administration system <highlight><bold>965</bold></highlight> is operable to create or edit advertisement media. Advertising administration system <highlight><bold>965</bold></highlight> can also be configured to format or encode the advertisements for transmissions. </paragraph>
<paragraph id="P-0305" lvl="0"><number>&lsqb;0305&rsqb;</number> AD IMS <highlight><bold>970</bold></highlight> interacts with advertising administration system <highlight><bold>965</bold></highlight>, and stores advertisements for future lookup and retrieval. AD IMS <highlight><bold>970</bold></highlight> is an archival and retrieval system similar to media production IMS <highlight><bold>950</bold></highlight> and extended-media IMS <highlight><bold>960</bold></highlight>. </paragraph>
<paragraph id="P-0306" lvl="0"><number>&lsqb;0306&rsqb;</number> Any ad developed with a hyperlink, can be &ldquo;clicked-on&rdquo; to request the advertiser&apos;s web page on the viewer browser. Browser activity on the viewer does not cause streaming to stop, pause or exit. The viewer remains active. If the user wants to browse the advertiser&apos;s web site, the player on the viewer provides for a pause control. A play control resumes the streaming process. </paragraph>
<paragraph id="P-0307" lvl="0"><number>&lsqb;0307&rsqb;</number> 2. Supporting Information </paragraph>
<paragraph id="P-0308" lvl="0"><number>&lsqb;0308&rsqb;</number> In addition to advertisements, the present invention includes various features that enhance the content of the media streams. Referring to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, in an embodiment, a video director or editor can operate media production system <highlight><bold>945</bold></highlight> or media encoding system <highlight><bold>940</bold></highlight> to link informative supporting media that enhances the related segment. In an embodiment, a separate frame is provided on a display for an enhanced media client <highlight><bold>920</bold></highlight> to present information, statistics, text, video, or like media or multimedia that are related to the media streams. For example, if a sports segment is being broadcast to show an interview of an athlete, in a separate frame, the current statistics for the interviewee can be presented for the user&apos;s perusal. Alternatively, the separate frame can include a menu of related data or web sites that online user can select. URL references can also be provided for the user to access, for example, more in-depth data. </paragraph>
<paragraph id="P-0309" lvl="0"><number>&lsqb;0309&rsqb;</number> In another embodiment, the informative supporting media or media enhancements includes captions or text corresponding to the segments as they are being viewed on enhanced media client <highlight><bold>920</bold></highlight>. Therefore, in an embodiment, a transcript of the segment is synchronized and displayed in a separate frame from the video presentation. In another embodiment, the captions are integrated into the media streams of the show segment and displayed in the same frame as the video. In an embodiment, the captions or text is created by a character generator associated with media production system <highlight><bold>945</bold></highlight>. In another embodiment, captions are generated by the teleprompting system (e.g., ParkerVision&apos;s SCRIPT Viewer&trade;). The captioning feature can be activated or de-activated as necessary. </paragraph>
<paragraph id="P-0310" lvl="0"><number>&lsqb;0310&rsqb;</number> 3. Extended Audio-Video </paragraph>
<paragraph id="P-0311" lvl="0"><number>&lsqb;0311&rsqb;</number> In an embodiment, the auxiliary information includes an extended audio or video segment (&ldquo;extended media&rdquo;). Extended media can be created and linked to a media productions in a variety of ways. For example, during an editing process, a video director or editor may decide to cut or fragment a show element. The element may be cut to save time or because of a breaking event that causes a change in the rundown. In such an event, the removed elements or a version of the element prior to editing is produced, encoded at, for example, extended-media encoding system <highlight><bold>955</bold></highlight> and stored in extended media IMS <highlight><bold>960</bold></highlight>. A link to the extended media allows an online user to select and view the extended media on demand. </paragraph>
<paragraph id="P-0312" lvl="0"><number>&lsqb;0312&rsqb;</number> Extended media also includes additional stories in text, audio or video format that are related to a particular media segment. For example, a show element can be a news story related to the PGA Players Championship tournament. Extended media for the news story can include text of par scores, video interview of a player, live audio of the tournament in progress, text article related to golfing equipment, schedule of upcoming tours, and the like. </paragraph>
<paragraph id="P-0313" lvl="0"><number>&lsqb;0313&rsqb;</number> 4. Opinion Research </paragraph>
<paragraph id="P-0314" lvl="0"><number>&lsqb;0314&rsqb;</number> In an embodiment, the present invention permits online polling or opinion gathering technologies to be integrated with a media production. The poll can be directed to the content of a specific show segment, a web page design for the hosting portal, preference for receiving advertisements, video presentation, and the like. For instance, in an embodiment, specific polls, surveys, and the like are created for specific show segments, and are cross-referenced and stored by the content production codes, URL, or the like identifying the show segments. When a show is assembled for broadcasts (live or on-demand), the appropriate poll is streamed at the designated interval with the related show segment. The poll can be presented on a display device in the same or a separate frame as discussed with regards to advertisements. During the broadcast, the portal&apos;s server receives the opinion data from the online users. In an embodiment, the opinion data is evaluated, and the results are returned to the display device in real time. In an embodiment, the portal&apos;s server provides the opinion results for an entire panel of respondents as well as the results for individual respondents. Reports can be generated and based on show, topic, advertiser, or the like for evaluation. </paragraph>
<paragraph id="P-0315" lvl="0"><number>&lsqb;0315&rsqb;</number> 5. Hyperlinks to Related Sites </paragraph>
<paragraph id="P-0316" lvl="0"><number>&lsqb;0316&rsqb;</number> In an embodiment, the present invention uses hyperlinks to provide media enhancements. Based on the content of a specific show segment, a URL, email, or geographical address of individuals or organizations related to a show segment is generated, cross-referenced and stored in the archival and retrieval system. The URL address also includes the web site for electronic bulletin boards. When a show is broadcast, this data is presented on the display device with the related show segment. Accordingly, an on-line user can activate a hyperlink to visit or send a message to the designated site or individual that is related to the show segment that is currently being viewed. The request for the referenced web site activates the web site on the viewer browser without impacting the current status of the viewer or player. </paragraph>
<paragraph id="P-0317" lvl="0"><number>&lsqb;0317&rsqb;</number> 6. Methods of Entering Auxiliary Information </paragraph>
<paragraph id="P-0318" lvl="0"><number>&lsqb;0318&rsqb;</number> The present invention is configured to utilize a variety of techniques or methodologies to link auxiliary information, including advertisements, to a media production. In an embodiment for linking auxiliary information, a director or editor enters an URL, file identifier, or like designator in a &ldquo;Web Link&rdquo; column of a news automation system (described below in <cross-reference target="DRAWINGS">FIG. 23</cross-reference> as Web Link Column <highlight><bold>2302</bold></highlight>). </paragraph>
<paragraph id="P-0319" lvl="0"><number>&lsqb;0319&rsqb;</number> A news automation system is a network of news production computers (not shown) within a newsroom environment. The news production computers are used to aggregate, edit, save or share news stories from a variety of sources among assignment editors, reporters, editors, producers and directors. The news sources include wire services or news services (such as, the Associated Press (AP), Konas and CNN services), police and fire information systems, and field reporters. A news automation system streamlines the show-building process and allows the producer or director to develop a rundown sheet and always know the status of stories during the rundown assembly process. As described above, companies such as iNEWS&trade; (i.e., the iNEWS&trade; news service available on the iNews.com web site), Newsmaker, Comprompter, or AP have developed news automation systems to manage the workflow processes associated with a newsroom operation. </paragraph>
<paragraph id="P-0320" lvl="0"><number>&lsqb;0320&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> illustrates a rundown GUI <highlight><bold>2300</bold></highlight> for a news automation system according to an embodiment of the present invention. Rundown GUI <highlight><bold>2300</bold></highlight> lists all of the show elements by line item. Page Column <highlight><bold>2304</bold></highlight> delineates a corresponding line-item designator for each element listed in rundown GUI <highlight><bold>2300</bold></highlight>. Each element is typically assigned a line-item, alpha-numeric designator such as A01, A02, A03, etc. Additionally, a newscast is typically assembled in blocks known as A, B, C and D blocks in a half-hour show. Thus, the first character in the line-item designator is used to identify a specific block. </paragraph>
<paragraph id="P-0321" lvl="0"><number>&lsqb;0321&rsqb;</number> Rundown GUI <highlight><bold>2300</bold></highlight> also includes one or more WEB Link columns <highlight><bold>2302</bold></highlight> for associating auxiliary information to an element. A director or producer would enter the URLs or like designator into WEB Link column <highlight><bold>2302</bold></highlight> by show element. For example, each element can be assigned a corresponding line-item, alpha-numeric designator such as A4, A3, and A5 (not shown) that may represent an &ldquo;intro,&rdquo; &ldquo;package,&rdquo; and &ldquo;tag,&rdquo; respectively, for a story. The producer or other responsible party can enter URL(s) within Web Link column <highlight><bold>2302</bold></highlight> for line A5 which is the &ldquo;tag&rdquo; or the end of the story. After the show has been executed and transmitted to an on-line user, the URL(s) would be presented on the display device during the &ldquo;tag&rdquo; section of the story. The URL(s) would, therefore, guide the user of the display device, for example, an extended play segment of the story. </paragraph>
<paragraph id="P-0322" lvl="0"><number>&lsqb;0322&rsqb;</number> Web segment classification column <highlight><bold>2308</bold></highlight> receives data from a standardized library of major and minor classifications. The standardized library helps keep all entries the same no matter who is entering the data. This library supports two separate applications. First, it supports the database organization of the lists that are presented to the viewer for selection by users. Second, it links the story to a category that allows the system to assign &ldquo;targeted&rdquo; ads. A numerical standard is used to prevent a broadcaster from making errors in spelling or terminology. The broadcaster can either enter the numerical identifier or select from a drop-down list. </paragraph>
<paragraph id="P-0323" lvl="0"><number>&lsqb;0323&rsqb;</number> Web effect column <highlight><bold>2306</bold></highlight> selects data from an established library of encoding acronyms. An encoding acronym identifies a specific file containing a &ldquo;group&rdquo; of commands that provides the post-production disposition instructions, including encoding instructions, for an element on a rundown. These commands would be entered on their respective control line(s) on an encoder rundown (such as, show rundown <highlight><bold>2402</bold></highlight> or shadow rundown <highlight><bold>2404</bold></highlight>). In an embodiment, this grouping of commands to represent an element or group of elements on an electronic rundown is implemented with the Transition Macro&trade; Element (TME) file developed by ParkerVision, Inc. Accordingly, TME acronyms identify TME files associated with commands that populates an encoder rundown GUI (such as GUI <highlight><bold>1100</bold></highlight>, <highlight><bold>1200</bold></highlight>, or <highlight><bold>1700</bold></highlight>) with the appropriate encoding instructions, as described above. </paragraph>
<paragraph id="P-0324" lvl="0"><number>&lsqb;0324&rsqb;</number> Provided below is an example of seven encoding acronyms (e.g., TME acronyms) that are implementable with the present invention for shadowing a newscast. The acronyms include &ldquo;Show Open,&rdquo; &ldquo;Break,&rdquo; &ldquo;Segment for Archive,&rdquo; &ldquo;Segment for Live Only,&rdquo; &ldquo;Open Segment for Archive,&rdquo; &ldquo;Open Segment for Live Only,&rdquo; and &ldquo;Script.&rdquo; </paragraph>
<paragraph id="P-0325" lvl="0"><number>&lsqb;0325&rsqb;</number> &ldquo;Show Open&rdquo; acronym is a two-step encoding acronym that first provides instructions to set a designated DVE to default values, video switcher to black on all busses, and audio mixer levels to a down position. The second step is initiated simultaneously with the start of the newscast. This step provides instructions for executing an encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>to start the encoding process. Encode mark <highlight><bold>1106</bold></highlight><highlight><italic>e </italic></highlight>is set automatically when the acronym is imported into the electronic rundown, or it can be set manually with a show template prior to initiating the second step of this encoding acronym. The instructions from this encoding acronym can be modified after importation to support live archival encoding. </paragraph>
<paragraph id="P-0326" lvl="0"><number>&lsqb;0326&rsqb;</number> &ldquo;Break&rdquo; acronym is a single-step encoding acronym that initiates a break sequence within the encoding process. When executed, the encoding instructions from this acronym effectively stop the live stream and replace it with a stream generated from the encoder, itself. In an embodiment, the encoder-generated stream includes predefined video advertisements that have been created, sold, and/or trafficked for webcasting. </paragraph>
<paragraph id="P-0327" lvl="0"><number>&lsqb;0327&rsqb;</number> &ldquo;Segment for Archive&rdquo; acronym is a single-step encoding acronym that provides instructions to signal the encoder that material from this point is to be archived. In an embodiment, the encoding instructions also signal the encoder to classify the newscast from this point into a defined major and/or minor classification. This encoding acronym includes instructions for positioning an encode object icon <highlight><bold>1106</bold></highlight><highlight><italic>t </italic></highlight>to auto-populate the major and/or minor classification field upon importation into the electronic rundown. </paragraph>
<paragraph id="P-0328" lvl="0"><number>&lsqb;0328&rsqb;</number> &ldquo;Segment for Live Only&rdquo; acronym is a single-step encoding acronym that provides instructions to signal the encoder that material from this point is not to be archived. This encoding acronym is used to designate non-archival events of the newscast such as, opens, tags, teases, banter, etc. This encoding acronym can also be used to block copyright material from being archived. This acronym differs from the &ldquo;Break&rdquo; encoding acronym that the stream is still being web cast and not replaced with an alternate media source. </paragraph>
<paragraph id="P-0329" lvl="0"><number>&lsqb;0329&rsqb;</number> &ldquo;Open Segment for Archive&rdquo; acronym is a single-step encoding acronym that is identical to the &ldquo;Segment for Archive&rdquo; acronym with the exception that it must be used after a &ldquo;Break&rdquo; acronym. The reason is to initiate the video switcher to encode the newscast media from an alternate video ad media source. </paragraph>
<paragraph id="P-0330" lvl="0"><number>&lsqb;0330&rsqb;</number> &ldquo;Open Segment for Live Only&rdquo; acronym is a single-step encoding acronym that is identical to the &ldquo;Segment Live Only&rdquo; acronym with the exception that it must be used after a &ldquo;Break&rdquo; acronym. The reason is to initiate the video switcher to encode the newscast media from an alternate video ad media source. </paragraph>
<paragraph id="P-0331" lvl="0"><number>&lsqb;0331&rsqb;</number> &ldquo;Script&rdquo; acronym is a single-step encoding acronym that is used when multiple scripts are being used within one of the aforementioned live or archive &ldquo;Segment&rdquo; acronyms. This encoding acronym contains instructions for placing control icons to append a next script and to play that script. </paragraph>
<paragraph id="P-0332" lvl="0"><number>&lsqb;0332&rsqb;</number> The aforementioned encoding acronyms have been described by way of example and not of limitation. Other acronyms can be prepared and practiced with the present invention as would be apparent to one skilled in the relevant art(s). </paragraph>
<paragraph id="P-0333" lvl="0"><number>&lsqb;0333&rsqb;</number> When the encoding instructions of rundown GUI <highlight><bold>2300</bold></highlight> is imported into an encoder rundown, the encoder rundown pulls in the encoding acronyms (e.g., TME acronyms), Web Segment Type, and Web URLs, along with Script having embedded script commands such as URLs. In an embodiment, rundown GUI <highlight><bold>2300</bold></highlight> is configured to be automatically converted into a set of computer readable broadcast instructions. In an embodiment, the set of broadcast instructions is created from the Transition Macro&trade; event-driven application program as described in commonly assigned U.S. patent Ser. No. 09/822,855, filed Apr. 2, 2001, by Holtz et al., and entitled &ldquo;Method, System and Computer Program Product for Full News Integration and Automation in a Real Time Video Production Environment&rdquo; (herein referred to as &ldquo;the &apos;855 application&rdquo;). The disclosure of the &apos;855 application is incorporated herein by reference as though set forth in its entirety. </paragraph>
<paragraph id="P-0334" lvl="0"><number>&lsqb;0334&rsqb;</number> The present invention encompasses other methodologies or techniques for linking auxiliary information. In another embodiment, auxiliary information is entered in the script pertaining to a specific element. As discussed above, the present invention includes a teleprompting system (not shown) that permits an operator to enter various script commands. One type of script command is an enhanced media command that instructs a system component (such as, media production system <highlight><bold>945</bold></highlight> or media encoding system <highlight><bold>940</bold></highlight>) to integrate media enhancements into a media production. As shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference> for example, auxiliary information, such as a URL reference or other identifier, can be embedded into a script that is sent to media encoding system <highlight><bold>940</bold></highlight> and viewable on text window <highlight><bold>1110</bold></highlight>. </paragraph>
<paragraph id="P-0335" lvl="0"><number>&lsqb;0335&rsqb;</number> Script integration of media enhancements improves the timing pace that auxiliary information is displayed on a display device because script integration is a real-time synchronous method to link objects with video when the talent is reading about the specific topic that the object references. For example, the talent may be reading a financial report about two separate companies. When discussing Company A performance, a graphic object with the companies stock or financial data can be displayed synchronized with the video. When Company B is discussed, the object changes to reflect Company B data. In this example, the director does not step into another segment to trigger an object, but the topic changes while the talent remains on the program output. In this application, script commands offer better control and synchronization. </paragraph>
<paragraph id="P-0336" lvl="0"><number>&lsqb;0336&rsqb;</number> Accordingly, in an embodiment, a teleprompting system sends messages (i.e., script commands) directly to an encoder that formats media productions to be transmitted over a computer network (i.e., network infrastructure <highlight><bold>910</bold></highlight>), but does not necessarily initiates the encoding process. The teleprompting system sends script text to the encoder for captioning and/or full text indexing. The teleprompting system is also configurable to send URL links or the like. Sending URL links from the teleprompting system is especially important for timing data window transitions (that can be viewed in text window <highlight><bold>1110</bold></highlight>) with scripts if the talent video shot does not transition. In other words, if a topic changes without a video transition during a media production, then an URL associated with the topic can be triggered via a script command. The script command is inserted in the script that the talent is reading to time the data window content (i.e., the text being read by the talent as it rolls in text window <highlight><bold>1110</bold></highlight>) to the topic. </paragraph>
<paragraph id="P-0337" lvl="0"><number>&lsqb;0337&rsqb;</number> On the other hand, if a video transition is required when a topic changes, the URL associated with the topic is triggered from a media production command integrated within an electronic rundown. Thus, in another embodiment, media enhancements are entered via an interactive electronic rundown such as GUI <highlight><bold>1100</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>. As discussed, GUI <highlight><bold>1100</bold></highlight> supports two methods for linking enhanced media to a media production. One method pertains to the placement of icons <highlight><bold>1106</bold></highlight> (namely, data objects <highlight><bold>1604</bold></highlight>) onto control line <highlight><bold>1104</bold></highlight><highlight><italic>p</italic></highlight>. As described with reference to <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, GUI <highlight><bold>1600</bold></highlight> permits an operator to configure data object <highlight><bold>1604</bold></highlight> to include various properties, including links to enhanced media. A reference field (not shown) is included in GUI <highlight><bold>1600</bold></highlight> to permit an operator to enter a file identifier, URL data, or the like for the enhanced media. </paragraph>
<paragraph id="P-0338" lvl="0"><number>&lsqb;0338&rsqb;</number> In another embodiment, media enhancements are linked to a media production directly from a field provided on an interactive electronic rundown, such as GUI <highlight><bold>1100</bold></highlight>. As discussed with reference to <cross-reference target="DRAWINGS">FIG. 15</cross-reference>, data control <highlight><bold>1510</bold></highlight> is used to enter auxiliary information and link the information to a specific segment or an entire show. The auxiliary information is entered by typing the URL reference or other identifier in reference window <highlight><bold>1512</bold></highlight> and activating data control <highlight><bold>1510</bold></highlight>. Accordingly, in an embodiment, an electronic rundown is responsible for preparing an encoder, starting encoding, sending URL links, and stopping encoding. </paragraph>
<paragraph id="P-0339" lvl="7"><number>&lsqb;0339&rsqb;</number> IX. Viewer Interface </paragraph>
<paragraph id="P-0340" lvl="0"><number>&lsqb;0340&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> illustrates streamer <highlight><bold>2000</bold></highlight> for use with a display device (e.g., enhanced media server <highlight><bold>920</bold></highlight>) according to an embodiment of the present invention. Streamer <highlight><bold>2000</bold></highlight> is a textual or graphical user interface that provides a common platform for integrating one or more of the following components: a media viewer <highlight><bold>2002</bold></highlight>, media index <highlight><bold>2004</bold></highlight>, viewer controls <highlight><bold>2006</bold></highlight>, auxiliary media <highlight><bold>2008</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2008</bold></highlight><highlight><italic>b</italic></highlight>, opinion media <highlight><bold>2010</bold></highlight>, media access area <highlight><bold>2012</bold></highlight>, banners <highlight><bold>2014</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2014</bold></highlight><highlight><italic>d</italic></highlight>, media access controls <highlight><bold>2016</bold></highlight>, and index button <highlight><bold>2018</bold></highlight>. As illustrated, streamer <highlight><bold>2000</bold></highlight> is configured to display each component in the same frame or window. However, in another embodiment, one or more of the components are displayed in a separate frame or window. </paragraph>
<paragraph id="P-0341" lvl="0"><number>&lsqb;0341&rsqb;</number> Streamer <highlight><bold>2000</bold></highlight> is generated by an application operating on a display device. In an embodiment, enhanced media server <highlight><bold>915</bold></highlight> transmits an XML application to instruct a browser application operating on enhanced media client <highlight><bold>920</bold></highlight> to create the requisite components of streamer <highlight><bold>2000</bold></highlight>. Other programming applications can be used as would be apparent to one skilled in the relevant art(s). </paragraph>
<paragraph id="P-0342" lvl="0"><number>&lsqb;0342&rsqb;</number> 1. Media Viewer </paragraph>
<paragraph id="P-0343" lvl="0"><number>&lsqb;0343&rsqb;</number> Media viewer <highlight><bold>2002</bold></highlight> is responsive to user commands to display on-demand and live media productions. In an embodiment, media viewer <highlight><bold>2002</bold></highlight> is operable to demultiplex media streams to support picture-in-picture (PIP) functionality. Accordingly, media viewer <highlight><bold>2002</bold></highlight> is configurable to display multiple media productions in the same or a separate window. </paragraph>
<paragraph id="P-0344" lvl="0"><number>&lsqb;0344&rsqb;</number> In an embodiment, a user would initiate a session with enhanced media server <highlight><bold>915</bold></highlight>, and assemble an on-demand multimedia presentation. The user has the option of requesting to watch a live presentation. If the user prefers to view a different show, the user can override the live presentation to view a previously aired show in its entirety or components of the show in the preferred arrangement. </paragraph>
<paragraph id="P-0345" lvl="0"><number>&lsqb;0345&rsqb;</number> Although media viewer <highlight><bold>2002</bold></highlight> is designed to display video, in an embodiment of the present invention, media viewer <highlight><bold>2002</bold></highlight> is configurable to only play audio without any video. This embodiment is used to support a radio broadcast as described above, or receive audio feeds from other web sites. In general, viewer <highlight><bold>2002</bold></highlight> can support input of any multimedia type or format. </paragraph>
<paragraph id="P-0346" lvl="0"><number>&lsqb;0346&rsqb;</number> 2. Viewer Controls </paragraph>
<paragraph id="P-0347" lvl="0"><number>&lsqb;0347&rsqb;</number> Viewer controls <highlight><bold>2006</bold></highlight> are responsive to user inputs to alter or control media viewer <highlight><bold>2002</bold></highlight>. In an embodiment, viewer controls <highlight><bold>2006</bold></highlight> enable the content displayed by media viewer <highlight><bold>2002</bold></highlight> to be started, fast-forwarded, reversed, stopped or paused at any time. Moreover, an entire segment within a show can be advanced or skipped forward or backward as desired by the user. Other controls include captioning. For instance, the script containing the text of a newscast can be displayed by media viewer <highlight><bold>2002</bold></highlight> below or over the current video. The text can also be displayed in a separate area. </paragraph>
<paragraph id="P-0348" lvl="0"><number>&lsqb;0348&rsqb;</number> Viewer controls <highlight><bold>2006</bold></highlight> are also operable to support online recording, volume controls, parental locks, PIP functionality, viewer size, multiple languages, stereo sound, and the like. In an embodiment, viewer controls <highlight><bold>2006</bold></highlight> include an interrupt button (not shown). For example, if enhance media client <highlight><bold>920</bold></highlight> receives a breaking news update, streamer <highlight><bold>2000</bold></highlight> can be configured to signal the user. The user would have the option of activating viewer control <highlight><bold>2006</bold></highlight> to implement an interrupt to either watch the breaking news update immediately or save the news update to a file for future viewing. The interrupt button (not shown) for viewer control <highlight><bold>2006</bold></highlight> can also be used with a commercial advertisement. The user could activate the interrupt button (not shown) for viewer control <highlight><bold>2006</bold></highlight> to pause or save the commercial advertisement to a file for future viewing. </paragraph>
<paragraph id="P-0349" lvl="0"><number>&lsqb;0349&rsqb;</number> In an embodiment, viewer controls <highlight><bold>2006</bold></highlight> include preset buttons (not shown). The preset buttons (not shown) for viewer controls <highlight><bold>2006</bold></highlight> can be activated to receive transmissions from, for example, a favorite television or radio station. </paragraph>
<paragraph id="P-0350" lvl="0"><number>&lsqb;0350&rsqb;</number> 3. Media Index </paragraph>
<paragraph id="P-0351" lvl="0"><number>&lsqb;0351&rsqb;</number> Media index <highlight><bold>2004</bold></highlight> displays a listing of available media productions that can be selected and displayed by media viewer <highlight><bold>2002</bold></highlight>. In an embodiment, media index <highlight><bold>2004</bold></highlight> contains the rundown from a specific show, or a listing of all shows available from a hosting web site. In another embodiment, media index <highlight><bold>2004</bold></highlight> contains a personalized listing of shows identified by a user. In an embodiment, the user establishes a profile to specify shows by topics or category, specify duration for the entire media production, enable breaking news updates, specify a start time, designate a fixed or flexible end time, or the like. The profile can be saved for future use. Index button <highlight><bold>2018</bold></highlight> is used to toggle between a personalized listing and general listing in response to user input. </paragraph>
<paragraph id="P-0352" lvl="0"><number>&lsqb;0352&rsqb;</number> Media index <highlight><bold>2004</bold></highlight> supports keyword searches for content in the archival and retrieval system of system <highlight><bold>900</bold></highlight>. In an embodiment, SQL queries are sent to enhanced media server <highlight><bold>915</bold></highlight>, which queries IM server <highlight><bold>930</bold></highlight> for the requested content. </paragraph>
<paragraph id="P-0353" lvl="0"><number>&lsqb;0353&rsqb;</number> Media index <highlight><bold>2004</bold></highlight> permits users to save content as they wish for later requests or to build an archive of related stories for use in a report, thesis, or other interests. </paragraph>
<paragraph id="P-0354" lvl="0"><number>&lsqb;0354&rsqb;</number> 4. Auxiliary Media </paragraph>
<paragraph id="P-0355" lvl="0"><number>&lsqb;0355&rsqb;</number> In an embodiment, streamer <highlight><bold>2000</bold></highlight> demultiplexes media streams from enhanced media server <highlight><bold>915</bold></highlight> to display auxiliary media <highlight><bold>2008</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2008</bold></highlight><highlight><italic>b</italic></highlight>. Auxiliary media <highlight><bold>2008</bold></highlight><highlight><italic>a </italic></highlight>includes extended media, caption data, graphics, web links, and the like. Activating a viewer control <highlight><bold>2006</bold></highlight> (shown as &ldquo;ExtraExtra&rdquo; and &ldquo;Live Text&rdquo;) permits one to switch between caption data and other auxiliary information. Auxiliary media <highlight><bold>2008</bold></highlight><highlight><italic>b</italic></highlight>, in a representative embodiment, is a hyperlink or hot button for a stock ticker or the like. The stock ticker can be supplied or sourced by the broadcaster or via any other source (such as the Internet), and can be either a standards-based ticker or customized to only illustrate the symbols of choice by the user. </paragraph>
<paragraph id="P-0356" lvl="0"><number>&lsqb;0356&rsqb;</number> 5. Opinion Media </paragraph>
<paragraph id="P-0357" lvl="0"><number>&lsqb;0357&rsqb;</number> In an embodiment, streamer <highlight><bold>2000</bold></highlight> demultiplexes media streams from enhanced media server <highlight><bold>915</bold></highlight> to display opinion media <highlight><bold>2010</bold></highlight>. The online user may interact with streamer <highlight><bold>2000</bold></highlight> to participate in a poll, take a survey or review the opinions of other respondents. </paragraph>
<paragraph id="P-0358" lvl="0"><number>&lsqb;0358&rsqb;</number> 6. Media Access Area </paragraph>
<paragraph id="P-0359" lvl="0"><number>&lsqb;0359&rsqb;</number> Streamer <highlight><bold>2000</bold></highlight> also includes a media access area <highlight><bold>2012</bold></highlight>. In an embodiment, media access area <highlight><bold>2012</bold></highlight> is a web browsing region that permits the user to visit and view other web sites without leaving media viewer <highlight><bold>2002</bold></highlight> or interrupting a current show displayed by media viewer <highlight><bold>2002</bold></highlight>. Hence, both windows are active such that media access area <highlight><bold>2012</bold></highlight> can be used to research information without having to leave media viewer <highlight><bold>2002</bold></highlight>. This avoids time-consuming loading, buffering and reloading when the user wishes to go back to the in-progress program on media viewer <highlight><bold>2002</bold></highlight>. </paragraph>
<paragraph id="P-0360" lvl="0"><number>&lsqb;0360&rsqb;</number> Media access area <highlight><bold>2012</bold></highlight> is also used as the browser for URL links that are activated from auxiliary media <highlight><bold>2008</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2008</bold></highlight><highlight><italic>b</italic></highlight>. In another embodiment, media access area <highlight><bold>2012</bold></highlight> displays an online user&apos;s rundown of the selections from media index <highlight><bold>2004</bold></highlight>. The selections can be placed in any order or re-ordered are indicated by the user. </paragraph>
<paragraph id="P-0361" lvl="0"><number>&lsqb;0361&rsqb;</number> Media access controls <highlight><bold>2016</bold></highlight> permits the user to manipulate the selections displayed in media access area <highlight><bold>2012</bold></highlight>. Media access controls <highlight><bold>2016</bold></highlight> includes a scroll buttons that instructs the media access area <highlight><bold>2012</bold></highlight> to caret up or down. Media access controls <highlight><bold>2016</bold></highlight> also includes a delete button for removing selections and a play button for sending a request to enhanced media server <highlight><bold>915</bold></highlight> for the selections. </paragraph>
<paragraph id="P-0362" lvl="0"><number>&lsqb;0362&rsqb;</number> Media access area <highlight><bold>2012</bold></highlight> is also configurable to permit users to submit questions to a Webmaster or network systems administrator for a broadcasting station or portal host. A user can also search a specific topic tied to a media production, such as a newscast. In an embodiment, each time a user selects a topic from the search results, advertisements linked to the topic are routed to the user. Streamer <highlight><bold>2000</bold></highlight> or enhanced media server <highlight><bold>915</bold></highlight> is also configurable to support monitoring and data logging to track web hits, advertisement hits, billing and costs. In an embodiment, streamer <highlight><bold>2000</bold></highlight> or enhanced media server <highlight><bold>915</bold></highlight>, supports communications with independent media measurement entities, such as, Nielson/Net-Ratings, Media Metrix and Arbitron for the development of independent industry reports. </paragraph>
<paragraph id="P-0363" lvl="0"><number>&lsqb;0363&rsqb;</number> 7. Banner </paragraph>
<paragraph id="P-0364" lvl="0"><number>&lsqb;0364&rsqb;</number> Streamer <highlight><bold>2000</bold></highlight> also processes the media streams from enhanced media server <highlight><bold>915</bold></highlight> to display banners <highlight><bold>2014</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2014</bold></highlight><highlight><italic>d</italic></highlight>. Advertisement banner <highlight><bold>2014</bold></highlight><highlight><italic>a </italic></highlight>is a static or dynamic banner that promotes the goods or services of a sponsor. Advertisement banner <highlight><bold>2014</bold></highlight><highlight><italic>a </italic></highlight>can be active to require the user to scroll or click-through the banner, or passive to require no action on part of the user. In an embodiment, the sponsor can be linked to a specific segment displayed by media viewer <highlight><bold>2002</bold></highlight>. </paragraph>
<paragraph id="P-0365" lvl="0"><number>&lsqb;0365&rsqb;</number> Advertisement banner <highlight><bold>2014</bold></highlight><highlight><italic>b </italic></highlight>is a sponsor button or mark linked to the media production. In an embodiment, advertisement banner <highlight><bold>2014</bold></highlight><highlight><italic>b </italic></highlight>is linked to a segment currently displayed by media viewer <highlight><bold>2002</bold></highlight> and advertisement banner <highlight><bold>2014</bold></highlight><highlight><italic>b </italic></highlight>is linked to the web page in general. </paragraph>
<paragraph id="P-0366" lvl="0"><number>&lsqb;0366&rsqb;</number> Advertisement banners <highlight><bold>2014</bold></highlight><highlight><italic>c</italic></highlight>-<highlight><bold>2014</bold></highlight><highlight><italic>d </italic></highlight>are used to promote the hosting web site or portal. Advertisement banners <highlight><bold>2014</bold></highlight><highlight><italic>a</italic></highlight>-<highlight><bold>2014</bold></highlight><highlight><italic>d </italic></highlight>can be a hot spot, hyperlink or nonfunctional. </paragraph>
<paragraph id="P-0367" lvl="0"><number>&lsqb;0367&rsqb;</number> 8. Alternative Skins </paragraph>
<paragraph id="P-0368" lvl="0"><number>&lsqb;0368&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> illustrates another embodiment of a client GUI (shown as streamer <highlight><bold>2100</bold></highlight>) for use with an enhanced media server <highlight><bold>920</bold></highlight>. In streamer <highlight><bold>2100</bold></highlight>, media access area <highlight><bold>2012</bold></highlight> provides a login menu that enables a user to access the content of enhanced media server <highlight><bold>920</bold></highlight>. Auxiliary media <highlight><bold>2008</bold></highlight><highlight><italic>a </italic></highlight>displays an HTML page from a web site that is linked to the current media stream shown by media viewer <highlight><bold>2002</bold></highlight>. </paragraph>
<paragraph id="P-0369" lvl="0"><number>&lsqb;0369&rsqb;</number> The above streamer embodiments have been described with reference to the hosting site being the actual broadcaster or content suppler. As such, the streamer components are implemented in the web site hosted by the local broadcaster. The present invention can also be implemented with a third party portal. An embodiment of a third party GUI is shown in <cross-reference target="DRAWINGS">FIG. 22</cross-reference>. Streamer <highlight><bold>2200</bold></highlight> permits the streamer components to be presented on a third party GUI with the third party host identified by advertisement banners <highlight><bold>2014</bold></highlight><highlight><italic>c</italic></highlight>-<highlight><bold>2014</bold></highlight><highlight><italic>d. </italic></highlight></paragraph>
<paragraph id="P-0370" lvl="7"><number>&lsqb;0370&rsqb;</number> X. Conclusion </paragraph>
<paragraph id="P-0371" lvl="0"><number>&lsqb;0371&rsqb;</number> The foregoing description of the specific embodiments will so fully reveal the general nature of the invention that others can, by applying knowledge within the skill of the art (including the contents of the documents cited and incorporated by reference herein), readily modify and/or adapt for various applications such specific embodiments, without undue experimentation, without departing from the general concept of the present invention. Therefore, such adaptations and modifications are intended to be within the meaning and range of equivalents of the disclosed embodiments, based on the teaching and guidance presented herein. It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation, such that the terminology or phraseology of the present specification is to be interpreted by the skilled artisan in light of the teachings and guidance presented herein, in combination with the knowledge of one skilled in the art. </paragraph>
<paragraph id="P-0372" lvl="0"><number>&lsqb;0372&rsqb;</number> While various embodiments of the present invention have been described above, it should be understood that they have been presented by way of example, and not limitation. It will be apparent to one skilled in the relevant art(s) that various changes in form and detail can be made therein without departing from the spirit and scope of the invention. Thus, the present invention should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A method of editing and distributing media throughout a network, comprising the steps of: 
<claim-text>(1) receiving media from a production, wherein said production comprises one or more elements of a story; </claim-text>
<claim-text>(2) editing association of auxiliary information with said story; and </claim-text>
<claim-text>(3) enabling display of said media and said auxiliary information at one or more media clients. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising the step of: 
<claim-text>(4) deliverying said production over one or more television mediums. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein step (3) and step (4) occur substantially at the same time. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein step (3) and step (4) occur substantially at the same time as producing said production. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising the step of: 
<claim-text>(4) converting said media into one or more packets. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein step (2) comprises the step of: 
<claim-text>(a) adding a header to at least one of said one or more packets to associate said auxiliary information with said story. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein step (2) comprises the step of: 
<claim-text>(a) associating an address to the location of said auxiliary information to associate said auxiliary information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein step (2) further comprises the step of: 
<claim-text>(b) specifying said address in a header appended to at least one of said one or more packets. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further comprising the step of: 
<claim-text>(5) formatting said one or more packets for transport to said one or more clients. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein step (5) comprises the step of: 
<claim-text>(a) formatting said one or more packets for compliance with a TCP over IP protocol suite. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein step (5) comprises the step of: 
<claim-text>(a) formatting said one or more packets for compliance with an HTTP protocol. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein step (5) comprises the step of: 
<claim-text>(a) formatting said one or more packets for compliance with a RTP protocol. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising the step of: 
<claim-text>(4) transmitting said media and said auxiliary information to said one or more clients. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein step (4) comprises the step of: 
<claim-text>(a) transmitting said media and said auxiliary information over a computer network to said one or more clients. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein step (4) comprises the step of: 
<claim-text>(a) transmitting said media and said auxiliary information to said one or more clients over a least one of an intranet, an extranet, a virtual private network, and the global Internet. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein step (2) comprises the step of: 
<claim-text>(a) associating auxiliary information with a corresponding element of said story. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. A method of editing encoded media, comprising the steps of: 
<claim-text>(1) receiving encoded media representing a production; </claim-text>
<claim-text>(2) modifying association of auxiliary information to one or more elements of said production; and </claim-text>
<claim-text>(3) storing said encoded media such that elements of said production are retrievable. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, further comprising the step of: 
<claim-text>(4) receiving a request from a client for one or more elements of said production. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, further comprising the step of: 
<claim-text>(5) transmitting instructions enabling presentation of one or more elements identified in said request to occur concurrently with a corresponding associated auxiliary information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, further comprising the step of: 
<claim-text>(4) storing instructions for displaying said auxiliary information, wherein said auxiliary information corresponds with the element being displayed on one or more clients. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, further comprising the step of: 
<claim-text>(4) formatting said encoded media for transport to one or more clients over the global Internet. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. A computer data signal embodied in a transmission medium, comprising: 
<claim-text>a first code segment including instructions for displaying one or more stories; and </claim-text>
<claim-text>a second code segment including instructions for displaying auxiliary information corresponding to at least one story, such that said auxiliary information is displayed concurrently with a corresponding story. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The computer data signal according to <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further comprising: 
<claim-text>a third code segment including instructions for transmitting to an enhanced media server a request for additional auxiliary information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The computer data signal according to <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further comprising: 
<claim-text>a third code segment including instructions for displaying auxiliary information corresponding with an element of said at least one story, such that said auxiliary information is displayed concurrently with a corresponding element. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The computer data signal according to <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, wherein said auxiliary information includes at least one of extended media, an URL address, an opinion poll, an email address, statistics, graphics, a text document, or an advertisement. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The computer data signal according to <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further comprising: 
<claim-text>a third code segment including instructions for requesting a customizable selection of one or more stories and/or one or more elements of a story. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. A computer program product comprising a computer useable medium having control logic embedded in said medium for causing a computer to edit and/or distribute media, said control logic comprising: 
<claim-text>first means for causing the computer to receive media from a production, wherein said production comprises one or more elements of a story; </claim-text>
<claim-text>second means for causing the computer to associate auxiliary information with said story; and </claim-text>
<claim-text>third means for causing the computer to enable display of said media and said auxiliary information at one or more enhanced media clients. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The computer program product according to <dependent-claim-reference depends_on="CLM-00022">claim 27</dependent-claim-reference>, wherein said third means is adapted to enable said display to occur at substantially the same time as a broadcast of said media over another distribution medium. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. A system for editing encoded media, comprising: 
<claim-text>first means for receiving encoded media representing a production; </claim-text>
<claim-text>second means for modifying association of auxiliary information to one or more elements of said production; and </claim-text>
<claim-text>third means for storing said encoded media such that elements of said production are retrievable on an on-demand basis. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00022">claim 29</dependent-claim-reference>, further comprising: 
<claim-text>fourth means for receiving a request from a client for one or more elements of said production. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. The system of <dependent-claim-reference depends_on="CLM-00033">claim 30</dependent-claim-reference>, further comprising: 
<claim-text>fifth means for transmitting instructions enabling presentation of one or more elements identified in said request to occur concurrently with a corresponding associated auxiliary information. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. A method of transmitting information within a communications network, comprising the steps of: 
<claim-text>(1) accessing one or more topics corresponding to a user profile; </claim-text>
<claim-text>(2) assembling a media production matching the one or more topics; and </claim-text>
<claim-text>(3) enabling display of the media production to the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, wherein step (1) further comprising the step of: 
<claim-text>(a) receiving the one or more topics from the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, wherein step (1) further comprising the step of: 
<claim-text>(a) inferring the one or more topics from psychographic data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, wherein step (1) further comprising the step of: 
<claim-text>(a) parsing a calendar to identify the one or more topics. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, wherein step (2) further comprising the step of: 
<claim-text>(a) setting a user-specified duration of the media production. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, further comprising the step of: 
<claim-text>(a) enabling formatting of the media production to match formats specified by the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, further comprising the step of: 
<claim-text>(a) transmitting a media production related to traffic and/or weather during a commute of the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00039">
<claim-text><highlight><bold>39</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, further comprising the step of: 
<claim-text>(a) enabling display of the media production at a time designated by the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00040">
<claim-text><highlight><bold>40</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, wherein step (2) further comprises the step of: 
<claim-text>(a) selecting video, documents, web links, audio feeds, or commercial offers to assemble the media production. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00041">
<claim-text><highlight><bold>41</bold></highlight>. A computer program product comprising a computer useable medium having control logic embedded in said medium for causing a computer to transmit media productions, said control logic comprising: 
<claim-text>first means for causing the computer to access one or more topics corresponding to a user profile; </claim-text>
<claim-text>second means for causing the computer to assemble a media production matching the one or more topics; and </claim-text>
<claim-text>third means for causing the computer to send the media production to the user. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00042">
<claim-text><highlight><bold>42</bold></highlight>. The computer program product according to claim <highlight><bold>41</bold></highlight>, further comprising: 
<claim-text>fourth means for causing the computer to determine the one or more topics from psychographic data.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001880A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001880A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001880A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001880A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001880A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001880A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001880A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001880A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001880A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001880A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001880A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030001880A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030001880A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030001880A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030001880A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030001880A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030001880A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030001880A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030001880A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00019">
<image id="EMI-D00019" file="US20030001880A1-20030102-D00019.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00020">
<image id="EMI-D00020" file="US20030001880A1-20030102-D00020.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00021">
<image id="EMI-D00021" file="US20030001880A1-20030102-D00021.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00022">
<image id="EMI-D00022" file="US20030001880A1-20030102-D00022.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00023">
<image id="EMI-D00023" file="US20030001880A1-20030102-D00023.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00024">
<image id="EMI-D00024" file="US20030001880A1-20030102-D00024.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00025">
<image id="EMI-D00025" file="US20030001880A1-20030102-D00025.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00026">
<image id="EMI-D00026" file="US20030001880A1-20030102-D00026.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00027">
<image id="EMI-D00027" file="US20030001880A1-20030102-D00027.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00028">
<image id="EMI-D00028" file="US20030001880A1-20030102-D00028.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00029">
<image id="EMI-D00029" file="US20030001880A1-20030102-D00029.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00030">
<image id="EMI-D00030" file="US20030001880A1-20030102-D00030.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00031">
<image id="EMI-D00031" file="US20030001880A1-20030102-D00031.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
