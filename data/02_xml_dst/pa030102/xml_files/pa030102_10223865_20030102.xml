<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030004644A1-20030102-D00000.TIF SYSTEM "US20030004644A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030004644A1-20030102-D00001.TIF SYSTEM "US20030004644A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030004644A1-20030102-D00002.TIF SYSTEM "US20030004644A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030004644A1-20030102-D00003.TIF SYSTEM "US20030004644A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030004644A1-20030102-D00004.TIF SYSTEM "US20030004644A1-20030102-D00004.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030004644</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10223865</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020819</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G08G001/16</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>701</class>
<subclass>301000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>340</class>
<subclass>903000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>340</class>
<subclass>436000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Methods and apparatus for stationary object detection</title-of-invention>
</technical-information>
<continuity-data>
<division-of>
<parent-child>
<child>
<document-id>
<doc-number>10223865</doc-number>
<kind-code>A1</kind-code>
<document-date>20020819</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09633127</doc-number>
<document-date>20000804</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>GRANTED</parent-status>
<parent-patent>
<document-id>
<doc-number>6438491</doc-number>
<country-code>US</country-code>
</document-id>
</parent-patent>
</parent-child>
</division-of>
<non-provisional-of-provisional>
<document-id>
<doc-number>60187942</doc-number>
<document-date>20000303</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
<non-provisional-of-provisional>
<document-id>
<doc-number>60147695</doc-number>
<document-date>19990806</document-date>
<country-code>US</country-code>
</document-id>
</non-provisional-of-provisional>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Bennie</given-name>
<middle-name>L.</middle-name>
<family-name>Farmer</family-name>
</name>
<residence>
<residence-us>
<city>Ann Arbor</city>
<state>MI</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
</inventors>
<assignee>
<organization-name>Telanon, Inc.</organization-name>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>HAHN LOESER &amp; PARKS, LLP</name-1>
<name-2>TWIN OAKS ESTATE</name-2>
<address>
<address-1>1225 W. MARKET STREET</address-1>
<city>AKRON</city>
<state>OH</state>
<postalcode>44313</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">The present invention provides systems and methods for measuring the likelihood that detected stationary objects are not normally present at a sensed location. Such systems and methods may be used by other systems to which information from the present invention are communicated, for minimizing nuisance alerts in onboard object detection systems such as collision warning, collision avoidance, and/or adaptive cruise control systems. The system includes at least one vehicle mounted sensor capable of sensing at least a target object and providing data related to the target object. The system also comprises a locating device which is capable of determining and providing data related to the location of the machine or vehicle and a processing unit which receives the data from the sensor and the data from the locating device. The processing unit is configured to determine a probability estimate or measure of likelihood that the target object is not a normally present object based upon a comparison to previously recorded data from a reference storage device. The reference storage device stores the previously recorded data acquired from at least one similar sensor and a vehicle locating device while operating in the same geographic area, or stores data derived from such previously recorded data. The invention may enhance vehicle collision warning, collision avoidance and/or adaptive cruise control systems as examples. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">TECHNICAL FIELD </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This invention is related to systems and methods for stationary object detection, including driver situation awareness, vehicle collision warning, collision avoidance and/or adaptive cruise control systems as examples. More particularly, this invention relates to improvements in stationary object detection, and accurately determining the likelihood that a objects detected using an object sensing system are not normally present at a sensed location. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE ART </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> Object detection systems can be useful in a variety of environments, including for use in land-based mobile machines and vehicles where there is a threat of collision with the objects. Such land-based mobile machines or vehicles may include subterranean or open-pit mining machines, on-road or off-road vehicles, robotic machines or the like. In the varying environments in which such machines are used, it should be evident that various obstacles and objects are within the possible path of the machine, and wish to be detected and often avoided. For example, vehicles may encounter conditions where there is no visibility of objects within the possible path of the vehicle. Collision warning systems are currently being developed to provide a warning to the commercial and/or passenger vehicle driver whenever an onboard sensor detects that an object presents a potential for a collision. For safety concerns, these systems must use a low threshold in determining whether the identified target object is a potential collision hazard in order to prevent the system from missing a bona fide hazard target. This results in the collision warning system sometimes generating a collision alert in response to non-hazard targets and/or clutter such as &ldquo;road furniture&rdquo;. Typical non-hazard targets include road signs, bridges, fences, guard rails and road-side burms, etc. These &ldquo;false&rdquo; alerts, also known as &ldquo;nuisance alerts&rdquo;, are an annoyance and can happen so often that the driver may delay reacting or ignore the warning and not react to a bona fide warning. Poor discrimination of such non-hazards from true hazards limits the effectiveness and reliability of such collision warning systems. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> There are currently several types of vehicle-based collision warning and adaptive cruise control products for use in commercial and passenger vehicles. The first system is known as Adaptive Cruise Control (ACC). ACC is an enhancement to conventional cruise control which has the ability to detect objects ahead of the moving vehicle when cruise control is engaged to improve the &ldquo;comfort and convenience&rdquo; of the system. It is not employed as a safety system as the driver must still pay attention and respond to potential hazards, and is often marketed as simply a &ldquo;more convenient&rdquo; form of cruise control, even though some evidence exists that its use offers safety benefits, as well, compared with conventional cruise control. When the ACC host vehicle is cruising at its cruise-control set-speed, the ACC automatically slows down the host vehicle to match the speed of a somewhat-slower-moving vehicle traveling in its lane ahead and establishes an &ldquo;appropriate&rdquo; following distance, which in many ACC designs the driver has a role in setting, within defined minimum and maximum distance limits. After that, the ACC enters &ldquo;distance-control&rdquo; mode, matching the forward-vehicle&apos;s speed (unless it accelerates beyond the host vehicle&apos;s set-speed), as long as it is present. If another vehicle cuts in and stays in the lane, the ACC will decelerate the host vehicle to re-establish the &ldquo;appropriate&rdquo; distance and then re-enter &ldquo;distance-control&rdquo; mode. Whenever the lane ahead clears, due to either vehicle changing lanes, the ACC will cause the host vehicle to smoothly accelerate tip to its cruise-control set-speed and keep that speed until a slower-moving vehicle is again detected in its lane ahead. The ACC typically uses a stand-alone forward-looking sensor system, which can not accurately judge whether a detected object is in fact on the roadway in the host vehicle&apos;s lane without generating an unacceptable number of nuisance alerts. Accordingly, it is generally understood in the automotive industry that ACC has been designed not to address this situation, and some ACC systems have even been designed not to respond to moving vehicles in their lanes traveling at speeds slow enough so that the driver might not realize they are moving. The reason for this is to attempt to avoid giving the driver a misimpression that the ACC does or should respond to stopped vehicles, with the result being that such an ACC provides even less functionality than it is capable of providing, due to this human-factors consideration. With an improved ability to sense objects and discriminate stationary objects, an improved version of ACC could developed to provide additional capabilities, such as the ability to respond to all vehicles in the host vehicle&apos;s lane, whether moving at normal highway speeds, moving slowly, moving and coming to a stop, or even stationary when first detected. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Another product is known as the Forward Collision Warning System (F-CWS). The F-CWS operates as an advisory system to the driver, who operates the vehicle in the normal way and is still fully responsible for safe operation. Various warnings are given for a wide range of potentially-dangerous situations involving moving vehicles and stationary vehicles or other large objects. Unlike ACC, the F-CWS is designed to operate while the vehicle is under full control of the driver, rather than while cruise control is operating, and also to warn the driver of a wide range of potentially dangerous situations, including those involving stationary objects that are judged by the F-CWS to lie in the expected path of the host vehicle. Due to the difficulty of distinguishing stopped vehicles or other stationary objects in the path of the vehicle, when compared to normal roadside or overhead highway structures, current products of this type on the sometimes warns the driver of a potential collision when there is no hazard, resulting in a nuisance alert. This is widely believed to be a primary reason why such products were first introduced on commercial vehicles, and have not been introduced on passenger vehicles, even in markets where the commercial vehicle products are currently in use (including the United States). Although an occasional nuisance alert can be an annoyance to a professional driver operating a commercial vehicle, such drivers are generally provided specific training on the use and limitations of these products, and with their extensive driving experience, often simply regard the occasional nuisance alert as a minor distraction. However, there is wide concern that passenger vehicle drivers, who may have much less driving experience and who cannot generally be required to undertake product-related training similar to commercial drivers, may react unpredictably to any nuisance alerts generated in error by a safety-related product such as F-CWS. Various approaches have been used in attempts to minimize these nuisance alerts. One such approach involves delaying an eventual warning while more information is taken to evaluate the probable location of a detected stationary object and the expected location of the host vehicle&apos;s line ahead. If the stationary object does not seem to be in the projected host vehicle&apos;s lane, it is usually judged not dangerous. On the other hand, if the object is confirmed as a hazard, the warning will be delayed. This will allow the driver less response time to avoid the collision with the object. At the same time, the viewing angle of the sensor system may be purposely limited to help reduce nuisance alerts, which may limit the effective capabilities of the system. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Although attempts have been made at improving the sensor to better identify objects, such sensors have not resolved the problems to date or are too expensive for incorporation in commercial or passenger vehicles. Infrared laser sensors have been developed which provide both horizontal and vertical scanning, and which give detailed object sensing resolution; however, such sensors to date have had difficulties operating acceptably in foul weather and with respect to objects whose reflectivity may be significantly reduced by ice, snow, or even road grime. Radar technology may overcome much of these environmental problems; however such radar products that provide both horizontal and vertical scanning require so much hardware and software to operate that they remain much too expensive for commercial and passenger vehicle use. Current radar-based commercial or passenger vehicle products can provide limited information about detected objects: distance, relative speed, and horizontal position (sometimes including estimated horizontal width). None of them offer information about the vertical position of a detected object, which can lead to uncertainty at all but very close range whether an in-path detected object is actually in the vehicle&apos;s path or is simply an overhead structure. Other attempts to improve the current F-CWS technology utilizing stand-alone sensors have not resolved the production of nuisance alerts, particularly in locations where sharp curves, low bridges, tunnels, and/or hills cause the system to mistakenly regard the detected stationary objects to lie oil the roadway in the host vehicle&apos;s path. The present state of the art for vehicle use does not have the ability to reliably detect whether a detected stationary object is it road level or is perhaps simply an overhead object such as a low bridge or tunnel opening. The ability to precisely locate a stationary object detected ahead to be at the horizontal coordinates matching the host vehicle&apos;s lane is not adequate to determine whether the object is in the roadway or overhead. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> The only existing forward-looking collision warning system in commercial use in the United States utilizes Doppler-based modulation for its radar sensor. Doppler processing is based on identifying objects by detecting the change in frequency between an emitted signal and a return signal reflected back from the detected object, and this &ldquo;Doppler shift&rdquo; relates directly to the detected object&apos;s speed relative to the sensor&apos;s transmitting antenna. With modern digital radar signal processing, typically using fast Fourier transform (FFT) methods, such radar sensors are designed to separate all detected objects into a number of separate &ldquo;Doppler bin&rdquo; categories, based on their Doppler frequency shift, and thus speeds relative to the sensor. The design of typical sensors used for vehicle-based ACC and CWS typically can identify an object separately from others if its relative speed is only a few tenths of a mile per hour different from the rest. In practice, this has proven very effective overall for these systems, but one result is that, with some exceptions for objects nearer the edges of the radar beam, all stationary objects detected within the radar beam appear to be moving at the same relative speed (they are fixed and the vehicle is moving towards them at some speed). Such Doppler-based radars are extremely accurate with respect to relative speed, as well as for distance (and horizontal angle, depending on the antenna design) to individual objects. However, for stationary objects, the distance and horizontal angle (if provided) are calculated for all objects whose relative speeds place them in the same Doppler bin, and for stationary objects, this results in distinct objects not being recognized as such, and the apparent distance and horizontal angle to a significant stationary object can be strongly influenced by other stationary objects within the radar beam. Because the radar beam is typically no more than 12 degrees wide and 4 degrees high, a fairly small amount of tthe stationary environment influences the results, but since the &ldquo;reflectivity&rdquo; or radar cross section (RCS) of an object and its nearness to the sensor are strong influences, the &ldquo;apparent&rdquo; location of an individual object when first detected is not only not precisely accurate with its physical location (because the result is being influenced by other stationary objects), its &ldquo;apparent location&rdquo; changes, often moving closer to the sensor, as the sensor approaches the object. This is due to the fact that the individual object takes up more of the radar beam as it is approached, so it has greater influence than at greater distance. Further, the distance itself is a strong influence on the radar return, so as it is approached, its smaller distance also gives it more influence on the calculations for the location of it as well as all other objects in its Doppler bin. The net effect is that individual stationary objects can only be precisely located when they are fairly close to the Doppler-based radar sensor, and at varying distances, their &ldquo;apparent locations&rdquo; appear to move in space as they are approached. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> Another potential product is the Short-range Collision Waning System (S/R-CWS). At present, a convenience-oriented product generally called Parking Aid is available on vehicles, which is a limited-function parking assistance system, generally utilizing ultrasonic sensors to warn the driver when the host vehicle is getting too close to another object in the rear or front while parking. These systems only need to operate over very short distances and for very slow speeds. Most vehicles have significant blind spots immediately to the rear, and many commercial vehicles have a blind spot immediately ahead, so a S/R-CWS designed to alert the driver to any dangerous situation, especially while the vehicle is moving in reverse, must meet difficult design requirements. It must reliably and quickly detect people, especially small children, who may be playing or otherwise be behind the vehicle without the driver&apos;s knowledge. It must provide warnings to the driver for such detections with adequate time for the driver to respond, while the vehicle is moving at normal speeds for maneuvering in parking or work areas, or backing down a driveway. To do so, and to reduce the potential for missed detections to an absolute minimum for safety reasons, it is difficult to design such stand-alone systems with current technology without having a significant potential for nuisance alerts. To be an acceptable product, it must have very few nuisance alerts, or else risk having the driver ignore critical alerts in areas where nuisance alerts might occur. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Although not discussed in detail, there are other collision warning systems which are also susceptible to nuisance alerts. Conquering the problems associated with nuisance alerts in such systems will not only allow greater deployment and acceptance of the ACC, F-CWS and the S/R-CWS and other related systems, but will also allow for the introduction of advanced collision avoidance systems. The collision avoidance systems have the ability to not only warn the driver, but will also take action to help avoid the collision such as slowing or stopping the vehicle. These systems have the potential to reduce collisions and improve driver safety, beyond the improvements possible with ACC, F-CWS, and S/R-CWS products. Additionally, in a variety of other environments, such as in the use of mobile machines such as robotic vehicles or the like, reliable object detection is essential, and similarly, the accurate measure of whether a sensed object is normally present at a sensed location will facilitate operation of such machines, in some cases to avoid the object but in other cases to investigate it. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Therefore, there remains a need in the art for a method and apparatus for accurately measuring the likelihood that detected stationary objects are normally present in an environment at a remotely sensed location. Such improved measuring capabilities would in turn improve suppression of nuisance alerts in such systems as adaptive cruise control and/or collision warning and/or collision avoidance systems. Such improved measurement would also enable sensing systems to operate at their fullest effective range and ability. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> To overcome the above indicated problems, the present invention provides systems and methods for determining the likelihood that stationary objects detected by a sensor in a geographic area are unusual, based on comparing remotely-sensed characteristics of those objects with characteristics detected by similar sensors operating with locating devices in the same geographical area on previous occasions. This invention is equally applicable to all known sensor technologies, including Doppler-based radar, because the characteristics of detected stationary objects, including apparent relative location, detected from a particular vehicle location are compared with characteristics detected on previous occasions by similar technology sensors operating at the same vehicle location; as a result, &ldquo;apparent location&rdquo; of stationary objects calculated from a vehicle location is compared with a similarly-calculated &ldquo;apparent location&rdquo; using detection by similar technology sensors from the same vehicle location. This approach has significant advantages, compared with comparisons between calculated absolute position based on &ldquo;apparent location&rdquo; calculated from Doppler-based sensor data and actual physical location recorded in a navigation-based map database, however detailed and accurate. In addition, the present invention offers advantages for non-Doppler-based sensor systems, due to the fact that it provides signal return comparisons, in addition to possible other characteristics detected on previous occasions by similar sensors, which give information in addition to location to help distinguish the presence of multiple stationary objects which appear to be at the location of an object which is normally there. This helps reduce the uncertainty of comparisons based solely on location-matching when location precision better than 1 meter is unavailable. Compared with the use of a navigation-based map database and similar sensors, the present invention also addresses the difficulty of reliably detecting whether a stationary object is at road level or overhead, by providing the ability to compare the signal return strength with what should be normal from each point in the approach path; in the case of a stationary vehicle beneath a low overhead structure, the relative locations will match the normal ones as the vehicle approaches, but the return signal magnitude should be greater than normal, due to the presence of the roadway-level object which is returning the signal ill addition to the overhead structure which would normally be the only stationary object at that location returning the signal. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> Such systems and methods may be used for minimizing nuisance alerts in onboard object detection systems such as collision warning, collision avoidance, and/or adaptive cruise control systems. The system includes at least one vehicle mounted sensor capable of sensing at least a stationary target object and providing data related to the target object. The system also comprises a locating device which is capable of determining and providing data related to the location of the machine or vehicle and a processing unit which receives the data from the sensor and the data from the locating device. The processing unit is configured to determine a probability estimate or measure of likelihood that the target object is not a normally present object or is otherwise unusual, based upon a comparison to previously recorded data from a reference storage device. The reference storage device stores the previously recorded data acquired from at least one similar sensor and a vehicle locating device while operating in the same geographical area where the target object is being detected, and/or data derived from such previously recorded data. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> It is an object of the present invention to provide a system which will reliably evaluate whether a target stationary object is unusual based on its remotely-detectable characteristics, and is therefore a bona fide object, such as a potential collision object, at a distance up to the operating distance limit of the sensor. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> It is another object of the invention to provide such evaluation of a target stationary object to a collision warning system to improve its decisions whether and how to alert the driver, and to an avoidance or ACC system to improve its decisions whether and how to alert the driver and how to control the vehicle. In this manner, the invention assists the identification of bona fide hazard targets and the suppression of collision warnings produced in response to various non-hazard targets and/or clutter commonly encountered in the operating environment of many land-based vehicles. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> It is another object of the invention to provide a vehicle&apos;s driver or a mobile machine&apos;s remote operator with improved situation awareness of unusual stationary objects, to allow the driver or operator to begin evaluating the situation, possibly in advance of alerts or other actions initiated by collision warning, ACC, or collision avoidance systems. This is normally done by identifying to the driver or remote operator the location of detected stationary objects which are not normally present or which for other reasons are sufficiently unusual. Since a collision warning, ACC, or collision avoidance system may require more time to sufficiently evaluate whether the unusual stationary object may also be hazardous, it is very possible that the driver will receive such situation awareness information before another system provides alerts or takes any other type of action. If the driver or operator agrees that objects identified by the situation awareness information do appear to be unusual, even if not dangerous, then such unusual but non-hazardous object identifications should not be considered &ldquo;nuisance alerts&rdquo;, and should not reduce the effectiveness of the invention. An example of such a situation is a car parked in an emergency lane adjacent to the host vehicle&apos;s lane, but too far away for a collision warning or collision avoidance system to determine with acceptable confidence whether it is in the host vehicle&apos;s lane. If called to the driver&apos;s attention as an unusual stationary object, the driver should quickly realize that there is no little to no danger, but may still appreciate the situation awareness message, so the driver or operator could begin changing lanes or simply watch more closely in case someone is near the car who might not see the approaching host vehicle and step into the lane. Such situation awareness information would normally be expected to work in conjunction with an associated collision warning, ACC, or collision avoidance system operating, but in some cases may operate as a stand-alone capability without full collision warning, ACC, or collision avoidance systems actively engaged or even present.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram depicting the creation of a reference database of the present invention; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a block diagram showing the sensor data and vehicle location data and individual elements associated therewith in accordance with the present invention; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is a block diagram showing a reference database and individual elements associated therewith in accordance with the present invention; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a block diagram of a driver alert system of the present invention; and </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a graph illustrating the use of the reference database to evaluate the likelihood that a target object represents a danger of collision with a vehicle.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE INVENTION </heading>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> The present invention provides a system which uses a statistics-based algorithm to determine whether one or more stationary objects noted by a sensing system are normally present objects or otherwise possible obstacles in the vicinity of the mobile machine or vehicle on which the system is used, whether intended to alert the operator or otherwise control operation of the vehicle to avoid objects in this vicinity. Although the invention will be described with reference to collision warning systems (CWS), collision avoidance systems (CAS) and/or adaptive cruise control (ACC) systems, it should be understood that the improved ability to detect the presence of target objects, whether expected or unexpected, may be used to improve many vehicle or machine applications in addition to these applications. The invention provides the additional capabilities of allowing proper identification of hazards, and allowing appropriate action to be taken earlier than possible without the subject invention or up to the greatest capacity of the object sensing systems. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> While the following discussion refers primarily to CWS, it is understood to include CAS, ACC, or any other related system. The sensor employed by the system often limits the performance of any detection or collision warning system. There are generally three categories of sensors; visible light, laser and radar. The visible light sensors typically use CCD technology to capture the road scene ahead of the vehicle. Also known as &ldquo;vision sensors&rdquo;, they can provide a great deal of detail to be used in identifying objects and locations. However, the technology is currently costly and does not work well in adverse weather conditions. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The laser sensors employed in a collision warning system typically operate in the infrared spectrum. Generally, an inexpensive laser diode generates the radiation, which is then shaped and scanned by various methods over the area of interest. Returning radiation is captured through lenses, and the intensity of the radiation can be measured. By pulsing the laser, highly accurate distances can be determined by elapsed time calculations. These distances include the distance away, angle up-and-down from dead center, and angle side-to-side from dead center. While laser systems are inexpensive and provide excellent object location capability, their performance also deteriorates in adverse weather conditions and due to foreign materials such as road grime on the surfaces such as tail lights and license plates, which would normally reflect enough of the infrared radiation to allow reliable detection. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Radar systems use radio frequency electromagnetic radiation for the detection of objects and are typically divided into either microwave or millimeter wave frequencies. The radar systems have the ability to operate in a much wider range of adverse weather conditions without any degradation in performance than is possible with sensors such as those described above, which operate in the visible light or infrared spectrums. However, the radar systems are generally more costly and must employ even more costly radar imaging technology (i.e. vertical/horizontal scanning radar, synthetic-aperture radar) to achieve the same level of object resolution available with the vision or laser systems. As a result, current affordable radar-imaging systems provide distance and side-to-side position (azimuth angle) information for detected objects, but no explicit up-and-down (elevation angle) information. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Current radar systems utilized on land vehicles use one of three major methods for modulating radar signals: pulse Doppler; frequency modulated continuous wave (FMCW) ramp; and frequency shift key (FESK). The modulation is typically combined with signal direction techniques. While the preferred direction technique is a horizontally- and vertically-scanned narrow beam, this is currently cost prohibitive, except for laser based sensors. The typically used techniques include horizontally-scanned which can give accurate results, but no vertical data; switched-beam which generally gives less accurate results, and no vertical data; and horizontal monopulse which generally gives more accurate results, but again, no vertical data. It should be recognized that as technology in these systems improves and become less expensive, many of these difficulties may be overcome to provide additional capabilities. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> Pulse Doppler modulation works similar to laser pulse to directly calculate an accurate distance to an object using elapsed time calculations. To reduce necessary processing, detected objects are generally sorted into distance ranges of a set amount chosen for the design, called &ldquo;distance bins&rdquo;; for vehicle radar, one meter is typically chosen for the &ldquo;distance bin&rdquo; size. A chosen transmit frequency is periodically pulsed for a very brief time to a higher frequency, and then back to the original transmit frequency. Returning signals can be processed into separate &ldquo;distance bins&rdquo; of objects, within which objects are processed into various Doppler &ldquo;bins&rdquo; to separate out objects moving at different speeds relative to the sensor. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> The FMCW ramp method uses time-varying changes in frequency which allows accurate distance and relative speed to be calculated for observed objects, based on changes in the modulation pattern in the returned versus broadcast signals. With this approach, moving and stationary individual objects can typically be identified as individual, separate objects based on their distances and horizontal locations. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> FSK is a simple version of FMCW which alternates frequencies between two or more frequencies over time in a step function. Distance and speed are determined independent of each other. This technology is typically used in conjunction with a monopulse direction technique comprising an antenna which uses a single transmit and two overlapping receive beams to derive the azimuth angle of each detected object. The measurement of distance, speed, and azimuth are very accurate with this system. However, since FSK is a Doppler-based technique and recognizes individual objects based on their relative speeds to the sensor, everything moving at the same speed (within a set narrow range) is considered to be the same object. This means that the distance and azimuth angle to each object is accurate for the centroid of everything observed by the radar with the same relative speed. For moving vehicles, this is usually umimportant as no two vehicles can match speeds closely enough to be confused. However, for stationary objects, since they are &ldquo;moving&rdquo; (relative to the sensor on the moving vehicle) towards the vehicle at the same speed as the rest of the stationary world, they are not detected as separate objects apart from their stationary surroundings. An individual roadside object will influence the distance and azimuth angle calculations to a greater degree if its radar-cross-section (RCS) is large, compared to its stationary surroundings, and if it is closer to the vehicle than its stationary surroundings (at least in the view of the radar sensor, which only detects within its narrowly-focused beam). The result is that the accurate locating capability of an FSK/monopulse sensor is somewhat limited for locating an individual stationary object in a cluttered stationary environment, at least unless/until the vehicle is close enough so that the object of interest is the only (or at least the most radar-return significant) object within the beam. This situation is also true of pulse Doppler processing, for objects processed into a given &ldquo;distance bin&rdquo; which are also moving at the same relative speed. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The present invention is designed to work with any of the above-described sensors, including those involving Doppler processing, which typically cannot separately identify stationary objects in the same &ldquo;Doppler bin&rdquo;. Due to the potential complications posed by Doppler processing of stationary objects, the discussion will focus on the behavior of the present invention when used with a Doppler-based sensor system. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> For a vehicle with an installed outward-looking sensor system, if the same path is taken repeatedly, and the same stationary objects are present, then (within some statistical scatter) the objects&apos; characteristics detected by the sensor from each given point along the path should be consistent and repeatable each time the same path is driven. These characteristics can include, but are not limited to, range, azimuth angle, signal return strength, and/or elevation angle. Also, the characteristics detected by the vehicle&apos;s sensor system along that path should change if stationary objects are added or removed from the observed area. Specifically in the case of a Doppler-based radar sensor, the amount of change, however, will depend on bow much influence the added (or removed) object has, in terms of relative RCS and relative position compared with other radar-reflective objects within the radar&apos;s beam. With a Doppler-based sensor, the addition of a new stationary object may not result in an additional object being identified as such. However, one or more characteristics detected for stationary objects in the nearby area along the path should change, and the significance of the changes in the detected characteristics can be examined to estimate the likelihood that an unusual stationary object is indeed present. According to the present invention, the data from the multiple passes by vehicles with similar sensors are stored and used to create a reference database which is accessed for comparison any time the vehicle encounters the same path. Any of the above sensor systems or new sensing systems which may be developed can be used to create the reference database of the invention as will be described in detail below. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> The following preferred embodiment of the present invention illustrates its use with a Doppler-based radar sensor system with only a single stationary &ldquo;target object&rdquo; detected along a travel path, which due to the Doppler-type processing as described above, may actually include more than one actual stationary object which are simultaneously detected within the radar beam, but whose near-identical speeds relative to the moving host vehicle result in their sharing the same &ldquo;Doppler bin&rdquo; during processing. As explained below, the phenomenon of &ldquo;apparent position&rdquo; of the detected stationary &ldquo;object&rdquo; moving in space as the host vehicle approaches the actual physical objects is not a problem for the present invention, since it never attempts to compare the absolute physical location of any of the individual physical objects with a calculated absolute position for the detected target object(s). Although a single target object is used for illustration, the detected presence of multiple target stationary objects is also easily handled by the present invention by simultaneously evaluating the multiple detected stationary objects against the reference database for the vehicle&apos;s present geographic area. This is true for multiple target objects detected simultaneously from a particular host vehicle location, whether by a Doppler-based sensor with objects whose relative speeds due to their positions in the radar beam differ enough to fall into separate Doppler bins for processing, or by non-Doppler-based sensors capable of detecting separate stationary objects as individual objects. Further, the comparison of multiple characteristics of a stationary target object detected by a sensor system with data stored in a reference database derived from detections by similar sensors operating with locating devices in the same geographical area on previous occasions is a technique which works with all types of sensor technologies, and which offers advantages over comparisons based on location comparisons alone. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 1, a</cross-reference> block diagram is shown detailing how a reference database <highlight><bold>23</bold></highlight> is created from multiple passes by a vehicle or mobile machine over the same path, such as a road segment, having at least one target object <highlight><bold>12</bold></highlight>. The target object <highlight><bold>12</bold></highlight> may, in the example of a collision warning system (CWS) <highlight><bold>19</bold></highlight>, normally create a nuisance alert to the operator of the host vehicle. A collision warning system normally consists of a sensor <highlight><bold>14</bold></highlight>, collision warning processor (CWP) <highlight><bold>20</bold></highlight>, and driver interface unit <highlight><bold>22</bold></highlight> connected by a common communications data bus as shown. Referring to <cross-reference target="DRAWINGS">FIGS. 1 and 2</cross-reference>, the sensor <highlight><bold>14</bold></highlight> identifies the target object <highlight><bold>12</bold></highlight> as the host vehicle approaches. The sensor <highlight><bold>14</bold></highlight> sends sensor data <highlight><bold>26</bold></highlight> related to the target object <highlight><bold>12</bold></highlight> to the CUP <highlight><bold>20</bold></highlight>. In normal operation, the sensor <highlight><bold>14</bold></highlight> transmits the sensor data <highlight><bold>26</bold></highlight> on a periodic basis (generally many times per second) to the CWP <highlight><bold>20</bold></highlight> which determines if an alert for the driver should be generated in response to the target object <highlight><bold>12</bold></highlight>. In this configuration, the host vehicle has a central processing unit <highlight><bold>16</bold></highlight> or equivalent processing capability, with software to &ldquo;time stamp&rdquo; incoming data messages immediately upon arrival, insert a sensor type <highlight><bold>30</bold></highlight>, consistent with the type of sensor <highlight><bold>14</bold></highlight> being used, after the &ldquo;time stamp&rdquo; for each sensor data <highlight><bold>26</bold></highlight> message, and provide for storage, except for certain measurement block data <highlight><bold>61</bold></highlight> that may be transmitted by vehicle location device <highlight><bold>18</bold></highlight>, as will be described. By time-stamping all appropriate arriving messages, using either actual time or the value of a high-frequency counter, the individual messages can later be analyzed with respect to their relative times of arrival, allowing sensor data <highlight><bold>26</bold></highlight> to be accurately related to location data <highlight><bold>28</bold></highlight> by their relative times of arrival at central processing unit <highlight><bold>16</bold></highlight>. The central processing unit <highlight><bold>16</bold></highlight> is linked to a collision warning system&apos;s data bus with necessary protocol conversion to allow it to monitor the CWS&apos;s messages from the sensor <highlight><bold>14</bold></highlight> to the CWP <highlight><bold>20</bold></highlight> and from the CWP <highlight><bold>20</bold></highlight> to the driver interface unit <highlight><bold>22</bold></highlight>, also known as a man-machine interface (MMI). The data messages <highlight><bold>26</bold></highlight> from the sensor <highlight><bold>14</bold></highlight> are captured, immediately time-stamped by appending onto the beginning of the data message the current timer value available to central processing unit <highlight><bold>16</bold></highlight>, with that becoming sensor time-stamp <highlight><bold>29</bold></highlight>, then inserting a sensor type <highlight><bold>30</bold></highlight> consistent with the type of sensor <highlight><bold>14</bold></highlight> being used, and temporarily stored by the central processing unit <highlight><bold>16</bold></highlight> in a data storage unit <highlight><bold>24</bold></highlight> as time-stamped sensor data <highlight><bold>26</bold></highlight>&prime;. At the same time, a vehicle locating device <highlight><bold>18</bold></highlight> transmits location data <highlight><bold>28</bold></highlight> to the central processing unit <highlight><bold>16</bold></highlight> on a periodic basis (generally once per second). Unless location data <highlight><bold>28</bold></highlight> is measurement block data <highlight><bold>61</bold></highlight>, it is also immediately time-stamped by appending onto the beginning of the data message the current timer value available to central processing unit <highlight><bold>16</bold></highlight>, with that becoming location time-stamp <highlight><bold>45</bold></highlight>, and temporarily stored by the central processing unit <highlight><bold>16</bold></highlight> in the data storage unit <highlight><bold>24</bold></highlight> as time-stamped vehicle location data <highlight><bold>28</bold></highlight>&prime;. If location data <highlight><bold>28</bold></highlight> is measurement block data <highlight><bold>61</bold></highlight>, it is sent without being time stamped to be temporarily stored by the central processing unit <highlight><bold>16</bold></highlight> in the data storage unit <highlight><bold>24</bold></highlight>. However, whenever a stationary-object alert is sent to the MMI <highlight><bold>22</bold></highlight> by the CWP <highlight><bold>20</bold></highlight>, the temporarily stored measurement block data <highlight><bold>61</bold></highlight>, time-stamped sensor data <highlight><bold>26</bold></highlight>&prime; and time-stamped location data <highlight><bold>28</bold></highlight>&prime; (representing a set period of time leading up to the detection of the target object) and the live measurement block data <highlight><bold>61</bold></highlight>, sensor data <highlight><bold>26</bold></highlight> and location data <highlight><bold>28</bold></highlight> are stored into permanent memory in the data storage unit <highlight><bold>24</bold></highlight> for a set time period past the end of any related stationary-object alerts, with location data <highlight><bold>28</bold></highlight> being converted into time-stamped location data <highlight><bold>28</bold></highlight>&prime; and sensor data <highlight><bold>26</bold></highlight> being converted into time-stamped sensor data <highlight><bold>26</bold></highlight>&prime; before being stored, as described above. In a preferred embodiment, central processing unit <highlight><bold>16</bold></highlight> contains software with decision logic which also evaluates whether the target object <highlight><bold>12</bold></highlight> would generate a stationary-object alert if the host vehicle were traveling at a higher speed up to a maximum level anticipated for vehicles in the current location; this would allow the vehicle capturing data to identify objects which could generate a stationary-object alert at a higher, and perhaps unsafe, speed without being required to actually attain that speed itself. In another preferred embodiment, the central processing unit <highlight><bold>16</bold></highlight> also contains software with decision logic which also evaluates whether the target object <highlight><bold>12</bold></highlight> has characteristics that do not make it a hazards but which may cause a smaller stationary object that could be hazardous to be ignored by the CWS <highlight><bold>19</bold></highlight> system; in that case, it would capture data for object <highlight><bold>12</bold></highlight> for use in that regard. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> Sensor data <highlight><bold>26</bold></highlight> is captured from the time the target object <highlight><bold>12</bold></highlight> was first detected until the closest point the vehicle came before passing by the target object <highlight><bold>12</bold></highlight>. Referring now to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the sensor data <highlight><bold>26</bold></highlight> in a preferred embodiment comprises a target number <highlight><bold>31</bold></highlight>, a fast Fourier transform (FFT) frame number <highlight><bold>32</bold></highlight>, a distance <highlight><bold>34</bold></highlight> to the detected object(s), a radar return magnitude <highlight><bold>36</bold></highlight>, relative speed <highlight><bold>38</bold></highlight> of the target object <highlight><bold>12</bold></highlight>, an azimuth angle <highlight><bold>40</bold></highlight> to the detected object(s), and a signal quality measure (M of N) <highlight><bold>42</bold></highlight>. It is also anticipated that object width <highlight><bold>41</bold></highlight>, an elevation angle <highlight><bold>43</bold></highlight>, and/or object height <highlight><bold>44</bold></highlight> could be transmitted from a sensor having the capability. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> In addition to the sensor data <highlight><bold>26</bold></highlight>, vehicle location data <highlight><bold>28</bold></highlight> is captured from the time the target object <highlight><bold>12</bold></highlight> was first detected until the closest point the vehicle came before passing by the target object <highlight><bold>12</bold></highlight>. The vehicle location device <highlight><bold>18</bold></highlight> may comprise a global positioning satellite (GPS) receiver to provide GPS-based location data to associate with the sensor data. The location data comprises a latititude <highlight><bold>46</bold></highlight>, a longitude <highlight><bold>48</bold></highlight> and a height <highlight><bold>50</bold></highlight> for the vehicle, a precise time for which the location is valid <highlight><bold>52</bold></highlight>, a heading <highlight><bold>54</bold></highlight> and a speed <highlight><bold>56</bold></highlight> of the vehicle. It is also contemplated that additional data can be obtained such as the number of satellites <highlight><bold>58</bold></highlight> used and a corresponding error estimate <highlight><bold>60</bold></highlight>. It is further contemplated that messages containing measurement block data <highlight><bold>61</bold></highlight> may be available from a GNSS-based vehicle location device <highlight><bold>18</bold></highlight>, as explained below. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> The vehicle location device <highlight><bold>18</bold></highlight> typically comprises a global navigation satellite system (GNSS) receiver such as a Global Positioning Satellite (GPS&mdash;U.S. satellites) receiver, a GLONASS (Russian satellites) receiver or a combined GPS/GLONASS receiver, but other developed systems could also be used. At this time, the most accurate positioning technology generally available for vehicles utilizes differential global positioning satellite (GPS) signals. A national radio-beacon based service is being developed by the United States government, called the National Differential GPS (NDGPS) system, with anticipated use by land vehicles and with a design goal of offering 10 meter or better positioning capability anywhere in the United States when fully deployed within several years. Another differential GPS service named the Wide Area Augmentation Service (WAAS) is also being developed by the United States government, primarily for aircraft use for Category I landings. This service, which will also be available within the next several years, is designed to offer 7.6 meter or better accuracy, and is provided via geostationary satellites broadcasting directly to GPS receivers over the same frequency used by the GPS satellites themselves. Preliminary results show that better results than the design goal may be possible for both systems, down to 2-3 meters accuracy with sophisticated GPS receivers designed to utilize those services. There are also certain commercial services which offer differential GPS corrections, with some claiming accuracies of approximately 1 meter with sophisticated GPS receivers. A significant increase in accuracy is available with even more sophisticated GPS processing using carrier phase differential corrections. The versions which allow operation from a moving vehicle with immediate results are called real time kinematic (RTK) products. These products can provide decimeter and even centimeter accuracy, but require the existence of a nearby GPS receiver and broadcast capability to the host vehicle. This technique is used in limited areas with some success, but broad use would require an extensive network of these stations, along with more sophisticated dual-frequency GPS receivers in the host vehicles themselves to allow quick accuracy recovery after satellite loss-of-lock when passing under overhead obstructions. While such a network would be feasible, only limited-area networks are known to exist or be planned in the United States. Further, even with the existence of such carrier-phase differential GPS corrections network, the associated dual-frequency, RTK GPS equipment required in the host vehicles may be more expensive than the single-frequency GPS technology currently available for use with existing commercial sources of differential GPS corrections and planned broadly-available NDGPS or WAAS. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> Improved accuracy is available by such devices designed to utilize any of several available differential GPS correction techniques that operate in real time. Such differential correction techniques include National Differential GPS differential corrections, Wide Area Augmentation Service (WAAS) differential corrections, or the use of Real-time Kinematic (RTK) techniques utilizing broadcast data from a compatible base station GPS receiver. The greatest accuracy during real time operation is currently available through RTK processing, but no broad network comparable to NDGPS or WAAS exists in the United States for it, and it requires more sophisticated and expensive GPS receivers to operate effectively than the other approaches, especially where frequent satellite blockage due to bridges, foliage, and/or tall buildings make use of dual-frequency receivers necessary to maintain acceptable high-precision operation. It is also contemplated that the measurement block data <highlight><bold>61</bold></highlight> data messages, if transmitted by vehicle location device <highlight><bold>18</bold></highlight>, can be post-processed with appropriate GNSS data from another source to provide greater location accuracy. Typical post-processing correction techniques include use of data available from the United States Government&apos;s Continuously Operating Reference Station (CORS) network, or data from another GPS receiver operating as a base station configured to record compatible GPS data for such purposes. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> Some vehicle locating devices use an inertial navigation unit (INU) on-board the host vehicle or some other on- or off-board equipment utilizing &ldquo;dead reckoning&rdquo; or similar technique with access to necessary data on vehicle motion. It is also contemplated that the vehicle location data can be obtained using a combination of satellite and inertial navigator systems in a vehicle navigation system. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> It is also contemplated that other locating devices which are not vehicle-based may be present with the driver in the vehicle and serve as the vehicle locating device while in the host vehicle. Such devices include cellular telephones utilizing built-in GPS capabilities and/or cellular telephone network-based location techniques, personal digital assistant devices with built-in GPS capabilities, and other types of portable devices with built-in location capabilities. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> It is further contemplated that in addition to the highest-accuracy primary vehicle locating device available, that other location devices may be utilized in cases when their performance is available and at least temporarily more accurate than the primary vehicle locating device. An example of this would be a single- or dual-frequency GNSS receiver utilized as the primary vehicle location device, with a vehicle navigation system, cellular telephone, or personal digital assistant available for backup for periods when temporary satellite blockage reduces the GNSS receiver&apos;s position. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> In order to reduce storage of unnecessary information, the data storage unit <highlight><bold>24</bold></highlight> comprises one or more temporary buffers (not shown) to store sensor data <highlight><bold>26</bold></highlight> and location data <highlight><bold>28</bold></highlight>. Only sensor data <highlight><bold>26</bold></highlight> and location data <highlight><bold>28</bold></highlight> related to stationary objects responsible for the stationary-object alert warning are saved in permanent storage (not shown) of the data storage unit <highlight><bold>24</bold></highlight>. When one buffer fills, another buffer is emptied and data <highlight><bold>26</bold></highlight>, <highlight><bold>28</bold></highlight> are stored there. Whenever a stationary-object alert is sent to the MMI <highlight><bold>22</bold></highlight> by the CWP <highlight><bold>20</bold></highlight>, the contents of the non-active buffer are stored into permanent memory, then the active buffer&apos;s contents are stored into permanent memory, and the &ldquo;live&rdquo; data <highlight><bold>26</bold></highlight>, <highlight><bold>28</bold></highlight> being captured is stored into permanent memory for a set time period past the end of any related stationary-object alerts. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the data <highlight><bold>26</bold></highlight>&prime;, <highlight><bold>28</bold></highlight>&prime;, <highlight><bold>61</bold></highlight> thus captured are then post-processed to form the reference database <highlight><bold>23</bold></highlight>. If measurement block data <highlight><bold>61</bold></highlight> are available, then the file containing that data is post-processed along with CORS data files <highlight><bold>70</bold></highlight> or similar data using post-processing software <highlight><bold>71</bold></highlight> such as NovaTel SoftSurv or equivalent. The CORS data files <highlight><bold>70</bold></highlight>, which are available from various CORS stations throughout the United States through the CORS web site, should be selected for the time periods during which the CWS <highlight><bold>19</bold></highlight> was operating and from stations as close to the geographic area where the CWS <highlight><bold>19</bold></highlight> was operating, to provide the best post-processed location accuracy. Various utility programs are also available through the same web site to decompress the downloaded files and interpolate the results to better match the data frequency of the measurement block data <highlight><bold>61</bold></highlight>. The result of the post processing, after selecting the desired data from the output, is location data <highlight><bold>28</bold></highlight>&Prime;, which matches location data <highlight><bold>28</bold></highlight>&prime;, except that it has no location time-stamp <highlight><bold>45</bold></highlight>, and that for periods in which differential GPS corrections were possible, its position accuracies are more accurate, indicated by having lower horizontal position error <highlight><bold>60</bold></highlight> values for data taken during those periods. A best-accuracy location data <highlight><bold>28</bold></highlight>&prime;&Prime; file is then created by replacing the values for location data <highlight><bold>28</bold></highlight>&prime; with the values found for data records with matching precise time <highlight><bold>52</bold></highlight>, if the horizontal position error estimate <highlight><bold>60</bold></highlight> is lower in the data record in the file location data <highlight><bold>28</bold></highlight>&Prime;. Note that location time-stamp <highlight><bold>45</bold></highlight> data should not be altered, and should exist in time-stamped best-accuracy location data <highlight><bold>28</bold></highlight>&prime;&Prime; after this process for each data record. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The next step in post processing, as shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, is to create a master reference database <highlight><bold>72</bold></highlight> from time-stamped best-accuracy location data <highlight><bold>28</bold></highlight>. and time-stamped sensor data <highlight><bold>26</bold></highlight>&prime;. Starting with the first sensor data <highlight><bold>26</bold></highlight>&prime; record, the following process should be performed to create the corresponding master reference database <highlight><bold>72</bold></highlight> record, until all sensor data <highlight><bold>26</bold></highlight>&prime; records have been processed. Using sensor time-stamp <highlight><bold>29</bold></highlight>, find the best-accuracy location data <highlight><bold>28</bold></highlight>&prime;&Prime; record whose location time-stamp <highlight><bold>45</bold></highlight> is closest to the same value. Then, using interpolation/extrapolation calculations, use values for latitude <highlight><bold>46</bold></highlight>, longitude <highlight><bold>48</bold></highlight>, height <highlight><bold>50</bold></highlight>, precise time <highlight><bold>52</bold></highlight>, heading <highlight><bold>54</bold></highlight>, speed <highlight><bold>56</bold></highlight>, number of satellites <highlight><bold>58</bold></highlight> and horizontal position error <highlight><bold>60</bold></highlight> from the chosen best-accuracy location data <highlight><bold>28</bold></highlight>&prime;&Prime; record and an adjacent one, to calculate latitude <highlight><bold>46</bold></highlight>&prime;, longitude <highlight><bold>48</bold></highlight>&prime;, height <highlight><bold>50</bold></highlight>&prime;, precise time <highlight><bold>52</bold></highlight>&prime;, heading <highlight><bold>54</bold></highlight>&prime;, speed <highlight><bold>56</bold></highlight>&prime;, number of satellites <highlight><bold>58</bold></highlight>&prime;, and horizontal position error <highlight><bold>60</bold></highlight>&prime;, consistent with a location time-stamp <highlight><bold>45</bold></highlight> value matching the chosen time-stamped sensor data <highlight><bold>26</bold></highlight>&prime; record&apos;s sensor time-stamp <highlight><bold>29</bold></highlight> value. Now, create the first data record in master reference database <highlight><bold>72</bold></highlight> with the following: latitude <highlight><bold>46</bold></highlight>&prime;, longitude <highlight><bold>48</bold></highlight>&prime;, height <highlight><bold>50</bold></highlight>&prime;, precise time <highlight><bold>52</bold></highlight>&prime;, heading <highlight><bold>54</bold></highlight>&prime;, speed <highlight><bold>56</bold></highlight>&prime;, number of satellites <highlight><bold>58</bold></highlight>&prime;, horizontal position error <highlight><bold>60</bold></highlight>&prime;, sensor type <highlight><bold>30</bold></highlight>, target number <highlight><bold>31</bold></highlight>, FFT frame number <highlight><bold>32</bold></highlight>, distance to detected object <highlight><bold>34</bold></highlight>, radar return magnitude <highlight><bold>36</bold></highlight>, relative speed <highlight><bold>38</bold></highlight>, azimuth angle <highlight><bold>40</bold></highlight>, signal quality <highlight><bold>42</bold></highlight>, object width <highlight><bold>41</bold></highlight>, elevation angle <highlight><bold>43</bold></highlight>, and object height <highlight><bold>44</bold></highlight>. The resulting master reference database <highlight><bold>72</bold></highlight> consists of every stationary object data point detected by the sensor <highlight><bold>14</bold></highlight> for a geographic area in which stationary objects <highlight><bold>12</bold></highlight> of interest were being detected, with all their observed characteristics recorded and indexed to the most-precise latitude/longitude/height position of the CWS <highlight><bold>19</bold></highlight> system available, along with the precise time that each observation was made. This master reference database <highlight><bold>72</bold></highlight> is designed to hold all data gathered for use by the present invention, and is used in the following steps to create the reference database <highlight><bold>23</bold></highlight> used by the present invention during real time operation, as will be shown below. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> The next step will use analytical methods to reduce the master reference data <highlight><bold>72</bold></highlight> to key relationships and statistical measures of data distributions. First, select all records for a particular sensor type <highlight><bold>30</bold></highlight>. It is important not to mix results from different types of sensor <highlight><bold>14</bold></highlight>, unless it is validated that results from certain different sensor types are consistent; this is because characteristics of objects are detected differently by various types of sensors. Second, for those records, to help identify all master reference database <highlight><bold>72</bold></highlight> relating to an individual stationary object <highlight><bold>12</bold></highlight>, calculate the latitude and longitude for each stationary object <highlight><bold>12</bold></highlight>, using the last observation in each observation sequence to benefit from the greater location accuracy provided by some types of sensors at close range. An approach to accomplish this is to sort the records using two sort keys&mdash;the primary key should be target number <highlight><bold>34</bold></highlight> and the secondary key should be precise time <highlight><bold>52</bold></highlight>&prime;. In that order, the last-occurring (that is, the one with the highest value of precise time <highlight><bold>52</bold></highlight>&prime;) record for each value of target number <highlight><bold>31</bold></highlight> should have the calculation performed. The calculation for object latitude <highlight><bold>74</bold></highlight> involves the values for latitude <highlight><bold>46</bold></highlight>&prime;, heading <highlight><bold>54</bold></highlight>&prime;, distance to object <highlight><bold>34</bold></highlight>, and azimuth angle <highlight><bold>40</bold></highlight>, plus conversion factors A and B to convert from the units of measure used for distance to object (typically feet or meters) and units of measure for the two angles (either degrees or radians) into measurement units for latitude and longitude, respectively. (Since the conversion from linear measurement to changes in longitude also depends on the local latitude, since lines of longitude converge as one moves away from the equator and towards either pole, a more accurate alternative is to receive the GPS-oriented X, Y, and Z location values which are typically in meters, rather than latitude, longitude, and height; in this way, the GPS receiver performs an accurate conversion before providing the figures.) The first equation is object latitude&equals;latitude&plus;A&times;(distance to object&times;cosine(heading&plus;azimuth angle)). The calculation for object longitude <highlight><bold>76</bold></highlight> involves the same data items, with that equation being object longitude,&equals;longitude&plus;B&times;(distance to object&times;sine(heading&plus;azimuth angle)). Once the object latitude <highlight><bold>74</bold></highlight> and object latitude <highlight><bold>76</bold></highlight> is calculated for the last data point in each sequence, all records in that sequence should have the just-calculated values for object latitude <highlight><bold>74</bold></highlight> and object longitude <highlight><bold>76</bold></highlight> entered into their data records. Once all data sequences have been processed in this way, resort the database using object latitude <highlight><bold>74</bold></highlight> and object longitude <highlight><bold>76</bold></highlight> as the two sort keys. (It doesn&apos;t matter which is the primary one&mdash;the object is simply to group the data files based on combinations of object latitude and object longitude.) Even though the values for object latitude <highlight><bold>74</bold></highlight> and object longitude <highlight><bold>76</bold></highlight> will only be exactly the same, even for the same stationary object <highlight><bold>12</bold></highlight>, for the records in a given observation sequence, the differences in values for object latitude and object longitude among records that observed the same stationary object <highlight><bold>12</bold></highlight> should be much smaller than those between observations of different stationary object <highlight><bold>12</bold></highlight> items. In the preferred embodiment, the final step in properly classifying each record according to the particular stationary object <highlight><bold>12</bold></highlight> it observed is to apply the following automated procedure: utilize a simple database routine or spreadsheet macro routine to start with the first record in the above sequence and calculate the difference in object latitude between it and-the next record, as well as the difference in object longitude between the first and the next record. Temporarily store both differences, and now calculate similar differences between the third record and the second one. If either of the second set of differences is not greater than some factor (perhaps 2, but this should be &ldquo;tuned&rdquo; based on results), then repeat the process with the next pair of records. Continue this until the calculated difference between a record and the last one is greater than the chosen factor times the stored value for object latitude difference or object longitude difference. At that point, generate a unique stationary object ID <highlight><bold>78</bold></highlight> value, assign it to all records just processed, but not including the record with the greater difference. Then repeat the process, treating the next record as the very first one was handled. With a little experience, this technique should assign a unique stationary object ID <highlight><bold>78</bold></highlight> to all records with observations for the same stationary object <highlight><bold>12</bold></highlight>. Another routine should check for unusually small numbers of records assigned to a given stationary object ID <highlight><bold>78</bold></highlight>, and generate reports on such records for human review and verification. That, with the additional technique of displaying the records&apos; object latitude and object longitude values on an x-y graph for human review, should permit the proper categorization of all records, according to the stationary objects observed, and assignment of a unique stationary object ID to all observation records in master reference database <highlight><bold>72</bold></highlight>. The final database structure for master reference database <highlight><bold>72</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, with each record consisting of values for data items <highlight><bold>46</bold></highlight>&prime;, <highlight><bold>48</bold></highlight>&prime;, <highlight><bold>50</bold></highlight>&prime;, <highlight><bold>52</bold></highlight>&prime;, <highlight><bold>54</bold></highlight>&prime;, <highlight><bold>56</bold></highlight>&prime;, <highlight><bold>58</bold></highlight>&prime;, <highlight><bold>60</bold></highlight>&prime;, <highlight><bold>30</bold></highlight>, <highlight><bold>31</bold></highlight>, <highlight><bold>32</bold></highlight>, <highlight><bold>34</bold></highlight>, <highlight><bold>36</bold></highlight>, <highlight><bold>38</bold></highlight>, <highlight><bold>40</bold></highlight>, <highlight><bold>42</bold></highlight>, <highlight><bold>43</bold></highlight>, <highlight><bold>44</bold></highlight>, <highlight><bold>45</bold></highlight>, <highlight><bold>74</bold></highlight>, <highlight><bold>76</bold></highlight>, and <highlight><bold>78</bold></highlight>. As additional observations are gathered, they are processed as shown above and added to master reference database <highlight><bold>72</bold></highlight>, which is maintained on a dedicated server and with support systems and procedures suitable for such large database applications. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Finally, reference database <highlight><bold>23</bold></highlight> can be created from master reference database <highlight><bold>72</bold></highlight>, which will be done whenever a new stationary object is identified and sufficient data are available, when additional data are received that indicate that some important characteristic of the stationary object seems to have changed and the new information is properly validated, and on a periodic basis simply to take advantage of the better results made possible by larger amounts of data and data reduction/statistical analysis methods. In order to take advantage of such analytical methods, as well as to minimize the size of reference database <highlight><bold>23</bold></highlight>, wherever possible data will be converted into equations of trendlines and accompanying measures of standard deviations to characterize the amount of &ldquo;data scatter&rdquo;. First, a conversion is made to take advantage of the precise timing accuracy available from the sensor <highlight><bold>14</bold></highlight> electronics, as well as its accuracy and reliability in measuring relative speeds between itself and a stationary object which is being approached. For graphical as well as multiple regression purposes, it is useful to convert the two dimensions of latitude <highlight><bold>46</bold></highlight>&prime; and longitude <highlight><bold>48</bold></highlight>&prime; into a single measure of distance traveled by the host vehicle along its constrained path, Vehicle Travel Distance to Target, or VTDT <highlight><bold>80</bold></highlight>. Each observation is generated by a fast Fourier transform (FFT) operation, with results being transmitted onto the data bus from sensor <highlight><bold>14</bold></highlight> on a very well-controlled basis. With sequentially-numbered FFT events, shown by FF frame number <highlight><bold>32</bold></highlight>, and values for precise time <highlight><bold>52</bold></highlight>, it is possible to calculate elapsed times between receipt of sequential FFT frames with great accuracy. With those precise time values between observations, plus relative speed <highlight><bold>38</bold></highlight> observed for stationary object <highlight><bold>12</bold></highlight>, which is really the closing speed of the host vehicle, it is possible to calculate the traveled distance between observations simply by the following equation: VTDT between successive sensor observations&equals;(precise time at first observation&minus;precise time at second observation)&times;relative speed. The approach for calculating values of VTDT for each observation point is to &ldquo;backtrack&rdquo; by starting with the last observation in the sequence and assigning its VTDT to be the detected distance to the stationary object at that closest point (which is the point at which the most accurate distance measurement to the stationary object is normally expected). Then, the VTDT is calculated for each of the earlier observations in turn, by calculating the VTDT between points as shown above, and adding that to the just-calculated observation&apos;s VTDT value. The result is that each observation point&apos;s VTDT value is a highly-accurate estimate of the distance the host vehicle would travel along its path before reaching the stationary object <highlight><bold>12</bold></highlight>. (Since by definition, it is not actually in the vehicle&apos;s path, this is more precisely the distance the vehicle would travel if it deviated after the last observation it made of the object and headed directly to it.) This conversion provides perhaps the most accurate estimate of the vehicle&apos;s actual travel path distance that would be available, except possibly from centimeter-level GNSS techniques with position fixes at 15 to 20 times per second. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> The next step is to perform an analysis to determine the polynomial equation which provides the &ldquo;best fit&rdquo; trendline for each of the observed stationary object characteristics versus VTDT, as well as to determine the standard deviation statistic as it varies with VTDT. The result for each characteristic is a polynominal equation that is a function of VTDT and derived constants. Assuming a third-order polynomial provides a good &ldquo;best fit&rdquo;, then the equations for characteristics of distance to object <highlight><bold>34</bold></highlight>, radar return magnitude <highlight><bold>36</bold></highlight>, and azimuth angle <highlight><bold>40</bold></highlight> are: </paragraph>
<paragraph lvl="0"><in-line-formula>Distance to object&equals;<highlight><italic>A</italic></highlight>1&times;(<highlight><italic>VTDI&circ; </italic></highlight>3)&plus;<highlight><italic>B</italic></highlight>1&times;(<highlight><italic>VTDT&circ; </italic></highlight>2)&plus;<highlight><italic>C</italic></highlight>1&times;(<highlight><italic>VTDT</italic></highlight>)&plus;<highlight><italic>D</italic></highlight>1 </in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>Distance to <highlight><italic>ob SD&equals;A</italic></highlight>2&times;(<highlight><italic>VTDT&circ; </italic></highlight>3)&plus;<highlight><italic>B</italic></highlight>2&times;(<highlight><italic>VTDT&circ; </italic></highlight>2)&plus;<highlight><italic>C</italic></highlight>2&times;(<highlight><italic>VTDT</italic></highlight>)&plus;<highlight><italic>D</italic></highlight>2 </in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>Radar return mag.&equals;<highlight><italic>A</italic></highlight>3&times;(<highlight><italic>VTDT&circ; </italic></highlight>3)&plus;<highlight><italic>B</italic></highlight>3&times;(<highlight><italic>VTDT&circ; </italic></highlight>2)&plus;<highlight><italic>C</italic></highlight>3&times;(<highlight><italic>VTDT</italic></highlight>)&plus;<highlight><italic>D</italic></highlight>3 </in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>Radar ret mag <highlight><italic>SD&equals;A</italic></highlight>4&times;(<highlight><italic>VTDT&circ; </italic></highlight>3)&plus;<highlight><italic>B</italic></highlight>4&times;(<highlight><italic>VTDT&circ; </italic></highlight>2)&plus;<highlight><italic>C</italic></highlight>4&times;(<highlight><italic>VTDT</italic></highlight>)&plus;<highlight><italic>D</italic></highlight>4 </in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>Azimuth angle&equals;<highlight><italic>A</italic></highlight>5&times;(<highlight><italic>VTDT&circ; </italic></highlight>3)&plus;<highlight><italic>B</italic></highlight>5&times;(<highlight><italic>VTDT&circ; </italic></highlight>2)&plus;<highlight><italic>C</italic></highlight>5&times;(<highlight><italic>VTDT</italic></highlight>)&plus;<highlight><italic>D</italic></highlight>5 </in-line-formula></paragraph>
<paragraph lvl="0"><in-line-formula>Azimuth angle SD&equals;<highlight><italic>A</italic></highlight>6&times;(<highlight><italic>VTDT&circ; </italic></highlight>3)&plus;<highlight><italic>B</italic></highlight>6&times;(<highlight><italic>VTDT&circ; </italic></highlight>2)&plus;<highlight><italic>C</italic></highlight>6&times;(<highlight><italic>VTDT</italic></highlight>)&plus;<highlight><italic>D</italic></highlight>6 </in-line-formula></paragraph>
<paragraph id="P-0045" lvl="7"><number>&lsqb;0045&rsqb;</number> So, using a third-order polynomial equation to describe the trendline for a characteristic as related to VTDT, and another third-order polynomial equation to describe the possible change in those data&apos;s standard deviation with values of VTDT, allows only eight numbers to describe these relationships. As a result, a preferred embodiment of the present invention which utilizes the three stationary object characteristics of distance to object <highlight><bold>34</bold></highlight>, radar return magnitude <highlight><bold>36</bold></highlight>, and azimuth angle <highlight><bold>40</bold></highlight> can have those characteristics&apos; relationships to position on the vehicle path VTDT <highlight><bold>80</bold></highlight> as it approaches the stationary object <highlight><bold>12</bold></highlight> fully described with only 24 values: A1, B1, C1, D1, A2, B2, C2, D2, A3, B3, C3, D3, A4, B4, C4, D4, A5, B5, C5, D5, A6, B6, C6, and D6. The remaining information necessary for reference database <highlight><bold>23</bold></highlight> that is necessary for real time operation of the present invention involves another conversion&mdash;how to convert the location data <highlight><bold>28</bold></highlight> provided by the vehicle locating device <highlight><bold>18</bold></highlight> on a real time basis into the VTDT coordinates used for the reference database <highlight><bold>23</bold></highlight> purposes. Once again, this information is derived from the observation data contained in master reference database <highlight><bold>72</bold></highlight>. By performing a multiple regression of previous observations of latitude <highlight><bold>46</bold></highlight>&prime; and longitude <highlight><bold>48</bold></highlight>&prime; onto VTDT <highlight><bold>80</bold></highlight>, the resulting relationship allows real time observations of the latitude <highlight><bold>46</bold></highlight> and longitude <highlight><bold>48</bold></highlight> to be converted into VTDT, which then permits calculation of trendline and standard deviation comparisons against characteristics being observed in real time with results from previous observations using similar sensors <highlight><bold>14</bold></highlight> from the same location on the vehicle path as the stationary object <highlight><bold>12</bold></highlight> was being approached. The resulting multiple regression formula takes the form of VTDT&equals;A&plus;B&times;latitude&plus;C &times;longitude, so the relationship can be specified with the three constants A, B, and C. The resulting structure for reference database <highlight><bold>23</bold></highlight> is shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, which is that the subset of database <highlight><bold>23</bold></highlight> which fully describes the necessary information for one stationary object <highlight><bold>12</bold></highlight> consists of the following 27 constant values: A, B, C, A1, B1, C1, D1, A2, B2, C2, D2, A3, B3, C3, D3, A4, B4, C4, D4, A5, B5, C5, DS, A6, B6, C6, and D6. These items, plus the latitude <highlight><bold>46</bold></highlight>&prime;, longitude <highlight><bold>48</bold></highlight>&prime;, and heading <highlight><bold>54</bold></highlight>&prime; from the first observation point in the master reference database <highlight><bold>72</bold></highlight> involving this particular stationary object <highlight><bold>12</bold></highlight>, are stored in a file using the stationary object ID <highlight><bold>78</bold></highlight> as its name, to easily relate that file back to the observation records in the master reference database <highlight><bold>72</bold></highlight> from which it was derived. For example, a reference database <highlight><bold>23</bold></highlight> file for stationary object <highlight><bold>12</bold></highlight> with a stationary object ID <highlight><bold>78</bold></highlight> of 12345 would have a file name in the reference database of 12345.rdb, with the rdb extension name signifying that it is a member of the reference database. As will be explained more fully below, the reason for the inclusion of the latitude, longitude, and heading of the first observation point for a particular stationary object in its reference database file is to allow quick identification of two things&mdash;that it is valid for an area that includes the given latitude and longitude coordinates, and that it should be used on a real time basis when a vehicle is approaching the given latitude and longitude coordinates, and traveling in a direction consistent with the heading that is expected that the vehicle will be traveling when it reaches those coordinates. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> Referring now to <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the block diagram shows how the reference database <highlight><bold>23</bold></highlight> is used during normal operation. As in the creation of the reference database <highlight><bold>23</bold></highlight>, the sensor <highlight><bold>14</bold></highlight> detects a target object <highlight><bold>12</bold></highlight>. The sensor data <highlight><bold>26</bold></highlight> is sent to the CWP<highlight><bold>20</bold></highlight> and is also sent to the central processing unit <highlight><bold>16</bold></highlight>. The vehicle locating device <highlight><bold>18</bold></highlight> sends vehicle location data <highlight><bold>28</bold></highlight> to the central processing unit <highlight><bold>16</bold></highlight>. Each time that sensor data <highlight><bold>26</bold></highlight> is received by central processing unit <highlight><bold>16</bold></highlight>, the sensor data <highlight><bold>26</bold></highlight> and location data <highlight><bold>28</bold></highlight> being captured real-time by the central processing unit <highlight><bold>16</bold></highlight> are compared to the recorded data from the reference database <highlight><bold>23</bold></highlight> for that highway segment, if any. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> If no data exist for that highway segment and it is included in the routes evaluated, then a communication is sent immediately to the CWS that there is highest confidence that the object is not &ldquo;road furniture&rdquo; and an appropriate message will be sent from central processing unit <highlight><bold>16</bold></highlight> to CWP <highlight><bold>20</bold></highlight> to that effect, whose logic will take that into account in determining whether stationary alert and/or other actions should be taken immediately. In many cases, This will allow the CWS to sound a valid alert sooner than it would have, since it would normally wait until it was close enough to discount the possibility that overhead structures or objects along curves were being seen. If either had been the case, that segment of highway would have had data recorded for them; the absence of such data confirms that no such situation normally exists there. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> If data do exist for that highway segment, then the real-time data are compared with the recorded data as will be discussed in detail below. One method of the present invention is to calculate a probability whether detected object(s) are only normal stationary items positioned along the roadway which do not constitute a threat to the CWS host vehicle i.e., not one of those object plus additional stationary object(s) which do appear hazardous. However, a simpler approach, which also address the same situations, is used in a preferred embodiment, and is illustrated in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> The following process will start whenever the host vehicle approaches the section of roadway that corresponds to a datafile in the reference database. Referencing <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, the central processing unit <highlight><bold>16</bold></highlight> will retrieve from the reference database <highlight><bold>23</bold></highlight> the stored file for the next section of highway containing an object that could generate a nuisance alert by knowing where the vehicle is located and its heading, based on continual updates from the vehicle location device <highlight><bold>18</bold></highlight>. The central processing unit <highlight><bold>16</bold></highlight> will store data from the file in its active memory, for fast calculations as the vehicle reaches the same locations with data recorded in the file that was retrieved. As the vehicle is moving, its current location and heading as identified by vehicle locating device <highlight><bold>18</bold></highlight> are used to identify all files in reference database <highlight><bold>23</bold></highlight> which include data for paths which the host vehicle could be following, for each new sensor datapoint, the following process takes place. If, based on location, heading, and location accuracy as identified by vehicle locating device <highlight><bold>18</bold></highlight>, there are multiple files identifying paths which the host vehicle could be following or about to follow, then the following process will be executed simultaneously for each of those reference database <highlight><bold>23</bold></highlight> files. For simplicity, the following illustrates the process using a single file from the reference <highlight><bold>23</bold></highlight> database. First, constants A <highlight><bold>88</bold></highlight>, B <highlight><bold>90</bold></highlight>, and C <highlight><bold>92</bold></highlight> are retrieved to be used with current latitude <highlight><bold>46</bold></highlight> and longitude <highlight><bold>48</bold></highlight>, as determined from such data from recent location data <highlight><bold>28</bold></highlight> reported to the central processing unit <highlight><bold>16</bold></highlight> by the vehicle locating device <highlight><bold>18</bold></highlight>, to calculate variable VDTD, using the equation VDTD&equals;A&times;latitude&plus;B&times;longitude&plus;C. Referring now to <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the position reported by the vehicle locating device <highlight><bold>18</bold></highlight> is shown on the x axis, along with its 2 standard deviation data distribution. For illustration, it is assumed that a Differential GPS system is in use, with a 2 standard deviation error of 10 meters. By locating the intersection of that range of location along the x axis, plus the range of reported distance for the current radar datapoint plus its 2 standard deviation distribution, and the 2 standard deviation distribution of the stored database for distance vs. position, Region A is generated. If there is no overlap, then the test based on a 2 standard deviation data distribution level fails at this point. If there is an overlap, as illustrated, then the next step is to transfer the Region A&apos;s x-axis range down to the stored database&apos;s 2 standard deviation distribution for magnitude versus position, which forms Region B. The last step is to create Region C by intersecting the reported magnitude plus its 2 standard deviation distribution with the reported position and its 2 standard deviation distribution, forming Region C. If there is no overlap between Region B and Region C, as is the case in this illustration, then the test based on a 2 standard deviation data distribution fails at this point. If there is overlap between Region B and Region C, then the test based on 2 standard deviation data distribution is passed. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> In a preferred embodiment, the above evaluation is first done assuming a 1 standard deviation data distribution. The test is passed, then that result is reported as described elsewhere. However, if it is failed, then the test is repeated using a 2 standard deviation data distribution assumption. The same process is repeated up to a maximum of an 8 standard deviation assumption. If the test is never passed at that level, then a &ldquo;maximum level exceeded&rdquo; message is communicated rather than proceeding further. These results are called &ldquo;stationary-object test&rdquo; results. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> Each time the test is run, the result is reported by the central processing unit <highlight><bold>16</bold></highlight> to the CWP <highlight><bold>20</bold></highlight> where the CWS logic will take the results of the test into account to determine its most appropriate action. In cases when a warning would have mistakenly been given (&ldquo;nuisance alert&rdquo;) due to ordinary, non-hazardous highway infrastructure, the continued passing of the central processing unit&apos;s test at very low standard deviation data distribution levels may be used by the CWV <highlight><bold>20</bold></highlight> to suppress the nuisance alert, depending on the particular standard deviation data distribution level achieved by the test and the level required by the CWP <highlight><bold>20</bold></highlight> to withhold action. In a preferred embodiment, further statistics from the reference database <highlight><bold>23</bold></highlight> file being used for the analysis are also communicated from the central processing unit <highlight><bold>16</bold></highlight> to the CWP <highlight><bold>20</bold></highlight>, which may also be taken into account by the CWP&apos;s logic which determines appropriate actions to take regarding possible alerts and/or other actions. In other cases when a warning would have been delayed during detection of an object believed to be in the vehicle&apos;s path, but far enough away to possibly be a bridge or other structure that could trigger a higher level of nuisance alerts, if the test is passed at only high standard deviation data distribution levels, then the detected stationary object may be unusual and the CWP <highlight><bold>20</bold></highlight> may choose to initiate action earlier than it would otherwise have done. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> The general concept is that the stored reference database of sensor data and location data for non-hazardous stationary objects along a specific stretch of roadway provides a &ldquo;truth table&rdquo; with multiple variables to use for attempting to discern whether a stationary object detected along the same stretch of highway appears with some degree of likelihood to be the same object whose radar data were recorded because a nuisance alert could normally be sounded by the particular type of CWS. More than mere location is needed, to help discern the situation of finding both the expected stationary object and some hazardous object in much the same location. This could easily occur with stalled cars under bridges, in tunnels, or even parked in the roadway close enough to a guardrail, tree, or other stationary object whose location could be recorded in the database. By utilizing the strength of the radar return, which will vary with the objects being illuminated by the beam as well as their respective radar cross-sections, as well as distance and azimuth angle from the radar&apos;s point of view along the entire stretch of roadway approaching the object, the ability to differentiate a hazardous situation with an unexpected stationary object in the roadway near a stationary object recorded in the database, is greatly enhanced. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Results of the stationary-object tests at various confidence levels are communicated via the data link to the CWS, with each related to the specific object and timeframe that were evaluated. The CWS will be designed to modify its stand-alone alert/action logic to factor in these stationary-object test. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> The database will need to be updated as changes are made to the highway infrastructure, to prevent &ldquo;aging&rdquo; of the performance improvement that this invention will provide the CWS and other related systems. There are a variety of methods available for updating the database. For databases where the full database is on a permanent storage medium, these can be updated with replacement media substituted for original media in customer&apos;s vehicle on as-needed or periodic basis (e.g., DVD disk replaced by updated disk) </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> Another technique involves supplementing the database employing a permanent storage medium, updated with database files transmitted by wireless communication to the host vehicle (e.g., DVD disk augmented with files transmitted to the vehicle and stored in temporary but nonvolatile memory, until updated DVD replaces existing one). It is also contemplated that the wireless link is also used to collect data from the customer&apos;s vehicles to identify potential database updates and perhaps to gather enough data to create the database updates, which are then transmitted to appropriate vehicles. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> In a further technique, all needed database files are transmitted via wireless communication to host vehicle, where they are stored in temporary but nonvolatile memory and the most-current location-specific files transmitted to the host vehicle in advance of time that they will be needed. The wireless link may also be used to collect data from the customer&apos;s vehicles to identify potential database updates and perhaps to gather enough data to create the database updates, which are then transmitted to appropriate vehicles. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> It is also contemplated, and is a preferred embodiment of the present invention, that the wireless communication link to customer host vehicles can operate through an Internet web site, which distributes needed database files to customer vehicles and also serves as e-commerce link for various database-related sales transactions and offering other opportunities of potential interest to the customer base. The Internet web site similarly could be used to collect data from the customer&apos;s vehicles for database updates. With such an approach, communication procedures will be utilized to maximize the customer&apos;s privacy with regard to vehicle location, unless such privacy is explicitly waived by the customer. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> It is also contemplated that, in addition to communicating results of the evaluation as described above and illustrated in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> to the CWP <highlight><bold>20</bold></highlight> for use as described, that such results are also used to determine when it would be useful to provide information to identify the location of any stationary objects <highlight><bold>12</bold></highlight> whose results of said evaluation make them appear to be unusual. In such case, it is a preferred embodiment of the present invention to provide such information on a timely basis to improve the driver&apos;s situation awareness of the forward driving environment. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> As can be seen, the present invention provides a method of utilizing the current state of the art sensor technology, and is adaptable to include improvements in next generation sensors as the cost makes these more available. There are an innumerable amount of methods available to utilize the data obtained by the present invention to calculate probabilities to determine whether a stationary object is indeed a nuisance alert. Review of several features universal to all the embodiments must be noted. First, the invention can be adapted for use with any sensor based object detection system, such as CWS, CAW and/or ACC system. The primary difference between the different CWS, CAW and/or ACC systems is the type of sensor, modulation techniques and signal direction techniques employed. The invention enhances the performance of any of these systems by providing a reference database of sensor and location data generally obtained with the same type system as which it is currently deployed. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> Secondly, while the configuration of the invention can be designed to be integral to the CWS and/or ACC system, the invention can also be a stand alone unit added to an existing CWS and/or ACC system. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> Third, the present invention is not limited to automobiles, but can be used on any land-based vehicles. These land-based vehicles include, but are not limited to, mobile machines such as mining machines, heavy construction machines and robots, whether manned or unmanned; on road vehicles such as heavy trucks, busses, passenger cars, minivans, light trucks and specialty vehicles (snowplow, emergency, etc.); and off-road vehicles such as heavy vehicles (military trucks, etc.), light vehicles (all-terrain vehicles, etc.), and others such as tracked vehicles (tanks, etc.). </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Finally, the present invention is not limited by the sensor direction and/or range. Although preferred embodiments of the invention have been described herein, various modifications or variations will be apparent to one skilled in the art without departing from the principles and teachings herein. Accordingly, the invention is not to be limited to the specific embodiments illustrated, but is only intended to be limited by the scope of the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A process to develop a reference database in conjunction with a system for stationary object detection, comprising the steps of: 
<claim-text>1) acquiring signals from at least one sensor, said sensor capable of sensing target objects and generating data related to said target objects; </claim-text>
<claim-text>2) storing said data from said at least one sensor in a temporary storage buffer; </claim-text>
<claim-text>3) determining the location of said at least one sensor; and </claim-text>
<claim-text>4) indexing said data with respect to at least one of said target object data or said sensor location for subsequent comparison to real time data acquired from at least one sensor located on a mobile machine or vehicle to evaluate whether said target object is or is not a normally-present object. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The process according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising the steps of: 
<claim-text>acquiring data from a vehicle locating device associated with said vehicle as said vehicle travels along a path providing said data from said at least one sensor to a collision warning system associated with said vehicle, said collision warning system generating signals indicating a possible collision of said vehicle with an obstacle; and </claim-text>
<claim-text>monitoring the signals from said collision avoidance system to a man-machine interface; and </claim-text>
<claim-text>permanently capturing said data from said at least one sensor and said vehicle locating device in response to a stationary target warning message from said collision avoidance system to said man-machine interface wherein said stationary target warning message relates to a non-collision situation or nuisance alert. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The process of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference> wherein said process is repeated more than once and includes a final step of combining the data from at least one sensor and said vehicle locating device from said path at a location which generated a nuisance alert in a manner increasing the confidence in said data. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. A process of creating a reference database comprising: 
<claim-text>1) obtaining sensor data of a target using at least one sensor device; </claim-text>
<claim-text>2) obtaining vehicle location data using a vehicle location device; </claim-text>
<claim-text>3) recording said sensor data and said vehicle location data for a selected time period within which a nuisance alert is generated by a vehicle collision avoidance system; </claim-text>
<claim-text>4) repeating steps 1-3 for a particular segment of the path of said vehicle; and </claim-text>
<claim-text>5) creating a database in which said particular segment in which said nuisance alert was generated is indexed using predetermined criteria. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference> wherein said sensor data of a target object comprises a target number, a fast Fourier transform number, a distance to the target, an azimuth angle to the target, a magnitude of sensor return and a quality indicator. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00004">claim 4</dependent-claim-reference>, wherein said vehicle location data comprises a latitude, a longitude, a heading, a velocity and a time. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A reference database comprising: 
<claim-text>records of associated data, each of said records containing at least sensor location data for a radar-based sensor and at least a distance and an azimuth angle to a stationary object relative to said sensor location. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The reference database of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, further comprising 
<claim-text>said records include a sensor signal return magnitude, and said azimuth angle is for all target objects along a path of said vehicle that were responsible for a nuisance alert during data capture. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The reference database of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein said data are retrievable by sensor location for each observation record. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The reference database of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein said data further comprise a stationary target object location, and wherein each of said records is retrievable by said stationary target object location. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The referenced database of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein said data resides on a replaceable permanent storage medium, wherein said database is updated by replacing said permanent storage medium with an updated version. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The reference database of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference> wherein said data is transmitted to a temporary storage medium located on a mobile machine or vehicle by wireless communications.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>4</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030004644A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030004644A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030004644A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030004644A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030004644A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
