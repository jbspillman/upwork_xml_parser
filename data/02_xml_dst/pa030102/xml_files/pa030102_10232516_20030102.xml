<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002750A1-20030102-D00000.TIF SYSTEM "US20030002750A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002750A1-20030102-D00001.TIF SYSTEM "US20030002750A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002750A1-20030102-D00002.TIF SYSTEM "US20030002750A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002750A1-20030102-D00003.TIF SYSTEM "US20030002750A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002750A1-20030102-D00004.TIF SYSTEM "US20030002750A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002750A1-20030102-D00005.TIF SYSTEM "US20030002750A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002750A1-20030102-D00006.TIF SYSTEM "US20030002750A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002750A1-20030102-D00007.TIF SYSTEM "US20030002750A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002750A1-20030102-D00008.TIF SYSTEM "US20030002750A1-20030102-D00008.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002750</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10232516</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020903</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>9-245522</doc-number>
</priority-application-number>
<filing-date>19970910</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06K009/36</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>382</class>
<subclass>284000</subclass>
</uspc>
</classification-us-primary>
</classification-us>
<title-of-invention>System and method for displaying an image indicating a positional relation between partially overlapping images</title-of-invention>
</technical-information>
<continuity-data>
<division-of>
<parent-child>
<child>
<document-id>
<doc-number>10232516</doc-number>
<kind-code>A1</kind-code>
<document-date>20020903</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09150288</doc-number>
<document-date>19980909</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>GRANTED</parent-status>
<parent-patent>
<document-id>
<doc-number>6466701</doc-number>
<country-code>US</country-code>
</document-id>
</parent-patent>
</parent-child>
</division-of>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Koichi</given-name>
<family-name>Ejiri</family-name>
</name>
<residence>
<residence-non-us>
<city>Chiba</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Shin</given-name>
<family-name>Aoki</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Takashi</given-name>
<family-name>Saitoh</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Guan</given-name>
<family-name>Haike</family-name>
</name>
<residence>
<residence-non-us>
<city>Kanagawa</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Takuji</given-name>
<family-name>Sakamoto</family-name>
</name>
<residence>
<residence-non-us>
<city>Tokyo</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>DICKSTEIN SHAPIRO MORIN &amp; OSHINSKY LLP</name-1>
<name-2></name-2>
<address>
<address-1>2101 L STREET NW</address-1>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20037-1526</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A camera system includes a display monitor which displays an image of an object, taken by an optical unit, on a screen of the monitor. A reading unit reads a preceding image and a current image among a plurality of partially overlapping images, from a memory device, the preceding image and the current image containing a common element. A determining unit determines a positional relation between the preceding image and the current image based on a common pattern derived from the common element in the two adjacent images read by the reading unit. A displaying unit displays an image indicating a boundary of the preceding image on the screen of the monitor at a shifted position according to the positional relation determined by the determining unit, with the current image concurrently displayed on the screen of the monitor. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> (1) Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to a camera system which electronically stores an image of an object and displays the image on a display monitor. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> (2) Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Generally, to achieve an adequately high level of resolution of an image captured by using a digital camera or a video camera, it is necessary to use a zoom-up function of the camera or move the camera close to an object to be imaged. This makes it difficult to obtain an image covering a wide angle related to the object. To capture an image covering a wide angle related to the object, it is necessary to use a zoom-down function of the camera or move the camera away from the object. However, this makes it difficult to obtain an image with a high level of resolution. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> In order to obtain a wide-angle image with a high resolution from an object, a divisional shooting method has been proposed. In the divisional shooting method, a plurality of partially overlapping images are successively shot so as to cover a wide angle related to the object, and they are synthesized to create a composite image with an adequate level of resolution. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> As disclosed in Japanese Published Utility Model Application No. 8-4783, an image processing device which is capable of combining a plurality of partially overlapping images together to create a composite image is known. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> To effectively carry out the divisional shooting method, it is necessary that, after a preceding image is taken and before a current image is taken, the user stop movement of an optical axis of the camera at an appropriate position where an overlapping portion of the two adjacent images is appropriate for subsequently producing a composite image from the images. However, in order to meet this requirement, a conventional digital camera requires a special adapter. If such an adapter is not used, it is difficult for the conventional digital camera to effectively carry out the divisional shooting method. In a case of the conventional digital camera with no special adapter, there is a possibility that no overlapping portion exists between the two adjacent images or a too large overlapping portion be produced between the two adjacent images. If the overlapping images with undesired overlapping portions are obtained through the divisional shooting method, it is difficult to effectively combine or synthesize the images together to create a composite image. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> An object of the present invention is to provide a camera system which displays an image indicating a positional relation among partially overlapping images, and enables an operator to easily and effectively carry out a divisional shooting process. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Another object of the present invention is to provide a divisional shooting method which displays an image indicating a positional relation among partially overlapping images on a screen of a monitor during a divisional shooting mode of a camera system. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> The above-mentioned objects of the present invention are achieved by a camera system which comprises: a display monitor which displays an image of an object, taken by an optical unit, on a screen of the monitor; a reading unit which reads a preceding image and a current image among a plurality of partially overlapping images, from a memory device, the preceding image and the current image containing a common element; a determining unit which determines a positional relation between the preceding image and the current image based on a common pattern derived from the common element in the two adjacent images read by the reading unit; and a displaying unit which displays an image indicating a boundary of the preceding image on the screen of the monitor at a shifted position according to the positional relation determined by the determining unit, with the current image concurrently displayed on the screen of the monitor. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The above-mentioned objects of the present invention are achieved by a divisional shooting method for a camera system in which at least two of partially overlapping images of an object, taken by an optical unit, are displayed, comprising the steps of: reading a preceding image and a current image among the partially overlapping images, from a memory device, the preceding image and the current image containing a common element; determining a positional relation between the preceding image and the current image based on a common pattern derived from the common element in the two adjacent images; and displaying an image, indicating a boundary of the preceding image, on a screen of a display monitor at a shifted position according to the positional relation determined by the determining step, with the current image concurrently displayed on the screen of the monitor. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> In the camera system of the present invention, a positional relation between the preceding image and the current image is determined based on a common pattern derived from the common element in the two adjacent images. The operator can easily carry out a divisional shooting mode of the camera system by viewing both the current image and the image indicating the positional relation between the partially overlapping images on the screen of the monitor. The positional relation between the preceding image and the current image is clearly noticeable to the operator by viewing the positional relation image on the screen of the monitor together with the current image while the camera is panned in a desired direction. Therefore, the operator easily stops the movement of the optical axis of the camera at an appropriate position by viewing the positional relation image on the screen of the monitor, and turns ON a shutter switch to store the current image.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Other objects, features and advantages of the present invention will become more apparent from the following detailed description when read in conjunction with the accompanying drawings in which: </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram of a preferred embodiment of a camera system of the present invention; </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is a flowchart for explaining a first example of a divisional shooting process performed by a processor of the camera system; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference>A and <cross-reference target="DRAWINGS">FIG. 3B</cross-reference> are diagrams showing an image which is displayed on a screen of a display monitor when the camera is moved in a given direction; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is a flowchart for explaining a second example of the divisional shooting process performed by the processor of the camera system; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a flowchart for explaining a third example of the divisional shooting process performed by the processor of the camera system; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a flowchart for explaining a fourth example of the divisional shooting process performed by the processor of the camera system; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flowchart for explaining an image storage process performed by the processor of the camera system when a shutter switch is turned ON; and </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference>A and <cross-reference target="DRAWINGS">FIG. 8B</cross-reference> are diagrams for explaining a determination of a positional relation between partially overlapping images in the divisional shooting process according to the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> A description will now be given of the preferred embodiments of the present invention with reference to the accompanying drawings. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> In order to carry out a divisional shooting process, the present invention utilizes a method and a system for determining a positional relation between partially overlapping images based upon a common pattern in an overlapping portion of the images. The method and the system are disclosed, for example, in U.S. patent application Ser. No. 08/807,571 filed on Feb. 27, 1997 and U.S. patent application Ser. No. 08/966,889 filed on Nov. 10, 1997, both assigned to the applicant of the present application. The contents of these co-pending applications are hereby incorporated by reference. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows a preferred embodiment of a camera system of the present invention. One example of the camera system of the present invention is a digital camera. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the camera system of the present embodiment includes an optical unit <highlight><bold>10</bold></highlight>. The optical unit <highlight><bold>10</bold></highlight> has an image pickup device <highlight><bold>12</bold></highlight>, a lens (not shown), and a lens positioner (not shown). The image pickup device <highlight><bold>12</bold></highlight> is comprised of a charge-coupled device (CCD). The image pickup device <highlight><bold>12</bold></highlight> converts light incident from an object into an electrical signal, or an image signal indicative of an input image of the object or the scene. The lens positioner mechanically positions the lens of the optical unit <highlight><bold>10</bold></highlight> at a desired distance from the object along an optical axis of the lens. Hereinafter, the lens of the optical unit <highlight><bold>10</bold></highlight> will be referred to as the camera. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> In the camera system of the present embodiment, a lens positioner actuator <highlight><bold>14</bold></highlight> actuates the lens positioner of the optical unit <highlight><bold>10</bold></highlight> so that the lens is positioned at a desired distance from the object along the optical axis of the lens. An operation part <highlight><bold>16</bold></highlight> is an operation part of the camera system of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, which includes a mode selection switch <highlight><bold>18</bold></highlight>, a shutter switch <highlight><bold>20</bold></highlight>, and other control switches (not shown). An operator can manipulate one of such switches of the operation part <highlight><bold>16</bold></highlight> so as to select one of operational modes of the camera system or to release the shutter of the camera system. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> In the camera system of the present embodiment, a video control unit <highlight><bold>24</bold></highlight> converts the signal from the image pickup device <highlight><bold>12</bold></highlight> into a digital signal, processes the digital signal to produce a frame of the input image, and stores the frame in a frame buffer <highlight><bold>25</bold></highlight>. The frame or image defined in the frame buffer <highlight><bold>25</bold></highlight> is a pixel map that has an array of pixel data, each indicating an intensity (and/or a color value) for a position of a corresponding one of the picture elements, or pixels, in the image. The video control unit <highlight><bold>24</bold></highlight> displays the image defined in the frame buffer <highlight><bold>25</bold></highlight> on a liquid-crystal display (LCD) monitor <highlight><bold>27</bold></highlight>, accessing the frame buffer <highlight><bold>25</bold></highlight> as frequently as a scan rate of the monitor <highlight><bold>27</bold></highlight>. The monitor <highlight><bold>27</bold></highlight> has a display screen <highlight><bold>27</bold></highlight>A, and the image defined in the frame buffer <highlight><bold>25</bold></highlight> is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> by the video control unit <highlight><bold>24</bold></highlight>. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> The video control unit <highlight><bold>24</bold></highlight> further includes a frame buffer <highlight><bold>26</bold></highlight> in addition to the frame buffer <highlight><bold>25</bold></highlight>. The frame buffer <highlight><bold>26</bold></highlight> stores auxiliary data indicative of a peripheral boundary <highlight><bold>27</bold></highlight>B (which will be described later) corresponding to the image defined in the frame buffer <highlight><bold>25</bold></highlight>. The video control unit <highlight><bold>24</bold></highlight> displays the peripheral boundary <highlight><bold>27</bold></highlight>B, indicated by the auxiliary data defined in the frame buffer <highlight><bold>26</bold></highlight>, on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, accessing the frame buffer <highlight><bold>26</bold></highlight> at the same time as the frame buffer <highlight><bold>25</bold></highlight>. Hence, the image defined in the frame buffer <highlight><bold>25</bold></highlight> and the auxiliary data defined in the frame buffer <highlight><bold>26</bold></highlight> are synthesized so that the image with the peripheral boundary <highlight><bold>27</bold></highlight>B is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> in an overlaid manner. The auxiliary data defined in the frame buffer <highlight><bold>26</bold></highlight> includes a frame number to identify a captured image among a plurality of partially overlapping images, which will be described later. Further, the auxiliary data may further include image data of a displacement vector or a direction of the optical axis of the camera, which will be described later. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> In the camera system of the present embodiment, an image memory <highlight><bold>28</bold></highlight> is a storage device which stores an image captured by the video control unit <highlight><bold>24</bold></highlight>. The image memory <highlight><bold>28</bold></highlight> may be any image storage device, for example, one of semiconductor memories including flash memories, or one of magnetic disks including floppy disks and mini-disks (MD). </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> In the camera system of the present embodiment, a processor <highlight><bold>30</bold></highlight> controls the overall operation of the camera system and carries out a divisional shooting process including determination of a positional relation between partially overlapping images based upon a common pattern in an overlapping portion of the images. The processor <highlight><bold>30</bold></highlight> includes an arithmetic control unit <highlight><bold>32</bold></highlight>, a read-only memory (ROM) <highlight><bold>33</bold></highlight>, and a random access memory (RAM) <highlight><bold>36</bold></highlight>. The ROM <highlight><bold>33</bold></highlight> stores a number of programs <highlight><bold>34</bold></highlight>A through <highlight><bold>34</bold></highlight>N, and fixed information, such as character fonts. The arithmetic control unit <highlight><bold>32</bold></highlight> carries out individual control operations for the elements of the camera system when one of the programs <highlight><bold>34</bold></highlight>A through <highlight><bold>34</bold></highlight>N in the ROM <highlight><bold>33</bold></highlight> is executed by the processor <highlight><bold>30</bold></highlight>. The RAM <highlight><bold>36</bold></highlight> is a main memory of the processor <highlight><bold>30</bold></highlight> which is available to any of the programs when it is executed. The RAM <highlight><bold>36</bold></highlight> serves as a work memory available to the arithmetic control unit <highlight><bold>32</bold></highlight>. Further, the processor <highlight><bold>30</bold></highlight> includes a power supply circuit (not shown) which supplies power to the camera system, and an interface (not shown) which connects the camera system with an external host computer. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> In the camera system of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the operator can select one of the operational modes by using the mode selection switch <highlight><bold>16</bold></highlight>. In the present embodiment, the operational modes of the camera system include a normal shooting mode and a divisional shooting mode. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> When the normal shooting mode is selected by the mode selection switch <highlight><bold>16</bold></highlight>, a single image of an object or a scene is captured through the image pickup device <highlight><bold>12</bold></highlight>, the image displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> is viewed, and the shutter switch <highlight><bold>20</bold></highlight> is turned ON by the operator so that the image defined in the frame memory <highlight><bold>25</bold></highlight> is stored in the image memory <highlight><bold>28</bold></highlight>. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> When the divisional shooting mode is selected in the camera system of the present embodiment, a plurality of partially overlapping images are successively shot so as to cover a wide angle related to an object to be imaged, and they are synthesized to create a composite image with an adequate level of resolution. The divisional shooting mode is useful to obtain a panoramic image or a high-resolution image through image composition. The camera system of the present invention is particularly relevant to the divisional shooting mode, and the following description will be given of an operation of the camera system of the present embodiment when the divisional shooting mode is performed. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> In the camera system of the present embodiment, when the divisional shooting mode is selected by the mode selection switch <highlight><bold>20</bold></highlight>, the processor <highlight><bold>30</bold></highlight> starts the execution of a divisional shooting processing program <highlight><bold>34</bold></highlight>I among the programs <highlight><bold>34</bold></highlight>A through <highlight><bold>34</bold></highlight>N in the ROM <highlight><bold>33</bold></highlight>. A divisional shooting process is performed by the processor <highlight><bold>30</bold></highlight> according to the divisional shooting processing program <highlight><bold>34</bold></highlight>I. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> In order to take a first one of partially overlapping images when the divisional shooting process is started, the operator directs the optical axis of the camera (or the lens of the optical unit <highlight><bold>10</bold></highlight>) to an object to be imaged. In accordance with the signal from the image pickup device <highlight><bold>12</bold></highlight>, the video control unit <highlight><bold>24</bold></highlight> stores a corresponding frame in the frame memory <highlight><bold>25</bold></highlight>, and displays the image on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. The operator turns ON the shutter switch <highlight><bold>20</bold></highlight> of the operation part <highlight><bold>16</bold></highlight> while viewing the image on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. A shutter signal from the operation part <highlight><bold>16</bold></highlight> is sent to the processor <highlight><bold>30</bold></highlight> immediately after the shutter switch <highlight><bold>20</bold></highlight> is turned ON. In response to the shutter signal, the processor <highlight><bold>30</bold></highlight> stores the image, defined in the frame memory <highlight><bold>25</bold></highlight> of the video control unit <highlight><bold>24</bold></highlight>, in the image memory <highlight><bold>28</bold></highlight>. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The above-mentioned image storage process is performed by the processor <highlight><bold>30</bold></highlight> of the camera system in accordance with an image storage processing program <highlight><bold>34</bold></highlight>N among the programs <highlight><bold>34</bold></highlight>A through <highlight><bold>34</bold></highlight>N stored in the ROM <highlight><bold>33</bold></highlight>. The execution of the image storage processing program <highlight><bold>34</bold></highlight>N is started by the processor <highlight><bold>30</bold></highlight> in response to the shutter signal. During the image storage process, all the image data corresponding to the entire screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> is not stored in the image memory <highlight><bold>28</bold></highlight>, but only a portion of the image data corresponding to an internal portion of the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> within the peripheral boundary <highlight><bold>27</bold></highlight>B is stored in the image memory <highlight><bold>28</bold></highlight>. The processor <highlight><bold>30</bold></highlight> adds a frame number to the auxiliary data of the frame buffer <highlight><bold>26</bold></highlight> and stores such data defined in the frame buffer <highlight><bold>26</bold></highlight>, in the image memory <highlight><bold>28</bold></highlight>, together with the image defined in the frame buffer <highlight><bold>25</bold></highlight>, during the image storage process. The data being stored in the image memory <highlight><bold>28</bold></highlight> may be compressed in a compact form or may not be compressed in the original form. During the image storage process, the writing of image data to the frame buffer <highlight><bold>25</bold></highlight> is inhibited and the image displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> is fixed. Before the image storage process ends, the writing of image data to the frame buffer <highlight><bold>25</bold></highlight> is allowed. Hence, after the image storage process is performed, the image defined in the frame buffer <highlight><bold>25</bold></highlight> can be variably updated according to the movement of the optical axis of the camera, and the resulting image is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> shows an image storage process performed by the processor <highlight><bold>30</bold></highlight> of the camera system of the present embodiment. The image storage processing program <highlight><bold>34</bold></highlight>N among the programs <highlight><bold>34</bold></highlight>A through <highlight><bold>34</bold></highlight>N in the ROM <highlight><bold>33</bold></highlight> is loaded to the RAM <highlight><bold>36</bold></highlight> and executed by the processor <highlight><bold>30</bold></highlight> immediately after the shutter switch <highlight><bold>20</bold></highlight> is turned ON by the operator. Then, the image storage process of <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is performed by the processor <highlight><bold>30</bold></highlight> according to the image storage processing program <highlight><bold>34</bold></highlight>N. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, at the start of the image storage process, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>500</bold></highlight> inhibits the writing of image data to the frame buffer <highlight><bold>25</bold></highlight> by the video control unit <highlight><bold>24</bold></highlight>. Hence, during the image storage process, the image displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> is fixed. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> The processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>502</bold></highlight> combines the auxiliary data of the frame buffer <highlight><bold>26</bold></highlight> with the image of the frame buffer <highlight><bold>25</bold></highlight> to create a synthesized image, and stores the synthesized image in the image memory <highlight><bold>28</bold></highlight>. As described above, the auxiliary data of the frame buffer <highlight><bold>26</bold></highlight> includes a frame number to identify a captured image among the partially overlapping images. The auxiliary data of the frame buffer <highlight><bold>26</bold></highlight> may include other parameter values (which will be described later). However, when the image storage process with respect to a first one of partially overlapping images is performed, the auxiliary data of the frame buffer <highlight><bold>26</bold></highlight> is null or vacant, and only the image of the frame buffer <highlight><bold>25</bold></highlight> is stored in the image memory <highlight><bold>28</bold></highlight> at the step S<highlight><bold>502</bold></highlight>. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> The processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>504</bold></highlight> allows the writing of image data to the frame buffer <highlight><bold>25</bold></highlight> by the video control unit <highlight><bold>24</bold></highlight>. After the step S<highlight><bold>504</bold></highlight> is performed, the image storage process of <cross-reference target="DRAWINGS">FIG. 7</cross-reference> ends. Hence, after the image storage process is performed, the image defined in the frame buffer <highlight><bold>25</bold></highlight> is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> After the first one of the partially overlapping images is taken, the operator pans the camera in a desired direction in order to take a following one of the partially overlapping images during the divisional shooting mode. By viewing the preceding image with the peripheral boundary on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, the operator stops the movement of the optical axis of the camera at an appropriate position where an overlapping portion of the two adjacent images is appropriate for subsequently producing a composite image from the images. Then, the current image is captured and stored in the image memory <highlight><bold>28</bold></highlight> in a similar manner. The above-described procedure is repeated until all the partially overlapping images for the object to be imaged are captured and stored. In this manner, the partially overlapping images are successively shot so as to cover a wide angle related to the object, and they are synthesized to create a composite image with an adequate level of resolution by using the technology as disclosed in the above-mentioned U.S. patent applications. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> According to the camera system of the present invention, the operator can easily carry out the divisional shooting process by viewing both the current image and the peripheral boundary <highlight><bold>27</bold></highlight>B (or the preceding image) on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. A positional relation between the preceding image and the current image is clearly noticeable to the operator by viewing the peripheral boundary <highlight><bold>27</bold></highlight>B on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> and the current image while the camera is panned in the desired direction. Therefore, the operator easily stops the movement of the optical axis of the camera at an appropriate position by viewing an image of the peripheral boundary <highlight><bold>27</bold></highlight>B, and turns ON the shutter switch <highlight><bold>20</bold></highlight> to store the current image. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a first example of the divisional shooting process performed by the processor <highlight><bold>30</bold></highlight> in accordance with the divisional shooting processing program <highlight><bold>34</bold></highlight>I. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, at the start of the divisional shooting process, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>100</bold></highlight> detects whether the image storage process, shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, with respect to a preceding one of the partially overlapping images ends. The end of the image storage process is notified to the arithmetic control unit <highlight><bold>32</bold></highlight> when the execution of the image storage processing program <highlight><bold>34</bold></highlight>N has normally ended. When the result at the step S<highlight><bold>100</bold></highlight> is negative, the processor <highlight><bold>30</bold></highlight> repeats the step S<highlight><bold>100</bold></highlight>. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> When the result at the step S<highlight><bold>100</bold></highlight> is affirmative, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>104</bold></highlight> reads out the pixel map of the preceding image from the image memory <highlight><bold>28</bold></highlight>, and reads out the pixel map of a currently-captured image from the frame buffer <highlight><bold>25</bold></highlight>. These pixel maps are temporarily stored in the RAM <highlight><bold>36</bold></highlight>. The pixel map of the preceding image is selected as a standard image. Each of the pixel data of the two adjacent images corresponding to an overlapping portion of the images is divided into blocks of a predetermined size, for example, 16 by 16 pixels. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> After the step S<highlight><bold>104</bold></highlight> is performed, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>106</bold></highlight> performs a matching between corresponding blocks from an overlapping portion of the two adjacent images. During the step S<highlight><bold>106</bold></highlight>, a common pattern in the two adjacent images is identified if a certain similarity threshold is met. This matching may be performed by checking the intensities of individual pixels of the corresponding blocks. This is useful for reducing the amount of required calculations. Alternatively, the matching may be performed by checking the color values of individual pixels of the corresponding blocks, but this will increase the amount of required calculations. The above matching procedures are repeated until all the blocks are processed so that a maximum-similarity common pattern in the preceding image and the maximum-similarity common pattern in the current image are detected. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> A method and a system for determining a positional relation between partially overlapping images based upon a common pattern in an overlapping portion of the images are disclosed in the above-mentioned U.S. patent applications, and the divisional shooting process according to the present invention utilizes the method and the system. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> As previously described, during the step S<highlight><bold>106</bold></highlight> of the divisional shooting process of <cross-reference target="DRAWINGS">FIG. 2, a</cross-reference> determination of a positional relation between partially overlapping images is carried out. By referring to <cross-reference target="DRAWINGS">FIG. 8</cross-reference>A and <cross-reference target="DRAWINGS">FIG. 8B, a</cross-reference> detailed procedure of the determination of the positional relation in the step S<highlight><bold>106</bold></highlight> will now be described. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> It is supposed that the pixel map of the preceding image from the image memory <highlight><bold>28</bold></highlight> and the pixel map of the current image from the frame buffer <highlight><bold>25</bold></highlight> have been read out as in the step S<highlight><bold>104</bold></highlight>. These pixel maps are temporarily stored in the RAM <highlight><bold>36</bold></highlight>. The pixel map of the preceding image is selected as the standard image. Each of the two adjacent images corresponding to an overlapping portion of the images is divided into blocks of a predetermined size. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>A, pixels &ldquo;A&rdquo;, &ldquo;B&rdquo; and &ldquo;C&rdquo; in the preceding image and pixels &ldquo;A&prime;&rdquo;, &ldquo;B&prime;&rdquo; and &ldquo;C&prime;&rdquo; in the current image correspond to the overlapping portion of the images. During the step S<highlight><bold>106</bold></highlight>, a matching between corresponding blocks from the overlapping portion of the two adjacent images is performed. A common pattern (such as the pixels A, B and C and the pixels A&prime;, B&prime; and C&prime;) in the two adjacent images is identified if a certain similarity threshold is met. This matching may be performed by checking the intensities of individual pixels of the corresponding blocks. The above matching procedures are repeated until all the blocks are processed, so that a maximum-similarity common pattern in the preceding image and the maximum-similarity common pattern in the current image are detected. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>B, the maximum-similarity common pattern in the two images is detected if the difference between the pixel values (or the intensities of the pixels A and A&prime;, the pixels B and B&prime; or the pixels C and C&prime;) of the corresponding blocks is found to be the minimum when the current image is moved relative to the preceding image by both a distance for a first number of pixels in the x-axis direction and a distance for a second number of pixels in the y-axis direction. Through the above pixel-based method, the processor <highlight><bold>30</bold></highlight> detects the maximum-similarity common pattern in the two images. That is, the processor <highlight><bold>30</bold></highlight> at the step S<highlight><bold>106</bold></highlight> carries out the determination of the positional relation between the partially overlapping images. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> In the above-described procedure, the maximum-similarity common pattern in the two images is detected by using the pixel-based method, in order to carry out the determination of the positional relation between the partially overlapping images. However, according to the present invention, it is also possible to achieve the determination of a positional relation between partially overlapping images at an accuracy higher than the accuracy of one pixel. As previously described, the determination of a positional relation between partially overlapping images based upon a common pattern in an overlapping portion of the images are disclosed in the above-mentioned U.S. patent applications, and, for that purpose, the divisional shooting process according to the present invention may utilize the method and the system. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Referring back to <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, during the step S<highlight><bold>106</bold></highlight>, the processor <highlight><bold>30</bold></highlight> further determines both coordinates (I, J) of a central pixel of the maximum-similarity common pattern in the preceding image and coordinates (Im, Jm) of a central pixel of the maximum-similarity common pattern in the current image. The coordinates (I, J) and the coordinates (Im, Jm) based on a screen coordinate system of the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> are determined by the processor <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> The processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>108</bold></highlight> determines a displacement vector (I-Im, J-Jm), which indicates a positional relation between the preceding image and the current image, by the difference between the coordinates (I, J) and the coordinates (Im, Jm). In the step S<highlight><bold>108</bold></highlight>, after the contents of the frame buffer <highlight><bold>26</bold></highlight> are cleared, the processor <highlight><bold>30</bold></highlight> writes image data, indicative of the displacement vector, to the frame buffer <highlight><bold>26</bold></highlight> as part of the auxiliary data. Hence, the image of the displacement vector (or the auxiliary data defined in the frame buffer <highlight><bold>26</bold></highlight>) is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>110</bold></highlight> detects whether the operator stops the movement of the optical axis of the camera (or detects whether the operator turns ON the shutter switch <highlight><bold>20</bold></highlight>). When the result at the step S<highlight><bold>110</bold></highlight> is negative, the above steps S<highlight><bold>106</bold></highlight> and S<highlight><bold>108</bold></highlight> are repeated. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> When the step S<highlight><bold>106</bold></highlight> is performed for second or subsequent ones of the partially overlapping images, the coordinates (I, J) of the central pixel of the maximum-similarity common pattern in the preceding image and the direction of the displacement vector are known. The matching procedures in the step S<highlight><bold>106</bold></highlight> may be performed for only the blocks of the current image in the overlapping portion of the two images, indicated by the direction of the displacement vector and the coordinates (I, J). By using such a simplified matching, the common pattern in the two adjacent images may be identified, and coordinates (Im, Jm) of the central pixel of the maximum-similarity common pattern in the current image may be determined. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> The operator stops the panning of the camera at an appropriate position where an appropriate overlapping portion of the two adjacent images can be seen with the image of the displacement vector on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, and turns ON the shutter switch <highlight><bold>20</bold></highlight> to store the current image. Every time the steps S<highlight><bold>106</bold></highlight> and S<highlight><bold>108</bold></highlight> are performed, the processor <highlight><bold>30</bold></highlight> compares the currently obtained displacement vector and the previously obtained displacement vector (stored in an internal register of the processor <highlight><bold>30</bold></highlight> or the RAM <highlight><bold>36</bold></highlight>) so as to determine whether the operator stops the movement of the optical axis of the camera. If the difference between the two displacement vectors is larger than a threshold value, the result at the step S<highlight><bold>110</bold></highlight> is negative. If the difference between the two displacement vectors is less than the threshold value, the result at the step S<highlight><bold>110</bold></highlight> is affirmative. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> When the result at the step S<highlight><bold>110</bold></highlight> is affirmative, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>112</bold></highlight> writes image data, indicative of the peripheral boundary <highlight><bold>27</bold></highlight>B of the preceding image, to the frame buffer <highlight><bold>26</bold></highlight> at a position shifted from the previous position. The shifted position is determined from the previous position based on the magnitude and direction of the displacement vector obtained in the step S<highlight><bold>108</bold></highlight>. Hence, the image of the peripheral boundary <highlight><bold>27</bold></highlight>B defined in the frame buffer <highlight><bold>26</bold></highlight> is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> as if the peripheral boundary <highlight><bold>27</bold></highlight>B is shifted according to the movement of the optical axis of the camera. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> In the step S<highlight><bold>112</bold></highlight>, the image data of the displacement vector obtained in the step S<highlight><bold>108</bold></highlight> may be left in the frame buffer <highlight><bold>26</bold></highlight> without change. Alternatively, the image data of the displacement vector in the frame buffer <highlight><bold>26</bold></highlight> may be deleted, and then the image data of the shifted peripheral boundary <highlight><bold>27</bold></highlight>B may be defined in the frame buffer <highlight><bold>26</bold></highlight>. The image of the peripheral boundary <highlight><bold>27</bold></highlight>B being displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> may be a frame of the preceding image or a solid model of the preceding image with a certain color attached to the internal pixels. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> The operator can easily carry out the divisional shooting process with the camera system by viewing both the current image and the peripheral boundary <highlight><bold>27</bold></highlight>B (or the preceding image) on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. A positional relation between the preceding image and the current image is clearly noticeable to the operator by viewing the peripheral boundary <highlight><bold>27</bold></highlight>B on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> and the current image while the camera is panned in a desired direction. Therefore, the operator easily stops the movement of the optical axis of the camera at an appropriate position by viewing an image of the peripheral boundary <highlight><bold>27</bold></highlight>A, and turns ON the shutter switch <highlight><bold>20</bold></highlight> to store the current image. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> After the step S<highlight><bold>112</bold></highlight> is performed, the control is transferred to the step S<highlight><bold>100</bold></highlight>. The processor <highlight><bold>30</bold></highlight> at the step S<highlight><bold>100</bold></highlight> waits for the end of the image storage process at which the currently captured image is further stored in the image memory <highlight><bold>28</bold></highlight>. As described above, during the image storage process, the frame number for the current image and the displacement vector for the current image are added to the auxiliary data of the frame buffer <highlight><bold>26</bold></highlight> and such data defined in the frame buffer <highlight><bold>26</bold></highlight> is stored in the image memory <highlight><bold>28</bold></highlight> together with the image defined in the frame buffer <highlight><bold>25</bold></highlight>. The frame number and the displacement data are used when synthesizing the partially overlapping images to create a composite image. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3A</cross-reference> shows an image which is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> when the camera is being moved in a given direction indicated in <cross-reference target="DRAWINGS">FIG. 3A</cross-reference>. In <cross-reference target="DRAWINGS">FIG. 3A, a</cross-reference> peripheral boundary of a preceding image is indicated by the dotted-line rectangle A&prime;B&prime;C&prime;D&prime;, and a peripheral boundary of a current image is indicated by the solid-line rectangle ABCD. A displacement between the preceding image and the current image proportional to the movement of the optical axis of the camera is defined by the displacement vector. In the case of <cross-reference target="DRAWINGS">FIG. 3</cross-reference>A, the displacement vector is directed to the left and has a length proportional to the movement of the optical axis of the camera. An image <highlight><bold>50</bold></highlight> of the displacement vector is displaced on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> as indicated in <cross-reference target="DRAWINGS">FIG. 3A</cross-reference>. Although the contents of the preceding image are not displayed, the operator can easily notice a positional relation between the preceding image and the current image on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> with the image <highlight><bold>50</bold></highlight>. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3B</cross-reference> shows an image which is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> when the movement of the optical axis of the camera is stopped and the shutter switch <highlight><bold>20</bold></highlight> is turned ON by the operator. In <cross-reference target="DRAWINGS">FIG. 3</cross-reference>B, an image <highlight><bold>52</bold></highlight> of the peripheral boundary <highlight><bold>27</bold></highlight>B, which is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, is indicated by the rectangle ABC&prime;D&prime;. The rectangle ABC&prime;D&prime; corresponds to an overlapping portion of the two adjacent images. As described above, the image data, indicative of the peripheral boundary <highlight><bold>27</bold></highlight>B of the preceding image, is written to the frame buffer <highlight><bold>26</bold></highlight> at positions shifted from the previous positions according to the movement of the optical axis of the camera. The image <highlight><bold>50</bold></highlight> of the displacement vector corresponding to the magnitude and direction of the displacement vector is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. The operator can clearly notice an appropriate overlapping portion of the two images by the image <highlight><bold>50</bold></highlight> of the displacement vector and the image <highlight><bold>52</bold></highlight> of the peripheral boundary <highlight><bold>27</bold></highlight>B. The image <highlight><bold>50</bold></highlight> of the displacement vector, at the time the movement of the optical axis of the camera is stopped, may be displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. Alternatively, the display of the image <highlight><bold>50</bold></highlight> of the displacement vector may be omitted. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> shows a second example of the divisional shooting process performed by the processor <highlight><bold>30</bold></highlight> in accordance with the divisional shooting processing program <highlight><bold>34</bold></highlight>I. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>, at the start of the divisional shooting process in the present embodiment, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>200</bold></highlight> detects whether the image storage process with respect to a preceding one of the partially overlapping images ends. The end of the image storage process is notified to the arithmetic control unit <highlight><bold>32</bold></highlight> when the execution of the image storage processing program <highlight><bold>34</bold></highlight>N has normally ended. When the result at the step S<highlight><bold>200</bold></highlight> is negative, the processor <highlight><bold>30</bold></highlight> repeats the step S<highlight><bold>200</bold></highlight>. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> When the result at the step S<highlight><bold>200</bold></highlight> is affirmative, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>204</bold></highlight> reads out the pixel map of the preceding image from the image memory <highlight><bold>28</bold></highlight>, and reads out the pixel map of the currently-captured image from the frame buffer <highlight><bold>25</bold></highlight>. The pixel maps are temporarily stored in the RAM <highlight><bold>36</bold></highlight>. The pixel map of the preceding image is selected as a standard image. Each of the pixel data of the two adjacent images corresponding to the overlapping portion of the images is divided into blocks of a predetermined size, for example, 16 by 16 pixels. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> After the step S<highlight><bold>204</bold></highlight> is performed, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>206</bold></highlight> performs a matching between corresponding blocks from the two adjacent images. During the step S<highlight><bold>206</bold></highlight>, a common pattern in the two adjacent images is identified if a certain similarity threshold is met. The matching procedures are repeated for every block until all the blocks are processed so that the common pattern in the preceding image and the common pattern in the current image are identified. </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> Further, during the step S<highlight><bold>206</bold></highlight>, the processor <highlight><bold>30</bold></highlight> determines both coordinates (I, J) of a central pixel of a maximum-similarity common pattern in the preceding image and coordinates (Im, Jm) of a central pixel of the maximum-similarity common pattern in the current image. The coordinates (I, J) and the coordinates (Im, Jm) based on a screen coordinate system of the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> are determined by the processor <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> The steps S<highlight><bold>200</bold></highlight>-S<highlight><bold>206</bold></highlight> in the present embodiment are essentially the same as the steps S<highlight><bold>100</bold></highlight>-S<highlight><bold>106</bold></highlight> in the embodiment of <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> The processor at step S<highlight><bold>208</bold></highlight> determines a displacement vector (I-Im, J-Jm), which indicates a positional relation between the preceding image and the current image, by the difference between the coordinates (I, J) and the coordinates (Im, Jm). In the present embodiment, during the step S<highlight><bold>208</bold></highlight>, the processor <highlight><bold>30</bold></highlight> writes image data, indicative of the peripheral boundary <highlight><bold>27</bold></highlight>B of the preceding image, to the frame buffer <highlight><bold>26</bold></highlight> at positions shifted from the previous positions. The shifted positions are indicated by the magnitude and direction of the displacement vector. Hence, the image of the peripheral boundary <highlight><bold>27</bold></highlight>B defined in the frame buffer <highlight><bold>26</bold></highlight> is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> Unlike the embodiment of <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, during the step S<highlight><bold>208</bold></highlight> in the present embodiment, the processor <highlight><bold>30</bold></highlight> does not write the image data of the displacement vector to the frame buffer <highlight><bold>26</bold></highlight> as part of the auxiliary data. Hence, the image of the displacement vector is not displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> The processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>210</bold></highlight> detects whether the operator stops the movement of the optical axis of the camera (or detects whether the operator turns ON the shutter switch <highlight><bold>20</bold></highlight>). When the result at the step S<highlight><bold>210</bold></highlight> is negative, the above steps S<highlight><bold>206</bold></highlight> and S<highlight><bold>208</bold></highlight> are repeated. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> The operator stops the panning of the camera at an appropriate position where an appropriate overlapping portion of the two adjacent images can be seen with the image of the displacement vector on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, and turns ON the shutter switch <highlight><bold>20</bold></highlight> to store the current image. Every time the steps S<highlight><bold>206</bold></highlight> and S<highlight><bold>208</bold></highlight> are performed, the processor <highlight><bold>30</bold></highlight> compares the currently obtained displacement vector and the previously obtained displacement vector (stored in the internal register or the RAM <highlight><bold>36</bold></highlight>) so as to determine whether the operator stops the panning of the camera. If the difference between the two displacement vectors is larger than a threshold value, the result at the step S<highlight><bold>210</bold></highlight> is negative. If the difference between the two displacement vectors is less than the threshold value, the result at the step S<highlight><bold>210</bold></highlight> is affirmative. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> When the result at the step S<highlight><bold>210</bold></highlight> is affirmative, the control is transferred to the step S<highlight><bold>200</bold></highlight>. The processor <highlight><bold>30</bold></highlight> at the step S<highlight><bold>200</bold></highlight> waits for the end of the image storage process at which the currently captured image is further stored in the image memory <highlight><bold>28</bold></highlight>. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> In the present embodiment, the operator can view a peripheral boundary image indicating a positional relation between the current image and the preceding image before the movement of the optical axis of the camera-is stopped or the shutter switch <highlight><bold>20</bold></highlight> is turned ON. The operator can easily carry out the divisional shooting process with the camera system, but the current image and the peripheral boundary image are always displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. It is desirable that the intensity and/or color of the peripheral boundary image may be set at a suitable value so as to prevent the peripheral boundary image from hindering the check for the current image on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> shows a third example of the divisional shooting process performed by the processor <highlight><bold>30</bold></highlight> in accordance with the divisional shooting processing program <highlight><bold>34</bold></highlight>I. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> In the present embodiment, the camera system further includes a three-dimensional gyro sensor <highlight><bold>40</bold></highlight> connected to the arithmetic control unit <highlight><bold>32</bold></highlight> of the processor <highlight><bold>30</bold></highlight> as indicated by the dotted line in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. The sensor <highlight><bold>40</bold></highlight> detects a three-dimensional direction of the optical axis of the optical unit <highlight><bold>10</bold></highlight> and outputs a signal indicating the optical axis direction to the arithmetic control unit <highlight><bold>32</bold></highlight> of the processor <highlight><bold>30</bold></highlight>. The sensor <highlight><bold>40</bold></highlight> may be a built-in type or an external-installation type for the camera system. Other elements of the camera system in the present embodiment are the same as corresponding elements of the camera system shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, and a description thereof will be omitted. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> When the divisional shooting mode is selected by the mode selection switch <highlight><bold>20</bold></highlight>, the processor <highlight><bold>30</bold></highlight> starts the execution of the divisional shooting processing program <highlight><bold>34</bold></highlight>I in the ROM <highlight><bold>33</bold></highlight>. The present embodiment of the divisional shooting process is performed by the processor <highlight><bold>30</bold></highlight> according to the divisional shooting processing program <highlight><bold>34</bold></highlight>I. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> In order to take a first one of partially overlapping images at the start of the divisional shooting process is started, the operator directs the optical axis of the camera to an object to be imaged and turns ON the shutter switch <highlight><bold>20</bold></highlight>. A shutter signal from the operation part <highlight><bold>16</bold></highlight> is sent to the processor <highlight><bold>30</bold></highlight> immediately after the shutter switch <highlight><bold>20</bold></highlight> is turned ON. In response to the shutter signal, the processor <highlight><bold>30</bold></highlight> reads a signal output by the sensor <highlight><bold>40</bold></highlight> at that time, and temporarily stores the signal in an internal register of the processor <highlight><bold>30</bold></highlight> or the RAM <highlight><bold>36</bold></highlight>. In accordance with the signal from the image pickup device <highlight><bold>12</bold></highlight>, the video control unit <highlight><bold>24</bold></highlight> stores a corresponding frame in the frame memory <highlight><bold>25</bold></highlight>, and displays the image on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. In response to the shutter signal, the processor <highlight><bold>30</bold></highlight> stores the image, defined in the frame memory <highlight><bold>25</bold></highlight>, in the image memory <highlight><bold>28</bold></highlight>. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> The above-mentioned image storage process is performed by the processor <highlight><bold>30</bold></highlight> according to the image storage processing program <highlight><bold>34</bold></highlight>N in the ROM <highlight><bold>33</bold></highlight>. The execution of the image storage processing program <highlight><bold>34</bold></highlight>N is started by the processor <highlight><bold>30</bold></highlight> in response to the shutter signal. During the image storage process, the processor <highlight><bold>30</bold></highlight> adds both the frame number and the optical axis direction signal to the auxiliary data of the frame buffer <highlight><bold>26</bold></highlight>, and stores such data defined in the frame buffer <highlight><bold>26</bold></highlight>, in the image memory <highlight><bold>28</bold></highlight>, together with the image defined in the frame buffer <highlight><bold>25</bold></highlight>. During the image storage process, the writing of image data to the frame buffer <highlight><bold>25</bold></highlight> is inhibited and the image displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> is fixed. Before the image storage process ends, the writing of image data to the frame buffer <highlight><bold>25</bold></highlight> is allowed. Hence, after the image storage process is performed, the image defined in the frame buffer <highlight><bold>25</bold></highlight> can be variably updated according to the movement of the optical axis of the camera, and the resulting image is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> After the first one of the partially overlapping images is taken, the operator pans the camera in a desired direction in order to take a following one of the partially overlapping images during the divisional shooting mode. By viewing the preceding image with the peripheral boundary on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, the operator stops the movement of the optical axis of the camera such that the preceding image and the currently-captured image overlap each other with an appropriate overlapping portion of the images. Then, the current image is captured and stored in the image memory <highlight><bold>28</bold></highlight> together with the auxiliary data, including the frame number and the optical axis direction signal, in a similar manner. The above-described procedure is repeated until all the partially overlapping images for the object to be imaged are captured and stored. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> With reference to <cross-reference target="DRAWINGS">FIG. 5, a</cross-reference> description will now be given of the third example of the divisional shooting process performed by the processor <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, at the start of the divisional shooting process in the present embodiment, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>300</bold></highlight> detects whether the image storage process of <cross-reference target="DRAWINGS">FIG. 7</cross-reference> with respect to a preceding one of the partially overlapping images ends. The end of the image storage process is notified to the processor <highlight><bold>30</bold></highlight>. When the result at the step S<highlight><bold>300</bold></highlight> is negative, the processor <highlight><bold>30</bold></highlight> repeats the step S<highlight><bold>300</bold></highlight>. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> When the result at the step S<highlight><bold>300</bold></highlight> is affirmative, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>304</bold></highlight> reads an optical axis direction signal (related to the current image) output by the sensor <highlight><bold>40</bold></highlight> at that time, and reads the optical axis direction signal (related to the preceding image) from the internal register or the RAM <highlight><bold>36</bold></highlight>. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> After the step S<highlight><bold>304</bold></highlight> is performed, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>306</bold></highlight> determines a displacement vector, which indicates a positional relation of the preceding image to the current image on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, by the difference between the optical axis direction signal related to the preceding image and the optical axis direction signal related to the current image. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> The processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>308</bold></highlight> writes image data, indicative of the displacement vector, to the frame buffer <highlight><bold>26</bold></highlight> as part of the auxiliary data after the contents of the frame buffer <highlight><bold>26</bold></highlight> are cleared. Hence, an image of the displacement vector (or the auxiliary data defined in the frame buffer <highlight><bold>26</bold></highlight>) is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, similar to the image <highlight><bold>50</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>A and <cross-reference target="DRAWINGS">FIG. 3B</cross-reference>. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> The processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>310</bold></highlight> detects whether the operator stops the movement of the optical axis of the camera (or detects whether the operator turns ON the shutter switch <highlight><bold>20</bold></highlight>). When the result at the step S<highlight><bold>310</bold></highlight> is negative, the above steps S<highlight><bold>304</bold></highlight> through S<highlight><bold>308</bold></highlight> are repeated. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> The operator stops the panning of the camera at an appropriate position where an appropriate overlapping portion of the two adjacent images can be seen with the image of the displacement vector on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, and turns ON the shutter switch <highlight><bold>20</bold></highlight> to store the current image. Every time the steps S<highlight><bold>304</bold></highlight> through S<highlight><bold>308</bold></highlight> are performed, the processor <highlight><bold>30</bold></highlight> compares the currently obtained displacement vector and the previously obtained displacement vector (stored in the internal register or the RAM <highlight><bold>36</bold></highlight>) so as to determine whether the operator stops the movement of the optical axis of the camera. If the difference between the two displacement vectors is larger than a threshold value, the result at the step S<highlight><bold>310</bold></highlight> is negative. If the difference between the two displacement vectors is less than the threshold value, the result at the step S<highlight><bold>310</bold></highlight> is affirmative. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> When the result at the step S<highlight><bold>310</bold></highlight> is affirmative, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>312</bold></highlight> writes image data, indicative of the peripheral boundary <highlight><bold>27</bold></highlight>B of the preceding image, to the frame buffer <highlight><bold>26</bold></highlight> at positions shifted from the previous positions. The shifted positions are indicated by the magnitude and direction of the displacement vector obtained in the step S<highlight><bold>306</bold></highlight>. Hence, the image of the peripheral boundary <highlight><bold>27</bold></highlight>B defined in the frame buffer <highlight><bold>26</bold></highlight> is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> In the step S<highlight><bold>312</bold></highlight>, the image data of the displacement vector obtained in the step S<highlight><bold>306</bold></highlight> may be left in the frame buffer <highlight><bold>26</bold></highlight> without change. Alternatively, the image data of the displacement vector in the frame buffer <highlight><bold>26</bold></highlight> may be deleted, and then the image data of the shifted peripheral boundary <highlight><bold>27</bold></highlight>B may be defined in the frame buffer <highlight><bold>26</bold></highlight>. The image of the peripheral boundary <highlight><bold>27</bold></highlight>B being displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> may be a frame of the preceding image or a solid model of the preceding image with a certain color attached to the internal pixels. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> The operator can easily carry out the divisional shooting process with the camera system by viewing both the current image and the peripheral boundary <highlight><bold>27</bold></highlight>B (or the preceding image) on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. A positional relation between the preceding image and the current image is clearly noticeable to the operator by viewing the peripheral boundary <highlight><bold>27</bold></highlight>B on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> and the current image while the camera is panned in a desired direction. Therefore, the operator easily stops the movement of the optical axis of the camera at an appropriate position by viewing an image of the peripheral boundary <highlight><bold>27</bold></highlight>B, and turns ON the shutter switch <highlight><bold>20</bold></highlight> to store the current image. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> After the step S<highlight><bold>312</bold></highlight> is performed, the control is transferred to the step S<highlight><bold>300</bold></highlight>. The processor <highlight><bold>30</bold></highlight> at the step S<highlight><bold>300</bold></highlight> waits for the end of the image storage process at which the currently captured image is further stored in the image memory <highlight><bold>28</bold></highlight>. As described above, during the image storage process, the frame number for the current image and the displacement vector for the current image are added to the auxiliary data of the frame buffer <highlight><bold>26</bold></highlight> and such data defined in the frame buffer <highlight><bold>26</bold></highlight> is stored in the image memory <highlight><bold>28</bold></highlight> together with the image defined in the frame buffer <highlight><bold>25</bold></highlight>. The frame number and the displacement data are used when synthesizing the partially overlapping images to create a composite image. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> shows a fourth example of the divisional shooting process performed by the processor <highlight><bold>30</bold></highlight> in accordance with a divisional shooting processing program <highlight><bold>34</bold></highlight>I. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, at the start of the divisional shooting process in the present embodiment, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>400</bold></highlight> detects whether the image storage process of <cross-reference target="DRAWINGS">FIG. 7</cross-reference> with respect to a preceding one of the partially overlapping images ends. The end of the image storage process is notified to the processor <highlight><bold>30</bold></highlight>. When the result at the step S<highlight><bold>400</bold></highlight> is negative, the processor <highlight><bold>30</bold></highlight> repeats the step S<highlight><bold>400</bold></highlight>. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> When the result at the step S<highlight><bold>400</bold></highlight> is affirmative, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>404</bold></highlight> reads an optical axis direction signal (related to the current image) output by the sensor <highlight><bold>40</bold></highlight> at that time, and reads the optical axis direction signal (related to the preceding image) from the internal register or the RAM <highlight><bold>36</bold></highlight>. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> After the step S<highlight><bold>404</bold></highlight> is performed, the processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>406</bold></highlight> determines a displacement vector, which indicates a positional relation of the preceding image to the current image on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, by the difference between the optical axis direction signal related to the preceding image and the optical axis direction signal related to the current image. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> The processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>408</bold></highlight> writes image data, indicative of the peripheral boundary <highlight><bold>27</bold></highlight>B of the preceding image, to the frame buffer <highlight><bold>26</bold></highlight> at positions shifted from the previous positions. The shifted positions are indicated by the magnitude and direction of the displacement vector obtained in the step S<highlight><bold>406</bold></highlight>. Hence, an image of the peripheral boundary <highlight><bold>27</bold></highlight>B defined in the frame buffer <highlight><bold>26</bold></highlight> is displayed on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, similar to the image <highlight><bold>52</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 3B</cross-reference>. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> The processor <highlight><bold>30</bold></highlight> at step S<highlight><bold>410</bold></highlight> detects whether the operator stops the movement of the optical axis of the camera (or detects whether the operator turns ON the shutter switch <highlight><bold>20</bold></highlight>). When the result at the step S<highlight><bold>410</bold></highlight> is negative, the above steps S<highlight><bold>404</bold></highlight> through S<highlight><bold>408</bold></highlight> are repeated. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> The operator stops the panning of the camera at an appropriate position where an appropriate overlapping portion of the two adjacent images can be seen with the image of the peripheral boundary <highlight><bold>27</bold></highlight>B on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>, and turns ON the shutter switch <highlight><bold>20</bold></highlight> to store the current image. Every time the steps S<highlight><bold>404</bold></highlight> through S<highlight><bold>408</bold></highlight> are performed, the processor <highlight><bold>30</bold></highlight> compares the currently obtained displacement vector and the previously obtained displacement vector (stored in the internal register or the RAM <highlight><bold>36</bold></highlight>) so as to determine whether the operator stops the movement of the optical axis of the camera. If the difference between the two displacement vectors is larger than a threshold value, the result at the step S<highlight><bold>410</bold></highlight> is negative. If the difference between the two displacement vectors is less than the threshold value, the result at the step S<highlight><bold>410</bold></highlight> is affirmative. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> The operator can easily carry out the divisional shooting process with the camera system by viewing both the current image and the peripheral boundary <highlight><bold>27</bold></highlight>B (or the preceding image) on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight>. A positional relation between the preceding image and the current image is clearly noticeable to the operator by viewing the peripheral boundary <highlight><bold>27</bold></highlight>B on the screen <highlight><bold>27</bold></highlight>A of the monitor <highlight><bold>27</bold></highlight> and the current image while the camera is panned in a desired direction. Therefore, the operator easily stops the movement of the optical axis of the camera at an appropriate position by viewing the image of the peripheral boundary <highlight><bold>27</bold></highlight>B, and turns ON the shutter switch <highlight><bold>20</bold></highlight> to store the current image. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> When the result at the step S<highlight><bold>410</bold></highlight> is affirmative, the control is transferred to the step S<highlight><bold>400</bold></highlight>. The processor <highlight><bold>30</bold></highlight> at the step S<highlight><bold>400</bold></highlight> waits for the end of the image storage process at which the currently captured image is further stored in the image memory <highlight><bold>28</bold></highlight>. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> The above-described embodiments of the present invention are applied to a digital camera. However, the present invention is not limited to the above-described embodiments. It is readily understood that the present invention is essentially applicable to a still-video camera and other camera systems which electronically store an image of an object and display the image on a display monitor. Further, variations and modifications of the above-described embodiments may be made without departing from the scope of the present invention. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> The present invention is based on Japanese priority application No. 9-245522, filed on Sep. 10, 1997, the entire contents of which are hereby incorporated by reference. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A camera system comprising: 
<claim-text>a display monitor for displaying an image of an object, taken by an optical unit, on a screen of the monitor; </claim-text>
<claim-text>a reading unit for reading a preceding image and a current image among a plurality of partially overlapping images, from a memory device, the preceding image and the current image containing a common element; </claim-text>
<claim-text>a determining unit for determining a positional relation between the preceding image and the current image based on a common pattern derived from the common element in the two adjacent images read by the reading unit; and </claim-text>
<claim-text>a displaying unit for displaying an image indicating a boundary of the preceding image on the screen of the monitor at a shifted position according to the positional relation determined by the determining unit, with the current image concurrently displayed on the screen of the monitor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The camera system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the determining unit performs a matching between corresponding blocks taken from an overlapping portion of the two adjacent images, so that a maximum-similarity common pattern in the two adjacent images is identified. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The camera system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the determining unit performs a matching between corresponding blocks taken from an overlapping portion of the two adjacent images by checking intensities of individual pixels of the corresponding blocks. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The camera system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the determining unit determines both coordinates of a central pixel of a maximum-similarity common pattern in the preceding image and coordinates of a central pixel of the maximum-similarity common pattern in the current image. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The camera system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising: 
<claim-text>a sensor for outputting an optical axis direction signal indicating a direction of an optical axis of the optical unit; and </claim-text>
<claim-text>a secondary determining unit for determining a positional relation between the preceding image and the current image based on a difference between the optical axis direction signal output by the sensor with respect to the current image and the optical axis direction signal output by the sensor with respect to the preceding image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The camera system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the determining unit determines a displacement vector, indicating a positional relation between the preceding image and the current image, based on a difference between coordinates of a central pixel of a maximum-similarity common pattern in the preceding image and coordinates of a central pixel of the maximum-similarity common pattern in the current image, and wherein the displaying unit displays an image of the displacement vector on the screen of the monitor with the current image concurrently displayed on the screen of the monitor. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The camera system according to <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, further comprising an image storing unit for storing an image of the object, taken by the optical unit, in an image memory, wherein the image storing unit stores auxiliary data, containing information indicating the positional relation from the determining unit, in the image memory, in addition to the image stored therein. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The camera system according to <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, further comprising an image storing unit for storing an image of the object, taken by the optical unit, in an image memory, wherein the image storing unit stores auxiliary data, containing information indicating the positional relation from the secondary determining unit, in the image memory, in additional to the image stored therein. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A divisional shooting method for a camera system in which at least two of partially overlapping images of an object, taken by an optical unit, are displayed, comprising the steps of: 
<claim-text>reading a preceding image and a current image among the partially overlapping images, from a memory device, the preceding image and the current image containing a common element; </claim-text>
<claim-text>determining a positional relation between the preceding image and the current image based on a common pattern derived from the common element in the two adjacent images; and </claim-text>
<claim-text>displaying an image, indicating a boundary of the preceding image, on a screen of a display monitor at a shifted position according to the positional relation determined by the determining step, with the current image concurrently displayed on the screen of the monitor. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein, in the determining step, a matching between corresponding blocks taken from an overlapping portion of the two adjacent images is performed, so that a maximum-similarity common pattern in the two adjacent images is identified. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein, in the determining step, a matching between corresponding blocks taken from an overlapping portion of the two adjacent images is performed by checking intensities of individual pixels of the corresponding blocks. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein, in the determining step, both coordinates of a central pixel of a maximum-similarity common pattern in the preceding image and coordinates of a central pixel of the maximum-similarity common pattern in the current image are determined. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, further comprising the steps: 
<claim-text>outputting an optical axis direction signal indicating a direction of an optical axis of the optical unit; and </claim-text>
<claim-text>determining a positional relation between the preceding image and the current image based on a difference between the optical axis direction signal output by the sensor with respect to the current image and the optical axis direction signal output by the sensor with respect to the preceding image. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein, in the determining step, a displacement vector, indicating a positional relation between the preceding image and the current image, is determined based on a difference between coordinates of a central pixel of a maximum-similarity common pattern in the preceding image and coordinates of a central pixel of the maximum-similarity common pattern in the current image, and wherein, in the displaying step, an image of the displacement vector is displayed on the screen of the monitor with the current image concurrently displayed on the screen of the monitor. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, further comprising a step of storing an image of the object, taken by the optical unit, in an image memory, wherein auxiliary data, containing information indicating the positional relation from the determining unit, is stored in the image memory in addition to the image stored therein. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method according to <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, further comprising a step of storing an image of the object, taken by the optical unit, in an image memory, wherein auxiliary data, containing information indicating the positional relation from the secondary determining unit, is stored in the image memory, in additional to the image stored therein.</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002750A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002750A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002750A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002750A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002750A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002750A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002750A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002750A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002750A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
