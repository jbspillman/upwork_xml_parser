<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030001861A1-20030102-D00000.TIF SYSTEM "US20030001861A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00001.TIF SYSTEM "US20030001861A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00002.TIF SYSTEM "US20030001861A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00003.TIF SYSTEM "US20030001861A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00004.TIF SYSTEM "US20030001861A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00005.TIF SYSTEM "US20030001861A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00006.TIF SYSTEM "US20030001861A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00007.TIF SYSTEM "US20030001861A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00008.TIF SYSTEM "US20030001861A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00009.TIF SYSTEM "US20030001861A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00010.TIF SYSTEM "US20030001861A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030001861A1-20030102-D00011.TIF SYSTEM "US20030001861A1-20030102-D00011.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030001861</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10233581</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020904</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G09G005/00</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>345</class>
<subclass>609000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>345</class>
<subclass>629000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Method and apparatus for pixel filtering using shared filter resource between overlay and texture mapping engines</title-of-invention>
</technical-information>
<continuity-data>
<continuations>
<continuation-of>
<parent-child>
<child>
<document-id>
<doc-number>10233581</doc-number>
<kind-code>A1</kind-code>
<document-date>20020904</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09480156</doc-number>
<document-date>20000110</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>GRANTED</parent-status>
<parent-patent>
<document-id>
<doc-number>6466226</doc-number>
<country-code>US</country-code>
</document-id>
</parent-patent>
</parent-child>
</continuation-of>
</continuations>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>David</given-name>
<middle-name>W.</middle-name>
<family-name>Watson</family-name>
</name>
<residence>
<residence-us>
<city>Rancho Murieta</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Kim</given-name>
<middle-name>A.</middle-name>
<family-name>Meinerth</family-name>
</name>
<residence>
<residence-us>
<city>Granite Bay</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Indraneel</given-name>
<family-name>Ghosh</family-name>
</name>
<residence>
<residence-us>
<city>Sunnyvale</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Thomas</given-name>
<middle-name>A.</middle-name>
<family-name>Piazza</family-name>
</name>
<residence>
<residence-us>
<city>Granite Bay</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Val</given-name>
<middle-name>G.</middle-name>
<family-name>Cook</family-name>
</name>
<residence>
<residence-us>
<city>Shingle Springs</city>
<state>CA</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<correspondence-address>
<name-1>ANTONELLI TERRY STOUT AND KRAUS</name-1>
<name-2></name-2>
<address>
<address-1>SUITE 1800</address-1>
<address-2>1300 NORTH SEVENTEENTH STREET</address-2>
<city>ARLINGTON</city>
<state>VA</state>
<postalcode>22209</postalcode>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A configurable filter module for providing shared filter resource between an overlay engine and a texture mapping engine of a graphics system. The configurable filter may comprise a plurality of linear blend units each of which receives data input from one of the overlay engine and a mapping engine cache, and generates a linear blend filter output respectively; and a filter output multiplexer which receives data output from the linear blend units and selects a proper byte ordering output, wherein the linear blend units serve as an overlay interpolator filter to perform linear blending of the data input from the overlay engine during a linear blend mode, and serve as a texture bilinear filter to perform bilinear filtering of the data input from the mapping engine cache during a bilinear filtering mode. </paragraph>
</subdoc-abstract>
<subdoc-description>
<cross-reference-to-related-applications>
<heading lvl="1">CLAIM FOR PRIORITY </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This is a continuation application from an application for &ldquo;Method And Apparatus For Pixel Filtering Using Commonly Shared Filter Resource Between Overlay And Texture Mapping Engines&rdquo; filed in the United States Patent &amp; Trademark Office on Jan. 10, 2000, assigned Ser. No. 09/480,156, and all of its subject matters are incorporated by reference herein under 35 U.S.C. &sect;120.</paragraph>
</cross-reference-to-related-applications>
<summary-of-invention>
<section>
<heading lvl="1">TECHNICAL FIELD </heading>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention relates to computer graphics, and more particularly, relates to a method and apparatus for pixel filtering using commonly shared filter resource between an overlay engine (2D graphics engine) and a texture mapping engine (3D graphics engine) in a computer system. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND </heading>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> A typical computer system includes a processor subsystem of one or more microprocessors such as Intel&reg; i386, i486, Celeron&trade; or Pentium&reg; processors, a memory subsystem, one or more chipsets provided to support different types of host processors for different platforms such as desktops, personal computers (PC), servers, workstations and mobile platforms, and to provide an interface with a plurality of input/output (I/O) devices including, for example, keyboards, input devices, disk controllers, and serial and parallel ports to printers, scanners and display devices. Chipsets may integrate a large amount of I/O bus interface circuitry and other circuitry onto only a few chips. Examples of such chipsets may include Intel&reg; 430, 440 and 450 series chipsets, and more recently Intel&reg; 810 and 8XX series chipsets. These chipsets may implement, for example, the I/O bus interface circuitry, direct memory access (DMA) controller, graphics controller, graphics memory controller, and other additional functionality such as graphics visual and texturing enhancements, data buffering, and integrated power management functions. </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> For graphics/multimedia applications, video data may be obtained from a video source by a graphics controller and displayed on a display monitor for viewing purposes. In traditional three-dimensional (3D) graphics systems, 3D images may be generated for representation on a two-dimensional (2D) display monitor. The 2D representation may be provided by defining a 3D model space and assigning sections of the 3D model space to pixels for a visual display on the display monitor. Each pixel may display the combined visual effects such as color, shade and transparency defined on an image. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> The visual characteristics of the 2D representation of the 3D image may also be enhanced by texturing. Texture may represent changes in intensity, color, opacity, or thematic contents (such as surface material type). The process of applying texture patterns to surfaces (adding graphics to scenery) is generally referred to as &ldquo;texture mapping&rdquo; and is well known and widely used technique in computer graphics. The texture may be represented by a 2D array of video data. Data elements in the array are called texels and the array is called a texture map. The two coordinate axes of the texture coordinate space are defined by rows and columns of the array typically designated in &ldquo;U&rdquo; and &ldquo;V&rdquo; coordinates. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Due to various geometric considerations and physical constraints on the amount of data representative of the texture map and pixel array on the display monitor, an image, pattern or video displayed on the display monitor may be subject to visual anomalies or distortions caused by an overlay or a texture manipulation such as, for example, shrinking or enlarging textures during perspective correction. Different types of filtering techniques may be used to prevent texture distortions. For example, an overlay vertical interpolator filter may be used to filter 2D data input from an overlay engine to approximate the vertical stretch blit (block level transfer) in the 2D overlay. Separately, a bilinear texture filter may be used to filter 3D data input from a 3D engine to approximate the perspective correct shading value of a 3D triangular surface. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> However, separate 2D and 3D arithmetic circuits are necessarily required at separate locations (i.e., the overlay engine and the 3D engine) to perform the 2D overlay stretch blit and the 3D texture cache functions. These arithmetic circuits can be burdensome and cost-prohibitive. In addition, separate linear interpolators are also required for different data formats to calculate multiple color resolutions. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> Accordingly, a need exists for a cost-effective filter solution with less hardware to eliminate the need to create separate 2D and 3D arithmetic circuits for the 2D overlay stretch blit and the 3D texture cache functions, and separate linear interpolators for different data formats for multiple color resolutions. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY </heading>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Accordingly, various embodiments of the present invention are directed to a configurable filter module for providing commonly shared filter resource between an overlay engine and a texture mapping engine of a graphics system. Such a filter module may comprise a plurality of linear blend units each of which receives data input from one of the overlay engine and a mapping engine cache, and generates a linear blend filter output respectively; a filter output multiplexer which receives data output from the linear blend units and selects a proper byte ordering output, wherein the linear blend units serve as an overlay interpolator filter to receive data input from the overlay engine for a linear blending function during a linear blend mode, and serve as a texture bilinear filter to receive data input from the mapping engine cache for a texture bilinear filtering function during a bilinear filtering mode. </paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> A more complete appreciation of exemplary embodiments of the present invention, and many of the attendant advantages of the present invention, will become readily apparent as the same becomes better understood by reference to the following detailed description when considered in conjunction with the accompanying drawings in which like reference symbols indicate the same or similar components, wherein: </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> illustrates a block diagram of an example computer system having a graphics/multimedia platform of multi-media engines according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates a block diagram of an example computer system having a host chipset for providing a graphics/multimedia platform according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates a functional diagram of an example graphics and memory controller hub (GMCH) according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> illustrates a top level I/O interconnect diagram of an example mapping engine cache output (MECO) unit for pixel filtering and providing shared filter resource functionality between an overlay engine and a 3D (texture mapping) engine according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates a block diagram of an example mapping engine cache output (MECO) unit for pixel filtering and providing shared filter resource functionality between an overlay engine and a 3D (texture mapping) engine according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates a block diagram of an example shared filter module for providing shared filter resource functionality between an overlay engine and a 3D (texture mapping) engine according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> illustrates a filter configuration diagram of an example shared filter module when configured for operation in Texel 1555 mode, Texel 4444 mode and Texel 565 mode according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates a filter configuration diagram of an example shared filter module when configured for operation in Overlay 565 mode according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates a filter configuration diagram of an example shared filter module when configured for operation in Overlay YUV mode according to an embodiment of the present invention; </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> illustrates a filter configuration diagram of an example shared filter when configured for operation in Overlay YUV 4:2:2 mode according to an embodiment of the present invention; and </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> illustrates a block diagram of an example dual linear blend unit (DLBU) for use in an example shared filter module according to an embodiment of the present invention. </paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION </heading>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The present invention is applicable for use with all types of computer systems, processors, video sources and chipsets, including follow-on chip designs which link together work stations such as computers, servers, peripherals, storage devices, and consumer electronics (CE) devices for audio and video communications. The video sources may include video storage media, video equipments and/or video consumer electronics (CE) devices. Examples of such consumer electronics (CE) devices may include digital video discs (DVD), audio compact discs (CD), videotapes, laser discs, CD-ROMs (read only memory), digital video cameras, digital still cameras, HD-TVs, satellite networks, cable networks, video cassette recorders (VCR), printers, scanners, imaging systems and cellular systems and those CE devices which may become available as technology advances in the future. However, for the sake of simplicity, discussions will concentrate mainly on a computer system having a basic graphics/multimedia platform architecture of multi-media engines executing in parallel to deliver high performance video capabilities, although the scope of the present invention is not limited thereto. The term &ldquo;graphics&rdquo; may include, but may not be limited to, computer-generated images, symbols, visual representations of natural and/or synthetic objects and scenes, pictures and text. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> Attention now is directed to the drawings and particularly to <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, an example computer system <highlight><bold>100</bold></highlight> having a graphics/multimedia platform of multi-media engines according to an embodiment of the present invention is illustrated. The computer system <highlight><bold>100</bold></highlight> (which can be a system commonly referred to as a personal computer or PC) may include one or more processors or central processing units (CPU) <highlight><bold>110</bold></highlight> such as Intel&reg; i386, i486, Celeron&trade; or Pentium&reg; processors, a memory controller <highlight><bold>120</bold></highlight> connected to the CPU <highlight><bold>110</bold></highlight> via a front side bus <highlight><bold>10</bold></highlight>, a system memory <highlight><bold>130</bold></highlight> connected to the memory controller <highlight><bold>120</bold></highlight> via a memory bus <highlight><bold>20</bold></highlight>, a graphics controller <highlight><bold>140</bold></highlight> connected to the memory controller <highlight><bold>120</bold></highlight> via a graphics bus (e.g., Advanced Graphics Port &ldquo;AGP&rdquo; bus) <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> Alternatively, the graphics controller <highlight><bold>140</bold></highlight> may also be configured to access the memory controller <highlight><bold>120</bold></highlight> via a peripheral bus such as a peripheral component interconnect (PCI) bus <highlight><bold>40</bold></highlight>, if so desired. The PCI bus may be a high performance 32 or 64 bit synchronous bus with automatic configurability and multiplexed address, control and data lines as described in the latest version of &ldquo;<highlight><italic>PCI Local Bus Specification, Revision </italic></highlight>2.1&rdquo; set forth by the PCI Special Interest Group (SIG) on Jun. 1, 1995 for added-on arrangements (e.g., expansion cards) with new video, networking, or disk memory storage capabilities. The graphics controller <highlight><bold>140</bold></highlight> controls a visual display of graphics and/or video images on a display monitor <highlight><bold>150</bold></highlight> (e.g., cathode ray tube, liquid crystal display and flat panel display). The display monitor <highlight><bold>150</bold></highlight> can be either an interlaced or progressive monitor, but typically is a progressive display device. A frame buffer <highlight><bold>160</bold></highlight> may be coupled to the graphics controller <highlight><bold>140</bold></highlight> for buffering the data from the graphics controller <highlight><bold>140</bold></highlight>, CPU <highlight><bold>110</bold></highlight>, or other devices within the computer system <highlight><bold>100</bold></highlight> for a visual display of video images on the display monitor <highlight><bold>150</bold></highlight>. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> A digital video disc (DVD) drive <highlight><bold>170</bold></highlight> is connected to the memory controller <highlight><bold>120</bold></highlight> via the PCI bus <highlight><bold>40</bold></highlight>. The DVD drive <highlight><bold>170</bold></highlight> may be configured to read data from any one of a number of currently available DVDs. For example, the DVD may be a DVD-Video disc for displaying a movie onto the display monitor <highlight><bold>150</bold></highlight>. Alternatively, the DVD may be a DVD-ROM disc having a computer program stored thereon in order to run the program on the computer system <highlight><bold>100</bold></highlight>. Since the present invention is directed to displaying DVD-Video on the display monitor <highlight><bold>150</bold></highlight>, all references hereinafter to DVD may pertain to DVD-Video. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> In the described embodiment, video and audio data from the DVD may be obtained in compressed format. The DVD may store both progressive and interlaced video content in a compressed format in accordance with a standard developed by the Motion Picture Experts Group (MPEG) for use with audio-video data (e.g., MPEG-1, MPEG-2 and MPEG-4). For example, a complete description of the MPEG-2 standard can be found in &ldquo;<highlight><italic>Information Technology B Generic Coding of Moving Pictures and Associated Audio Information: Video</italic></highlight>&rdquo; published by the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC); ISO-IEC 13818-2; May. 15, 1996. However, the standard formats need not be limited to MPEG-2; other standards for use with audio-video data may also be readily utilized. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> A video stream decoder <highlight><bold>180</bold></highlight> is connected to the graphics controller <highlight><bold>140</bold></highlight> and receives the compressed video data stream from the DVD drive <highlight><bold>170</bold></highlight>. The video stream decoder <highlight><bold>180</bold></highlight> buffers the compressed video data stream in a dynamic random access memory (DRAM) <highlight><bold>190</bold></highlight>, which is coupled to the video stream decoder <highlight><bold>180</bold></highlight>. Although a DRAM is preferred for the speed, other storage devices such as a read-only-memory (ROM) and video random-access-memory (VRAM) may be utilized for the memory <highlight><bold>190</bold></highlight>. The video stream decoder <highlight><bold>180</bold></highlight> then retrieves the video data from the memory <highlight><bold>190</bold></highlight> as needed and decompresses and decodes the video data. The decoded video data is output to the graphics controller <highlight><bold>140</bold></highlight> for processing and eventual display on the display monitor <highlight><bold>150</bold></highlight>. </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> In a preferred embodiment of the present invention, the memory controller <highlight><bold>120</bold></highlight> and the graphics controller <highlight><bold>140</bold></highlight> may be integrated as a single graphics and memory controller hub (GMCH) including dedicated multi-media engines executing in parallel to deliver high performance 3D, 2D and motion compensation video capabilities. The GMCH may be implemented as a PCI chip such as, for example, PIIX4&reg; chip and PIIX6&reg; chip manufactured by Intel Corporation. In addition, such a GMCH may also be implemented as part of a host chipset along with an I/O controller hub (ICH) and a firmware hub (FWH) as described, for example, in Intel&reg; 810 and 8XX series chipsets. </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> illustrates an example computer system <highlight><bold>100</bold></highlight> including such a host chipset <highlight><bold>200</bold></highlight> according to an embodiment of the present invention. As shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the computer system <highlight><bold>100</bold></highlight> includes essentially the same components shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, except for the host chipset <highlight><bold>200</bold></highlight> which provide a highly-integrated three-chip solution consisting of a graphics and memory controller hub (GMCH) <highlight><bold>210</bold></highlight>, an input/output (I/O) controller hub (ICH) <highlight><bold>220</bold></highlight> and a firmware hub (FWH) <highlight><bold>230</bold></highlight>. </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> The GMCH <highlight><bold>210</bold></highlight> provides graphics and video functions and interfaces one or more memory devices to the system bus <highlight><bold>10</bold></highlight>. The GMCH <highlight><bold>210</bold></highlight> may include a memory controller as well as a graphics controller (which in turn may include a 3D engine, a 2D engine, and a video engine). GMCH <highlight><bold>210</bold></highlight> may be interconnected to any of a system memory <highlight><bold>130</bold></highlight>, a local display memory <highlight><bold>155</bold></highlight>, a display monitor <highlight><bold>150</bold></highlight> (e.g., a computer monitor) and to a television (TV) via an encoder and a digital video output signal. GMCH <highlight><bold>210</bold></highlight> maybe, for example, an Intel&reg; 82810 or 82810-DC100 chip. The GMCH <highlight><bold>210</bold></highlight> also operates as a bridge or interface for communications or signals sent between the processor <highlight><bold>110</bold></highlight> and one or more I/O devices which may be connected to an ICH <highlight><bold>220</bold></highlight>. </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> The ICH <highlight><bold>220</bold></highlight> interfaces one or more I/O devices to GMCH <highlight><bold>210</bold></highlight>. FWH <highlight><bold>230</bold></highlight> is connected to the ICH <highlight><bold>220</bold></highlight> and provides firmware for additional system control. The ICH <highlight><bold>220</bold></highlight> may be for example an Intel&reg; 82801 chip and the FWH <highlight><bold>230</bold></highlight> may be for example an Intel&reg; 82802 chip. </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> The ICH <highlight><bold>220</bold></highlight> may be connected to a variety of I/O devices and the like, such as: a Peripheral Component Interconnect (PCI) bus <highlight><bold>40</bold></highlight> (PCI Local Bus Specification Revision 2.2) which may have one or more I/O devices connected to PCI slots <highlight><bold>194</bold></highlight>, an Industry Standard Architecture (ISA) bus option <highlight><bold>196</bold></highlight> and a local area network (LAN) option <highlight><bold>198</bold></highlight>; a Super I/O chip <highlight><bold>192</bold></highlight> for connection to a mouse, keyboard and other peripheral devices (not shown); an audio coder/decoder (Codec) and modem Codec; a plurality of Universal Serial Bus (USB) ports (USB Specification, Revision 1.0); and a plurality of Ultra/66 AT Attachment (ATA) 2 ports (X3T9.2 948D specification; commonly also known as Integrated Drive Electronics (IDE) ports) for receiving one or more magnetic hard disk drives or other I/O devices. </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> The USB ports and IDE ports may be used to provide an interface to a hard disk drive (HDD) and compact disk read-only-memory (CD-ROM). I/O devices and a flash memory (e.g., EPROM) may also be connected to the ICH of the host chipset for extensive I/O supports and functionality. Those I/O devices may include, for example, a keyboard controller for controlling operations of an alphanumeric keyboard, a cursor control device such as a mouse, track ball, touch pad, joystick, etc., a mass storage device such as magnetic tapes, hard disk drives (HDD), and floppy disk drives (FDD), and serial and parallel ports to printers and scanners. The flash memory may be connected to the ICH of the host chipset via a low pin count (LDC) bus. The flash memory may store a set of system basic input/output start up (BIOS) routines at startup of the computer system <highlight><bold>100</bold></highlight>. The super I/O chip <highlight><bold>192</bold></highlight> may provide an interface with another group of I/O devices. </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> One or more speakers are typically connected to the computer system for outputting sounds or audio information (speech, music, etc.). According to an embodiment, a compact disc (CD) player or preferably a Digital Video Disc (DVD) player is connected to the ICH <highlight><bold>130</bold></highlight> via one of the I/O ports (e.g., IDE ports, USB ports, PCI slots). The DVD player uses information encoded on a DVD disc to provide digital audio and video data streams and other information to allow the computer system to display and output a movie or other multimedia (e.g., audio and video) presentation. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> illustrates a block diagram of a graphics and memory controller hub (GMCH) <highlight><bold>210</bold></highlight> according to an example embodiment of the present invention. The GMCH <highlight><bold>210</bold></highlight> may include a graphics controller <highlight><bold>140</bold></highlight> to provide graphics and video functions and a memory controller <highlight><bold>120</bold></highlight> to control and interface one or more memory devices via the system bus <highlight><bold>10</bold></highlight>. Memory controller <highlight><bold>120</bold></highlight> may be connected to the system bus <highlight><bold>10</bold></highlight> via a buffer <highlight><bold>216</bold></highlight> and a system bus interface <highlight><bold>212</bold></highlight>. The memory controller <highlight><bold>120</bold></highlight> may also be connected to the ICH <highlight><bold>220</bold></highlight> via a buffer <highlight><bold>216</bold></highlight> and a hub interface <highlight><bold>214</bold></highlight>. In addition, the GMCH <highlight><bold>210</bold></highlight> may be connected to a system memory <highlight><bold>130</bold></highlight> and, optionally, a local display memory <highlight><bold>155</bold></highlight> (also commonly referred to as video or graphics memory typically provided on a video card or video memory card). In a cost saving unified memory architecture (UMA), the local display memory <highlight><bold>155</bold></highlight> may be reside in the computer system. In such an architecture, the system memory <highlight><bold>130</bold></highlight> may operate as both system memory and the local display memory. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The graphics controller <highlight><bold>140</bold></highlight> of the GMCH <highlight><bold>210</bold></highlight> may include a 3D (texture mapping) engine <highlight><bold>310</bold></highlight> for performing a variety of 3D graphics functions, including creating a rasterized 2D display image from representation of 3D objects, a 2D engine <highlight><bold>320</bold></highlight> for performing 2D functions, a display engine <highlight><bold>330</bold></highlight> for displaying video or graphics images, and a digital video output port <highlight><bold>340</bold></highlight> for outputting digital video signals and providing connection to traditional TVs or new space-saving digital flat panel display. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> The 3D (texture mapping) engine <highlight><bold>310</bold></highlight> performs a variety of functions including perspective-correct texture mapping to deliver 3D graphics without annoying visual anomalies such as warping, bending or swimming, bilinear and anisotropic filtering to provide smoother and more realistic appearance 3D images, MIP mapping to reduce blockiness and enhance image quality, Gouraud shading, alpha-blending, fogging and Z-buffering. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The 2D engine <highlight><bold>320</bold></highlight> includes a blitter (BLT) engine <highlight><bold>322</bold></highlight> and an arithmetic stretch blitter (BLT) engine <highlight><bold>324</bold></highlight> for performing fixed blitter and stretch blitter (BLT) operations, which refer to a block transfer of pixel data between memory locations. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> The display engine <highlight><bold>330</bold></highlight> includes a hardware motion compensation module <highlight><bold>332</bold></highlight> for performing motion compensation to improve video quality, a hardware cursor <highlight><bold>334</bold></highlight> for providing cursor patterns, an overlay engine <highlight><bold>336</bold></highlight> for merging either video data captured from a video source or data delivered from the 2D engine <highlight><bold>320</bold></highlight> with graphics data on the display monitor <highlight><bold>150</bold></highlight>, and a digital-to-analog converter (DAC) <highlight><bold>338</bold></highlight> for converting digital video to analog video signals (YUV color space to RGB color space) for a visual display on the display monitor <highlight><bold>150</bold></highlight>. The hardware motion compensation module <highlight><bold>332</bold></highlight> may alternatively reside within the 3D engine <highlight><bold>310</bold></highlight> for purposes of simplicity. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> A texture palette <highlight><bold>213</bold></highlight>, also known as a color lookup table (CLUT), may be provided within GMCH <highlight><bold>210</bold></highlight> to identify a subset from a larger range of colors. A small number of colors in the palette <highlight><bold>215</bold></highlight> allows fewer bits to be used to identify the color or intensity of each pixel. The colors for the textures are identified as indices to the texture palette <highlight><bold>215</bold></highlight>. In addition, a sub-picture palette <highlight><bold>215</bold></highlight> may separately be provided for color alpha-blending sub-picture pixels for transparency. However, a single dual-purpose palette may be used as both a texture palette and a sub-picture palette to save hardware and reduce costs. The alpha-blending of the sub-picture with video is an operation typically associated with DVD processing, while texturing is typically associated with 3D processing. In most cases, the computer system may not perform both 3D texturing and alpha-blending at the same time (e.g., DVD videos and 3D games are not typically running at the same time on a computer system). </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> Turning now to <cross-reference target="DRAWINGS">FIG. 4, a</cross-reference> top level I/O interconnect diagram of an example mapping engine cache output (MECO) unit <highlight><bold>400</bold></highlight> for pixel filtering and providing shared filter resource functionality between an overlay engine <highlight><bold>336</bold></highlight> and a 3D (texture mapping) engine <highlight><bold>310</bold></highlight> according to an embodiment of the present invention is illustrated. The MECO unit <highlight><bold>400</bold></highlight>, a mapping engine cache <highlight><bold>410</bold></highlight> and a color calculator <highlight><bold>420</bold></highlight> may reside in the 3D engine <highlight><bold>310</bold></highlight> and form a texture pipeline within the 3D engine <highlight><bold>310</bold></highlight>. The MECO unit <highlight><bold>400</bold></highlight> has an interface directly with the 2D engine <highlight><bold>320</bold></highlight> for receiving 2D inputs (64 bits A &amp; B data input: pixels) from the 2D engine <highlight><bold>320</bold></highlight> through the overlay engine <highlight><bold>336</bold></highlight>. The mapping engine cache <highlight><bold>410</bold></highlight> provides 3D inputs (16 bits A &amp; B data input: texels) from the setup stage of the 3D (texture mapping) engine <highlight><bold>310</bold></highlight> to the MECO unit <highlight><bold>400</bold></highlight>. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> illustrates a block diagram of an example mapping engine cache output (MECO) unit <highlight><bold>400</bold></highlight> for pixel filtering and providing time-domain shared filter resource functionality between an overlay engine and a 3D (texture mapping) engine according to an embodiment of the present invention. As shown in <cross-reference target="DRAWINGS">FIG. 5</cross-reference>, the MECO unit <highlight><bold>400</bold></highlight> contains a shared filter module <highlight><bold>500</bold></highlight> for providing commonly shared filter resource functionality between the overlay engine <highlight><bold>336</bold></highlight> and the 3D (texture mapping) engine <highlight><bold>310</bold></highlight>, and following downstream units, including, for example, a color space converter <highlight><bold>510</bold></highlight>, an anisotropic filter module <highlight><bold>520</bold></highlight>, a dithering unit <highlight><bold>530</bold></highlight>, a re-order FIFO <highlight><bold>540</bold></highlight>, and a motion compensation module <highlight><bold>550</bold></highlight>. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> The shared filter module <highlight><bold>500</bold></highlight> may be a re-configurable filter intended to serve as either an overlay interpolator (Overlay Vertical Stretch Blit) filter for linear blending 2D inputs from a 2D engine <highlight><bold>320</bold></highlight> through an overlay engine <highlight><bold>336</bold></highlight> or a bilinear texture filter for bilinear filtering 3D inputs from a 3D engine <highlight><bold>310</bold></highlight>. The re-configurable filter may be designed to advantageously eliminate the need to create separate 2D and 3D arithmetic circuits for the 2D overlay stretch blit and the 3D texture cache functions. In either filter configuration, the shared filter module <highlight><bold>400</bold></highlight> may be utilized to bi-linear color values to approximate the perspective correct shading value of a 3D triangular surface and the vertical stretch blit in the 2D overlay. However, the shared filter module <highlight><bold>500</bold></highlight> can only service one module function at a time. Arbitration may be required between the overlay engine <highlight><bold>336</bold></highlight> and the texture mapping engine cache <highlight><bold>410</bold></highlight> with overlay assigned the highest priority. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> The color space converter <highlight><bold>510</bold></highlight> receives YUV data and converts the same into RGB data. YUV represents color-difference video data containing one luminance component (Y) and two chrominance components (U, V). YUV may also be referred to as YCrCb (where Cr and Cb are chrominance values corresponding to U and V). Thus the terms YUV and YCrCb may be used interchangeably hereinbelow. In contrast to YUV, RGB represents composite video data containing red (R), green (G) and blue (B) components. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> The anisotropic filter module <highlight><bold>520</bold></highlight> sums four pixels from different levels-of-detail (LOD) levels ranging, for example, from 1024&times;1024 to 1&times;1 texels, and then averages them to produce an average of four LOD levels. Data is received from the color space converter <highlight><bold>510</bold></highlight> accumulated over the next three data cycles to accumulate a total of four texels. When four texels have been accumulated, the value may be averaged to produce the final result and the corresponding valid signal may be activated to indicate the completion. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> The dithering unit <highlight><bold>530</bold></highlight> reads dither weights from a table and sums the dither weights with the current pixel data received from the anisotropic filter module <highlight><bold>520</bold></highlight>. The re-ordering FIFO <highlight><bold>540</bold></highlight> properly sorts pixels for the proper output format. The motion compensation module <highlight><bold>550</bold></highlight> then averages two pixels (the previous and future pixel values) and sums an error term with the averaged result. Finally, the motion compensation module <highlight><bold>550</bold></highlight> sends data to the color calculator <highlight><bold>420</bold></highlight> (see <cross-reference target="DRAWINGS">FIG. 4</cross-reference>) for handling final color calculations that the texture map may contain, that is, blending the shading with the texture maps to process the texels before rendering on the display monitor <highlight><bold>150</bold></highlight>. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> The shared filter module <highlight><bold>500</bold></highlight> uses a gate saving optimization based on the linear blend equation as follows:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>A&plus;&agr;</italic></highlight>(<highlight><italic>B&minus;A</italic></highlight>)</in-line-formula></paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> where A represents either first 64 bit or 16 bit data input, and B represents either second 64 bit or 16 bit data input. The linear blend equation may expand to:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>A&plus;&agr;B&minus;&agr;</italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> rearranging terms:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>A&minus;&agr;A&plus;&agr;B</italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> factoring out A from the first two terms:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>A</italic></highlight>(1&minus;&agr;)&plus;&agr;<highlight><italic>B</italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> complement alpha and remove the minus sign:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>A</italic></highlight>(1&plus;{overscore (&agr;)})&plus;&agr;<highlight><italic>B</italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> multiply parenthesis quantity by A finally yields:</paragraph>
<paragraph lvl="0"><in-line-formula><highlight><italic>A&plus;{overscore (&agr;)}A&plus;&agr;B</italic></highlight></in-line-formula></paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Based on the linear blend equation, a multiply-free linear blend unit (LBU) may be created. The optimization may be accomplished by noting that a binary multiplication can be achieved by summing the multiplicand by itself shifted by the bit position of any active bits (bits containing 1) in the multiplier. In this situation, A will be selected when B is not. This allows selection of A or B as inputs to the master summer of the multiply, thus reducing the number of terms to 2 that would normally be required. In order to support two data formats, 565 pixel grouping (5 bits of red value, 6 bits of green value and 5 bits of blue value) or a 88 pixel grouping, the linear blend unit (LBU) may split into a three-bit multiply section and a five bit multiply section. Two of these split linear blend units may be combined into a dual linear blend unit (DLBU) with the capability of operating in an 88 resolution format or a 565 resolution format. Four such dual linear blend units (DLBU) plus one single linear blend unit (LBU) may be required for all pixel/texel formats. All filter modes may be controlled by filter inputs, such as an &ldquo;Ovalidln&rdquo; signal from the overlay engine <highlight><bold>336</bold></highlight> and a &ldquo;565/88&rdquo; filter mode select signal from the mapping engine cache (MEC) <highlight><bold>410</bold></highlight>. The following modes of filtering are required: 1) overlay vertical interpolator filtering, and 2) bilinear texture filtering. In order to support all the precision needed by the downstream dithering unit <highlight><bold>530</bold></highlight> (see <cross-reference target="DRAWINGS">FIG. 5</cross-reference>), the last dual linear blend unit (DLBU) may carry 24 bit precision out for RGB (eight bit precision for each R, G and B) dithering inputs. All other linear blend units (both dual and single) only carry eight bits of precision for 8 bit modes and split the precision to 565 for RGB. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates a block diagram of an example shared filter module <highlight><bold>500</bold></highlight> for providing commonly shared filter resource functionality between an overlay (2D) engine and a texture mapping (3D) engine according to an embodiment of the present invention. As shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, the shared filter module <highlight><bold>500</bold></highlight> may comprise a plurality of linear blend units <highlight><bold>610</bold></highlight>, <highlight><bold>620</bold></highlight>, <highlight><bold>630</bold></highlight>, <highlight><bold>640</bold></highlight> and <highlight><bold>650</bold></highlight> which receive 64 bit (2D) or 16 bit (3D) A &amp; B data input from either an overlay engine <highlight><bold>336</bold></highlight> or a mapping engine cache (MEC) <highlight><bold>410</bold></highlight>, and generate dual linear blend filter output respectively, via respective registers <highlight><bold>612</bold></highlight>, <highlight><bold>622</bold></highlight>, <highlight><bold>632</bold></highlight>, and <highlight><bold>642</bold></highlight>, and a filter output multiplexer <highlight><bold>660</bold></highlight> which receives data output from the linear blend units <highlight><bold>610</bold></highlight>, <highlight><bold>620</bold></highlight>, <highlight><bold>630</bold></highlight>, <highlight><bold>640</bold></highlight> and <highlight><bold>650</bold></highlight> and selects the proper byte ordering for the downstream units, i.e., the color space converter <highlight><bold>510</bold></highlight> via registers <highlight><bold>662</bold></highlight>, <highlight><bold>664</bold></highlight>, <highlight><bold>666</bold></highlight> and <highlight><bold>668</bold></highlight>. There may be nine linear blend units used to form the shared filter module <highlight><bold>500</bold></highlight> (four dual linear blend units (LBU<highlight><bold>0</bold></highlight>-LBU<highlight><bold>3</bold></highlight>) and a single linear blend unit (LBU<highlight><bold>8</bold></highlight>)). Each dual linear blend unit (LBU<highlight><bold>0</bold></highlight>-LBU<highlight><bold>3</bold></highlight>) is designed to support two data formats, for example, 565 and 88 configurations. Each dual linear blend unit (LBU<highlight><bold>0</bold></highlight>-LBU<highlight><bold>3</bold></highlight>) may be configured as two split linear blend units or three split linear blend units and the associated circuitry to support both data formats. Dual linear blend unit (LBU<highlight><bold>3</bold></highlight>) <highlight><bold>640</bold></highlight> may be arranged to receive 64 bit (2D) or 16 bit (3D) A &amp; B data input via selectors <highlight><bold>602</bold></highlight> and <highlight><bold>604</bold></highlight> under control of a filter mode signal (bilinear/linear blend control bits). In contrast to the dual linear blend unit (LBU<highlight><bold>0</bold></highlight>-LBU<highlight><bold>3</bold></highlight>), the single linear blend unit (LBU<highlight><bold>8</bold></highlight>) supports only one data format, that is the <highlight><bold>88</bold></highlight> configuration. In either blend unit, rounding circuitry may be provided to round away from zero with signed data. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> The shared filter module <highlight><bold>500</bold></highlight> has two basic modes of operation: a linear blend mode implementing the linear blend equation A&plus;alpha(B&minus;A), and a bilinear mode implementing bilinear filtering function. When operated in the linear blend mode, the shared filter module <highlight><bold>500</bold></highlight> serves as an overlay interpolator (Overlay Vertical Stretch Blit) filter which receives 2D input data from the overlay engine <highlight><bold>336</bold></highlight>. 2D input data may consist of overlay surface A, overlay surface B, alpha, a request for filter signal and a signed signal. The function A&plus;alpha(B&minus;A) is calculated and the result is returned to the overlay engine <highlight><bold>336</bold></highlight>. Nine linear blend units of the shared filter module <highlight><bold>500</bold></highlight> act as linear interpolators. Nine such linear interpolators may be required for all formats supported. The linear interpolator contains the following: the A and B data input may be eight bits unsigned for Y and &minus;128 to 127 in two&apos;s complement for U and V. Precision for alpha may be six bits. All calculations may be rounded away from zero. Data formats supported for pixels may include 1555,565 and 88 color formats. Vertical stretch blit can produce one 64 bit quantity per clock. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> When operated in the bilinear mode, the shared filter module <highlight><bold>500</bold></highlight> serves as a texture bilinear filter to receive 3D input data from the mapping engine cache <highlight><bold>410</bold></highlight>. 3D input data may consist of texels. Bilinear filtering may be accomplished on texels using the equation: C&equals;C<highlight><bold>1</bold></highlight>(1&minus;.u)(1&minus;.v)&plus;C<highlight><bold>2</bold></highlight>(.u(1&minus;.v))&plus;C<highlight><bold>3</bold></highlight>(.u*.v)&plus;C<highlight><bold>4</bold></highlight>(1&minus;.u)*.v, where C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>,C<highlight><bold>3</bold></highlight> and C<highlight><bold>4</bold></highlight> are the four adjacent texels making up the locations U&minus;V, U&plus;<highlight><bold>1</bold></highlight>&minus;V, U&minus;V&plus;1 and U&plus;1&minus;V&plus;1. The values .u and .v are the fractional locations within the C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, C<highlight><bold>3</bold></highlight>, C<highlight><bold>4</bold></highlight> texels. Data formats supported for texels may include 1555 ARGB, 0565 ARGB and 4444 ARGB color formats, where A is alpha. Color spaces of YUV and RGB are also supported. Texel 1555, 565 and 4444 produce one 16 bit quantity (i.e. 1555, 565 or 4444) per clock. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> The nine linear blend units of the shared filter module <highlight><bold>500</bold></highlight> (four dual linear blend units (LBU<highlight><bold>0</bold></highlight>-LBU<highlight><bold>3</bold></highlight>) and a single linear blend unit (LBU<highlight><bold>8</bold></highlight>)) can be configured as either eight (8) eight bit linear interpolators, three (3) eight bit bi-linear interpolators, or four (4) 555 bi-linear interpolators for operation in either a linear blend mode implementing the linear blend equation A&plus;alpha(B&minus;A) or a bilinear mode in different data formats. These data formats include, for example: (1) Texel 1555, Texel 4444, and Texel 565; (2) Overlay 565; (3) Overlay YUV; and (4) YUV 4:2:0/4:2:2. Texel 1555, Texel 4444, Texel 565, and YUV 4:2:0/4:2:2 format require the bilinear filter configuration, whereas the Overlay 565 and Overlay YUV require the linear blending configuration. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> Control bits (bilinear/linear blend) determine the filter configuration of the shared filter module <highlight><bold>500</bold></highlight>. An overlay valid data signal may be used to control the arbitration and selection of the filter owner (i.e., overlay and texture). Arbitration may be performed between the overlay stretch blit and the texture cache functions. The overlay maintains the highest priority and the texture cache may be assigned the lowest (two state priority). When valid overlay is present (determined by the overlay valid signal) the overlay engine <highlight><bold>336</bold></highlight> owns the filter operation of the shared filter module <highlight><bold>500</bold></highlight> until the overlay valid signal is no longer asserted. During this time the texture pipeline within the 3D engine <highlight><bold>310</bold></highlight> freezes (if any) current operations and waits until the overlay engine <highlight><bold>336</bold></highlight> has completed use of the shared filter module <highlight><bold>500</bold></highlight>. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> illustrates a filter configuration diagram of an example shared filter module <highlight><bold>500</bold></highlight> when configured for bilinear filter operation in Texel 1555 mode and Texel 4444 mode according to an embodiment of the present invention. As shown in <cross-reference target="DRAWINGS">FIG. 7</cross-reference>, each of the dual linear blend units (LUB<highlight><bold>0</bold></highlight>-<highlight><bold>3</bold></highlight>) of the shared filter module <highlight><bold>500</bold></highlight> may be configured as three linear blend units <highlight><bold>610</bold></highlight>A-<highlight><bold>610</bold></highlight>C, <highlight><bold>620</bold></highlight>A-<highlight><bold>620</bold></highlight>C, and <highlight><bold>640</bold></highlight>A-<highlight><bold>640</bold></highlight>C, and two linear blend units <highlight><bold>630</bold></highlight>A-<highlight><bold>630</bold></highlight>B. Dual linear blend units (BLU<highlight><bold>0</bold></highlight>, BLU<highlight><bold>1</bold></highlight> and BLU<highlight><bold>3</bold></highlight>) <highlight><bold>610</bold></highlight>A-<highlight><bold>610</bold></highlight>C, <highlight><bold>620</bold></highlight>A-<highlight><bold>620</bold></highlight>C and <highlight><bold>640</bold></highlight>A-<highlight><bold>640</bold></highlight>C are configured for bi-linear filtering of A &amp; B data input from the mapping engine cache <highlight><bold>410</bold></highlight> to approximate perspective correct shading value of a 3D triangular surface for a 565 resolution format. In contrast to BLU<highlight><bold>0</bold></highlight>, BLU<highlight><bold>1</bold></highlight> and BLU<highlight><bold>3</bold></highlight>, the dual linear blend unit (LBU<highlight><bold>2</bold></highlight>) <highlight><bold>630</bold></highlight>A-<highlight><bold>630</bold></highlight>B and the single LBU <highlight><bold>650</bold></highlight> are configured for bi-linear filtering of A &amp; B data input from the mapping engine cache <highlight><bold>410</bold></highlight> to approximate perspective correct shading value of a 3D triangular surface for a 88 resolution format. Registers <highlight><bold>710</bold></highlight>-<highlight><bold>780</bold></highlight> may be provided to control operation of the filter configuration. As for Texel 565 mode, the dual linear blend units (BLU<highlight><bold>0</bold></highlight>, BLU<highlight><bold>1</bold></highlight> and BLU<highlight><bold>3</bold></highlight>) <highlight><bold>610</bold></highlight>A-<highlight><bold>610</bold></highlight>C, <highlight><bold>620</bold></highlight>A-<highlight><bold>620</bold></highlight>C and <highlight><bold>640</bold></highlight>A-<highlight><bold>640</bold></highlight>C are configured for bi-linear filtering of A &amp; B data input from the mapping engine cache <highlight><bold>410</bold></highlight> to approximate perspective correct shading value of a 3D triangular surface for a 565 resolution format. However, the dual LUB<highlight><bold>2</bold></highlight> <highlight><bold>630</bold></highlight>A-<highlight><bold>630</bold></highlight>B and the single LBU <highlight><bold>650</bold></highlight> may not be used. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> illustrates a filter configuration diagram of an example shared filter module <highlight><bold>500</bold></highlight> when configured for operation in Overlay 565 mode according to an embodiment of the present invention. As shown in <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, all dual linear blend units (LUB<highlight><bold>0</bold></highlight>-<highlight><bold>3</bold></highlight>) of the shared filter module <highlight><bold>500</bold></highlight> may be configured as three linear blend units <highlight><bold>610</bold></highlight>A-<highlight><bold>610</bold></highlight>C, <highlight><bold>620</bold></highlight>A-<highlight><bold>620</bold></highlight>C, <highlight><bold>630</bold></highlight>A-<highlight><bold>630</bold></highlight>C and <highlight><bold>640</bold></highlight>A-<highlight><bold>640</bold></highlight>C for linear blending A &amp; B data input from the overlay engine <highlight><bold>336</bold></highlight> to approximate perspective correct shading value of a 3D triangular surface for a 565 resolution format. Registers <highlight><bold>612</bold></highlight>, <highlight><bold>622</bold></highlight>, <highlight><bold>632</bold></highlight> and <highlight><bold>642</bold></highlight> may be provided to control operation of the filter configuration. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> illustrates a filter configuration diagram of an example shared filter module when configured for operation in Overlay YUV mode according to an embodiment of the present invention. As shown in <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, all dual linear blend units (LUB<highlight><bold>0</bold></highlight>-<highlight><bold>3</bold></highlight>) of the shared filter module <highlight><bold>500</bold></highlight> may be configured as two linear blend units <highlight><bold>610</bold></highlight>A-<highlight><bold>610</bold></highlight>C, <highlight><bold>620</bold></highlight>A-<highlight><bold>620</bold></highlight>C, <highlight><bold>630</bold></highlight>A-<highlight><bold>630</bold></highlight>C and <highlight><bold>640</bold></highlight>A-<highlight><bold>640</bold></highlight>C for linear blending A &amp; B data input from the overlay engine <highlight><bold>336</bold></highlight> to approximate perspective correct shading value of a 3D triangular surface for a 88 resolution format. Single LUB<highlight><bold>8</bold></highlight> may not be used. Registers <highlight><bold>910</bold></highlight>-<highlight><bold>924</bold></highlight> may be provided to control operation of the filter configuration. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> illustrates a filter configuration diagram of an example shared filter when configured for operation in Overlay YUV 4:2:0/4:2:2 mode according to an embodiment of the present invention. YUV 4:2:0 is a planar format typically used for digital playback since planar YUV 4:2:0 format requires less bandwidth. In contrast to YUV 4:2:0, YUV 4:2:2 is a packed or interleaved format used for graphics generation and video processing since YUV 4:2:2 format provides a more detailed, richer display. As shown in <cross-reference target="DRAWINGS">FIG. 10</cross-reference>, all dual linear blend units (LUB<highlight><bold>0</bold></highlight>-<highlight><bold>3</bold></highlight>) of the shared filter module <highlight><bold>500</bold></highlight> may be configured as two linear blend units <highlight><bold>610</bold></highlight>A-<highlight><bold>610</bold></highlight>B, <highlight><bold>620</bold></highlight>A-<highlight><bold>620</bold></highlight>B, <highlight><bold>630</bold></highlight>A-<highlight><bold>630</bold></highlight>B and <highlight><bold>640</bold></highlight>A-<highlight><bold>640</bold></highlight>B for bi-linear filtering of A &amp; B data input from the mapping engine cache <highlight><bold>410</bold></highlight> to approximate perspective correct shading value of a 3D triangular surface for a 88 resolution format. Registers <highlight><bold>930</bold></highlight>-<highlight><bold>940</bold></highlight> may be provided to control operation of the filter configuration. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11</cross-reference> illustrates a block diagram of an example dual linear blend unit (LBU) for use in an example shared filter module <highlight><bold>500</bold></highlight> according to an embodiment of the present invention. As described previously, the dual linear blend unit (LBU) may be designed to support two data formats, 565 and 88 configurations. As a result, a single combined interpolator may be all that is required to interpolate color values to approximate perspective correct shading value of a 3D triangular surface of both a 565 resolution format and an 88 resolution format. Such use of a single interpolator eliminates the need to create separate calculation units for each bit resolution of linear interpolations. As shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>, the LBU unit may be partitioned into four calculation units, two high order 5 bit and 3 bit calculation units <highlight><bold>1100</bold></highlight> and <highlight><bold>1110</bold></highlight>, and two low order 5 bit and 3 bit calculation units <highlight><bold>1120</bold></highlight> and <highlight><bold>1130</bold></highlight>. Adders <highlight><bold>1140</bold></highlight>-<highlight><bold>1170</bold></highlight>, <highlight><bold>1190</bold></highlight> and <highlight><bold>1210</bold></highlight>, multiplexers <highlight><bold>1180</bold></highlight>, <highlight><bold>1200</bold></highlight> and <highlight><bold>1230</bold></highlight>, and rounding circuitry <highlight><bold>1220</bold></highlight> may be provided to create a high order 8 bit precision calculation, a low order 8 bit precision calculation and a middle 6 bit calculation. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Using the above partitioning, the high order 5 bit calculation unit <highlight><bold>1100</bold></highlight> can be shifted right by three positions and added to the high order 3 bit calculation unit <highlight><bold>1110</bold></highlight> by the adders <highlight><bold>1140</bold></highlight> and <highlight><bold>1150</bold></highlight> to create a high order 8 bit precision calculation. Likewise, the low order 3 bit calculation unit <highlight><bold>1120</bold></highlight> can be shifted right five positions and added to the low order 5 bit calculation unit <highlight><bold>1130</bold></highlight> to create a low order 8 bit precision calculation. For 565 resolutions the high and low order 5 bit calculation units <highlight><bold>1100</bold></highlight> and <highlight><bold>1130</bold></highlight> are passed through unchanged and the high order 3 bit calculation unit <highlight><bold>1110</bold></highlight> is shifted right three positions and added to the low order 3 bit calculation unit <highlight><bold>1120</bold></highlight> to create the middle 6 bit calculation. The final carry addition sends data to the mode select multiplexer <highlight><bold>1230</bold></highlight> for either a 565 or 88 formatting. Reconfiguration of the 3 and 5 bit calculation units <highlight><bold>1100</bold></highlight>, <highlight><bold>1110</bold></highlight>, <highlight><bold>1120</bold></highlight>, <highlight><bold>1130</bold></highlight> may be achieved by the multiplexers <highlight><bold>1180</bold></highlight>, <highlight><bold>1200</bold></highlight> and <highlight><bold>1230</bold></highlight> controlled from a 565/88 configuration bit. Rounding circuitry <highlight><bold>1220</bold></highlight> is provided to round away from zero with signed data. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> As described from the foregoing, the present invention advantageously provides a shared filter module designed with minimal hardware for providing commonly shared filter resource between an overlay engine and a 3D (texture mapping) engine in order to eliminate the need to create separate 2D and 3D arithmetic circuits for the 2D overlay stretch blit and the 3D texture cache functions, and separate linear interpolators for different data formats for multiple color resolutions. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> While there have been illustrated and described what are considered to be exemplary embodiments of the present invention, it will be understood by those skilled in the art and as technology develops that various changes and modifications may be made, and equivalents may be substituted for elements thereof without departing from the true scope of the present invention. For example, the present invention is applicable to all types of computer systems and video consumer electronics (CE) devices, including, but not limited to, high definition TV (HDTV), video games, video imaging devices and video disks. The present invention is also applicable for all types of compressed video data stream in different formats, and need not be limited to the computer system <highlight><bold>100</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, but can be adapted to other video processing devices and systems. Many modifications may be made to adapt the teachings of the present invention to a particular situation without departing from the scope thereof. Therefore, it is intended that the present invention not be limited to the various exemplary embodiments disclosed, but that the present invention includes all embodiments falling within the scope of the appended claims. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A configurable filter module comprising: 
<claim-text>a plurality of linear blend units each to receive data input from one of an overlay engine and a mapping engine cache, and generate a linear blend filter output respectively; and </claim-text>
<claim-text>a filter output multiplexer to receive data output from the linear blend units and select a proper byte ordering output, </claim-text>
<claim-text>wherein said linear blend units serve as an overlay interpolator filter to perform linear blending of the data input from the overlay engine during a linear blend mode, and serve as a texture bilinear filter to perform bilinear filtering of the data input from the mapping engine cache during a bilinear filtering mode. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the plurality of linear blending units comprise four dual linear blend units provided to support at least two data formats, and a single linear blend unit provided to support only one data format. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein the dual linear blend units are configured as either two split linear blend units or three split linear blend units and include associated circuitry to support both data formats under control of a filter select signal. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein the linear blending is accomplished on pixels using the equation A&plus;&agr;(B&minus;A), where A represents 2-dimensional pixel data from the overlay engine indicating overlay surface A, B represents 2-dimensional data from the overlay engine indicating overlay surface B, and alpha (&agr;) represents a blending coefficient. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein the bilinear filtering is accomplished on texels using the equation: C&equals;C<highlight><bold>1</bold></highlight>(1&minus;.u)(1&minus;.v)&plus;C<highlight><bold>2</bold></highlight>(.u(1&minus;.v))&plus;C<highlight><bold>3</bold></highlight>(.u*.v)&plus;C<highlight><bold>4</bold></highlight>(1&minus;.u)*.v, where C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, C<highlight><bold>3</bold></highlight> and C<highlight><bold>4</bold></highlight> represent 3-dimentional texel data from the mapping engine cache indicating four adjacent texels of locations U&minus;V, U&plus;1&minus;V, U&minus;V&plus;1 and U&plus;1&minus;V&plus;1, and where values .u and .v indicate fractional locations within the C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, C<highlight><bold>3</bold></highlight>, C<highlight><bold>4</bold></highlight> texels. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein requests from the overlay engine for overlay interpolation take precedence over requests from the mapping engine cache. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the linear blend units can be configured as one of eight 8-bit linear interpolators, three 8-bit bi-linear interpolators and four 565 bi-linear interpolators to perform either said linear blending or said bilinear filtering of data input from respective overlay engine and mapping engine cache. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the linear blend units are configured as a combination of thrice-split linear blend units, a twice-split linear blend unit and a single linear blend unit for bilinear filtering data input from the mapping engine cache to approximate perspective correct shading value of a 3-dimensional triangular surface for different resolution formats. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the linear blend units are configured as four thrice-split linear blend units arranged in parallel for linear blending data input from the overlay engine to approximate perspective correct shading value of a 3-dimensional triangular surface for different resolution formats. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein the linear blend units are configured as a combination of four dual linear blend units and a single linear blend unit arranged in parallel for bilinear filtering data input from the mapping engine cache to approximate perspective correct shading value of a 3-dimensional triangular surface for different resolution formats. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The configurable filter module as claimed in <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein each of the linear blend units act as a single interpolator to calculate multiple color resolutions of different data format precision, and comprises: 
<claim-text>a high order 5-bit calculation unit arranged to shift data input from left to right by three bit positions; </claim-text>
<claim-text>a high order 3-bit calculation unit arranged to shift data input from left to right by five bit positions; </claim-text>
<claim-text>first adders arranged to add outputs from the high order 5-bit and 3-bit calculation units to create a high order 8-bit precision calculation; </claim-text>
<claim-text>a low order 3-bit calculation unit arranged to shift data input from left to right by five bit positions; </claim-text>
<claim-text>a low order 5-bit calculation unit arranged to shift data input from left to right by three bit positions; </claim-text>
<claim-text>second adders arranged to add outputs from the low order 5-bit and 3-bit calculation units to create a low order 8-bit precision calculation; and </claim-text>
<claim-text>means for calculating multiple color resolutions of different data format precision based on the high order 8-bit precision calculation and the low order 8-bit precision calculation. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. A method for providing shared filter functionality between first and second discrete engines in a graphics system to process video data comprising: 
<claim-text>receiving video data from one of the first engine and the second engine; </claim-text>
<claim-text>configuring a plurality of linear blend units to perform linear blending of the video data received from the first engine or to perform bilinear filtering of the video data received from the second engine; and </claim-text>
<claim-text>determining filter color values to approximate perspective shading of a triangular surface of an image in different resolution formats. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 12</dependent-claim-reference>, wherein the first engine corresponds to an overlay engine, the second engine corresponds to a texture mapping engine, and the linear blending is accomplished on pixels using the equation A&plus;alpha(B&minus;A), where A represents 2-dimensional pixel data from the overlay engine indicating overlay surface A, B represents 2-dimensional data from the overlay engine indicating overlay surface B, and alpha represents a blending coefficient. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein the bilinear filtering is accomplished on texels using the equation: C&equals;C<highlight><bold>1</bold></highlight>(1&minus;.u)(1&minus;.v)&plus;C<highlight><bold>2</bold></highlight>(.u(1&minus;.v))&plus;C<highlight><bold>3</bold></highlight>(.u*.v)&plus;C<highlight><bold>4</bold></highlight>(1&minus;.u)*.v, where C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, C<highlight><bold>3</bold></highlight> and C<highlight><bold>4</bold></highlight> represent 3-dimentional texel data from said texture mapping engine indicating four adjacent texels of locations U&minus;V, U&plus;1&minus;V, U&minus;V&plus;1 and U&plus;1&minus;V&plus;1, and where values .u and .v indicate fractional locations within the C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, C<highlight><bold>3</bold></highlight>, C<highlight><bold>4</bold></highlight> texels. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 13</dependent-claim-reference>, wherein requests from the overlay engine for overlay interpolation take precedence over requests from the texture mapping engine. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. A graphics controller comprising: 
<claim-text>an engine to provide video data in two-dimension (2D); </claim-text>
<claim-text>a cache to store video data in three-dimension (3D); and </claim-text>
<claim-text>a configurable filter to provide shared filter resources and to perform linear blending of video data in 2D from the engine, or bilinear filtering of video data in 3D from the cache for a visual display. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein the engine is an overlay engine configured to perform 2D graphics functions and include a blifter (BLT) engine and an arithmetic stretch blitter (BLT) engine for performing fixed blitter and stretch blitter (BLT) operations. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 17</dependent-claim-reference>, further comprising a 3D engine to provide video data in 3D for storage in the cache, perform 3D graphics functions, including creating a rasterized 2D display image from representation of 3D, perspective-correct texture mapping to deliver 3D graphics, bilinear and anisotropic filtering, MIP mapping to reduce blockiness and enhance image quality, Gouraud shading, alpha-blending, fogging and Z-buffering. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein the 3D engine further comprises: 
<claim-text>a color space converter to receive YUV data and convert into RGB data, where YUV represents color-difference video data containing one luminance component (Y) and two chrominance components (U, V), and RGB represents composite video data containing red (R), green (G) and blue (B) components of an image; </claim-text>
<claim-text>an anisotropic filter to combine pixels from different levels-of-detail (LOD) levels to produce an average of selected multiple LOD levels; </claim-text>
<claim-text>a dithering unit to read dither weights from a table and sum the dither weights with the current pixel data received from the anisotropic filter; </claim-text>
<claim-text>a re-ordering FIFO to sort pixels for the proper output format; and </claim-text>
<claim-text>a motion compensation unit to average successive pixels, sum an error term with the averaged result, and send data for final color calculations before rendering for said visual display. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein said configurable filter comprises: 
<claim-text>a plurality of linear blend units to receive data input from one of the engine and the cache; and </claim-text>
<claim-text>a filter output multiplexer to receive data output from the linear blend units and select a proper byte ordering output, </claim-text>
<claim-text>wherein said linear blend units serve as an overlay interpolator filter to perform said linear blending of the video data received from the engine during a linear blend mode, and serve as a texture bilinear filter to perform said bilinear filtering of the video data received from the cache during a bilinear filtering mode. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the plurality of linear blending units comprise four dual linear blend units provided to support at least two data formats, and a single linear blend unit provided to support only one data format. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the dual linear blend units are configured as either two split linear blend units or three split linear blend units and include associated circuitry to support both data formats under control of a filter select signal. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the linear blending is accomplished on pixels using the equation A&plus;alpha(B&minus;A), where A represents 2-dimensional pixel data from the engine indicating overlay surface A, B represents 2-dimensional data from the engine indicating overlay surface B, and alpha represents a blending coefficient. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the bilinear filtering is accomplished on texels using the equation: C&equals;C<highlight><bold>1</bold></highlight>(1&minus;.u)(1&minus;.v)&plus;C<highlight><bold>2</bold></highlight>(.u(1&minus;.v))&plus;C<highlight><bold>3</bold></highlight>(.u*.v)&plus;C<highlight><bold>4</bold></highlight>(1&minus;.u)*.v, where C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, C<highlight><bold>3</bold></highlight> and C<highlight><bold>4</bold></highlight> represent 3-dimensional texel data from the cache indicating four adjacent texels of locations U&minus;V, U&plus;1&minus;V, U&minus;V&plus;1 and U&plus;1&minus;V&plus;1, and where values .u and v indicate fractional locations within the C<highlight><bold>1</bold></highlight>, C<highlight><bold>2</bold></highlight>, C<highlight><bold>3</bold></highlight>, C<highlight><bold>4</bold></highlight> texels. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein requests from the engine for overlay interpolation take precedence over requests from the cache. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the linear blend units can be configured as one of eight 8-bit linear interpolators, three 8-bit bi-linear interpolators and four 565 bi-linear interpolators to perform either said linear blending or said bilinear filtering of video data received from the engine and the cache. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the linear blend units are configured as a combination of three thrice-split linear blend units, a twice-split linear blend unit and a single linear blend unit for bilinear filtering data received from the cache to approximate perspective correct shading value of a 3-dimensional triangular surface for different resolution formats. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the linear blend units are configured as four thrice-split linear blend units arranged in parallel for linear blending video data received from the engine to approximate perspective correct shading value of a 3-dimensional triangular surface for different resolution formats. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein the linear blend units are configured as a combination of four dual linear blend units and a single linear blend unit arranged in parallel for bilinear filtering video data received from the cache to approximate perspective correct shading value of a 3-dimensional triangular surface for different resolution formats. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The graphics controller as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein each of said linear blend units act as a single interpolator to calculate multiple color resolutions of different data format precision, and comprises: 
<claim-text>a high order 5-bit calculation unit arranged to shift video data received from left to right by three bit positions; </claim-text>
<claim-text>a high order 3-bit calculation unit arranged to shift data received from left to right by five bit positions; </claim-text>
<claim-text>first adders arranged to add outputs from the high order 5-bit and 3-bit calculation units to create a high order 8-bit precision calculation; </claim-text>
<claim-text>a low order 3-bit calculation unit arranged to shift data input from left to right by five bit positions; </claim-text>
<claim-text>a low order 5-bit calculation unit arranged to shift data input from left to right by three bit positions; </claim-text>
<claim-text>second adders arranged to add outputs from the low order 5-bit and 3-bit calculation units to create a low order 8-bit precision calculation; and </claim-text>
<claim-text>means for calculating multiple color resolutions of different data format precision based on the high order 8-bit precision calculation and the low order 8-bit precision calculation.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>4</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030001861A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030001861A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030001861A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030001861A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030001861A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030001861A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030001861A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030001861A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030001861A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030001861A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030001861A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030001861A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
