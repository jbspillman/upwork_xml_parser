<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030005073A1-20030102-D00000.TIF SYSTEM "US20030005073A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00001.TIF SYSTEM "US20030005073A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00002.TIF SYSTEM "US20030005073A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00003.TIF SYSTEM "US20030005073A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00004.TIF SYSTEM "US20030005073A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00005.TIF SYSTEM "US20030005073A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00006.TIF SYSTEM "US20030005073A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00007.TIF SYSTEM "US20030005073A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00008.TIF SYSTEM "US20030005073A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00009.TIF SYSTEM "US20030005073A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00010.TIF SYSTEM "US20030005073A1-20030102-D00010.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00011.TIF SYSTEM "US20030005073A1-20030102-D00011.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00012.TIF SYSTEM "US20030005073A1-20030102-D00012.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00013.TIF SYSTEM "US20030005073A1-20030102-D00013.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00014.TIF SYSTEM "US20030005073A1-20030102-D00014.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00015.TIF SYSTEM "US20030005073A1-20030102-D00015.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00016.TIF SYSTEM "US20030005073A1-20030102-D00016.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00017.TIF SYSTEM "US20030005073A1-20030102-D00017.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00018.TIF SYSTEM "US20030005073A1-20030102-D00018.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00019.TIF SYSTEM "US20030005073A1-20030102-D00019.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00020.TIF SYSTEM "US20030005073A1-20030102-D00020.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00021.TIF SYSTEM "US20030005073A1-20030102-D00021.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00022.TIF SYSTEM "US20030005073A1-20030102-D00022.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00023.TIF SYSTEM "US20030005073A1-20030102-D00023.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00024.TIF SYSTEM "US20030005073A1-20030102-D00024.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00025.TIF SYSTEM "US20030005073A1-20030102-D00025.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00026.TIF SYSTEM "US20030005073A1-20030102-D00026.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00027.TIF SYSTEM "US20030005073A1-20030102-D00027.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00028.TIF SYSTEM "US20030005073A1-20030102-D00028.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00029.TIF SYSTEM "US20030005073A1-20030102-D00029.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00030.TIF SYSTEM "US20030005073A1-20030102-D00030.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00031.TIF SYSTEM "US20030005073A1-20030102-D00031.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00032.TIF SYSTEM "US20030005073A1-20030102-D00032.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00033.TIF SYSTEM "US20030005073A1-20030102-D00033.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00034.TIF SYSTEM "US20030005073A1-20030102-D00034.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00035.TIF SYSTEM "US20030005073A1-20030102-D00035.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00036.TIF SYSTEM "US20030005073A1-20030102-D00036.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00037.TIF SYSTEM "US20030005073A1-20030102-D00037.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00038.TIF SYSTEM "US20030005073A1-20030102-D00038.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00039.TIF SYSTEM "US20030005073A1-20030102-D00039.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00040.TIF SYSTEM "US20030005073A1-20030102-D00040.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00041.TIF SYSTEM "US20030005073A1-20030102-D00041.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00042.TIF SYSTEM "US20030005073A1-20030102-D00042.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00043.TIF SYSTEM "US20030005073A1-20030102-D00043.TIF" NDATA TIF>
<!ENTITY US20030005073A1-20030102-D00044.TIF SYSTEM "US20030005073A1-20030102-D00044.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030005073</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10234482</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020905</filing-date>
</domestic-filing-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>8-337205</doc-number>
</priority-application-number>
<filing-date>19961217</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<foreign-priority-data>
<priority-application-number>
<doc-number>9-221617</doc-number>
</priority-application-number>
<filing-date>19970818</filing-date>
<country-code>JP</country-code>
</foreign-priority-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>G06F015/167</ipc>
</classification-ipc-primary>
<classification-ipc-secondary>
<ipc>G06F012/00</ipc>
</classification-ipc-secondary>
<classification-ipc-secondary>
<ipc>G06F015/76</ipc>
</classification-ipc-secondary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>709</class>
<subclass>213000</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>711</class>
<subclass>147000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>712</class>
<subclass>027000</subclass>
</uspc>
</classification-us-secondary>
<classification-us-secondary>
<uspc>
<class>712</class>
<subclass>029000</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>Signal processing device accessible as memory</title-of-invention>
</technical-information>
<continuity-data>
<division-of>
<parent-child>
<child>
<document-id>
<doc-number>10234482</doc-number>
<kind-code>A1</kind-code>
<document-date>20020905</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>08955089</doc-number>
<document-date>19971021</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>GRANTED</parent-status>
<parent-patent>
<document-id>
<doc-number>6470380</doc-number>
<country-code>US</country-code>
</document-id>
</parent-patent>
</parent-child>
</division-of>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Hideki</given-name>
<family-name>Yoshizawa</family-name>
</name>
<residence>
<residence-non-us>
<city>Kawasaki-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Toru</given-name>
<family-name>Tsuruta</family-name>
</name>
<residence>
<residence-non-us>
<city>Kawasaki-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Norichika</given-name>
<family-name>Kumamoto</family-name>
</name>
<residence>
<residence-non-us>
<city>Kawasaki-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Yuji</given-name>
<family-name>Nomura</family-name>
</name>
<residence>
<residence-non-us>
<city>Kawasaki-shi</city>
<country-code>JP</country-code>
</residence-non-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>Fujitsu Limited</organization-name>
<address>
<city>Kawasaki</city>
<country>
<country-code>JP</country-code>
</country>
</address>
<assignee-type>03</assignee-type>
</assignee>
<correspondence-address>
<name-1>STAAS &amp; HALSEY LLP</name-1>
<name-2></name-2>
<address>
<address-1>700 11TH STREET, NW</address-1>
<address-2>SUITE 500</address-2>
<city>WASHINGTON</city>
<state>DC</state>
<postalcode>20001</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A signal processing device is provided by connecting information processing units to each other using communication links and connecting the information processing units to each other and a host processor using an external bus. Parallel and pipe-line processing is accommodated by communication between the information processing units via the communication links and respective storage units of the information processing units and also by communication between the host processor and the information processing units via the external bus and the respective storage units. The host processor can communicate with the information processing units via the external bus through the respective storage units, the storage units being accessible as memory by the host processor. If each information processing unit is implemented on a single chip as an integrated circuit, the signal processing device can be incorporated in a computer in the same manner as conventional memory device are incorporated. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> 1. Field of the Invention </paragraph>
<paragraph id="P-0002" lvl="0"><number>&lsqb;0002&rsqb;</number> The present invention generally relates to data processing devices, and particularly relates to a signal processing accelerator which is incorporated into a personal computer to effect high-speed processing of multi-media data or the like. </paragraph>
<paragraph id="P-0003" lvl="0"><number>&lsqb;0003&rsqb;</number> 2. Description of the Related Art </paragraph>
<paragraph id="P-0004" lvl="0"><number>&lsqb;0004&rsqb;</number> Recent expansion in the number of application fields of data processing has resulted in an increasing demand for a device which can process a vast amount of data such as image and audio data at high speed. In particular, multi-media equipment is required to process image and audio data or the like at high speed in line with the display speed of moving pictures. </paragraph>
<paragraph id="P-0005" lvl="0"><number>&lsqb;0005&rsqb;</number> Multi-media equipment for high-speed data processing generally has a system configuration which incorporates a number of pieces of dedicated hardware for respective signal processing. When high-speed data processing is achieved through dedicated hardware, however, such a system has drawbacks in costs and lack of expandability and upgradability of the equipment. That is, costs are incurred with respect to design, development, and manufacture of dedicated hardware for respective signal processing, so that a resulting system incorporating the dedicated hardware becomes expensive. Further, dedicated hardware is designed for specific data processing, and, thus, is limited in use thereof because only limited types of processing is executable by such hardware. A problem of lack of expandability and upgradability thus arises when there is a need to apply the hardware to a new application field. </paragraph>
<paragraph id="P-0006" lvl="0"><number>&lsqb;0006&rsqb;</number> Recent enhancement in speed and performance of general-purpose processors has made it possible to use general-purpose processors for high-speed data processing. When compared with systems of dedicated hardware described above, systems employing such general-purpose processors are characterized in that software is used for achieving various signal processing functions. Such software-based systems for achieving various signal processing functions have advantages in that they are implemented at relatively low cost and have superior functional expandability when compared to the dedicated-hardware systems. </paragraph>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> However, software-based systems employing general-purpose processors have disadvantages as follows. </paragraph>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> First, since general-purpose processors in these software-bases systems are required to run operating systems (OSs), the general-purpose processors cannot be used exclusively for signal processing. Namely, since OS tasks need to be executed during the signal processing, it is difficult to sufficiently step up the signal processing speed. This poses a problem, especially, when real-time processing is required. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Second, general-purpose processors are designed for handling general data operations, but are not suitable for signal processing. Because of this, general-purpose processors cannot exhibit desirable performance in a field such as image processing where parallel data processing is preferred. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> Third, when data transfer is conducted via a bus between a general-purpose processor, memories, I/O ports, etc., an increase in bus access may result in access collisions between data transfer for the signal processing and data transfer for other processes such as OS tasks, thereby reducing the speed of data transfer. For example, when data is first transferred from an I/O port to a memory, then transferred many times between the memory and a general-purpose processor to carry out signal processing, and finally transferred from the memory to the I/O port, the frequency of bus access is quite high. In such a case, a decrease in data-transfer speed due to access collisions cannot be avoided. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The software-based signal processing systems employing general-purpose processors also have a problem in that a sufficient data processing speed cannot be achieved because of the three reasons identified above. This problem becomes particularly conspicuous when a plurality of signal processing operations need to be simultaneously carried out as required in multi-media signal processing. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> On the other hand, a system configuration which incorporates DSPs (digital signal processors) or the like specifically designed for signal processing can achieve processing of image and audio data at such a speed as to meet various requirements. Further, so-called multi-media-extended-instruction-set processors (e.g., P55C of the Intel corporation) are now available, and these processors are equipped with signal processing functions as extended instructions in addition to an original set of instructions. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> Such a system, however, incurs additional costs for design, development, and manufacture of dedicated hardware portions for signal processing. Also, bus collisions at a time of data transfer place a cap on the data processing speed as described above. Accordingly, this system cannot exhibit a desirable performance because of bus-access conflict between a plurality of signal processing operations particularly when such a plurality of signal processing operations need to be simultaneously carried out as in multi-media signal processing. </paragraph>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Accordingly, there is a need for an architecture of a signal processing accelerator which is incorporated into a personal computer or the like and can achieve a sufficient signal processing speed at a relatively low cost. </paragraph>
</section>
<section>
<heading lvl="1">SUMMARY OF THE INVENTION </heading>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> Accordingly, it is a general object of the present invention to provide a signal processing accelerator having an architecture which can satisfy the need described above. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> It is another and more specific object of the present invention to provide a signal processing accelerator having an architecture which is incorporated into a personal computer or the like and can achieve a sufficient signal processing speed at a relatively low cost. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> In order to achieve the aforementioned objects according to the present invention, a device for signal processing includes a plurality of information processing units and communication links connected between the information processing units. Each of the information processing units includes a signal processing unit for processing data, a communication control unit for communicating with other information processing units via the communication links, and a storage unit for storing data and programs executed by the signal processing unit. The storage unit is used for data exchange between each of the information processing units and an external bus. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> In the device described above, the plurality of information processing units can communicate with each other without using the external bus, so that high-speed signal processing is achieved by avoiding a reduction in data processing speed caused by bus conflict. Further, a plurality of processes such as image processing and audio processing can be allocated to different information processing units, so that this device is suited to multi-media signal processing which requires processing of a plurality of different signals. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> According to one aspect of the present invention, the storage unit includes a memory for storing the data and the programs and a memory control unit for controlling the memory such that the memory is accessible from the external bus when the data exchange is conducted. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> Accordingly, if the signal processing unit, the communication control unit, and the storage unit are implemented on a single chip as an integrated circuit, the device can be incorporated in a personal computer or the like in the same manner as conventional memory devices are incorporated. Because of this, costs for incorporating the above device can be included in the costs of the memory devices, and the device inserted into the memory devices can be utilized by using software. In this manner, costs of hardware extension can be reduced while providing a system having a functional expandability. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> According to another aspect of the present invention, the memory control unit includes a key-data storage unit for storing key information, and controls the memory such that the memory is accessible from the external bus only when data matching the key information is provided from the external bus. </paragraph>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> In the device described above, the memory of the storage unit is generally conditioned so as not to be accessible as a memory from the external bus, thereby preventing the operation system of a host processor from taking control of the memory for use as an OS memory space. Only when the keys are unlocked, will data exchange between the host processor and the information processing units become possible. </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> According to yet another aspect of the present invention, when a process is comprised of procedures which can be simultaneously carried out in parallel, the information processing units are operated in parallel, thereby achieving high-speed data processing. </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> According to yet another aspect of the present invention, when a process is comprised of procedures among which a given procedure requires results of another procedure and any procedure needs to be repeated, the information processing units are operated in a pipe-line manner such that all procedures are carried out at the same time by respective information processing units, thereby achieving high-speed data processing. </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> According to still another aspect of the present invention, when a host processor (CPU) generates an interruption upon fetching and decoding a particular instruction, the information processing units can serve as a virtual machine by executing this instruction on behalf of the host processor. This configuration allows the system to run a program as if the host processor executed such an instruction. </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> According to further aspect of the present invention, a first resource-management program and a second resource-management program are provided in an application interface layer and a device-driver layer, respectively, and control process allocation and data connection as well as hardware of the information processing units. Because of this configuration, data to be processed does not have to be brought all the way up to the uppermost application layer where user programs and application programs reside, so that efficient processing is carried out with regard to data transfer. </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> Other objects and further features of the present invention will be apparent from the following detailed description when read in conjunction with the accompanying drawings.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram of a signal processing accelerator according to the present invention; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is an illustrative drawing showing software architecture corresponding to the hardware architecture of the signal processing accelerator shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is an illustrative drawing showing resource allocation of the signal processing accelerator under the control of the resource-management programs shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>; </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 4A through 4C</cross-reference> are illustrative drawings showing examples of connections between processor elements; </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 5A and 5B</cross-reference> are illustrative drawings showing two different allocations of processes; </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a flowchart of a main routine of a dynamic-process-allocation algorithm according to the present invention; </paragraph>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flowchart of step S<highlight><bold>3</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, where one processor element is allocated to a process; </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flowchart of step S<highlight><bold>4</bold></highlight> as shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, where a plurality of processor elements are allocated to a process; </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a flowchart of calculation of an allocation efficiency for a next allocation which is conducted at the step S<highlight><bold>14</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 7</cross-reference> as well as at the step S<highlight><bold>28</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 8</cross-reference>; </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10A</cross-reference> is a table chart showing results obtained when the dynamic-process-allocation algorithm is used; </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10B</cross-reference> is a table chart showing results obtained when a simple allocation algorithm is used; </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11A</cross-reference> is a table chart showing simulation conditions; </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11B</cross-reference> is a table chart showing simulation results; </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is an illustrative drawing showing a memory space into which the DRAM of the signal processing accelerator of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is incorporated when the resource-management program controls the processor elements to carry out data processing; </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is an illustrative drawing showing address conversion between a host processor and the signal processing accelerator; </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a block diagram of a detailed configuration of the DRAM controller of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is an illustrative drawing showing state transitions of an information processing unit of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>; </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is an illustrative drawing showing a mechanism for executing virtual-machine codes according to the present invention; </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a flowchart of exceptional handling by the signal processing accelerator for emulation; </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a block diagram showing a switching mechanism which switches, between a client processor and a memory when the client processor and the memory are connected to a host processor via a memory interface; </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is a circuit diagram of an address-check means of <cross-reference target="DRAWINGS">FIG. 18</cross-reference> which activates an output thereof when a particular address in a memory space is provided; </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is a circuit diagram of the address-check means of <cross-reference target="DRAWINGS">FIG. 18</cross-reference> which activates an output thereof when an address within a particular memory-space range is provided; </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> is an illustrative drawing schematically showing a change of bit positions in a bit arrangement; </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 22A</cross-reference> is an illustrative drawing showing a relation between a data word and sub-words; </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 22B</cross-reference> is an illustrative drawing showing a key code (key information); </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> is a flowchart of a process of generating data words in which each sub-word is comprised of a key code; </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 24</cross-reference> is a flowchart of a process of reading data words in which each sub-word is comprised of a key code, and extracting the key code from the data words; </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 25A and 25B</cross-reference> are illustrative drawings for explaining a key comparison which is made by using a time data series to avoid an effect of the shuffling of bit positions; </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 26</cross-reference> is a flowchart of a process of generating data based on a key code so that the data has each bit thereof representing one bit of the key code in a time order; </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 27</cross-reference> is a flowchart of a process of extracting a key code from data that is read; </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 28</cross-reference> is an illustrative drawing for explaining a key comparison which is made based on the number of 0s or 1s so as to nullify the effect of the bit-position shuffling; </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 29</cross-reference> is a flowchart of a process of counting the number of is included in each data word when a plurality of data words are provided; </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 30</cross-reference> is a flowchart of a process of generating a plurality of data words such that the number of is included in a given data word is equal to a number that is represented by a corresponding input data word when a plurality of input data words are supplied; </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 31</cross-reference> is a flowchart of a variation of the switching process based on a key comparison; </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 32</cross-reference> is a flowchart of another variation of the switching process based on a key comparison; </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 33</cross-reference> is an illustrative drawing for explaining a pattern-check process in which parity is used as a predetermined pattern; </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 34</cross-reference> is a flowchart of a process of checking supplied data with regard to parity thereof; </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 35</cross-reference> is an illustrative drawing for explaining a process of making a pattern check using a predetermined set of bits included in data; </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 36</cross-reference> is a flowchart of a method of extracting a predetermined set of bits from supplied data and using the predetermined set for pattern check; </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 37</cross-reference> is an illustrative drawing for explaining a pattern-check process which is performed based on whether a supplied data word is comprised of a predetermined pattern; </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 38</cross-reference> is a flowchart of a process of checking whether a supplied data word is comprised of 0s or comprised of 1s; </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 39</cross-reference> is a flowchart of a process of acquiring a memory area by means of OS (operating system) functions of a host processor; </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 40</cross-reference> is a block diagram of a system in which control of allocating memory areas and control of switching applications are carried out independently from each other; </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 41</cross-reference> is a flowchart showing an example of a process of controlling memory allocation and switching applications in the system of <cross-reference target="DRAWINGS">FIG. 40</cross-reference>; </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 42</cross-reference> is a block diagram of a system in, which synchronization is established between client processors or between the host processor and a client processor; </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 43A and 43B</cross-reference> are charts showing an example of synchronized operations between a host processor and a client processor; and </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 44A and 44B</cross-reference> are charts showing an example of synchronized operations between client processors.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS </heading>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> In the following, embodiments of the present invention will be described with reference to the accompanying drawings. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is a block diagram of a signal processing accelerator according to the present invention. The signal processing accelerator of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> includes a plurality of information processing units <highlight><bold>10</bold></highlight> which are identical to each other. Each of the information processing units <highlight><bold>10</bold></highlight> is connected with each other, and, also, is connected to a host memory bus <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> The information processing unit <highlight><bold>10</bold></highlight> includes a signal processing processor <highlight><bold>11</bold></highlight>, an instruction cache <highlight><bold>12</bold></highlight>, a data RAM <highlight><bold>13</bold></highlight>, link-control units <highlight><bold>14</bold></highlight> and <highlight><bold>15</bold></highlight>, a main cache <highlight><bold>16</bold></highlight>, a link cache <highlight><bold>17</bold></highlight>, a DRAM <highlight><bold>18</bold></highlight>, and a DRAM controller <highlight><bold>19</bold></highlight>. The signal processing processor <highlight><bold>11</bold></highlight>, the instruction cache <highlight><bold>12</bold></highlight>, and the data RAM <highlight><bold>13</bold></highlight> together make up a signal processing unit <highlight><bold>25</bold></highlight>. The link-control units <highlight><bold>14</bold></highlight> and <highlight><bold>15</bold></highlight>, the main cache <highlight><bold>16</bold></highlight>, and the link cache <highlight><bold>17</bold></highlight> together form a communication-control unit <highlight><bold>26</bold></highlight>. </paragraph>
<paragraph id="P-0078" lvl="0"><number>&lsqb;0078&rsqb;</number> A communication link <highlight><bold>20</bold></highlight> is connected to each of the link-control units, <highlight><bold>14</bold></highlight> and <highlight><bold>15</bold></highlight>. The information processing units <highlight><bold>10</bold></highlight> are connected in series via the communication links <highlight><bold>20</bold></highlight> so that each information processing unit <highlight><bold>10</bold></highlight> can directly communicate with adjacent information processing units <highlight><bold>10</bold></highlight> via the communication links <highlight><bold>20</bold></highlight>. Communication between two information processing units <highlight><bold>10</bold></highlight> which are spaced apart from each other can be effected by successively propagating communication data through intervening information processing units <highlight><bold>10</bold></highlight> from a given unit to the next unit. <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows three information processing units <highlight><bold>10</bold></highlight> as an example, but any number of information processing units <highlight><bold>10</bold></highlight> can be provided. Each of the information processing units <highlight><bold>10</bold></highlight> is connected to the host memory bus <highlight><bold>30</bold></highlight> via the DRAM controller <highlight><bold>19</bold></highlight>. A host processor <highlight><bold>31</bold></highlight> is connected to the host memory bus <highlight><bold>30</bold></highlight>. </paragraph>
<paragraph id="P-0079" lvl="0"><number>&lsqb;0079&rsqb;</number> The signal processing processor <highlight><bold>11</bold></highlight> carries out signal processing functions. The instruction cache <highlight><bold>12</bold></highlight> is a cache memory for storing instructions which are frequently used by the signal processing processor <highlight><bold>11</bold></highlight>. Programs carried out by the signal processing processor <highlight><bold>11</bold></highlight> are stored in the DRAM <highlight><bold>18</bold></highlight> in addition to the instruction cache <highlight><bold>12</bold></highlight>. The data RAM <highlight><bold>13</bold></highlight> is used as a memory work area for saving intermediate results or the like obtained while the signal processing processor <highlight><bold>11</bold></highlight> attends to data processing. </paragraph>
<paragraph id="P-0080" lvl="0"><number>&lsqb;0080&rsqb;</number> The main cache <highlight><bold>16</bold></highlight> and the link cache <highlight><bold>17</bold></highlight> are cache memories for storing data which is processed by the signal processing processor <highlight><bold>11</bold></highlight>. The main cache <highlight><bold>16</bold></highlight> stores data which is extracted from the DRAM <highlight><bold>18</bold></highlight> of the same information processing unit <highlight><bold>10</bold></highlight>, whereas the link cache <highlight><bold>17</bold></highlight> holds data which is transferred from other information processing units <highlight><bold>10</bold></highlight> via the link-control units <highlight><bold>14</bold></highlight> and <highlight><bold>15</bold></highlight>. Even when the data stored in the main cache <highlight><bold>16</bold></highlight> is swapped out, the same data can be retrieved from the DRAM <highlight><bold>18</bold></highlight> of the same information processing unit <highlight><bold>10</bold></highlight> when it becomes necessary. On the other hand, if the data in the link cache <highlight><bold>17</bold></highlight> is swapped out, the same data has to be brought in from other information processing units <highlight><bold>10</bold></highlight> via the communication links <highlight><bold>20</bold></highlight>. If the main cache <highlight><bold>16</bold></highlight> and the link cache <highlight><bold>17</bold></highlight> are structured as one and the same cache memory, a problem may arise in that data transferred from another information processing unit <highlight><bold>10</bold></highlight> may be swapped out despite a heavy communication load in order to secure storage of data extracted from the DRAM <highlight><bold>18</bold></highlight> of the same information processing unit <highlight><bold>10</bold></highlight>. Because of this, the main cache <highlight><bold>16</bold></highlight> and the link cache <highlight><bold>17</bold></highlight> are provided as separate cache memories in accordance with different functions thereof. </paragraph>
<paragraph id="P-0081" lvl="0"><number>&lsqb;0081&rsqb;</number> The information processing unit <highlight><bold>10</bold></highlight> is connected to the host memory bus <highlight><bold>30</bold></highlight> via the DRAM controller <highlight><bold>19</bold></highlight>, which includes the DRAM <highlight><bold>18</bold></highlight>. Memory space of the DRAM <highlight><bold>18</bold></highlight> is controlled by the DRAM controller <highlight><bold>19</bold></highlight>, and is allocated to physical address space controlled by the host processor <highlight><bold>31</bold></highlight>. By using physical addresses allocated to the DRAM <highlight><bold>18</bold></highlight>, the host processor <highlight><bold>31</bold></highlight> can exchange data with the information processing unit <highlight><bold>10</bold></highlight>. Namely, the host processor <highlight><bold>31</bold></highlight> accesses the DRAM <highlight><bold>18</bold></highlight> via the host memory bus <highlight><bold>30</bold></highlight>, and writes data and programs in the DRAM <highlight><bold>18</bold></highlight>. The information processing unit <highlight><bold>10</bold></highlight> uses the data stored in the DRAM <highlight><bold>18</bold></highlight> as input data, and executes the programs in the DRAM <highlight><bold>18</bold></highlight> so as to carry out required data processing. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> During the data processing, the plurality of information processing units <highlight><bold>10</bold></highlight> carry out parallel processing or pipe-line processing by communicating with each other. For example, some of the information processing units <highlight><bold>10</bold></highlight> may perform parallel image-data processing, while other information processing units <highlight><bold>10</bold></highlight> carry out parallel audio-data processing. As previously described, communications between the plurality of information processing units <highlight><bold>10</bold></highlight> are conducted via the communication links <highlight><bold>20</bold></highlight>. Because of these dedicated communication links, the host memory bus <highlight><bold>30</bold></highlight> can provide a data-transfer route for other processes such as OS processes of the host processor <highlight><bold>31</bold></highlight> without paying attention to the communications between the information processing units <highlight><bold>10</bold></highlight>. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> Each of the information processing units <highlight><bold>10</bold></highlight> stores processed data in the DRAM <highlight><bold>18</bold></highlight>. The host processor <highlight><bold>31</bold></highlight> accesses the DRAM <highlight><bold>18</bold></highlight> via the host memory bus <highlight><bold>30</bold></highlight> so as to read the processed data from the DRAM <highlight><bold>18</bold></highlight>. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> The signal processing accelerator of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> includes the plurality of information processing units <highlight><bold>10</bold></highlight> which can communicate with each other without using the host memory bus <highlight><bold>30</bold></highlight> to carry out parallel processing, so that high-speed signal processing is achieved without suffering a decrease in data processing speed which would be caused by bus-access conflict. Further, each of the information processing units <highlight><bold>10</bold></highlight> may be assigned to each of a plurality of processes in image processing and/or audio processing, so that the signal processing accelerator of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is suitable for multi-media signal processing since such processing requires simultaneous processing of different signals. </paragraph>
<paragraph id="P-0085" lvl="0"><number>&lsqb;0085&rsqb;</number> Moreover, the signal processing unit <highlight><bold>25</bold></highlight> (i.e., the signal processing processor <highlight><bold>11</bold></highlight>, the instruction cache <highlight><bold>12</bold></highlight>, and the data RAM <highlight><bold>13</bold></highlight>), the communication-control unit <highlight><bold>26</bold></highlight> (i.e., the main cache <highlight><bold>16</bold></highlight>, the link cache <highlight><bold>17</bold></highlight>, and the link-control units <highlight><bold>14</bold></highlight> and <highlight><bold>15</bold></highlight>), and the memory (i.e., the DRAM <highlight><bold>18</bold></highlight> and the DRAM controller <highlight><bold>19</bold></highlight>) may be implemented as an integrated circuit on one chip. In this manner, the signal processing accelerator of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> can be incorporated into a personal computer in the same manner as prior-art memory devices are incorporated. Because of this, costs for incorporating the signal processing accelerator can be included into the costs of the memory devices, and the signal processing accelerator inserted in the memory devices can be utilized by using software. In this manner, costs of hardware extension can be reduced while providing a system having a functional expandability. </paragraph>
<paragraph id="P-0086" lvl="0"><number>&lsqb;0086&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> is an illustrative drawing showing a software architecture corresponding to the hardware architecture of the signal processing accelerator shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. </paragraph>
<paragraph id="P-0087" lvl="0"><number>&lsqb;0087&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows a hierarchy of software structure with regard to a personal computer by superimposing a software structure of the present invention on that of the prior art. In the prior art, a hierarchical structure of software includes an application layer, an API (application interface) layer, and a device-driver layer. The application layer includes user programs and application programs such as Windows application programs. The API layer includes programs such as dynamic loading libraries which are dynamically loaded at a time of process execution. The device-driver layer includes device drivers for controlling hardware of various devices. In <cross-reference target="DRAWINGS">FIG. 2</cross-reference>, the API layer includes three dynamic loading libraries XX.API, YY.API, and ZZ.API. Each of these library programs operates device hardware XX, YY, and ZZ, respectively, by using device drivers XX.VxD, YY.VxD, and ZZ.VxD, respectively, located in the device-driver layer. The device hardware XX, YY, and ZZ include a hard drive, a display, a memory, a DSP, etc. </paragraph>
<paragraph id="P-0088" lvl="0"><number>&lsqb;0088&rsqb;</number> The software architecture of the present invention includes a dynamic loading library RMI.API in the API layer for operating the signal processing accelerator of the present invention, and further includes a device driver RMI.VxD in the device-driver layer for controlling the signal processing accelerator. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> RMI.API is a dynamic loading library for carrying out processes such as allocation of resources (the information processing units <highlight><bold>10</bold></highlight>) provided in the signal processing accelerator, and is communicable with other dynamic loading libraries of the prior art. The layer which includes RMI.API can be regarded as the API layer as in the prior art. Since this layer serves as a venue in which RMI.API communicates with other dynamic loading libraries, however, this layer is also referred to as an RMI-API-association layer when discussing some features of the present invention. </paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> RMI.VxD is a device driver for controlling the hardware of the signal processing accelerator, and can exchange data with other prior-art device drivers. The layer which includes RMI.VxD can be regarded as the device-driver layer as in the prior art. Since this layer serves as a venue in which RMI.VxD communicates with other device drivers, however, this layer is also referred to as an driver-association layer when discussing some features of the present invention. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> The RMI.VxD controls resources (the information processing units <highlight><bold>10</bold></highlight>) of the hardware, but processes closer to the user-application level such as allocation of resources are carried out by RMI.API. Since functional differences between RMI.API and RMI.VxD are not so distinctive as to provide a clear boundary, the RMI-API-association layer and the driver-association layer are collectively referred to as a resource-management layer in the present invention. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> Drawbacks of the prior-art software architecture will be illustrated below by taking an example in which an application program applies data processing using the device YY to data stored in the device XX, and outputs processed data to the device ZZ. In this example, the data is brought to the application layer from the device XX via XX.VxD and XX.API in the hierarchy of the software structure shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. Then, the data is supplied to the device YY via YY.API and YY.VxD. After processing of the data, processed data is brought up to the application layer again, and, finally, is provided to the device ZZ via ZZ.API and ZZ.VxD. Moving the data back and forth between the device hardware and the uppermost layer of the software hierarchy corresponds to repeated data transfer via a bus between respective hardware devices. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> In the software architecture of the present invention, when an application program makes a request for processing of data using the signal processing accelerator and outputting of processed data to the device ZZ, RMI.VxD in the resource-management layer receives data from the device driver XX.VxD, and uses the signal processing accelerator for processing of the data before supplying the processed data to the device driver ZZ.VxD. In this manner, there is no need to bring up data all the way to the uppermost layer of the software hierarchy. This is equivalent to reducing the number of bus accesses to a minimum level when data transfer via a bus is taken into consideration. </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> In multi-media data processing in which a plurality of processes need to be simultaneously carried out as in image-data processing and audio-data processing, the hierarchical software structure of the prior art suffers an increasing number of data transfers between the uppermost application layer and a plurality of devices as the number of processes increases. On the other hand, the hierarchical software structure of the present invention is provided with the resource-management layer which controls the signal processing accelerator to carry out a plurality of processes simultaneously, so that there is no need to bring data all the way up to the uppermost application layer, thereby achieving effective processing in terms of data transfer. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> is an illustrative drawing showing resource allocation of the signal processing accelerator under the control of the resource-management programs (RMI.API and RMI.VxD) in the resource-management layer. As previously described, RMI.API mainly controls resource allocation while RMI.VxD controls hardware in actual data processing. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 3, a</cross-reference> resource-management program RMI controls a plurality of PEs (processor elements) <highlight><bold>40</bold></highlight>. Each of the PEs <highlight><bold>40</bold></highlight> corresponds to a respective one of the signal processing processors <highlight><bold>11</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, and conceptually represents a data processing function of the signal processing processor <highlight><bold>11</bold></highlight>. An input channel <highlight><bold>41</bold></highlight> is a pointer pointing to the device driver XX.VxD, and an output channel <highlight><bold>42</bold></highlight> is a pointer pointing to the device driver ZZ.VxD. In this manner, the resource-management program RMI receives data from the device driver XX.VxD, and uses the plurality of the PEs <highlight><bold>40</bold></highlight> for processing the data before outputting the processed data to the device driver ZZ.VxD. If input and output device drivers are different from those of this example, reference destinations by the input channel <highlight><bold>41</bold></highlight> and the output channel <highlight><bold>42</bold></highlight> are changed. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> The resource-management program RMI receives from a user program a pointer pointing to an input-data origin, a pointer pointing to an output-data destination, information on execution programs which are to be executed by the PEs <highlight><bold>40</bold></highlight>, and information about how to connect the PEs <highlight><bold>40</bold></highlight>. The execution programs to be executed by the PEs <highlight><bold>40</bold></highlight> are written specifically for the signal processing accelerator of <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, and each of the execution programs may be a program module executed by the respective PEs <highlight><bold>40</bold></highlight>, which serves as a processing element. In this case, the number of execution programs is the same as the number of the PEs <highlight><bold>40</bold></highlight> to be used. The user program loads the dynamic loading library RMI.API first, and, then, specifies the input-data origin, the output-data destination, names of the execution programs, and connections between the execution programs. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> The resource-management program RMI selects a required number of PEs <highlight><bold>40</bold></highlight> from available PEs <highlight><bold>40</bold></highlight> stored in a free-resource stack <highlight><bold>43</bold></highlight>, and allocates the selected PEs <highlight><bold>40</bold></highlight> to respective processing of the execution programs. Further, the resource-management program RMI arranges the input channel <highlight><bold>41</bold></highlight>, the allocated PEs <highlight><bold>40</bold></highlight>, and the output channel <highlight><bold>42</bold></highlight> so as to establish a connection for data processing between the device driver XX.VxD pointed to by the input channel <highlight><bold>41</bold></highlight> and the device driver ZZ.VxD pointed to by the output channel <highlight><bold>42</bold></highlight>. After the data processing, the resource-management program RMI releases the allocated PEs <highlight><bold>40</bold></highlight>, and stores them in the free-resource stack <highlight><bold>43</bold></highlight>. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> When an execution of a process is requested during an execution of another process, the resource-management program RMI selects a requested number of PEs <highlight><bold>40</bold></highlight> from available PEs <highlight><bold>40</bold></highlight> stored in the free-resource stack <highlight><bold>43</bold></highlight>, and allocates the selected PEs <highlight><bold>40</bold></highlight> to the new process. Control following the allocation is the same as before. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 4A through 4C</cross-reference> are illustrative drawings showing examples of connections between the PEs <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> shows a configuration in which the PEs <highlight><bold>40</bold></highlight> are arranged in series to carry out pipe-line processing. In computation of computer graphics, for example, various data processing operations are involved, including geometric transformation computation which divides objects into polygons and obtains vertex coordinates, colors, reflection indexes, etc., rasterizing computation which scans interiors of the polygons after dividing the interiors into scan lines, texture mapping computation which maps texture onto pixels on each scan line, and Z-buffer computation which carries out hidden-surface processing based on a distance of each pixel from the viewpoint. In this example, the PEs <highlight><bold>40</bold></highlight> arranged in series as shown in <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> are each allocated to the geometric transformation computation, the rasterizing computation, the texture mapping computation, and the Z-buffer computation so as to achieve high-speed processing through a pipe-line operation of these computations. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> shows a configuration in which the PEs <highlight><bold>40</bold></highlight> are arranged in parallel to perform parallel processing. In image processing, for example, a Laplacian filter is often applied to an image in order to enhance edges. In such a case, a filtering operation needs to be conducted at each position within the image. The configuration of <cross-reference target="DRAWINGS">FIG. 4B</cross-reference> may be applied to this case by dividing the image into a plurality of small portions and allocating the PEs <highlight><bold>40</bold></highlight> to filtering operations of respective portions. In this manner, the filtering operation in its entirety can be carried out in parallel, thereby achieving high-speed processing. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> The pipe-line operation by a series connection as shown in <cross-reference target="DRAWINGS">FIG. 4A</cross-reference> can be combined with the parallel processing by a parallel connection as shown in <cross-reference target="DRAWINGS">FIG. 4B</cross-reference>. <cross-reference target="DRAWINGS">FIG. 4C</cross-reference> shows an example of connections of the PEs <highlight><bold>40</bold></highlight> which combines the series connection and the parallel connection. When two images are matched with each other, for example, products of pixel values between the two images are obtained with respect to each pixel, and, then, a sum of the products is calculated. In such a case, PEs <highlight><bold>40</bold></highlight> arranged in parallel may be used for calculating products of pixel values at a plurality of portions within the image frame, and a PE <highlight><bold>40</bold></highlight> connected in series with these PEs <highlight><bold>40</bold></highlight> may be used for obtaining the sum of the products. In this manner, high-speed processing is achieved. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 3</cross-reference>, the resource-management program RMI in the resource-management layer controls the resource allocation of the signal processing accelerator. Performance of the system will be greatly affected by how PEs <highlight><bold>40</bold></highlight> (free resources) are allocated to respective programs. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> For example, assume that the signal processing accelerator is comprised of four information processing units <highlight><bold>10</bold></highlight> (i.e., four PEs <highlight><bold>40</bold></highlight>). Further, assume that a process includes two procedures, and each procedure is carried out by a single PE <highlight><bold>40</bold></highlight>. The amount of data transfer between two PEs <highlight><bold>40</bold></highlight> in operation is denoted as M. In a description given below, two such processes are carried out by allocating the four PEs <highlight><bold>40</bold></highlight>. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 5A and 5B</cross-reference> are illustrative drawings showing two different allocations of processes. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 5A, a</cross-reference> process <highlight><bold>1</bold></highlight> is allocated to processor elements PE<highlight><bold>1</bold></highlight> and PE<highlight><bold>3</bold></highlight>, and a process <highlight><bold>2</bold></highlight> is allocated to processor elements PE<highlight><bold>2</bold></highlight> and PE<highlight><bold>4</bold></highlight>. Since the amount of data transfer between two PEs allocated to the same process is M, M data transfer is conducted between PE<highlight><bold>1</bold></highlight> and PE<highlight><bold>3</bold></highlight> via PE<highlight><bold>2</bold></highlight>. By the same token, M data transfer is present between PE<highlight><bold>2</bold></highlight> and PE<highlight><bold>4</bold></highlight> via PE<highlight><bold>3</bold></highlight>. Therefore, the amount of data transfer is M between PE<highlight><bold>1</bold></highlight> and PE<highlight><bold>2</bold></highlight>, is 2M between PE<highlight><bold>2</bold></highlight> and PE<highlight><bold>3</bold></highlight>, and is M between PE<highlight><bold>3</bold></highlight> and PE<highlight><bold>4</bold></highlight>. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 5</cross-reference>B, the process <highlight><bold>1</bold></highlight> is allocated to the processor elements PE<highlight><bold>1</bold></highlight> and PE<highlight><bold>2</bold></highlight>, and the process <highlight><bold>2</bold></highlight> is allocated to processor elements PE<highlight><bold>3</bold></highlight> and PE<highlight><bold>4</bold></highlight>. In this case, the amount of data transfer is M between PE<highlight><bold>1</bold></highlight> and PE<highlight><bold>2</bold></highlight> as well as between PE<highlight><bold>3</bold></highlight> and PE<highlight><bold>4</bold></highlight>. No data transfer is present between PE<highlight><bold>2</bold></highlight> and PE<highlight><bold>3</bold></highlight>. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> If the capacity of data transfer through a link connecting adjacent PEs is 1.5 Mbit/sec, for example, the configuration of <cross-reference target="DRAWINGS">FIG. 5A</cross-reference> cannot allow both processes to run at the same time. On the other hand, the configuration of <cross-reference target="DRAWINGS">FIG. 5B</cross-reference> achieves simultaneous computation of both processes. In this manner, the way in which the processes are allocated determines the amount of data transfer on each link, creating one case in which simultaneous computation is possible and the other case in which simultaneous computation is impossible. When simultaneous computation is impossible, data processing speed as a whole is bound to decrease. How many PEs <highlight><bold>40</bold></highlight> are requested at what timing is totally unknown before the request is actually made, so that allocation of the PEs <highlight><bold>40</bold></highlight> should be dynamically handled. Because of this, there is a need for an efficient dynamic-process-allocation algorithm. </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> In the following, a dynamic-process-allocation algorithm according to the present invention will be described. This dynamic-process-allocation algorithm allocates resources according to two criteria. The first criterion requires that data transfer of an allocated process causes the least interference possible to other data transfers. The second criterion requires that a next process can be allocated to cause the least interference possible to other data transfers after the allocation of a current process. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> First, various amounts of data transfers on transfer links which result from allocation of a given process are estimated, and a maximum amount of data transfer is identified. This maximum amount is obtained with respect to each different pattern of allocation. Then, an allocation pattern which minimizes this maximum amount is selected. This is a selection of an allocation pattern according to the first criterion. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> It is likely that a plurality of allocation patterns are selected according to the first criterion. The second criterion is used to select one of the allocation patterns such that allocation of a next process will suffer the least interference possible as a result of the allocation of the current process. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> is a flowchart of a main routine of the dynamic-process-allocation algorithm. As shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>, this algorithm obtains an optimum allocation in a different manner between an allocation of one PE and an allocation of a plurality of PEs. When use of only one PE is requested, no data transfer will result from the allocation of a pertinent process, so that influence on the next process allocation should only be taken into consideration. On the other hand, when a plurality of PEs are requested, data transfer should be conducted via communication links, so that efficiency of the current process varies depending on the way in which the process is allocated to the PEs. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> At a step S<highlight><bold>1</bold></highlight> in <cross-reference target="DRAWINGS">FIG. 6, a</cross-reference> check is made as to how many PEs are available as free resources. If there is no available PE, the procedure ends. Otherwise, the procedure goes to a step S<highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> At the step S<highlight><bold>2</bold></highlight>, a check is made whether the number of requested PEs is one. If it is one, the procedure goes to a step S<highlight><bold>3</bold></highlight>. Otherwise, the procedure goes to a step S<highlight><bold>4</bold></highlight>. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> At the step S<highlight><bold>3</bold></highlight>, one PE is allocated to the process. If the allocation fails, the procedure ends. Otherwise, the procedure goes to a step S<highlight><bold>5</bold></highlight>. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> At the step S<highlight><bold>4</bold></highlight>, a plurality of PEs are allocated to the process. If the allocation fails, the procedure ends. Otherwise, the procedure goes to the step S<highlight><bold>5</bold></highlight>. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> At the step S<highlight><bold>5</bold></highlight>, a process ID is updated. Namely, a new process ID is assigned to the newly allocated process. This ends the procedure. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference> is a flowchart of the step S<highlight><bold>3</bold></highlight> shown-in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> where one PE is allocated to the process. </paragraph>
<paragraph id="P-0120" lvl="0"><number>&lsqb;0120&rsqb;</number> At a step S<highlight><bold>1</bold></highlight>, a search is made for available PEs. </paragraph>
<paragraph id="P-0121" lvl="0"><number>&lsqb;0121&rsqb;</number> At a step S<highlight><bold>12</bold></highlight>, a loop is introduced to all the available PEs. Namely, the following steps are successively carried out for each of the available PEs. </paragraph>
<paragraph id="P-0122" lvl="0"><number>&lsqb;0122&rsqb;</number> At a step S<highlight><bold>13</bold></highlight>, one PE is tentatively allocated to the process. </paragraph>
<paragraph id="P-0123" lvl="0"><number>&lsqb;0123&rsqb;</number> At a step S<highlight><bold>14</bold></highlight>, an allocation efficiency for a next allocation is calculated. The calculation of the allocation efficiency will be described later. A resulting value of the calculation is hereinafter denoted as RESULT. </paragraph>
<paragraph id="P-0124" lvl="0"><number>&lsqb;0124&rsqb;</number> At a step S<highlight><bold>15</bold></highlight>, a minimum value of RESULT is held. That is, if RESULT of the current tentative allocation is smaller than a stored value of RESULT, the stored value is replaced by the newly obtained RESULT. </paragraph>
<paragraph id="P-0125" lvl="0"><number>&lsqb;0125&rsqb;</number> At a step S<highlight><bold>16</bold></highlight>, the loop is ended. </paragraph>
<paragraph id="P-0126" lvl="0"><number>&lsqb;0126&rsqb;</number> At a step S<highlight><bold>17</bold></highlight>, the PE which brought about the minimum value of RESULT is allocated to the process. This ends the procedure. </paragraph>
<paragraph id="P-0127" lvl="0"><number>&lsqb;0127&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a flowchart of the step S<highlight><bold>4</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 6</cross-reference> where a plurality of PEs are allocated to the process. </paragraph>
<paragraph id="P-0128" lvl="0"><number>&lsqb;0128&rsqb;</number> At a step S<highlight><bold>21</bold></highlight>, a search is made for available PEs. </paragraph>
<paragraph id="P-0129" lvl="0"><number>&lsqb;0129&rsqb;</number> At a step S<highlight><bold>22</bold></highlight>, a first loop is introduced to all combinations of the requested number of available PEs. Namely, the following steps are successively carried out for each of the combinations formed by the requested number of available PEs. </paragraph>
<paragraph id="P-0130" lvl="0"><number>&lsqb;0130&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>, the amount of data transfer is calculated with respect to each communication link by assuming that the process is allocated to a current combination of PEs. </paragraph>
<paragraph id="P-0131" lvl="0"><number>&lsqb;0131&rsqb;</number> At a step S<highlight><bold>24</bold></highlight>, a combination of PEs which minimizes a maximum amount of data transfer is held. </paragraph>
<paragraph id="P-0132" lvl="0"><number>&lsqb;0132&rsqb;</number> At a step S<highlight><bold>25</bold></highlight>, the first loop is ended. </paragraph>
<paragraph id="P-0133" lvl="0"><number>&lsqb;0133&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>, a second loop is introduced to all the selected combinations which equally minimize the maximum amount of data transfer. </paragraph>
<paragraph id="P-0134" lvl="0"><number>&lsqb;0134&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>, a plurality of PEs are tentatively allocated to the process according to one of the selected combinations. </paragraph>
<paragraph id="P-0135" lvl="0"><number>&lsqb;0135&rsqb;</number> At a step S<highlight><bold>28</bold></highlight>, the allocation efficiency for a next allocation is calculated. The calculation of the allocation efficiency will be described later. A resulting value of the calculation is denoted as RESULT. </paragraph>
<paragraph id="P-0136" lvl="0"><number>&lsqb;0136&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>, a minimum value of RESULT is held. That is, if RESULT of the current tentative allocation is smaller than a stored value of RESULT, the stored value is replaced by the newly obtained RESULT. </paragraph>
<paragraph id="P-0137" lvl="0"><number>&lsqb;0137&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>, the second loop is ended. </paragraph>
<paragraph id="P-0138" lvl="0"><number>&lsqb;0138&rsqb;</number> At a step S<highlight><bold>31</bold></highlight>, a combination of PEs which brought about the minimum value of RESULT is actually allocated to the process. This ends the procedure. </paragraph>
<paragraph id="P-0139" lvl="0"><number>&lsqb;0139&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a flowchart of the calculation of the allocation efficiency for a next allocation which is conducted at the step S<highlight><bold>14</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 7</cross-reference> as well as at the step S<highlight><bold>28</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 8</cross-reference>. </paragraph>
<paragraph id="P-0140" lvl="0"><number>&lsqb;0140&rsqb;</number> At a step S<highlight><bold>41</bold></highlight>, the leftmost PE is selected from all the available PEs, and is denoted as PE_L. </paragraph>
<paragraph id="P-0141" lvl="0"><number>&lsqb;0141&rsqb;</number> At a step S<highlight><bold>42</bold></highlight>, the rightmost PE is selected from all the available PEs, and is denoted as PE_R. </paragraph>
<paragraph id="P-0142" lvl="0"><number>&lsqb;0142&rsqb;</number> At a step S<highlight><bold>43</bold></highlight>, the number of communication links intervening between PE_L and PE_R is counted, and the obtained number is provided as RESULT. This ends the procedure. </paragraph>
<paragraph id="P-0143" lvl="0"><number>&lsqb;0143&rsqb;</number> As described above, the flowchart of <cross-reference target="DRAWINGS">FIG. 9</cross-reference> selects the leftmost PE and the rightmost PE, and counts the number of intervening communication links. The number of intervening communication links is used here as a measure to indicate the allocation efficiency for a next process. One may appreciate ramifications of use of this measure from the following description. If the number of intervening communication links is small, this indicates that all the available PEs exist in a small pack. If the number of intervening communication links is large, on the other hand, this means that the available PEs are spread over a wide range along the extension of communication links. If the process is allocated to PEs packed in a narrow range, the number of intervening PEs between the allocated PEs should be relatively small, so that the maximum amount of data transfer after the allocation is likely to be small. If the process is allocated to PEs spread over a wide range, the number of intervening PEs is relatively large so that the data transfer for the allocated process is more likely to interfere with other data transfers. In this case, thus, the maximum amount of data transfer after the allocation is likely to be large. In this manner, the flowchart of <cross-reference target="DRAWINGS">FIG. 9</cross-reference> provides a criterion indicating to what extent the available PEs remaining after a process allocation are packed in a narrow range. That is, this criterion indicates how efficient the data transfer will be when some of the available PEs remaining after a process allocation ate used for a next allocation. </paragraph>
<paragraph id="P-0144" lvl="0"><number>&lsqb;0144&rsqb;</number> In what follows, a description will be given with regard to a case in which requests for resources and releases of resources are made as follows: </paragraph>
<paragraph id="P-0145" lvl="2"><number>&lsqb;0145&rsqb;</number> 1. a PE is requested (for process <highlight><bold>1</bold></highlight>); </paragraph>
<paragraph id="P-0146" lvl="2"><number>&lsqb;0146&rsqb;</number> 2. a PE is further requested (for process <highlight><bold>2</bold></highlight>); </paragraph>
<paragraph id="P-0147" lvl="2"><number>&lsqb;0147&rsqb;</number> 3. the PE for process <highlight><bold>1</bold></highlight> is released; </paragraph>
<paragraph id="P-0148" lvl="2"><number>&lsqb;0148&rsqb;</number> 4. two PEs conducting M data transfer therebetween are requested (for process <highlight><bold>3</bold></highlight>); </paragraph>
<paragraph id="P-0149" lvl="2"><number>&lsqb;0149&rsqb;</number> 5. the PE for process <highlight><bold>2</bold></highlight> is released; and </paragraph>
<paragraph id="P-0150" lvl="2"><number>&lsqb;0150&rsqb;</number> 6. two PEs conducting M data transfer therebetween are requested (for process <highlight><bold>4</bold></highlight>). </paragraph>
<paragraph id="P-0151" lvl="0"><number>&lsqb;0151&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10A</cross-reference> is a table chart showing results obtained when the dynamic-process-allocation algorithm described above is used. <cross-reference target="DRAWINGS">FIG. 10B</cross-reference> is a table chart showing results obtained when a simple allocation algorithm is used. This simple allocation algorithm allocates available PEs successively selected from the left hand side. In the figures, LK&lsqb;n, m&rsqb; represents the amount of data transfer on a communication link between the n-th PE and the m-th PE. </paragraph>
<paragraph id="P-0152" lvl="0"><number>&lsqb;0152&rsqb;</number> As can be seen from <cross-reference target="DRAWINGS">FIG. 10</cross-reference>A and <cross-reference target="DRAWINGS">FIG. 10</cross-reference>B, LK&lsqb;<highlight><bold>2</bold></highlight>, <highlight><bold>3</bold></highlight>&rsqb; at time <highlight><bold>6</bold></highlight> is zero when the dynamic-process-allocation algorithm of the present invention is used, and is 2M when the simple allocation algorithm is used. The allocation patterns at time <highlight><bold>6</bold></highlight> of these two algorithms correspond to allocation patterns shown in <cross-reference target="DRAWINGS">FIGS. 5A and 5B</cross-reference>. The maximum amount of data transfer over the entire time span is M in the dynamic-process-allocation algorithm of the present invention. On the other hand, the simple allocation algorithm results in the maximum amount of data transfer being 2M. In this manner, the dynamic-process-allocation algorithm of the present invention achieves an efficient process allocation. </paragraph>
<paragraph id="P-0153" lvl="0"><number>&lsqb;0153&rsqb;</number> A computer simulation was conducted in order to demonstrate the dynamic-process-allocation algorithm of the present invention. <cross-reference target="DRAWINGS">FIG. 11A</cross-reference> is a table chart showing simulation conditions, and <cross-reference target="DRAWINGS">FIG. 11B</cross-reference> is a table chart showing simulation results. In this computer simulation, a random number generation is used for determining the number of PEs requested at a time of a resource request. For the sake of simplicity, the amount of data transfer between PEs in each process is set to 1. </paragraph>
<paragraph id="P-0154" lvl="0"><number>&lsqb;0154&rsqb;</number> In a total of 1023 trials, the sum of maximum amounts of data transfer is 1279 in the case of the simple allocation algorithm. In the case of the dynamic-process-allocation algorithm of the present invention, this sum is 1220. These numbers indicate that the dynamic-process-allocation algorithm of the present invention allocates resources so as to maintain a small amount of data transfer. </paragraph>
<paragraph id="P-0155" lvl="0"><number>&lsqb;0155&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 11B</cross-reference> shows a comparison between the algorithm of the present invention and the simple allocation algorithm by using the maximum amount of data transfer as a measure for comparison. As shown in <cross-reference target="DRAWINGS">FIG. 11</cross-reference>B, only in about 5% of the total trials, did the simple allocation algorithm show superior results to the algorithm of the present invention. The algorithm of the present invention outperformed the simple allocation algorithm in about 11% of the total trials. These figures clearly signify superiority of the algorithm of the present invention. </paragraph>
<paragraph id="P-0156" lvl="0"><number>&lsqb;0156&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 12</cross-reference> is an illustrative drawing showing a memory space into which the DRAM <highlight><bold>18</bold></highlight> of the signal processing accelerator of <cross-reference target="DRAWINGS">FIG. 1</cross-reference> is incorporated when the resource-management program controls the PEs <highlight><bold>40</bold></highlight> to carry out data processing. </paragraph>
<paragraph id="P-0157" lvl="0"><number>&lsqb;0157&rsqb;</number> As described in connection with <cross-reference target="DRAWINGS">FIG. 1</cross-reference>, the information processing units <highlight><bold>10</bold></highlight> of the signal processing accelerator communicate with each other via the communication links <highlight><bold>20</bold></highlight>. In this manner, the signal processing processors <highlight><bold>11</bold></highlight> of the information processing units <highlight><bold>10</bold></highlight> can access the DRAMs <highlight><bold>18</bold></highlight> of other information processing units <highlight><bold>10</bold></highlight> in order to read and write data. When viewed from each of the signal processing processors <highlight><bold>11</bold></highlight>, the DRAMs <highlight><bold>18</bold></highlight> of the information processing units <highlight><bold>10</bold></highlight> form a single unified memory space. </paragraph>
<paragraph id="P-0158" lvl="0"><number>&lsqb;0158&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 12</cross-reference>, the PEs <highlight><bold>40</bold></highlight> which carry out data processing between the input channel <highlight><bold>41</bold></highlight> and the output channel <highlight><bold>42</bold></highlight> exchange data with each other via the unified memory space. Namely, data processed by a given PE <highlight><bold>40</bold></highlight> is stored at an indicated address in the unified memory, and another PE reads the data from this address of the unified memory to further process the data. In this manner, the DRAMs <highlight><bold>18</bold></highlight>, which are provided for the respective information processing units <highlight><bold>10</bold></highlight>, can make up the unified memory space because of communications between the information processing units <highlight><bold>10</bold></highlight>. Each information processing unit <highlight><bold>10</bold></highlight> thus can attend to information processing without discriminating a memory space of its own unit against memory spaces of other information processing units <highlight><bold>10</bold></highlight>. </paragraph>
<paragraph id="P-0159" lvl="0"><number>&lsqb;0159&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 13</cross-reference> is an illustrative drawing showing address conversion between the host processor and the signal processing accelerator. As shown in <cross-reference target="DRAWINGS">FIG. 13, a</cross-reference> VM mechanism <highlight><bold>55</bold></highlight> for controlling virtual memory on the side of the host processor converts a host-processor virtual-address space <highlight><bold>51</bold></highlight> into a host-processor physical-address space <highlight><bold>52</bold></highlight>. The host-processor virtual-address space <highlight><bold>51</bold></highlight> may, for example, constitute a 5-GB memory space at maximum. </paragraph>
<paragraph id="P-0160" lvl="0"><number>&lsqb;0160&rsqb;</number> An accelerator physical-address space <highlight><bold>53</bold></highlight> of a given DRAM <highlight><bold>18</bold></highlight>, which is controlled by the DRAM controller <highlight><bold>19</bold></highlight> of a corresponding information processing unit <highlight><bold>10</bold></highlight>, is allocated to part of the host-processor physical-address space <highlight><bold>52</bold></highlight>. The accelerator physical-address space <highlight><bold>53</bold></highlight> may, for example, be a 512-KB memory space at maximum. Since the accelerator physical-address space <highlight><bold>53</bold></highlight> is allocated to the host-processor physical-address space <highlight><bold>52</bold></highlight> and hence to the host-processor virtual-address space <highlight><bold>51</bold></highlight>, data transfer is achieved between the host processor <highlight><bold>31</bold></highlight> and the information processing unit <highlight><bold>10</bold></highlight>. </paragraph>
<paragraph id="P-0161" lvl="0"><number>&lsqb;0161&rsqb;</number> The accelerator physical-address space <highlight><bold>53</bold></highlight> is allocated to an accelerator processor-address space <highlight><bold>54</bold></highlight> (i.e., the unified memory space) with a predetermined offset. The accelerator processor-address space <highlight><bold>54</bold></highlight> may, for example, have a 4-GB memory space at maximum. The accelerator physical-address space <highlight><bold>53</bold></highlight> of each DRAM <highlight><bold>18</bold></highlight>, which is controlled by the DRAM controller <highlight><bold>19</bold></highlight> of a corresponding information processing unit <highlight><bold>10</bold></highlight>, is allocated to a respective portion of the accelerator processor-address space <highlight><bold>54</bold></highlight> by a respective predetermined offset. In this manner, the DRAMs <highlight><bold>18</bold></highlight> provided in the respective information processing units <highlight><bold>10</bold></highlight> together make up the unified memory. </paragraph>
<paragraph id="P-0162" lvl="0"><number>&lsqb;0162&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 14</cross-reference> is a block diagram of a detailed configuration of the DRAM controller <highlight><bold>19</bold></highlight> of the information processing unit <highlight><bold>10</bold></highlight>. </paragraph>
<paragraph id="P-0163" lvl="0"><number>&lsqb;0163&rsqb;</number> As previously described, the DRAM <highlight><bold>18</bold></highlight> controlled by the DRAM controller <highlight><bold>19</bold></highlight> is allocated to the host-processor virtual-address space <highlight><bold>51</bold></highlight> of the host processor <highlight><bold>31</bold></highlight>. This allocation to the host-processor virtual-address space <highlight><bold>51</bold></highlight> of the host processor <highlight><bold>31</bold></highlight> can be controlled by the operating system. When the signal processing accelerator is used with a conventional operating system which does not support such an allocation function, however, a precaution must be taken to prohibit the operating system from taking control of the DRAM <highlight><bold>18</bold></highlight> and exclusively using it as part of the OS memory space. That is, the DRAM <highlight><bold>18</bold></highlight> should not be recognized by the operating system as a memory at an initial state. Only when the signal processing accelerator is used, should the DRAM <highlight><bold>18</bold></highlight> be allocated to the host-processor virtual-address space <highlight><bold>51</bold></highlight> as a memory accessible from the operating system. Once allocated, the DRAM <highlight><bold>18</bold></highlight> can serve as a venue through which data is exchanged between the host processor <highlight><bold>31</bold></highlight> and the signal processing accelerator. </paragraph>
<paragraph id="P-0164" lvl="0"><number>&lsqb;0164&rsqb;</number> In order to achieve this, the host processor <highlight><bold>31</bold></highlight> is allowed to allocate the DRAM <highlight><bold>18</bold></highlight> to the host-processor virtual-address space <highlight><bold>51</bold></highlight> only after successfully unlocking keys. That is, the host processor <highlight><bold>31</bold></highlight> supplies data to the DRAM controller <highlight><bold>19</bold></highlight> as key information such that the DRAM <highlight><bold>18</bold></highlight> is recognized as a memory by the operating system only when the supplied data matches predetermined key information. </paragraph>
<paragraph id="P-0165" lvl="0"><number>&lsqb;0165&rsqb;</number> The DRAM controller <highlight><bold>19</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 14</cross-reference> includes the DRAM <highlight><bold>18</bold></highlight>, a key register <highlight><bold>61</bold></highlight>, a comparator <highlight><bold>62</bold></highlight>, a host-memory control circuit <highlight><bold>63</bold></highlight>, and a control register <highlight><bold>64</bold></highlight>. The DRAM <highlight><bold>18</bold></highlight> is a conventional DRAM which includes memory cells, a word-selection mechanism, a column-selection mechanism, sense amplifiers, a precharging mechanism, etc., and a description thereof will be omitted. </paragraph>
<paragraph id="P-0166" lvl="0"><number>&lsqb;0166&rsqb;</number> The key register <highlight><bold>61</bold></highlight> stores a plurality of key data. When a plurality of data provided from the host processor <highlight><bold>31</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>) matches the plurality of keys stored in the key register <highlight><bold>61</bold></highlight>, the keys are unlocked. The comparator <highlight><bold>62</bold></highlight> compares the data supplied from the host processor <highlight><bold>31</bold></highlight> via the host memory bus <highlight><bold>30</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>) with the plurality of key data stored in the key register <highlight><bold>61</bold></highlight>. The comparator <highlight><bold>62</bold></highlight> supplies results of the comparison to the host-memory control circuit <highlight><bold>63</bold></highlight>. </paragraph>
<paragraph id="P-0167" lvl="0"><number>&lsqb;0167&rsqb;</number> The host-memory control circuit <highlight><bold>63</bold></highlight> controls the DRAM <highlight><bold>18</bold></highlight>, key register <highlight><bold>61</bold></highlight>, and the control register <highlight><bold>64</bold></highlight>. When data is written in a particular register which is provided in the control register <highlight><bold>64</bold></highlight> for the purpose of key matching, the host-memory control circuit <highlight><bold>63</bold></highlight> supplies a plurality of key numbers to the key register <highlight><bold>61</bold></highlight> so that the key register <highlight><bold>61</bold></highlight> outputs a plurality of keys. The comparator <highlight><bold>62</bold></highlight> compares the plurality of keys with the plurality of data provided from the host memory bus <highlight><bold>30</bold></highlight>. If all the keys are matched, the host-memory control circuit <highlight><bold>63</bold></highlight> writes recognition codes in a recognition-code register of the control register <highlight><bold>64</bold></highlight>. The host processor <highlight><bold>31</bold></highlight> reads and recognizes the recognition codes so that the host processor <highlight><bold>31</bold></highlight> recognizes the DRAM <highlight><bold>18</bold></highlight> and the DRAM controller <highlight><bold>19</bold></highlight> as a memory. Details of this recognition operation will be later described. </paragraph>
<paragraph id="P-0168" lvl="0"><number>&lsqb;0168&rsqb;</number> In addition to the key matching register and the recognition-code register described above, the control register <highlight><bold>64</bold></highlight> includes an initialization register for initializing the signal processing unit <highlight><bold>25</bold></highlight> and the communication-control unit <highlight><bold>26</bold></highlight>, a reset-signal flag for controlling operations of the signal processing unit <highlight><bold>25</bold></highlight>, etc. </paragraph>
<paragraph id="P-0169" lvl="0"><number>&lsqb;0169&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 15</cross-reference> is an illustrative drawing showing state transitions of the information processing unit <highlight><bold>10</bold></highlight>. </paragraph>
<paragraph id="P-0170" lvl="0"><number>&lsqb;0170&rsqb;</number> Immediately after the system is turned on, the information processing unit <highlight><bold>10</bold></highlight> is in an initial state ST<highlight><bold>1</bold></highlight>. By this time, other conventional DRAMs connected to the host memory bus <highlight><bold>30</bold></highlight> are recognized as memories. The DRAM <highlight><bold>18</bold></highlight> of the information processing unit <highlight><bold>10</bold></highlight>, however, is not recognized as memories at this time. </paragraph>
<paragraph id="P-0171" lvl="0"><number>&lsqb;0171&rsqb;</number> In the initial state ST<highlight><bold>1</bold></highlight>, data and storage addresses are supplied from the resource-management program or other programs via the host memory bus <highlight><bold>30</bold></highlight>. At the same time, control signals RAS, /CAS, WE, and /OE are provided in order to access the DRAM controller <highlight><bold>19</bold></highlight>. If data is written in the key matching register of the control register <highlight><bold>64</bold></highlight>, a state transition takes place from the initial state ST<highlight><bold>1</bold></highlight> to the key matching mode ST<highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0172" lvl="0"><number>&lsqb;0172&rsqb;</number> In the key matching mode ST<highlight><bold>2</bold></highlight>, the host-memory control circuit <highlight><bold>63</bold></highlight> supplies a plurality of key numbers to the key register <highlight><bold>61</bold></highlight>. The key register <highlight><bold>61</bold></highlight> successively feeds a plurality of keys to the comparator <highlight><bold>62</bold></highlight> in response to the plurality of key numbers. The comparator <highlight><bold>62</bold></highlight> compares the plurality of data provided via the host memory bus <highlight><bold>30</bold></highlight> with the plurality of keys, and sends comparison results to the host-memory control circuit <highlight><bold>63</bold></highlight>. If all the keys match the supplied data, a state transition is made from the key matching mode ST<highlight><bold>2</bold></highlight> to a tentatively unlocked state ST<highlight><bold>3</bold></highlight>. If all the keys and the data do not match, the information processing unit <highlight><bold>10</bold></highlight> goes back to the initial state ST<highlight><bold>1</bold></highlight>. </paragraph>
<paragraph id="P-0173" lvl="0"><number>&lsqb;0173&rsqb;</number> In the tentatively unlocked state ST<highlight><bold>3</bold></highlight>, the host-memory control circuit <highlight><bold>63</bold></highlight> writes recognition codes in the recognition-code register of the control register <highlight><bold>64</bold></highlight>. The host processor <highlight><bold>31</bold></highlight> reads the recognition codes, and checks the codes to recognize the DRAM <highlight><bold>18</bold></highlight> as a memory, thereby registering the DRAM <highlight><bold>18</bold></highlight> in a device table. The access by the host processor <highlight><bold>31</bold></highlight> to the recognition-code register brings about a state transition to an unlocked state ST<highlight><bold>4</bold></highlight>. </paragraph>
<paragraph id="P-0174" lvl="0"><number>&lsqb;0174&rsqb;</number> In the unlocked state ST<highlight><bold>4</bold></highlight>, the host processor <highlight><bold>31</bold></highlight> write an initialization request in the initialization register of the control register <highlight><bold>64</bold></highlight>. When the initialization request is written, the signal processing unit <highlight><bold>25</bold></highlight> and the communication-control unit <highlight><bold>26</bold></highlight> are initialized. The writing of the initialization request changes a state to a signal-processing-processor reset state ST<highlight><bold>5</bold></highlight>. </paragraph>
<paragraph id="P-0175" lvl="0"><number>&lsqb;0175&rsqb;</number> In the signal-processing-processor reset state ST<highlight><bold>5</bold></highlight>, the host processor <highlight><bold>31</bold></highlight> writes information in the DRAM <highlight><bold>18</bold></highlight> with regard to execution programs, address pointers referring to data input/output buffers, etc. Further, the host processor <highlight><bold>31</bold></highlight> clears a reset-signal flag of the control register <highlight><bold>64</bold></highlight>. When the reset-signal flag is removed, the signal processing unit <highlight><bold>25</bold></highlight> starts data processing. With the start of the data processing, a state is changed to a signal-processing-processor running state ST<highlight><bold>6</bold></highlight>. </paragraph>
<paragraph id="P-0176" lvl="0"><number>&lsqb;0176&rsqb;</number> Changing the reset-signal flag back and forth between the cleared status and the set status, a state can be shifted back and forth between the signal-processing-processor reset state ST<highlight><bold>5</bold></highlight> and the signal-processing-processor running state ST<highlight><bold>6</bold></highlight>. In this manner, programs can be updated and results can be read out at appropriate timings during the signal-processing-processor reset state ST<highlight><bold>5</bold></highlight>. </paragraph>
<paragraph id="P-0177" lvl="0"><number>&lsqb;0177&rsqb;</number> From the signal-processing-processor running state ST<highlight><bold>6</bold></highlight>, a state goes to the initial state ST<highlight><bold>1</bold></highlight> upon completion of the data processing operations. In this state, the host processor <highlight><bold>31</bold></highlight> does not recognize the DRAM <highlight><bold>18</bold></highlight> of the information processing unit <highlight><bold>10</bold></highlight> as a memory. </paragraph>
<paragraph id="P-0178" lvl="0"><number>&lsqb;0178&rsqb;</number> As described above, the initial state does not allow the DRAM <highlight><bold>18</bold></highlight> to be recognized as a memory so that the operation system does not take control of the DRAM <highlight><bold>18</bold></highlight> and use it as OS memory space. When the signal processing accelerator is used, however, keys are unlocked to allow the DRAM <highlight><bold>18</bold></highlight> to be recognized as a usable memory. Unlocking of the keys is tantamount to searching in the host-processor physical-address space <highlight><bold>52</bold></highlight> for the DRAM <highlight><bold>18</bold></highlight> of the information processing unit <highlight><bold>10</bold></highlight> which is not a conventional DRAM. </paragraph>
<paragraph id="P-0179" lvl="0"><number>&lsqb;0179&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> is an illustrative drawing showing a mechanism for executing virtual-machine codes according to the present invention. Microprocessors of the Intel corporation, for example, include a P55C microprocessor which can execute a multi-media-extended-instruction set MMX. This instruction set is provided as an extension to a general-purpose instruction set. If programs using the extended instruction set MMX are executed by a general-purpose processor such as a Pentium processor which does not support extended instructions, an interruption INT6 is generated as an instruction exception at the time of execution of an extended instruction. If an interruption handling routine is provided, however, the signal processing accelerator of the present invention can emulate this extended instruction, thereby serving as a virtual machine. </paragraph>
<paragraph id="P-0180" lvl="0"><number>&lsqb;0180&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 16</cross-reference> shows a software structure for implementing such a virtual machine by taking the Pentium processor and the extended instruction set MMX as an example. As shown in <cross-reference target="DRAWINGS">FIG. 16</cross-reference>, the application layer includes an ordinary application program and an MMX user program. The extended instruction set MMX is used in the MMX user program, but not used in the ordinary application program. These programs are executed by a Pentium processor which does not support the extended instruction set MMX. When the MMX user program is executed, the Pentium processor generates an interruption INT6 at the time of execution of an extended instruction MMX. </paragraph>
<paragraph id="P-0181" lvl="0"><number>&lsqb;0181&rsqb;</number> A virtual-machine program VMMX in addition to the resource-management program RMI resides in the resource-management layer. The virtual-machine program VMMX handles interruption. Upon receiving the interruption INT6, the virtual-machine program VMMX writes an extended instruction MMX causing the interruption in an instruction queue (FIFO) of the main memory. The virtual-machine program VMMX reads an extended instruction MMX from the FIFO of the main memory, and supplies it to the resource-management program RMI. The resource-management program RMI writes programs for the signal processing accelerator to emulate the extended instruction MMX, pointers pointing to input/output references, etc., in the unified memory. Each PE of the signal processing accelerator emulates the extended instruction MMX, and stores emulation results in the unified memory. The emulation results are passed to the user program in the application layer via the resource-management program RMI and the virtual-machine program VMMX in the resource-management layer. </paragraph>
<paragraph id="P-0182" lvl="0"><number>&lsqb;0182&rsqb;</number> In this manner, when a general-purpose processor not supporting the extended instruction set MMX executes an extended instruction MMX, the interruption INT6 is detected to control the signal processing accelerator of the present invention to emulate the extended instruction MMX. In this configuration, programs can be executed as if the processor supports the execution instruction set MMX. Here, the extended instruction set MMX, the interruption INT6, the Pentium processor, etc., are used merely as an example for explanation. That is, emulation by the signal processing accelerator as exceptional handling in response to detection of interruption is not limited to processors and systems of the Intel corporation, but can be applied to any system. Further, the virtual machine (signal processing accelerator) may execute an instruction of a user&apos;s own creation as exceptional handling so that the user can create and execute instructions which are not supported by any commercially available processors. </paragraph>
<paragraph id="P-0183" lvl="0"><number>&lsqb;0183&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 17</cross-reference> is a flowchart of exceptional handling by the signal processing accelerator for emulation. </paragraph>
<paragraph id="P-0184" lvl="0"><number>&lsqb;0184&rsqb;</number> At a step S<highlight><bold>51</bold></highlight>, a virtual machine code (virtual machine instruction) of a user program is fetched by the host processor <highlight><bold>31</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>). The virtual machine code is an instruction which is to be emulated by the signal processing accelerator. The host processor <highlight><bold>31</bold></highlight> detects an illegal instruction when decoding the virtual machine code, and generates an interruption signal INT6. The interruption signal generated by the host processor <highlight><bold>31</bold></highlight> does not have to be INT6, but can be any code as long as the code indicates an instruction exception. </paragraph>
<paragraph id="P-0185" lvl="0"><number>&lsqb;0185&rsqb;</number> At a step S<highlight><bold>52</bold></highlight>, a virtual machine program (i.e., an interruption handling routine corresponding to VMMX of <cross-reference target="DRAWINGS">FIG. 16</cross-reference>) detects the interruption signal INT6, and transfers the virtual machine code causing the interruption to FIFO serving as an instruction queue. In this example, the virtual machine code causing the interruption is assumed to be a data processing instruction. </paragraph>
<paragraph id="P-0186" lvl="0"><number>&lsqb;0186&rsqb;</number> At a step S<highlight><bold>53</bold></highlight>, the resource-management program RMI (RMI.API and RMI.VxD) reads the virtual machine code from the FIFO, and checks whether processing of a previous virtual-machine instruction is finished. After the processing of the previous virtual-machine instruction is completed, the procedure goes to a step S<highlight><bold>54</bold></highlight>. </paragraph>
<paragraph id="P-0187" lvl="0"><number>&lsqb;0187&rsqb;</number> At the step S<highlight><bold>54</bold></highlight>, the resource-management program RMI writes the virtual machine code in an instruction queue which stores instructions to be executed by the signal processing processor <highlight><bold>11</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 1</cross-reference>). After writing the virtual machine code in the instruction queue, the resource-management program RMI gives an instruction to the signal processing accelerator to emulation the virtual machine instruction, and, also, sends-a notice of execution completion to the virtual machine program. </paragraph>
<paragraph id="P-0188" lvl="0"><number>&lsqb;0188&rsqb;</number> At a step S<highlight><bold>55</bold></highlight>, the virtual machine program receives the notice of execution completion so as to know that the execution is completed, and prompts the host processor <highlight><bold>31</bold></highlight> to resume operations after the interruption handling. </paragraph>
<paragraph id="P-0189" lvl="0"><number>&lsqb;0189&rsqb;</number> At a step S<highlight><bold>56</bold></highlight>, the next instruction of the user program is fetched by the host processor <highlight><bold>31</bold></highlight>. </paragraph>
<paragraph id="P-0190" lvl="0"><number>&lsqb;0190&rsqb;</number> At a step S<highlight><bold>57</bold></highlight>, the signal processing accelerator performs the emulation of the virtual machine instruction independently of the execution of the user program by the host processor <highlight><bold>31</bold></highlight>. </paragraph>
<paragraph id="P-0191" lvl="0"><number>&lsqb;0191&rsqb;</number> At a step S<highlight><bold>58</bold></highlight>, results of the emulation are stored in a virtual-machine register block (the DRAM <highlight><bold>18</bold></highlight> of the information processing unit <highlight><bold>10</bold></highlight> shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>). </paragraph>
<paragraph id="P-0192" lvl="0"><number>&lsqb;0192&rsqb;</number> At a step S<highlight><bold>59</bold></highlight>, the host processor <highlight><bold>31</bold></highlight> fetches a virtual machine code of the user program independently of the emulation by the signal processing accelerator. When decoding the virtual machine code, the host processor <highlight><bold>31</bold></highlight> learns that this virtual machine code is an illegal instruction, and, then, generates an interruption signal INT6. The interruption signal generated by the host processor <highlight><bold>31</bold></highlight> does not have to be INT6, but can be any code as long as the code indicates an instruction exception. </paragraph>
<paragraph id="P-0193" lvl="0"><number>&lsqb;0193&rsqb;</number> At a step S<highlight><bold>60</bold></highlight>, upon detection of the interruption signal INT6, the virtual machine program transfers the virtual machine code causing the interruption to the FIFO which serves as an instruction queue. In this example, this virtual machine code is assumed to be a data-read instruction. </paragraph>
<paragraph id="P-0194" lvl="0"><number>&lsqb;0194&rsqb;</number> At a step S<highlight><bold>61</bold></highlight>, the resource-management program RMI reads the virtual machine code from the FIFO, and checks whether processing of the previous virtual-machine instruction is finished. After the processing of the previous virtual-machine instruction is completed, the procedure goes to a step S<highlight><bold>62</bold></highlight>. </paragraph>
<paragraph id="P-0195" lvl="0"><number>&lsqb;0195&rsqb;</number> At a step S<highlight><bold>62</bold></highlight>, the resource-management program RMI stores the virtual machine code to the instruction queue which is provided for storing instructions to be executed by the signal processing accelerator. </paragraph>
<paragraph id="P-0196" lvl="0"><number>&lsqb;0196&rsqb;</number> At a step S<highlight><bold>63</bold></highlight>, the resource-management program RMI copies the results of the emulation from the virtual-machine register block to the memory space of the user program. Further, the resource-management program RMI sends a notice of execution completion to the virtual machine program. </paragraph>
<paragraph id="P-0197" lvl="0"><number>&lsqb;0197&rsqb;</number> At a step S<highlight><bold>64</bold></highlight>, the virtual machine program receives the notice of execution completion so as to know that the execution is completed, and prompts the host processor <highlight><bold>31</bold></highlight> to resume operations after the interruption handling. </paragraph>
<paragraph id="P-0198" lvl="0"><number>&lsqb;0198&rsqb;</number> At a step S<highlight><bold>65</bold></highlight>, the next instruction of the user program is fetched by the host processor <highlight><bold>31</bold></highlight>. </paragraph>
<paragraph id="P-0199" lvl="0"><number>&lsqb;0199&rsqb;</number> In this manner, when a virtual machine instruction is fetched by the host processor <highlight><bold>31</bold></highlight>, the virtual machine program detects the interruption signal INT6, and the signal processing accelerator emulates the virtual machine instruction under the control of the resource-management program RMI. Therefore, the user program can be executed as if the host processor <highlight><bold>31</bold></highlight> itself was executing the virtual machine instructions. </paragraph>
<paragraph id="P-0200" lvl="0"><number>&lsqb;0200&rsqb;</number> In what follows, various methods of controlling a client processor by using a host processor will be described with regard to a system in which the client processor (signal processing processor or signal processing accelerator of the previous embodiments) is connected to the host processor via a memory interface (i.e., host-memory bus to which main memories are connected). Here, the memory interface is an interface through which the host processor accesses the main memories connected to the host-memory bus, and the main memories store data and instruction codes executable by the host processor which are initially read from an auxiliary memory device. </paragraph>
<paragraph id="P-0201" lvl="0"><number>&lsqb;0201&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 18</cross-reference> is a block diagram showing a switching mechanism which switches between a client processor and a memory when the client processor and the memory are connected to a host processor via a memory interface. </paragraph>
<paragraph id="P-0202" lvl="0"><number>&lsqb;0202&rsqb;</number> As shown in <cross-reference target="DRAWINGS">FIG. 18, a</cross-reference> host processor <highlight><bold>101</bold></highlight> is connected to a client processor <highlight><bold>102</bold></highlight> and a memory <highlight><bold>103</bold></highlight> via a switch means <highlight><bold>104</bold></highlight>. The host processor <highlight><bold>101</bold></highlight> can access only one of the client processor <highlight><bold>102</bold></highlight> and the memory <highlight><bold>103</bold></highlight> at a time, and the switch means <highlight><bold>104</bold></highlight> controls which one of them is accessible at a given time. </paragraph>
<paragraph id="P-0203" lvl="0"><number>&lsqb;0203&rsqb;</number> The switch means <highlight><bold>104</bold></highlight> includes an address-check means <highlight><bold>105</bold></highlight>, a key-check means <highlight><bold>106</bold></highlight>, a switch flag <highlight><bold>107</bold></highlight>, an AND logic <highlight><bold>108</bold></highlight>, and a switch <highlight><bold>109</bold></highlight>. The host processor <highlight><bold>101</bold></highlight> writes predetermined data at a predetermined address. Upon the address input, the address-check means <highlight><bold>105</bold></highlight> activates an output thereof. When the output of the address-check means <highlight><bold>105</bold></highlight> is activated, the key-check means <highlight><bold>106</bold></highlight> compares the predetermined data supplied from the host processor <highlight><bold>101</bold></highlight> with predetermined key information. If the supplied data and the key information match, the key-check means <highlight><bold>106</bold></highlight> sets a flag to the switch flag <highlight><bold>107</bold></highlight>. The switch flag <highlight><bold>107</bold></highlight> produces an active output when a flag is set. The AND logic <highlight><bold>108</bold></highlight> opens the switch <highlight><bold>109</bold></highlight> when both the output of the address-check means <highlight><bold>105</bold></highlight> and the output of the switch flag <highlight><bold>107</bold></highlight> are active. In this manner, the host processor <highlight><bold>101</bold></highlight> accesses the client processor <highlight><bold>102</bold></highlight> instead of accessing the memory <highlight><bold>103</bold></highlight>. When the client processor <highlight><bold>102</bold></highlight> needs to access the memory <highlight><bold>103</bold></highlight>, the host processor <highlight><bold>101</bold></highlight> supplies predetermined data to a predetermined address so as to clear the flag of the switch flag <highlight><bold>107</bold></highlight>. </paragraph>
<paragraph id="P-0204" lvl="0"><number>&lsqb;0204&rsqb;</number> In this manner, writing of predetermined key data at a predetermined address makes it possible to switch between the client processor <highlight><bold>102</bold></highlight> and the memory <highlight><bold>103</bold></highlight>. If a comparison between data and key information is made more than one time, a probability of an accidental match between the data and the key can be reduced. Namely, the larger the number of required comparison, the greater the reliability of the match. </paragraph>
<paragraph id="P-0205" lvl="0"><number>&lsqb;0205&rsqb;</number> The predetermined address described above may be a particular address in a memory space. </paragraph>
<paragraph id="P-0206" lvl="0"><number>&lsqb;0206&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 19</cross-reference> is a circuit diagram of the address-check means <highlight><bold>105</bold></highlight> which activates an output thereof when a particular address in a memory space is provided. </paragraph>
<paragraph id="P-0207" lvl="0"><number>&lsqb;0207&rsqb;</number> The address-check means <highlight><bold>105</bold></highlight> includes a storage means <highlight><bold>111</bold></highlight> for storing the particular address and a comparator <highlight><bold>112</bold></highlight>. When the same address as that stored in the storage means <highlight><bold>111</bold></highlight> is provided, the address-check means <highlight><bold>105</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 19</cross-reference> activates an output thereof. </paragraph>
<paragraph id="P-0208" lvl="0"><number>&lsqb;0208&rsqb;</number> Alternately, the predetermined address described above may be an address within a particular range in a memory space. </paragraph>
<paragraph id="P-0209" lvl="0"><number>&lsqb;0209&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 20</cross-reference> is a circuit diagram of the address-check means <highlight><bold>105</bold></highlight> which activates an output thereof when an address within a particular memory-space range is provided. </paragraph>
<paragraph id="P-0210" lvl="0"><number>&lsqb;0210&rsqb;</number> The address-check means <highlight><bold>105</bold></highlight> includes a storage means <highlight><bold>111</bold></highlight>A for storing a first address, a storage means <highlight><bold>111</bold></highlight>B for storing a second address, comparators <highlight><bold>112</bold></highlight>A and <highlight><bold>112</bold></highlight>B, and an AND logic <highlight><bold>113</bold></highlight>. The comparator <highlight><bold>112</bold></highlight>A activates an output thereof when a provided address is larger than the first address stored in the storage means <highlight><bold>111</bold></highlight>A. The comparator <highlight><bold>112</bold></highlight>B activates an output thereof when the provided address is smaller than the second address stored in the storage means <highlight><bold>111</bold></highlight>B. An address-check output from the AND logic <highlight><bold>113</bold></highlight>, therefore, becomes active when the provided address is within a range between the first address and the second address. </paragraph>
<paragraph id="P-0211" lvl="0"><number>&lsqb;0211&rsqb;</number> In <cross-reference target="DRAWINGS">FIG. 18</cross-reference>, when the key-check means <highlight><bold>106</bold></highlight> compares supplied data with predetermined key information, shuffling of bit positions in a data-bit arrangement may surface as a problem. In a computer system, generally, bit positions in a data-bit arrangement are changed at a memory interface. Such a change is brought about when a data bus is laid out from a host processor to memories by placing emphasis on factors such as a noise reduction and a layout-area-size reduction while ignoring an order of bit lines of the data bus. </paragraph>
<paragraph id="P-0212" lvl="0"><number>&lsqb;0212&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 21</cross-reference> is an illustrative drawing schematically showing a change of bit positions in a bit arrangement. As shown in <cross-reference target="DRAWINGS">FIG. 21</cross-reference>, the most significant bit MSB on the host-processor side is changed to a fourth bit on the memory side, and the least significant bit LSB is displaced to a third-bit position, for example. Such shuffling of bit positions in a bit arrangement does not surface as a problem in a conventional computer system since data stored in memories in a shuffled bit order is read out and transmitted to the host processor in a rearranged and corrected bit order. </paragraph>
<paragraph id="P-0213" lvl="0"><number>&lsqb;0213&rsqb;</number> When the key-check means <highlight><bold>106</bold></highlight> compares supplied data with predetermined key information, however, shuffling of bit positions renders it meaningless to make a direct comparison of bit patterns between the supplied data and the key information. To overcome this problem, various methods as described below are presented. </paragraph>
<paragraph id="P-0214" lvl="0"><number>&lsqb;0214&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 22A</cross-reference> is an illustrative drawing showing a relation between a data word and sub-words, and <cross-reference target="DRAWINGS">FIG. 22B</cross-reference> is an illustrative drawing showing a key code (key information). In many systems, generally, changes of bit positions only occur sub-word by sub-word, and bit positions within a given sub-word are not changed. When the data word is 32 bits including four sub-words of 8 bits, for example, sub-words are switched with each other, but an arrangement of 8 bits within each sub-word does not change in such systems. </paragraph>
<paragraph id="P-0215" lvl="0"><number>&lsqb;0215&rsqb;</number> In such systems, therefore, a data word in which each sub-word is a key code (key information) may be supplied from a host processor to the key-check means <highlight><bold>106</bold></highlight> to obviate the problem of the data-bit shuffling. In this case, switching of sub-words during an intervening path does not affect the comparison of each sub-word with the key code by the key-check means <highlight><bold>106</bold></highlight>, and, thus, a correct check result is obtained. </paragraph>
<paragraph id="P-0216" lvl="0"><number>&lsqb;0216&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 23</cross-reference> is a flowchart of a process of generating data words in which each sub-word is comprised of a key code. </paragraph>
<paragraph id="P-0217" lvl="0"><number>&lsqb;0217&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>-<highlight><bold>1</bold></highlight>, Lw data x&lsqb;i&rsqb; (i&equals;1, . . . , Lw) are provided. Here, each datum x&lsqb;i&rsqb; is a key code which is comprised of Kw bits. </paragraph>
<paragraph id="P-0218" lvl="0"><number>&lsqb;0218&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>-<highlight><bold>2</bold></highlight>, a loop repeating Lw times based on a variable i is started. </paragraph>
<paragraph id="P-0219" lvl="0"><number>&lsqb;0219&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>-<highlight><bold>3</bold></highlight>, datum y&lsqb;i&rsqb; comprised of Mw bits is set to zero. </paragraph>
<paragraph id="P-0220" lvl="0"><number>&lsqb;0220&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>-<highlight><bold>4</bold></highlight>, a loop repeating Mw/Kw times is started. Here, Mw is the number of data-word bits (e.g., 32), and Kw is the number of sub-word bits (e.g., 8). </paragraph>
<paragraph id="P-0221" lvl="0"><number>&lsqb;0221&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>-<highlight><bold>5</bold></highlight>, a bit-wise OR operation is performed between y&lsqb;i) and x(i), and an obtained result is substituted for an old value of y&lsqb;i&rsqb;. </paragraph>
<paragraph id="P-0222" lvl="0"><number>&lsqb;0222&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>-<highlight><bold>6</bold></highlight>, each bit of y(i&rsqb; is shifted to the left by Kw bits. That is, the datum x&lsqb;i&rsqb; incorporated into y&lsqb;i&rsqb; at the step S<highlight><bold>23</bold></highlight>-<highlight><bold>5</bold></highlight> is shifted to a sub-word second from the right. </paragraph>
<paragraph id="P-0223" lvl="0"><number>&lsqb;0223&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>-<highlight><bold>7</bold></highlight>, a check is made whether the above procedure is repeated Mw/Kw times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0224" lvl="0"><number>&lsqb;0224&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>-<highlight><bold>8</bold></highlight>, a check is made whether the loop based on the variable i is repeated Lw times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0225" lvl="0"><number>&lsqb;0225&rsqb;</number> At a step S<highlight><bold>23</bold></highlight>-<highlight><bold>9</bold></highlight>, Lw data y&lsqb;i&rsqb; are obtained as output data. Each datum y&lsqb;i&rsqb; has sub-words each of which is comprised of the key code. When y&lsqb;i&rsqb; is written into a predetermined address, thus, a key-code comparison is correctly made even when there is shuffling of sub-word orders. </paragraph>
<paragraph id="P-0226" lvl="0"><number>&lsqb;0226&rsqb;</number> In the system of <cross-reference target="DRAWINGS">FIG. 18, a</cross-reference> switch between the client processor and the memory is made when data is written at a predetermined address, as previously described. In this case, it is preferable for the host processor to be able to confirm if a switch is actually made after an attempt to switch over to the client processor is made. To achieve this, the predetermined key data is read from the client processor, and the host processor performs a key comparison. </paragraph>
<paragraph id="P-0227" lvl="0"><number>&lsqb;0227&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 24</cross-reference> is a flowchart of a process of reading data words in which each sub-word is comprised of a key code, and extracting the key code from the data words. </paragraph>
<paragraph id="P-0228" lvl="0"><number>&lsqb;0228&rsqb;</number> At a step S<highlight><bold>24</bold></highlight>-<highlight><bold>1</bold></highlight>, Nr data y&lsqb;i&rsqb; (i&equals;1, . . . , Nr) are read. Here, each datum y&lsqb;i&rsqb; is comprised of Mr bits. </paragraph>
<paragraph id="P-0229" lvl="0"><number>&lsqb;0229&rsqb;</number> At a step S<highlight><bold>24</bold></highlight>-<highlight><bold>2</bold></highlight>, a mask MASK which is comprised of Mr bits having lower Kr bits of 1 and the remaining bits of 0 is created. </paragraph>
<paragraph id="P-0230" lvl="0"><number>&lsqb;0230&rsqb;</number> At a step S<highlight><bold>24</bold></highlight>-<highlight><bold>3</bold></highlight>, a loop repeating Nr times based on a variable i is started. </paragraph>
<paragraph id="P-0231" lvl="0"><number>&lsqb;0231&rsqb;</number> At a step S<highlight><bold>24</bold></highlight>-<highlight><bold>4</bold></highlight>, a bit-wise AND operation is performed between the mask MASK and the datum y&lsqb;i&rsqb;, and an obtained result is substituted for x&lsqb;i&rsqb;. </paragraph>
<paragraph id="P-0232" lvl="0"><number>&lsqb;0232&rsqb;</number> At a step S<highlight><bold>24</bold></highlight>-<highlight><bold>5</bold></highlight>, a check is made whether the loop based on the variable i is repeated Nr times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0233" lvl="0"><number>&lsqb;0233&rsqb;</number> At a step S<highlight><bold>24</bold></highlight>-<highlight><bold>6</bold></highlight>, Nr data x&lsqb;i&rsqb; are obtained as output data. Each datum x&lsqb;i&rsqb; is compared with the predetermined key code to allow the host computer to check whether an attempted switch has actually taken effect. </paragraph>
<paragraph id="P-0234" lvl="0"><number>&lsqb;0234&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 25A and 25B</cross-reference> are illustrative drawings for explaining a key comparison which is made by using a time data series to avoid an effect of the shuffling of bit positions. As shown in <cross-reference target="DRAWINGS">FIG. 25A, a</cross-reference> plurality of data words, each of which is either an all-zero bit pattern or an all-one bit pattern, are written into the memory space. If one bit is taken out from each of the data words and arranged in a time order, a time data series as shown in <cross-reference target="DRAWINGS">FIG. 25B</cross-reference> can be formed. This time data series is not affected by whatever shuffling of bit positions occurring through the memory interface, and, thus, can be used as data for a key comparison. </paragraph>
<paragraph id="P-0235" lvl="0"><number>&lsqb;0235&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 26</cross-reference> is a flowchart of a process of generating data based on a key code so that the data has each bit thereof representing one bit of the key code in a time order. </paragraph>
<paragraph id="P-0236" lvl="0"><number>&lsqb;0236&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>-<highlight><bold>1</bold></highlight>, Lw data x&lsqb;i&rsqb; (i&equals;1, . . . , Lw) are provided. Here, each datum x&lsqb;i&rsqb; is a key code which is comprised of Kw bits. </paragraph>
<paragraph id="P-0237" lvl="0"><number>&lsqb;0237&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>-<highlight><bold>2</bold></highlight>, a mask MASK comprised of Kw bits is created. Only the least significant bit of the mask MASK is 1, and other bits are 0. </paragraph>
<paragraph id="P-0238" lvl="0"><number>&lsqb;0238&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>-<highlight><bold>3</bold></highlight>, a loop repeating Lw times based on a variable j is started. </paragraph>
<paragraph id="P-0239" lvl="0"><number>&lsqb;0239&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>-<highlight><bold>4</bold></highlight>, a loop repeating Kw times based on a variable i is started. </paragraph>
<paragraph id="P-0240" lvl="0"><number>&lsqb;0240&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>-<highlight><bold>5</bold></highlight>, an OR operation is performed between x&lsqb;i&rsqb; and the mask MASK. If the resulting value is 1, the procedure goes to a step S<highlight><bold>26</bold></highlight>-<highlight><bold>6</bold></highlight>. Otherwise, the procedure goes to a step S<highlight><bold>26</bold></highlight>-<highlight><bold>7</bold></highlight>. </paragraph>
<paragraph id="P-0241" lvl="0"><number>&lsqb;0241&rsqb;</number> At the step S<highlight><bold>26</bold></highlight>-<highlight><bold>6</bold></highlight>, datum y&lsqb;jKw&plus;i&rsqb; comprised of Mw bits are set to 1 with respect to all bits thereof. </paragraph>
<paragraph id="P-0242" lvl="0"><number>&lsqb;0242&rsqb;</number> At the step S<highlight><bold>26</bold></highlight>-<highlight><bold>7</bold></highlight>, the datum y&lsqb;jKw&plus;i&rsqb; comprised of Mw bits are set to 0 with respect to all bits thereof. </paragraph>
<paragraph id="P-0243" lvl="0"><number>&lsqb;0243&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>-<highlight><bold>8</bold></highlight>, x&lsqb;i&rsqb; is shifted to the right by one bit. </paragraph>
<paragraph id="P-0244" lvl="0"><number>&lsqb;0244&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>-<highlight><bold>9</bold></highlight>, a check is made whether the loop based on the variable i is repeated Kw times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0245" lvl="0"><number>&lsqb;0245&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>-<highlight><bold>10</bold></highlight>, a check is made whether the loop based on the variable j is repeated Lw times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0246" lvl="0"><number>&lsqb;0246&rsqb;</number> At a step S<highlight><bold>26</bold></highlight>-<highlight><bold>11</bold></highlight>, (Kw)x(Lw) data y&lsqb;i&rsqb; are obtained as output data. Each datum y&lsqb;i&rsqb; is comprised of Mw bits, where either all of the Mw bits are 0 or all of the Mr bits are 1. When a line of bits is taken from the data y&lsqb;i&rsqb; along a time line (in a direction in which the variable i changes), the line of bits represents a time series corresponding to the key code. When the data y&lsqb;i&rsqb; is written in a predetermined address, a key comparison will produce a correct comparison result even when there a is bit-position shuffling. </paragraph>
<paragraph id="P-0247" lvl="0"><number>&lsqb;0247&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 27</cross-reference> is a flowchart of a process of extracting a key code from data that is read. </paragraph>
<paragraph id="P-0248" lvl="0"><number>&lsqb;0248&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>1</bold></highlight>, Nr data y&lsqb;i&rsqb; (i&equals;1, . . . , Nr) are read. Here, each datum y&lsqb;i&rsqb; is comprised of Mr bits. </paragraph>
<paragraph id="P-0249" lvl="0"><number>&lsqb;0249&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>2</bold></highlight>, a mask MASK which is comprised of Mr bits having a value of 1 only in the least significant bit is created. </paragraph>
<paragraph id="P-0250" lvl="0"><number>&lsqb;0250&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>3</bold></highlight>, a loop repeating Nr/Kr times based on a variable j is started. </paragraph>
<paragraph id="P-0251" lvl="0"><number>&lsqb;0251&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>4</bold></highlight>, datum x&lsqb;j&rsqb; comprised of Kr bits is set to zero. </paragraph>
<paragraph id="P-0252" lvl="0"><number>&lsqb;0252&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>5</bold></highlight>, a loop repeating Kr times based on a variable i is started. </paragraph>
<paragraph id="P-0253" lvl="0"><number>&lsqb;0253&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>6</bold></highlight>, x&lsqb;j&rsqb; is shifted to the left by one bit. </paragraph>
<paragraph id="P-0254" lvl="0"><number>&lsqb;0254&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>7</bold></highlight>, a value of y&lsqb;jKr&plus;i&rsqb; is checked. If all the bits are 1, the procedure goes to a step S<highlight><bold>27</bold></highlight>-<highlight><bold>8</bold></highlight>. If all the bits are 0, the procedure goes to a step S<highlight><bold>27</bold></highlight>-<highlight><bold>9</bold></highlight>. Otherwise, the procedure ends with an error report. </paragraph>
<paragraph id="P-0255" lvl="0"><number>&lsqb;0255&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>8</bold></highlight>, a bit-wise OR operation is performed between the mask MASK and the datum x&lsqb;j&rsqb;, and an obtained result is substituted for x&lsqb;j&rsqb;. </paragraph>
<paragraph id="P-0256" lvl="0"><number>&lsqb;0256&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>9</bold></highlight>, a check is made whether the loop based on the variable i is repeated Kr times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0257" lvl="0"><number>&lsqb;0257&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>10</bold></highlight>, a check is made whether the loop based on the variable j is repeated Nr/Kr times. </paragraph>
<paragraph id="P-0258" lvl="7"><number>&lsqb;0258&rsqb;</number> If it is, the loop is ended. </paragraph>
<paragraph id="P-0259" lvl="0"><number>&lsqb;0259&rsqb;</number> At a step S<highlight><bold>27</bold></highlight>-<highlight><bold>11</bold></highlight>, Nr/Kr data x&lsqb;i&rsqb; are obtained. Each datum x&lsqb;i&rsqb; is comprised of Kr bits. Each datum x&lsqb;i&rsqb; is compared with the predetermined key code to allow the host computer to check whether an attempted switch has actually taken effect. </paragraph>
<paragraph id="P-0260" lvl="0"><number>&lsqb;0260&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 28</cross-reference> is an illustrative drawing for explaining a key comparison which is made based on the number of 0s or 1s so as to nullify the effect of the bit-position shuffling. Counting the numbers of 0s and 1s included in a data word shown in the figure finds that there are fourteen 0s and eighteen 1s. The numbers of 0s and 1s included in a data word do not change whatever bit-position shuffling takes place through the memory interface. The numbers of 0s and 1s thus can be used as data for a key comparison. </paragraph>
<paragraph id="P-0261" lvl="0"><number>&lsqb;0261&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 29</cross-reference> is a flowchart of a process of counting the number of is included in each data word when a plurality of data words are provided. </paragraph>
<paragraph id="P-0262" lvl="0"><number>&lsqb;0262&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>1</bold></highlight>, Lw data x&lsqb;i&rsqb; (i&equals;1, . . . , Lw) are provided. Here, each datum x&lsqb;i&rsqb; is comprised of Kw bits. </paragraph>
<paragraph id="P-0263" lvl="0"><number>&lsqb;0263&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>2</bold></highlight>, a mask MASK comprised of Kw bits is created. Only the least significant bit of the mask MASK is 1, and other bits are 0. </paragraph>
<paragraph id="P-0264" lvl="0"><number>&lsqb;0264&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>3</bold></highlight>, a loop repeating Lw times based on a variable j is started. </paragraph>
<paragraph id="P-0265" lvl="0"><number>&lsqb;0265&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>4</bold></highlight>, y&lsqb;j&rsqb; is set to zero, and a variable temp is set equal to x&lsqb;j&rsqb;. </paragraph>
<paragraph id="P-0266" lvl="0"><number>&lsqb;0266&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>5</bold></highlight>, a loop repeating Kw times based on a variable i is started. </paragraph>
<paragraph id="P-0267" lvl="0"><number>&lsqb;0267&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>6</bold></highlight>, a bit-wise AND operation is performed between the variable temp and the mask MASK. If the resulting value is 0, the procedure skips a step S<highlight><bold>29</bold></highlight>-<highlight><bold>7</bold></highlight>. If the resulting value is equal to the mask MASK, the procedure goes to the step S<highlight><bold>29</bold></highlight>-<highlight><bold>7</bold></highlight>. </paragraph>
<paragraph id="P-0268" lvl="0"><number>&lsqb;0268&rsqb;</number> At </paragraph>
<paragraph id="P-0269" lvl="0"><number>&lsqb;0269&rsqb;</number> the step S<highlight><bold>29</bold></highlight>-<highlight><bold>7</bold></highlight>, y&lsqb;j&rsqb; is incremented by 1. </paragraph>
<paragraph id="P-0270" lvl="0"><number>&lsqb;0270&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>8</bold></highlight>, the variable temp is shifted to the right by one bit. </paragraph>
<paragraph id="P-0271" lvl="0"><number>&lsqb;0271&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>9</bold></highlight>, a check is made whether the loop based on the variable i is repeated Kw times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0272" lvl="0"><number>&lsqb;0272&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>10</bold></highlight>, a check is made whether the loop based on the variable j is repeated Lw times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0273" lvl="0"><number>&lsqb;0273&rsqb;</number> At a step S<highlight><bold>29</bold></highlight>-<highlight><bold>11</bold></highlight>, Lw data y&lsqb;j&rsqb; (j&equals;1, . . . , Lw) are obtained. Namely, when a plurality of data words x is provided, the number of 1s included in each data word is counted to generate data y representing the numbers of 1s. </paragraph>
<paragraph id="P-0274" lvl="0"><number>&lsqb;0274&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 30</cross-reference> is a flowchart of a process of generating a plurality of data words such that the number of is included in a given data word is equal to a number that is represented by a corresponding input data word when a plurality of input data words are supplied. </paragraph>
<paragraph id="P-0275" lvl="0"><number>&lsqb;0275&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 30</cross-reference> is a flowchart of a process of extracting a key code from data that is read. </paragraph>
<paragraph id="P-0276" lvl="0"><number>&lsqb;0276&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>1</bold></highlight>, Nr data y&lsqb;i&rsqb; (i&equals;1, . . . , Nr) are supplied. Here, each datum y&lsqb;i&rsqb; is comprised of Mr bits. </paragraph>
<paragraph id="P-0277" lvl="0"><number>&lsqb;0277&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>2</bold></highlight>, a mask MASK which is comprised of Mr bits having a value of 1 only in the least significant bit is created. </paragraph>
<paragraph id="P-0278" lvl="0"><number>&lsqb;0278&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>3</bold></highlight>, a loop repeating Nr times based on a variable j is started. </paragraph>
<paragraph id="P-0279" lvl="0"><number>&lsqb;0279&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>4</bold></highlight>, x&lsqb;j&rsqb; is set to zero. </paragraph>
<paragraph id="P-0280" lvl="0"><number>&lsqb;0280&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>5</bold></highlight>, a loop repeating Kr times based on a variable i is started. </paragraph>
<paragraph id="P-0281" lvl="0"><number>&lsqb;0281&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>6</bold></highlight>, x&lsqb;j&rsqb; is shifted to the left by one bit. </paragraph>
<paragraph id="P-0282" lvl="0"><number>&lsqb;0282&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>7</bold></highlight>, a check is made whether the variable i is smaller than y&lsqb;j&rsqb;. If it is not, the procedure skips a step S<highlight><bold>30</bold></highlight>-<highlight><bold>8</bold></highlight>. Otherwise, the procedure goes to the step S<highlight><bold>30</bold></highlight>-<highlight><bold>8</bold></highlight>. </paragraph>
<paragraph id="P-0283" lvl="0"><number>&lsqb;0283&rsqb;</number> At the step S<highlight><bold>30</bold></highlight>-<highlight><bold>8</bold></highlight>, a bit-wise OR operation is performed between the mask MASK and the datum x&lsqb;j&rsqb;, and an obtained result is substituted for x&lsqb;j&rsqb;. </paragraph>
<paragraph id="P-0284" lvl="0"><number>&lsqb;0284&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>9</bold></highlight>, a check is made whether the loop based on the variable i is repeated Kr times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0285" lvl="0"><number>&lsqb;0285&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>10</bold></highlight>, a check is made whether the loop based on the variable j is repeated Nr times. If it is, the loop is ended. </paragraph>
<paragraph id="P-0286" lvl="0"><number>&lsqb;0286&rsqb;</number> At a step S<highlight><bold>30</bold></highlight>-<highlight><bold>11</bold></highlight>, Nr data x&lsqb;j&rsqb; (j&equals;1, . . . , Nr) are obtained. Each datum x&lsqb;j&rsqb; is comprised of Kr bits, in which y&lsqb;j&rsqb; bits are 1 and remaining bits are 0. Namely, a plurality of data words x are obtained such that the number of is included in a given data word x is equal to a number that is represented by a corresponding data word y when a plurality of data words y are supplied. </paragraph>
<paragraph id="P-0287" lvl="0"><number>&lsqb;0287&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 31</cross-reference> is a flowchart of a variation of the switching process based on a key comparison. </paragraph>
<paragraph id="P-0288" lvl="0"><number>&lsqb;0288&rsqb;</number> As previously described, a plurality of key data may be written in the memory space and compared with a plurality of key codes, so as to achieve a highly reliable verification (i.e., verification of a switch request) excluding a possibility of a coincidental match. A reliability of the verification can be further enhanced by checking the number of write operations and the number of read operations in addition to the checking of key information. </paragraph>
<paragraph id="P-0289" lvl="0"><number>&lsqb;0289&rsqb;</number> At a step S<highlight><bold>31</bold></highlight>-<highlight><bold>1</bold></highlight>, a loop repeating N times is started. </paragraph>
<paragraph id="P-0290" lvl="0"><number>&lsqb;0290&rsqb;</number> At a step S<highlight><bold>31</bold></highlight>-<highlight><bold>2</bold></highlight>, a check is made whether a write operation for writing key data has been conducted exactly Wi times. If it has, the procedure goes to a step S<highlight><bold>31</bold></highlight>-<highlight><bold>3</bold></highlight>. Otherwise, the procedure goes to a step S<highlight><bold>31</bold></highlight>-<highlight><bold>7</bold></highlight>. </paragraph>
<paragraph id="P-0291" lvl="0"><number>&lsqb;0291&rsqb;</number> At the step S<highlight><bold>31</bold></highlight>-<highlight><bold>3</bold></highlight>, a check is made whether all of Wi key data match corresponding key codes. If they do, the procedure goes to a step S<highlight><bold>31</bold></highlight>-<highlight><bold>4</bold></highlight>. Otherwise, the procedure goes to the step S<highlight><bold>31</bold></highlight>-<highlight><bold>7</bold></highlight>. </paragraph>
<paragraph id="P-0292" lvl="0"><number>&lsqb;0292&rsqb;</number> At the step S<highlight><bold>31</bold></highlight>-<highlight><bold>4</bold></highlight>, a check is made whether the number of read operations conducted for reading data is Ri. If it is, the procedure goes to a step S<highlight><bold>31</bold></highlight>-<highlight><bold>5</bold></highlight>. Otherwise, the procedure goes to the step S<highlight><bold>317</bold></highlight>. Here, the read operations mean reading some data from a predetermined address. All that matters here is only the number of executed read instructions, and the contents of data obtained through the read operations are irrelevant with regard to this verification operation. Only the counted number is used in the verification process. </paragraph>
<paragraph id="P-0293" lvl="0"><number>&lsqb;0293&rsqb;</number> At the step S<highlight><bold>31</bold></highlight>-<highlight><bold>5</bold></highlight>, the loop having repeated N times is finished. </paragraph>
<paragraph id="P-0294" lvl="0"><number>&lsqb;0294&rsqb;</number> At a step S<highlight><bold>31</bold></highlight>-<highlight><bold>6</bold></highlight>, it is ascertained that the verification has given a positive result. </paragraph>
<paragraph id="P-0295" lvl="0"><number>&lsqb;0295&rsqb;</number> At the step S<highlight><bold>31</bold></highlight>-<highlight><bold>7</bold></highlight>, it is ascertained that the verification has given a negative result. </paragraph>
<paragraph id="P-0296" lvl="0"><number>&lsqb;0296&rsqb;</number> In this manner, the number of data-read operations and the number of data-write operations are checked in addition to the check of key information so as to achieve a highly reliable verification, excluding a possibility of a coincidental match. </paragraph>
<paragraph id="P-0297" lvl="0"><number>&lsqb;0297&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 32</cross-reference> is a flowchart of another variation of the switching process based on a key comparison. </paragraph>
<paragraph id="P-0298" lvl="0"><number>&lsqb;0298&rsqb;</number> In the process of <cross-reference target="DRAWINGS">FIG. 32, a</cross-reference> check is made whether a predetermined pattern included in key data matches a verification pattern prior to the checking of key information. This process excludes cases in which no pattern match is obtained before conducting the check of key information, so that a verification process can be conducted at a higher speed. </paragraph>
<paragraph id="P-0299" lvl="0"><number>&lsqb;0299&rsqb;</number> At a step S<highlight><bold>32</bold></highlight>-<highlight><bold>1</bold></highlight>, key data is written. </paragraph>
<paragraph id="P-0300" lvl="0"><number>&lsqb;0300&rsqb;</number> At a step S<highlight><bold>32</bold></highlight>-<highlight><bold>2</bold></highlight>, a check is made whether a predetermined pattern in the key data matches a verification pattern. If it does, the procedure goes to a step S<highlight><bold>32</bold></highlight>-<highlight><bold>3</bold></highlight>. Otherwise, the procedure goes to a step S<highlight><bold>32</bold></highlight>-<highlight><bold>5</bold></highlight>. </paragraph>
<paragraph id="P-0301" lvl="0"><number>&lsqb;0301&rsqb;</number> At the step S<highlight><bold>32</bold></highlight>-<highlight><bold>3</bold></highlight>, a check is made whether a key match is found. If it is, the procedure goes to a step S<highlight><bold>32</bold></highlight>-<highlight><bold>4</bold></highlight>. Otherwise, the procedure goes to the step S<highlight><bold>32</bold></highlight>-<highlight><bold>5</bold></highlight>. </paragraph>
<paragraph id="P-0302" lvl="0"><number>&lsqb;0302&rsqb;</number> At the step S<highlight><bold>32</bold></highlight>-<highlight><bold>4</bold></highlight>, it is ascertained that the verification has given a positive result. </paragraph>
<paragraph id="P-0303" lvl="0"><number>&lsqb;0303&rsqb;</number> At the step S<highlight><bold>32</bold></highlight>-<highlight><bold>5</bold></highlight>, it is ascertained that the verification has given a negative result. </paragraph>
<paragraph id="P-0304" lvl="0"><number>&lsqb;0304&rsqb;</number> In this manner, a check is made whether a match is found for a predetermined pattern so as to exclude cases in which no pattern match is obtained before conducting the check of key information, so that a verification process can be conducted at a higher speed. </paragraph>
<paragraph id="P-0305" lvl="0"><number>&lsqb;0305&rsqb;</number> Here, the above-mentioned predetermined pattern may be a pattern which is included in a data word written as key data when the system does not shuffle bit positions. In systems in which bit positions are shuffled, the predetermined pattern may be a pattern which is contained in key data extracted from written data words, or may be a pattern which is contained in a data word itself. </paragraph>
<paragraph id="P-0306" lvl="0"><number>&lsqb;0306&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 33</cross-reference> is an illustrative drawing for explaining a pattern-check process in which parity is used as the predetermined pattern. </paragraph>
<paragraph id="P-0307" lvl="0"><number>&lsqb;0307&rsqb;</number> Counting the number of is included in a 32 bit data word of the figure reveals that there are eighteen is, and parity is even. If such a parity check is conducted prior to the check of key information, cases in which keys do not match can be quickly excluded in advance. </paragraph>
<paragraph id="P-0308" lvl="0"><number>&lsqb;0308&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 34</cross-reference> is a flowchart of a process of checking supplied data with regard to parity thereof. </paragraph>
<paragraph id="P-0309" lvl="0"><number>&lsqb;0309&rsqb;</number> At </paragraph>
<paragraph id="P-0310" lvl="0"><number>&lsqb;0310&rsqb;</number> a step S<highlight><bold>34</bold></highlight>-<highlight><bold>1</bold></highlight>, data x comprised of Kw bits is supplied. </paragraph>
<paragraph id="P-0311" lvl="0"><number>&lsqb;0311&rsqb;</number> At a step S<highlight><bold>34</bold></highlight>-<highlight><bold>2</bold></highlight>, a mask MASK which is comprised of Kw bits and has a value of 1 only at the least significant bit is created. </paragraph>
<paragraph id="P-0312" lvl="0"><number>&lsqb;0312&rsqb;</number> At a step S<highlight><bold>34</bold></highlight>-<highlight><bold>3</bold></highlight>, a variable y is set to zero. </paragraph>
<paragraph id="P-0313" lvl="0"><number>&lsqb;0313&rsqb;</number> At a step S<highlight><bold>34</bold></highlight>-<highlight><bold>4</bold></highlight>, a loop repeating Kw times based on a variable i is started. </paragraph>
<paragraph id="P-0314" lvl="0"><number>&lsqb;0314&rsqb;</number> At a step S<highlight><bold>34</bold></highlight>-<highlight><bold>5</bold></highlight>, an AND operation is performed between the mask MASK and the data x, and, further, an EXOR operation is taken between the result of the AND operation and the variable y. </paragraph>
<paragraph id="P-0315" lvl="0"><number>&lsqb;0315&rsqb;</number> At a step S<highlight><bold>34</bold></highlight>-<highlight><bold>6</bold></highlight>, the data x is shifted to the right by one bit. </paragraph>
<paragraph id="P-0316" lvl="0"><number>&lsqb;0316&rsqb;</number> At a step S<highlight><bold>34</bold></highlight>-<highlight><bold>7</bold></highlight>, the loop is ended when the above-procedure is repeated Kw times. </paragraph>
<paragraph id="P-0317" lvl="0"><number>&lsqb;0317&rsqb;</number> At a step S<highlight><bold>34</bold></highlight>-<highlight><bold>8</bold></highlight>, the variable y is checked. If the variable y is 0, the number of 1s in the data x is even. If the variable y is 1, the number of is in the data x is odd. </paragraph>
<paragraph id="P-0318" lvl="0"><number>&lsqb;0318&rsqb;</number> When a pattern check is to be made, even parity, for example, is used as a verification pattern. Namely, the procedure shown in the flowchart of <cross-reference target="DRAWINGS">FIG. 34</cross-reference> is performed with regard to data x, and it is ascertained that the predetermined pattern matches the verification pattern when the obtained result y shows even parity. </paragraph>
<paragraph id="P-0319" lvl="0"><number>&lsqb;0319&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 35</cross-reference> is an illustrative drawing for explaining a process of making a pattern check using a predetermined set of bits included in the data. </paragraph>
<paragraph id="P-0320" lvl="0"><number>&lsqb;0320&rsqb;</number> As shown in the figure, a plurality of bits are extracted from data at predetermined bit positions, and a set of these bits is to be used as the predetermined pattern for pattern check. If a check is made as to whether this pattern matches a verification pattern prior to the check of key information, cases in which keys do not match can be quickly excluded in advance. </paragraph>
<paragraph id="P-0321" lvl="0"><number>&lsqb;0321&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 36</cross-reference> is a flowchart of a method of extracting a predetermined set of bits from supplied data and using the predetermined set for pattern check. </paragraph>
<paragraph id="P-0322" lvl="0"><number>&lsqb;0322&rsqb;</number> At a step S<highlight><bold>36</bold></highlight>-<highlight><bold>1</bold></highlight>, data x comprised of K bits is supplied. Further, data CHK comprised of K bits used for check as well as a verification pattern PAT comprised of N bits are prepared. The data CHK has a bit value of 1 at predetermined bit positions, and has a bit value of 0 at other bit positions. The number of bits that are 1 is N. </paragraph>
<paragraph id="P-0323" lvl="0"><number>&lsqb;0323&rsqb;</number> At a step S<highlight><bold>36</bold></highlight>-<highlight><bold>2</bold></highlight>, a mask MASK which is comprised of K bits and only the least significant bit thereof is 1 is created. </paragraph>
<paragraph id="P-0324" lvl="0"><number>&lsqb;0324&rsqb;</number> At a step S<highlight><bold>36</bold></highlight>-<highlight><bold>3</bold></highlight>, data y is set to zero. </paragraph>
<paragraph id="P-0325" lvl="0"><number>&lsqb;0325&rsqb;</number> At a step S<highlight><bold>36</bold></highlight>-<highlight><bold>4</bold></highlight>, a loop repeating K times based on a variable i is started. </paragraph>
<paragraph id="P-0326" lvl="0"><number>&lsqb;0326&rsqb;</number> At a step S<highlight><bold>36</bold></highlight>-<highlight><bold>5</bold></highlight>, a check is made whether an AND operation between the mask MASK and the data CHK produces a result of 1 or a result of 0. If the result is 1, the procedure goes to a step S<highlight><bold>36</bold></highlight>-<highlight><bold>6</bold></highlight>. If the result is 0, the procedure goes to a step S<highlight><bold>36</bold></highlight>-<highlight><bold>8</bold></highlight>. </paragraph>
<paragraph id="P-0327" lvl="0"><number>&lsqb;0327&rsqb;</number> At a step S<highlight><bold>36</bold></highlight>-<highlight><bold>6</bold></highlight>, a check is made whether an AND operation between the mask MASK and the data x produces the same result as an AND operation between the mask MASK and the verification pattern PAT. If it does, the procedure goes to a step S<highlight><bold>36</bold></highlight>-<highlight><bold>7</bold></highlight>. Otherwise, the procedure goes to a step S<highlight><bold>36</bold></highlight>-<highlight><bold>11</bold></highlight>. </paragraph>
<paragraph id="P-0328" lvl="0"><number>&lsqb;0328&rsqb;</number> At the step S<highlight><bold>36</bold></highlight>-<highlight><bold>7</bold></highlight>, the verification pattern PAT is shifted to the right by one bit. </paragraph>
<paragraph id="P-0329" lvl="0"><number>&lsqb;0329&rsqb;</number> At a step S<highlight><bold>36</bold></highlight>-<highlight><bold>8</bold></highlight>, the data CHK and the data x are shifted to the right by one bit. </paragraph>
<paragraph id="P-0330" lvl="0"><number>&lsqb;0330&rsqb;</number> At a step S<highlight><bold>36</bold></highlight>-<highlight><bold>9</bold></highlight>, the loop based on the variable i is ended when the loop is repeated K times. </paragraph>
<paragraph id="P-0331" lvl="0"><number>&lsqb;0331&rsqb;</number> At a step S<highlight><bold>36</bold></highlight>-<highlight><bold>10</bold></highlight>, it is ascertained that a pattern match is found. </paragraph>
<paragraph id="P-0332" lvl="0"><number>&lsqb;0332&rsqb;</number> At the step S<highlight><bold>36</bold></highlight>-<highlight><bold>11</bold></highlight>, it is ascertained that no pattern match is found. </paragraph>
<paragraph id="P-0333" lvl="0"><number>&lsqb;0333&rsqb;</number> In this manner, a comparison can be made between the verification pattern and a set of bits provided at predetermined bit positions of the data x. </paragraph>
<paragraph id="P-0334" lvl="0"><number>&lsqb;0334&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 37</cross-reference> is an illustrative drawing for explaining a pattern-check process which is performed based on whether a supplied data word is comprised of a predetermined pattern. </paragraph>
<paragraph id="P-0335" lvl="0"><number>&lsqb;0335&rsqb;</number> Taken as an example here is a case in which, as shown in <cross-reference target="DRAWINGS">FIG. 25</cross-reference>A, data words either comprised of Os or comprised of is define a time series which is to be used for a key comparison. As shown in <cross-reference target="DRAWINGS">FIG. 37, a</cross-reference> pattern check is readily performed by checking whether or not a given data word has all bits thereof comprised of the same bits which are either 0 or 1. Namely, if all bits are comprised of the same bits, a positive. verification is obtained. If all bits are not comprised of the same bits, the verification process rejects demand for the switch. If this pattern check is performed prior to a key comparison, cases in which keys do not match can be excluded in advance. </paragraph>
<paragraph id="P-0336" lvl="0"><number>&lsqb;0336&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 38</cross-reference> is a flowchart of a process of checking whether a supplied data word is comprised of 0s or comprised of 1s. </paragraph>
<paragraph id="P-0337" lvl="0"><number>&lsqb;0337&rsqb;</number> At a step S<highlight><bold>38</bold></highlight>-<highlight><bold>1</bold></highlight>, datum x comprised of K bits is supplied. </paragraph>
<paragraph id="P-0338" lvl="0"><number>&lsqb;0338&rsqb;</number> At a step S<highlight><bold>38</bold></highlight>-<highlight><bold>2</bold></highlight>, a mask MASK which is comprised of K bits and has a bit value of 1 only at the least significant bit thereof is created. </paragraph>
<paragraph id="P-0339" lvl="0"><number>&lsqb;0339&rsqb;</number> At a step S<highlight><bold>38</bold></highlight>-<highlight><bold>3</bold></highlight>, datum y is set to 1, and datum z is set to 0. </paragraph>
<paragraph id="P-0340" lvl="0"><number>&lsqb;0340&rsqb;</number> At a step S<highlight><bold>38</bold></highlight>-<highlight><bold>4</bold></highlight>, a loop repeating K times based on a variable i is started. </paragraph>
<paragraph id="P-0341" lvl="0"><number>&lsqb;0341&rsqb;</number> At a step S<highlight><bold>38</bold></highlight>-<highlight><bold>5</bold></highlight>, an AND operation is taken between the mask MASK and the datum x, and a further AND operation is taken between the result of the AND operation and the datum y. The obtained result is substituted for the datum y. </paragraph>
<paragraph id="P-0342" lvl="0"><number>&lsqb;0342&rsqb;</number> At a step S<highlight><bold>38</bold></highlight>-<highlight><bold>6</bold></highlight>, an AND operation is taken between the mask MASK and the datum x, and, further, an OR operation is taken between the result of the AND operation and the datum z. The obtained result is substituted for the datum z. </paragraph>
<paragraph id="P-0343" lvl="0"><number>&lsqb;0343&rsqb;</number> At the step S<highlight><bold>38</bold></highlight>-<highlight><bold>7</bold></highlight>, the datum x is shifted to the right by one bit. </paragraph>
<paragraph id="P-0344" lvl="0"><number>&lsqb;0344&rsqb;</number> At a step S<highlight><bold>38</bold></highlight>-<highlight><bold>8</bold></highlight>, the loop based on the variable i is ended when the loop is repeated K times. </paragraph>
<paragraph id="P-0345" lvl="0"><number>&lsqb;0345&rsqb;</number> At a step S<highlight><bold>38</bold></highlight>-<highlight><bold>9</bold></highlight>, a value of the datum y and a value of the datum z are checked. If both values are 0 or both values are 1, the procedure goes to a step S<highlight><bold>38</bold></highlight>-<highlight><bold>10</bold></highlight>. Otherwise, the procedure goes to a step S<highlight><bold>38</bold></highlight>-<highlight><bold>11</bold></highlight>. </paragraph>
<paragraph id="P-0346" lvl="0"><number>&lsqb;0346&rsqb;</number> At a step S<highlight><bold>38</bold></highlight>-<highlight><bold>10</bold></highlight>, it is ascertained that a pattern match is found. </paragraph>
<paragraph id="P-0347" lvl="0"><number>&lsqb;0347&rsqb;</number> At the step S<highlight><bold>38</bold></highlight>-<highlight><bold>11</bold></highlight>, it is ascertained that no pattern match is found. </paragraph>
<paragraph id="P-0348" lvl="0"><number>&lsqb;0348&rsqb;</number> In this manner, a check is made as to whether or not all the bits of the datum x are comprised of the same bits of either Os or is. That is, a comparison with a verification pattern is made. </paragraph>
<paragraph id="P-0349" lvl="0"><number>&lsqb;0349&rsqb;</number> In what follows, a description will be given with regard to a process of allocating a memory area which becomes necessary when the host processor controls the client processor. When an attempt is made to allocate a memory area to the client processor, an area usable by the client processor might be already occupied by another application process. In this case, reallocation of memory areas is necessary in order to provide a memory area for the client processor. </paragraph>
<paragraph id="P-0350" lvl="0"><number>&lsqb;0350&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 39</cross-reference> is a flowchart of a process of acquiring a memory area by means of OS (operation system) functions of the host processor. </paragraph>
<paragraph id="P-0351" lvl="0"><number>&lsqb;0351&rsqb;</number> At a step S<highlight><bold>39</bold></highlight>-<highlight><bold>1</bold></highlight>, a check is made whether an area usable by the client processor has space to accommodate another process. If there is space, the procedure goes to a step S<highlight><bold>39</bold></highlight>-<highlight><bold>6</bold></highlight>. Otherwise, the procedure goes to a step S<highlight><bold>39</bold></highlight>-<highlight><bold>2</bold></highlight>. </paragraph>
<paragraph id="P-0352" lvl="0"><number>&lsqb;0352&rsqb;</number> At the step S<highlight><bold>39</bold></highlight>-<highlight><bold>2</bold></highlight>, a search is made for applications which are currently using the client processor area. </paragraph>
<paragraph id="P-0353" lvl="0"><number>&lsqb;0353&rsqb;</number> At a step S<highlight><bold>39</bold></highlight>-<highlight><bold>3</bold></highlight>, a check is made whether it is possible to obtain another area for accommodating the applications currently occupying the client processor area. If it is, the procedure goes to a step S<highlight><bold>39</bold></highlight>-<highlight><bold>5</bold></highlight>. Otherwise, the procedure goes to a step S<highlight><bold>39</bold></highlight>-<highlight><bold>4</bold></highlight>. </paragraph>
<paragraph id="P-0354" lvl="0"><number>&lsqb;0354&rsqb;</number> At the step S<highlight><bold>39</bold></highlight>-<highlight><bold>4</bold></highlight>, an application having a low priority order is swapped out. </paragraph>
<paragraph id="P-0355" lvl="0"><number>&lsqb;0355&rsqb;</number> At the step S<highlight><bold>39</bold></highlight>-<highlight><bold>5</bold></highlight>, an area is obtained for accommodating an application which is currently using the client processor area, and the application is reallocated to the newly obtained area. </paragraph>
<paragraph id="P-0356" lvl="0"><number>&lsqb;0356&rsqb;</number> At the step S<highlight><bold>39</bold></highlight>-<highlight><bold>6</bold></highlight>, the client processor is allocated to the created vacant area. </paragraph>
<paragraph id="P-0357" lvl="0"><number>&lsqb;0357&rsqb;</number> In this manner, reallocation of the client processor area is attended to by means of OS functions of the host processor. </paragraph>
<paragraph id="P-0358" lvl="0"><number>&lsqb;0358&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 40</cross-reference> is a block diagram of a system in which control of allocating memory areas and control of switching applications are carried out independently from each other. </paragraph>
<paragraph id="P-0359" lvl="0"><number>&lsqb;0359&rsqb;</number> A system of <cross-reference target="DRAWINGS">FIG. 40</cross-reference> includes a host processor <highlight><bold>201</bold></highlight>, a client processor <highlight><bold>202</bold></highlight>, a main memory <highlight><bold>203</bold></highlight>, a switch <highlight><bold>204</bold></highlight>, a switch <highlight><bold>205</bold></highlight>, an address bus <highlight><bold>206</bold></highlight>, and a data bus <highlight><bold>207</bold></highlight>. </paragraph>
<paragraph id="P-0360" lvl="0"><number>&lsqb;0360&rsqb;</number> The host processor <highlight><bold>201</bold></highlight> allocates a client processor area to the memory space of the main memory <highlight><bold>203</bold></highlight>, and controls the allocated area. </paragraph>
<paragraph id="P-0361" lvl="0"><number>&lsqb;0361&rsqb;</number> The client processor <highlight><bold>202</bold></highlight> exchanges data with the host processor <highlight><bold>201</bold></highlight> through an interface established in the memory space of the main memory <highlight><bold>203</bold></highlight>. </paragraph>
<paragraph id="P-0362" lvl="0"><number>&lsqb;0362&rsqb;</number> The main memory <highlight><bold>203</bold></highlight> is a work memory directly connected to the host processor <highlight><bold>201</bold></highlight>. </paragraph>
<paragraph id="P-0363" lvl="0"><number>&lsqb;0363&rsqb;</number> The client processor <highlight><bold>202</bold></highlight> includes a processor <highlight><bold>210</bold></highlight>, a memory <highlight><bold>211</bold></highlight>, a memory-allocation circuit <highlight><bold>212</bold></highlight>, an address-comparison circuit <highlight><bold>213</bold></highlight>, a processor-RST register <highlight><bold>214</bold></highlight>, and a memory-allocation-RST register <highlight><bold>215</bold></highlight>. </paragraph>
<paragraph id="P-0364" lvl="0"><number>&lsqb;0364&rsqb;</number> The host processor <highlight><bold>201</bold></highlight> writes control information and data in an area which the host processor <highlight><bold>201</bold></highlight> allocated in the memory space. In response, the processor <highlight><bold>210</bold></highlight> receives the control information and the data to attend to data processing. Data obtained as a result of the processing is written in the memory <highlight><bold>211</bold></highlight>, and is passed to the host processor <highlight><bold>201</bold></highlight>. </paragraph>
<paragraph id="P-0365" lvl="2"><number>&lsqb;0365&rsqb;</number> The memory <highlight><bold>211</bold></highlight> provides a memory space which overlaps the main memory space of the main memory <highlight><bold>203</bold></highlight>. The memory space of the memory <highlight><bold>211</bold></highlight> is allocated to an address space of the processor <highlight><bold>210</bold></highlight>. Through this allocated memory space, the host processor <highlight><bold>201</bold></highlight> and the client processor <highlight><bold>202</bold></highlight> can communicate with each other. </paragraph>
<paragraph id="P-0366" lvl="0"><number>&lsqb;0366&rsqb;</number> The memory-allocation circuit <highlight><bold>212</bold></highlight> operates when the client processor <highlight><bold>202</bold></highlight> is not allocated to the main memory, and monitors an access request which is sent from the host processor <highlight><bold>201</bold></highlight>. The memory-allocation circuit <highlight><bold>212</bold></highlight> learns which portion of the main memory should be allocated to the client processor <highlight><bold>202</bold></highlight> when a predetermined access of a special kind (e.g., an access by key information) is attempted, and, then, allocates the client processor <highlight><bold>202</bold></highlight> to this portion of the memory space. </paragraph>
<paragraph id="P-0367" lvl="0"><number>&lsqb;0367&rsqb;</number> The address-comparison circuit <highlight><bold>213</bold></highlight> operates after the client processor <highlight><bold>202</bold></highlight> is allocated to the main memory. The address-comparison circuit <highlight><bold>213</bold></highlight> checks whether an access from the host processor <highlight><bold>201</bold></highlight> is directed to the client processor area, an address of which is kept in the memory-allocation circuit <highlight><bold>212</bold></highlight>. </paragraph>
<paragraph id="P-0368" lvl="0"><number>&lsqb;0368&rsqb;</number> The processor-RST register <highlight><bold>214</bold></highlight> is used for resetting the processor <highlight><bold>210</bold></highlight>. When an ASSERT signal is sent to the processor-RST register <highlight><bold>214</bold></highlight>, the client processor <highlight><bold>202</bold></highlight> is initialized. A new application program is loaded into the memory <highlight><bold>211</bold></highlight> from the host processor <highlight><bold>201</bold></highlight> during a reset-ASSERT period, so that a switch to the new application can be made after a reset-NEGATE signal. </paragraph>
<paragraph id="P-0369" lvl="0"><number>&lsqb;0369&rsqb;</number> The memory-allocation-RST register <highlight><bold>215</bold></highlight> is used for resetting allocation of the client processor <highlight><bold>202</bold></highlight> to the main memory space. When an ASSERT signal is sent to the memory-allocation-RST register <highlight><bold>215</bold></highlight>, the memory-allocation circuit <highlight><bold>212</bold></highlight>, which has allocated the client processor <highlight><bold>202</bold></highlight> to the main memory, is reset. An area where the client processor <highlight><bold>202</bold></highlight> is allocated is changed from an address space A to an address space B, for example as shown in <cross-reference target="DRAWINGS">FIG. 40</cross-reference>, during a reset-ASSERT period. By doing so, communication between the host processor <highlight><bold>201</bold></highlight> and the client processor <highlight><bold>202</bold></highlight> can be conducted using a newly allocated area in the main memory after a reset-NEGATE signal. In this manner, reallocation of a memory area can be carried out in real-time so as to rearrange the main memory area in a manner convenient to the host processor <highlight><bold>201</bold></highlight>. </paragraph>
<paragraph id="P-0370" lvl="0"><number>&lsqb;0370&rsqb;</number> The switches <highlight><bold>204</bold></highlight> and <highlight><bold>205</bold></highlight> are provided between the data bus <highlight><bold>207</bold></highlight> and one of the client processor <highlight><bold>202</bold></highlight> and the main memory <highlight><bold>203</bold></highlight>, respectively, and is controlled by the memory-allocation circuit <highlight><bold>212</bold></highlight> of the client processor <highlight><bold>202</bold></highlight>. A switch between the main memory <highlight><bold>203</bold></highlight> and the client processor <highlight><bold>202</bold></highlight> is made by using the switches <highlight><bold>204</bold></highlight> and <highlight><bold>205</bold></highlight> with respect to the host processor <highlight><bold>201</bold></highlight>. </paragraph>
<paragraph id="P-0371" lvl="0"><number>&lsqb;0371&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 41</cross-reference> is a flowchart showing an example of a process of controlling memory allocation and switching applications in the system of <cross-reference target="DRAWINGS">FIG. 40</cross-reference>. </paragraph>
<paragraph id="P-0372" lvl="0"><number>&lsqb;0372&rsqb;</number> At steps S<highlight><bold>41</bold></highlight>-<highlight><bold>1</bold></highlight> through S<highlight><bold>41</bold></highlight>-<highlight><bold>7</bold></highlight>, the memory <highlight><bold>211</bold></highlight> is allocated to the main-memory address space A during a period when the memory-allocation-RST register <highlight><bold>215</bold></highlight> is provided with an ASSERT signal, and a program and data of an application A are loaded while the processor-RST register <highlight><bold>214</bold></highlight> is receiving an ASSERT signal. In this manner, a memory area is allocated to the application A, and data processing can now commence. </paragraph>
<paragraph id="P-0373" lvl="0"><number>&lsqb;0373&rsqb;</number> At steps S<highlight><bold>41</bold></highlight>-<highlight><bold>8</bold></highlight> through S<highlight><bold>41</bold></highlight>-<highlight><bold>12</bold></highlight>, a program and data of an application B are loaded while the processor-RST register <highlight><bold>214</bold></highlight> is provided with an ASSERT signal. In this manner, a switch from the application A to the application B can be carried out while the allocated memory area is retained. </paragraph>
<paragraph id="P-0374" lvl="0"><number>&lsqb;0374&rsqb;</number> At steps S<highlight><bold>41</bold></highlight>-<highlight><bold>13</bold></highlight> through S<highlight><bold>41</bold></highlight>-<highlight><bold>16</bold></highlight>, the memory <highlight><bold>211</bold></highlight> is allocated to the main-memory address space B while the memory-allocation-RST register <highlight><bold>215</bold></highlight> is provided with an ASSERT signal. In this manner, the client processor <highlight><bold>202</bold></highlight> can be reallocated to another memory area which is convenient to the host processor <highlight><bold>201</bold></highlight> without initializing the application process. </paragraph>
<paragraph id="P-0375" lvl="0"><number>&lsqb;0375&rsqb;</number> As described above, the processor-RST register <highlight><bold>214</bold></highlight> for initializing the processor <highlight><bold>210</bold></highlight> of the client processor <highlight><bold>202</bold></highlight> and the memory-allocation-RST register <highlight><bold>215</bold></highlight> for initializing the memory-allocation circuit <highlight><bold>212</bold></highlight> are separately provided, so that the allocation of a memory area and the switching of applications can be conducted independently from each other. </paragraph>
<paragraph id="P-0376" lvl="0"><number>&lsqb;0376&rsqb;</number> In what follows, a description will be given with regard to a process of establishing synchronization between client processors or between the host processor and a client processor when a plurality of client processors are provided. </paragraph>
<paragraph id="P-0377" lvl="0"><number>&lsqb;0377&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 42</cross-reference> is a block diagram of a system in which synchronization is established between client processors or between the host processor and a client processor. </paragraph>
<paragraph id="P-0378" lvl="0"><number>&lsqb;0378&rsqb;</number> The system of <cross-reference target="DRAWINGS">FIG. 42</cross-reference> includes a host processor <highlight><bold>301</bold></highlight> and a plurality of client processors <highlight><bold>302</bold></highlight>. The host processor <highlight><bold>301</bold></highlight> controls the client processors <highlight><bold>302</bold></highlight> allocated to a host-processor address space. </paragraph>
<paragraph id="P-0379" lvl="0"><number>&lsqb;0379&rsqb;</number> Each of the client processors <highlight><bold>302</bold></highlight> includes a processor <highlight><bold>310</bold></highlight>, a memory <highlight><bold>311</bold></highlight>, a start/stop resistor <highlight><bold>312</bold></highlight>, and a status register <highlight><bold>313</bold></highlight>. </paragraph>
<paragraph id="P-0380" lvl="0"><number>&lsqb;0380&rsqb;</number> The memory <highlight><bold>311</bold></highlight> is used as a venue to exchange data between the host processor <highlight><bold>301</bold></highlight> and the client processors <highlight><bold>302</bold></highlight>. </paragraph>
<paragraph id="P-0381" lvl="0"><number>&lsqb;0381&rsqb;</number> The host processor <highlight><bold>301</bold></highlight> writes control information and data in an area which the host processor <highlight><bold>301</bold></highlight> allocated in the memory space. In response, the processor <highlight><bold>310</bold></highlight> receives the control information and the data to attend to data processing. Data obtained as a result of the processing is written in the memory <highlight><bold>311</bold></highlight>, and is passed to the host processor <highlight><bold>301</bold></highlight>. </paragraph>
<paragraph id="P-0382" lvl="0"><number>&lsqb;0382&rsqb;</number> The start/stop resistor <highlight><bold>312</bold></highlight> stores information which indicates the start or stop of operations of the processor <highlight><bold>310</bold></highlight>. The start/stop resistor <highlight><bold>312</bold></highlight> is accessible for read/write operations from both the host processor <highlight><bold>301</bold></highlight> and the processor <highlight><bold>310</bold></highlight>. </paragraph>
<paragraph id="P-0383" lvl="0"><number>&lsqb;0383&rsqb;</number> The status register <highlight><bold>313</bold></highlight> is set in synchronism with the start/stop resistor <highlight><bold>312</bold></highlight>, and stores status information of the host processor <highlight><bold>301</bold></highlight> or status information of the client processor <highlight><bold>302</bold></highlight> at a time of the start or stop of operations of the client processor <highlight><bold>302</bold></highlight>. </paragraph>
<paragraph id="P-0384" lvl="0"><number>&lsqb;0384&rsqb;</number> Assume that an application <highlight><bold>1</bold></highlight> and an application <highlight><bold>2</bold></highlight> are performed by the two client processors <highlight><bold>302</bold></highlight>, respectively. In order to establish synchronization between the applications <highlight><bold>1</bold></highlight> and <highlight><bold>2</bold></highlight> by a unit of time or by a unit of processing, the host processor <highlight><bold>301</bold></highlight> simultaneously activates the two client processors <highlight><bold>302</bold></highlight> by referring to the start/stop resistor <highlight><bold>312</bold></highlight> and the status register <highlight><bold>313</bold></highlight> of the client processor <highlight><bold>302</bold></highlight>. In this manner, synchronization can be established between different applications. Use of these registers also makes it possible to achieve synchronized operations between the host processor <highlight><bold>301</bold></highlight> and the client processors <highlight><bold>302</bold></highlight>. </paragraph>
<paragraph id="P-0385" lvl="0"><number>&lsqb;0385&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 43A and 43B</cross-reference> are charts showing an example of synchronized operations between a host processor and a client processor. <cross-reference target="DRAWINGS">FIG. 43A</cross-reference> shows a timing chart of synchronized operations, and <cross-reference target="DRAWINGS">FIG. 43B</cross-reference> shows details of the synchronized operations of the host processor and the client processor. </paragraph>
<paragraph id="P-0386" lvl="0"><number>&lsqb;0386&rsqb;</number> In an example shown in <cross-reference target="DRAWINGS">FIGS. 43A and 43B</cross-reference>, data streams of video data VideoA, VideoB, and VideoC are supplied from an external network attached to the system, for example. The host processor <highlight><bold>301</bold></highlight> receives a video-synchronization signal Vsync. The host processor <highlight><bold>301</bold></highlight> controls the status of the video-synchronization signal Vsync by a unit of one frame, and activates a client processor <highlight><bold>302</bold></highlight>. In doing so, the host processor <highlight><bold>301</bold></highlight> controls the start/stop resistor <highlight><bold>312</bold></highlight> and the status register <highlight><bold>313</bold></highlight> of the client processor <highlight><bold>302</bold></highlight> in order to control the client processor <highlight><bold>302</bold></highlight> based on a start setting, a stop setting (i.e., processing status indicating completion of current data processing), an input status indicating whether data for next processing is received, etc. </paragraph>
<paragraph id="P-0387" lvl="0"><number>&lsqb;0387&rsqb;</number> <cross-reference target="DRAWINGS">FIGS. 44A and 44B</cross-reference> are charts showing an example of synchronized operations between client processors. <cross-reference target="DRAWINGS">FIG. 44A</cross-reference> shows a timing chart of synchronized operations, and <cross-reference target="DRAWINGS">FIG. 44B</cross-reference> shows details of the synchronized operations of the host processor and the client processors. </paragraph>
<paragraph id="P-0388" lvl="0"><number>&lsqb;0388&rsqb;</number> In an example shown in <cross-reference target="DRAWINGS">FIGS. 44A and 44B</cross-reference>, data streams of video data VideoA, VideoB, and VideoC are supplied from an external network attached to the system, for example, and, further, data streams of audio data AudioA through AudioI are supplied. One of the two client processors <highlight><bold>302</bold></highlight> attends to processing of the video data VideoA through VideoC, for example, and the other performs the processing of the audio data AudioA through AudioI. The host processor <highlight><bold>301</bold></highlight> controls the start/stop resistor <highlight><bold>312</bold></highlight> and the status register <highlight><bold>313</bold></highlight> of the client processor <highlight><bold>302</bold></highlight> by a unit of one video frame in order to control the client processor <highlight><bold>302</bold></highlight> based on a start setting, a stop setting (i.e., processing status indicating completion of current data processing), an input status indicating whether data for next processing is received, etc. </paragraph>
<paragraph id="P-0389" lvl="0"><number>&lsqb;0389&rsqb;</number> The signal processing described in the above embodiments according to the present invention is not limited to processing of image data or audio data, but can be applied to another type of signal processing such as conversion of communication protocols. </paragraph>
<paragraph id="P-0390" lvl="0"><number>&lsqb;0390&rsqb;</number> Further, the present invention is not limited to these embodiments, but variations and modifications may be made without departing from the scope of the present invention. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<heading lvl="1">What is claimed is: </heading>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. A computer program product for data processing using a plurality of information processing units which are connected in series via communication links and incorporated in a computer having a CPU and a bus, each of said information processing units being accessible as a memory by said CPU via said bus, said computer program product comprising: 
<claim-text>a computer usable medium providing program-code means for controlling said computer so as to cause said information processing units to carry out said data processing, said program-code means comprising: </claim-text>
<claim-text>first resource-management means for controlling process allocation to said information processing units and data connection between said information processing units in response to a request for said data processing from an application program; and </claim-text>
<claim-text>second resource-management means for controlling said information processing units to carry out said data processing according to said process allocation and said data connection, </claim-text>
<claim-text>wherein said first resource-management means resides in an application interface layer of software of said computer, and said second resource-management means resides in a device-driver layer of said software of-said computer. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The computer program product as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein said first resource-management means establishes parallel data connections between said information processing units such that said information processing units carry out parallel processing. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The computer program product as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein said first resource-management means establishes serial data connections between said information processing units such that said information processing units carry out a pipe-line operation by successively passing data from a given one of said information processing units to a next one of said information processing units. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The computer program product as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein said computer-code means further comprises virtual-machine means for detecting an interruption when said interruption is generated by said CPU executing said application program and for. handing an instruction causing said interruption in said application program to said first resource-management means, wherein said first resource-management means and said second resource-management means control said information processing units to execute said instruction. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The computer program product as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein said first resource-management means controls said process allocation so as to minimize a maximum amount of data transfer between said information processing units after said process allocation. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The computer program product as claimed in <dependent-claim-reference depends_on="CLM-00011">claim 14</dependent-claim-reference>, wherein said first resource-management means comprises: 
<claim-text>first process-allocation means for obtaining combinations of said information processing units for said process allocation such that a maximum amount of data transfer between said information processing units after said process allocation is minimized; and </claim-text>
<claim-text>second process-allocation means for selecting one of said combinations such that said information processing units remaining unallocated after said process allocation are provided in a range defined by as small a number of said communication links as possible. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. A software architecture comprising: 
<claim-text>an application layer in which application programs are provided; </claim-text>
<claim-text>an application interface layer in which dynamic loading libraries are provided to be dynamically loaded when said application programs are executed; </claim-text>
<claim-text>a device-driver layer in which device drivers are provided to control hardware devices corresponding to respective ones of said dynamic loading libraries; and </claim-text>
<claim-text>a resource-management program provided in said application interface layer and said device-driver layer, said resource-management program controlling a plurality of information processing elements implemented as a hardware device and controlling process allocation to said information processing elements and data connection between said information processing elements. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. A method of allocating a process to a plurality of information processing units connected in series via communication links so as to communicate with each other, said method comprising: 
<claim-text>obtaining combinations of said information processing units for process allocation such that a maximum amount of data transfer between said information processing units after said process allocation is minimized; and </claim-text>
<claim-text>selecting one of said combinations such that said information processing units remaining unallocated after said process allocation are provided in a range defined by as small a number of said communication links as possible. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. A method of controlling at least one client processor connected to a host processor having a main memory, said method comprising the steps of: 
<claim-text>a) accessing a memory space of said main memory from said host processor; and </claim-text>
<claim-text>b) allocating a portion of said memory space for use for communication between said host processor and said at least one client processor in response to said accessing. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further comprising a step of disconnecting said at least one client processor from said host processor by releasing said portion of said memory space in response to said accessing. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, wherein said accessing comprises a plurality of accesses which are made to a predetermined address. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, wherein said accessing comprises a plurality of accesses which are made within a predetermined range of addresses. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, wherein said step a) comprises a step of writing data including a key in said memory space, and said step b) comprises a step of allocating said portion of said memory space for said use for said communication when said key matches a predetermined key. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference>, wherein said step a) comprises a step of writing a data word including a plurality of identical sub-words in said memory space, each of said sub-words being said key. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference>, wherein said step a) comprises a step of writing data words in said memory space, said data words including data words comprised of only is and data words comprised of only 0s, said key being represented as a time series of is and Os each of which is taken from a corresponding one of said. data words. </claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference>, wherein said step a) comprises a step of writing data words in said memory space, said key being represented by one of a number of 1s and a number of Os included in each of said data words. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference>, wherein said step b) further comprises a step of counting a number of accesses of said accessing, and allocates said portion of, said memory space for said use for said communication when said number is a predetermined number. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference>, wherein said step b) further comprises a step of checking parity of said data and deciding that said key fails to match said predetermined key without actually checking said key when said parity fails to meet a predetermined parity condition. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 26</dependent-claim-reference>, wherein said step b) further comprises a step of checking a predetermined set of bits included in said data and deciding that said key fails to match said predetermined key without actually checking said key when said predetermined set of bits fails to match a predetermined bit pattern. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 28</dependent-claim-reference>, wherein said step b) further comprises a step of deciding that said key fails to match said predetermined key without actually checking said key when one of said data words is comprised of bits of. different values. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, wherein said step b) further comprises a step of allocating said at least one client processor to said portion of said memory space after moving an application to another portion of said memory space when said portion of said memory space is occupied by said application. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further comprising a step of controlling allocation of said portion of said memory space for said at least one client processor and allocation of an application to said at least one client processor independently from each other. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The method as claimed in <dependent-claim-reference depends_on="CLM-00022">claim 22</dependent-claim-reference>, further comprising a step of establishing synchronization between said host processor and said at least one client processor, and a step of establishing synchronization between a plurality of client processors inclusive of said at least one client processor. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. A machine readable medium having a program embodied therein for controlling at least one client processor connected to a host processor having a main memory, said program comprising: 
<claim-text>first program code means for accessing a memory space of said main memory from said host processor; and </claim-text>
<claim-text>second program code means for allocating a portion of said memory space for use for communication between said host processor and said at least one client processor in response to said accessing. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. The machine readable medium as claimed in claim <highlight><bold>37</bold></highlight>, further comprising a program code means for disconnecting said at least one client processor from said host processor by releasing said portion of said memory space in response to said-accessing. </claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The machine readable medium as claimed in claim <highlight><bold>37</bold></highlight>, wherein said second program code means further comprises program code means for allocating said at least one client processor to said portion of said memory space after moving an application to another portion of said memory space when said portion of said memory space is occupied by said application. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The machine readable medium as claimed in claim <highlight><bold>37</bold></highlight>, further comprising program code means for controlling allocation of said portion of said memory space for said at least one client processor and allocation of an application to said at least one client processor independently from each other. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The machine readable medium as claimed in claim <highlight><bold>37</bold></highlight>, further comprising program code means for establishing synchronization between said host processor and said at least one client processor, and a step of establishing synchronization between a plurality of client processors inclusive of said at least one client processor. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. A device for signal processing connected to a host processor through an external bus and comprising: 
<claim-text>information processing units comprising respective DRAMs coupled to the external bus, said information processing units connected to each other by a communication link and to each other and to the host processor by the external bus through the respective DRAMs, and said information processing units exchanging data with each other through the communication link and the respective DRAMs and processing data while exchanging data with the host processor through only the respective DRAMs.</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>1</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030005073A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030005073A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030005073A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030005073A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030005073A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030005073A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030005073A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030005073A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030005073A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030005073A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030005073A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00011">
<image id="EMI-D00011" file="US20030005073A1-20030102-D00011.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00012">
<image id="EMI-D00012" file="US20030005073A1-20030102-D00012.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00013">
<image id="EMI-D00013" file="US20030005073A1-20030102-D00013.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00014">
<image id="EMI-D00014" file="US20030005073A1-20030102-D00014.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00015">
<image id="EMI-D00015" file="US20030005073A1-20030102-D00015.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00016">
<image id="EMI-D00016" file="US20030005073A1-20030102-D00016.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00017">
<image id="EMI-D00017" file="US20030005073A1-20030102-D00017.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00018">
<image id="EMI-D00018" file="US20030005073A1-20030102-D00018.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00019">
<image id="EMI-D00019" file="US20030005073A1-20030102-D00019.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00020">
<image id="EMI-D00020" file="US20030005073A1-20030102-D00020.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00021">
<image id="EMI-D00021" file="US20030005073A1-20030102-D00021.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00022">
<image id="EMI-D00022" file="US20030005073A1-20030102-D00022.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00023">
<image id="EMI-D00023" file="US20030005073A1-20030102-D00023.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00024">
<image id="EMI-D00024" file="US20030005073A1-20030102-D00024.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00025">
<image id="EMI-D00025" file="US20030005073A1-20030102-D00025.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00026">
<image id="EMI-D00026" file="US20030005073A1-20030102-D00026.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00027">
<image id="EMI-D00027" file="US20030005073A1-20030102-D00027.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00028">
<image id="EMI-D00028" file="US20030005073A1-20030102-D00028.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00029">
<image id="EMI-D00029" file="US20030005073A1-20030102-D00029.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00030">
<image id="EMI-D00030" file="US20030005073A1-20030102-D00030.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00031">
<image id="EMI-D00031" file="US20030005073A1-20030102-D00031.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00032">
<image id="EMI-D00032" file="US20030005073A1-20030102-D00032.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00033">
<image id="EMI-D00033" file="US20030005073A1-20030102-D00033.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00034">
<image id="EMI-D00034" file="US20030005073A1-20030102-D00034.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00035">
<image id="EMI-D00035" file="US20030005073A1-20030102-D00035.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00036">
<image id="EMI-D00036" file="US20030005073A1-20030102-D00036.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00037">
<image id="EMI-D00037" file="US20030005073A1-20030102-D00037.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00038">
<image id="EMI-D00038" file="US20030005073A1-20030102-D00038.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00039">
<image id="EMI-D00039" file="US20030005073A1-20030102-D00039.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00040">
<image id="EMI-D00040" file="US20030005073A1-20030102-D00040.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00041">
<image id="EMI-D00041" file="US20030005073A1-20030102-D00041.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00042">
<image id="EMI-D00042" file="US20030005073A1-20030102-D00042.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00043">
<image id="EMI-D00043" file="US20030005073A1-20030102-D00043.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00044">
<image id="EMI-D00044" file="US20030005073A1-20030102-D00044.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
