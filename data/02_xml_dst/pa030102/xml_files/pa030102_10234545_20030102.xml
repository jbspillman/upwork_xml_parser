<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE patent-application-publication SYSTEM "pap-v16-2002-01-01.dtd" [
<!ENTITY US20030002584A1-20030102-D00000.TIF SYSTEM "US20030002584A1-20030102-D00000.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00001.TIF SYSTEM "US20030002584A1-20030102-D00001.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00002.TIF SYSTEM "US20030002584A1-20030102-D00002.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00003.TIF SYSTEM "US20030002584A1-20030102-D00003.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00004.TIF SYSTEM "US20030002584A1-20030102-D00004.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00005.TIF SYSTEM "US20030002584A1-20030102-D00005.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00006.TIF SYSTEM "US20030002584A1-20030102-D00006.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00007.TIF SYSTEM "US20030002584A1-20030102-D00007.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00008.TIF SYSTEM "US20030002584A1-20030102-D00008.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00009.TIF SYSTEM "US20030002584A1-20030102-D00009.TIF" NDATA TIF>
<!ENTITY US20030002584A1-20030102-D00010.TIF SYSTEM "US20030002584A1-20030102-D00010.TIF" NDATA TIF>
]>
<patent-application-publication>
<subdoc-bibliographic-information>
<document-id>
<doc-number>20030002584</doc-number>
<kind-code>A1</kind-code>
<document-date>20030102</document-date>
</document-id>
<publication-filing-type>new</publication-filing-type>
<domestic-filing-data>
<application-number>
<doc-number>10234545</doc-number>
</application-number>
<application-number-series-code>10</application-number-series-code>
<filing-date>20020904</filing-date>
</domestic-filing-data>
<technical-information>
<classification-ipc>
<classification-ipc-primary>
<ipc>H04N007/12</ipc>
</classification-ipc-primary>
<classification-ipc-edition>07</classification-ipc-edition>
</classification-ipc>
<classification-us>
<classification-us-primary>
<uspc>
<class>375</class>
<subclass>240210</subclass>
</uspc>
</classification-us-primary>
<classification-us-secondary>
<uspc>
<class>375</class>
<subclass>240250</subclass>
</uspc>
</classification-us-secondary>
</classification-us>
<title-of-invention>MPEG video decoder with integrated scaling and display functions</title-of-invention>
</technical-information>
<continuity-data>
<division-of>
<parent-child>
<child>
<document-id>
<doc-number>10234545</doc-number>
<kind-code>A1</kind-code>
<document-date>20020904</document-date>
</document-id>
</child>
<parent>
<document-id>
<doc-number>09237601</doc-number>
<document-date>19990125</document-date>
<country-code>US</country-code>
</document-id>
</parent>
<parent-status>GRANTED</parent-status>
<parent-patent>
<document-id>
<doc-number>6470051</doc-number>
<country-code>US</country-code>
</document-id>
</parent-patent>
</parent-child>
</division-of>
</continuity-data>
<inventors>
<first-named-inventor>
<name>
<given-name>Francesco</given-name>
<middle-name>A.</middle-name>
<family-name>Campisano</family-name>
</name>
<residence>
<residence-us>
<city>Owego</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</first-named-inventor>
<inventor>
<name>
<given-name>Dennis</given-name>
<middle-name>P.</middle-name>
<family-name>Cheney</family-name>
</name>
<residence>
<residence-us>
<city>Vestal</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>David</given-name>
<middle-name>A.</middle-name>
<family-name>Hrusecky</family-name>
</name>
<residence>
<residence-us>
<city>Johnson City</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Chuck</given-name>
<middle-name>H.</middle-name>
<family-name>Ngai</family-name>
</name>
<residence>
<residence-us>
<city>Endwell</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
<inventor>
<name>
<given-name>Ronald</given-name>
<middle-name>S.</middle-name>
<family-name>Svec</family-name>
</name>
<residence>
<residence-us>
<city>Berkshire</city>
<state>NY</state>
<country-code>US</country-code>
</residence-us>
</residence>
<authority-applicant>INV</authority-applicant>
</inventor>
</inventors>
<assignee>
<organization-name>INTERNATIONAL BUSINESS MACHINES CORPORATION</organization-name>
<address>
<city>ARMONK</city>
<state>NY</state>
<postalcode>10504</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
<assignee-type>02</assignee-type>
</assignee>
<correspondence-address>
<name-1>IBM Corporation</name-1>
<name-2>Dept. N50/Bldg. 40-4</name-2>
<address>
<address-1>1701 North Street</address-1>
<city>Endicott</city>
<state>NY</state>
<postalcode>13760</postalcode>
<country>
<country-code>US</country-code>
</country>
</address>
</correspondence-address>
</subdoc-bibliographic-information>
<subdoc-abstract>
<paragraph id="A-0001" lvl="0">A digital video decoder system, method and article of manufacture are provided having integrated scaling capabilities for presentation of video in full size or a predetermined reduced size, while at the same time allowing for reduced external memory requirements for frame buffer storage. The integrated system utilizes an existing decimation unit to scale the decoded stream of video data when the system is in scaled video mode. Display mode switch logic oversees switching between normal video mode and scaled video mode, wherein the switching occurs without perceptual degradation of a display of the decoded stream of video data. Scaled decoded video frames are buffered in a frame buffer which is partitioned depending upon whether the digital video decoding system is in normal video mode or scaled video mode. In scaled video mode, the frame buffer accommodates both full size I and P frames, as well as scaled I, P &amp; B frames. The full size I and P frames are used to support future decode operations, while the scaled I, P &amp; B frames are retrieved for display. </paragraph>
</subdoc-abstract>
<subdoc-description>
<summary-of-invention>
<section>
<heading lvl="1">CROSS-REFERENCE TO RELATED APPLICATIONS </heading>
<paragraph id="P-0001" lvl="0"><number>&lsqb;0001&rsqb;</number> This application contains subject matter which is related to the subject matter of the following United States patent applications, which are assigned to the same assignee of this application. Each of the below listed applications is hereby incorporated herein by reference: </paragraph>
<paragraph id="P-0002" lvl="2"><number>&lsqb;0002&rsqb;</number> &ldquo;Anti-Flicker Logic For MPEG Video Decoder With Integrated Scaling and Display Functions,&rdquo; by D. Hrusecky, co-filed herewith, Ser. No. ______, (attorney docket no. EN998143); </paragraph>
<paragraph id="P-0003" lvl="2"><number>&lsqb;0003&rsqb;</number> &ldquo;Multi-Format Reduced Memory MPEG-2 Compliant Decoder,&rdquo; by Cheney et al., Ser. No. 08/958,632; </paragraph>
<paragraph id="P-0004" lvl="2"><number>&lsqb;0004&rsqb;</number> &ldquo;Multi-Format Reduced Memory Video Decoder With Adjustable Polyphase Expansion Filter,&rdquo; by D. Hrusecky, Ser. No. 09/015,463, which is a continuation-in-part application from pending U.S. patent application &ldquo;Multi-Format Reduced Memory MPEG-2 Compliant Decoder,&rdquo; by Cheney et al., Ser. No. 08/958,632; </paragraph>
<paragraph id="P-0005" lvl="2"><number>&lsqb;0005&rsqb;</number> &ldquo;Multi-Format Reduced Memory MPEG Decoder With Hybrid Memory Address Generation,&rdquo; by Cheney et al., Ser. No. 09/014,896, which is a continuation-in-part application from pending U.S. patent application &ldquo;Multi-Format Reduced Memory MPEG-2 Compliant Decoder,&rdquo; by Cheney et al., Ser. No. 08/958,632; and </paragraph>
<paragraph id="P-0006" lvl="2"><number>&lsqb;0006&rsqb;</number> &ldquo;Compression/Decompression Engine For Enhanced Memory Storage In MPEG Decoder,&rdquo; by Buerkle et al., Ser. No. 08/971,438. </paragraph>
</section>
<section>
<heading lvl="1">TECHNICAL FIELD </heading>
<paragraph id="P-0007" lvl="0"><number>&lsqb;0007&rsqb;</number> The present invention is directed generally to digital video signal processing, and more particularly, to integrated decode systems, methods and articles of manufacture which allow selective scaling of video presentation by a predetermined reduction factor, while at the same time allowing for reduced external memory requirements for frame buffer storage. </paragraph>
</section>
<section>
<heading lvl="1">BACKGROUND OF THE INVENTION </heading>
<paragraph id="P-0008" lvl="0"><number>&lsqb;0008&rsqb;</number> The MPEG-2 standard describes an encoding method that results in substantial bandwidth reduction by a subjective lossy compression followed by a lossless compression. The encoded, compressed digital data is subsequently decompressed and decoded in an MPEG-2 compliant decoder. Video decoding in accordance with the MPEG-2 standard is described in detail in commonly assigned U.S. Pat. No. 5,576,765, entitled &ldquo;Video Decoder&rdquo;, which is hereby incorporated herein by reference in its entirety. </paragraph>
<paragraph id="P-0009" lvl="0"><number>&lsqb;0009&rsqb;</number> Video decoders are typically embodied as general or special purpose processors and memory. For a conventional MPEG-2 decoder, two decoded reference frames are typically stored in memory at the same time. Thus, the cost of memory can often dominate the cost of the decode system. For example, an MPEG-2 video decoder might employ 2 MB or more of external memory, which generally comprises Dynamic Random Access Memory (DRAM). External memory is used for various data areas, or buffers such as frame buffers. </paragraph>
<paragraph id="P-0010" lvl="0"><number>&lsqb;0010&rsqb;</number> In practice, the MPEG-2 video decoder is typically limited to 2 MB of external memory in order to minimize cost of the end product. The decoder must perform all of its functions within this limitation. For example, of particular importance is enabling output for both the European market which utilizes the PAL standard of 576 video scan lines and the U.S. market which utilizes the NTSC standard of 480 video scan lines. Even if there is no 2 MB of external memory limitation, it is advantageous to perform the video decode and display in as small a memory space as possible in order to give the remaining memory to other built-in features, such as on-screen graphics. </paragraph>
<paragraph id="P-0011" lvl="0"><number>&lsqb;0011&rsqb;</number> The MPEG-2 decompressed video data buffers, also called frame buffers, consume the largest part of external DRAM, therefore they are the prime candidate for memory reduction/compression. The frame buffers contain final pixel display and MPEG-reference data, and hence the reduction technique must also retain high video fidelity. </paragraph>
<paragraph id="P-0012" lvl="0"><number>&lsqb;0012&rsqb;</number> As the MPEG video decoder market becomes more and more competitive, there is a need for high level of feature integration at the lowest possible cost to achieve success in the marketplace. One such feature that, in the past, would have required circuitry external to the video decoder function is video scaling. The kind of scaling desired is to reduce the size of the display picture by a factor, such as 2 or 4, in both the horizontal and vertical axis. </paragraph>
<paragraph id="P-0013" lvl="0"><number>&lsqb;0013&rsqb;</number> In view of the above, and in order to establish commercial advantage, a novel design is desired wherein a video scaling feature is built into the video decoder, such that advantageous use of existing decoder hardware can be applied to the processes required to produce a high quality scaled image. In one principal aspect, the present invention addresses this need. </paragraph>
</section>
<section>
<heading lvl="1">DISCLOSURE OF THE INVENTION </heading>
<paragraph id="P-0014" lvl="0"><number>&lsqb;0014&rsqb;</number> Briefly summarized, this invention comprises in one aspect a video decoding system which includes a video decoder for decoding an encoded stream of video data and a decimation unit coupled to the video decoder. The video decoder produces a decoded stream of video data and the decimation unit is adapted to scale the decoded stream of video data for display. The scaling occurs within the video decode system prior to storage of the decoded stream of video data in a frame buffer. </paragraph>
<paragraph id="P-0015" lvl="0"><number>&lsqb;0015&rsqb;</number> In another aspect, the invention comprises a digital video decoding system which includes a video decoder and a video scalar. The video decoder decodes an encoded stream of video data and produces therefrom a decoded stream of video data. The video scalar is coupled to the video decoder for scaling the decoded stream of video data prior to storage thereof in a frame buffer. The video decoding system includes a normal video mode and a scaled video mode. The video scalar scales the decoded stream of video data when the digital video decoding system is in the scaled video mode. The digital video decoding system further includes display mode switch logic for switching between the normal video mode and the scaled video mode, wherein the switching occurs without perceptual degradation of the display of the decoded stream of video data. </paragraph>
<paragraph id="P-0016" lvl="0"><number>&lsqb;0016&rsqb;</number> In yet another aspect, a digital video decoding system is provided having a normal video mode and a scaled video mode. When in the normal video mode, full size frames are output for display on a video display coupled to the digital video decoding system, and when in the scaled video mode, scaled frames comprising a fractional size of the full size frames are output for display on the video display. A frame buffer is provided for temporarily storing the full size frames and the scaled frames after a decoding time thereof and prior to a display time, wherein there is a predefined latency between the decoding time and the display time. The predefined latency between the decoding time and the display time comprises a first latency when the digital video decoding system is in normal video mode and a second latency when the digital video decoding system is in scaled video mode. </paragraph>
<paragraph id="P-0017" lvl="0"><number>&lsqb;0017&rsqb;</number> In still another aspect, a frame buffer is provided for a digital video decoding system having video scaling capabilities. The frame buffer includes multiple defined memory areas for receiving I, P &amp; B frames of a decoded stream of video data. The multiple defined memory areas comprise a first area and a second area for receiving full size I and P frames of the decoded stream of video data, as well as at least one third area for receiving scaled I, P &amp; B frames of the decoded stream of video data commensurate with the first area and the second area receiving the full size I and P frames. </paragraph>
<paragraph id="P-0018" lvl="0"><number>&lsqb;0018&rsqb;</number> In a further aspect, the invention comprises a frame buffer for a digital video decoding system having video scaling capabilities. The frame buffer includes memory associated with the digital video decoding system. The memory is of a predefined size. The frame buffer further includes control logic for partitioning the memory of the predefined size into three buffer areas when the digital video decoding system is in a normal video mode, wherein the three buffer areas receive full size I, P &amp; B frames of a decoded stream of video data. The control logic is further adapted to partition the memory into five buffer areas when the digital video decoding system is in a scaled video mode. The five buffer areas comprise a first area and a second area for receiving full size I and P frames of the decoded stream of video data, and at least a third area, fourth area and fifth area for receiving scaled I, P &amp; B frames of the decoded stream of video data. </paragraph>
<paragraph id="P-0019" lvl="0"><number>&lsqb;0019&rsqb;</number> Methods and articles of manufacture corresponding to the above-outlined systems and frame buffers are also described and claimed herein. </paragraph>
<paragraph id="P-0020" lvl="0"><number>&lsqb;0020&rsqb;</number> To restate, disclosed herein is a digital video decode system, method and article of manufacture which present an integrated scaling capability. The decoder is arranged such that it reduces the overall bandwidth to external memory when in the scaling mode. For example, the display picture can be reduced by a factor of 2 and/or 4 in both the horizontal and vertical axis. Advantageously, the integrated scaling function for the video decode system presented herein uses existing decoder hardware to produce a high quality scaled image. </paragraph>
<paragraph id="P-0021" lvl="0"><number>&lsqb;0021&rsqb;</number> By performing decimation/scaling at decode time, the total memory bandwidth requirement is reduced, making more memory bandwidth available to other features, such as onscreen graphics. Thus, scaling implemented in accordance with this invention requires less external memory (i.e., frame buffer memory) than would be required by a post-processing approach, i.e., a display scaler would require four full size frame buffers. Further, in accordance with this invention, switching between non-scaling and scaling modes does not produce display artifacts. Scaling in accordance with this invention can also be employed with B frame memory reduction in full frame format, as well as with letterbox format.</paragraph>
</section>
</summary-of-invention>
<brief-description-of-drawings>
<section>
<heading lvl="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<paragraph id="P-0022" lvl="0"><number>&lsqb;0022&rsqb;</number> The above-described objects, advantages and features of the present invention, as well as others, will be more readily understood from the following detailed description of certain preferred embodiments of the invention, when considered in conjunction with the accompanying drawings in which: </paragraph>
<paragraph id="P-0023" lvl="0"><number>&lsqb;0023&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 1</cross-reference> shows an exemplary pair of groups of pictures (GOPs); </paragraph>
<paragraph id="P-0024" lvl="0"><number>&lsqb;0024&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 2</cross-reference> shows an exemplary macroblock (MB) subdivision of a picture (4:2:0 format); </paragraph>
<paragraph id="P-0025" lvl="0"><number>&lsqb;0025&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> depicts a block diagram of a video decoder; </paragraph>
<paragraph id="P-0026" lvl="0"><number>&lsqb;0026&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 4</cross-reference> is block diagram of a video decoding system to employ the principles of the present invention; </paragraph>
<paragraph id="P-0027" lvl="0"><number>&lsqb;0027&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> is a detailed embodiment of a video decoding system in accordance with the principles of the present invention; </paragraph>
<paragraph id="P-0028" lvl="0"><number>&lsqb;0028&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> illustrates frame buffer subdivision in a normal mode and in a video scaling mode in accordance with the present invention; </paragraph>
<paragraph id="P-0029" lvl="0"><number>&lsqb;0029&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference><highlight><italic>a </italic></highlight>is a timing diagram showing delayed display timing in a video scaling mode in accordance with the principles of the present invention; </paragraph>
<paragraph id="P-0030" lvl="0"><number>&lsqb;0030&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 7</cross-reference><highlight><italic>b </italic></highlight>illustrates one example of switching of the small frame buffers <highlight><bold>2</bold></highlight>, <highlight><bold>4</bold></highlight> &amp; <highlight><bold>6</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 6</cross-reference> in accordance with the present invention; </paragraph>
<paragraph id="P-0031" lvl="0"><number>&lsqb;0031&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 8</cross-reference> is a block diagram of one embodiment of a decimation unit in accordance with the principles of the present invention for the video decode system of <cross-reference target="DRAWINGS">FIG. 5</cross-reference>; </paragraph>
<paragraph id="P-0032" lvl="0"><number>&lsqb;0032&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 9</cross-reference> is a block diagram of one embodiment of display mode switch logic in accordance with the principles of the present invention for the video decode system of <cross-reference target="DRAWINGS">FIG. 5</cross-reference>; and </paragraph>
<paragraph id="P-0033" lvl="0"><number>&lsqb;0033&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flowchart of one embodiment of processing implemented by the sync generator of <cross-reference target="DRAWINGS">FIG. 9</cross-reference> in accordance with the principles of the present invention.</paragraph>
</section>
</brief-description-of-drawings>
<detailed-description>
<section>
<heading lvl="1">BEST MODE FOR CARRYING OUT THE INVENTION </heading>
<paragraph id="P-0034" lvl="0"><number>&lsqb;0034&rsqb;</number> As the present invention may be applied in connection with an MPEG-2 decoder, in order to facilitate an understanding of the invention, some pertinent aspects of the MPEG-2 compression algorithm are first reviewed. It is to be noted, however, that the invention can also be applied to other video coding algorithms which share some of the features of the MPEG-2 algorithm. </paragraph>
<paragraph id="P-0035" lvl="0"><number>&lsqb;0035&rsqb;</number> To begin with, it will be understood that the compression of a data object, such as a page of text, an image, a segment of speech, or a video sequence, can be thought of as a series of steps, including: 1) a decomposition of that object into a collection of tokens; 2) the representation of those tokens by binary strings which have minimal length in some sense; and 3) the concatenation of the strings in a well-defined order. Steps 2 and 3 are lossless, i.e., the original data is faithfully recoverable upon reversal, and Step 2 is known as entropy coding. Step 1 can be either lossless or lossy in general. Most video compression algorithms are lossy because of stringent bitrate requirements. A successful lossy compression algorithm eliminates redundant and irrelevant information, allowing relatively large errors where they are not likely to be visually significant and carefully representing aspects of a sequence to which the human observer is very sensitive. The techniques employed in the MPEG-2 algorithm for Step 1 can be described as predictive/interpolative motion-compensated hybrid DCT/DPCM coding. Huffman coding, also known as variable length coding, is used in Step 2. </paragraph>
<paragraph id="P-0036" lvl="0"><number>&lsqb;0036&rsqb;</number> The MPEG-2 video standard specifies a coded representation of video for transmission as set forth in ISO-IEC JTC1/SC29/WG11, Generic Coding of Moving Pictures and Associated Audio Information: Video, International Standard, 1994. The algorithm is designed to operate on interlaced or non-interlaced component video. Each picture has three components: luminance (Y), red color difference (Cr), and blue color difference (Cb). The video data may be coded in 4:4:4 format, in which case there is one Cr and one Cb sample for each Y sample, in 4:2:2 format, in which case there are half as many Cr and Cb samples as luminance samples in the horizontal direction, or in 4:2:0 format, in which case there are half as many Cr and Cb samples as luminance samples in both the horizontal and vertical directions. </paragraph>
<paragraph id="P-0037" lvl="0"><number>&lsqb;0037&rsqb;</number> An MPEG-2 data stream consists of a video stream and an audio stream which are packed, together with systems information and possibly other bitstreams, into a systems data stream that can be regarded as layered. Within the video layer of the MPEG-2 data stream, the compressed data is further layered. A description of the organization of the layers will aid in understanding the invention. These layers of the MPEG-2 Video Layered Structure are shown in <cross-reference target="DRAWINGS">FIGS. 1 &amp; 2</cross-reference>. The layers pertain to the operation of the compression algorithm as well as the composition of a compressed bit stream. The highest layer is the Video Sequence Layer, containing control information and parameters for the entire sequence. At the next layer, a sequence is subdivided into sets of consecutive pictures, each known as a &ldquo;Group of Pictures&rdquo; (GOP). A general illustration of this layer is shown in <cross-reference target="DRAWINGS">FIG. 1</cross-reference>. Decoding may begin at the start of any GOP, essentially independent of the preceding GOPs. There is no limit to the number of pictures which may be in a GOP, nor do there have to be equal numbers of pictures in all GOPs. </paragraph>
<paragraph id="P-0038" lvl="0"><number>&lsqb;0038&rsqb;</number> The third or Picture layer is a single picture. A general illustration of this layer is shown in <cross-reference target="DRAWINGS">FIG. 2</cross-reference>. The luminance component of each picture is subdivided into 16&times;16 regions; the color difference components are subdivided into appropriately sized blocks spatially co-sited with the 16&times;16 luminance regions; for 4:4:4 video, the color difference components are 16&times;16, for 4:2:2 video, the color difference components are 8&times;16, and for 4:2:0 video, the color difference components are 8&times;8. Taken together, these co-sited luminance region and color difference regions make up the fifth layer, known as a &ldquo;macroblock&rdquo; (MB). Macroblocks in a picture are numbered consecutively in lexicographic order, starting with Macroblock 1. </paragraph>
<paragraph id="P-0039" lvl="0"><number>&lsqb;0039&rsqb;</number> Between the Picture and MB layers is the fourth or &ldquo;slice&rdquo; layer. Each slice consists of some number of consecutive MB&apos;s. Finally, each MB consists of four 8&times;8 luminance blocks and 8, 4, or 2 (for 4:4:4, 4:2:2 and 4:2:0 video) chrominance blocks. The Sequence, GOP, Picture, and slice layers all have headers associated with them. The headers begin with byte-aligned Start Codes and contain information pertinent to the data contained in the corresponding layer. </paragraph>
<paragraph id="P-0040" lvl="0"><number>&lsqb;0040&rsqb;</number> A picture can be either field-structured or frame-structured. A frame-structured picture contains information to reconstruct an entire frame, i.e., the combination of one field containing the odd lines and the other field containing the even lines. A field-structured picture contains information to reconstruct one field. If the width of each luminance frame (in picture elements or pixels) is denoted as C and the height as R (C is for columns, R is for rows), a field-structured picture contains information for C&times;R/2 pixels. </paragraph>
<paragraph id="P-0041" lvl="0"><number>&lsqb;0041&rsqb;</number> The two fields in a frame are the top field and the bottom field. If we number the lines in a frame starting from 1, then the top field contains the odd lines (1, 3, 5, . . . ) and the bottom field contains the even lines (2, 4, 6, . . . ). Thus we may also call the top field the odd field, and the bottom field the even field. </paragraph>
<paragraph id="P-0042" lvl="0"><number>&lsqb;0042&rsqb;</number> A macroblock in a field-structured picture contains a 16&times;16 pixel segment from a single field. A macroblock in a frame-structured picture contains a 16&times;16 pixel segment from the frame that both fields compose; each macroblock contains a 16&times;8 region from each of the two fields. </paragraph>
<paragraph id="P-0043" lvl="0"><number>&lsqb;0043&rsqb;</number> Within a GOP, three types of pictures can appear. The distinguishing difference among the picture types is the compression method used. The first type, Intramode pictures or I-pictures, are compressed independently of any other picture. Although there is no fixed upper bound on the distance between I-pictures, it is expected that they will be interspersed frequently throughout a sequence to facilitate random access and other special modes of operation. Predictively motion-compensated pictures (P pictures) are reconstructed from the compressed data in that picture plus two reconstructed fields from previously displayed I or P pictures. Bidirectionally motion-compensated pictures (B pictures) are reconstructed from the compressed data in that picture plus two reconstructed fields from previously displayed I or P pictures and two reconstructed fields from 1 or P pictures that will be displayed in the future. Because reconstructed I or P pictures can be used to reconstruct other pictures, they are called reference pictures. </paragraph>
<paragraph id="P-0044" lvl="0"><number>&lsqb;0044&rsqb;</number> With the MPEG-2 standard, a frame can be coded either as a frame-structured picture or as two field-structured pictures. If a frame is coded as two field-structured pictures, then both fields can be coded as I pictures, the first field can be coded as an I picture and the second field as a P picture, both fields can be coded as P pictures, or both fields can be coded as B pictures. </paragraph>
<paragraph id="P-0045" lvl="0"><number>&lsqb;0045&rsqb;</number> If a frame is coded as a frame-structured I picture, as two field-structured I pictures, or as a field-structured I picture followed by a field-structured P picture, we say that the frame is an I frame; it can be reconstructed without using picture data from previous frames. If a frame is coded as a frame-structured P picture or as two field-structured P pictures, we say that the frame is a P frame; it can be reconstructed from information in the current frame and the previously coded I or P frame. If a frame is coded as a frame-structured B picture or as two field-structured B pictures, we say that the frame is a B frame; it can be reconstructed from information in the current frame and the two previously coded I or P frames (i.e., the I or P frames that will appear before and after the B frame). We refer to I or P frames as reference frames. </paragraph>
<paragraph id="P-0046" lvl="0"><number>&lsqb;0046&rsqb;</number> A common compression technique is transform coding. In MPEG-2 and several other compression standards, the discrete cosine transform (DCT) is the transform of choice. The compression of an I-picture is achieved by the steps of 1) taking the DCT of blocks of pixels, 2) quantizing the DCT coefficients, and 3) Huffman coding the result. In MPEG-2, the DCT operation converts a block of n&times;n pixels into an n&times;n set of transform coefficients. Like several of the international compression standards, the MPEG-2 algorithm uses a DCT block size of 8&times;8. The DCT transformation by itself is a lossless operation, which can be inverted to within the precision of the computing device and the algorithm with which it is performed. </paragraph>
<paragraph id="P-0047" lvl="0"><number>&lsqb;0047&rsqb;</number> The second step, quantization of the DCT coefficients, is the primary source of lossiness in the MPEG-2 algorithm. Denoting the elements of the two-dimensional array of DCT coefficients by cmn, where m and n can range from 0 to 7, aside from truncation or rounding corrections, quantization is achieved by dividing each DCT coefficient cmn by wmn times QP, with wmn being a weighting factor and QP being the quantizer parameter. The weighting factor wmn allows coarser quantization to be applied to the less visually significant coefficients. The quantizer parameter QP is the primary means of trading off quality vs. bit-rate in MPEG-2. It is important to note that QP can vary from MB to MB within a picture. </paragraph>
<paragraph id="P-0048" lvl="0"><number>&lsqb;0048&rsqb;</number> Following quantization, the DCT coefficient information for each MB is organized and coded, using a set of Huffman codes. As the details of this step are not essential to an understanding of the invention and are generally understood in the art, no further description is needed here. </paragraph>
<paragraph id="P-0049" lvl="0"><number>&lsqb;0049&rsqb;</number> Most video sequences exhibit a high degree of correlation between consecutive pictures. A useful method to remove this redundancy prior to coding a picture is &ldquo;motion compensation&rdquo;. MPEG-2 provides tools for several methods of motion compensation. </paragraph>
<paragraph id="P-0050" lvl="0"><number>&lsqb;0050&rsqb;</number> The methods of motion compensation have the following in common. For each macroblock, one or more motion vectors are encoded in the bit stream. These motion vectors allow the decoder to reconstruct a macroblock, called the predictive macroblock. The encoder subtracts the &ldquo;predictive&rdquo; macroblock from the macroblock to be encoded to form the &ldquo;difference&rdquo; macroblock. The encoder uses tools to compress the difference macroblock that are essentially similar to the tools used to compress an intra macroblock. </paragraph>
<paragraph id="P-0051" lvl="0"><number>&lsqb;0051&rsqb;</number> The type of a picture determines the methods of motion compensation that can be used. The encoder chooses from among these methods for each macroblock in the picture. If no motion compensation is used, the macroblock is intra (I). The encoder can make any macroblock intra. In a P or a B picture, forward (F) motion compensation can be used; in this case, the predictive macroblock is formed from data in the previous I or P frame. In a B picture, backward (B) motion compensation can also be used; in this case, the predictive macroblock is formed from data in the future I or P frame. In a B picture, forward/backward (FB) motion compensation can also be used; in this case, the predictive macroblock is formed from data in the previous I or P frame and the future I or P frame. </paragraph>
<paragraph id="P-0052" lvl="0"><number>&lsqb;0052&rsqb;</number> Because I and P pictures are used as references to reconstruct other pictures (B and P pictures) they are called reference pictures. Because two reference frames are needed to reconstruct B frames, MPEG-2 decoders typically store two decoded reference frames in memory. </paragraph>
<paragraph id="P-0053" lvl="0"><number>&lsqb;0053&rsqb;</number> Aside from the need to code side information relating to the MB mode used to code each MB and any motion vectors associated with that mode, the coding of motion-compensated macroblocks is very similar to that of intramode MBs. Although there is a small difference in the quantization, the model of division by wmn times QP still holds. </paragraph>
<paragraph id="P-0054" lvl="0"><number>&lsqb;0054&rsqb;</number> The MPEG-2 algorithm can be used with fixed bit-rate transmission media. However, the number of bits in each picture will not be exactly constant, due to the different types of picture processing, as well as the inherent variation with time of the spatio-temporal complexity of the scene being coded. The MPEG-2 algorithm uses a buffer-based rate control strategy to put meaningful bounds on the variation allowed in the bit-rate. A Video Buffer Verifier (VBV) is devised in the form of a virtual buffer, whose sole task is to place bounds on the number of bits used to code each picture so that the overall bit-rate equals the target allocation and the short-term deviation from the target is bounded. This rate control scheme can be explained as follows. Consider a system consisting of a buffer followed by a hypothetical decoder. The buffer is filled at a constant bit-rate with compressed data in a bit stream from the storage medium. Both the buffer size and the bit-rate are parameters which are transmitted in the compressed bit stream. After an initial delay, which is also derived from information in the bit stream, the hypothetical decoder instantaneously removes from the buffer all of the data associated with the first picture. Thereafter, at intervals equal to the picture rate of the sequence, the decoder removes all data associated with the earliest picture in the buffer. </paragraph>
<paragraph id="P-0055" lvl="0"><number>&lsqb;0055&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 3</cross-reference> shows a diagram of a conventional video decoder. </paragraph>
<paragraph id="P-0056" lvl="0"><number>&lsqb;0056&rsqb;</number> The compressed data enters as signal <highlight><bold>11</bold></highlight> and is stored in the compressed data memory <highlight><bold>12</bold></highlight>. The variable length decoder (VLD) <highlight><bold>14</bold></highlight> reads the compressed data as signal <highlight><bold>13</bold></highlight> and sends motion compensation information as signal <highlight><bold>16</bold></highlight> to the motion compensation (MC) unit <highlight><bold>17</bold></highlight> and quantized coefficients as signal <highlight><bold>15</bold></highlight> to the inverse quantization (IQ) unit <highlight><bold>18</bold></highlight>. The motion compensation unit reads the reference data from the reference frame memory <highlight><bold>20</bold></highlight> as signal <highlight><bold>19</bold></highlight> to form the predicted macroblock, which is sent as the signal <highlight><bold>22</bold></highlight> to the adder <highlight><bold>25</bold></highlight>. The inverse quantization unit computes the unquantized coefficients, which are sent as signal <highlight><bold>21</bold></highlight> to the inverse transform (IDCT) unit <highlight><bold>23</bold></highlight>. The inverse transform unit computes the reconstructed difference macroblock as the inverse transform of the unquantized coefficients. The reconstructed difference macroblock is sent as signal <highlight><bold>24</bold></highlight> to the adder <highlight><bold>25</bold></highlight>, where it is added to the predicted macroblock. The adder <highlight><bold>25</bold></highlight> computes the reconstructed macroblock as the sum of the reconstructed difference macroblock and the predicted macroblock. The reconstructed macroblock is then sent as signal <highlight><bold>26</bold></highlight> to the demultiplexer <highlight><bold>27</bold></highlight>, which stores the reconstructed macroblock as signal <highlight><bold>29</bold></highlight> to the reference memory if the macroblock comes from a reference picture or sends it out (to memory or display) as signal <highlight><bold>28</bold></highlight>. Reference frames are sent out as signal <highlight><bold>30</bold></highlight> from the reference frame memory. </paragraph>
<paragraph id="P-0057" lvl="0"><number>&lsqb;0057&rsqb;</number> Various techniques have been proposed for reducing memory requirements of a decode system by storing decoded video data in compressed form. One such technique is described in the above-incorporated patent application entitled &ldquo;Multi-Format Reduced Memory MPEG-2 Compliant Decoder,&rdquo; Ser. No. 08/958,632. This co-pending application relates to a method for reducing memory requirements for frame buffer storage for an MPEG-2 decoder, and to editing or modifying the video output, e.g., from a 4:3 form factor of television to a 16:9 format of motion pictures. A significant aspect of the technique is decimation of the B-coded pictures within hardware of the video decoder. This technique includes first motion compensating the P-coded and B-coded pictures, followed by decimating the B-coded pictures during the decode phase, and increasing the size of scan line fetches for the I-coded and P-coded pictures to enable their horizontal decimation during the display phase. </paragraph>
<paragraph id="P-0058" lvl="0"><number>&lsqb;0058&rsqb;</number> A decode system, generally denoted <highlight><bold>40</bold></highlight>, to employ the present invention is depicted in <cross-reference target="DRAWINGS">FIG. 4</cross-reference>. System <highlight><bold>40</bold></highlight> includes a bus interface <highlight><bold>44</bold></highlight> which couples the decode system <highlight><bold>40</bold></highlight> to a memory bus <highlight><bold>42</bold></highlight>. MPEG encoded video data is fetched from PCI bus <highlight><bold>42</bold></highlight> by a DMA controller <highlight><bold>46</bold></highlight> which writes the data to a video First-In/First-Out (FIFO) buffer <highlight><bold>48</bold></highlight>. The DMA controller also fetches on-screen display and/or audio data from bus <highlight><bold>42</bold></highlight> for writing to an OSD/audio FIFO <highlight><bold>50</bold></highlight>. A memory controller <highlight><bold>52</bold></highlight> will place video data into a correct memory buffer within dynamic random access memory (DRAM) <highlight><bold>53</bold></highlight>. MPEG compressed video data is then retrieved by the video decoder <highlight><bold>54</bold></highlight> from DRAM <highlight><bold>53</bold></highlight> and decoded as described above in connection with <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. Conventionally, the decoded video data is then stored back into the frame buffers of DRAM <highlight><bold>53</bold></highlight> for subsequent use as already described. When a reference frame is needed, or when video data is to be output from the decode system, stored data in DRAM <highlight><bold>53</bold></highlight> is retrieved by the MEM controller and forwarded for output via a display &amp; OSD interface <highlight><bold>58</bold></highlight>. Audio data, also retrieved by the memory controller <highlight><bold>52</bold></highlight>, is output through an audio interface <highlight><bold>60</bold></highlight>. </paragraph>
<paragraph id="P-0059" lvl="0"><number>&lsqb;0059&rsqb;</number> As discussed initially herein, this invention addresses the need for a decoding system with integrated scaling capability which can scale the size of an MPEG-2 video presentation by a predetermined reduction factor. At the same time, the invention preferably allows for reduction in external memory requirements for full-frame buffer storage as well, e.g., using the above-described B frame memory reduction technique. As the MPEG-2 video decoder market becomes more and more competitive, the need for high level of feature integration at the lowest possible cost is important to achieving success in the marketplace. The present invention acknowledges this by providing a scaling mode to reduce the size of a display picture by a predefined factor, such as 2 and/or 4 in both the horizontal and vertical axis. </paragraph>
<paragraph id="P-0060" lvl="0"><number>&lsqb;0060&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 5</cross-reference> depicts one embodiment of a video decode system in accordance with the principles of the present invention. This video decode system includes external memory <highlight><bold>53</bold></highlight>, which in the embodiment shown comprises SDRAM frame buffer storage. Memory <highlight><bold>53</bold></highlight> interfaces with a memory control unit <highlight><bold>52</bold></highlight>. Memory control unit <highlight><bold>52</bold></highlight> receives decoded video data from a video decoder <highlight><bold>54</bold></highlight> and provides video data for display through video display unit <highlight><bold>90</bold></highlight>. In accordance with the principles of the present invention, video decode system <highlight><bold>65</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 5</cross-reference> includes numerous features which implement a video scaling mode capability. </paragraph>
<paragraph id="P-0061" lvl="0"><number>&lsqb;0061&rsqb;</number> For example, decimation unit <highlight><bold>82</bold></highlight> is modified to include both a normal video decimation mode and a video scaling mode. Frame buffers <highlight><bold>53</bold></highlight> are modified to accommodate storage of decoded video data in either full-frame format or a combination of full-frame format and scaled video format. Display mode switch logic <highlight><bold>96</bold></highlight> is provided within video display unit <highlight><bold>90</bold></highlight> to facilitate seamless switching between normal video mode and scaled video mode. Frame buffer pointer control <highlight><bold>86</bold></highlight> is modified to provide the correct frame buffer pointers based on the novel partitioning of the frame buffers when in normal video mode and when in scaled video mode. Further, as described in the above-incorporated, co-filed United States patent application, a flicker reduction mechanism is preferably integrated within video display unit <highlight><bold>90</bold></highlight>, and in particular within vertical upsample logic <highlight><bold>94</bold></highlight>. Each of these features is described in detail below, with the exception of flicker reduction which is described in the co-filed application. </paragraph>
<paragraph id="P-0062" lvl="0"><number>&lsqb;0062&rsqb;</number> Operationally, an MPEG input video source is fed through memory control unit <highlight><bold>52</bold></highlight> as coded MPEG-2 video data to the input of video decoder <highlight><bold>54</bold></highlight>. Decoder <highlight><bold>54</bold></highlight> includes a Huffman decoder <highlight><bold>72</bold></highlight>, Inverse Quantizer <highlight><bold>74</bold></highlight>, Inverse DCT <highlight><bold>76</bold></highlight>, Motion Compensation <highlight><bold>78</bold></highlight> and adder <highlight><bold>80</bold></highlight>, which function as described above in connection with the video decoder of <cross-reference target="DRAWINGS">FIG. 3</cross-reference>. An internal processor <highlight><bold>70</bold></highlight> oversees the video decode process and, in accordance with the principles of the present invention, receives a signal from a host system whenever the host desires to switch the video display between, for example, normal video display and scaled video display. This signal is referred to in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> as a &ldquo;host controlled format change&rdquo; signal. In response to host format changes, control signals are sent from internal processor <highlight><bold>70</bold></highlight> to Huffman decoder <highlight><bold>72</bold></highlight>, Inverse Quantizer <highlight><bold>74</bold></highlight>, Motion Compensation <highlight><bold>78</bold></highlight>, as well as to upsample logic <highlight><bold>94</bold></highlight>, display fetch unit <highlight><bold>92</bold></highlight> and display mode switch logic <highlight><bold>96</bold></highlight> within video display <highlight><bold>90</bold></highlight>. Again, these control signals direct the video decode system in accordance with the principles of the present invention (and as described below) to switch the display output between, for example, normal video mode and scaled video mode. </paragraph>
<paragraph id="P-0063" lvl="0"><number>&lsqb;0063&rsqb;</number> Full size macroblocks of decoded video data are sequentially output from video decoder <highlight><bold>54</bold></highlight> to decimation unit <highlight><bold>82</bold></highlight> where, in one embodiment, the full size macroblocks undergo one of two types of compression. First, if full size video is desired, then decimation of the B-coded pictures only is still preferably performed as described in the above-incorporated application entitled: &ldquo;Multi-Format Reduced Memory MPEG-2 Compliant Decoder&rdquo;. In this normal video mode, decimation is a process of reducing the amount of data by interpolating or averaging combined values to get an interpolated pixel value. Interpolation reduces the number of pixels, and therefore, less external memory is required in the overall system. In a second mode, decimation unit <highlight><bold>82</bold></highlight> performs picture scaling in accordance with the principles of this invention. By way of example, the type of scaling employed may reduce the overall size of the display picture by a factor of 2 or 4 in both the horizontal and vertical axis. </paragraph>
<paragraph id="P-0064" lvl="0"><number>&lsqb;0064&rsqb;</number> Along with providing decimation unit <highlight><bold>82</bold></highlight> with a stream of decoded full-size macroblocks, video decoder also sends a &ldquo;motion compensation unit block complete&rdquo; signal on line <highlight><bold>83</bold></highlight>, which lets decimation unit <highlight><bold>82</bold></highlight> know when a macroblock has been completely decoded. Similarly, decimation unit <highlight><bold>82</bold></highlight> provides a &ldquo;decimator busy&rdquo; signal on line <highlight><bold>85</bold></highlight> to motion compensation unit <highlight><bold>78</bold></highlight> of video decoder <highlight><bold>54</bold></highlight>. This &ldquo;decimator busy&rdquo; signal informs the motion compensation unit when the decimation unit is busy and when the unit has completed its operations, after which the motion compensation unit can proceed to the next macroblock. </paragraph>
<paragraph id="P-0065" lvl="0"><number>&lsqb;0065&rsqb;</number> Motion compensation unit <highlight><bold>78</bold></highlight> of video decoder <highlight><bold>54</bold></highlight> provides read video addresses directly to memory control unit <highlight><bold>52</bold></highlight>, and write video addresses to decimation unit <highlight><bold>82</bold></highlight> for writing of decoded video data (full size) and/or scaled macroblocks to external memory <highlight><bold>53</bold></highlight>. In parallel with the read video address and write video address, pointers are provided by frame buffer pointer control <highlight><bold>86</bold></highlight> to the memory control unit. These pointers define which frame buffer areas within SDRAM <highlight><bold>53</bold></highlight> are to be accessed by a given read video address or write video address in accordance with the partitionings of the frame buffer memory space pursuant to this invention (as described further below). These pointers are referred to in <cross-reference target="DRAWINGS">FIG. 5</cross-reference> as current pointer and current small pointer, with current pointer comprising a pointer for a full size macroblock, and current small pointer comprising a pointer for a scaled macroblock. </paragraph>
<paragraph id="P-0066" lvl="0"><number>&lsqb;0066&rsqb;</number> Decimation unit <highlight><bold>82</bold></highlight> receives the decoded full-size macroblocks, buffers the information internally and if scaling mode is activated, performs scaling as described below. In a normal mode, decimation unit <highlight><bold>82</bold></highlight> outputs decoded video data full-size macroblocks to memory control unit <highlight><bold>52</bold></highlight> for storage in frame buffers <highlight><bold>53</bold></highlight>. When in scaling mode, decimation unit <highlight><bold>82</bold></highlight> scales the full-size macroblocks and outputs scaled macroblocks to memory control unit <highlight><bold>52</bold></highlight> for storage in frame buffers <highlight><bold>53</bold></highlight>. </paragraph>
<paragraph id="P-0067" lvl="0"><number>&lsqb;0067&rsqb;</number> Frame buffer pointer control <highlight><bold>86</bold></highlight> is significant and controls rotation of the frame buffers, i.e., frame buffer assignments, when in normal video mode and video scaling mode in accordance with the principles of the present invention (described further below). </paragraph>
<paragraph id="P-0068" lvl="0"><number>&lsqb;0068&rsqb;</number> As described in the above-incorporated applications, decimation unit <highlight><bold>82</bold></highlight> also functions as part of video display unit <highlight><bold>90</bold></highlight> when retrieving data for display. Specifically, decoded video data comprising full-size scan lines is retrieved from frame buffer storage <highlight><bold>53</bold></highlight> and fed through decimation unit <highlight><bold>82</bold></highlight> for B-frame re-expansion of pictures as explained in the above-incorporated patent application entitled &ldquo;Multi-Format Reduced Memory Video Decoder With Adjustable Polyphase Expansion Filter.&rdquo; This is done so that consistency is maintained for the video within a group of pictures, and thus reduced resolution of any one picture is not perceptible. After re-expansion, the full-size scan lines are provided to display output interface <highlight><bold>98</bold></highlight>. </paragraph>
<paragraph id="P-0069" lvl="0"><number>&lsqb;0069&rsqb;</number> Alternatively, when in video scaling mode, decoded video comprising scaled scan lines is retrieved from frame buffer storage <highlight><bold>53</bold></highlight> and fed directly to scan line video buffers <highlight><bold>84</bold></highlight>. The scan lines are divided between luminance and chrominance data and both a current scan line and a prior scan line are fed from scan line video buffers <highlight><bold>84</bold></highlight> to vertical and horizontal upsample logic <highlight><bold>94</bold></highlight>. Upsample controls are received from display fetch unit <highlight><bold>92</bold></highlight>, which coordinates letterbox formatting, SIF upsampling, 4:2:0 to 4:2:2 upsampling, and flicker reduction (in accordance with the principles of the above-incorporated, co-filed patent application). </paragraph>
<paragraph id="P-0070" lvl="0"><number>&lsqb;0070&rsqb;</number> Display fetch unit <highlight><bold>92</bold></highlight> provides the read video address for retrieval of scan lines from frame buffer storage <highlight><bold>53</bold></highlight>. A &ldquo;current pointer, current small pointer&rdquo; synchronization (sync) signal for display is received by memory control unit <highlight><bold>52</bold></highlight> from display mode switch logic <highlight><bold>96</bold></highlight> of video display unit <highlight><bold>90</bold></highlight>. As noted above, the current pointer, current small pointer signal points to the particular frame buffer area from which scan lines are to be retrieved, while the read video address signal designates the particular scan lines to be retrieved within that frame buffer area. </paragraph>
<paragraph id="P-0071" lvl="0"><number>&lsqb;0071&rsqb;</number> Display mode switch logic <highlight><bold>96</bold></highlight> is provided in accordance with the principles of the present invention in order to ensure seamless switching between, for example, scaled video mode and normal video mode. Logic <highlight><bold>96</bold></highlight> receives as input a control signal from internal processor <highlight><bold>70</bold></highlight> of video decoder <highlight><bold>54</bold></highlight>, as well as a vertical synchronization (VSYNC) signal (from display output interface <highlight><bold>98</bold></highlight>) and a B picture &ldquo;MPEG-2 repeat field&rdquo; signal from Huffman decoder <highlight><bold>72</bold></highlight> of video decoder <highlight><bold>54</bold></highlight>. VSYNC is an external synchronization signal that indicates the start of a new display field. Output from display mode switch logic <highlight><bold>96</bold></highlight>, in addition to the current pointer, current small pointer sync for the display, is a &ldquo;display format sync for display&rdquo; signal fed to display fetch unit <highlight><bold>92</bold></highlight>, as well as a &ldquo;display format sync for decode&rdquo; signal fed to the decode logic of decimation unit <highlight><bold>82</bold></highlight>. Display mode switch logic <highlight><bold>96</bold></highlight> also outputs a &ldquo;block video&rdquo; signal to display output interface <highlight><bold>98</bold></highlight> which is employed, in accordance with the principles of the present invention, to block one display frame to keep noise from the display when switching between display modes. Video data is received at the display output interface from upsample logic <highlight><bold>94</bold></highlight>. The decimation unit, frame buffer partitioning, frame buffer pointer control and display mode switch logic, all implemented in accordance with the principles of this invention, are described in greater detail below with reference to FIGS. <highlight><bold>6</bold></highlight>-<highlight><bold>10</bold></highlight>. </paragraph>
<paragraph id="P-0072" lvl="0"><number>&lsqb;0072&rsqb;</number> First, the frame buffers. The frame buffers are used to store the constructed pictures for display, as well as for prediction of subsequent pictures. Since a B picture is not used for prediction, its frame buffer is available for use after the picture has been displayed. For I or P pictures, the frame buffer needs to be held after display, particularly for predicting B pictures. </paragraph>
<paragraph id="P-0073" lvl="0"><number>&lsqb;0073&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 6</cross-reference> depicts frame buffer allocation for both normal video mode and scaled video mode in accordance with the principles of this invention. In normal mode, there are three frame buffers to support the decoding and display processes. Frame buffer 0 and frame buffer 1 are allocated for 1 and P pictures, while frame buffer 2 is assigned to B pictures. The frame buffers are tagged by buffer pointers, i.e., the current pointers from frame buffer pointer control <highlight><bold>86</bold></highlight> of <cross-reference target="DRAWINGS">FIG. 5</cross-reference>. </paragraph>
<paragraph id="P-0074" lvl="0"><number>&lsqb;0074&rsqb;</number> In the scaled video mode, at least five frame buffers are employed. Frame buffer 0 and frame buffer 1 again accommodate full size I and P picture video. The at least three other buffers, which are labeled frame buffer 2, frame buffer 4 and frame buffer 6 in the example shown, are tagged by small pointers generated by the frame buffer pointer control. These small buffers are mainly used for display purposes when in scaled video mode. The buffers are small size in order to fit the video scalings. When decoding an I or P picture, the constructed picture is stored into either buffer 0 or buffer 1 depending upon whichever is available. At the same time, a scaled down version of the same picture is stored into one of the smaller buffers, i.e., frame buffer 2, frame buffer 4 or frame buffer 6. The full size video is then used for prediction, while the small sized video in the small frame buffers is used for display of the scaled down picture. </paragraph>
<paragraph id="P-0075" lvl="0"><number>&lsqb;0075&rsqb;</number> The frame buffers are configured by microcode during initialization of the video decode system. A memory base address is assigned to each frame buffer, and these memory base addresses are selected by the buffer pointers generated by frame buffer pointer control. The read and write video addresses refer to specific addresses within a selected frame buffer. Unless otherwise indicated, the term &ldquo;frame buffer&rdquo; is used herein below as inclusive of all frame buffer memory configured during initialization. &ldquo;Frame buffer area&rdquo; refers to one of the specific frame buffers depicted in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. </paragraph>
<paragraph id="P-0076" lvl="0"><number>&lsqb;0076&rsqb;</number> The video display operates in real time, and therefore, frame buffer pointers must be switched according to the VSYNC timing. Since decoding is always ahead of the display, a frame buffer must be made available to store the decoded picture. Therefore, the frame buffer pointers must be switched before decoding starts. To avoid the disturbance to the display frame buffer, a copy of the display buffer pointer is maintained. The buffer switching time is at the beginning of each picture decode. The display buffer pointer is also changed at that time, however, it will not be used until copy display pointer time which is the beginning of picture display. One embodiment of normal mode buffer pointer rotation is described below. </paragraph>
<paragraph id="P-0077" lvl="0"><number>&lsqb;0077&rsqb;</number> The following assumes four buffer pointers, with each pointer containing two bits to indicate which one of the three frame buffers (buffer 0, 1 and 2) is being accessed. </paragraph>
<paragraph id="P-0078" lvl="2"><number>&lsqb;0078&rsqb;</number> current pointer&mdash;indicates the frame buffer to be used for the constructing picture; </paragraph>
<paragraph id="P-0079" lvl="2"><number>&lsqb;0079&rsqb;</number> display pointer&mdash;indicates the frame buffer to be used for the display; </paragraph>
<paragraph id="P-0080" lvl="2"><number>&lsqb;0080&rsqb;</number> future pointer&mdash;indicates the frame buffer to be used for the backward prediction; and </paragraph>
<paragraph id="P-0081" lvl="2"><number>&lsqb;0081&rsqb;</number> past pointer&mdash;indicates the frame buffer to be used for the forward prediction. </paragraph>
<paragraph id="P-0082" lvl="0"><number>&lsqb;0082&rsqb;</number> At startup, the future pointer is initialized to &ldquo;1&rdquo; and the other pointers are set to &ldquo;0&rdquo;. At the beginning of an I or P picture decode, the value from the past pointer is loaded into the current pointer and the value from the future pointer is loaded into the display pointer. The values in the future pointer and the past pointer are swapped. If the decoding picture is a B picture, the current pointer and the display pointer are set to &ldquo;2&rdquo;. Frame buffer 2 is reserved, in one example, for the B pictures. The future pointer and past pointer remain unchanged. Pointer switching in normal mode is described in greater detail in U.S. Pat. No. 5,668,599 by Cheney et al., entitled &ldquo;Memory Management For An MPEG-2 Compliant Decoder,&rdquo; the entirety of which is hereby incorporated herein by reference. </paragraph>
<paragraph id="P-0083" lvl="0"><number>&lsqb;0083&rsqb;</number> In scaled video mode, the display time of a picture is delayed by an additional field time in accordance with the present invention. The purpose of this delay is to decouple the decode and the display processes so that the decoded scaled video can be placed anywhere on the screen. <cross-reference target="DRAWINGS">FIG. 7</cross-reference><highlight><italic>a </italic></highlight>depicts one example of the delayed display timing in scaled video mode. This display timing is adjusted dynamically according to the mode, i.e., whether normal mode or scaled video mode. The one field time delay is needed in accordance with this invention to properly manage the buffers. At least five buffers are again assumed in the video scaling mode. As described above, two of these five buffers comprise full-size frame buffers, and are labeled frame buffer 0 and frame buffer 1 in <cross-reference target="DRAWINGS">FIG. 6</cross-reference>. These full-size frame buffers are the same as the corresponding buffers used in normal video mode. The at least three small frame buffers, i.e., frame buffer 2, frame buffer 4 and frame buffer 6, are allocated in the same memory space occupied by frame buffer 2 used in the normal video mode. These three small frame buffers are controlled by a different algorithm than described above. </paragraph>
<paragraph id="P-0084" lvl="0"><number>&lsqb;0084&rsqb;</number> Specifically, four additional pointers are used in scaled video mode. These pointers are: </paragraph>
<paragraph id="P-0085" lvl="2"><number>&lsqb;0085&rsqb;</number> small current pointer&mdash;indicates a small buffer for the decimated constructing picture; </paragraph>
<paragraph id="P-0086" lvl="2"><number>&lsqb;0086&rsqb;</number> small display pointer&mdash;indicates a small buffer for the display; </paragraph>
<paragraph id="P-0087" lvl="2"><number>&lsqb;0087&rsqb;</number> small future pointer&mdash;indicates the small buffer for the future display; and </paragraph>
<paragraph id="P-0088" lvl="2"><number>&lsqb;0088&rsqb;</number> small transition pointer&mdash;indicates the small buffer for the transition. </paragraph>
<paragraph id="P-0089" lvl="0"><number>&lsqb;0089&rsqb;</number> When the decoder is initialized, the small current pointer, small display pointer, small future pointer and small transition pointer are set to 0, 2, 4 and 6, respectively. At the start of each picture decoding, the small current pointer is loaded from the small transition pointer and the small transition pointer is loaded from the small display pointer. If the decoding picture is a B picture, then the small display pointer is loaded from the small transition pointer and the small future pointer remains unchanged. If the decoding picture is an I or P picture, the small display pointer is loaded from the small future pointer and the small future pointer is loaded from the small transition pointer. One example of small frame buffer switching in accordance with the present invention is depicted in <cross-reference target="DRAWINGS">FIG. 7</cross-reference><highlight><italic>b. </italic></highlight></paragraph>
<paragraph id="P-0090" lvl="0"><number>&lsqb;0090&rsqb;</number> The full-size frame buffers, frame buffer 0 and frame buffer 1, are switching as if the decoder is running in normal mode. These two buffers are needed for prediction, but are not for display in scaled video mode. When an I or P picture is being decoded, the picture is stored in both buffers indicated by the current (full frame) pointer and the small current pointer. During a B picture decoding, frame buffer 2 indicated by the current (full frame) pointer will not be used. Only the small frame buffer identified by the small current pointer is used for the decimated picture. In normal mode, the display pointer is used for display, while in scaled video mode, the small display pointer is used. The two buffer switching algorithms operate simultaneously at the beginning of each picture decoding. The buffer pointers are simply selected depending upon which mode the decoder is in. </paragraph>
<paragraph id="P-0091" lvl="0"><number>&lsqb;0091&rsqb;</number> Next, <cross-reference target="DRAWINGS">FIG. 8</cross-reference> depicts one embodiment of a decimation unit <highlight><bold>82</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 5</cross-reference>) employed in accordance with the present invention. </paragraph>
<paragraph id="P-0092" lvl="0"><number>&lsqb;0092&rsqb;</number> In previous implementations of the decode decimation unit, e.g., described in the above-incorporated patent application entitled &ldquo;Multi-Format Reduced Memory MPEG-2 Compliant Decoder&rdquo;, the decimation unit was limited to operating on B pictures only, for either letterbox or memory reduction purposes. In a scaled video mode as presented herein, however, the decode decimation unit processes all picture types. This is desirable in order to save memory bandwidth at display time, since (in one embodiment) scaled pictures and multi-plane, high resolution OSD graphics may be mixed at the output. </paragraph>
<paragraph id="P-0093" lvl="0"><number>&lsqb;0093&rsqb;</number> In the embodiment of <cross-reference target="DRAWINGS">FIG. 8</cross-reference>, the decimation unit includes decimation logic <highlight><bold>200</bold></highlight>, which receives the decoded video data from the video decoder and outputs a decimated data flow to a decimation buffer <highlight><bold>220</bold></highlight>. Output from decimation buffer <highlight><bold>220</bold></highlight> is multiplexed <highlight><bold>230</bold></highlight> with the undecimated, decoded video data received from the video decoder such that multiplexer <highlight><bold>230</bold></highlight> outputs the decoded video data, as well as the scaled macroblocks for storage in frame buffers 0, 1, 2, 4 and 6 as described above when in scaled video mode. The write video address from the motion compensation unit of the video decoder is fed to memory write controls <highlight><bold>240</bold></highlight> within the decimation unit, which control writing of data from decimation buffer <highlight><bold>220</bold></highlight>. The write video addresses, either with or without decimation scaling, are also output through a multiplexer <highlight><bold>250</bold></highlight> to the memory control unit (see <cross-reference target="DRAWINGS">FIG. 5</cross-reference>). </paragraph>
<paragraph id="P-0094" lvl="0"><number>&lsqb;0094&rsqb;</number> Multiplexers <highlight><bold>230</bold></highlight> &amp; <highlight><bold>250</bold></highlight> are controlled by decimate control signals <highlight><bold>210</bold></highlight>. The decimate control logic receives as input a signal called &ldquo;MCU_block_complete&rdquo; from the motion compensation unit of the video decoder. This signal indicates when the decimator can begin to write the scaled macroblock. The decimator informs the motion compensation unit that it is currently busy through a signal labeled &ldquo;decimator_busy&rdquo;. </paragraph>
<paragraph id="P-0095" lvl="0"><number>&lsqb;0095&rsqb;</number> For a given macroblock, there are two phases. One phase is for the luminance, and the other phase is for chrominance. Each phase requires a write of one full-sized macroblock and one scaled macroblock, again, assuming scaled video mode. </paragraph>
<paragraph id="P-0096" lvl="0"><number>&lsqb;0096&rsqb;</number> Various specific changes to the decimation hardware/process described in the above-incorporated &ldquo;Multi-Format Reduced Memory MPEG-2 Compliant Decoder&rdquo; application are intended herein. One change in the data flow of the decimation process is the addition (in one example) of a 4 to 1 horizontal reduction, which is implemented in the horizontal decimate function of the decimation logic. This is to support {fraction (1/16)} size scaling. </paragraph>
<paragraph id="P-0097" lvl="0"><number>&lsqb;0097&rsqb;</number> Another, change is to increase the decimation buffer size to 32&times;32 bits. As I and P pictures are processed, the full-sized macroblock is written to memory, while the decimator scales down the macroblock at the same time and stores a small macroblock in the decimation buffer <highlight><bold>220</bold></highlight>. After the full-sized macroblock is written to memory, the decimator writes the scaled macroblock to another buffer location within memory (i.e., frame buffer 2, frame buffer 4 or frame buffer 6 in the example above). The larger decimation buffer allows for the storing of the small macroblock. </paragraph>
<paragraph id="P-0098" lvl="0"><number>&lsqb;0098&rsqb;</number> The decimate state machine logic is also changed to allow two modes of operation, i.e., again assuming a scaled video mode. The first mode is B picture processing and the second mode is reference picture processing. For B picture processing, only the small macroblocks are written to memory through decimation buffer <highlight><bold>220</bold></highlight>. The data is paced through the decimation unit as fast as the motion compensation unit can deliver it, since the decimation buffer can hold a complete scaled macroblock. For reference picture operations, the full-size macroblocks are written to memory first through multiplexer <highlight><bold>230</bold></highlight>, followed by the writing of the scaled macroblocks. This requires the data flow to be paced by the memory control unit responding to requests for writing. </paragraph>
<paragraph id="P-0099" lvl="0"><number>&lsqb;0099&rsqb;</number> Since the size of the source compressed image may vary, there are exceptions to the above process. The decimator is only required if some type of reduction is needed to form a scaled picture. Certain video sources will already be small in size, and one dimension, or both dimensions may not require scaling. For example, it is common to have 352&times;240 sized images (typical MPEG-1 size). In this case, it would be unnecessary to do any decimation to provide a &frac14; scaling. For reference frames, the motion compensation unit is required to write the full-sized macroblock to the reference frame buffer in memory, and then to the display frame buffer in memory, since the display process is only operating on the display frame buffer during scaling. </paragraph>
<paragraph id="P-0100" lvl="0"><number>&lsqb;0100&rsqb;</number> For the same image size to be reduced to {fraction (1/16)} scaling, there would need to be a decimation step. Once again, there is an exception in this case. </paragraph>
<paragraph id="P-0101" lvl="0"><number>&lsqb;0101&rsqb;</number> One of the objects of the scaling feature is to remove interlacing artifacts. On true MPEG-1 images, there is no interlacing since the pictures are exclusively frame encoded. MPEG-2 can allow interlaced pictures of the same resolution (352&times;240) and the decimator only uses the top field picture to create the scaled macroblock. The bottom field is discarded. Therefore, for a reference picture, the MCU would be required to write the macroblock for the top field picture to both the reference frame buffer and display buffer. For B pictures, the MCU would only need to write the top field picture into the display frame buffer. </paragraph>
<paragraph id="P-0102" lvl="0"><number>&lsqb;0102&rsqb;</number> The video decode system in accordance with the present invention provides smooth transitions when entering and exiting small picture mode. Since frame buffer 2 is used for capture and display of small picture images (including reference and B pictures) when in video scaling mode, care must be taken to prevent interference between the decode and display processes at the time of display format switching. Also, there is a latency adjustment of one field time that must take place during the transition. Normal display modes have a 1.5 frame latency between decoding and displaying reference pictures, and a 0.5 frame latency for B pictures. In small picture mode, the reference frame latency is changes to two frames and the B frame latency is changed to one frame. </paragraph>
<paragraph id="P-0103" lvl="0"><number>&lsqb;0103&rsqb;</number> For the display format change to occur seamlessly, the display must not be in the process of displaying a B picture when the transition occurs, otherwise the picture will appear disturbed. Therefore, transition must take place when a reference picture is being displayed. This is forced to happen by the microcode during a sequence header, when the first frame of the new sequence is a reference frame, and the display is acting on the last frame of a previous sequence. </paragraph>
<paragraph id="P-0104" lvl="0"><number>&lsqb;0104&rsqb;</number> During the transition into and out of small picture mode, the hardware must make the adjustment in latency without disturbing the decode or display process. Frame sync must be adjusted to the new mode. Further, field parity must be maintained. As a result of making the adjustment into small picture mode, a delay of one frame time is introduced, which may effect PTS comparison. Subsequently, a skipped frame may be required in order to make up the time difference. This only occurs when entering small picture mode. When leaving small picture mode, there is no loss of synchronization. The transition could also come at a time when a picture is already being skipped or repeated. </paragraph>
<paragraph id="P-0105" lvl="0"><number>&lsqb;0105&rsqb;</number> Referring to <cross-reference target="DRAWINGS">FIG. 9</cross-reference>, the display format change signal is written asynchronously by the host. The format is received as a control signal into a display format register <highlight><bold>310</bold></highlight>, and microcode waits until processing the sequence header before writing the information into display format register <highlight><bold>310</bold></highlight>. This information is then seen by sync generator <highlight><bold>300</bold></highlight>, as well as register stages <highlight><bold>330</bold></highlight>, <highlight><bold>340</bold></highlight> and <highlight><bold>360</bold></highlight>. Register stage 1 <highlight><bold>330</bold></highlight> captures the information at the next frame sync. Decode processes use the stage 1 register <highlight><bold>330</bold></highlight>, and the display processes use the stage 3 register <highlight><bold>360</bold></highlight>. </paragraph>
<paragraph id="P-0106" lvl="0"><number>&lsqb;0106&rsqb;</number> Field counter <highlight><bold>320</bold></highlight> simply counts down from a starting number of fields in a frame to a value of 1, and then repeats. Counter <highlight><bold>320</bold></highlight> is loaded by sync generator <highlight><bold>300</bold></highlight> via a control signal as shown. Sync generator <highlight><bold>300</bold></highlight> also receives the VSYNC signal, as well as the output of stage 1 register <highlight><bold>330</bold></highlight>. Sync generator <highlight><bold>300</bold></highlight> creates three signals, namely, a &ldquo;frame sync&rdquo; signal, a &ldquo;new picture&rdquo; signal and a &ldquo;block video&rdquo; signal. The &ldquo;frame sync&rdquo; signal indicates to the decode process when to begin decoding a new frame. The &ldquo;new picture&rdquo; signal indicates to the display process when to begin displaying a new frame. &ldquo;Block video&rdquo; is used to selectively suppress one frame of video image during transition of the video decode system from a normal frame to a scaled frame. The frame sync and new picture signals are pulses that are created once every two field times. In normal mode, the signals are 180&deg; out of phase, but in scaling mode (in accordance with this invention) the signals are in phase. This is described further below in connection with the flowchart of <cross-reference target="DRAWINGS">FIG. 10</cross-reference>. </paragraph>
<paragraph id="P-0107" lvl="0"><number>&lsqb;0107&rsqb;</number> In all cases involving a switch into scaled picture mode, there is a repeated frame which is blocked from view at the display. The block is necessary due to buffer conflicts between the current reference frame and the reference frame that is currently being displayed. When video is blocked, the output of the decoder can be forced to a background color, such as black. </paragraph>
<paragraph id="P-0108" lvl="0"><number>&lsqb;0108&rsqb;</number> The latency adjustment is performed as soon as the stage 1 register changes. There is an absence of a frame sync which allows the current display frame to be scheduled to repeat. The sync generator then adjusts the frame sync to occur in phase with the new picture, causing the latency adjustment. During the repeated reference frame, the video is blocked for one frame time. </paragraph>
<paragraph id="P-0109" lvl="0"><number>&lsqb;0109&rsqb;</number> <cross-reference target="DRAWINGS">FIG. 10</cross-reference> is a flowchart of one embodiment of processing implemented by sync generator <highlight><bold>300</bold></highlight> (<cross-reference target="DRAWINGS">FIG. 9</cross-reference>). </paragraph>
<paragraph id="P-0110" lvl="0"><number>&lsqb;0110&rsqb;</number> With initiation <highlight><bold>600</bold></highlight>, processing waits for a VSYNC signal <highlight><bold>610</bold></highlight> representative of the start of a new field. Upon receipt of the VSYNC signal, processing generates a &ldquo;new picture&rdquo; sync signal and inquires whether the field is being repeated based on received MPEG-2 syntax <highlight><bold>630</bold></highlight>. The initial field counter (FC) value depends upon whether the field is to be repeated. If 3:2 pulldown is employed then the initial value of the field counter is 3 <highlight><bold>640</bold></highlight>, otherwise normal interlace is desired and the field counter is loaded with a value of 2. </paragraph>
<paragraph id="P-0111" lvl="0"><number>&lsqb;0111&rsqb;</number> Once the field counter is set, processing inquires whether scaling is to be implemented <highlight><bold>650</bold></highlight> and <highlight><bold>670</bold></highlight>, respectively. If no, then the decode system is in non-scaling or normal video mode. In this case, processing waits for a next VSYNC signal <highlight><bold>680</bold></highlight> and then inquires whether the field count equals two <highlight><bold>690</bold></highlight>. If no, (e.g., because the field counter was loaded with a value 3), the field counter is decremented <highlight><bold>710</bold></highlight> and processing waits for a next VSYNC signal <highlight><bold>680</bold></highlight>. Once the field count equals 2, the &ldquo;frame sync&rdquo; signal is generated <highlight><bold>700</bold></highlight>, after which the field count is decremented <highlight><bold>710</bold></highlight> and processing determines whether the field count value now equals 1 <highlight><bold>720</bold></highlight>. If the value equals 1, processing generates a &ldquo;new picture&rdquo; signal <highlight><bold>620</bold></highlight> after waiting for a new VSYNC <highlight><bold>610</bold></highlight>. </paragraph>
<paragraph id="P-0112" lvl="0"><number>&lsqb;0112&rsqb;</number> Assuming scaling mode is desired, then processing proceeds from inquiry <highlight><bold>650</bold></highlight> or <highlight><bold>670</bold></highlight> to wait for a next VSYNC <highlight><bold>730</bold></highlight>, after which determination is made whether the field count equals 1 <highlight><bold>740</bold></highlight>. If no, the field counter is decremented and processing returns to wait for a next VSYNC <highlight><bold>730</bold></highlight>. If the field count value is 1, then a new picture sync signal is generated <highlight><bold>750</bold></highlight>. Thereafter, the field counter is loaded with a value of 2 and the block video signal is generated <highlight><bold>760</bold></highlight>. Again, the block video signal is output from the sync generator to the display output interface (see <cross-reference target="DRAWINGS">FIG. 5</cross-reference>) for blocking of a next frame of video. </paragraph>
<paragraph id="P-0113" lvl="0"><number>&lsqb;0113&rsqb;</number> After sending the block video signal, processing enters a steady state, video scaling subprocess beginning by waiting for a next VSYNC signal <highlight><bold>780</bold></highlight>, after which processing determines whether the field count equals 1 <highlight><bold>790</bold></highlight>. If no, processing inquires whether the field count equals 2 <highlight><bold>840</bold></highlight>, and again if no, processing decrements the field counter <highlight><bold>860</bold></highlight> and returns to wait for the next VSYNC signal <highlight><bold>780</bold></highlight>. Otherwise, a determination is made as to whether the scaling command has now been turned off by the host system <highlight><bold>850</bold></highlight>. If no, the field counter is decremented and processing waits for a next VSYNC signal <highlight><bold>780</bold></highlight>. If the scaling mode has been switched off, then the field counter is decremented at instruction <highlight><bold>710</bold></highlight> in the non-scaling process described above. </paragraph>
<paragraph id="P-0114" lvl="0"><number>&lsqb;0114&rsqb;</number> If the field count equals 1 at inquiry <highlight><bold>790</bold></highlight>, then processing generates both the &ldquo;new picture&rdquo; signal and the &ldquo;frame sync&rdquo; signal in the same phase. Again, to implement scaling it is necessary to change the latency between the decode process and the display process from one and a half frame times to two frame times for reference pictures, making the new picture signal and frame sync signal in phase. Processing then determines whether the MPEG-2 repeat field is set <highlight><bold>810</bold></highlight> to decide whether to load the field counter with a value of 2 <highlight><bold>830</bold></highlight> or 3 <highlight><bold>820</bold></highlight> depending upon whether normal interlacing or 3:2 pulldown is desired. This is necessary even though an adjustment in latency is made in order to accommodate any type of frame rate conversion. After setting the field counter, processing returns to wait for a next VSYNC signal <highlight><bold>780</bold></highlight>. </paragraph>
<paragraph id="P-0115" lvl="0"><number>&lsqb;0115&rsqb;</number> Those skilled in the art will note from the above discussion that in order to implement smooth switching between normal mode and scaled video mode it is necessary to pass through a transitional phase before reaching the steady state scaling process. Further, it is necessary to adjust the frame sync signal to occur within the same phase as the new picture signal. </paragraph>
<paragraph id="P-0116" lvl="0"><number>&lsqb;0116&rsqb;</number> The present invention can be included, for example, in an article of manufacture (e.g., one or more computer program products) having, for instance, computer usable media. This media has embodied therein, for instance, computer readable program code means for providing and facilitating the capabilities of the present invention. The articles of manufacture can be included as part of the computer system or sold separately. </paragraph>
<paragraph id="P-0117" lvl="0"><number>&lsqb;0117&rsqb;</number> Additionally, at-least one program storage device readable by machine, tangibly embodying at least one program of instructions executable by the machine, to perform the capabilities of the present invention, can be provided. </paragraph>
<paragraph id="P-0118" lvl="0"><number>&lsqb;0118&rsqb;</number> The flow diagrams depicted herein are provided by way of example. There may be variations to these diagrams or the steps (or operations) described herein without departing from the spirit of the invention. For instance, in certain cases, the steps may be performed in differing order, or steps may be added, deleted or modified. All of these variations are considered to comprise part of the present invention as recited in the appended claims. </paragraph>
<paragraph id="P-0119" lvl="0"><number>&lsqb;0119&rsqb;</number> While the invention has been described in detail herein in accordance with certain preferred embodiments thereof, many modifications and changes therein may be effected by those skilled in the art. Accordingly, it is intended by the appended claims to cover all such modifications and changes as fall within the true spirit and scope of the invention. </paragraph>
</section>
</detailed-description>
</subdoc-description>
<subdoc-claims>
<claim id="CLM-00001">
<claim-text><highlight><bold>1</bold></highlight>. An integrated video decoding system comprising: 
<claim-text>a video decoder for decoding an encoded stream of video data, said video decoder producing a decoded stream of video data; and </claim-text>
<claim-text>a decimation unit coupled to said video decoder and adapted to selectively scale said decoded stream of video data for display. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00002">
<claim-text><highlight><bold>2</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said video decoding system further comprises a frame buffer, and wherein said decimation unit comprises means for scaling said decoded stream of video data prior to storage thereof in said frame buffer. </claim-text>
</claim>
<claim id="CLM-00003">
<claim-text><highlight><bold>3</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein said frame buffer comprises multiple defined memory areas for receiving I, P &amp; B frames of said decoded stream of video data, said multiple defined memory areas comprising a first area and a second area for receiving full size I and P frames of said decoded stream of video data, and at least one third area for receiving scaled I, P &amp; B frames of said decoded stream of video data commensurate with said first area and said second area receiving said full size I and P frames. </claim-text>
</claim>
<claim id="CLM-00004">
<claim-text><highlight><bold>4</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00003">claim 3</dependent-claim-reference>, wherein said at least one third area comprises at least three areas, said at least three areas receiving said scaled I, P &amp; B frames of said decoded stream of video data commensurate with said first area and said second area receiving said full size I and P frames of said decoded stream of video data. </claim-text>
</claim>
<claim id="CLM-00005">
<claim-text><highlight><bold>5</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00002">claim 2</dependent-claim-reference>, wherein said frame buffer comprises memory of predefined size, and wherein said video decoding system further comprises a normal video mode for displaying said decoded stream of video data without scaling, and a scaled video mode for scaling said decoded stream of video data prior to display, and wherein said video decoding system further comprises frame buffer pointer control logic for partitioning said memory of predefined size into multiple buffer areas when said video decoding system is in said normal video mode, wherein said multiple buffer areas comprise at least three buffer areas for receiving decoded I, P &amp; B frames of said decoded stream of video data, and wherein said frame buffer pointer control logic comprises means for partitioning said memory of predefined size into at least five buffer areas when said video decoding system is in said scaled video mode, said at least five buffer areas comprising a first area and a second area for receiving full size I and P frames of said decoded stream of video data, and at least a third area, a fourth area and a fifth area for receiving scaled I, P &amp; B frames of said decoded stream of video data. </claim-text>
</claim>
<claim id="CLM-00006">
<claim-text><highlight><bold>6</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00005">claim 5</dependent-claim-reference>, wherein said decimation unit comprises means for performing B frame memory reduction only on said decoded stream of video data when said video decoding system is in said normal video mode, said B frame memory reduction being performed prior to storage of each B frame of said decoded stream of video data in said frame buffer. </claim-text>
</claim>
<claim id="CLM-00007">
<claim-text><highlight><bold>7</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said video decoding system further comprises a frame buffer, and wherein said decimation unit comprises means for scaling said decoded stream of video data prior to storage thereof in said frame buffer, and wherein said video decoding system further comprises a normal video mode and a scaled video mode, and wherein said decimation unit is adapted to scale said decoded stream of video data for display when in said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00008">
<claim-text><highlight><bold>8</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, wherein said decimation unit is adapted to perform B frame memory reduction only on said decoded stream of video data prior to storage for each B frame in said frame buffer when said video decoding system is in said normal video mode. </claim-text>
</claim>
<claim id="CLM-00009">
<claim-text><highlight><bold>9</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00007">claim 7</dependent-claim-reference>, further comprising display mode switch logic for switching between said normal video mode and said scaled video mode, wherein said switching occurs without perceptual degradation of the display. </claim-text>
</claim>
<claim id="CLM-00010">
<claim-text><highlight><bold>10</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein said display mode switch logic comprises means for blocking a frame of video from said display when switching between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00011">
<claim-text><highlight><bold>11</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00011">claim 10</dependent-claim-reference>, wherein said display mode switch logic comprises a sync generator, said sync generator outputting a &ldquo;new picture&rdquo; signal and a &ldquo;frame sync&rdquo; signal, and wherein said sync generator comprises means for outputting said new picture signal and said frame sync signal in different phase when in said normal video mode, and means for outputting said new picture signal and said frame sync signal in phase when in said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00012">
<claim-text><highlight><bold>12</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein a frame of said decoded stream of video data includes an MPEG-2 repeat field signal, and wherein said display mode switch logic comprises means for ignoring said MPEG-2 repeat field signal when decoding said frame simultaneous with switching between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00013">
<claim-text><highlight><bold>13</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00009">claim 9</dependent-claim-reference>, wherein said video decoder comprises a decode process, and wherein said display comprises a display process, and said display mode switch logic comprises means for changing a latency between said decode process and said display process when switching between said normal video mode and said scaled video mode, said changing of said latency ensuring that said decoded stream of video data is accommodated within said frame buffer when in said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00014">
<claim-text><highlight><bold>14</bold></highlight>. The video decoding system of <dependent-claim-reference depends_on="CLM-00001">claim 1</dependent-claim-reference>, wherein said decimation unit&apos;s scaling of said decoded stream of video data comprises at least one of one-quarter or one-half frame reduction. </claim-text>
</claim>
<claim id="CLM-00015">
<claim-text><highlight><bold>15</bold></highlight>. A digital video decoding system comprising: 
<claim-text>a video decoder for decoding an encoded stream of video data, said video decoder producing therefrom a decoded stream of video data; </claim-text>
<claim-text>a video scalar for scaling said decoded stream of video data prior to storage thereof in a frame buffer, wherein said video decoding system comprises a normal video mode and a scaled video mode, said video scalar scaling said decoded stream of video data when said digital video decoding system is in said scaled video mode; and </claim-text>
<claim-text>display mode switch logic for switching between said normal video mode and said scaled video mode, wherein said switching occurs without perceptual degradation of a video display of said decoded stream of video data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00016">
<claim-text><highlight><bold>16</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, wherein said display mode switch logic includes logic for blanking said video display for a defined period of time when switching between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00017">
<claim-text><highlight><bold>17</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00011">claim 16</dependent-claim-reference>, wherein said predefined period of time for blanking said video display comprises one frame time of the digital video decoding system. </claim-text>
</claim>
<claim id="CLM-00018">
<claim-text><highlight><bold>18</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00011">claim 15</dependent-claim-reference>, wherein said video scalar comprises a decimation unit coupled to said video decoder and adapted to scale said decoded stream of video data prior to storage thereof in said frame buffer when said digital video decoding system is in said scaled video mode, said decoded stream of video data comprising I, P &amp; B frames and said decimation unit being adapted to scale said I, P &amp; B frames prior to storage thereof in said frame buffer. </claim-text>
</claim>
<claim id="CLM-00019">
<claim-text><highlight><bold>19</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein said decimation unit is further adapted to perform B frame memory reduction only of said decoded stream of video data prior to storage of B frames thereof in said frame buffer when said digital video decoding system is in said normal video mode. </claim-text>
</claim>
<claim id="CLM-00020">
<claim-text><highlight><bold>20</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein said video decoder comprises a decode process and said video display comprises a display process, and wherein said decode process and said display process have a first latency when in said normal video mode, and a second latency when in said scaled video mode, and wherein said display mode switch logic comprises means for switching between said first latency and said second latency when switching between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00021">
<claim-text><highlight><bold>21</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00022">claim 20</dependent-claim-reference>, wherein said display mode switch logic comprises a sync generator, said sync generator comprising means for ignoring an MPEG-2 repeat field signal of a frame of said I, P &amp; B frames being processed when switching between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00022">
<claim-text><highlight><bold>22</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00022">claim 21</dependent-claim-reference>, wherein said sync generator outputs a &ldquo;new picture&rdquo; signal and a &ldquo;frame sync&rdquo; signal for use in retrieving from said frame buffer and displaying said decoded stream of video data, wherein said sync generator outputs said new picture signal and said frame sync signal in phase when said digital video decode system is in said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00023">
<claim-text><highlight><bold>23</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00011">claim 18</dependent-claim-reference>, wherein said frame buffer comprises multiple defined memory areas for receiving I, P &amp; B frames of said decoded stream of video data, said multiple defined memory areas comprising a first area and a second area for receiving unscaled I and P frames of said decoded stream of video data, and at least one third area for receiving scaled I, P &amp; B frames of said decoded stream of video data commensurate with the first area and the second area receiving said unscaled I and P frames. </claim-text>
</claim>
<claim id="CLM-00024">
<claim-text><highlight><bold>24</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00022">claim 23</dependent-claim-reference>, wherein said unscaled I and P frames comprise full size I and P frames, and wherein said scaled I, P &amp; B frames comprise a fractional size of said full size I and P frames, said fractional size comprising at least one of one-quarter or one-half said full size. </claim-text>
</claim>
<claim id="CLM-00025">
<claim-text><highlight><bold>25</bold></highlight>. A digital video decoding system comprising: 
<claim-text>a normal video mode and a scaled video mode, wherein when in said normal video mode, full size frames are output for display on a video display coupled to said digital video decoding system and when in scaled video mode, scaled frames comprising a fractional size of said full size frames are output for display on said video display; </claim-text>
<claim-text>a frame buffer for temporarily storing said full size frames and said scaled frames after a decoding time thereof and prior to a display time thereof, wherein there is a predefined latency between said decoding time and said display time; and </claim-text>
<claim-text>wherein said predefined latency between said decoding time and said display time comprises a first latency when in normal video mode and a second latency when in scaled video mode. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00026">
<claim-text><highlight><bold>26</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein said decoded stream of video data comprises an interlaced format, and said first latency comprises one and one half frame times for reference frames, and said second latency comprises two frame times for reference frames. </claim-text>
</claim>
<claim id="CLM-00027">
<claim-text><highlight><bold>27</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, further comprising display mode switch logic for switching between said normal video mode and said scaled video mode, wherein said switching occurs without perceptual degradation of said video display. </claim-text>
</claim>
<claim id="CLM-00028">
<claim-text><highlight><bold>28</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00022">claim 27</dependent-claim-reference>, wherein said display mode switch logic includes logic for blanking said video display for a predefined period of time when switching between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00029">
<claim-text><highlight><bold>29</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00022">claim 27</dependent-claim-reference>, wherein said display mode switch logic includes a sync generator, said sync generator including means for ascertaining during said switching from normal video mode to scaled video mode whether a next frame to be displayed includes an MPEG-2 repeat field signal, and if so, for suppressing said MPEG-2 repeat field signal when displaying said next frame. </claim-text>
</claim>
<claim id="CLM-00030">
<claim-text><highlight><bold>30</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00022">claim 25</dependent-claim-reference>, wherein said frame buffer comprises multiple defined memory areas for receiving I, P &amp; B frames of a decoded stream of video data, said multiple defined memory areas comprising a first memory area and a second memory area for receiving full size I and P frames of said decoded stream of video data, and when in said scaled video mode, at least one third area for receiving scaled I, P &amp; B frames of said decoded stream of video data commensurate with said first area and said second area receiving said full size I and P frames. </claim-text>
</claim>
<claim id="CLM-00031">
<claim-text><highlight><bold>31</bold></highlight>. The digital video decoding system of <dependent-claim-reference depends_on="CLM-00033">claim 30</dependent-claim-reference>, further comprising a video decoder for decoding an encoded stream of video data and producing therefrom said decoded stream of video data, and a decimation unit coupled to said video decoder and adapted to scale said decoded stream of video data for said video display when said digital video decoding system is in said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00032">
<claim-text><highlight><bold>32</bold></highlight>. A frame buffer for a digital video decoding system having video scaling capabilities, said frame buffer comprising: 
<claim-text>multiple defined memory areas for receiving I, P &amp; B frames of a decoded stream of video data, said multiple defined memory areas comprising: 
<claim-text>(i) a first area and a second area for receiving full size I and P frames of said decoded stream of video data; and </claim-text>
<claim-text>(ii) at least one third area for receiving scaled I, P &amp; B frames of said decoded stream of video data commensurate with said first area and said second area receiving said full size I and P frames. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00033">
<claim-text><highlight><bold>33</bold></highlight>. The frame buffer of <dependent-claim-reference depends_on="CLM-00033">claim 32</dependent-claim-reference>, wherein said at least one third area comprises at least three areas, said at least three areas receiving said scaled I, P &amp; B frames of said decoded stream of video data. </claim-text>
</claim>
<claim id="CLM-00034">
<claim-text><highlight><bold>34</bold></highlight>. The frame buffer of <dependent-claim-reference depends_on="CLM-00033">claim 33</dependent-claim-reference>, wherein said multiple defined memory areas comprise a predefined region of memory coupled to said digital video decoding system, wherein said full size I and P frames of said decoded stream of video data are employed by a decode process of said digital video decoding system and said scaled I, P &amp; B frames of said decoded stream of video data are employed by a display process of said digital video decoding system when said digital video decoding system is in a scaled video mode. </claim-text>
</claim>
<claim id="CLM-00035">
<claim-text><highlight><bold>35</bold></highlight>. A frame buffer for a digital video decoding system having video scaling capabilities, said frame buffer comprising: 
<claim-text>memory associated with said digital video decoding system, said memory being of a predefined size; </claim-text>
<claim-text>control logic for partitioning said memory of predefined size into three buffer areas when said digital video decoding system is in a normal video mode, wherein said three buffer areas receive full size I, P &amp; B frames of a decoded stream of video data; and </claim-text>
<claim-text>wherein said control logic is further adapted to partition said memory into at least five buffer areas when said digital video decoding system is in a scaled video mode, said at least five buffer areas comprising a first area and a second area for receiving full size I and P frames of said decoded stream of video data, and at least a third area, a fourth area and a fifth area for receiving scaled I, P &amp; B frames of said decoded stream of video data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00036">
<claim-text><highlight><bold>36</bold></highlight>. A method for processing an encoded stream of video data employing a digital video decoding system, said method comprising: 
<claim-text>decoding the encoded stream of video data to produce a decoded stream of video data; </claim-text>
<claim-text>scaling the decoded stream of video data when the digital video decoding system is in a scaled video mode, said scaling producing a scaled decoded stream of video data; and </claim-text>
<claim-text>after said scaling, buffering said scaled decoded stream of video data in a frame buffer to await display thereof. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00037">
<claim-text><highlight><bold>37</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 36</dependent-claim-reference>, further comprising displaying said scaled decoded stream of video data upon retrieval from said frame buffer, wherein said decoding and said displaying occur in phase when said digital video decoding system is in said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00038">
<claim-text><highlight><bold>38</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 37</dependent-claim-reference>, wherein said decoding and said displaying occur out of phase when said digital video decoding system is in a normal video mode in which said decoded stream of video data does not undergo said scaling. </claim-text>
</claim>
<claim id="CLM-00039">
<claim-text><highlight><bold>39</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 38</dependent-claim-reference>, further comprising switching between said normal video mode and said scaled video mode, said switching comprising transitioning said decoding and said displaying from out of phase in said normal video mode to in phase in said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00040">
<claim-text><highlight><bold>40</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 39</dependent-claim-reference>, wherein said switching includes blanking said display for one frame time when transitioning between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00041">
<claim-text><highlight><bold>41</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 39</dependent-claim-reference>, wherein said switching between said normal video mode and said scaled video mode comprises delaying switching until said display is displaying a reference frame of said decoded stream of video data. </claim-text>
</claim>
<claim id="CLM-00042">
<claim-text><highlight><bold>42</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 36</dependent-claim-reference>, wherein said decoded stream of video data comprises I, P &amp; B frames, and wherein said scaling comprises scaling said I, P &amp; B frames when said digital video decoding system is in said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00043">
<claim-text><highlight><bold>43</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 42</dependent-claim-reference>, wherein said buffering comprises buffering unscaled I and P frames in said frame buffer commensurate with buffering scaled I, P &amp; B frames when in said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00044">
<claim-text><highlight><bold>44</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 43</dependent-claim-reference>, further comprising performing B frame memory reduction only on said decoded stream of video data when said digital video decoding system is in a normal video mode, said B frame memory reduction on said decoded stream of video data being performed prior to buffering of said decoded stream of video data in said frame buffer. </claim-text>
</claim>
<claim id="CLM-00045">
<claim-text><highlight><bold>45</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00033">claim 36</dependent-claim-reference>, wherein said digital video decoding system includes a normal video mode, and said method comprises switching between said normal video mode and said scaled video mode, and wherein said switching comprises ignoring an MPEG-2 repeat field signal of a frame of the decoded stream of video data being processed for display when switching between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00046">
<claim-text><highlight><bold>46</bold></highlight>. A method for processing an encoded stream of video data employing a digital video decoding system having a normal video mode and a scaled video mode, said method comprising: 
<claim-text>decoding the encoded stream of video data to produce a decoded stream of video data; </claim-text>
<claim-text>scaling, when in said scaled video mode, the decoded stream of video data prior to storage thereof in a frame buffer; and </claim-text>
<claim-text>switching between said normal video mode and said scaled video mode without perceptual degradation of a video display of said decoded stream of video data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00047">
<claim-text><highlight><bold>47</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, wherein said switching includes blanking said video display for at least one frame time when transitioning between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00048">
<claim-text><highlight><bold>48</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further comprising decimating, when in said normal video mode, the decoded stream of video data prior to storage thereof in a frame buffer, said decimating comprising performing B frame memory reduction only on said decoded stream of video data. </claim-text>
</claim>
<claim id="CLM-00049">
<claim-text><highlight><bold>49</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, wherein said switching comprises ignoring an MPEG-2 repeat field signal of a frame of the decoded stream of video data being processed for display when switching between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00050">
<claim-text><highlight><bold>50</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00044">claim 46</dependent-claim-reference>, further comprising displaying said decoded stream of video data upon retrieval from said frame buffer, wherein said decoding and said displaying occur in phase when said digital video decoding system is in said scaled video mode, and said decoding and said displaying occur out of phase when said digital video decoding system is in said normal video mode. </claim-text>
</claim>
<claim id="CLM-00051">
<claim-text><highlight><bold>51</bold></highlight>. A method for processing an encoded stream of video data employing a digital video decoding system having a normal video mode and a scaled video mode, said method comprising: 
<claim-text>decoding the encoded stream of video data to produce a decoded stream of video data; </claim-text>
<claim-text>buffering the decoded stream of video data; </claim-text>
<claim-text>displaying the buffered decoded stream of video data; and </claim-text>
<claim-text>controlling said displaying and said decoding such that there exists a first latency between decoding time and displaying time for a frame when said digital video decoding system is in said normal video mode and a second latency between decoding time and display time for a frame when said digital video decoding system is in said scaled video mode. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00052">
<claim-text><highlight><bold>52</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 51</dependent-claim-reference>, wherein said decoded stream of video data comprises an interlaced format, and wherein said first latency comprises one and one half frame times for reference frames, and said second latency comprises two frame times for reference frames. </claim-text>
</claim>
<claim id="CLM-00053">
<claim-text><highlight><bold>53</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 51</dependent-claim-reference>, further comprising switching between said normal video mode and said scaled video mode, said switching including changing between said first latency and said second latency of decoding time to display time, wherein said switching occurs without perceptual degradation of the display of said decoded stream of video data. </claim-text>
</claim>
<claim id="CLM-00054">
<claim-text><highlight><bold>54</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 53</dependent-claim-reference>, wherein said switching includes blanking said display for a predefined period of time when switching between said normal video mode and said scaled video mode. </claim-text>
</claim>
<claim id="CLM-00055">
<claim-text><highlight><bold>55</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 54</dependent-claim-reference>, wherein said switching comprises ascertaining when switching from normal video mode to scaled video mode whether a next frame to be displayed includes an MPEG-2 repeat field signal, and if so, suppressing said MPEG-2 repeat field signal when displaying said next frame. </claim-text>
</claim>
<claim id="CLM-00056">
<claim-text><highlight><bold>56</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 51</dependent-claim-reference>, wherein said buffering comprises buffering the decoded stream of video data in a frame buffer comprising multiple defined memory areas for receiving I, P &amp; B frames of said decoded stream of video data, said buffering comprising, when in said scaled video mode, buffering full size I and P frames of said decoded stream of video data commensurate with buffering scaled I, P &amp; B frames of said decoded stream of video data. </claim-text>
</claim>
<claim id="CLM-00057">
<claim-text><highlight><bold>57</bold></highlight>. A method for allocating a frame buffer for a digital video decoding system having video scaling capabilities, said method comprising: 
<claim-text>partitioning the frame buffer into multiple memory areas for receiving I, P &amp; B frames of a decoded stream of video data, said partitioning comprising: 
<claim-text>defining a first area and a second area for receiving full size I and P frames of said decoded stream of video data, and </claim-text>
<claim-text>defining at least one third area for receiving scaled I, P &amp; B frames of said decoded stream of video data commensurate with the first area and the second area receiving the full size I and P frames. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00058">
<claim-text><highlight><bold>58</bold></highlight>. A method for allocating a frame buffer for a digital video decoding system having video scaling capabilities, said method comprising: 
<claim-text>partitioning the frame buffer into three buffer areas when said digital video decoding system is in a normal video mode, wherein said three buffer areas receive full size I, P &amp; B frames of a decoded stream of video data; and </claim-text>
<claim-text>partitioning said frame buffer into at least three buffer areas when said digital video decoding system is in a scaled video mode, said at least three buffer areas comprising a first area and a second area for receiving full size I and P frames of said decoded stream of video data, and at least one third area for receiving scaled I, P &amp; B frames of said decoded stream of video data. </claim-text>
</claim-text>
</claim>
<claim id="CLM-00059">
<claim-text><highlight><bold>59</bold></highlight>. The method of <dependent-claim-reference depends_on="CLM-00055">claim 58</dependent-claim-reference>, wherein said at least one third area comprises at least a third area, a fourth area and a fifth area for receiving said scaled I, P &amp; B frames of said decoded stream of video data, wherein said at least third area, fourth area and fifth area each comprise less area than said first area or said second area. </claim-text>
</claim>
<claim id="CLM-00060">
<claim-text><highlight><bold>60</bold></highlight>. An article of manufacture comprising: 
<claim-text>a computer program product comprising a computer usable medium having computer readable program code means therein for use in processing an encoded stream of video data employing a digital video-decoding system, said computer readable program code means in said computer program product comprising: 
<claim-text>computer readable program code means for causing a computer to effect decoding the encoded stream of video data to produce a decoded stream of video data; </claim-text>
<claim-text>computer readable program code means for causing a computer to effect scaling the decoded stream of video data when the digital video decoding system is in a scaled video mode, said scaling producing a scaled decoded stream of video data; and </claim-text>
<claim-text>computer readable program code means for causing a computer to effect buffering said scaled decoded stream of video data in a frame buffer to await display thereof. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00061">
<claim-text><highlight><bold>61</bold></highlight>. An article of manufacture comprising: 
<claim-text>a computer program product comprising a computer usable medium having computer readable program code means therein for use in processing an encoded stream of video data employing a digital video decoding system having a normal video mode and a scaled video mode, said computer readable program code means in said computer program product comprising: 
<claim-text>computer readable program code means for causing a computer to effect decoding the encoded stream of video data to produce a decoded stream of video data; </claim-text>
<claim-text>computer readable program code means for causing a computer to effect scaling the decoded stream of video data prior to storage thereof in a frame buffer when said digital video decoding system is in said scaled video mode; and </claim-text>
<claim-text>computer readable program code means for causing a computer to effect switching between said normal video mode and said scaled video mode without perceptual degradation of a video display of said decoded stream of video data. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00062">
<claim-text><highlight><bold>62</bold></highlight>. An article of manufacture comprising: 
<claim-text>a computer program product comprising a computer usable medium having computer readable program code means therein for use in processing an encoded stream of video data employing a digital video decoding system having a normal video mode and a scaled video mode, said computer readable program code means in said computer program product comprising: 
<claim-text>computer readable program code means for causing a computer to effect decoding the encoded stream of video data to produce a decoded stream of video data; </claim-text>
<claim-text>computer readable program code means for causing a computer to effect buffering the decoded stream of video data; </claim-text>
<claim-text>computer readable program code means for causing a computer to effect displaying the buffered decoded stream of video data; and </claim-text>
<claim-text>computer readable program code means for causing a computer to effect controlling said displaying and said decoding such that there exists a first latency between decoding time and displaying time for a frame when said digital video decoding system is in said normal video mode and a second latency between decoding time and display time for a frame when said digital video decoding system is in said scaled video mode. </claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00063">
<claim-text><highlight><bold>63</bold></highlight>. An article of manufacture comprising: 
<claim-text>a computer program product comprising a computer usable medium having computer readable program code means therein for allocating a frame buffer for a digital video decoding system having video scaling capabilities, said computer readable program code means in said computer program product comprising: 
<claim-text>computer readable program code means for causing a computer to effect partitioning the frame buffer into multiple memory areas for receiving I, P &amp; B frames of a decoded stream of video data, said computer readable program code means for causing a computer to effect partitioning comprising: 
<claim-text>(i) computer readable program code means for causing a computer to effect defining a first area and a second area for receiving full size I and P frames of said decoded stream of video data, and </claim-text>
<claim-text>(ii) computer readable program code means for causing a computer to effect defining at least one third area for receiving scaled I, P &amp; B frames of said decoded stream of video data commensurate with said first area and said second area receiving the full size I and P frames. </claim-text>
</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00064">
<claim-text><highlight><bold>64</bold></highlight>. An article of manufacture comprising: 
<claim-text>a computer program product comprising a computer usable medium having computer readable program code means therein for use in allocating a frame buffer for a digital video decoding system having video scaling capabilities, said computer readable program code means in said computer program product comprising: 
<claim-text>computer readable program code means for causing a computer to effect partitioning the frame buffer into three buffer areas when said digital video decoding system is in a normal video mode, wherein said three buffer areas receive full size I, P &amp; B frames of a decoded stream of video data; and </claim-text>
<claim-text>computer readable program code means for causing a computer to effect partitioning said frame buffer into at least three buffer areas when said digital video decoding system is in a scaled video mode, said at least three buffer areas comprising a first area and a second area for receiving full size I and P frames of said decoded stream of video data, and at least one third area for receiving scaled I, P &amp; B frames of said decoded stream of video data.</claim-text>
</claim-text>
</claim-text>
</claim>
</subdoc-claims>
<subdoc-drawings id="DRAWINGS">
<heading lvl="0" align="CENTER">Drawings</heading>
<representative-figure>5</representative-figure>
<figure id="figure-D00000">
<image id="EMI-D00000" file="US20030002584A1-20030102-D00000.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00001">
<image id="EMI-D00001" file="US20030002584A1-20030102-D00001.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00002">
<image id="EMI-D00002" file="US20030002584A1-20030102-D00002.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00003">
<image id="EMI-D00003" file="US20030002584A1-20030102-D00003.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00004">
<image id="EMI-D00004" file="US20030002584A1-20030102-D00004.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00005">
<image id="EMI-D00005" file="US20030002584A1-20030102-D00005.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00006">
<image id="EMI-D00006" file="US20030002584A1-20030102-D00006.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00007">
<image id="EMI-D00007" file="US20030002584A1-20030102-D00007.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00008">
<image id="EMI-D00008" file="US20030002584A1-20030102-D00008.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00009">
<image id="EMI-D00009" file="US20030002584A1-20030102-D00009.TIF" imf="TIFF" ti="DR"/>
</figure>
<figure id="figure-D00010">
<image id="EMI-D00010" file="US20030002584A1-20030102-D00010.TIF" imf="TIFF" ti="DR"/>
</figure>
</subdoc-drawings>
</patent-application-publication>
